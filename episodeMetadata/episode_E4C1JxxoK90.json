{
  "id": "E4C1JxxoK90",
  "title": "906: How Prof. Jason Corso Solved Computer Visionâ€™s Data Problem",
  "channelId": "UCMbtqTGdSsxYYhhTpV4lSTQ",
  "publishedAt": "2025-07-18T11:00:34.000Z",
  "cleanText": "This is episode number 96 with Dr. Jason Corso, professor at the University of Michigan and co-founder of Voxel51.\n\nWelcome back to the SuperDataScience Podcast. We've got an exceptional guest for you today. It's Dr. Jason Corso. He's professor of robotics, electrical engineering, and computer science at the prestigious University of Michigan. With over 20 years of research experience spanning video understanding, robotics, and AI, he's published over 150 academic papers in that time that together have been cited over 20,000 times. In addition to his academic work, he's also co-founder and chief science officer at Voxel51, a leading platform for visual AI development. His work bridges academic innovation and obviously real-world impact, earning him major honors that I don't have time to list, but there's a ton of them. Today's episode skews a bit more towards hands-on practitioners like data scientists and ML engineers, particularly anyone tackling computer vision problems. That said, Jason is a charismatic and exceptional communicator, so perhaps any listener to this podcast will enjoy today's episode. In it, Jason details how his research spin out Voxel51 is solving the biggest bottleneck in computer vision, the surprising way autonomous vehicles learn to handle accidents they've never seen, and why the secret to better AI models isn't better algorithms, it's something else that's hiding in plain sight. All right, let's jump right into our conversation. Jason, welcome to the SuperDataScience Podcast. Where are you calling in from today?\n\nUh, great to be here, Jon. I'm calling in from Western New York in Buffalo.\n\nNice. It is a town that uh it's it's the airport that I frequent most in the world. I actually I love that airport. It is tiny, efficient. Uh it's kind of just the right size. It has everything you need, but you can get in and out of there very quickly. And so I frequently am going between New York and Toronto, and Buffalo is my airport of choice. Uh lots of interesting there's there's a famous art museum in Buffalo, isn't there?\n\nUh there is. Uh, it recently had a renovation. It's called the AKG now, but it's used to be called the Albbright Knox Gallery, and it was actually designed by a local architect by the name of Eie Green. And in fact, when I uh when I used to live here uh some 15, 20 years ago, I owned one of his houses as well, and it was such a cool little house on the west side. Buffalo is a great old city, old architecture and stuff like that.\n\nFor sure. It's something that probably people don't expect if they've never been there, but it's stunning. You know, you can kind of from the highway, you can kind of look, you can there's a lot of great vantage points of the architecture in the city as you drive around it. And it's beautiful.\n\nAbsolutely. Yeah. Good people, good views, and uh we got the Bills as well. So, there you go.\n\nYeah, the Buffalo Bills for sure. That was my football team growing up as well. Getting that uh in Toronto, we had, you know, we'd get American broadcasts over the lake, over Lake Ontario. And so my local football team growing up was the Bills as well.\n\nUh so I I lived through the was it four or five years that the Bills made the Super Bowl in the 90s and never won.\n\nIt was four years although pre it predates my my Buffalonian status but um it still is painful for the region I think. Although these days uh the Bills kind of the city kind of rallies behind or the whole region kind of rallies behind the Bills. Uh but anyway yeah\n\nfor sure they're a strong club. Um, so yeah, so despite living in Buffalo, you are actually actually a University of Michigan professor. You're a professor of robotics over there as well as a professor of electrical engineering and computer science. Tell us a bit Jason or Professor Corso about the work that you do over there at Michigan.\n\nRight on. So please call me Jason. Uh, so so yeah, so I I live this dual life. I also have a family. My family's here. uh but um yeah I'm a 20some year veteran of of the generally computer vision um the angle I take in computer vision is uh what I call like physically grounded cognitive systems right so I'm interested in problems since my dissertation right my dissertation was called techniques for vision-based human computer interaction right so we had cameras watching humans and the humans would do things and then that would in you know create interaction scenarios you know in fact we built this thing called the 4D touchpad. I think it was at like a workshop at CVPR in maybe like 2003 or something like that. And it it used like gesture tracking uh and in some sense created multi-touch prior to there being like iPads and so on. But that's the type of of work that I've done over the years. My research group uh has focused on areas like uh video captioning. You know, we have the f one of the first if not the first paper at CBPR 2013 on video captioning. We apply that nowadays to guidance of humans doing activities, you know, like I'm cooking a dish in my kitchen or whatever, right? Like I'm about to reach for the salt, but the recipe is for sugar and and my AI can tell me, you know, don't don't use salt, use sugar. Or more more socially relevant perhaps is an exciting project we have right now, which is applying the same type of AI agentic guidance type scenarios in rural healthcare scenarios, right? like a major problem in the US and really worldwide is just a shortage of trained physicians. So our project is is trying to enable the upskilling of like RNs or physicians assistants or nurse practitioners who can go out into rural America in in say a mobile clinic or whatnot and do anything from like um cardiac ultrasound to like deep vein thrombosis in the lower limbs with um AI kind of guiding them through every step of the process, you know. So it's it's an exciting area. I really enjoy computer vision. are joining the boundaries of like computer vision and the fact that like humans are looking to be or or like we are trying to build systems that work alongside humans to upscale them or to basically um create you know a better world in some sense and maybe that's pie in the sky but that's that's a real driver right like we do things by by humans for humans and of humans right so so that's that's been a 20 year 20 year driver\n\nyeah and it sounds it sounds like cutting edge research it sounds like it would be very impactful. It doesn't sound pie in the sky either. It sounds like a real tangible way to be making the world a better place with with which AI with AI, which is perhaps the thing that we love most on this show uh above all. And you me you mentioned something there CVPR for our listeners who don't know what that means. It's the conference on computer vision and pattern recognition. And you can correct me if I'm wrong on this Jason, but I think it's hands down the biggest most important academic conference on computer vision in the world. Uh it's definitely one of the two. Yeah. So there there have been two historically that are among the top. So CBPR is one of them. The other one is called ICCV um international conference on computer vision. Usually these generally there are two conferences per year and so it's CVPR happens every year ICCV happens every other year and then the third one is ECCV European conference on computer vision and that alternates with ICCB but generally those are the two key conferences in computer vision. there are many others that are that are amazing especially now as the as the field has been exploding you know in some sense I I wish there were even more conferences that were a little smaller right because I mean when I was a grad student CVPR had something like 500 papers max maybe a thousand attendees actually probably even had less than 500 papers you know 20 years ago nowadays I think there's like 2500 papers on average every year 10,000 plus attendees uh it's great to see the growth but it's also hard to know where to go how to focus like what what to you know what you know what you're going to learn at the conference and so on.\n\nFor sure. Interesting to hear about that growth over time. And so with all of this experience with this 20 years of experience that you have in computer vision, you identified about a decade ago some key problems that could be solved in this space with a technological solution and you founded you co-founded a company called Voxel51. You were CEO of that company for it looks like about seven years and then for the past few years you've been chief science officer. Tell us about Voxel51, how it got started, how it came out of your university research.\n\nAbsolutely. Yeah. So, so you know I as a as an individual um I identify kind of like as a creator. So I've always had like one hand on the keyboard while I'm lecturing or whatever or or meeting with someone because I just love to build things. And over time in you know in in the in the research lab we we began to notice that data was playing a key role alongside algorithmic or model work. You know usually when you when you're an academic you're writing a paper generally that paper's going to be about a new model or a new algorithm. And although you know there had been some early works in data sets like Caltech 256 or like in an imageet and so on like the the number of data papers was significantly dwarfed by the number of model papers and and it remains true today right it's just the the general mind the mindset however we began to notice that like as model capabilities began to improve for a given problem say object detection or you know even more concretely like pedestrian avoidance for autonomous vehicles just as an example, like we began to notice that you can kind of pull a model architecture off the shelf, one of maybe half a dozen or so, and the performance you got out of of the system you ended up training was more of a function of the data set you used to train that model than it was which of the six model architectures you chose. Uh, and you know, we we basically began to build this conviction around data is at least as important, if not more important than the model architecture you choose. And ultimately, Box Soul 51 grew out of that observation or that vision, right? Like this this notion that wait people need data. And it's not like we were the first to think this or the only to think this, right? But like our initial one of our initial mantras was better data, better models. And and we like truly believe in that. Um but and importantly as a creator or a builder like um there just was not enough tooling around how one works with data, how one analyzes data, right? like as a grad student, I had this data set where I actually went into the cafeteria early one morning and took some photos, you know, of of the layout I was trying to do m basically like semantic mapping of of the environment and I think my data set had a hundred images, maybe even a little less than that, right? So, like, you know, I could look and study the impact of any algorithmic modification on every single sample of that data set when I when I was doing this whatever it was 20ome years ago. Um fast forward to even just 10 years after that like 10 years ago when imaginet came around a million data samples or actually the the full image is 20 20 some million samples right nowadays you have five billion samples per data set even in some open source data sets like the Lion 5B you may have heard of or like I know the Florence the Florence 2 data set or Florence 2 model was trained on a five billion sample data set it's just impossible it was it was becoming impossible to like basically put your eyeballs on enough of the data samples to build an intuition over what when you work over with your model how it's going to be impacted by the data and vice versa and so on. So, so ultimately box 51 is a company that tries to speed up the work you do with your data and the work you do with your models by providing the right dev tool in some sense for visual AI. Um, we are an open source tool. We released the open source tool in August of 20.\n\nUh it's been a while ago now that I'm forgetting. It's either 2019 or 2020. Don't quote me on which one of those it is. We have about uh three million installs of of that or more. Um and you know we've always tried to have the like the IC like the ideal user ideal customer of the of that tool is really a like heav heavy technical data scientist or computer vision scientist. And so it's, you know, super flexible and you can write plugins for it or, you know, extensions for it for the front end and the back end. And um, yeah. Anyway, great. So that's a quick overview of where we were and sort of why we got started. Um, not sure if you have any questions about that.\n\nUh, no, it's it's a it's a great story on the origin. You identify a painoint through your expertise and then you're able to create a product to solve that painpoint. and you've already had a huge amount of success with three million downloads and uh the GitHub repo which so we'll talk about I realize the open source is a little bit different but it also gives some perspective on how important solutions like this are when the GitHub repo has 10,000 stars like your stuff.\n\nAbsolutely.\n\nYep. Um and uh have you ever heard of um so there's we actually recently in an episode in episode 901 which came out a few weeks ago um we we had someone on the show named Lilith Bat Leah who she runs um workshops at ICML and I clear two other big uh machine learning conferences which obviously you know Jason but just for our audience um and uh so she ran working groups or she runs working groups at uh on datacentric machine learning. Uh so it's a DMLR, datacentric machine learning research is kind of like the acronym that's used there. Have you come across that that acronym before? It sounds similar to what you're describing.\n\nUh absolutely. I mean I mean datacentric ML can mean a lot of things. Uh but even at Voxel we we used to use that in our like outbound communitydriven marketing material as well. Like I mean I you know it I say it can mean a lot of things not to put it down but it's it is like it's it's critical to recognize that you know when we think of building technical technological software systems we think of writing code and then we're you know we hope that you know like we can debug a software system like the the tool we're using right now to record this right. Um but when you think of machine learning there's code and then there's the data that goes into the code in some sense like it gets kind of transformed into data weights or coefficients or something something like that. But these two things are inseparable and and as the evolution from you know what what some folks have called software 1.0 just code to software 2.0 which is essentially just a different type of code. It's just humans can't\n\n\nReally write it.\nWe write other code to train it from data.\nUm, you know, so like data, data has been used to train up machine learning systems for decades now.\nBut I think there's just an when we, when we collectively as a, as a research community or a user community, think of datacentric machine learning, I think what, what I was saying earlier, where we tend to emphasize that, oh, wait, it's not just that there's data in this code and the code is more important, it's that you really cannot separate or divorce the two things, right?\nLike the data and the structure, the model structure, or even like the ops underneath it.\nThese are, these are wed together in a way that is critical to understand all facets.\nAnd if you really want to build a successful ML system or AI system, you really need the right tooling around analyzing the data, analyzing the models, analyzing the ops, and they, they do need to work in concert so that you have a good sense of what's going on.\nIt seems really obvious when we say it out loud like this, but it, it is amazing how much attention, you know, in terms of new releases go on to, you know, some exciting new model.\nBut in something like this in computer vision, where you think about it's probably easy for users to imagine something like the machine vision problem of an autonomous vehicle, where you have sensors on a vehicle that are driving through streets and you wanted to make safe driving decisions.\nUm, obviously as close to 100% of the time as possible in that kind of scenario.\nIt makes it kind of easy to imagine how, you know, the model, if it has, you know, some percentage improvement over some other model, like that's great, but the model isn't going to be valuable at all if you don't have data covering the whole gamut of situations that that autonomous vehicle is going to run into.\nUh, you know, if you, if you only train the vehicle on situations where there's no car accidents, it's like, never, there's no possible world where that AI system could know how to handle, uh, you know, seeing an accident happen right in front of it.\nAnd so hopefully, you know, that's a very simplistic example that I just gave, but hopefully that, you know, it kind of allows us to visualize pretty easily the critical importance of data in having any AI model work effectively in the real world, which computer vision systems, I think, basically always are operating in the real world.\nYep.\nSo, I mean, I think you're, I think you hit it on the head, really, right?\nLike that, like, and I, and I think it's a great example, especially because, um, you know, I mean, I, I have an 18-year-old recently taught her how to drive and so on.\nI'm wondering like, how many miles does she have to drive before she's going to see even like a near miss or even just a situation where like a kid runs out into the street, right?\nUm, so I think the number is something like, um, it's in the tens of millions of miles driven for every accident that's recorded by like the US government or Nitsa.\nUm, and you know, and so like, actually finding the hardest part about this, this, this world of building highly successful, like 99.999, whatever percent accurate systems is getting your, getting the data, then getting the data labeled, and then training the model and figuring out what are the failure modes, what are the success cases, what are my failure modes, and where do I need to add more data and begin this process, right?\nSo actually, something I'm really excited about at Voxel51 right now is this new direction we've taken our product, you know, like I think annotation companies, right?\nThe problem of going, taking raw data and and labeling, put box boxes or class labels or classes or whatever on your data samples to train the machine learning algorithm on it, um, those were probably like the first wave of companies in, in computer vision, at least in modern computer vision, machine learning based computer vision, um, but Voxel51 never identified as an annotation company.\nWe were always in some sense, we, we explicitly decided strategically, are we are not an annotation company.\nWe actually don't even support.\nYou can do a lot of things in Voxel51, including load varieties of different labels into the software tool and visualize them and so on, but until this coming summer, you will not have been able to edit them in our tool.\nLike we were so against it, almost like we had almost like a one button mouse challenge that Apple had over the years, right?\nUm, and, and, um, you know, nowadays, like that, that annotation problem is so, has been so central, but I think it's transforming based on this, these two, these decades of progress.\nAnd so with, um, performant foundation models now, we have this tool, this new product line called Verified Auto-Labeling, which can take this raw media, automatically generate labels on it via foundation models.\nAnd obviously, like there's a, there's going to be a spectrum of performance, right?\nFor certain classes that the foundation models have heard a lot, have seen a lot, like pedestrians or bicycles or other vehicles, it's going to work pretty well.\nFor other scenarios like teddy bears or, you know, certain types of hats or coffee mugs, whatever, maybe it'll work less.\nBut the, but the critical aspect and what's I think really exciting from our perspective is the V and the verification part of that, right?\nUm, what our workflow is, right?\nYou take your raw media, you apply foundation models, and we have like a battery of them you can apply against it, and then we have our custom ML that will rank the outputs from those foundation models so that you can in batch have high confidence that you're like automatically going to accept something like 70% of them, you know, and already that's a huge amount of money that you're saving and like in time and so on.\nAnd then for the remaining 30%, we can still rank them again.\nSo you can have your human labelers, your human QA people only spending time on the challenging scenarios, right?\nThe scenarios like the ones you're pointing out, like the corner cases, the hard cases that we really need humans to look at and humans to verify and so on.\nVery cool.\nSo this Verified Auto-Labeling, this new initiative that's, you said summer, so we're talking northern hemisphere summer for our international listeners.\nSo it's kind of like around the time that this episode is coming out is when this Verified Auto-Labeling starts to be something that people can, can use in Voxel51.\nYeah, actually it, it recently went into alpha with some customers.\nSo it's already, it's already in alpha and we are improving it and it will be, uh, in every release over the, over the coming two months, probably, it will get more functionality and more users, um, to adopt it.\nYeah.\nFantastic.\nAnd it sounds like this is then solving what is the biggest bottleneck in computer vision and you're doing that using intelligent techniques so that, uh, it makes it way more time-efficient and cost-effective orders of magnitude relative to having humans be annotating the data.\nAbsolutely.\nYeah.\nI mean, the, the, the, like the tagline that I like, not approved by marketing, but that I like these days is like, uh, curation is the new annotation, right?\nLike, I mean, annotation 1.0, know, if we want to use that analogy, was basically, I don't really know how to filter my data, so I'm just going to send it all to humans to label and I have to pay for all that and it's time consuming as well, and then I'm going to get it back and give it to my machine learning engineers and maybe one, 1%, maybe 10% of that's useful, you know, it's hard to say, you don't really know, it's kind of like walking in a dark hallway without any light switch on, right?\nWhich door are you going to try?\nI think nowadays we're probably in like the one, you know, annotation 1.5 era, where it's, it's obvious to apply a foundation model even for something like prefiltering, just so you can rank your data so you're going to send it to humans to label.\nAnd I think the like Verified Auto-Labeling is farther along the line in saying, wait a second, sure, pre-filter your data, only apply certain things, but we're also saying, wait, you also, you still don't have to have humans annotate everything, right?\nYou, you can like, you can rank them, filter them and so on, so you can just accept the automatic labels out of the box.\nAnd where do I think we're actually going?\nLike, what is actually annotation 2.0, and that this is not what we're releasing this summer, but it's likely coming in the future, right?\nIf I have my way, um, you know, is this notion that instead of the humans asking the foundation models what they should label or what the labels are or or what have you, there's, it's more agentic, where like there's a problem statement given, you know, behemoth amount of unlabeled data, and then the models are able to actually ask the humans questions just when, when it's necessary, um, and, uh, it's more, more driven by the, the AI agent, if you will, so even fewer, less human involvements that's needed.\nThat is awesome, Jason.\nSo, it sounds like Voxel51 has figured out how to leverage the latest technology in terms of what we can do with automation to allow people to get the highest quality data for building high performance computer vision models at a fraction of the effort and the cost.\nThat's cool.\nAbsolutely.\nPut a nail on the head right there.\nYep.\nNice.\nUm, so yeah, fantastic.\nI mean, that's, that's a, this is a Friday episode, so it's, uh, it's, it's, it's not amongst our longer episodes, and so, you know, we, that was, uh, a short but very rich episode with you, Professor Corso, Jason, uh, we could certainly, I mean, we could easily have had an episode that was like, you know, Joe Rogan style, three or four hours with you, I'm sure, uh, on computer vision if, if we had to, because, uh, you have such rich, such a rich understanding of the space.\nUm, before I let my guests go, I always ask them for a book recommendation.\nWhat do you have for us?\nUh, cool.\nSo, I am an avid reader and I was just, just saying, well, if you want to do a saying in my head, if you want to do a three or four hour hour episode one time, maybe when we're both stuck in the Buffalo airport in a snowstorm, we, we can record then.\nUm, avid reader here.\nUm, I guess one of the best books I've read in the last few months is a book called Quit by Annie Duke.\nAnd it really puts the, you know, like I'm, I'm a, I'm a hard worker.\nI'm a grinder, right?\nSo like, I'm always one to like, really just want to see a project through.\nAnd it really puts that type of grit, which every founder needs in some sense and every professor really needs these days as well, up against this notion that like, make sure you're being smart about how you spend your time and how you're planning, pre-planning when you might want to deep switch or quit, quit, quit an angle and go in a different angle.\nI think for, for really any adult, I think it, like the lessons learned that, you know, that she writes in this book were fantastic, are fantastic.\nI like that a lot.\nYeah, it's, uh, it's tricky for those of us, probably a lot of our listeners, you know, if they, if the way that you choose to spend your free time is listening to a technical podcast about data science and AI, uh, you're probably somebody who has a lot of grit and is really pushing their career, and yeah, but this kind of thing, it becomes important, especially, you know, as opportunities accumulate, as you, as you focus and have more grit, more and more opportunities come up and you can't keep doing everything.\nYou know, it's a, it's a tricky thing.\nYou know, even just things like I used to be pre-pandemic, I used to be able to be inbox zero and respond to anything that should be responded to.\nAnd you know, there's things that's a simple, silly example.\nI mean, it sounds like this quick thing is kind of more about big strategic decisions, but just figuring out what you have to let go so that you can make space for even bigger things.\nAbsolutely.\nI mean, there's no, in terms of like the strategy and the tactics of decision-m, there's nothing too small to think about, frankly.\nSo like the notion of email inbox, like or inbox zero or whatever is highly relevant.\nI think the way I would put it is one of, one of our investors uses, has used the term, um, indigestion, right?\nLike if, if you're so successful, you're going to get indigestion over just trying to do too much, and, uh, it's, it's definitely something to be to watch out for, I think, and, and the author Annie Duke really does a good job of explaining that.\nNice.\nSounds like a great book.\nAnd then so for people who want more literary recommendations from, uh, your avid reading brain or, uh, you know, more insights on what you're up to with Voxel51, computer vision research, where should they be following your work?\nAbsolutely.\nYeah.\nSo, uh, I guess number one would be to follow me on LinkedIn.\nUm, I, I do try to post two, three, two to three times per week, uh, various opinions and so on.\nAlso, you can find the Voxel51 open source repository at github.com/voxel51.\nThe word 51.\nUh, and you can also find me, find me on, on Blue Sky at Jason Corso as well.\nI knew you'd be on Blue Sky.\nI called that before we even hit the record button when I said that this question would come off at the end.\nI was like, you have the right profile, uh, to also have a, a Blue Sky account.\nUh, I'm gonna have to get in there at some point.\nI'm not academic enough anymore that I have to have one, but, uh, yeah, I'd like to, I'd like to still pretend that I'm academic enough.\nUm, nice.\nThank you so much, Jason.\nThis has been an awesome episode.\nThanks for joining us, and I look forward to that, uh, three to four hour episode that we record in the snowstorm.\nRight on.\nIt was great to chat, Jon.\nThanks for having me.\nThanks to Jason Corso for coming on the show and providing such an informative and entertaining episode.\nIn it, Professor Corso covered how he discovered that model performance depends more on the quality of training data than on the choice of algorithm architecture, leading to Voxel51's founding principle: Better data, better models.\nUh, he also talked about how Voxel51's Verified Auto-Labeling uses foundation models to automatically label data, then ranks output so teams can accept about 70% automatically and focus human reviewers only on challenging edge cases, overall saving massive time and cost.\nHe also talked about how we've moved from annotation 1.0, sending everything to humans, through annotation 1.5, where we prefilter with AI and are now approaching, uh, annotation 2.0, where AI agents actively ask humans questions only when necessary.\nAll right, I hope you enjoyed today's episode.\nBe sure not to miss any of our exciting upcoming episodes.\nSubscribe to this podcast if you haven't already, but most importantly, I just hope you'll keep on listening.\nUntil next time, keep on rocking it out there and I'm looking forward to enjoying another round of the SuperDataScience Podcast with you very soon.\n[Music]\n",
  "metadata": {
    "summary": "Jason Corso joins the podcast to discuss Voxel51's work in computer vision, focusing on their new tool, Verified Auto-Labeling. This tool leverages foundation models to automatically label data, significantly speeding up the process and reducing costs. Corso highlights the critical role of high-quality data in training effective AI models, especially for applications like autonomous vehicles, where the ability to handle real-world accident scenarios is crucial. He emphasizes the shift from traditional annotation methods to a more curated approach, where AI pre-filters data, allowing human labelers to focus on challenging cases. The episode targets data scientists and ML engineers working on computer vision problems.",
    "topClaims": [
      {
        "text": "Voxel51 is solving the biggest bottleneck in computer vision, the surprising way autonomous vehicles learn to handle accidents.",
        "rating": 8.5,
        "chunkId": "ck-E4C1JxxoK90-0"
      },
      {
        "text": "I created a product to solve a pain point, and it has already had a huge amount of success with three million downloads.",
        "rating": 9,
        "chunkId": "ck-E4C1JxxoK90-10"
      },
      {
        "text": "Data and model structure are wed together in a way that is critical to understand all facets.",
        "rating": 7.5,
        "chunkId": "ck-E4C1JxxoK90-14"
      },
      {
        "text": "Verified Auto-Labeling can automatically generate labels on raw media via foundation models.",
        "rating": 8,
        "chunkId": "ck-E4C1JxxoK90-19"
      },
      {
        "text": "Curation is the new annotation, because annotation 1.0 was just sending everything to humans to label.",
        "rating": 8.5,
        "chunkId": "ck-E4C1JxxoK90-21"
      }
    ],
    "topQuotes": [
      {
        "text": "I lived through the was it four or five years that the Bills made the Super Bowl in the 90s and never won.",
        "chunkId": "ck-E4C1JxxoK90-4",
        "chunkNum": 4,
        "relevance": 9.5,
        "interesting": 9
      },
      {
        "text": "We basically began to build this conviction around data is at least as important, if not more important than the model architecture.",
        "chunkId": "ck-E4C1JxxoK90-7",
        "chunkNum": 7,
        "relevance": 9,
        "interesting": 8
      },
      {
        "text": "I can automatically accept something like 70% of them, and already that's a huge amount of money that I'm saving.",
        "chunkId": "ck-E4C1JxxoK90-20",
        "chunkNum": 20,
        "relevance": 9,
        "interesting": 9.5
      },
      {
        "text": "Curation is the new annotation, right? Like, I mean, annotation 1.0 was basically, I don't really know how to filter my data.",
        "chunkId": "ck-E4C1JxxoK90-21",
        "chunkNum": 21,
        "relevance": 9,
        "interesting": 8.5
      },
      {
        "text": "I discovered that model performance depends more on the quality of training data than on the choice of algorithm architecture.",
        "chunkId": "ck-E4C1JxxoK90-23",
        "chunkNum": 23,
        "relevance": 8,
        "interesting": 7.5
      }
    ],
    "topTopics": [
      {
        "name": "voxel51",
        "count": 10,
        "description": "A company focused on computer vision tools."
      },
      {
        "name": "auto labeling",
        "count": 8,
        "description": "A new product for automated data labeling."
      },
      {
        "name": "training data",
        "count": 7,
        "description": "The importance of data in machine learning."
      },
      {
        "name": "computer vision",
        "count": 5,
        "description": "The biggest academic conference on computer vision."
      },
      {
        "name": "autonomous vehicles",
        "count": 4,
        "description": "The application of AI in autonomous vehicles."
      }
    ],
    "videoInfo": {
      "id": "E4C1JxxoK90",
      "etag": "2_OOF1L708lhrad6R04qX1c0QIs",
      "kind": "youtube#video",
      "snippet": {
        "tags": [
          "How Prof. Jason Corso Solved Computer Visionâ€™s Data Problem",
          "Computer Vision",
          "Machine Learning",
          "Data Centric AI",
          "Auto Labeling",
          "Voxel51",
          "AI tools",
          "Robotics",
          "Artificial Intelligence",
          "ML workflow",
          "Data Science",
          "Super Data Science Podcast",
          "SuperDataScience",
          "data science",
          "Jon Krohn",
          "Google",
          "AI model",
          "LLMs",
          "AI",
          "Five Minute Friday",
          "artificial intelligence",
          "Jason Corso",
          "Computer Vision Data",
          "Auto-Labelling",
          "data-centric machine learning",
          "DCML",
          "Verified Auto-Labelling"
        ],
        "title": "906: How Prof. Jason Corso Solved Computer Visionâ€™s Data Problem",
        "channelId": "UCMbtqTGdSsxYYhhTpV4lSTQ",
        "localized": {
          "title": "906: How Prof. Jason Corso Solved Computer Visionâ€™s Data Problem",
          "description": "#Voxel51 #VisualAI #AI\n\nJason Corso speaks to @JonKrohnLearns in this Five-Minute Friday all about Voxel51â€™s latest tool, Verified Auto-Labelling, and the companyâ€™s incredible success in developing popular tools for computer vision.\n\nAdditional materials: https://www.superdatascience.com/906\n\nInterested in sponsoring a SuperDataScience Podcast episode? Email natalie@superdatascience.com for sponsorship information."
        },
        "categoryId": "28",
        "thumbnails": {
          "high": {
            "url": "https://i.ytimg.com/vi/E4C1JxxoK90/hqdefault.jpg",
            "width": 480,
            "height": 360
          },
          "maxres": {
            "url": "https://i.ytimg.com/vi/E4C1JxxoK90/maxresdefault.jpg",
            "width": 1280,
            "height": 720
          },
          "medium": {
            "url": "https://i.ytimg.com/vi/E4C1JxxoK90/mqdefault.jpg",
            "width": 320,
            "height": 180
          },
          "default": {
            "url": "https://i.ytimg.com/vi/E4C1JxxoK90/default.jpg",
            "width": 120,
            "height": 90
          },
          "standard": {
            "url": "https://i.ytimg.com/vi/E4C1JxxoK90/sddefault.jpg",
            "width": 640,
            "height": 480
          }
        },
        "description": "#Voxel51 #VisualAI #AI\n\nJason Corso speaks to @JonKrohnLearns in this Five-Minute Friday all about Voxel51â€™s latest tool, Verified Auto-Labelling, and the companyâ€™s incredible success in developing popular tools for computer vision.\n\nAdditional materials: https://www.superdatascience.com/906\n\nInterested in sponsoring a SuperDataScience Podcast episode? Email natalie@superdatascience.com for sponsorship information.",
        "publishedAt": "2025-07-18T11:00:34Z",
        "channelTitle": "Super Data Science: ML & AI Podcast with Jon Krohn",
        "defaultLanguage": "en",
        "defaultAudioLanguage": "en",
        "liveBroadcastContent": "none"
      },
      "statistics": {
        "likeCount": "2",
        "viewCount": "21",
        "commentCount": "1",
        "favoriteCount": "0"
      },
      "contentDetails": {
        "caption": "false",
        "duration": "PT29M22S",
        "dimension": "2d",
        "definition": "hd",
        "projection": "rectangular",
        "contentRating": {},
        "licensedContent": false
      }
    },
    "checkCount": 1,
    "nodeCounts": [
      {
        "node": "voxel51",
        "count": 8
      },
      {
        "node": "jason-corso",
        "count": 3
      },
      {
        "node": "buffalo",
        "count": 3
      },
      {
        "node": "data-labeling",
        "count": 3
      },
      {
        "node": "foundation-models",
        "count": 3
      },
      {
        "node": "university-of-michigan",
        "count": 2
      },
      {
        "node": "autonomous-vehicles",
        "count": 2
      },
      {
        "node": "ai-models",
        "count": 2
      },
      {
        "node": "toronto",
        "count": 2
      },
      {
        "node": "cvpr",
        "count": 2
      },
      {
        "node": "datacentric-ml",
        "count": 2
      },
      {
        "node": "software-1-0",
        "count": 2
      },
      {
        "node": "ai-system",
        "count": 2
      },
      {
        "node": "verified-auto-labeling",
        "count": 2
      },
      {
        "node": "auto-labeling",
        "count": 2
      },
      {
        "node": "annotation-2-0",
        "count": 2
      },
      {
        "node": "superdatascience-podcast",
        "count": 1
      },
      {
        "node": "robotics",
        "count": 1
      },
      {
        "node": "bottleneck",
        "count": 1
      },
      {
        "node": "airport",
        "count": 1
      },
      {
        "node": "art-museum",
        "count": 1
      },
      {
        "node": "akg",
        "count": 1
      },
      {
        "node": "albbright-knox-gallery",
        "count": 1
      },
      {
        "node": "eie-green",
        "count": 1
      },
      {
        "node": "architecture",
        "count": 1
      },
      {
        "node": "renovation",
        "count": 1
      },
      {
        "node": "buffalo-bills",
        "count": 1
      },
      {
        "node": "american-broadcasts",
        "count": 1
      },
      {
        "node": "lake-ontario",
        "count": 1
      },
      {
        "node": "bills-super-bowl",
        "count": 1
      },
      {
        "node": "robotics-professor",
        "count": 1
      },
      {
        "node": "electrical-engineering",
        "count": 1
      },
      {
        "node": "professor-corso",
        "count": 1
      },
      {
        "node": "buffalo-region",
        "count": 1
      },
      {
        "node": "cognitive-systems",
        "count": 1
      },
      {
        "node": "human-computer-interaction",
        "count": 1
      },
      {
        "node": "4d-touchpad",
        "count": 1
      },
      {
        "node": "video-captioning",
        "count": 1
      },
      {
        "node": "ai-guidance",
        "count": 1
      },
      {
        "node": "rural-healthcare",
        "count": 1
      },
      {
        "node": "medical-upskilling",
        "count": 1
      },
      {
        "node": "ai-agentic-guidance",
        "count": 1
      },
      {
        "node": "deep-vein-thrombosis",
        "count": 1
      },
      {
        "node": "iccv",
        "count": 1
      },
      {
        "node": "eccv",
        "count": 1
      },
      {
        "node": "field-exploding",
        "count": 1
      },
      {
        "node": "conference-papers",
        "count": 1
      },
      {
        "node": "conference-attendees",
        "count": 1
      },
      {
        "node": "model-architecture",
        "count": 1
      },
      {
        "node": "object-detection",
        "count": 1
      },
      {
        "node": "pedestrian-avoidance",
        "count": 1
      },
      {
        "node": "better-data-better-models",
        "count": 1
      },
      {
        "node": "algorithms",
        "count": 1
      },
      {
        "node": "semantic-mapping",
        "count": 1
      },
      {
        "node": "algorithmic-modification",
        "count": 1
      },
      {
        "node": "image-datasets",
        "count": 1
      },
      {
        "node": "lion-5b",
        "count": 1
      },
      {
        "node": "box-51",
        "count": 1
      },
      {
        "node": "dev-tools",
        "count": 1
      },
      {
        "node": "work-speedup",
        "count": 1
      },
      {
        "node": "data-impact",
        "count": 1
      },
      {
        "node": "open-source-tool",
        "count": 1
      },
      {
        "node": "ideal-customer",
        "count": 1
      },
      {
        "node": "data-scientist",
        "count": 1
      },
      {
        "node": "vision-scientist",
        "count": 1
      },
      {
        "node": "plugins",
        "count": 1
      },
      {
        "node": "extensions",
        "count": 1
      },
      {
        "node": "painpoint-solution",
        "count": 1
      },
      {
        "node": "three-million-downloads",
        "count": 1
      },
      {
        "node": "github-repo",
        "count": 1
      },
      {
        "node": "expertise-product",
        "count": 1
      },
      {
        "node": "episode-901",
        "count": 1
      },
      {
        "node": "lilith-bat-leah",
        "count": 1
      },
      {
        "node": "icml",
        "count": 1
      },
      {
        "node": "workshops",
        "count": 1
      },
      {
        "node": "machine-learning-conferences",
        "count": 1
      },
      {
        "node": "datacentric-machine-learning",
        "count": 1
      },
      {
        "node": "dmlr",
        "count": 1
      },
      {
        "node": "voxel",
        "count": 1
      },
      {
        "node": "outbound-marketing",
        "count": 1
      },
      {
        "node": "data-weights",
        "count": 1
      },
      {
        "node": "coefficients",
        "count": 1
      },
      {
        "node": "ops",
        "count": 1
      },
      {
        "node": "data-analysis",
        "count": 1
      },
      {
        "node": "model-analysis",
        "count": 1
      },
      {
        "node": "ops-analysis",
        "count": 1
      },
      {
        "node": "ml-tooling",
        "count": 1
      },
      {
        "node": "new-releases",
        "count": 1
      },
      {
        "node": "data-coverage",
        "count": 1
      },
      {
        "node": "vehicle-sensors",
        "count": 1
      },
      {
        "node": "vehicle-situations",
        "count": 1
      },
      {
        "node": "car-accidents",
        "count": 1
      },
      {
        "node": "accurate-systems",
        "count": 1
      },
      {
        "node": "failure-modes",
        "count": 1
      },
      {
        "node": "nitsa",
        "count": 1
      },
      {
        "node": "accident-recording",
        "count": 1
      },
      {
        "node": "successful-systems",
        "count": 1
      },
      {
        "node": "annotation-companies",
        "count": 1
      },
      {
        "node": "machine-learning-algorithm",
        "count": 1
      },
      {
        "node": "software-tool",
        "count": 1
      },
      {
        "node": "one-button-mouse",
        "count": 1
      },
      {
        "node": "annotation-problem",
        "count": 1
      },
      {
        "node": "decades-of-progress",
        "count": 1
      },
      {
        "node": "raw-media",
        "count": 1
      },
      {
        "node": "automatically-generate-labels",
        "count": 1
      },
      {
        "node": "teddy-bears",
        "count": 1
      },
      {
        "node": "verification-part",
        "count": 1
      },
      {
        "node": "workflow",
        "count": 1
      },
      {
        "node": "custom-ml",
        "count": 1
      },
      {
        "node": "batch-acceptance",
        "count": 1
      },
      {
        "node": "human-labelers",
        "count": 1
      },
      {
        "node": "human-qa",
        "count": 1
      },
      {
        "node": "data-annotation",
        "count": 1
      },
      {
        "node": "curation",
        "count": 1
      },
      {
        "node": "pre-filtering",
        "count": 1
      },
      {
        "node": "annie-duke",
        "count": 1
      },
      {
        "node": "indigestion",
        "count": 1
      },
      {
        "node": "literary-recommendations",
        "count": 1
      },
      {
        "node": "linkedin",
        "count": 1
      },
      {
        "node": "academic",
        "count": 1
      },
      {
        "node": "episode",
        "count": 1
      },
      {
        "node": "ai-agents",
        "count": 1
      },
      {
        "node": "superdatascience",
        "count": 1
      }
    ],
    "topicGroups": {
      "groups": [
        {
          "topics": [
            "foundation-models",
            "ai-models",
            "ai-system",
            "ai-models",
            "datacentric-ml",
            "auto-labeling",
            "ai-guidance",
            "model-architecture",
            "algorithms",
            "machine-learning-algorithm",
            "data-weights",
            "coefficients",
            "datacentric-machine-learning",
            "voxel",
            "data-analysis",
            "model-analysis",
            "machine-learning-algorithm"
          ],
          "category": {
            "id": "machine-learning",
            "name": "Machine Learning",
            "description": "Machine learning models, algorithms, and related concepts."
          }
        },
        {
          "topics": [
            "data-labeling",
            "verified-auto-labeling",
            "annotation-2-0",
            "image-datasets",
            "data-impact",
            "data-coverage",
            "annotation-companies",
            "data-labeling",
            "auto-labeling",
            "better-data-better-models"
          ],
          "category": {
            "id": "data-and-annotation",
            "name": "Data and Annotation",
            "description": "Data, labeling, and related tools and techniques."
          }
        },
        {
          "topics": [
            "cvpr",
            "iccv",
            "eccv",
            "object-detection",
            "semantic-mapping",
            "video-captioning",
            "icml"
          ],
          "category": {
            "id": "computer-vision",
            "name": "Computer Vision",
            "description": "Computer vision and related conferences and research."
          }
        },
        {
          "topics": [
            "autonomous-vehicles",
            "pedestrian-avoidance",
            "vehicle-sensors",
            "vehicle-situations",
            "car-accidents",
            "accident-recording"
          ],
          "category": {
            "id": "autonomous-vehicles",
            "name": "Autonomous Vehicles",
            "description": "Autonomous vehicles and related technologies."
          }
        },
        {
          "topics": [
            "software-1-0",
            "dev-tools",
            "open-source-tool",
            "plugins",
            "extensions",
            "ml-tooling",
            "software-tool",
            "algorithmic-modification"
          ],
          "category": {
            "id": "software-and-tools",
            "name": "Software and Tools",
            "description": "Software, tools, and development practices."
          }
        },
        {
          "topics": [
            "superdatascience-podcast",
            "three-million-downloads",
            "github-repo",
            "outbound-marketing",
            "episode-901"
          ],
          "category": {
            "id": "podcast-and-marketing",
            "name": "Podcast and Marketing",
            "description": "Podcast episode details and marketing."
          }
        },
        {
          "topics": [
            "jason-corso",
            "professor-corso",
            "data-scientist",
            "vision-scientist",
            "ideal-customer",
            "expertise-product",
            "robotics-professor"
          ],
          "category": {
            "id": "people-and-expertise",
            "name": "People and Expertise",
            "description": "People, roles, and expertise."
          }
        },
        {
          "topics": [
            "buffalo",
            "university-of-michigan",
            "toronto",
            "buffalo-region",
            "lake-ontario"
          ],
          "category": {
            "id": "locations-and-institutions",
            "name": "Locations and Institutions",
            "description": "Locations and institutions."
          }
        },
        {
          "topics": [
            "cvpr",
            "iccv",
            "eccv",
            "icml",
            "workshops",
            "machine-learning-conferences"
          ],
          "category": {
            "id": "conferences-and-workshops",
            "name": "Conferences and Workshops",
            "description": "Conferences and workshops."
          }
        },
        {
          "topics": [
            "painpoint-solution",
            "expertise-product",
            "ideal-customer",
            "work-speedup"
          ],
          "category": {
            "id": "business-and-product",
            "name": "Business and Product",
            "description": "Business and product related topics."
          }
        },
        {
          "topics": [
            "voxel51",
            "lion-5b",
            "box-51",
            "akg",
            "eie-green",
            "4d-touchpad",
            "dmlr",
            "nitsa"
          ],
          "category": {
            "id": "specific-projects-and-tools",
            "name": "Specific Projects and Tools",
            "description": "Specific projects and tools."
          }
        },
        {
          "topics": [
            "robotics",
            "cognitive-systems",
            "human-computer-interaction",
            "electrical-engineering"
          ],
          "category": {
            "id": "robotics-and-related-fields",
            "name": "Robotics and Related Fields",
            "description": "Robotics and related fields."
          }
        },
        {
          "topics": [
            "rural-healthcare",
            "medical-upskilling",
            "deep-vein-thrombosis"
          ],
          "category": {
            "id": "healthcare-and-medical",
            "name": "Healthcare and Medical",
            "description": "Healthcare and medical applications."
          }
        },
        {
          "topics": [
            "airport",
            "architecture",
            "renovation"
          ],
          "category": {
            "id": "infrastructure",
            "name": "Infrastructure",
            "description": "Infrastructure and related topics."
          }
        },
        {
          "topics": [
            "buffalo-bills",
            "bills-super-bowl",
            "american-broadcasts",
            "albbright-knox-gallery",
            "art-museum"
          ],
          "category": {
            "id": "sports-and-entertainment",
            "name": "Sports and Entertainment",
            "description": "Sports and entertainment."
          }
        },
        {
          "topics": [
            "ops",
            "ops-analysis",
            "failure-modes",
            "accurate-systems",
            "successful-systems"
          ],
          "category": {
            "id": "system-operations-and-analysis",
            "name": "System Operations and Analysis",
            "description": "System operations and analysis."
          }
        },
        {
          "topics": [
            "new-releases"
          ],
          "category": {
            "id": "new-releases",
            "name": "New Releases",
            "description": "New releases and related topics."
          }
        },
        {
          "topics": [
            "bottleneck",
            "field-exploding",
            "conference-papers",
            "conference-attendees",
            "lilith-bat-leah"
          ],
          "category": {
            "id": "miscellaneous",
            "name": "Miscellaneous",
            "description": "Miscellaneous topics."
          }
        }
      ]
    },
    "shortSummary": "In this episode, Jason Corso discusses Voxel51's Verified Auto-Labeling tool and how it addresses the data bottleneck in computer vision, particularly for autonomous vehicles.",
    "lastStoryCheck": "2025-07-18T13:45:10.485Z",
    "storyCheckResults": {
      "missingChunks": [],
      "missingStories": [],
      "totalCategories": 11,
      "totalChunksChecked": 24
    }
  }
}