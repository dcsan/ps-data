{
  "episodeId": "fRiqVdqeYNA",
  "channelSlug": "@boundaryml",
  "title": "OpenAI Agent SDK vs BAML",
  "publishedAt": "2025-06-20T22:29:01.000Z",
  "rawLines": [
    {
      "lang": "en",
      "text": "Hello. Okay, so",
      "offset": 1.439,
      "duration": 6.561
    },
    {
      "lang": "en",
      "text": "uh we're going to talk about the OpenAI",
      "offset": 4.72,
      "duration": 6.959
    },
    {
      "lang": "en",
      "text": "agent SDK today. Um so I was recently",
      "offset": 8,
      "duration": 6.96
    },
    {
      "lang": "en",
      "text": "actually just trying this out and um at",
      "offset": 11.679,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "first blush it was like wow, this is all",
      "offset": 14.96,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "you got to do. You create a new um uh",
      "offset": 17.199,
      "duration": 5.92
    },
    {
      "lang": "en",
      "text": "agent. Uh you import this. This is the",
      "offset": 20.72,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "TypeScript version, by the way. Um, you",
      "offset": 23.119,
      "duration": 6.08
    },
    {
      "lang": "en",
      "text": "give it an instruction uh and you just",
      "offset": 25.84,
      "duration": 6.239
    },
    {
      "lang": "en",
      "text": "run it and it goes amazing. That seems",
      "offset": 29.199,
      "duration": 5.841
    },
    {
      "lang": "en",
      "text": "super simple. Um, right. Their their",
      "offset": 32.079,
      "duration": 5.921
    },
    {
      "lang": "en",
      "text": "docs are are great. Um, they have some",
      "offset": 35.04,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "good examples. Uh, their guides are",
      "offset": 38,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "really intuitive. Uh, I actually really",
      "offset": 41.04,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "love this being able to say um, you",
      "offset": 43.12,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "know, how do you do tool calling? Um,",
      "offset": 45.6,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "you know, they have built-in stuff. Web",
      "offset": 48.32,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "search. This is amazing. a oneliner for",
      "offset": 49.92,
      "duration": 4.959
    },
    {
      "lang": "en",
      "text": "being able to say like, &quot;Oh yeah, I want",
      "offset": 53.12,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "my agent to go search the web.&quot; Um, and",
      "offset": 54.879,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "then file search and computer use code",
      "offset": 58.16,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "interpreter, right? Like you can just",
      "offset": 60.559,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "like add oneliners here. Um, it's",
      "offset": 61.92,
      "duration": 5.519
    },
    {
      "lang": "en",
      "text": "incredible. So they also allow you to do",
      "offset": 64.559,
      "duration": 5.361
    },
    {
      "lang": "en",
      "text": "stuff like adding tools really easily,",
      "offset": 67.439,
      "duration": 5.281
    },
    {
      "lang": "en",
      "text": "uh, which have execute callbacks, so",
      "offset": 69.92,
      "duration": 4.879
    },
    {
      "lang": "en",
      "text": "you, you know, do whatever API calls you",
      "offset": 72.72,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "want after that. Um, very intuitive,",
      "offset": 74.799,
      "duration": 6.561
    },
    {
      "lang": "en",
      "text": "very nice. So um",
      "offset": 77.84,
      "duration": 5.599
    },
    {
      "lang": "en",
      "text": "uh they can have these these multi-",
      "offset": 81.36,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "aents these things called handoffs right",
      "offset": 83.439,
      "duration": 4.961
    },
    {
      "lang": "en",
      "text": "they talk about guard railing streaming",
      "offset": 85.759,
      "duration": 5.841
    },
    {
      "lang": "en",
      "text": "um pausing doing human loop interactions",
      "offset": 88.4,
      "duration": 6.16
    },
    {
      "lang": "en",
      "text": "um MCP right they have their own tracing",
      "offset": 91.6,
      "duration": 6.32
    },
    {
      "lang": "en",
      "text": "um this is all really good stuff um one",
      "offset": 94.56,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "of the cool things too is that they can",
      "offset": 97.92,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "integrate with thirdparty providers like",
      "offset": 100.24,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "different SDKs like the Burcell AI SDK",
      "offset": 102.64,
      "duration": 6.32
    },
    {
      "lang": "en",
      "text": "um this is really nice because they ISDK",
      "offset": 106.24,
      "duration": 6.4
    },
    {
      "lang": "en",
      "text": "has their own stuff going on. Um, so",
      "offset": 108.96,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "this was all really great and I and I",
      "offset": 112.64,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "did a little demo and I'll I'll show you",
      "offset": 114.24,
      "duration": 5.919
    },
    {
      "lang": "en",
      "text": "kind of um how how it all works. Um, but",
      "offset": 115.92,
      "duration": 7.6
    },
    {
      "lang": "en",
      "text": "caveat uh I I kind of ran into some",
      "offset": 120.159,
      "duration": 6.081
    },
    {
      "lang": "en",
      "text": "stuff um kind of like when you start",
      "offset": 123.52,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "iterating on a project and you were",
      "offset": 126.24,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "like, &quot;Hey, I'm ready to go to",
      "offset": 128.16,
      "duration": 2.719
    },
    {
      "lang": "en",
      "text": "production.&quot; Um, you know, what does",
      "offset": 129.28,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "that look like and and how does that",
      "offset": 130.879,
      "duration": 3.121
    },
    {
      "lang": "en",
      "text": "feel from a developer experience",
      "offset": 132.48,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "perspective? Um so I I uh yeah so let's",
      "offset": 134,
      "duration": 8
    },
    {
      "lang": "en",
      "text": "let's get started. Um so coming over",
      "offset": 138.16,
      "duration": 8.159
    },
    {
      "lang": "en",
      "text": "here to cursor um it's pretty easy as",
      "offset": 142,
      "duration": 8.08
    },
    {
      "lang": "en",
      "text": "you saw to uh define your your agent. Um",
      "offset": 146.319,
      "duration": 6.161
    },
    {
      "lang": "en",
      "text": "and the use case here that I am doing is",
      "offset": 150.08,
      "duration": 6.96
    },
    {
      "lang": "en",
      "text": "I want a a startup validator idea. Um, I",
      "offset": 152.48,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "want and and the way that I want to do",
      "offset": 157.04,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "that is to create synthetic profiles to",
      "offset": 158.48,
      "duration": 4.479
    },
    {
      "lang": "en",
      "text": "be able to go and ask product questions",
      "offset": 160.64,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "about it and have these uh synthetic",
      "offset": 162.959,
      "duration": 6.801
    },
    {
      "lang": "en",
      "text": "profiles uh created by an LLM agent um",
      "offset": 165.36,
      "duration": 6.159
    },
    {
      "lang": "en",
      "text": "that has different backgrounds, pain",
      "offset": 169.76,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "points, needs, that kind of thing. Um,",
      "offset": 171.519,
      "duration": 4.561
    },
    {
      "lang": "en",
      "text": "and so I want it to go out there and do",
      "offset": 174,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "it and and you know, search the",
      "offset": 176.08,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "internet, have these personas um out",
      "offset": 178.16,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "actually go out and use real data from",
      "offset": 180.08,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "the internet. Um and and I'm doing this",
      "offset": 181.84,
      "duration": 6.08
    },
    {
      "lang": "en",
      "text": "here. So um basically you can see how",
      "offset": 185.36,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "easy this is. Create new agent. Um",
      "offset": 187.92,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "create your prompt. Uh they have this",
      "offset": 190.48,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "really nice thing for their structured",
      "offset": 192.72,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "output JSON. Um caveat, you have to use",
      "offset": 194.4,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "the word JSON in here. They will throw",
      "offset": 197.84,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "an error if you do not. Um and then you",
      "offset": 199.44,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "can see what this person schema looks",
      "offset": 202.159,
      "duration": 3.521
    },
    {
      "lang": "en",
      "text": "like. Right? This is just a Zod schema.",
      "offset": 203.92,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "We've seen this. um we pass back a name,",
      "offset": 205.68,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "age, occupation, um you know, all these",
      "offset": 208.64,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "all these different things that um are",
      "offset": 211.04,
      "duration": 6.88
    },
    {
      "lang": "en",
      "text": "relevant. So, um so coming back here,",
      "offset": 213.44,
      "duration": 7.439
    },
    {
      "lang": "en",
      "text": "when we actually run it, um we want to",
      "offset": 217.92,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "say, you know, generate these these",
      "offset": 220.879,
      "duration": 4.801
    },
    {
      "lang": "en",
      "text": "personas. Um the really nice thing about",
      "offset": 223.04,
      "duration": 5.199
    },
    {
      "lang": "en",
      "text": "this is you can just literally say run.",
      "offset": 225.68,
      "duration": 5.119
    },
    {
      "lang": "en",
      "text": "Um this is getting imported from the",
      "offset": 228.239,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "aisk.",
      "offset": 230.799,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "Um and this width traces is also really",
      "offset": 232.959,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "nice. I'll show you this in a second. Um",
      "offset": 235.519,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "what this looks like on their dashboard",
      "offset": 237.12,
      "duration": 5.039
    },
    {
      "lang": "en",
      "text": "to be able to group um uh agents uh",
      "offset": 238.879,
      "duration": 6.401
    },
    {
      "lang": "en",
      "text": "running together uh in in one section.",
      "offset": 242.159,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "Um all right. So you get the final",
      "offset": 245.28,
      "duration": 5.039
    },
    {
      "lang": "en",
      "text": "output. This is typed um right? You get",
      "offset": 247.519,
      "duration": 5.841
    },
    {
      "lang": "en",
      "text": "personas and this is the odd schema. Um",
      "offset": 250.319,
      "duration": 5.521
    },
    {
      "lang": "en",
      "text": "and then you can just output this. So um",
      "offset": 253.36,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "I'm doing a little bit extra stuff in",
      "offset": 255.84,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "here yielding um intermediate uh areas",
      "offset": 257.199,
      "duration": 6.72
    },
    {
      "lang": "en",
      "text": "because we're doing streaming um and",
      "offset": 261.44,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "things like that. So let me show you um",
      "offset": 263.919,
      "duration": 5.361
    },
    {
      "lang": "en",
      "text": "let's go into kind of like a iteration",
      "offset": 266.4,
      "duration": 5.359
    },
    {
      "lang": "en",
      "text": "loop here of what it's actually like to",
      "offset": 269.28,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "do prompt engineering on here, right?",
      "offset": 271.759,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "Because you know as we all know maybe we",
      "offset": 274.32,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "want to add you know another thing that",
      "offset": 276.639,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "says and um make sure they're not too",
      "offset": 278.479,
      "duration": 4.961
    },
    {
      "lang": "en",
      "text": "similar to each other, right? This is",
      "offset": 281.919,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "the prompt prompt uh engineering",
      "offset": 283.44,
      "duration": 5.039
    },
    {
      "lang": "en",
      "text": "iteration type. So, so let's just run",
      "offset": 285.759,
      "duration": 9.361
    },
    {
      "lang": "en",
      "text": "this. Um, and let's say our idea is um,",
      "offset": 288.479,
      "duration": 8.961
    },
    {
      "lang": "en",
      "text": "uh, to have sustainable food delivery",
      "offset": 295.12,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "services and we want to create five, uh,",
      "offset": 297.44,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "different personas. So, okay, let's run",
      "offset": 300.16,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "this. Uh, it's doing a little bit of",
      "offset": 303.04,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "streaming. Uh, we can't get the exact",
      "offset": 305.28,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "output because it's trying to create an",
      "offset": 308.32,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "object. Um, so we actually have to wait.",
      "offset": 310.08,
      "duration": 3.679
    },
    {
      "lang": "en",
      "text": "We can't get that structured output",
      "offset": 312.32,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "until it's actually done. So streaming",
      "offset": 313.759,
      "duration": 4.561
    },
    {
      "lang": "en",
      "text": "in this case um only gets you a little",
      "offset": 316.08,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "bit of information. Um but here we go.",
      "offset": 318.32,
      "duration": 5.599
    },
    {
      "lang": "en",
      "text": "So first we get this invalid output",
      "offset": 321.36,
      "duration": 6.64
    },
    {
      "lang": "en",
      "text": "type. Um not super useful. Okay. So what",
      "offset": 323.919,
      "duration": 5.84
    },
    {
      "lang": "en",
      "text": "do I what does that mean? You know I",
      "offset": 328,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "would imagine okay maybe it couldn't",
      "offset": 329.759,
      "duration": 5.361
    },
    {
      "lang": "en",
      "text": "coers it into the output type. Um we",
      "offset": 332,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "don't get a lot of information. Uh so my",
      "offset": 335.12,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "next thing would be logically let's go",
      "offset": 337.28,
      "duration": 5.919
    },
    {
      "lang": "en",
      "text": "check out the logs. So uh we come over",
      "offset": 339.6,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "here. Um, now we're looking at the logs",
      "offset": 343.199,
      "duration": 6.161
    },
    {
      "lang": "en",
      "text": "for today and let's just see. Uh, you're",
      "offset": 345.6,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "an expert in this. Da da da. Generate",
      "offset": 349.36,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "five user user personas. Okay, great.",
      "offset": 351.28,
      "duration": 7.04
    },
    {
      "lang": "en",
      "text": "Okay, here's the JSON output.",
      "offset": 354.24,
      "duration": 7.12
    },
    {
      "lang": "en",
      "text": "Looks pretty good. Looks like some JSON.",
      "offset": 358.32,
      "duration": 5.599
    },
    {
      "lang": "en",
      "text": "Don't know why that's not working. Very",
      "offset": 361.36,
      "duration": 5.92
    },
    {
      "lang": "en",
      "text": "interesting. Okay. Um, doesn't give me",
      "offset": 363.919,
      "duration": 5.041
    },
    {
      "lang": "en",
      "text": "any data. How do how do I debug this?",
      "offset": 367.28,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "Right. Um the other thing here is this",
      "offset": 368.96,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "is where the traces come up that with",
      "offset": 372.16,
      "duration": 9.08
    },
    {
      "lang": "en",
      "text": "trace uh and we do grouping by uh okay",
      "offset": 373.84,
      "duration": 7.4
    },
    {
      "lang": "en",
      "text": "yeah okay so we get text output is this",
      "offset": 386.16,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "even the same one I don't know right",
      "offset": 389.36,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "this is like you can see how hard this",
      "offset": 391.28,
      "duration": 5.039
    },
    {
      "lang": "en",
      "text": "is to start debugging",
      "offset": 393.28,
      "duration": 6.16
    },
    {
      "lang": "en",
      "text": "um was this the one I actually I I don't",
      "offset": 396.319,
      "duration": 4.481
    },
    {
      "lang": "en",
      "text": "know. I've been like running these a",
      "offset": 399.44,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "whole bunch. I can't call it. This is a",
      "offset": 400.8,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "string output. Did it try to coersse",
      "offset": 403.6,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "this inside the agent SDK? Right.",
      "offset": 405.52,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "There's a lot of stuff in here that now",
      "offset": 407.84,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "you can see, okay, well, I'm going to",
      "offset": 410.16,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "try to prompt my engineer my way through",
      "offset": 411.6,
      "duration": 5.92
    },
    {
      "lang": "en",
      "text": "this. Um, and it's like, how do I what I",
      "offset": 414.24,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "don't even know what it's failing on,",
      "offset": 417.52,
      "duration": 3.119
    },
    {
      "lang": "en",
      "text": "right? It didn't give me a good error.",
      "offset": 418.96,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "Um, I have already kind of gone through",
      "offset": 420.639,
      "duration": 5.521
    },
    {
      "lang": "en",
      "text": "this and and uh fixed it. Um, so here I",
      "offset": 422.96,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "kind of gave it a, you know, few shot",
      "offset": 426.16,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "example, um, where it says, okay, this",
      "offset": 427.84,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "is what it should look like. Here's the",
      "offset": 430.479,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "example JSON format. Um, now let's do",
      "offset": 432.16,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "it. Even though I would assume I",
      "offset": 435.199,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "wouldn't actually have to do this",
      "offset": 437.84,
      "duration": 3.359
    },
    {
      "lang": "en",
      "text": "because I'm already passing in the JSON",
      "offset": 439.12,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "object type. Um, I think it should do it",
      "offset": 441.199,
      "duration": 5.361
    },
    {
      "lang": "en",
      "text": "for me in my opinion. Um, so let's run",
      "offset": 443.44,
      "duration": 7.039
    },
    {
      "lang": "en",
      "text": "this one. Um, same thing. Sustainable",
      "offset": 446.56,
      "duration": 7.12
    },
    {
      "lang": "en",
      "text": "food service processing. still have to",
      "offset": 450.479,
      "duration": 6.321
    },
    {
      "lang": "en",
      "text": "wait because it's a a generic it's a",
      "offset": 453.68,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "formatted output, JSON output. Um, so it",
      "offset": 456.8,
      "duration": 4.239
    },
    {
      "lang": "en",
      "text": "wouldn't really make sense to stream it.",
      "offset": 459.44,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "Okay, sweet. Um, this is just how I've",
      "offset": 461.039,
      "duration": 5.361
    },
    {
      "lang": "en",
      "text": "formatted it in the CLI. Great. We did",
      "offset": 463.68,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "Persona. Um, they're getting",
      "offset": 466.4,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "backgrounds. Perfect. We got five of",
      "offset": 468.56,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "them. Great. Love that. Okay, so now",
      "offset": 470.96,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "coming back over to logs. Okay, looks",
      "offset": 474.16,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "like we got a new one that came in.",
      "offset": 476.56,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "It has the updated prompt.",
      "offset": 479.84,
      "duration": 6.16
    },
    {
      "lang": "en",
      "text": "The output looks exactly the same. Okay.",
      "offset": 482.56,
      "duration": 5.84
    },
    {
      "lang": "en",
      "text": "Have no idea why the other one failed.",
      "offset": 486,
      "duration": 5.039
    },
    {
      "lang": "en",
      "text": "Come back in here.",
      "offset": 488.4,
      "duration": 5.199
    },
    {
      "lang": "en",
      "text": "Okay. Now we have a little bit more",
      "offset": 491.039,
      "duration": 6.321
    },
    {
      "lang": "en",
      "text": "information here. Um,",
      "offset": 493.599,
      "duration": 7.521
    },
    {
      "lang": "en",
      "text": "again, the output looks fine. So, so you",
      "offset": 497.36,
      "duration": 6.399
    },
    {
      "lang": "en",
      "text": "can see here like it's very hard to",
      "offset": 501.12,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "debug uh um which is which is very",
      "offset": 503.759,
      "duration": 6.16
    },
    {
      "lang": "en",
      "text": "frustrating. So, um I'm going to plug a",
      "offset": 506.56,
      "duration": 7.2
    },
    {
      "lang": "en",
      "text": "little bit here because uh I shall um my",
      "offset": 509.919,
      "duration": 6.961
    },
    {
      "lang": "en",
      "text": "own product uh which",
      "offset": 513.76,
      "duration": 5.519
    },
    {
      "lang": "en",
      "text": "simplifies a lot of this experience uh a",
      "offset": 516.88,
      "duration": 4.639
    },
    {
      "lang": "en",
      "text": "lot of like the developer loop um the",
      "offset": 519.279,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "developer experience through being able",
      "offset": 521.519,
      "duration": 4.241
    },
    {
      "lang": "en",
      "text": "to prompt engineer yourself um through",
      "offset": 523.2,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "this doing structured output streaming",
      "offset": 525.76,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "structured output all these things that",
      "offset": 527.68,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "are very much needed when you're",
      "offset": 530,
      "duration": 5.839
    },
    {
      "lang": "en",
      "text": "building any sort of um LM application.",
      "offset": 531.839,
      "duration": 7.361
    },
    {
      "lang": "en",
      "text": "So um what we're going to use here is",
      "offset": 535.839,
      "duration": 8.081
    },
    {
      "lang": "en",
      "text": "called BAML. Uh and so BAML is another",
      "offset": 539.2,
      "duration": 6.639
    },
    {
      "lang": "en",
      "text": "library uh but it's also a programming",
      "offset": 543.92,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "language that allows you to build your",
      "offset": 545.839,
      "duration": 6.801
    },
    {
      "lang": "en",
      "text": "agents and your LM apps um uh with this",
      "offset": 548.48,
      "duration": 6.08
    },
    {
      "lang": "en",
      "text": "new programming language which is which",
      "offset": 552.64,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "is amazing. I mean it just like works",
      "offset": 554.56,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "out of the box. Uh it gives you",
      "offset": 557.04,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "low-level primitives to be able to see",
      "offset": 559.04,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "and and debug and be able to actually do",
      "offset": 561.12,
      "duration": 5.839
    },
    {
      "lang": "en",
      "text": "your prompt iteration. um inside of VS",
      "offset": 564,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "Code right where you're living. You",
      "offset": 566.959,
      "duration": 3.041
    },
    {
      "lang": "en",
      "text": "don't have to jump out to a logs page.",
      "offset": 568.399,
      "duration": 2.88
    },
    {
      "lang": "en",
      "text": "You don't have to come back all these",
      "offset": 570,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "things. So I'll show you a little",
      "offset": 571.279,
      "duration": 5.041
    },
    {
      "lang": "en",
      "text": "example of what that looks like. So",
      "offset": 573.2,
      "duration": 6.319
    },
    {
      "lang": "en",
      "text": "so um the difference is uh you know",
      "offset": 576.32,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "defining your agent in your TypeScript",
      "offset": 579.519,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "code, your Python code, whatever it is.",
      "offset": 581.6,
      "duration": 4.239
    },
    {
      "lang": "en",
      "text": "Um you do that here uh with the agent",
      "offset": 583.519,
      "duration": 4.721
    },
    {
      "lang": "en",
      "text": "SDK. With BAML",
      "offset": 585.839,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "you actually have these new files uh",
      "offset": 588.24,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "BAML files. So here's the exact same",
      "offset": 590.399,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "prompt. Um, and so we have a generate",
      "offset": 592.72,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "persona prompt. It takes in a startup",
      "offset": 595.839,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "idea. It takes in the number of",
      "offset": 597.76,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "personas, right? And you can see now how",
      "offset": 598.959,
      "duration": 5.761
    },
    {
      "lang": "en",
      "text": "much easier this is to just like look at",
      "offset": 601.92,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "this is the whole prompt, right? Um, and",
      "offset": 604.72,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "it there's no mixing in extra stuff.",
      "offset": 607.6,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "Like I don't like the agent SDK",
      "offset": 609.76,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "sometimes injects extra information that",
      "offset": 612.08,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "I just, you know, don't know what",
      "offset": 614.64,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "actually was showing up until I go to",
      "offset": 616.64,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "their UI and look at the logs. And it's",
      "offset": 618.48,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "just again the iteration loop is is very",
      "offset": 620.16,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "difficult to see. So you can see here",
      "offset": 622.56,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "we're going to output a persona. It's",
      "offset": 625.04,
      "duration": 3.359
    },
    {
      "lang": "en",
      "text": "going to have these things. We don't",
      "offset": 626.72,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "need descriptions on them. You know,",
      "offset": 628.399,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "we're going to let the LM course it into",
      "offset": 629.92,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "that. Um and one of the really cool",
      "offset": 631.839,
      "duration": 4.881
    },
    {
      "lang": "en",
      "text": "things is for the other one, we had to",
      "offset": 634.48,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "create an entire CLI uh that tried to",
      "offset": 636.72,
      "duration": 4.799
    },
    {
      "lang": "en",
      "text": "stream this output and and do all this",
      "offset": 639.6,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "stuff, right? there's is like a, you",
      "offset": 641.519,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "know, if you're doing a web app, if",
      "offset": 643.6,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "you're doing anything else, you have to",
      "offset": 645.12,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "basically create your own tooling just",
      "offset": 647.36,
      "duration": 4.479
    },
    {
      "lang": "en",
      "text": "to be able to test these prompts and do",
      "offset": 649.36,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "iterations on them. Um, right? And it's",
      "offset": 651.839,
      "duration": 4.481
    },
    {
      "lang": "en",
      "text": "just like, you know, everybody's going",
      "offset": 654.56,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "to have their own version of tooling and",
      "offset": 656.32,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "and all these things. So, what BAML did",
      "offset": 657.68,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "is they said, we're going to provide the",
      "offset": 660.16,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "tooling for you. Uh, we're going to",
      "offset": 662.16,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "allow you to run your own tests based",
      "offset": 663.92,
      "duration": 4.479
    },
    {
      "lang": "en",
      "text": "off different things. Let's say this is",
      "offset": 666.56,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "um sustainable food service delivery.",
      "offset": 668.399,
      "duration": 5.761
    },
    {
      "lang": "en",
      "text": "and let's run this test. And so let's",
      "offset": 671.36,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "see what happens here. So immediately we",
      "offset": 674.16,
      "duration": 6.88
    },
    {
      "lang": "en",
      "text": "get inside cursor, VS code, whatever. Um",
      "offset": 677.36,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "you can see the exact prompt that we're",
      "offset": 681.04,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "about to send to the LLM. Um you can",
      "offset": 683.36,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "even see it in different ways. You can",
      "offset": 686.8,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "look at the actual tokens that it sent.",
      "offset": 688.64,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "So now you can see, hey, how much how",
      "offset": 690.56,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "much am I going to be um spending here?",
      "offset": 692.8,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "Um and then you can even see the raw",
      "offset": 694.959,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "curl. You can copy paste this to your uh",
      "offset": 696.959,
      "duration": 4.721
    },
    {
      "lang": "en",
      "text": "command line and you can just like",
      "offset": 700.079,
      "duration": 3.281
    },
    {
      "lang": "en",
      "text": "actually run this. So there's no",
      "offset": 701.68,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "obuscation of like we're adding more",
      "offset": 703.36,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "stuff in there. What you see is what you",
      "offset": 705.76,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "get and it's and it's very clear.",
      "offset": 707.92,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "There's no magic happening behind the",
      "offset": 709.92,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "scenes. So",
      "offset": 712.079,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "um so yeah, so let's test this. You can",
      "offset": 714.56,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "see we've injected these variables. Uh",
      "offset": 716.399,
      "duration": 5.201
    },
    {
      "lang": "en",
      "text": "we're going to do three profiles. Uh and",
      "offset": 718.64,
      "duration": 7.68
    },
    {
      "lang": "en",
      "text": "let's run it. So you see right away",
      "offset": 721.6,
      "duration": 8.88
    },
    {
      "lang": "en",
      "text": "we get this output right in VS Code and",
      "offset": 726.32,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "you can see this it's streaming the",
      "offset": 730.48,
      "duration": 3.359
    },
    {
      "lang": "en",
      "text": "actual output. We don't have to wait for",
      "offset": 732.32,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "the whole thing. It's already coercing",
      "offset": 733.839,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "it into the correct format. It's doing",
      "offset": 735.36,
      "duration": 5.599
    },
    {
      "lang": "en",
      "text": "partial JSON object types. Um which is",
      "offset": 737.92,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "incredible which is something that you",
      "offset": 740.959,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "can't get you can't get in these other",
      "offset": 742.88,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "libraries. Um, and the only reason you",
      "offset": 744.56,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "can get that is because this custom",
      "offset": 746.72,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "programming language we've defined, we",
      "offset": 749.12,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "know the type that you're trying to",
      "offset": 751.68,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "coersse it into. So, we know ahead of",
      "offset": 752.959,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "time before um the LM actually spits",
      "offset": 755.12,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "anything out that you're looking for",
      "offset": 758.399,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "background, you're looking for name,",
      "offset": 760.72,
      "duration": 2.559
    },
    {
      "lang": "en",
      "text": "you're looking for age, and that's how",
      "offset": 762,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "we can get these partial type streaming",
      "offset": 763.279,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "types. Um, which is incredible. It",
      "offset": 765.04,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "allows you to do all sorts of things.",
      "offset": 767.519,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "Um, especially when you're doing UIs,",
      "offset": 769.04,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "you can do these these streaming UI",
      "offset": 771.279,
      "duration": 4.481
    },
    {
      "lang": "en",
      "text": "types, which we can we can go in a",
      "offset": 773.92,
      "duration": 4.719
    },
    {
      "lang": "en",
      "text": "little bit later, but you can see how",
      "offset": 775.76,
      "duration": 5.519
    },
    {
      "lang": "en",
      "text": "easy it is. Let's say uh we wanted to",
      "offset": 778.639,
      "duration": 7.281
    },
    {
      "lang": "en",
      "text": "add uh let's say what do we want to add?",
      "offset": 781.279,
      "duration": 7.201
    },
    {
      "lang": "en",
      "text": "Cursor make something up the validation",
      "offset": 785.92,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "questions. Okay, maybe they have some",
      "offset": 788.48,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "stuff. Okay, so what did what did this",
      "offset": 790,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "do? Um that's the only place we updated",
      "offset": 792.24,
      "duration": 6.96
    },
    {
      "lang": "en",
      "text": "it. Uh but you can see here",
      "offset": 795.44,
      "duration": 6.399
    },
    {
      "lang": "en",
      "text": "all it is is because we have this",
      "offset": 799.2,
      "duration": 6.079
    },
    {
      "lang": "en",
      "text": "context output format it just says okay",
      "offset": 801.839,
      "duration": 5.041
    },
    {
      "lang": "en",
      "text": "great we just added this validation",
      "offset": 805.279,
      "duration": 3.761
    },
    {
      "lang": "en",
      "text": "questions we didn't update the prompt we",
      "offset": 806.88,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "didn't do anything let's just see what",
      "offset": 809.04,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "happens",
      "offset": 811.04,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "okay it's coming out it's creating",
      "offset": 812.88,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "background painoints",
      "offset": 815.12,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "boom validation questions incredible I",
      "offset": 817.76,
      "duration": 5.759
    },
    {
      "lang": "en",
      "text": "didn't have to do anything um I mean",
      "offset": 821.12,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "that's that's not just the power of BML",
      "offset": 823.519,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "you know it's that's also the power of",
      "offset": 825.68,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "of LMS and how it can infer that okay",
      "offset": 826.959,
      "duration": 5.201
    },
    {
      "lang": "en",
      "text": "based off of this prompt you're also",
      "offset": 830.079,
      "duration": 5.681
    },
    {
      "lang": "en",
      "text": "asking for this now um so super powerful",
      "offset": 832.16,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "you can see the iteration loop and how",
      "offset": 835.76,
      "duration": 4.879
    },
    {
      "lang": "en",
      "text": "much faster it is um and if there's if",
      "offset": 837.36,
      "duration": 6.88
    },
    {
      "lang": "en",
      "text": "there's an error um you you'll see it",
      "offset": 840.639,
      "duration": 6.32
    },
    {
      "lang": "en",
      "text": "right away there's no question of oh I",
      "offset": 844.24,
      "duration": 5.92
    },
    {
      "lang": "en",
      "text": "have to go over to this UI uh I have to",
      "offset": 846.959,
      "duration": 6.88
    },
    {
      "lang": "en",
      "text": "find the specific log output was it this",
      "offset": 850.16,
      "duration": 6.239
    },
    {
      "lang": "en",
      "text": "one was it this one and then you're",
      "offset": 853.839,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "like, whoa, what is this prompt? It's",
      "offset": 856.399,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "not formatted.",
      "offset": 858.959,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "What was my where's my input? I don't I",
      "offset": 860.8,
      "duration": 5.839
    },
    {
      "lang": "en",
      "text": "can't differentiate between that. Okay,",
      "offset": 863.519,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "great. You did JSON output, but there",
      "offset": 866.639,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "was an error here. So, like like where's",
      "offset": 868.399,
      "duration": 5.281
    },
    {
      "lang": "en",
      "text": "my where are you going to tell me that",
      "offset": 872.399,
      "duration": 2.961
    },
    {
      "lang": "en",
      "text": "there was an error? I have no idea.",
      "offset": 873.68,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "That's you know, and going into",
      "offset": 875.36,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "production, it's like, you know, you",
      "offset": 876.72,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "start seeing errors and they're not",
      "offset": 878.72,
      "duration": 3.359
    },
    {
      "lang": "en",
      "text": "showing up in any of these these",
      "offset": 880.48,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "observability platforms. It's like, you",
      "offset": 882.079,
      "duration": 4.721
    },
    {
      "lang": "en",
      "text": "know, you would think that your stuff's",
      "offset": 884.8,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "working perfectly fine and and yet the",
      "offset": 886.8,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "user is is uh you know, seeing these",
      "offset": 889.04,
      "duration": 7.52
    },
    {
      "lang": "en",
      "text": "errors. So, um so the power of BAML um",
      "offset": 891.76,
      "duration": 6.639
    },
    {
      "lang": "en",
      "text": "you can see it here. It's amazing. Your",
      "offset": 896.56,
      "duration": 6.32
    },
    {
      "lang": "en",
      "text": "iteration loop is is uh super quick. Um",
      "offset": 898.399,
      "duration": 7.201
    },
    {
      "lang": "en",
      "text": "and and so let's let's just actually I",
      "offset": 902.88,
      "duration": 5.199
    },
    {
      "lang": "en",
      "text": "also created a little CLI just to do a",
      "offset": 905.6,
      "duration": 6.96
    },
    {
      "lang": "en",
      "text": "direct onetoone comparison. So this um",
      "offset": 908.079,
      "duration": 7.361
    },
    {
      "lang": "en",
      "text": "streaming output uh you can see here we",
      "offset": 912.56,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "actually export these types for you. So",
      "offset": 915.44,
      "duration": 6.16
    },
    {
      "lang": "en",
      "text": "when you import um this the the uh the",
      "offset": 917.92,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "code actually gets generated for you and",
      "offset": 921.6,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "so you can see here we actually are",
      "offset": 923.92,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "exporting this type this is the same",
      "offset": 925.92,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "type that you defined in here this",
      "offset": 927.92,
      "duration": 7.76
    },
    {
      "lang": "en",
      "text": "persona. So you can see this persona has",
      "offset": 930.16,
      "duration": 7.44
    },
    {
      "lang": "en",
      "text": "um these same types. This is a",
      "offset": 935.68,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "TypeScript type uh which now allows you",
      "offset": 937.6,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "to work with um with all this stuff. So",
      "offset": 940.24,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "So here's how you call the the stream",
      "offset": 943.36,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "output. You say, &quot;Hey, this is my",
      "offset": 945.44,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "function. This is type safe generate",
      "offset": 947.44,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "personas.&quot; Um we're passing in the idea.",
      "offset": 949.759,
      "duration": 4.561
    },
    {
      "lang": "en",
      "text": "We're passing in the the number, right?",
      "offset": 952.48,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "Those are the two inputs uh into the the",
      "offset": 954.32,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "thing. And we're going to return this",
      "offset": 957.12,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "persona output. So,",
      "offset": 958.56,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "so right now you can see this returns a",
      "offset": 961.199,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "balance stream. Uh it's a partial",
      "offset": 963.04,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "stream, right? As we were talking about",
      "offset": 964.88,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "before, um you can get that like",
      "offset": 966.32,
      "duration": 5.199
    },
    {
      "lang": "en",
      "text": "intermediate state of the JSON object.",
      "offset": 969.36,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "You don't need to wait until the entire",
      "offset": 971.519,
      "duration": 6.081
    },
    {
      "lang": "en",
      "text": "um stream from the LLM is done um uh",
      "offset": 974,
      "duration": 6.32
    },
    {
      "lang": "en",
      "text": "trying to parse that JSON. Uh we do that",
      "offset": 977.6,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "behind the scenes on your behalf. So, so",
      "offset": 980.32,
      "duration": 5.199
    },
    {
      "lang": "en",
      "text": "again the normal for await loop on a",
      "offset": 983.36,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "stream. Um, but you can see here the",
      "offset": 985.519,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "stream is a partial of this persona. So",
      "offset": 987.92,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "now we can do things in the middle of",
      "offset": 990.959,
      "duration": 5.361
    },
    {
      "lang": "en",
      "text": "this and yield um things like we're",
      "offset": 993.6,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "processing this person. We can we can",
      "offset": 996.32,
      "duration": 5.759
    },
    {
      "lang": "en",
      "text": "output their name. Um, uh, processing",
      "offset": 998.56,
      "duration": 6.399
    },
    {
      "lang": "en",
      "text": "person. Yeah. Yeah. And so um, then we",
      "offset": 1002.079,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "can tell which persona it is, right? And",
      "offset": 1004.959,
      "duration": 5.041
    },
    {
      "lang": "en",
      "text": "then at the end of it, we say, okay,",
      "offset": 1007.279,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "great. Now we we know we're done with",
      "offset": 1010,
      "duration": 4.639
    },
    {
      "lang": "en",
      "text": "the stream. um let's get that actual",
      "offset": 1012.399,
      "duration": 4.641
    },
    {
      "lang": "en",
      "text": "full full object back and return that.",
      "offset": 1014.639,
      "duration": 7.801
    },
    {
      "lang": "en",
      "text": "So let's just look at that um CLI.",
      "offset": 1017.04,
      "duration": 5.4
    },
    {
      "lang": "en",
      "text": "Same thing. Here we are. We're going to",
      "offset": 1023.12,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "stream this. Okay, you can immediately",
      "offset": 1025.28,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "see the difference. We're processing the",
      "offset": 1027.28,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "first person. Now we're going to process",
      "offset": 1029.76,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "the second one. Okay, we're getting",
      "offset": 1031.76,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "intermediate data uh back in between.",
      "offset": 1033.36,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "So, um, this is because the LM is",
      "offset": 1036.24,
      "duration": 4.719
    },
    {
      "lang": "en",
      "text": "streaming things in different, um, and",
      "offset": 1038.64,
      "duration": 4.799
    },
    {
      "lang": "en",
      "text": "we're getting information back, um, in",
      "offset": 1040.959,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "different orders, uh, that we're being",
      "offset": 1043.439,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "able to parse it in that partial, uh,",
      "offset": 1045.12,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "format. But again, perfect. So, we got",
      "offset": 1047.12,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "the same exact, um, information out, uh,",
      "offset": 1049.2,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "as we did before, but you can see here",
      "offset": 1052.88,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "that it it did it in a in a real",
      "offset": 1054.96,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "streaming way, not just a, hey, we're",
      "offset": 1057.28,
      "duration": 3.519
    },
    {
      "lang": "en",
      "text": "looking for structured output and we",
      "offset": 1059.36,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "can't do it until the end of of the",
      "offset": 1060.799,
      "duration": 5.041
    },
    {
      "lang": "en",
      "text": "thing. So, um, yeah, I think that wraps",
      "offset": 1062.64,
      "duration": 7.2
    },
    {
      "lang": "en",
      "text": "it up. Um, the TLDDR, I think, you know,",
      "offset": 1065.84,
      "duration": 6.48
    },
    {
      "lang": "en",
      "text": "again, the they open AI has done a great",
      "offset": 1069.84,
      "duration": 6.079
    },
    {
      "lang": "en",
      "text": "job at simplifying how you build um,",
      "offset": 1072.32,
      "duration": 6.56
    },
    {
      "lang": "en",
      "text": "agents. Um, but they also offuscate a",
      "offset": 1075.919,
      "duration": 6.081
    },
    {
      "lang": "en",
      "text": "lot of stuff that once you start running",
      "offset": 1078.88,
      "duration": 5.039
    },
    {
      "lang": "en",
      "text": "into issues and errors and you want to",
      "offset": 1082,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "do prompt uh, iteration um, you know, it",
      "offset": 1083.919,
      "duration": 5.841
    },
    {
      "lang": "en",
      "text": "just becomes really difficult. You know,",
      "offset": 1087.36,
      "duration": 5.92
    },
    {
      "lang": "en",
      "text": "to me, this is like the the Vzero or um",
      "offset": 1089.76,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "or Bolt or any of those great",
      "offset": 1093.28,
      "duration": 6.32
    },
    {
      "lang": "en",
      "text": "prototyping tools. Um but as soon as you",
      "offset": 1095.2,
      "duration": 6.16
    },
    {
      "lang": "en",
      "text": "get past a prototype and you want to go",
      "offset": 1099.6,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "to production becomes very difficult. Um",
      "offset": 1101.36,
      "duration": 6.72
    },
    {
      "lang": "en",
      "text": "and and so you know coming back to to",
      "offset": 1105.12,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "BAML and some of the the pros there is",
      "offset": 1108.08,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "just like it gives you that",
      "offset": 1110.88,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "observability right next to where you're",
      "offset": 1112.32,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "actually coding the prompt, right? And",
      "offset": 1114.72,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "that's the the power um of giving you",
      "offset": 1116.72,
      "duration": 7.52
    },
    {
      "lang": "en",
      "text": "low-level uh um uh functions and and",
      "offset": 1119.52,
      "duration": 7.44
    },
    {
      "lang": "en",
      "text": "prototypes for for being able to to do",
      "offset": 1124.24,
      "duration": 6.559
    },
    {
      "lang": "en",
      "text": "that. So anyway, um I'm biased uh but I",
      "offset": 1126.96,
      "duration": 6.8
    },
    {
      "lang": "en",
      "text": "think um boundary is the the clear",
      "offset": 1130.799,
      "duration": 7.841
    },
    {
      "lang": "en",
      "text": "winner here. So all right, thanks again",
      "offset": 1133.76,
      "duration": 4.88
    }
  ],
  "cleanText": "Hello. Okay, so, uh, we're going to talk about the OpenAI Agent SDK today. Um, so I was recently actually just trying this out, and, um, at first blush, it was like, \"Wow, this is all you got to do.\" You create a new, um, uh, agent. Uh, you import this. This is the TypeScript version, by the way. Um, you give it an instruction, uh, and you just run it, and it goes amazing. That seems super simple. Um, right. Their docs are are great. Um, they have some good examples. Uh, their guides are really intuitive. Uh, I actually really love this, being able to say, um, you know, how do you do tool calling? Um, you know, they have built-in stuff: web search. This is amazing, a oneliner for being able to say like, \"Oh yeah, I want my agent to go search the web.\" Um, and then file search and computer use code interpreter, right? Like, you can just like add oneliners here. Um, it's incredible. So, they also allow you to do stuff like adding tools really easily, uh, which have execute callbacks, so you, you know, do whatever API calls you want after that. Um, very intuitive, very nice. So, um, uh, they can have these, these multi-agents, these things called handoffs, right? They talk about guard railing, streaming, um, pausing, doing human loop interactions, um, MCP, right? They have their own tracing. Um, this is all really good stuff. Um, one of the cool things, too, is that they can integrate with third-party providers like different SDKs, like the Burcell AI SDK. Um, this is really nice because the ISDK has their own stuff going on. Um, so this was all really great, and I, and I did a little demo, and I'll, I'll show you kind of, um, how, how it all works. Um, but caveat, uh, I, I kind of ran into some stuff, um, kind of like when you start iterating on a project, and you were like, \"Hey, I'm ready to go to production.\" Um, you know, what does that look like, and, and how does that feel from a developer experience perspective? Um, so I, I, uh, yeah, so let's, let's get started. Um, so coming over here to cursor, um, it's pretty easy, as you saw, to uh, define your, your agent. Um, and the use case here that I am doing is I want a startup validator idea. Um, I want, and, and the way that I want to do that is to create synthetic profiles to be able to go and ask product questions about it and have these uh, synthetic profiles uh, created by an LLM agent, um, that has different backgrounds, pain points, needs, that kind of thing. Um, and so I want it to go out there and do it, and, and you know, search the internet, have these personas, um, out, actually go out and use real data from the internet. Um, and, and I'm doing this here. So, um, basically, you can see how easy this is. Create new agent. Um, create your prompt. Uh, they have this really nice thing for their structured output JSON. Um, caveat, you have to use the word JSON in here. They will throw an error if you do not. Um, and then you can see what this person schema looks like, right? This is just a Zod schema. We've seen this. Um, we pass back a name, age, occupation, um, you know, all these, all these different things that, um, are relevant. So, um, so coming back here, when we actually run it, um, we want to say, you know, generate these, these personas. Um, the really nice thing about this is you can just literally say run. Um, this is getting imported from the aisk.\nUm, and this width traces is also really nice. I'll show you this in a second. Um, what this looks like on their dashboard to be able to group, um, uh, agents, uh, running together, uh, in, in one section. Um, all right. So you get the final output. This is typed, um, right? You get personas, and this is the odd schema. Um, and then you can just output this. So, um, I'm doing a little bit extra stuff in here, yielding, um, intermediate uh, areas because we're doing streaming, um, and things like that. So, let me show you, um, let's go into kind of like a iteration loop here of what it's actually like to do prompt engineering on here, right? Because, you know, as we all know, maybe we want to add, you know, another thing that says, \"And, um, make sure they're not too similar to each other,\" right? This is the prompt, prompt, uh, engineering iteration type. So, so let's just run this. Um, and let's say our idea is, um, uh, to have sustainable food delivery services, and we want to create five, uh, different personas. So, okay, let's run this. Uh, it's doing a little bit of streaming. Uh, we can't get the exact output because it's trying to create an object. Um, so we actually have to wait. We can't get that structured output until it's actually done. So, streaming in this case, um, only gets you a little bit of information. Um, but here we go. So, first, we get this invalid output type. Um, not super useful. Okay. So, what do I, what does that mean? You know, I would imagine, okay, maybe it couldn't coerce it into the output type. Um, we don't get a lot of information. Uh, so my next thing would be logically, let's go check out the logs. So, uh, we come over here. Um, now we're looking at the logs for today, and let's just see. Uh, you're an expert in this. Da da da. Generate five user user personas. Okay, great. Okay, here's the JSON output.\nLooks pretty good. Looks like some JSON. Don't know why that's not working. Very interesting. Okay. Um, doesn't give me any data. How do, how do I debug this? Right. Um, the other thing here is this is where the traces come up that with trace, uh, and we do grouping by, uh, okay, yeah, okay, so we get text output. Is this even the same one? I don't know, right? This is like, you can see how hard this is to start debugging.\nUm, was this the one I actually, I, I don't know. I've been like running these a whole bunch. I can't call it. This is a string output. Did it try to coerce this inside the agent SDK? Right. There's a lot of stuff in here that now you can see, okay, well, I'm going to try to prompt my engineer my way through this. Um, and it's like, how do I, what, I don't even know what it's failing on, right? It didn't give me a good error. Um, I have already kind of gone through this and, and, uh, fixed it. Um, so here I kind of gave it a, you know, few shot example, um, where it says, okay, this is what it should look like. Here's the example JSON format. Um, now let's do it. Even though I would assume I wouldn't actually have to do this because I'm already passing in the JSON object type. Um, I think it should do it for me, in my opinion. Um, so let's run this one. Um, same thing. Sustainable food service processing. Still have to wait because it's a, a generic, it's a formatted output, JSON output. Um, so it wouldn't really make sense to stream it. Okay, sweet. Um, this is just how I've formatted it in the CLI. Great. We did Persona. Um, they're getting backgrounds. Perfect. We got five of them. Great. Love that. Okay, so now coming back over to logs. Okay, looks like we got a new one that came in.\nIt has the updated prompt.\nThe output looks exactly the same. Okay. Have no idea why the other one failed. Come back in here.\nOkay. Now we have a little bit more information here. Um, again, the output looks fine. So, so you can see here, like, it's very hard to debug, uh, um, which is, which is very frustrating. So, um, I'm going to plug a little bit here because, uh, I shall, um, my own product, uh, which simplifies a lot of this experience, uh, a lot of like the developer loop, um, the developer experience through being able to prompt engineer yourself, um, through this, doing structured output, streaming structured output, all these things that are very much needed when you're building any sort of, um, LM application. So, um, what we're going to use here is called BAML. Uh, and so BAML is another library, uh, but it's also a programming language that allows you to build your agents and your LM apps, um, uh, with this new programming language, which is, which is amazing. I mean, it just like works out of the box. Uh, it gives you low-level primitives to be able to see and, and debug and be able to actually do your prompt iteration, um, inside of VS Code, right, where you're living. You don't have to jump out to a logs page. You don't have to come back, all these things. So, I'll show you a little example of what that looks like. So, so, um, the difference is, uh, you know, defining your agent in your TypeScript code, your Python code, whatever it is. Um, you do that here, uh, with the agent SDK. With BAML, you actually have these new files, uh, BAML files. So, here's the exact same prompt. Um, and so we have a generate persona prompt. It takes in a startup idea. It takes in the number of personas, right? And you can see now how much easier this is to just like look at, this is the whole prompt, right? Um, and it, there's no mixing in extra stuff. Like, I don't like the agent SDK sometimes injects extra information that I just, you know, don't know what actually was showing up until I go to their UI and look at the logs. And it's just again, the iteration loop is is very difficult to see. So, you can see here, we're going to output a persona. It's going to have these things. We don't need descriptions on them. You know, we're going to let the LM coerce it into that. Um, and one of the really cool things is, for the other one, we had to create an entire CLI, uh, that tried to stream this output and, and do all this stuff, right? There's is like a, you know, if you're doing a web app, if you're doing anything else, you have to basically create your own tooling just to be able to test these prompts and do iterations on them. Um, right? And it's just like, you know, everybody's going to have their own version of tooling and, and all these things. So, what BAML did is they said, \"We're going to provide the tooling for you. Uh, we're going to allow you to run your own tests based off different things.\" Let's say this is, um, sustainable food service delivery. And let's run this test. And so, let's see what happens here. So, immediately, we get inside cursor, VS code, whatever. Um, you can see the exact prompt that we're about to send to the LLM. Um, you can even see it in different ways. You can look at the actual tokens that it sent. So, now you can see, hey, how much, how much am I going to be, um, spending here? Um, and then you can even see the raw curl. You can copy paste this to your, uh, command line, and you can just like actually run this. So, there's no obfuscation of like, we're adding more stuff in there. What you see is what you get, and it's, and it's very clear. There's no magic happening behind the scenes. So, um, so yeah, so let's test this. You can see we've injected these variables. Uh, we're going to do three profiles. Uh, and let's run it. So, you see right away, we get this output right in VS Code, and you can see this, it's streaming the actual output. We don't have to wait for the whole thing. It's already coercing it into the correct format. It's doing partial JSON object types. Um, which is incredible, which is something that you can't get, you can't get in these other libraries. Um, and the only reason you can get that is because this custom programming language we've defined, we know the type that you're trying to coerce it into. So, we know ahead of time before, um, the LM actually spits anything out that you're looking for background, you're looking for name, you're looking for age, and that's how we can get these partial type streaming types. Um, which is incredible. It allows you to do all sorts of things. Um, especially when you're doing UIs, you can do these, these streaming UI types, which we can, we can go in a little bit later, but you can see how easy it is. Let's say, uh, we wanted to add, uh, let's say, what do we want to add? Cursor, make something up, the validation questions. Okay, maybe they have some stuff. Okay, so what did, what did this do? Um, that's the only place we updated it. Uh, but you can see here, all it is is because we have this context output format, it just says, okay, great, we just added this validation questions, we didn't update the prompt, we didn't do anything, let's just see what happens.\nOkay, it's coming out, it's creating background, painoints, boom, validation questions, incredible. I didn't have to do anything. Um, I mean, that's, that's not just the power of BAML, you know, it's that's also the power of of LMS and how it can infer that, okay, based off of this prompt, you're also asking for this now. Um, so super powerful, you can see the iteration loop and how much faster it is. Um, and if there's, if there's an error, um, you, you'll see it right away. There's no question of, \"Oh, I have to go over to this UI, uh, I have to find the specific log output, was it this one, was it this one?\" And then you're like, \"Whoa, what is this prompt? It's not formatted. What was my, where's my input? I don't, I can't differentiate between that.\" Okay, great. You did JSON output, but there was an error here. So, like, like, where's my, where are you going to tell me that there was an error? I have no idea. That's, you know, and going into production, it's like, you know, you start seeing errors, and they're not showing up in any of these, these observability platforms. It's like, you know, you would think that your stuff's working perfectly fine, and, and yet the user is, is, uh, you know, seeing these errors. So, um, so the power of BAML, um, you can see it here. It's amazing. Your iteration loop is, is, uh, super quick. Um, and, and so let's, let's just actually, I also created a little CLI just to do a direct one-to-one comparison. So, this, um, streaming output, uh, you can see here, we actually export these types for you. So, when you import, um, this, the, the, uh, the code actually gets generated for you, and so you can see here, we actually are exporting this type, this is the same type that you defined in here, this persona. So, you can see this persona has, um, these same types. This is a TypeScript type, uh, which now allows you to work with, um, with all this stuff.\n\n\nSo, here's how you call the stream output.\n\nYou say, \"Hey, this is my function. This is type safe generate personas.\"\n\nUm, we're passing in the idea. We're passing in the number, right? Those are the two inputs uh into the thing. And we're going to return this persona output.\n\nSo, right now you can see this returns a balance stream. Uh, it's a partial stream, right? As we were talking about before, um, you can get that like intermediate state of the JSON object. You don't need to wait until the entire um stream from the LLM is done um uh trying to parse that JSON. Uh, we do that behind the scenes on your behalf.\n\nSo, so again the normal for await loop on a stream. Um, but you can see here the stream is a partial of this persona. So now we can do things in the middle of this and yield um things like we're processing this person. We can output their name. Um, uh, processing person. Yeah. Yeah.\n\nAnd so um, then we can tell which persona it is, right? And then at the end of it, we say, okay, great. Now we we know we're done with the stream. um let's get that actual full full object back and return that.\n\nSo let's just look at that um CLI. Same thing. Here we are. We're going to stream this. Okay, you can immediately see the difference. We're processing the first person. Now we're going to process the second one. Okay, we're getting intermediate data uh back in between.\n\nSo, um, this is because the LM is streaming things in different, um, and we're getting information back, um, in different orders, uh, that we're being able to parse it in that partial, uh, format. But again, perfect. So, we got the same exact, um, information out, uh, as we did before, but you can see here that it it did it in a in a real streaming way, not just a, hey, we're looking for structured output and we can't do it until the end of of the thing.\n\nSo, um, yeah, I think that wraps it up. Um, the TLDDR, I think, you know, again, the OpenAI has done a great job at simplifying how you build um, agents. Um, but they also offuscate a lot of stuff that once you start running into issues and errors and you want to do prompt uh, iteration um, you know, it just becomes really difficult. You know, to me, this is like the the Vzero or um or Bolt or any of those great prototyping tools. Um but as soon as you get past a prototype and you want to go to production becomes very difficult. Um and and so you know coming back to to BAML and some of the the pros there is just like it gives you that observability right next to where you're actually coding the prompt, right? And that's the the power um of giving you low-level uh um uh functions and and prototypes for for being able to to do that.\n\nSo anyway, um I'm biased uh but I think um boundary is the the clear winner here.\n\nSo all right, thanks again.\n",
  "dumpedAt": "2025-07-21T18:43:25.878Z"
}