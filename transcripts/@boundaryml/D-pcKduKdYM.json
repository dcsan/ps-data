{
  "episodeId": "D-pcKduKdYM",
  "channelSlug": "@boundaryml",
  "title": "ðŸ¦„ reasoning models vs reasoning prompts: ep#2",
  "publishedAt": "2025-04-08T18:43:36.000Z",
  "rawLines": [
    {
      "lang": "en",
      "text": "All right. So, we're going to do another",
      "offset": 2.399,
      "duration": 4.721
    },
    {
      "lang": "en",
      "text": "episode today of AI that works with",
      "offset": 4.64,
      "duration": 3.959
    },
    {
      "lang": "en",
      "text": "myself and",
      "offset": 7.12,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "Dexter. And last week, we talked about",
      "offset": 8.599,
      "duration": 4.681
    },
    {
      "lang": "en",
      "text": "how to do classification with a thousand",
      "offset": 11.28,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "plus classes. And this week, we want to",
      "offset": 13.28,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "talk about something I thought was",
      "offset": 16.24,
      "duration": 2.799
    },
    {
      "lang": "en",
      "text": "really relevant, especially with all the",
      "offset": 17.44,
      "duration": 3.599
    },
    {
      "lang": "en",
      "text": "new models coming out recently. Uh,",
      "offset": 19.039,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "Llama 4 came out, a few other approaches",
      "offset": 21.039,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "came out. And the things that we want to",
      "offset": 23.439,
      "duration": 4.481
    },
    {
      "lang": "en",
      "text": "spend the most time on is how do these",
      "offset": 25.359,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "reasoning models actually help us? Do",
      "offset": 27.92,
      "duration": 3.439
    },
    {
      "lang": "en",
      "text": "they help us? Is there an advantage to",
      "offset": 29.599,
      "duration": 3.281
    },
    {
      "lang": "en",
      "text": "using them? Is there an advantage to not",
      "offset": 31.359,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "using them? Um, could we leverage some",
      "offset": 32.88,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "of the reasoning capabilities in",
      "offset": 35.04,
      "duration": 3.359
    },
    {
      "lang": "en",
      "text": "existing models without using a",
      "offset": 36.32,
      "duration": 5.759
    },
    {
      "lang": "en",
      "text": "reasoning model? Um, and with that,",
      "offset": 38.399,
      "duration": 5.84
    },
    {
      "lang": "en",
      "text": "let's go off and start talking about",
      "offset": 42.079,
      "duration": 5.441
    },
    {
      "lang": "en",
      "text": "some of the stuff. But as we always say,",
      "offset": 44.239,
      "duration": 4.961
    },
    {
      "lang": "en",
      "text": "it's really hard to go and have a",
      "offset": 47.52,
      "duration": 3.359
    },
    {
      "lang": "en",
      "text": "conversation about these techniques that",
      "offset": 49.2,
      "duration": 2.92
    },
    {
      "lang": "en",
      "text": "seem so",
      "offset": 50.879,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "abstract without actually a concrete",
      "offset": 52.12,
      "duration": 4.84
    },
    {
      "lang": "en",
      "text": "example. So, Dex here has put together a",
      "offset": 54.399,
      "duration": 5.041
    },
    {
      "lang": "en",
      "text": "really, really good example. uh that I",
      "offset": 56.96,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "think is going to be helpful and",
      "offset": 59.44,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "somewhat um good grounding for all of us",
      "offset": 61.039,
      "duration": 3.361
    },
    {
      "lang": "en",
      "text": "to talk about. So we're going to talk",
      "offset": 63.359,
      "duration": 3.041
    },
    {
      "lang": "en",
      "text": "about the example first and then dive",
      "offset": 64.4,
      "duration": 3.32
    },
    {
      "lang": "en",
      "text": "into the reasoning",
      "offset": 66.4,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "capabilities. You want to take it away",
      "offset": 67.72,
      "duration": 5.399
    },
    {
      "lang": "en",
      "text": "next? Yeah, let's do it. Um so we have",
      "offset": 69.52,
      "duration": 7.599
    },
    {
      "lang": "en",
      "text": "built um really quickly there is a",
      "offset": 73.119,
      "duration": 7.961
    },
    {
      "lang": "en",
      "text": "public neo forj database for movie",
      "offset": 77.119,
      "duration": 5.761
    },
    {
      "lang": "en",
      "text": "recommendations. So this is just a",
      "offset": 81.08,
      "duration": 3.399
    },
    {
      "lang": "en",
      "text": "public data set. Anyone can plug into",
      "offset": 82.88,
      "duration": 2.96
    },
    {
      "lang": "en",
      "text": "it. It's kind of got like public",
      "offset": 84.479,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "username and password. And we've just",
      "offset": 85.84,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "built a small little AI agent that can",
      "offset": 88.159,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "answer questions about movies. And it's",
      "offset": 90,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "using agentic tool calling to generate",
      "offset": 92.159,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "cipher queries to query against the",
      "offset": 94.079,
      "duration": 6.08
    },
    {
      "lang": "en",
      "text": "database for and cipher is the um name",
      "offset": 96.159,
      "duration": 6.241
    },
    {
      "lang": "en",
      "text": "of the SQLish dialect that they use. So",
      "offset": 100.159,
      "duration": 5.041
    },
    {
      "lang": "en",
      "text": "I can ask this thing something like hey",
      "offset": 102.4,
      "duration": 5.719
    },
    {
      "lang": "en",
      "text": "who's in point",
      "offset": 105.2,
      "duration": 6.48
    },
    {
      "lang": "en",
      "text": "break and we see it gets back and it",
      "offset": 108.119,
      "duration": 5.32
    },
    {
      "lang": "en",
      "text": "runs this query and then you can see",
      "offset": 111.68,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "kind of what came back from the database",
      "offset": 113.439,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "and it gives you the main actors and so",
      "offset": 115.52,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "you can ask it even more complex queries",
      "offset": 117.759,
      "duration": 6.761
    },
    {
      "lang": "en",
      "text": "like what else are they in",
      "offset": 119.52,
      "duration": 7.64
    },
    {
      "lang": "en",
      "text": "um and it gets this very",
      "offset": 124.52,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "long pile of JSON.",
      "offset": 127.16,
      "duration": 6.28
    },
    {
      "lang": "en",
      "text": "Um, one of the challenges with this is,",
      "offset": 130.52,
      "duration": 5.4
    },
    {
      "lang": "en",
      "text": "uh, you'll notice, uh, it's just not",
      "offset": 133.44,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "that smart in certain cases. Uh, so if I",
      "offset": 135.92,
      "duration": 6.24
    },
    {
      "lang": "en",
      "text": "say who's in the matrix,",
      "offset": 138.64,
      "duration": 4.959
    },
    {
      "lang": "en",
      "text": "um, it's going to run this query and",
      "offset": 142.16,
      "duration": 2.56
    },
    {
      "lang": "en",
      "text": "it's going to get it wrong and it's just",
      "offset": 143.599,
      "duration": 2.481
    },
    {
      "lang": "en",
      "text": "going to keep trying over and over again",
      "offset": 144.72,
      "duration": 4.879
    },
    {
      "lang": "en",
      "text": "until it breaks. Um, but I can come back",
      "offset": 146.08,
      "duration": 8.239
    },
    {
      "lang": "en",
      "text": "here and say like who's in matrix the",
      "offset": 149.599,
      "duration": 6.321
    },
    {
      "lang": "en",
      "text": "and then eventually it'll figure it out",
      "offset": 154.319,
      "duration": 4.241
    },
    {
      "lang": "en",
      "text": "and get the right title. Um, so there's",
      "offset": 155.92,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "some interesting things around like",
      "offset": 158.56,
      "duration": 3.679
    },
    {
      "lang": "en",
      "text": "giving it correct like directions and",
      "offset": 160.16,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "instructions to follow that I think",
      "offset": 162.239,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "we're I think we're using 40 mini right",
      "offset": 163.84,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "now. Um, but we'll get into kind of some",
      "offset": 165.519,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "of the interesting challenges uh with",
      "offset": 168,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "how to how to get this thing to do. So",
      "offset": 170.959,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "for like writing SQL, writing code, and",
      "offset": 173.12,
      "duration": 4.479
    },
    {
      "lang": "en",
      "text": "other types of tasks that like reasoning",
      "offset": 175.599,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "models tend to be much better at. Um,",
      "offset": 177.599,
      "duration": 4.241
    },
    {
      "lang": "en",
      "text": "we'll look at kind of hey, let's drop in",
      "offset": 180.239,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "a reasoning model and and see how how",
      "offset": 181.84,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "powerful this is. And then we'll uh dig",
      "offset": 183.599,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "into some techniques for hey, how can",
      "offset": 186.08,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "you use smaller models or non-reasoning",
      "offset": 188.159,
      "duration": 4.641
    },
    {
      "lang": "en",
      "text": "models and uh build your own reasoning",
      "offset": 190.239,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "pipeline um and kind of what's happening",
      "offset": 192.8,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "under the hood there. So the code for",
      "offset": 195.599,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "this is in the repo. Um we'll add some",
      "offset": 197.68,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "more outlines and stuff to this as we",
      "offset": 200.159,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "go. Um but like five, what do you want",
      "offset": 201.92,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "to do? You want to jump into like the",
      "offset": 204.879,
      "duration": 2.401
    },
    {
      "lang": "en",
      "text": "architecture of just what's going on in",
      "offset": 205.92,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "the inside? Yeah, I think let's just",
      "offset": 207.28,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "grab a whiteboard and just really",
      "offset": 209.84,
      "duration": 2.8
    },
    {
      "lang": "en",
      "text": "quickly outline the code that we have",
      "offset": 211.12,
      "duration": 3.679
    },
    {
      "lang": "en",
      "text": "today. Once we have the code that we",
      "offset": 212.64,
      "duration": 4.239
    },
    {
      "lang": "en",
      "text": "have today um and then we can go ahead",
      "offset": 214.799,
      "duration": 5.921
    },
    {
      "lang": "en",
      "text": "and kind of go from here and uh uh talk",
      "offset": 216.879,
      "duration": 6.08
    },
    {
      "lang": "en",
      "text": "about the reasoning structure. Yeah,",
      "offset": 220.72,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "cool. So, um I think the core of this is",
      "offset": 222.959,
      "duration": 5.771
    },
    {
      "lang": "en",
      "text": "just the chat loop.",
      "offset": 226.08,
      "duration": 4.28
    },
    {
      "lang": "en",
      "text": "[Music]",
      "offset": 228.73,
      "duration": 4.71
    },
    {
      "lang": "en",
      "text": "Um so, uh essentially what we've got",
      "offset": 230.36,
      "duration": 6.2
    },
    {
      "lang": "en",
      "text": "here is we've got this big for loop. Um",
      "offset": 233.44,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "I'm actually going to draw this out. So,",
      "offset": 236.56,
      "duration": 5.039
    },
    {
      "lang": "en",
      "text": "a message comes in from the front end,",
      "offset": 238.56,
      "duration": 4.2
    },
    {
      "lang": "en",
      "text": "from the",
      "offset": 241.599,
      "duration": 4.481
    },
    {
      "lang": "en",
      "text": "user. Um, and uh, Vibob, I also sent you",
      "offset": 242.76,
      "duration": 4.679
    },
    {
      "lang": "en",
      "text": "I I just shot you a link to this",
      "offset": 246.08,
      "duration": 3.239
    },
    {
      "lang": "en",
      "text": "whiteboard as well.",
      "offset": 247.439,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "Um, and we basically going to pass that",
      "offset": 249.319,
      "duration": 5.48
    },
    {
      "lang": "en",
      "text": "into our prompt um, that we called chat",
      "offset": 251.84,
      "duration": 4.2
    },
    {
      "lang": "en",
      "text": "with",
      "offset": 254.799,
      "duration": 5.72
    },
    {
      "lang": "en",
      "text": "graph. Um, so you can see that is",
      "offset": 256.04,
      "duration": 8.48
    },
    {
      "lang": "en",
      "text": "uh, as you may expect a BAML function.",
      "offset": 260.519,
      "duration": 6.441
    },
    {
      "lang": "en",
      "text": "Um, actually, let me just pull up the",
      "offset": 264.52,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "actual",
      "offset": 266.96,
      "duration": 5.16
    },
    {
      "lang": "en",
      "text": "code. Um,",
      "offset": 268.12,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "wonderful. Okay, cool. So, um, we're",
      "offset": 282.96,
      "duration": 3.679
    },
    {
      "lang": "en",
      "text": "basically asking it, hey, try to help",
      "offset": 285.28,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "the user out. We give it the schema of",
      "offset": 286.639,
      "duration": 5.801
    },
    {
      "lang": "en",
      "text": "the database which is",
      "offset": 288.8,
      "duration": 6.399
    },
    {
      "lang": "en",
      "text": "um a big file that looks like this that",
      "offset": 292.44,
      "duration": 4.52
    },
    {
      "lang": "en",
      "text": "just describes the different nodes in",
      "offset": 295.199,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "the graph. Um, and then for each",
      "offset": 296.96,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "message, we put that in. And then we put",
      "offset": 299.12,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "in a system message that basically asks",
      "offset": 301.84,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "it to output things in a specific",
      "offset": 303.6,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "format. And our response is either going",
      "offset": 305.759,
      "duration": 4.241
    },
    {
      "lang": "en",
      "text": "to be a, you know, string, hey, here's",
      "offset": 307.68,
      "duration": 7.28
    },
    {
      "lang": "en",
      "text": "your answer um, action reply, or",
      "offset": 310,
      "duration": 6.72
    },
    {
      "lang": "en",
      "text": "um, it's going to be a graph query where",
      "offset": 314.96,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "it's going to tell us what query it",
      "offset": 316.72,
      "duration": 2.64
    },
    {
      "lang": "en",
      "text": "wants to run. So, those are the two",
      "offset": 318,
      "duration": 2.479
    },
    {
      "lang": "en",
      "text": "options. And we're basically going to",
      "offset": 319.36,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "ask the model to output one of those two",
      "offset": 320.479,
      "duration": 6.801
    },
    {
      "lang": "en",
      "text": "things. If it outputs a graph query um",
      "offset": 322.96,
      "duration": 7.519
    },
    {
      "lang": "en",
      "text": "we will we will go run that tool. Um so",
      "offset": 327.28,
      "duration": 5.479
    },
    {
      "lang": "en",
      "text": "let's say it outputs you",
      "offset": 330.479,
      "duration": 4.28
    },
    {
      "lang": "en",
      "text": "know query",
      "offset": 332.759,
      "duration": 4.601
    },
    {
      "lang": "en",
      "text": "graph then we actually go connect to the",
      "offset": 334.759,
      "duration": 6.321
    },
    {
      "lang": "en",
      "text": "neo forj database",
      "offset": 337.36,
      "duration": 3.72
    },
    {
      "lang": "en",
      "text": "uh and then we add to what we call the",
      "offset": 342.759,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "working context here. Thank",
      "offset": 345.52,
      "duration": 8.2
    },
    {
      "lang": "en",
      "text": "you. Right. So it starts with the user",
      "offset": 348.039,
      "duration": 8.641
    },
    {
      "lang": "en",
      "text": "message and",
      "offset": 353.72,
      "duration": 5.88
    },
    {
      "lang": "en",
      "text": "then we will append to the working",
      "offset": 356.68,
      "duration": 6.44
    },
    {
      "lang": "en",
      "text": "context query graph with actually like",
      "offset": 359.6,
      "duration": 7.68
    },
    {
      "lang": "en",
      "text": "the the cipher that it uh",
      "offset": 363.12,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "selected and then we add the neo forj",
      "offset": 367.639,
      "duration": 6.441
    },
    {
      "lang": "en",
      "text": "result neo forj result",
      "offset": 370.96,
      "duration": 5.679
    },
    {
      "lang": "en",
      "text": "um including if there was an error there",
      "offset": 374.08,
      "duration": 4.6
    },
    {
      "lang": "en",
      "text": "or something like that.",
      "offset": 376.639,
      "duration": 5.041
    },
    {
      "lang": "en",
      "text": "Um, and then we basically pass that back",
      "offset": 378.68,
      "duration": 5.72
    },
    {
      "lang": "en",
      "text": "into the LLM and it may decide, oh, if",
      "offset": 381.68,
      "duration": 4.239
    },
    {
      "lang": "en",
      "text": "there's an error or it didn't get any",
      "offset": 384.4,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "results, um, we saw in the matrix",
      "offset": 385.919,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "example, it just kept trying the same",
      "offset": 387.68,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "thing again as 40in is want to do. So,",
      "offset": 389.039,
      "duration": 5.761
    },
    {
      "lang": "en",
      "text": "it may loop back through this way or it",
      "offset": 391.52,
      "duration": 5.119
    },
    {
      "lang": "en",
      "text": "may at some point realize, okay, cool.",
      "offset": 394.8,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "I'm done calling tools and I want to",
      "offset": 396.639,
      "duration": 3.801
    },
    {
      "lang": "en",
      "text": "just",
      "offset": 399.36,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "reply. And then at that point, we kind",
      "offset": 400.44,
      "duration": 6.12
    },
    {
      "lang": "en",
      "text": "of exit out and send that reply back to",
      "offset": 403.12,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "the user. And while these are happening,",
      "offset": 406.56,
      "duration": 6.32
    },
    {
      "lang": "en",
      "text": "we're also streaming those back into the",
      "offset": 408.24,
      "duration": 7.44
    },
    {
      "lang": "en",
      "text": "uh into the kind of context window. You",
      "offset": 412.88,
      "duration": 4.879
    },
    {
      "lang": "en",
      "text": "got it. I'm just trying to make a curved",
      "offset": 415.68,
      "duration": 4.919
    },
    {
      "lang": "en",
      "text": "arm line really fast here. I got",
      "offset": 417.759,
      "duration": 6.16
    },
    {
      "lang": "en",
      "text": "you like that. Yeah, exactly. Yeah.",
      "offset": 420.599,
      "duration": 4.641
    },
    {
      "lang": "en",
      "text": "Yeah.",
      "offset": 423.919,
      "duration": 3.761
    },
    {
      "lang": "en",
      "text": "Cool. Uh does that make sense?",
      "offset": 425.24,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "Questions?",
      "offset": 427.68,
      "duration": 3
    },
    {
      "lang": "en",
      "text": "Um I'll just recap really fast um on",
      "offset": 430.72,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "this really fast. Um, so the idea is",
      "offset": 433.599,
      "duration": 4.481
    },
    {
      "lang": "en",
      "text": "basically that if an LLM is going to go",
      "offset": 435.84,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "reply to something, we want to be able",
      "offset": 438.08,
      "duration": 5.519
    },
    {
      "lang": "en",
      "text": "to iterate on iterably over time in this",
      "offset": 439.44,
      "duration": 6.72
    },
    {
      "lang": "en",
      "text": "sort of approach as what Dex showed. And",
      "offset": 443.599,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "if we can't iterate on it, then the",
      "offset": 446.16,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "problem is we rely on the model to be",
      "offset": 447.759,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "perfectly correct. So the front end",
      "offset": 449.52,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "really doesn't care about any of these",
      "offset": 451.759,
      "duration": 2.88
    },
    {
      "lang": "en",
      "text": "things. And the reason that the code",
      "offset": 453.28,
      "duration": 3.08
    },
    {
      "lang": "en",
      "text": "that you see is a little bit more",
      "offset": 454.639,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "complicated is because what we're",
      "offset": 456.36,
      "duration": 3.64
    },
    {
      "lang": "en",
      "text": "actually doing under the hood is every",
      "offset": 458.479,
      "duration": 2.961
    },
    {
      "lang": "en",
      "text": "single time we add something to the",
      "offset": 460,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "working context, we're also streaming an",
      "offset": 461.44,
      "duration": 5.479
    },
    {
      "lang": "en",
      "text": "event out to the front",
      "offset": 464.08,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "end, letting it know what we're doing to",
      "offset": 466.919,
      "duration": 4.521
    },
    {
      "lang": "en",
      "text": "the working context. So the user doesn't",
      "offset": 469.12,
      "duration": 4.44
    },
    {
      "lang": "en",
      "text": "actually see an opaque block until we",
      "offset": 471.44,
      "duration": 6.24
    },
    {
      "lang": "en",
      "text": "reply. The user is actually seeing the",
      "offset": 473.56,
      "duration": 6.52
    },
    {
      "lang": "en",
      "text": "the working context as it's happening.",
      "offset": 477.68,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "And there's interesting things that we",
      "offset": 480.08,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "can do in the front end if we wanted to,",
      "offset": 481.84,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "which is once the front end is actually",
      "offset": 484.24,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "done, we could technically just delete",
      "offset": 485.919,
      "duration": 3
    },
    {
      "lang": "en",
      "text": "the working context and only show the",
      "offset": 487.28,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "reply. So, so the user doesn't have to",
      "offset": 488.919,
      "duration": 3.96
    },
    {
      "lang": "en",
      "text": "know that it can see like it's an in",
      "offset": 491.52,
      "duration": 2.48
    },
    {
      "lang": "en",
      "text": "progress training. That's a front end",
      "offset": 492.879,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "only query that we could like we could",
      "offset": 494,
      "duration": 6.96
    },
    {
      "lang": "en",
      "text": "hide. Go ahead. So, we did like who's in",
      "offset": 496.879,
      "duration": 7.44
    },
    {
      "lang": "en",
      "text": "uh who's got a good movie.",
      "offset": 500.96,
      "duration": 5.88
    },
    {
      "lang": "en",
      "text": "Um, finding Nemo. That's",
      "offset": 504.319,
      "duration": 5.841
    },
    {
      "lang": "en",
      "text": "great. I just thought about it.",
      "offset": 506.84,
      "duration": 6.119
    },
    {
      "lang": "en",
      "text": "Um um yeah so like our working context",
      "offset": 510.16,
      "duration": 5.119
    },
    {
      "lang": "en",
      "text": "is this query and the response and then",
      "offset": 512.959,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "here's our final answer and I think the",
      "offset": 515.279,
      "duration": 3.281
    },
    {
      "lang": "en",
      "text": "implementation right is that actually",
      "offset": 517.279,
      "duration": 3.361
    },
    {
      "lang": "en",
      "text": "even when I ask another question this",
      "offset": 518.56,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "gets cleared out of the context window",
      "offset": 520.64,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "right the steps and we only just see the",
      "offset": 522.56,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "messages that have happened right",
      "offset": 524.48,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "exactly",
      "offset": 526.48,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "so the idea is that over time the chat",
      "offset": 529.2,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "doesn't need to preserve all the cipher",
      "offset": 531.92,
      "duration": 2.479
    },
    {
      "lang": "en",
      "text": "queries that I have it just kind of",
      "offset": 533.279,
      "duration": 3.521
    },
    {
      "lang": "en",
      "text": "needs to preserve the answer",
      "offset": 534.399,
      "duration": 6.081
    },
    {
      "lang": "en",
      "text": "um so like on the X chat, we still send",
      "offset": 536.8,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "the whole contacts window, but we",
      "offset": 540.48,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "actually clear these things out. And so",
      "offset": 542.56,
      "duration": 3.279
    },
    {
      "lang": "en",
      "text": "you just have the reply and then the",
      "offset": 544.48,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "user message. And then as we're building",
      "offset": 545.839,
      "duration": 5.201
    },
    {
      "lang": "en",
      "text": "up the continued working context, it may",
      "offset": 547.76,
      "duration": 5.199
    },
    {
      "lang": "en",
      "text": "have a bunch of queries here until we",
      "offset": 551.04,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "get to the next reply and then these get",
      "offset": 552.959,
      "duration": 4.641
    },
    {
      "lang": "en",
      "text": "crossed out again. Exactly. You nailed",
      "offset": 555.04,
      "duration": 5.919
    },
    {
      "lang": "en",
      "text": "it, Dex. So can I ask a quick question",
      "offset": 557.6,
      "duration": 4.52
    },
    {
      "lang": "en",
      "text": "about that?",
      "offset": 560.959,
      "duration": 5.361
    },
    {
      "lang": "en",
      "text": "So I've been doing similar queries with",
      "offset": 562.12,
      "duration": 7.32
    },
    {
      "lang": "en",
      "text": "uh Neo4j and GraphQL as well. Is there",
      "offset": 566.32,
      "duration": 5.519
    },
    {
      "lang": "en",
      "text": "any advantage keeping the context around",
      "offset": 569.44,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "to help correct it? So I found like",
      "offset": 571.839,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "sometimes you can't get that first shot",
      "offset": 575.2,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "of a query. You prompt it and then it",
      "offset": 577.519,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "gets the right one. Have you have you",
      "offset": 579.44,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "noticed that pattern? So here's what we",
      "offset": 581.44,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "actually do under the hood. So whenever",
      "offset": 583.68,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "this Neo4j result comes, this Neo4j",
      "offset": 585.279,
      "duration": 4.961
    },
    {
      "lang": "en",
      "text": "result could be either green because it",
      "offset": 587.839,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "actually solved it or it could be red",
      "offset": 590.24,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "because it doesn't have the answer. If",
      "offset": 591.839,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "it's red, we literally what we really do",
      "offset": 594.399,
      "duration": 5.681
    },
    {
      "lang": "en",
      "text": "is like if this sorry I'll I'll write",
      "offset": 597.279,
      "duration": 4.721
    },
    {
      "lang": "en",
      "text": "this as an error. What we really inject",
      "offset": 600.08,
      "duration": 6.4
    },
    {
      "lang": "en",
      "text": "is something that looks like this.",
      "offset": 602,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "Oops. An error happened.",
      "offset": 607.16,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "You could imagine injecting something",
      "offset": 614,
      "duration": 3.279
    },
    {
      "lang": "en",
      "text": "like this where you just say oops an",
      "offset": 615.44,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "error happened add it to the context and",
      "offset": 617.279,
      "duration": 3.361
    },
    {
      "lang": "en",
      "text": "now send it back to the model and the",
      "offset": 619.279,
      "duration": 4.961
    },
    {
      "lang": "en",
      "text": "model now generates a new query which we",
      "offset": 620.64,
      "duration": 6.72
    },
    {
      "lang": "en",
      "text": "then get a new neoforj call oops which",
      "offset": 624.24,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "we get a new neoforj call and if it's",
      "offset": 627.36,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "another error then we keep on adding it",
      "offset": 629.12,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "um but if it's not an error it's",
      "offset": 631.519,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "actually a result then we add the result",
      "offset": 633.12,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "and then we ask the model to go again",
      "offset": 635.44,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "but anytime it's not an error what we do",
      "offset": 637.519,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "is we actually delete all the previous",
      "offset": 639.76,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "queries and all the previous context and",
      "offset": 642.399,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "just add it in like this.",
      "offset": 644.079,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "Gotcha. Okay, that makes sense. And that",
      "offset": 646.399,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "that error as you called it, there's",
      "offset": 648.24,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "obviously like a a UI a user could",
      "offset": 650.079,
      "duration": 4.721
    },
    {
      "lang": "en",
      "text": "interject and say, &quot;Hey, you got it",
      "offset": 653.2,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "wrong.&quot; And that gives us this",
      "offset": 654.8,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "opportunity to develop that again,",
      "offset": 656.72,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "right? Well, we actually just let the",
      "offset": 658.64,
      "duration": 3.759
    },
    {
      "lang": "en",
      "text": "model know that the errors happen like",
      "offset": 660.72,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "Neo4j is telling us the citra query is",
      "offset": 662.399,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "wrong. But I think this gets in Yeah,",
      "offset": 664.56,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "sorry. I think this gets into um kind of",
      "offset": 668.079,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "your point on the last episode as well,",
      "offset": 670.16,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "Vibb, which was basically like you can",
      "offset": 671.839,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "build whatever you want. And if you have",
      "offset": 674.24,
      "duration": 3.279
    },
    {
      "lang": "en",
      "text": "things structured like this and you have",
      "offset": 675.92,
      "duration": 3.359
    },
    {
      "lang": "en",
      "text": "each step and you have control over it,",
      "offset": 677.519,
      "duration": 3.361
    },
    {
      "lang": "en",
      "text": "then yes, you could build something of",
      "offset": 679.279,
      "duration": 3.521
    },
    {
      "lang": "en",
      "text": "like, oh, when we have two errors in a",
      "offset": 680.88,
      "duration": 3.519
    },
    {
      "lang": "en",
      "text": "row, don't send it back to the model.",
      "offset": 682.8,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "Actually send it to the user, but keep",
      "offset": 684.399,
      "duration": 3.201
    },
    {
      "lang": "en",
      "text": "those errors around and send a",
      "offset": 685.92,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "deterministic message to the user of",
      "offset": 687.6,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "like, hey, we've got two errors, like",
      "offset": 689.2,
      "duration": 2.639
    },
    {
      "lang": "en",
      "text": "what do you want to do about it? And",
      "offset": 690.72,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "then append that rather, you know what I",
      "offset": 691.839,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "mean?",
      "offset": 694.16,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "Yeah. just I mean I guess there's",
      "offset": 695.92,
      "duration": 3.599
    },
    {
      "lang": "en",
      "text": "there's two forms of error, right?",
      "offset": 697.92,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "There's the it created an invalid query.",
      "offset": 699.519,
      "duration": 5.041
    },
    {
      "lang": "en",
      "text": "The other form is it got the query",
      "offset": 702.56,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "wrong. Um quite complex queries like you",
      "offset": 704.56,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "know um give me all the people who did",
      "offset": 707.76,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "this who are also starring in that who",
      "offset": 710,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "are friends with this. Um I find those",
      "offset": 712,
      "duration": 5.279
    },
    {
      "lang": "en",
      "text": "queries can break down they break down",
      "offset": 714.48,
      "duration": 6.24
    },
    {
      "lang": "en",
      "text": "slower in cipher than GraphQL. Um, yeah.",
      "offset": 717.279,
      "duration": 5.281
    },
    {
      "lang": "en",
      "text": "But then a really easy thing you can do",
      "offset": 720.72,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "is like me and Dex talked about how you",
      "offset": 722.56,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "could delete the user messages and then",
      "offset": 724.56,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "add in a and we what we do is like we",
      "offset": 726.72,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "basically just delete the user message",
      "offset": 728.72,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "and we only add in the reply. You could",
      "offset": 729.92,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "say an if statement that says if the",
      "offset": 732.32,
      "duration": 5.199
    },
    {
      "lang": "en",
      "text": "query is more than 5,000 characters then",
      "offset": 734.56,
      "duration": 3.959
    },
    {
      "lang": "en",
      "text": "include",
      "offset": 737.519,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "it in the context window. It's a choice.",
      "offset": 738.519,
      "duration": 6.521
    },
    {
      "lang": "en",
      "text": "Yeah. like the way you build the context",
      "offset": 742.959,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "for the user is really a choice of what",
      "offset": 745.04,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "you do.",
      "offset": 747.04,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "And if you go back to the UI dance,",
      "offset": 748.959,
      "duration": 4.801
    },
    {
      "lang": "en",
      "text": "yeah, you could even do this in a",
      "offset": 751.44,
      "duration": 3.519
    },
    {
      "lang": "en",
      "text": "different way where you could actually",
      "offset": 753.76,
      "duration": 3.199
    },
    {
      "lang": "en",
      "text": "put checkboxes into your UI that says",
      "offset": 754.959,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "like should the should the model",
      "offset": 756.959,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "preserve this into the context or not.",
      "offset": 758.399,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "So you could even make it user driven",
      "offset": 760.079,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "about whether or not the queries are",
      "offset": 762.079,
      "duration": 4.241
    },
    {
      "lang": "en",
      "text": "passed in. It's really turn your users",
      "offset": 763.76,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "into context engineers. Yeah, exactly.",
      "offset": 766.32,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "turning your users into context",
      "offset": 769.2,
      "duration": 2.8
    },
    {
      "lang": "en",
      "text": "engineers along the way so they can make",
      "offset": 770.48,
      "duration": 3.039
    },
    {
      "lang": "en",
      "text": "an educated decision. You can have good",
      "offset": 772,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "defaults like very long queries get",
      "offset": 773.519,
      "duration": 6.041
    },
    {
      "lang": "en",
      "text": "added in very simple queries",
      "offset": 776.079,
      "duration": 8
    },
    {
      "lang": "en",
      "text": "don't. Does that make sense u?",
      "offset": 779.56,
      "duration": 6.519
    },
    {
      "lang": "en",
      "text": "Yeah definitely that's a that's a really",
      "offset": 784.079,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "clear way of looking at it. Thanks.",
      "offset": 786.079,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "Awesome. Um but now that we have this",
      "offset": 787.839,
      "duration": 4.641
    },
    {
      "lang": "en",
      "text": "framework, I want to talk about the next",
      "offset": 790.959,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "part which is actually the reasoning",
      "offset": 792.48,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "models because we if without an example",
      "offset": 794.639,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "it seems really abstract on how do you",
      "offset": 796.56,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "go do this but let's talk about a little",
      "offset": 798.8,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "bit about what a reasoning model is in",
      "offset": 801.6,
      "duration": 4.919
    },
    {
      "lang": "en",
      "text": "the first place.",
      "offset": 803.68,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "Um so uh D I'm going to go to the",
      "offset": 806.519,
      "duration": 4.76
    },
    {
      "lang": "en",
      "text": "whiteboard really fast. I'm Oh yeah,",
      "offset": 809.44,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "let's do it. Yeah, sorry. Um okay. Yeah,",
      "offset": 811.279,
      "duration": 3.441
    },
    {
      "lang": "en",
      "text": "because the whole point of this is less",
      "offset": 813.36,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "about this content. This is more just",
      "offset": 814.72,
      "duration": 3.679
    },
    {
      "lang": "en",
      "text": "like setting the stage for how this",
      "offset": 816.48,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "thing works. So when you're reading the",
      "offset": 818.399,
      "duration": 2.321
    },
    {
      "lang": "en",
      "text": "code, you get it. Because what we're",
      "offset": 819.6,
      "duration": 2.479
    },
    {
      "lang": "en",
      "text": "going to go do is actually make this",
      "offset": 820.72,
      "duration": 4.559
    },
    {
      "lang": "en",
      "text": "pipeline way more complex because like",
      "offset": 822.079,
      "duration": 4.041
    },
    {
      "lang": "en",
      "text": "and",
      "offset": 825.279,
      "duration": 2.961
    },
    {
      "lang": "en",
      "text": "like do some whiteboarding, but then",
      "offset": 826.12,
      "duration": 3.24
    },
    {
      "lang": "en",
      "text": "like we're going to come up with some",
      "offset": 828.24,
      "duration": 2.96
    },
    {
      "lang": "en",
      "text": "really interesting and complex questions",
      "offset": 829.36,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "that 40 mini is just like no way it's",
      "offset": 831.2,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "going to get the cipher query right.",
      "offset": 833.36,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "Yeah. So let's talk a little bit about",
      "offset": 835.12,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "what a reasoning model is and I think",
      "offset": 837.519,
      "duration": 2.88
    },
    {
      "lang": "en",
      "text": "that's going to help us understand what",
      "offset": 838.959,
      "duration": 3.041
    },
    {
      "lang": "en",
      "text": "they do under the hood and then we can",
      "offset": 840.399,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "talk about it. So, we all know what an",
      "offset": 842,
      "duration": 4.639
    },
    {
      "lang": "en",
      "text": "uh uh well, okay, well, I'm assuming",
      "offset": 844.48,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "most people that come here know what an",
      "offset": 846.639,
      "duration": 4.841
    },
    {
      "lang": "en",
      "text": "LLM is. It's a thing that takes in input",
      "offset": 847.92,
      "duration": 6.76
    },
    {
      "lang": "en",
      "text": "tokens and then spits out",
      "offset": 851.48,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "Oh. Oh, interesting. inputs and arrow",
      "offset": 854.68,
      "duration": 5.719
    },
    {
      "lang": "en",
      "text": "choice. Uh it's a thing that takes in um",
      "offset": 857.48,
      "duration": 5.08
    },
    {
      "lang": "en",
      "text": "input tokens and then spits out another",
      "offset": 860.399,
      "duration": 5.841
    },
    {
      "lang": "en",
      "text": "only a single token at at a time. And",
      "offset": 862.56,
      "duration": 7.639
    },
    {
      "lang": "en",
      "text": "what we do is",
      "offset": 866.24,
      "duration": 3.959
    },
    {
      "lang": "en",
      "text": "uh interesting uh here I got you.",
      "offset": 870.32,
      "duration": 8.24
    },
    {
      "lang": "en",
      "text": "Yeah. Oh interest. Thank you. What we do",
      "offset": 875.72,
      "duration": 4.52
    },
    {
      "lang": "en",
      "text": "under the hood is we keep on generating",
      "offset": 878.56,
      "duration": 5.519
    },
    {
      "lang": "en",
      "text": "this as long as uh the token is not this",
      "offset": 880.24,
      "duration": 7.839
    },
    {
      "lang": "en",
      "text": "special token called eof or uh there's",
      "offset": 884.079,
      "duration": 8.241
    },
    {
      "lang": "en",
      "text": "some like we'll call it eof or eof which",
      "offset": 888.079,
      "duration": 6.641
    },
    {
      "lang": "en",
      "text": "is some like termination token. If the",
      "offset": 892.32,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "token is a termination token, then we",
      "offset": 894.72,
      "duration": 5.32
    },
    {
      "lang": "en",
      "text": "stop and then um and then we go do",
      "offset": 896.56,
      "duration": 5
    },
    {
      "lang": "en",
      "text": "things.",
      "offset": 900.04,
      "duration": 3.799
    },
    {
      "lang": "en",
      "text": "Now, let's talk about what a reasoning",
      "offset": 901.56,
      "duration": 3.8
    },
    {
      "lang": "en",
      "text": "model does. A reasoning model does",
      "offset": 903.839,
      "duration": 5.281
    },
    {
      "lang": "en",
      "text": "something very very very similar to",
      "offset": 905.36,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "this. Um, and I'm not going to claim",
      "offset": 909.959,
      "duration": 4.12
    },
    {
      "lang": "en",
      "text": "that OpenAI does this exactly, but in",
      "offset": 912.16,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "theory it should be somewhat similar",
      "offset": 914.079,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "where there's a special token that we",
      "offset": 916.48,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "add into our So like we have an EOF",
      "offset": 918.48,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "token, we actually add in another",
      "offset": 920.16,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "special token that the model is allowed",
      "offset": 922.16,
      "duration": 5
    },
    {
      "lang": "en",
      "text": "to generate that looks like",
      "offset": 923.68,
      "duration": 7.76
    },
    {
      "lang": "en",
      "text": "this. Reason start. There's like a",
      "offset": 927.16,
      "duration": 5.96
    },
    {
      "lang": "en",
      "text": "couple tokens that it's allowed to do.",
      "offset": 931.44,
      "duration": 2.759
    },
    {
      "lang": "en",
      "text": "Reasoning",
      "offset": 933.12,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "start, reasoning",
      "offset": 934.199,
      "duration": 4.281
    },
    {
      "lang": "en",
      "text": "N. Like this. Got it. So the model is",
      "offset": 938.76,
      "duration": 5.8
    },
    {
      "lang": "en",
      "text": "actually deciding when its reasoning",
      "offset": 942.32,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "starts and oops I spelled reasoning",
      "offset": 944.56,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "wrong. The model is to some degree",
      "offset": 946.8,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "deciding what when the reasoning will",
      "offset": 949.12,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "start and end and if it should reason at",
      "offset": 950.72,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "all. The model may not generate the",
      "offset": 952.8,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "reasoning start token. Now I as open AI",
      "offset": 954.56,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "could enforce that the model generate",
      "offset": 958.24,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "the reasoning start token and it has to",
      "offset": 960.56,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "reason no matter what. So this first",
      "offset": 962.399,
      "duration": 5.841
    },
    {
      "lang": "en",
      "text": "token, in fact, my input token could",
      "offset": 965.68,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "just be when I start off, like when I",
      "offset": 968.24,
      "duration": 5.039
    },
    {
      "lang": "en",
      "text": "have my text, I could do text plus",
      "offset": 969.92,
      "duration": 5.919
    },
    {
      "lang": "en",
      "text": "reasoning",
      "offset": 973.279,
      "duration": 2.56
    },
    {
      "lang": "en",
      "text": "start. Yeah. Have you seen I feel like",
      "offset": 975.959,
      "duration": 4.201
    },
    {
      "lang": "en",
      "text": "I've seen people like prompt engineering",
      "offset": 978.16,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "with like either like, you know, doing",
      "offset": 980.16,
      "duration": 5.359
    },
    {
      "lang": "en",
      "text": "the oh, but wait inside the thinking or",
      "offset": 982.16,
      "duration": 6.4
    },
    {
      "lang": "en",
      "text": "doing the like Yeah. just starting the",
      "offset": 985.519,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "thinking and then passing all of that",
      "offset": 988.56,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "into the LLM where it's like you",
      "offset": 990.959,
      "duration": 3.041
    },
    {
      "lang": "en",
      "text": "actually you write the first three",
      "offset": 992.48,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "sentences of thinking yourself",
      "offset": 994,
      "duration": 5.199
    },
    {
      "lang": "en",
      "text": "put it on a certain path even if you",
      "offset": 996.8,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "actually write the first three sentences",
      "offset": 999.199,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "of thinking just remember that the model",
      "offset": 1000.72,
      "duration": 4.239
    },
    {
      "lang": "en",
      "text": "provider itself actually has to do the",
      "offset": 1003.04,
      "duration": 4.239
    },
    {
      "lang": "en",
      "text": "thinking themselves the model provider",
      "offset": 1004.959,
      "duration": 3.521
    },
    {
      "lang": "en",
      "text": "is actually the one doing the thinking",
      "offset": 1007.279,
      "duration": 2.48
    },
    {
      "lang": "en",
      "text": "so the model provider is the one doing",
      "offset": 1008.48,
      "duration": 2.719
    },
    {
      "lang": "en",
      "text": "thinking even if you write the thinking",
      "offset": 1009.759,
      "duration": 4.481
    },
    {
      "lang": "en",
      "text": "text yourself you write something like",
      "offset": 1011.199,
      "duration": 5.921
    },
    {
      "lang": "en",
      "text": "um prompt",
      "offset": 1014.24,
      "duration": 6.08
    },
    {
      "lang": "en",
      "text": "And then you can write something like",
      "offset": 1017.12,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "this. You can write thinking and then",
      "offset": 1021.16,
      "duration": 6.039
    },
    {
      "lang": "en",
      "text": "you can say blah blah blah. You'll go",
      "offset": 1023.279,
      "duration": 5.92
    },
    {
      "lang": "en",
      "text": "write your thinking part over here.",
      "offset": 1027.199,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "Eventually the model provider will add a",
      "offset": 1029.199,
      "duration": 4.041
    },
    {
      "lang": "en",
      "text": "special token",
      "offset": 1031.679,
      "duration": 5.681
    },
    {
      "lang": "en",
      "text": "called reasoning start of some kind that",
      "offset": 1033.24,
      "duration": 6.52
    },
    {
      "lang": "en",
      "text": "is not under your control. Oh,",
      "offset": 1037.36,
      "duration": 3.599
    },
    {
      "lang": "en",
      "text": "interesting. Cannot make all of it",
      "offset": 1039.76,
      "duration": 4.199
    },
    {
      "lang": "en",
      "text": "orange.",
      "offset": 1040.959,
      "duration": 3
    },
    {
      "lang": "en",
      "text": "um that is not under your",
      "offset": 1044.039,
      "duration": 5.801
    },
    {
      "lang": "en",
      "text": "control that they control that adds it",
      "offset": 1046.679,
      "duration": 4.761
    },
    {
      "lang": "en",
      "text": "in. So technically your thinking part",
      "offset": 1049.84,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "looks still more like the prompt than",
      "offset": 1051.44,
      "duration": 3.119
    },
    {
      "lang": "en",
      "text": "the actual reasoning part of the base.",
      "offset": 1052.96,
      "duration": 4.719
    },
    {
      "lang": "en",
      "text": "Oh, I see. They don't actually let you",
      "offset": 1054.559,
      "duration": 6.48
    },
    {
      "lang": "en",
      "text": "input the reasoning token. Exactly.",
      "offset": 1057.679,
      "duration": 4.801
    },
    {
      "lang": "en",
      "text": "Because there's there's a token that",
      "offset": 1061.039,
      "duration": 3.121
    },
    {
      "lang": "en",
      "text": "indicates that the reasoning starts. Now",
      "offset": 1062.48,
      "duration": 2.88
    },
    {
      "lang": "en",
      "text": "it's possible that this is an",
      "offset": 1064.16,
      "duration": 2.48
    },
    {
      "lang": "en",
      "text": "implementation detail and they don't",
      "offset": 1065.36,
      "duration": 3.199
    },
    {
      "lang": "en",
      "text": "actually need the reasoning start but",
      "offset": 1066.64,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "they probably need some token to",
      "offset": 1068.559,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "indicate that the reasoning is hap that",
      "offset": 1070,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "this is a reasoning segment. It's e it's",
      "offset": 1071.679,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "going to be easier to train the model if",
      "offset": 1073.44,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "it knows that these are reasoning",
      "offset": 1075.919,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "chunks. Yeah. Um and then the model will",
      "offset": 1077.2,
      "duration": 5.16
    },
    {
      "lang": "en",
      "text": "generate a bunch of text down",
      "offset": 1080.24,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "here. Uh and I'm going to make this",
      "offset": 1082.36,
      "duration": 4.04
    },
    {
      "lang": "en",
      "text": "white because this is this is regular",
      "offset": 1084.48,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "generation. So we can think of purple as",
      "offset": 1086.4,
      "duration": 4.639
    },
    {
      "lang": "en",
      "text": "inputs from a user. We can think of blue",
      "offset": 1088.16,
      "duration": 4.12
    },
    {
      "lang": "en",
      "text": "as",
      "offset": 1091.039,
      "duration": 4.961
    },
    {
      "lang": "en",
      "text": "um uh reasoning. So it's just like",
      "offset": 1092.28,
      "duration": 5.8
    },
    {
      "lang": "en",
      "text": "regular text that the model generates.",
      "offset": 1096,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "Then the model will generate another",
      "offset": 1098.08,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "special piece of",
      "offset": 1099.6,
      "duration": 2.88
    },
    {
      "lang": "en",
      "text": "text and then the model will generate",
      "offset": 1104.12,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "more",
      "offset": 1106.32,
      "duration": 4.479
    },
    {
      "lang": "en",
      "text": "text, right? And this is really what a",
      "offset": 1108.44,
      "duration": 3.96
    },
    {
      "lang": "en",
      "text": "reasoning model to some degree is doing",
      "offset": 1110.799,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "under the hood. And what the model is",
      "offset": 1112.4,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "trained to do is it's trained to",
      "offset": 1115.039,
      "duration": 3.041
    },
    {
      "lang": "en",
      "text": "understand the meaning of these two",
      "offset": 1116.559,
      "duration": 4.961
    },
    {
      "lang": "en",
      "text": "tokens as being like extremely useful.",
      "offset": 1118.08,
      "duration": 4.959
    },
    {
      "lang": "en",
      "text": "If you think about what the model can do",
      "offset": 1121.52,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "now is in the training loop, someone can",
      "offset": 1123.039,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "go ahead and go train the model to go",
      "offset": 1124.88,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "say that uh how do I do can you do a",
      "offset": 1127.44,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "curve thing again? Sorry.",
      "offset": 1129.28,
      "duration": 5.279
    },
    {
      "lang": "en",
      "text": "Yeah. uh",
      "offset": 1131.52,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "someone can actually train the model to",
      "offset": 1134.559,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "say that hey the text that lives between",
      "offset": 1136.24,
      "duration": 4.559
    },
    {
      "lang": "en",
      "text": "reasoning start and reasoning end is",
      "offset": 1138.4,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "actually highly informative and you",
      "offset": 1140.799,
      "duration": 5.441
    },
    {
      "lang": "en",
      "text": "should consider that a lot when you uh",
      "offset": 1143.76,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "make decisions on what text to generate",
      "offset": 1146.24,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "next right draws a lot of weight from",
      "offset": 1148.16,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "the like attention mechanism exactly and",
      "offset": 1150.48,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "that's a thing that the model could just",
      "offset": 1152.88,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "be fine-tuned to go do uh and that's",
      "offset": 1154.16,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "really what fundamentally what a",
      "offset": 1156.88,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "reasoning model is doing under the hood",
      "offset": 1158.4,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "and again can't really claim to know",
      "offset": 1160.24,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "exactly what models do. Uh it is very",
      "offset": 1162.08,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "hard to go predict anything about",
      "offset": 1164.24,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "models. Well, we've been doing parts of",
      "offset": 1165.52,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "this in prompts since way before it was",
      "offset": 1168.08,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "like baked into the model, right? You",
      "offset": 1170.24,
      "duration": 3.439
    },
    {
      "lang": "en",
      "text": "could like ask it like, &quot;Hey, always",
      "offset": 1171.84,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "think about what to do, step one, step",
      "offset": 1173.679,
      "duration": 3.761
    },
    {
      "lang": "en",
      "text": "two, step three, and then give your",
      "offset": 1175.44,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "answer.&quot; And some models that are good",
      "offset": 1177.44,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "at instruction following might actually",
      "offset": 1179.12,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "just like it's not fine-tuned to trust",
      "offset": 1180.64,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "that stuff more, but it does you do",
      "offset": 1183.28,
      "duration": 5.759
    },
    {
      "lang": "en",
      "text": "force it to kind of like expand out on",
      "offset": 1186.32,
      "duration": 4.479
    },
    {
      "lang": "en",
      "text": "like what it thinks about the problem",
      "offset": 1189.039,
      "duration": 3.441
    },
    {
      "lang": "en",
      "text": "and what needs to happen before it",
      "offset": 1190.799,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "actually gives you the answer. Right.",
      "offset": 1192.48,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "Exactly.",
      "offset": 1194.799,
      "duration": 3.281
    },
    {
      "lang": "en",
      "text": "I think that's the whole point. So we",
      "offset": 1196.559,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "could go do this, but this thing just",
      "offset": 1198.08,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "allows the model to go have this in its",
      "offset": 1199.679,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "training loop. Now the problem is in the",
      "offset": 1201.12,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "basic training loop of what a model is",
      "offset": 1203.36,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "doing, it's really just trained to draw",
      "offset": 1204.96,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "attention from whatever it thinks is",
      "offset": 1207.2,
      "duration": 4.28
    },
    {
      "lang": "en",
      "text": "relevant. So if you just do",
      "offset": 1208.96,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "this in the model generation loop, the",
      "offset": 1211.48,
      "duration": 4.52
    },
    {
      "lang": "en",
      "text": "model is really just drawing attention",
      "offset": 1214.24,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "from anything that it thinks is",
      "offset": 1216,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "relevant.",
      "offset": 1217.6,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "I call this like standard generation or",
      "offset": 1219.2,
      "duration": 4.68
    },
    {
      "lang": "en",
      "text": "normal generation or something. Yeah.",
      "offset": 1221.2,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "Yeah. The generation is the same. All",
      "offset": 1223.88,
      "duration": 3.96
    },
    {
      "lang": "en",
      "text": "I'm saying is what the model is trying",
      "offset": 1226.4,
      "duration": 2.72
    },
    {
      "lang": "en",
      "text": "to do is learn the difference between",
      "offset": 1227.84,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "tokens between these two tokens. Yeah,",
      "offset": 1229.12,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "have extra weight. The text, the actual",
      "offset": 1231.76,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "tokens in here have no special meaning.",
      "offset": 1234.4,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "It's just that this is a good marker for",
      "offset": 1236.48,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "the model",
      "offset": 1238.4,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "to know that everything in between has",
      "offset": 1240.32,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "special weight and it should be",
      "offset": 1242.32,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "considered a little bit more uh",
      "offset": 1243.84,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "logically flowing. And it might even",
      "offset": 1245.76,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "bias things at the bottom. I don't",
      "offset": 1247.12,
      "duration": 3.039
    },
    {
      "lang": "en",
      "text": "really know how the model works, but it",
      "offset": 1248.96,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "you could reason that it could bias",
      "offset": 1250.159,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "things at the bottom of the reasoning",
      "offset": 1252.32,
      "duration": 2.88
    },
    {
      "lang": "en",
      "text": "loop more than things at the top of the",
      "offset": 1253.679,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "reasoning loop. Right. Right. And like",
      "offset": 1255.2,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "the the old school way you would do this",
      "offset": 1258.159,
      "duration": 4.561
    },
    {
      "lang": "en",
      "text": "would basically be like you would you",
      "offset": 1260.64,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "would call an LLM",
      "offset": 1262.72,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "um and you would put in your input",
      "offset": 1265.12,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "tokens and you would say like make a",
      "offset": 1267.039,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "plan like think about this thing and",
      "offset": 1268.72,
      "duration": 4.12
    },
    {
      "lang": "en",
      "text": "tell me what you",
      "offset": 1270.559,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "think and then you would put that in the",
      "offset": 1272.84,
      "duration": 4.199
    },
    {
      "lang": "en",
      "text": "LM and then it would output your like",
      "offset": 1274.96,
      "duration": 4.839
    },
    {
      "lang": "en",
      "text": "answer which was like okay here's the",
      "offset": 1277.039,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "plan and then you would take that plan",
      "offset": 1279.799,
      "duration": 4.12
    },
    {
      "lang": "en",
      "text": "and you would pass it into another like",
      "offset": 1282.159,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "either probably the same LLM but just",
      "offset": 1283.919,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "like a fresh prompt.",
      "offset": 1285.76,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "And then it would be like okay based on",
      "offset": 1287.679,
      "duration": 5.041
    },
    {
      "lang": "en",
      "text": "that plan here's the answer and the plan",
      "offset": 1289.6,
      "duration": 5.199
    },
    {
      "lang": "en",
      "text": "is something like you know do a complex",
      "offset": 1292.72,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "math problem or generate a bunch of code",
      "offset": 1294.799,
      "duration": 3.521
    },
    {
      "lang": "en",
      "text": "or whatever it is right if you've used",
      "offset": 1296.72,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "cursor or clots on it like you've seen",
      "offset": 1298.32,
      "duration": 5.599
    },
    {
      "lang": "en",
      "text": "it do this right exactly so like if I go",
      "offset": 1300.64,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "over here",
      "offset": 1303.919,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "um if I go over here in the above",
      "offset": 1305.76,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "section decks",
      "offset": 1307.76,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "in the wrong thinking so this is one way",
      "offset": 1309.6,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "to go do that where it's still standard",
      "offset": 1312,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "generation and I'm just taking advantage",
      "offset": 1313.52,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "of the fact that I can force the model",
      "offset": 1315.52,
      "duration": 3
    },
    {
      "lang": "en",
      "text": "to generate these thinking",
      "offset": 1316.96,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "tokens. The only difference is instead",
      "offset": 1318.52,
      "duration": 3.88
    },
    {
      "lang": "en",
      "text": "of the model like knowing what these",
      "offset": 1320.96,
      "duration": 3.199
    },
    {
      "lang": "en",
      "text": "thinking tokens are and having to infer",
      "offset": 1322.4,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "that things between these are thinking,",
      "offset": 1324.159,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "I can just train it in the training loop",
      "offset": 1326.32,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "to know the difference.",
      "offset": 1328.48,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "Yeah. Otherwise, it's just taking",
      "offset": 1331.28,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "whatever its normal sort of like",
      "offset": 1332.799,
      "duration": 4.561
    },
    {
      "lang": "en",
      "text": "interpretation of thinking as just what",
      "offset": 1335.2,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "is the meaning of that token in general,",
      "offset": 1337.36,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "but not as a special token. Exactly.",
      "offset": 1338.96,
      "duration": 6.079
    },
    {
      "lang": "en",
      "text": "Exactly. That's it. So that's really all",
      "offset": 1342,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "that's happening here is the model is",
      "offset": 1345.039,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "somehow able to come up with",
      "offset": 1346.64,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "understanding what a thinking model is.",
      "offset": 1348.559,
      "duration": 5.441
    },
    {
      "lang": "en",
      "text": "Um there's I think uh there's a question",
      "offset": 1351.039,
      "duration": 4.801
    },
    {
      "lang": "en",
      "text": "in the chat. Yeah. Which which elems are",
      "offset": 1354,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "these reasoning tokens applicable to?",
      "offset": 1355.84,
      "duration": 5.839
    },
    {
      "lang": "en",
      "text": "Um so these reasoning tokens are u again",
      "offset": 1358.96,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "this is like one possible implementation",
      "offset": 1361.679,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "of how reasoning could work in. Um this",
      "offset": 1363.76,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "there's a few other different ways that",
      "offset": 1366.159,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "you could implement such a thing. Um for",
      "offset": 1367.76,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "example the you could technically say",
      "offset": 1370.32,
      "duration": 3.599
    },
    {
      "lang": "en",
      "text": "that reasoning start is not required. I",
      "offset": 1372,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "will only generate a reasoning end token",
      "offset": 1373.919,
      "duration": 3
    },
    {
      "lang": "en",
      "text": "nothing",
      "offset": 1375.76,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "else. Uh you could use tool calling or",
      "offset": 1376.919,
      "duration": 3.721
    },
    {
      "lang": "en",
      "text": "something else as an implementation",
      "offset": 1379.52,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "detail of how this works. But most have",
      "offset": 1380.64,
      "duration": 5.919
    },
    {
      "lang": "en",
      "text": "something of this akin of where reason",
      "offset": 1383.679,
      "duration": 4.721
    },
    {
      "lang": "en",
      "text": "starts. They need to have some de",
      "offset": 1386.559,
      "duration": 4.561
    },
    {
      "lang": "en",
      "text": "demarcation in the way that the LM",
      "offset": 1388.4,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "generates tokens that tells you where it",
      "offset": 1391.12,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "ends and where it starts. Yeah. So like",
      "offset": 1393.6,
      "duration": 4.959
    },
    {
      "lang": "en",
      "text": "the the tool calling one's really",
      "offset": 1396.4,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "interesting. I want to I want to pause",
      "offset": 1398.559,
      "duration": 2.561
    },
    {
      "lang": "en",
      "text": "on that for a sec. So like you could",
      "offset": 1399.76,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "have a function like send email and then",
      "offset": 1401.12,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "you could have the parameters be",
      "offset": 1403.36,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "something like uh you know oh let me",
      "offset": 1405.44,
      "duration": 8.719
    },
    {
      "lang": "en",
      "text": "make proper JSON here you know thought",
      "offset": 1408.72,
      "duration": 5.439
    },
    {
      "lang": "en",
      "text": "process and that's a string and then you",
      "offset": 1415.32,
      "duration": 7.08
    },
    {
      "lang": "en",
      "text": "have email content right",
      "offset": 1418.4,
      "duration": 5.92
    },
    {
      "lang": "en",
      "text": "and so in this case if you ask the model",
      "offset": 1422.4,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "to output those fields in that order",
      "offset": 1424.32,
      "duration": 3.599
    },
    {
      "lang": "en",
      "text": "it's going to tell you like oh here's",
      "offset": 1426.32,
      "duration": 3.359
    },
    {
      "lang": "en",
      "text": "what I was thinking about and then also",
      "offset": 1427.919,
      "duration": 2.961
    },
    {
      "lang": "en",
      "text": "here's the email. So you're kind of",
      "offset": 1429.679,
      "duration": 3.281
    },
    {
      "lang": "en",
      "text": "forcing it to output tokens about its",
      "offset": 1430.88,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "thought process.",
      "offset": 1432.96,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "Yes. But that is very much akin to like",
      "offset": 1434.799,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "this option right over here. Exactly.",
      "offset": 1437.12,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "Yeah. Same idea. Like people have been I",
      "offset": 1438.96,
      "duration": 2.959
    },
    {
      "lang": "en",
      "text": "think I think when function calling",
      "offset": 1440.72,
      "duration": 2.959
    },
    {
      "lang": "en",
      "text": "first came out in like April 2023,",
      "offset": 1441.919,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "OpenAI had advice actually to put the",
      "offset": 1443.679,
      "duration": 4.961
    },
    {
      "lang": "en",
      "text": "first parameter of your function to be",
      "offset": 1447.039,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "like thought or like thinking or like",
      "offset": 1448.64,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "whatever it is. And I think I've seen",
      "offset": 1451.279,
      "duration": 3.121
    },
    {
      "lang": "en",
      "text": "like like the early lang chain function",
      "offset": 1452.48,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "calling loops would actually do that.",
      "offset": 1454.4,
      "duration": 2.72
    },
    {
      "lang": "en",
      "text": "They would have it output the thought",
      "offset": 1455.84,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "and then they would strip that out and",
      "offset": 1457.12,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "print it to the console and then go run",
      "offset": 1458.88,
      "duration": 3.799
    },
    {
      "lang": "en",
      "text": "run the function that it output.",
      "offset": 1460.64,
      "duration": 5.039
    },
    {
      "lang": "en",
      "text": "Exactly. So, we'll talk about this in a",
      "offset": 1462.679,
      "duration": 5.401
    },
    {
      "lang": "en",
      "text": "few seconds. Um, but just to catch",
      "offset": 1465.679,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "everyone else up. Um, oh, I'll leave",
      "offset": 1468.08,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "that there. Um, do these two different",
      "offset": 1469.919,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "approaches of how thinking works under",
      "offset": 1472.96,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "the hood makes any questions about them",
      "offset": 1474.799,
      "duration": 4.561
    },
    {
      "lang": "en",
      "text": "so",
      "offset": 1477.12,
      "duration": 2.24
    },
    {
      "lang": "en",
      "text": "far? I'll wait a couple seconds just to",
      "offset": 1481.4,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "see if people are typing them out.",
      "offset": 1483.76,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "Um, but if not, I think I want to move",
      "offset": 1486.36,
      "duration": 4.12
    },
    {
      "lang": "en",
      "text": "on to the next part that I think is",
      "offset": 1488.96,
      "duration": 3.199
    },
    {
      "lang": "en",
      "text": "going to be a lot more interesting.",
      "offset": 1490.48,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "Yeah. Which is going to be more along",
      "offset": 1492.159,
      "duration": 4.52
    },
    {
      "lang": "en",
      "text": "the lines of how do we actually get",
      "offset": 1494.4,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "models to do thought processes kind of",
      "offset": 1496.679,
      "duration": 5.161
    },
    {
      "lang": "en",
      "text": "akin to what you were saying? Uh, Dex.",
      "offset": 1499.76,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "Yeah. What one thing I'd be one thing",
      "offset": 1501.84,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "I'd be interested to try is like I have",
      "offset": 1505.12,
      "duration": 4.559
    },
    {
      "lang": "en",
      "text": "a couple like top of mind like really",
      "offset": 1506.88,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "hard cipher queries like like text",
      "offset": 1509.679,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "descriptions of queries and we can try",
      "offset": 1512.08,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "and see if this thing can get it. We can",
      "offset": 1513.6,
      "duration": 4.959
    },
    {
      "lang": "en",
      "text": "drop in like switch the model to a much",
      "offset": 1515.84,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "smarter model and see that that model",
      "offset": 1518.559,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "can actually figure it out and then go",
      "offset": 1520.24,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "back to see hey how can we pipeline boro",
      "offset": 1522.24,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "mini to get it to get close to the sim",
      "offset": 1524.88,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "same same same results. What do you",
      "offset": 1526.88,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "think about that? All right cool idea.",
      "offset": 1528.64,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "Um, so I'm going to refresh this. Let's",
      "offset": 1531.12,
      "duration": 5.64
    },
    {
      "lang": "en",
      "text": "ask something like tell me how many",
      "offset": 1533.6,
      "duration": 7.48
    },
    {
      "lang": "en",
      "text": "movies that Kiana",
      "offset": 1536.76,
      "duration": 8.159
    },
    {
      "lang": "en",
      "text": "Reeves and Alan Degenerous this might be",
      "offset": 1541.08,
      "duration": 8.4
    },
    {
      "lang": "en",
      "text": "zero are both in.",
      "offset": 1544.919,
      "duration": 4.561
    },
    {
      "lang": "en",
      "text": "Okay. Yeah. So, I don't know if this",
      "offset": 1551.279,
      "duration": 3.441
    },
    {
      "lang": "en",
      "text": "query is wrong or what, but I don't",
      "offset": 1553.12,
      "duration": 2.84
    },
    {
      "lang": "en",
      "text": "know.",
      "offset": 1554.72,
      "duration": 3.439
    },
    {
      "lang": "en",
      "text": "Um, what's another what's another one",
      "offset": 1555.96,
      "duration": 4.599
    },
    {
      "lang": "en",
      "text": "that's hard to get right? Um, as it",
      "offset": 1558.159,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "turns out, it's actually very hard to",
      "offset": 1560.559,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "write. Um, uh, you can try the Kevin",
      "offset": 1562.08,
      "duration": 5.079
    },
    {
      "lang": "en",
      "text": "Bacon",
      "offset": 1564.799,
      "duration": 7
    },
    {
      "lang": "en",
      "text": "number's Kevin Bacon number.",
      "offset": 1567.159,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "Yeah.",
      "offset": 1580.24,
      "duration": 3
    },
    {
      "lang": "en",
      "text": "Um, what's the definition of Kevin Bacon",
      "offset": 1584.48,
      "duration": 3.679
    },
    {
      "lang": "en",
      "text": "number?",
      "offset": 1586.64,
      "duration": 4.12
    },
    {
      "lang": "en",
      "text": "It's six degrees of Kevin",
      "offset": 1588.159,
      "duration": 6.161
    },
    {
      "lang": "en",
      "text": "Bacon. He's like, um, you can just ask",
      "offset": 1590.76,
      "duration": 6.36
    },
    {
      "lang": "en",
      "text": "it to do six degrees of play play six",
      "offset": 1594.32,
      "duration": 4.12
    },
    {
      "lang": "en",
      "text": "degrees of Kevin",
      "offset": 1597.12,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "Bacon with K",
      "offset": 1598.44,
      "duration": 3.56
    },
    {
      "lang": "en",
      "text": "Reeves. Spell it",
      "offset": 1606.76,
      "duration": 3.48
    },
    {
      "lang": "en",
      "text": "right. Okay.",
      "offset": 1615.159,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "What",
      "offset": 1618.24,
      "duration": 4.559
    },
    {
      "lang": "en",
      "text": "happened? Just say try again.",
      "offset": 1619.48,
      "duration": 6.36
    },
    {
      "lang": "en",
      "text": "Let's see. I think this might be a back",
      "offset": 1622.799,
      "duration": 5.201
    },
    {
      "lang": "en",
      "text": "end problem.",
      "offset": 1625.84,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "Uh,",
      "offset": 1628,
      "duration": 2.48
    },
    {
      "lang": "en",
      "text": "okay. There you go.",
      "offset": 1639.48,
      "duration": 4.679
    },
    {
      "lang": "en",
      "text": "So as we saw I think the most",
      "offset": 1642.24,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "interesting part here was that this kind",
      "offset": 1644.159,
      "duration": 3.961
    },
    {
      "lang": "en",
      "text": "of",
      "offset": 1646.88,
      "duration": 3.48
    },
    {
      "lang": "en",
      "text": "uh",
      "offset": 1648.12,
      "duration": 5.159
    },
    {
      "lang": "en",
      "text": "um this kind of has an issue where we",
      "offset": 1650.36,
      "duration": 4.76
    },
    {
      "lang": "en",
      "text": "was having a lot of variability coming",
      "offset": 1653.279,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "into this. So the question becomes how",
      "offset": 1655.12,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "could we make this better if we wanted",
      "offset": 1657.36,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "to? Let's swap it out to 03 reasoning 03",
      "offset": 1658.88,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "mini. Uh what's the 03 model that you",
      "offset": 1662,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "have? Uh I think you have 03 preview in",
      "offset": 1664.48,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "here.",
      "offset": 1667.36,
      "duration": 5.72
    },
    {
      "lang": "en",
      "text": "Uh, let's use mini.",
      "offset": 1669.12,
      "duration": 3.96
    },
    {
      "lang": "en",
      "text": "Uh, yeah, 03 mini. Okay. Oh, 03 mini. I",
      "offset": 1674.48,
      "duration": 4.799
    },
    {
      "lang": "en",
      "text": "think that's a reasoning model. So, we",
      "offset": 1677.6,
      "duration": 4.76
    },
    {
      "lang": "en",
      "text": "should just",
      "offset": 1679.279,
      "duration": 3.081
    },
    {
      "lang": "en",
      "text": "Okay, that did a regen, right? Yeah.",
      "offset": 1684.44,
      "duration": 5.16
    },
    {
      "lang": "en",
      "text": "Okay,",
      "offset": 1687.279,
      "duration": 2.321
    },
    {
      "lang": "en",
      "text": "cool.",
      "offset": 1690.36,
      "duration": 3
    },
    {
      "lang": "en",
      "text": "Ah, lazy.",
      "offset": 1696.039,
      "duration": 5.561
    },
    {
      "lang": "en",
      "text": "So one I mean firstly the model is going",
      "offset": 1699.679,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "to get a lot slower. We all know this",
      "offset": 1701.6,
      "duration": 3.24
    },
    {
      "lang": "en",
      "text": "because it's going to be start",
      "offset": 1703.279,
      "duration": 7
    },
    {
      "lang": "en",
      "text": "thinking. Hey sorry people",
      "offset": 1704.84,
      "duration": 5.439
    },
    {
      "lang": "en",
      "text": "um it started to go do this and it was",
      "offset": 1712.559,
      "duration": 3.201
    },
    {
      "lang": "en",
      "text": "able to go do something that's kind of",
      "offset": 1714.559,
      "duration": 3.201
    },
    {
      "lang": "en",
      "text": "similar. But what will end up happening",
      "offset": 1715.76,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "is that this model is going to be a",
      "offset": 1717.76,
      "duration": 4.639
    },
    {
      "lang": "en",
      "text": "little bit more um how do I describe it?",
      "offset": 1719.2,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "A little bit more reliable on a lot more",
      "offset": 1722.399,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "questions. So like for example right now",
      "offset": 1724.32,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "we have to add a lot more context about",
      "offset": 1726.48,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "what Kevin Bacon is. Just restart you",
      "offset": 1727.84,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "start a new question say compute the",
      "offset": 1730.24,
      "duration": 4.919
    },
    {
      "lang": "en",
      "text": "Kevin Bacon number",
      "offset": 1731.52,
      "duration": 3.639
    },
    {
      "lang": "en",
      "text": "for a particular actor uh for Kevin Spy",
      "offset": 1736.64,
      "duration": 8.519
    },
    {
      "lang": "en",
      "text": "or uh yeah Kevin Spacy.",
      "offset": 1740.88,
      "duration": 6.56
    },
    {
      "lang": "en",
      "text": "Sure. And what this model will do is",
      "offset": 1745.159,
      "duration": 4.041
    },
    {
      "lang": "en",
      "text": "because it kind of knows what the Kevin",
      "offset": 1747.44,
      "duration": 3.119
    },
    {
      "lang": "en",
      "text": "Bacon number is will probably produce",
      "offset": 1749.2,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "some of the answers of exactly what that",
      "offset": 1750.559,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "is along the way.",
      "offset": 1752.32,
      "duration": 5.359
    },
    {
      "lang": "en",
      "text": "And it was all everybody's number is",
      "offset": 1755.919,
      "duration": 3.801
    },
    {
      "lang": "en",
      "text": "two. Okay, so let's do another one. What",
      "offset": 1757.679,
      "duration": 7.841
    },
    {
      "lang": "en",
      "text": "actors have a Kevin Bacon number five?",
      "offset": 1759.72,
      "duration": 7.64
    },
    {
      "lang": "en",
      "text": "Good question. Now, this is going to be",
      "offset": 1765.52,
      "duration": 3.48
    },
    {
      "lang": "en",
      "text": "a very interesting query,",
      "offset": 1767.36,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "but I think what I want to start playing",
      "offset": 1769,
      "duration": 3.559
    },
    {
      "lang": "en",
      "text": "around with that, I'm going to ask for",
      "offset": 1771.279,
      "duration": 6.76
    },
    {
      "lang": "en",
      "text": "Yeah. Um Yeah. Yeah. Yeah. Um,",
      "offset": 1772.559,
      "duration": 5.48
    },
    {
      "lang": "en",
      "text": "uh, once it's done, there's also, I will",
      "offset": 1781.52,
      "duration": 6.32
    },
    {
      "lang": "en",
      "text": "say there's a bunch of, um, if you go if",
      "offset": 1784,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "you go to the database, I'll just show",
      "offset": 1787.84,
      "duration": 2.959
    },
    {
      "lang": "en",
      "text": "you as well. There, they have a bunch of",
      "offset": 1789.44,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "interesting queries with good prompts",
      "offset": 1790.799,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "that we could try as well. So, if you go",
      "offset": 1792.64,
      "duration": 6.32
    },
    {
      "lang": "en",
      "text": "to connect to the server and you do play",
      "offset": 1794.48,
      "duration": 5.799
    },
    {
      "lang": "en",
      "text": "this",
      "offset": 1798.96,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "thing, there we go. Uh this gives you a",
      "offset": 1800.279,
      "duration": 4.681
    },
    {
      "lang": "en",
      "text": "bunch of HTML with like problems and",
      "offset": 1802.88,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "things you can do. So we can put in some",
      "offset": 1804.96,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "of these like really complica complex",
      "offset": 1806.64,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "like chicardian distance things and we",
      "offset": 1808.72,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "can ask it to like do this kind of",
      "offset": 1811.12,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "stuff. But um anyways, yeah. You want to",
      "offset": 1812.96,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "jump in the code? Yeah, I'm going to",
      "offset": 1815.2,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "request remote control for participate.",
      "offset": 1817.36,
      "duration": 6.16
    },
    {
      "lang": "en",
      "text": "Yep. Cool. Uh let's talk about how we",
      "offset": 1819.36,
      "duration": 6.4
    },
    {
      "lang": "en",
      "text": "could if we wanted Oops, I'm still on",
      "offset": 1823.52,
      "duration": 3.159
    },
    {
      "lang": "en",
      "text": "drawing",
      "offset": 1825.76,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "mode. Let's talk about how we could if",
      "offset": 1826.679,
      "duration": 4.12
    },
    {
      "lang": "en",
      "text": "we wanted take advantage. And I'm going",
      "offset": 1828.96,
      "duration": 3.64
    },
    {
      "lang": "en",
      "text": "to have to do no vim mode because I'm a",
      "offset": 1830.799,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "flood. Uh if we want to take advantage",
      "offset": 1832.6,
      "duration": 4.84
    },
    {
      "lang": "en",
      "text": "of GPT40 mini and somehow turn this into",
      "offset": 1835.12,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "a reasoning model. Well, the first thing",
      "offset": 1837.44,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "we could do is we could just tell the",
      "offset": 1839.279,
      "duration": 5
    },
    {
      "lang": "en",
      "text": "model",
      "offset": 1841.279,
      "duration": 3
    },
    {
      "lang": "en",
      "text": "um before",
      "offset": 1848.6,
      "duration": 8.319
    },
    {
      "lang": "en",
      "text": "answering note what is useful and",
      "offset": 1850.919,
      "duration": 10
    },
    {
      "lang": "en",
      "text": "particularly hard.",
      "offset": 1856.919,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "And we can answer this right here.",
      "offset": 1863.679,
      "duration": 4.281
    },
    {
      "lang": "en",
      "text": "example. Okay. And before we go into",
      "offset": 1883.32,
      "duration": 3.4
    },
    {
      "lang": "en",
      "text": "this, I kind of want to just walk",
      "offset": 1885.679,
      "duration": 3.041
    },
    {
      "lang": "en",
      "text": "through this without having to go and do",
      "offset": 1886.72,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "the entire prompt the whole time. Um,",
      "offset": 1888.72,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "can you do me a favor and paste the",
      "offset": 1891.76,
      "duration": 2.72
    },
    {
      "lang": "en",
      "text": "scheme? Oh, yeah. Let's get I'll get the",
      "offset": 1893.039,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "scheme in there for you. Uh, one second.",
      "offset": 1894.48,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "One second. Uh, let me just add the",
      "offset": 1896.799,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "hashtag. So,",
      "offset": 1898.48,
      "duration": 7
    },
    {
      "lang": "en",
      "text": "cool. You can plug that. Yep.",
      "offset": 1900.559,
      "duration": 4.921
    },
    {
      "lang": "en",
      "text": "Don't need the uh",
      "offset": 1908.24,
      "duration": 8.159
    },
    {
      "lang": "en",
      "text": "Yeah, let me just uh real quick.",
      "offset": 1911.36,
      "duration": 7.439
    },
    {
      "lang": "en",
      "text": "Yeah, we definitely don't need this.",
      "offset": 1916.399,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "Cool. So, let's look at what the prompt",
      "offset": 1918.799,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "ends up being like just so we can get a",
      "offset": 1921.039,
      "duration": 3
    },
    {
      "lang": "en",
      "text": "good feel for this.",
      "offset": 1922.64,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "Um so a prompt has a massive input with",
      "offset": 1924.039,
      "duration": 7.12
    },
    {
      "lang": "en",
      "text": "the actual schema but then at the",
      "offset": 1926.96,
      "duration": 6.8
    },
    {
      "lang": "en",
      "text": "very at the very bottom what we do is we",
      "offset": 1931.159,
      "duration": 4.52
    },
    {
      "lang": "en",
      "text": "add in the user's messages and after the",
      "offset": 1933.76,
      "duration": 3.519
    },
    {
      "lang": "en",
      "text": "user's messages we tell the model what",
      "offset": 1935.679,
      "duration": 2.88
    },
    {
      "lang": "en",
      "text": "it should be doing. We tell it that it",
      "offset": 1937.279,
      "duration": 2.4
    },
    {
      "lang": "en",
      "text": "should be answering in one of these",
      "offset": 1938.559,
      "duration": 3.761
    },
    {
      "lang": "en",
      "text": "schemas but then before answering I",
      "offset": 1939.679,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "actually wanted to go and note these",
      "offset": 1942.32,
      "duration": 4.52
    },
    {
      "lang": "en",
      "text": "things that are particularly hard.",
      "offset": 1944.159,
      "duration": 5.041
    },
    {
      "lang": "en",
      "text": "So, and now we'll say that the model",
      "offset": 1946.84,
      "duration": 3.8
    },
    {
      "lang": "en",
      "text": "will actually note what things are",
      "offset": 1949.2,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "particularly hard and I'll start with a",
      "offset": 1950.64,
      "duration": 2.96
    },
    {
      "lang": "en",
      "text": "cipher and then I'll go ahead and go",
      "offset": 1952.24,
      "duration": 4.799
    },
    {
      "lang": "en",
      "text": "return it for us. So, I've in effect",
      "offset": 1953.6,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "I've turned this model into a reasoning",
      "offset": 1957.039,
      "duration": 3.441
    },
    {
      "lang": "en",
      "text": "model without actually using any",
      "offset": 1958.88,
      "duration": 3.519
    },
    {
      "lang": "en",
      "text": "reasoning under the hood. If I Well,",
      "offset": 1960.48,
      "duration": 4.799
    },
    {
      "lang": "en",
      "text": "this is still 03 mini, right? Nope. Oh,",
      "offset": 1962.399,
      "duration": 5.16
    },
    {
      "lang": "en",
      "text": "you switch it. Okay, nice.",
      "offset": 1965.279,
      "duration": 6.721
    },
    {
      "lang": "en",
      "text": "Yeah. If I make this part go",
      "offset": 1967.559,
      "duration": 4.441
    },
    {
      "lang": "en",
      "text": "away, now this part is no longer in the",
      "offset": 1975.72,
      "duration": 4.679
    },
    {
      "lang": "en",
      "text": "problem. The model is going to output",
      "offset": 1978.2,
      "duration": 4.92
    },
    {
      "lang": "en",
      "text": "just outputs the JSON. Exactly. So it's",
      "offset": 1980.399,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "going to we there's an interesting",
      "offset": 1983.12,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "balance that I'm able to strike which is",
      "offset": 1984.32,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "I can turn an existing model into a",
      "offset": 1986.64,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "reasoning model and make it go do things",
      "offset": 1988.48,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "by telling it how to go do things. Now",
      "offset": 1990.799,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "if I out I I think one technique that",
      "offset": 1992.72,
      "duration": 3.679
    },
    {
      "lang": "en",
      "text": "someone mentioned in the thing is I",
      "offset": 1994.64,
      "duration": 3.279
    },
    {
      "lang": "en",
      "text": "could tell the model to output thinking",
      "offset": 1996.399,
      "duration": 3.361
    },
    {
      "lang": "en",
      "text": "tags",
      "offset": 1997.919,
      "duration": 5.521
    },
    {
      "lang": "en",
      "text": "um and again this is",
      "offset": 1999.76,
      "duration": 5.799
    },
    {
      "lang": "en",
      "text": "uh",
      "offset": 2003.44,
      "duration": 5.239
    },
    {
      "lang": "en",
      "text": "notes and my notes and then go",
      "offset": 2005.559,
      "duration": 6.6
    },
    {
      "lang": "en",
      "text": "answer and if I go okay",
      "offset": 2008.679,
      "duration": 5.48
    },
    {
      "lang": "en",
      "text": "so here you can actually like experiment",
      "offset": 2012.159,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "which like which which thinking token",
      "offset": 2014.159,
      "duration": 4.961
    },
    {
      "lang": "en",
      "text": "name is actually the best for for",
      "offset": 2016.559,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "getting good results right and you can",
      "offset": 2019.12,
      "duration": 2.88
    },
    {
      "lang": "en",
      "text": "see that the model is actually not even",
      "offset": 2020.64,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "outputting this and maybe it's cuz the",
      "offset": 2022,
      "duration": 5.279
    },
    {
      "lang": "en",
      "text": "word example is bad. So we can go play",
      "offset": 2024.48,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "around with this and it's still not",
      "offset": 2027.279,
      "duration": 2.721
    },
    {
      "lang": "en",
      "text": "outputting this. It seems like it's a",
      "offset": 2028.399,
      "duration": 2.88
    },
    {
      "lang": "en",
      "text": "little bit easier for the model to just",
      "offset": 2030,
      "duration": 2.64
    },
    {
      "lang": "en",
      "text": "not have to think about this from like a",
      "offset": 2031.279,
      "duration": 4.481
    },
    {
      "lang": "en",
      "text": "notes perspective and just like answer",
      "offset": 2032.64,
      "duration": 6.48
    },
    {
      "lang": "en",
      "text": "with this as a point as a as a list and",
      "offset": 2035.76,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "one thing to note here is it's actually",
      "offset": 2039.12,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "really bene now what I could have done",
      "offset": 2040.72,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "is one of the and I want to comment what",
      "offset": 2043.44,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "I was noting earlier is I could have",
      "offset": 2045.36,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "added a thing into here a little bit",
      "offset": 2047.2,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "better.",
      "offset": 2049.28,
      "duration": 3.24
    },
    {
      "lang": "en",
      "text": "It's called",
      "offset": 2051.04,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "like Oops. Yeah. Let's skip the action",
      "offset": 2052.52,
      "duration": 4.839
    },
    {
      "lang": "en",
      "text": "first. Yeah.",
      "offset": 2055.2,
      "duration": 4.719
    },
    {
      "lang": "en",
      "text": "Reasoning",
      "offset": 2057.359,
      "duration": 2.56
    },
    {
      "lang": "en",
      "text": "string. I can add this into both of",
      "offset": 2063.56,
      "duration": 5.519
    },
    {
      "lang": "en",
      "text": "these instead of doing",
      "offset": 2066.28,
      "duration": 5.799
    },
    {
      "lang": "en",
      "text": "this. And now when I get answer, I",
      "offset": 2069.079,
      "duration": 4.6
    },
    {
      "lang": "en",
      "text": "actually get like a little answer, a",
      "offset": 2072.079,
      "duration": 2.881
    },
    {
      "lang": "en",
      "text": "reasoning behind what the model is",
      "offset": 2073.679,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "trying to do. This was the function",
      "offset": 2074.96,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "calling version of what we're This is",
      "offset": 2077.28,
      "duration": 2.799
    },
    {
      "lang": "en",
      "text": "the function calling version of getting",
      "offset": 2078.56,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "reasoning out. And this has a couple of",
      "offset": 2080.079,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "benefits. But in reality, the this",
      "offset": 2081.76,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "actually has if I make a more",
      "offset": 2084,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "complicated query like",
      "offset": 2085.52,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "what",
      "offset": 2088.96,
      "duration": 2.24
    },
    {
      "lang": "en",
      "text": "is it",
      "offset": 2091.399,
      "duration": 3.161
    },
    {
      "lang": "en",
      "text": "reads like what is RE's most uh",
      "offset": 2097.96,
      "duration": 4.28
    },
    {
      "lang": "en",
      "text": "reasoning number. You can see that like",
      "offset": 2100.72,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "this is feels a lot lot more constrained",
      "offset": 2102.24,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "for the model. So let's try and let's",
      "offset": 2104.48,
      "duration": 5.599
    },
    {
      "lang": "en",
      "text": "try and not do this and instead use a",
      "offset": 2106.88,
      "duration": 5.92
    },
    {
      "lang": "en",
      "text": "more previous thing. Um over here when",
      "offset": 2110.079,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "you what do you mean by constrained for",
      "offset": 2112.8,
      "duration": 2.72
    },
    {
      "lang": "en",
      "text": "the model? You mean you're just like",
      "offset": 2114.24,
      "duration": 2.96
    },
    {
      "lang": "en",
      "text": "forcing it to output it in a specific",
      "offset": 2115.52,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "format instead of like what it's used",
      "offset": 2117.2,
      "duration": 5.879
    },
    {
      "lang": "en",
      "text": "to? This reasoning is kind of",
      "offset": 2119.2,
      "duration": 7.52
    },
    {
      "lang": "en",
      "text": "um it's kind of like um really uh what's",
      "offset": 2123.079,
      "duration": 4.801
    },
    {
      "lang": "en",
      "text": "the word I'm looking",
      "offset": 2126.72,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "for? It's really it's not how models",
      "offset": 2127.88,
      "duration": 5.32
    },
    {
      "lang": "en",
      "text": "write. It's not like the training data",
      "offset": 2130.96,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "set is not going to have large blocks of",
      "offset": 2133.2,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "useful text in JSON objects. They're",
      "offset": 2135.119,
      "duration": 4.801
    },
    {
      "lang": "en",
      "text": "going to be in plain text before the",
      "offset": 2138,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "JSON object. Exactly. Yeah. Like now",
      "offset": 2139.92,
      "duration": 5.199
    },
    {
      "lang": "en",
      "text": "what we can do is now we can see this",
      "offset": 2143.52,
      "duration": 3.16
    },
    {
      "lang": "en",
      "text": "for",
      "offset": 2145.119,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "example where now when it's outputting",
      "offset": 2146.68,
      "duration": 4.36
    },
    {
      "lang": "en",
      "text": "the reasoning if I just can I make this",
      "offset": 2149.359,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "bigger really fast? Sorry. Yeah. Yeah. I",
      "offset": 2151.04,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "can also zoom out. Oh yeah, that's",
      "offset": 2153.52,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "great. Okay. Now if I actually look at",
      "offset": 2155.92,
      "duration": 2.88
    },
    {
      "lang": "en",
      "text": "just the difference between these two",
      "offset": 2157.599,
      "duration": 2.561
    },
    {
      "lang": "en",
      "text": "things to determine Kevin I need to",
      "offset": 2158.8,
      "duration": 2.799
    },
    {
      "lang": "en",
      "text": "perform a giraffe query that connects to",
      "offset": 2160.16,
      "duration": 3.199
    },
    {
      "lang": "en",
      "text": "reeves to the actors and movies through",
      "offset": 2161.599,
      "duration": 5.201
    },
    {
      "lang": "en",
      "text": "this and it's trying to do this but if I",
      "offset": 2163.359,
      "duration": 5.441
    },
    {
      "lang": "en",
      "text": "look over here it's actually able to",
      "offset": 2166.8,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "just output this a little bit more now",
      "offset": 2168.8,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "and it's able to go understand what uh",
      "offset": 2172.4,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "the text here is in a little bit more",
      "offset": 2174.32,
      "duration": 5.519
    },
    {
      "lang": "en",
      "text": "well and it's cool sorry what's really",
      "offset": 2177.28,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "dope about this that I'm just noticing",
      "offset": 2179.839,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "is like it's outputting the cipher and",
      "offset": 2181.2,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "then it's use and it's doing that in",
      "offset": 2183.359,
      "duration": 3.441
    },
    {
      "lang": "en",
      "text": "whatever format it wants and then it's",
      "offset": 2185.119,
      "duration": 3.761
    },
    {
      "lang": "en",
      "text": "converting that into a JSON format. So",
      "offset": 2186.8,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "it's like writing cipher in the way that",
      "offset": 2188.88,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "like most of the training set will be",
      "offset": 2190.72,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "written as as like cipher in markdown",
      "offset": 2192.72,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "explaining and then it's going to",
      "offset": 2195.2,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "put that into the actual structured",
      "offset": 2197.44,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "object. Exactly. Now you might say that",
      "offset": 2199.04,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "when you display a graph query to a user",
      "offset": 2201.44,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "you might still want to include",
      "offset": 2204,
      "duration": 3.119
    },
    {
      "lang": "en",
      "text": "reasoning because there's multiple",
      "offset": 2205.2,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "impacts of how you can leverage using",
      "offset": 2207.119,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "reasoning. One is to make the model",
      "offset": 2209.04,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "better and this technique of outputting",
      "offset": 2210.96,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "the uh reasoning in the context actually",
      "offset": 2213.04,
      "duration": 4.799
    },
    {
      "lang": "en",
      "text": "just makes the model better. Now there's",
      "offset": 2215.28,
      "duration": 4.44
    },
    {
      "lang": "en",
      "text": "another way that we might want to do",
      "offset": 2217.839,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "this which is I might want to show the",
      "offset": 2219.72,
      "duration": 4.359
    },
    {
      "lang": "en",
      "text": "user exactly what's going on behind the",
      "offset": 2222.24,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "scenes. So if I want to go do that then",
      "offset": 2224.079,
      "duration": 3.961
    },
    {
      "lang": "en",
      "text": "I can add reasoning over",
      "offset": 2226.079,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "here description and of like the like",
      "offset": 2228.04,
      "duration": 5.48
    },
    {
      "lang": "en",
      "text": "post post reason kind of thing. Exactly.",
      "offset": 2231.119,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "And what I want to hear I want to write",
      "offset": 2233.52,
      "duration": 4.68
    },
    {
      "lang": "en",
      "text": "here is like a short",
      "offset": 2234.96,
      "duration": 6.72
    },
    {
      "lang": "en",
      "text": "message to the user",
      "offset": 2238.2,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "uh",
      "offset": 2241.68,
      "duration": 6.159
    },
    {
      "lang": "en",
      "text": "summarizing the notes.",
      "offset": 2243.56,
      "duration": 7.08
    },
    {
      "lang": "en",
      "text": "So when I go run this I still get",
      "offset": 2247.839,
      "duration": 4.52
    },
    {
      "lang": "en",
      "text": "reasoning as I",
      "offset": 2250.64,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "want and then I can give the re a",
      "offset": 2252.359,
      "duration": 6.841
    },
    {
      "lang": "en",
      "text": "shorter version of the reasoning to uh",
      "offset": 2255.76,
      "duration": 5.839
    },
    {
      "lang": "en",
      "text": "the end user. So I can kind of man",
      "offset": 2259.2,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "reasoning is now becoming a thing that I",
      "offset": 2261.599,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "can choose what I'm doing with rather",
      "offset": 2263.28,
      "duration": 6.319
    },
    {
      "lang": "en",
      "text": "than a thing that I have to go do in a",
      "offset": 2266.079,
      "duration": 5.441
    },
    {
      "lang": "en",
      "text": "specific way. So I think the blend of",
      "offset": 2269.599,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "what reasoning is it's very overloaded",
      "offset": 2271.52,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "for a lot of users.",
      "offset": 2273.359,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "Go ahead. It's like the the same thing",
      "offset": 2276,
      "duration": 2.56
    },
    {
      "lang": "en",
      "text": "we did last week where it's like okay",
      "offset": 2277.359,
      "duration": 2.561
    },
    {
      "lang": "en",
      "text": "you have one version of this that goes",
      "offset": 2278.56,
      "duration": 2.72
    },
    {
      "lang": "en",
      "text": "into the embedding, one version that",
      "offset": 2279.92,
      "duration": 2.96
    },
    {
      "lang": "en",
      "text": "goes into the LM and one version that is",
      "offset": 2281.28,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "read by deterministic code and those are",
      "offset": 2282.88,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "all three different things. And so now",
      "offset": 2284.64,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "you're splitting out like what's the LM",
      "offset": 2286.56,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "reasoning versus what's a thing that's",
      "offset": 2289.04,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "valuable for me to show in the UI for",
      "offset": 2290.8,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "the user. Exactly. And the fact that we",
      "offset": 2292.56,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "happen to call it all reasoning is a",
      "offset": 2295.44,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "totally different concept. Um it's just",
      "offset": 2298,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "like we're humans are bad at naming uh",
      "offset": 2300.8,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "and we're using the same name to do two",
      "offset": 2303.28,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "different things which normally you",
      "offset": 2305.52,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "wouldn't do but you can just see how",
      "offset": 2307.52,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "much better the reasoning is now. So in",
      "offset": 2309.92,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "some effect by nature of me telling the",
      "offset": 2311.68,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "model that I actually have to go and",
      "offset": 2313.92,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "display reasoning to the user I actually",
      "offset": 2315.44,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "got a better reasoning process right",
      "offset": 2317.92,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "over here as well.",
      "offset": 2319.44,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "Hey uh could you clarify if this is the",
      "offset": 2321.92,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "same as chain of thought.",
      "offset": 2324.24,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "Uh it's it's very similar to chain of",
      "offset": 2326.48,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "thought. I think it's a little bit more",
      "offset": 2329.04,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "free form",
      "offset": 2330.64,
      "duration": 4.719
    },
    {
      "lang": "en",
      "text": "uh than chain of thought. I think um you",
      "offset": 2333.04,
      "duration": 4.799
    },
    {
      "lang": "en",
      "text": "can I think when I I think when people",
      "offset": 2335.359,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "first introduced chain of thought it was",
      "offset": 2337.839,
      "duration": 4.721
    },
    {
      "lang": "en",
      "text": "like a very structured approach to how",
      "offset": 2339.76,
      "duration": 5.359
    },
    {
      "lang": "en",
      "text": "you approach a problem. It's a subset of",
      "offset": 2342.56,
      "duration": 6.32
    },
    {
      "lang": "en",
      "text": "reasoning. Reasoning is a bigger group.",
      "offset": 2345.119,
      "duration": 6.24
    },
    {
      "lang": "en",
      "text": "Um because reasoning doesn't necessarily",
      "offset": 2348.88,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "mean like I'm going to chain of thought",
      "offset": 2351.359,
      "duration": 3.041
    },
    {
      "lang": "en",
      "text": "to me I think when the paper came out",
      "offset": 2352.64,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "implied that there's a sequence of",
      "offset": 2354.4,
      "duration": 3.16
    },
    {
      "lang": "en",
      "text": "things that I will go",
      "offset": 2355.76,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "do here. the model happened to believe",
      "offset": 2357.56,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "that a sequence made",
      "offset": 2360.16,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "sense. But if I change my test case to",
      "offset": 2361.8,
      "duration": 4.92
    },
    {
      "lang": "en",
      "text": "to something else where it's like uh",
      "offset": 2365.04,
      "duration": 2.96
    },
    {
      "lang": "en",
      "text": "what it's going to read is bacon number.",
      "offset": 2366.72,
      "duration": 2.2
    },
    {
      "lang": "en",
      "text": "It's",
      "offset": 2368,
      "duration": 5.599
    },
    {
      "lang": "en",
      "text": "like how do I make",
      "offset": 2368.92,
      "duration": 4.679
    },
    {
      "lang": "en",
      "text": "cookies and the model's actually going",
      "offset": 2376.359,
      "duration": 3.72
    },
    {
      "lang": "en",
      "text": "to reply and the answer might be like I",
      "offset": 2378.4,
      "duration": 3.4
    },
    {
      "lang": "en",
      "text": "actually don't want the model to reply",
      "offset": 2380.079,
      "duration": 5.201
    },
    {
      "lang": "en",
      "text": "here. Um I can actually inject that into",
      "offset": 2381.8,
      "duration": 7.4
    },
    {
      "lang": "en",
      "text": "the reasoning over here. Uh it's over",
      "offset": 2385.28,
      "duration": 6.92
    },
    {
      "lang": "en",
      "text": "here before entering. Know what is hard?",
      "offset": 2389.2,
      "duration": 6.44
    },
    {
      "lang": "en",
      "text": "Um know what is it",
      "offset": 2392.2,
      "duration": 8.919
    },
    {
      "lang": "en",
      "text": "hard or things that indicate the user is",
      "offset": 2395.64,
      "duration": 7.88
    },
    {
      "lang": "en",
      "text": "not",
      "offset": 2401.119,
      "duration": 2.401
    },
    {
      "lang": "en",
      "text": "using. Let me try and find my way out of",
      "offset": 2410.2,
      "duration": 6.12
    },
    {
      "lang": "en",
      "text": "this. trying to help the ether out",
      "offset": 2412.32,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "as let's add another class.",
      "offset": 2429.96,
      "duration": 6.639
    },
    {
      "lang": "en",
      "text": "Uh,",
      "offset": 2433.599,
      "duration": 3
    },
    {
      "lang": "en",
      "text": "let me get added to the return types.",
      "offset": 2444.4,
      "duration": 5.24
    },
    {
      "lang": "en",
      "text": "Yeah.",
      "offset": 2446.64,
      "duration": 3
    },
    {
      "lang": "en",
      "text": "Um, so I can go do something like this",
      "offset": 2453.359,
      "duration": 4.641
    },
    {
      "lang": "en",
      "text": "and give an action like to the user of",
      "offset": 2455.599,
      "duration": 5.041
    },
    {
      "lang": "en",
      "text": "like not relevant.",
      "offset": 2458,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "It's interesting that it didn't print",
      "offset": 2460.64,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "out all of the text though. It's just",
      "offset": 2462,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "going straight to JSON again. So I think",
      "offset": 2464,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "it's more about what the model's able to",
      "offset": 2466.4,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "do. So chain of thought is again very",
      "offset": 2468.079,
      "duration": 4.881
    },
    {
      "lang": "en",
      "text": "prescribed in what it's going to go do.",
      "offset": 2470.319,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "Yeah. Because when it does something in",
      "offset": 2472.96,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "chain of thought, you're kind of forcing",
      "offset": 2474.64,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "it to go down that line of reasoning.",
      "offset": 2476.56,
      "duration": 5.92
    },
    {
      "lang": "en",
      "text": "What I'm doing here, I specifically ask",
      "offset": 2479.68,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "the model to note what is useful and",
      "offset": 2482.48,
      "duration": 2.72
    },
    {
      "lang": "en",
      "text": "particularly hard or things that",
      "offset": 2484,
      "duration": 2.56
    },
    {
      "lang": "en",
      "text": "indicate the user is not using the",
      "offset": 2485.2,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "schema. But if the model feels that it's",
      "offset": 2486.56,
      "duration": 5.039
    },
    {
      "lang": "en",
      "text": "a very direct query, then it doesn't",
      "offset": 2488.72,
      "duration": 5.599
    },
    {
      "lang": "en",
      "text": "really have to go and go make that line.",
      "offset": 2491.599,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "It doesn't have to generate those",
      "offset": 2494.319,
      "duration": 2.401
    },
    {
      "lang": "en",
      "text": "tokens. It's easier for it to just",
      "offset": 2495.44,
      "duration": 2.879
    },
    {
      "lang": "en",
      "text": "generate the final output. And that's",
      "offset": 2496.72,
      "duration": 2.879
    },
    {
      "lang": "en",
      "text": "where I think reasoning is a slightly",
      "offset": 2498.319,
      "duration": 2.881
    },
    {
      "lang": "en",
      "text": "bigger superset of chain of thought.",
      "offset": 2499.599,
      "duration": 3.281
    },
    {
      "lang": "en",
      "text": "Chain of thought is almost prescriptive.",
      "offset": 2501.2,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "If it doesn't do chain of thought, that",
      "offset": 2502.88,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "is bad because I added a chain of",
      "offset": 2504.24,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "thought prompt. Reasoning, I think, was",
      "offset": 2506,
      "duration": 3.599
    },
    {
      "lang": "en",
      "text": "invented with this premise. And that's",
      "offset": 2508.24,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "what I think Openi did really amazingly.",
      "offset": 2509.599,
      "duration": 5.041
    },
    {
      "lang": "en",
      "text": "this premise of elasticity on how much",
      "offset": 2511.76,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "reasoning I'm allowed to do, how much",
      "offset": 2514.64,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "reasoning I don't want to do. And in",
      "offset": 2516.079,
      "duration": 4.561
    },
    {
      "lang": "en",
      "text": "this case, the model is choosing none.",
      "offset": 2517.76,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "And in the chain of thought world, it's",
      "offset": 2520.64,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "almost going to have to it it almost has",
      "offset": 2522.88,
      "duration": 4.959
    },
    {
      "lang": "en",
      "text": "to do chain of thought. Does that answer",
      "offset": 2525.44,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "the question about the nuance there,",
      "offset": 2527.839,
      "duration": 2.561
    },
    {
      "lang": "en",
      "text": "Pashant? But I think they're very very",
      "offset": 2529.04,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "similar.",
      "offset": 2530.4,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "Yeah. Uh I think it does. I mean, I'm",
      "offset": 2533.119,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "still trying to wrap my head around like",
      "offset": 2535.44,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "the model choice here. So if you had an",
      "offset": 2537.119,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "actual reasoning model, it treats the",
      "offset": 2540.56,
      "duration": 3.039
    },
    {
      "lang": "en",
      "text": "prompt completely differently. So you're",
      "offset": 2542.319,
      "duration": 2.561
    },
    {
      "lang": "en",
      "text": "not talking about that form of reasoning",
      "offset": 2543.599,
      "duration": 2.801
    },
    {
      "lang": "en",
      "text": "here. This this reasoning here is purely",
      "offset": 2544.88,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "related to the model's internal thinking",
      "offset": 2546.4,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "process. Exactly. And if you go back to",
      "offset": 2548.56,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "the other thing that's the you want to",
      "offset": 2550.72,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "go back to the UI. No, no, not the UI,",
      "offset": 2553.92,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "the Excalibur.",
      "offset": 2556.24,
      "duration": 7.28
    },
    {
      "lang": "en",
      "text": "Yeah. Yeah. So in the reasoning model",
      "offset": 2558.64,
      "duration": 6.88
    },
    {
      "lang": "en",
      "text": "what ends up happening is a model that's",
      "offset": 2563.52,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "fine-tuned with reasoning is forced to",
      "offset": 2565.52,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "generate a reasoning start token. So it",
      "offset": 2568.24,
      "duration": 5.16
    },
    {
      "lang": "en",
      "text": "has to out it has to do reasoning to",
      "offset": 2570.16,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "text and now after it does the reasoning",
      "offset": 2573.4,
      "duration": 4.12
    },
    {
      "lang": "en",
      "text": "text then only eventually it'll output",
      "offset": 2575.92,
      "duration": 3.199
    },
    {
      "lang": "en",
      "text": "the reasoning end token then it can",
      "offset": 2577.52,
      "duration": 2.88
    },
    {
      "lang": "en",
      "text": "generate the regular text that I need",
      "offset": 2579.119,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "for the actual u",
      "offset": 2580.4,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "response. But in a chain of thought",
      "offset": 2584.44,
      "duration": 4.36
    },
    {
      "lang": "en",
      "text": "world there's no such thing as reasoning",
      "offset": 2587.04,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "text and reasoning end. But I I almost",
      "offset": 2588.8,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "am chain of thought is more like this.",
      "offset": 2590.96,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "If the model doesn't generate thinking",
      "offset": 2593.44,
      "duration": 4.36
    },
    {
      "lang": "en",
      "text": "text as a part of its response, it is",
      "offset": 2595.44,
      "duration": 3.96
    },
    {
      "lang": "en",
      "text": "bad.",
      "offset": 2597.8,
      "duration": 3.48
    },
    {
      "lang": "en",
      "text": "Reasoning all right because it doesn't",
      "offset": 2599.4,
      "duration": 3.56
    },
    {
      "lang": "en",
      "text": "abide by my instructions of what I told",
      "offset": 2601.28,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "it to do. Reasoning is a little bit I",
      "offset": 2602.96,
      "duration": 4.28
    },
    {
      "lang": "en",
      "text": "think the whole goal of reasoning is",
      "offset": 2605.2,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "elasticity. So the amount of tokens that",
      "offset": 2607.24,
      "duration": 3.8
    },
    {
      "lang": "en",
      "text": "the model generates in here could be",
      "offset": 2609.52,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "zero, it could be 500, it could be a",
      "offset": 2611.04,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "thousand. And that's why OpenAI even",
      "offset": 2612.88,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "gives you a choice of how many reasoning",
      "offset": 2614.88,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "tokens you're allowed to generate,",
      "offset": 2616.96,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "right? How hard do you want it to think?",
      "offset": 2618.48,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "Right. Well, how hard do you want it to",
      "offset": 2620.16,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "think is one concept, but it's really",
      "offset": 2622.8,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "around like how many tokens are you",
      "offset": 2624.16,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "allowed to generate in this block? Yep.",
      "offset": 2626.4,
      "duration": 5.199
    },
    {
      "lang": "en",
      "text": "Right. Um, and that's kind of associated",
      "offset": 2629.28,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "with thinking, but think about what that",
      "offset": 2631.599,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "does to the model. It actually it could",
      "offset": 2633.04,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "technically terminate",
      "offset": 2635.599,
      "duration": 2.881
    },
    {
      "lang": "en",
      "text": "midthought because open is saying that",
      "offset": 2639.079,
      "duration": 3.481
    },
    {
      "lang": "en",
      "text": "there's no more tokens that you can",
      "offset": 2641.44,
      "duration": 2.24
    },
    {
      "lang": "en",
      "text": "generate after this because they can't",
      "offset": 2642.56,
      "duration": 2.48
    },
    {
      "lang": "en",
      "text": "predict the future tokens. They can only",
      "offset": 2643.68,
      "duration": 2.88
    },
    {
      "lang": "en",
      "text": "generate tokens up until now. It's kind",
      "offset": 2645.04,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "of like the conraint constraint",
      "offset": 2646.56,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "generation thing, right? When you force",
      "offset": 2648.16,
      "duration": 3.439
    },
    {
      "lang": "en",
      "text": "the model to only generate tokens that",
      "offset": 2649.68,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "are valid JSON, you kind of you kind of",
      "offset": 2651.599,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "screw up with it trying to write like",
      "offset": 2653.92,
      "duration": 3.679
    },
    {
      "lang": "en",
      "text": "whatever like in the way that it's been",
      "offset": 2655.839,
      "duration": 4.801
    },
    {
      "lang": "en",
      "text": "trained to write things. Yeah. But the",
      "offset": 2657.599,
      "duration": 5.681
    },
    {
      "lang": "en",
      "text": "only caveat here is that the tokens here",
      "offset": 2660.64,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "that it generates in the reasoning text",
      "offset": 2663.28,
      "duration": 3.64
    },
    {
      "lang": "en",
      "text": "could have a huge",
      "offset": 2665.28,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "impact if I were them. Uh you could have",
      "offset": 2666.92,
      "duration": 4.439
    },
    {
      "lang": "en",
      "text": "a huge impact in how these next tokens",
      "offset": 2669.44,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "are generated in a little bit more",
      "offset": 2671.359,
      "duration": 3.201
    },
    {
      "lang": "en",
      "text": "nuanced way than it would normally be",
      "offset": 2672.72,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "generated. So if you if you're doing",
      "offset": 2674.56,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "this, there's no special things that",
      "offset": 2676.96,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "things in the thinking tag are getting.",
      "offset": 2678.8,
      "duration": 4.2
    },
    {
      "lang": "en",
      "text": "It's giving no special",
      "offset": 2680.72,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "weight. But you could imagine that in",
      "offset": 2683,
      "duration": 4.44
    },
    {
      "lang": "en",
      "text": "the training loop, the model has learned",
      "offset": 2685.2,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "that things between the reasoning block",
      "offset": 2687.44,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "are actually extra useful. So there's",
      "offset": 2689.92,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "one advantage to thinking models that",
      "offset": 2692.56,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "can't really be replicated with any",
      "offset": 2694.56,
      "duration": 5.279
    },
    {
      "lang": "en",
      "text": "prompt engineering technique.",
      "offset": 2697.04,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "Now the problem with thinking models is",
      "offset": 2699.839,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "you will they cost a lot more because",
      "offset": 2702.48,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "fundamentally you are asking the model",
      "offset": 2705.599,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "to generate special tokens in here that",
      "offset": 2707.28,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "are just going to be a lot more tokens",
      "offset": 2709.2,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "right it's just what this whole thing",
      "offset": 2711.599,
      "duration": 3.281
    },
    {
      "lang": "en",
      "text": "about like inference time test time",
      "offset": 2713.119,
      "duration": 3.441
    },
    {
      "lang": "en",
      "text": "compute is just like oh if the model",
      "offset": 2714.88,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "generates more tokens before it actually",
      "offset": 2716.56,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "puts its answer in you get a better",
      "offset": 2718.4,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "answer uh and so people realize like oh",
      "offset": 2720.56,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "we don't need way smarter models we just",
      "offset": 2722.96,
      "duration": 3.359
    },
    {
      "lang": "en",
      "text": "need them to generate more tokens before",
      "offset": 2724.8,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "they answer and so now it's like okay",
      "offset": 2726.319,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "cool So we need more GPUs and we need",
      "offset": 2728.56,
      "duration": 3.279
    },
    {
      "lang": "en",
      "text": "more inference and we need more compute.",
      "offset": 2730.16,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "Exactly. And the real thought process if",
      "offset": 2731.839,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "you go back to our to our other thing",
      "offset": 2733.76,
      "duration": 5.839
    },
    {
      "lang": "en",
      "text": "the code the code. Yeah. The real",
      "offset": 2737.359,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "thought process that I'm really having",
      "offset": 2739.599,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "when I make these decisions of do I just",
      "offset": 2741.44,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "swap out for a reasoning model or not?",
      "offset": 2743.119,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "It comes along the lines of the",
      "offset": 2745.359,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "following. when I decide to go use this",
      "offset": 2746.72,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "thing and swap out a reason model, what",
      "offset": 2749.359,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "I'm really saying is I want to spend",
      "offset": 2751.52,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "less time on this prompt side of it and",
      "offset": 2753.2,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "I wanted to mostly just work out of the",
      "offset": 2756.48,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "box. So, I today am willing to spend",
      "offset": 2758.24,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "more money. So, I spend less time",
      "offset": 2760.48,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "prompting and the model spends more time",
      "offset": 2762.8,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "prompting. It's a monthly equation and a",
      "offset": 2764.72,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "time equation. I want to spend less time",
      "offset": 2767.44,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "and and I want to spend more money in",
      "offset": 2770,
      "duration": 3.599
    },
    {
      "lang": "en",
      "text": "favor of time to get a better slightly",
      "offset": 2771.68,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "better response. Now, you go ahead. Go",
      "offset": 2773.599,
      "duration": 4.881
    },
    {
      "lang": "en",
      "text": "ahead. I we we have 10 minutes left and",
      "offset": 2776.56,
      "duration": 3.759
    },
    {
      "lang": "en",
      "text": "I wanted to kind of propose just like um",
      "offset": 2778.48,
      "duration": 3.599
    },
    {
      "lang": "en",
      "text": "a couple interesting things I' I'd be",
      "offset": 2780.319,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "interested to mess with um in the time",
      "offset": 2782.079,
      "duration": 6.561
    },
    {
      "lang": "en",
      "text": "we have left. Cool. Uh go for it. Um so",
      "offset": 2784.319,
      "duration": 6.961
    },
    {
      "lang": "en",
      "text": "I have you seen debate prompting? Have",
      "offset": 2788.64,
      "duration": 5.199
    },
    {
      "lang": "en",
      "text": "you seen this paper? Yes. Yes. Yeah. I",
      "offset": 2791.28,
      "duration": 4.799
    },
    {
      "lang": "en",
      "text": "was interested to see like hey if we if",
      "offset": 2793.839,
      "duration": 4.961
    },
    {
      "lang": "en",
      "text": "we kind of take out um how do I get this",
      "offset": 2796.079,
      "duration": 5.681
    },
    {
      "lang": "en",
      "text": "stupid annotation thing off? So like",
      "offset": 2798.8,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "Yeah. Okay. So, if we change this back",
      "offset": 2801.76,
      "duration": 7.359
    },
    {
      "lang": "en",
      "text": "to like, you know, which actors have a",
      "offset": 2804.4,
      "duration": 5.959
    },
    {
      "lang": "en",
      "text": "Kevin",
      "offset": 2809.119,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "Bacon number of five, which was the",
      "offset": 2810.359,
      "duration": 4.041
    },
    {
      "lang": "en",
      "text": "thing that like the model just like",
      "offset": 2813.2,
      "duration": 3.32
    },
    {
      "lang": "en",
      "text": "completely like floundered on the last",
      "offset": 2814.4,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "time. Um, and can we put in some debate",
      "offset": 2816.52,
      "duration": 7.88
    },
    {
      "lang": "en",
      "text": "prompting where it's like we ask it like",
      "offset": 2820,
      "duration": 6.119
    },
    {
      "lang": "en",
      "text": "initial",
      "offset": 2824.4,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "reasoning problems with initial",
      "offset": 2826.119,
      "duration": 6.281
    },
    {
      "lang": "en",
      "text": "reasoning?",
      "offset": 2829.92,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "Um, you know, well, we could we could do",
      "offset": 2832.4,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "this in the main prompt. We don't even",
      "offset": 2834.96,
      "duration": 4.2
    },
    {
      "lang": "en",
      "text": "have to do this in the structure.",
      "offset": 2836.24,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "Um, okay. Let's try this and then we'll",
      "offset": 2839.16,
      "duration": 5.159
    },
    {
      "lang": "en",
      "text": "we'll put in the main prompt as well.",
      "offset": 2841.44,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "Um, or you want to do that? Yeah. Yeah,",
      "offset": 2844.319,
      "duration": 3.201
    },
    {
      "lang": "en",
      "text": "let's play the main. It'll probably work",
      "offset": 2846,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "out a little better. Okay, cool. So this",
      "offset": 2847.52,
      "duration": 5.799
    },
    {
      "lang": "en",
      "text": "is like initial",
      "offset": 2850,
      "duration": 5.72
    },
    {
      "lang": "en",
      "text": "reasoning, problems with initial",
      "offset": 2853.319,
      "duration": 6.28
    },
    {
      "lang": "en",
      "text": "reasoning, improved reasoning,",
      "offset": 2855.72,
      "duration": 5.359
    },
    {
      "lang": "en",
      "text": "uh final",
      "offset": 2859.599,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "reasoning, and then the schema. Right?",
      "offset": 2861.079,
      "duration": 4.04
    },
    {
      "lang": "en",
      "text": "So now there's a do you want to put this",
      "offset": 2863.44,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "down here or do you want to leave it",
      "offset": 2865.119,
      "duration": 2.801
    },
    {
      "lang": "en",
      "text": "like that? That's fine. That's fine.",
      "offset": 2866.56,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "That's good. That's good. Okay. So",
      "offset": 2867.92,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "there's a actually you can run this and",
      "offset": 2870.4,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "I'll tell you a couple things that h",
      "offset": 2872,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "happen off the bat. So Okay. So the",
      "offset": 2873.44,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "first thing that you'll notice is you're",
      "offset": 2876.319,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "you're getting very short reasoning",
      "offset": 2878.24,
      "duration": 4.879
    },
    {
      "lang": "en",
      "text": "responses. Yeah. So and the reason for",
      "offset": 2880.079,
      "duration": 6.24
    },
    {
      "lang": "en",
      "text": "that is because",
      "offset": 2883.119,
      "duration": 5.521
    },
    {
      "lang": "en",
      "text": "because we put it on bulleted list. It's",
      "offset": 2886.319,
      "duration": 5.121
    },
    {
      "lang": "en",
      "text": "because No, no, no. It's because How do",
      "offset": 2888.64,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "I type? Can I Can you give me the typing",
      "offset": 2891.44,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "thingy? Oh yeah, there's a way to turn",
      "offset": 2893.28,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "off Vim mode. Hold on. Does anyone",
      "offset": 2895.2,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "remember which one it is? It's okay.",
      "offset": 2896.8,
      "duration": 3.039
    },
    {
      "lang": "en",
      "text": "Just give me normal VI mode. I just need",
      "offset": 2898.4,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "typing. Uh I I type like a plug. Yeah,",
      "offset": 2899.839,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "that's fine.",
      "offset": 2902.88,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "You have you have other uh you have",
      "offset": 2904.079,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "other you want to put this in like a",
      "offset": 2905.92,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "markdown header just just by nature",
      "offset": 2907.839,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "putting it in",
      "offset": 2910.079,
      "duration": 6.121
    },
    {
      "lang": "en",
      "text": "um putting into here. Yeah. Make a huge",
      "offset": 2912.079,
      "duration": 8.201
    },
    {
      "lang": "en",
      "text": "difference in how things do",
      "offset": 2916.2,
      "duration": 7.08
    },
    {
      "lang": "en",
      "text": "and we can even do something like we can",
      "offset": 2920.28,
      "duration": 4.12
    },
    {
      "lang": "en",
      "text": "even tell it it's like I want to",
      "offset": 2923.28,
      "duration": 3.279
    },
    {
      "lang": "en",
      "text": "generate a cipher. Oh yeah. I was going",
      "offset": 2924.4,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "that was the next thing I was going to",
      "offset": 2926.559,
      "duration": 2.56
    },
    {
      "lang": "en",
      "text": "suggest is like you know one of these",
      "offset": 2927.52,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "headers is like propose cipher cipher",
      "offset": 2929.119,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "query and then problems with query and",
      "offset": 2931.44,
      "duration": 3.32
    },
    {
      "lang": "en",
      "text": "then",
      "offset": 2933.44,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "and",
      "offset": 2934.76,
      "duration": 3
    },
    {
      "lang": "en",
      "text": "exactly and now we can actually go do it",
      "offset": 2938.44,
      "duration": 4.36
    },
    {
      "lang": "en",
      "text": "like over here and we can actually kind",
      "offset": 2941.119,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "of guide the model and the kind of",
      "offset": 2942.8,
      "duration": 3.279
    },
    {
      "lang": "en",
      "text": "reason that we wanted to do and again",
      "offset": 2944.319,
      "duration": 4.481
    },
    {
      "lang": "en",
      "text": "it's more about like",
      "offset": 2946.079,
      "duration": 4.721
    },
    {
      "lang": "en",
      "text": "it's more about how we're guiding the",
      "offset": 2948.8,
      "duration": 4.799
    },
    {
      "lang": "en",
      "text": "model really more than anything else and",
      "offset": 2950.8,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "it turns out if I know what kind of",
      "offset": 2953.599,
      "duration": 3.441
    },
    {
      "lang": "en",
      "text": "approach I'm building and I'm not",
      "offset": 2955.68,
      "duration": 3.72
    },
    {
      "lang": "en",
      "text": "actually building like",
      "offset": 2957.04,
      "duration": 6.559
    },
    {
      "lang": "en",
      "text": "um if I'm not actually building a uh",
      "offset": 2959.4,
      "duration": 6.52
    },
    {
      "lang": "en",
      "text": "sorry if I'm not building an an",
      "offset": 2963.599,
      "duration": 4.561
    },
    {
      "lang": "en",
      "text": "everything chatbot like open AI and I",
      "offset": 2965.92,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "know building specifically a thing that",
      "offset": 2968.16,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "talks about cipher queries and uh rag",
      "offset": 2969.92,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "pipeline cypher queries on like a graph",
      "offset": 2972.64,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "database then I'm actually able to guide",
      "offset": 2975.44,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "the structure of my technique a lot more",
      "offset": 2978,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "if I don't know this then I want to go",
      "offset": 2980.24,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "fall back to a more free form approach",
      "offset": 2982.4,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "or like you know you have a router at",
      "offset": 2984.88,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "the top that is like oh is this about",
      "offset": 2986.64,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "Neo forj movies and then route it to",
      "offset": 2988.48,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "this prompt to handle that. Exactly.",
      "offset": 2990.64,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "Yes, you can do it that way as well. So",
      "offset": 2992.88,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "kind of build our reliability up over",
      "offset": 2995.76,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "time but it's all a trade-off on this",
      "offset": 2997.68,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "elasticity thing that I was talking",
      "offset": 2999.92,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "about which is like look at the very",
      "offset": 3002.88,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "beginning I can have one prompt that I",
      "offset": 3004.96,
      "duration": 3.599
    },
    {
      "lang": "en",
      "text": "just throw at a mega model and it has to",
      "offset": 3006.72,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "do everything and go figure it out. The",
      "offset": 3008.559,
      "duration": 3.441
    },
    {
      "lang": "en",
      "text": "problem with this onep prompt approach",
      "offset": 3010.48,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "that I go right where I use and oh can",
      "offset": 3012,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "you you I can just do it on the black",
      "offset": 3014.24,
      "duration": 3.599
    },
    {
      "lang": "en",
      "text": "screen it's fine. Okay. The problem with",
      "offset": 3015.68,
      "duration": 3.679
    },
    {
      "lang": "en",
      "text": "this one prompt approach that I will",
      "offset": 3017.839,
      "duration": 3.201
    },
    {
      "lang": "en",
      "text": "often end up with is that my",
      "offset": 3019.359,
      "duration": 2.96
    },
    {
      "lang": "en",
      "text": "distribution will end up looking",
      "offset": 3021.04,
      "duration": 2.88
    },
    {
      "lang": "en",
      "text": "something like this. It's a very like",
      "offset": 3022.319,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "it's a very like normal distribution",
      "offset": 3023.92,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "that's very quite spread out. I get a",
      "offset": 3026.48,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "lot of variation in my responses. Now,",
      "offset": 3028,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "what Dex just suggested was I could have",
      "offset": 3031.04,
      "duration": 5.039
    },
    {
      "lang": "en",
      "text": "a route where I build a specific prompt",
      "offset": 3032.96,
      "duration": 5.399
    },
    {
      "lang": "en",
      "text": "that is really really good at cipher",
      "offset": 3036.079,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "queries and another it's going to be",
      "offset": 3038.359,
      "duration": 4.841
    },
    {
      "lang": "en",
      "text": "trash at making cookie recipes though.",
      "offset": 3040.4,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "Yeah, it's going to be trash at making",
      "offset": 3043.2,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "cookie. Exactly. Um, where I could go",
      "offset": 3044.319,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "ahead and like say something that this",
      "offset": 3046.72,
      "duration": 5.639
    },
    {
      "lang": "en",
      "text": "is like about like an intent",
      "offset": 3047.92,
      "duration": 10.12
    },
    {
      "lang": "en",
      "text": "router and then oops uh cipher",
      "offset": 3052.359,
      "duration": 8.041
    },
    {
      "lang": "en",
      "text": "prompt and then I can have I can still",
      "offset": 3058.04,
      "duration": 5.48
    },
    {
      "lang": "en",
      "text": "do my my everything prompt over here.",
      "offset": 3060.4,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "Yeah. Everything else. Right. Exactly.",
      "offset": 3063.52,
      "duration": 4.559
    },
    {
      "lang": "en",
      "text": "So now what what ends up happening Oh my",
      "offset": 3065.92,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "god, this so hard. What ends up",
      "offset": 3068.079,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "happening is my distribution for these",
      "offset": 3070.16,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "prompts will get slightly better. This",
      "offset": 3071.76,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "prompt should technically have a pretty",
      "offset": 3073.76,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "high distribution with low spread where",
      "offset": 3075.28,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "I can accurately get their intent",
      "offset": 3078.8,
      "duration": 4.559
    },
    {
      "lang": "en",
      "text": "classification. Yep. And then what I aim",
      "offset": 3080.64,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "for is I want this prompt to have a",
      "offset": 3083.359,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "really really high distribution on",
      "offset": 3085.28,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "cipher queries and kind of perform worse",
      "offset": 3087.04,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "on everything else at the benefit of",
      "offset": 3088.64,
      "duration": 4.959
    },
    {
      "lang": "en",
      "text": "outperforming on cipher queries. And",
      "offset": 3090.96,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "then I can actually have another one",
      "offset": 3093.599,
      "duration": 4.881
    },
    {
      "lang": "en",
      "text": "that says that it's going to work again.",
      "offset": 3096.16,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "It's going to have a high it's going to",
      "offset": 3098.48,
      "duration": 2.879
    },
    {
      "lang": "en",
      "text": "have a high spread and low accuracy on",
      "offset": 3099.68,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "everything else. I can slowly compose",
      "offset": 3101.359,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "these systems together to build a",
      "offset": 3103.52,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "slightly more accurate system. And this",
      "offset": 3105.76,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "is where I can still throw a reasoning",
      "offset": 3107.839,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "model at this part of my pipeline, but",
      "offset": 3109.52,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "have more specific reasoning on this",
      "offset": 3111.44,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "side of my pipeline. So I can slowly",
      "offset": 3113.599,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "build the system that I actually want to",
      "offset": 3115.839,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "build with more guidance along the way.",
      "offset": 3117.52,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "So it's the blend of the two. And what's",
      "offset": 3120.079,
      "duration": 4.641
    },
    {
      "lang": "en",
      "text": "amazing about this technique is there's",
      "offset": 3122.8,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "nothing here that actually says I can't",
      "offset": 3124.72,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "actually do this with 03 mini. Like I",
      "offset": 3126,
      "duration": 5.92
    },
    {
      "lang": "en",
      "text": "can kind of blend. I can let a reasoning",
      "offset": 3130.4,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "model do its thing and on top of that I",
      "offset": 3131.92,
      "duration": 6.08
    },
    {
      "lang": "en",
      "text": "can also leverage non the non-reasoning",
      "offset": 3134.64,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "approach to go ahead and think about",
      "offset": 3138,
      "duration": 3.599
    },
    {
      "lang": "en",
      "text": "this as well and once it's done it will",
      "offset": 3139.52,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "go do it. I wish we thinking tokens. We",
      "offset": 3141.599,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "really should.",
      "offset": 3143.839,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "Um yes I would like that too if you'll",
      "offset": 3145.599,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "spit out the thinking tokens. Yeah, if",
      "offset": 3148.16,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "you do the curl, you can see both. And",
      "offset": 3150,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "thinking tokens come, it's so crazy",
      "offset": 3151.68,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "because like the thinking tokens just",
      "offset": 3153.92,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "get spewed out raw and then it spits out",
      "offset": 3155.68,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "JSON at the end, which is actually kind",
      "offset": 3157.92,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "of bambly when you think about it. Yeah.",
      "offset": 3160,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "Um I want to try one more thing um in",
      "offset": 3162.079,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "the five minutes we have left on the",
      "offset": 3164.88,
      "duration": 3.679
    },
    {
      "lang": "en",
      "text": "clock and then we can um hold for time",
      "offset": 3166.4,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "for questions at the end. Does that",
      "offset": 3168.559,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "work? Let's do it. Um I want to take",
      "offset": 3170.16,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "these three things and uh put them in",
      "offset": 3172.4,
      "duration": 5.919
    },
    {
      "lang": "en",
      "text": "the response.",
      "offset": 3175.76,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "um do it.",
      "offset": 3178.319,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "So, and then I want to spit them out to",
      "offset": 3180.96,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "the user in the UI because like this",
      "offset": 3182.559,
      "duration": 4.721
    },
    {
      "lang": "en",
      "text": "becomes kind of a magical kind of AI app",
      "offset": 3184.8,
      "duration": 4.68
    },
    {
      "lang": "en",
      "text": "building experience as",
      "offset": 3187.28,
      "duration": 7.4
    },
    {
      "lang": "en",
      "text": "well. Um so,",
      "offset": 3189.48,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "uh and just be like a short summary of",
      "offset": 3197.44,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "initial message, a shorter a short",
      "offset": 3199.52,
      "duration": 6.68
    },
    {
      "lang": "en",
      "text": "summary to display to the user.",
      "offset": 3201.52,
      "duration": 4.68
    },
    {
      "lang": "en",
      "text": "Yeah, it's specific that we want to talk",
      "offset": 3206.64,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "about displaying to the user because we",
      "offset": 3208.079,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "don't want to bias the actual generation",
      "offset": 3209.92,
      "duration": 4.6
    },
    {
      "lang": "en",
      "text": "token that's going to go generate.",
      "offset": 3211.92,
      "duration": 6.639
    },
    {
      "lang": "en",
      "text": "Um, cool. Um, sick. And then in our",
      "offset": 3214.52,
      "duration": 6.12
    },
    {
      "lang": "en",
      "text": "actual server code, like the fact that",
      "offset": 3218.559,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "we have kind of built this agent at",
      "offset": 3220.64,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "hawk, we can do some really interesting",
      "offset": 3222.24,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "things and like kind of take the outputs",
      "offset": 3224.72,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "of our fancy prompting and throw it",
      "offset": 3227.04,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "through everything else. Um, I added",
      "offset": 3229.44,
      "duration": 4.639
    },
    {
      "lang": "en",
      "text": "another one which is called not",
      "offset": 3232.48,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "relevant. Can you delete that? That's",
      "offset": 3234.079,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "why this uh Oh, yeah. Yeah. Yeah. Yeah.",
      "offset": 3236.16,
      "duration": 5.84
    },
    {
      "lang": "en",
      "text": "Um on line 39. Yeah. We'll just get rid",
      "offset": 3239.119,
      "duration": 5.081
    },
    {
      "lang": "en",
      "text": "of this.",
      "offset": 3242,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "Yep. Chat doesn't work. That's why.",
      "offset": 3244.2,
      "duration": 6.68
    },
    {
      "lang": "en",
      "text": "Yeah. Um I love that JavaScript. I'm",
      "offset": 3246.96,
      "duration": 7.56
    },
    {
      "lang": "en",
      "text": "actually going to",
      "offset": 3250.88,
      "duration": 3.64
    },
    {
      "lang": "en",
      "text": "um cool. and then completion the send a",
      "offset": 3260.359,
      "duration": 9.361
    },
    {
      "lang": "en",
      "text": "reasoning event. Yeah.",
      "offset": 3264.72,
      "duration": 5
    },
    {
      "lang": "en",
      "text": "And then on the front end we can",
      "offset": 3271.599,
      "duration": 5.681
    },
    {
      "lang": "en",
      "text": "actually try to display this",
      "offset": 3273.28,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "um ah where is our app app.ts page app.",
      "offset": 3277.4,
      "duration": 9.76
    },
    {
      "lang": "en",
      "text": "Yeah components. Here we go. Um,",
      "offset": 3281.839,
      "duration": 5.321
    },
    {
      "lang": "en",
      "text": "nice. This is going to be a little bit",
      "offset": 3299.04,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "janky, but let's see. Let's see how this",
      "offset": 3300.559,
      "duration": 4.04
    },
    {
      "lang": "en",
      "text": "looks.",
      "offset": 3302.48,
      "duration": 5.119
    },
    {
      "lang": "en",
      "text": "Um, or this is live coding. I've never",
      "offset": 3304.599,
      "duration": 4.281
    },
    {
      "lang": "en",
      "text": "tried this before. Oh, you're on 03",
      "offset": 3307.599,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "Mini. Can you get Oh, whatever. Uh,",
      "offset": 3308.88,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "sure. Love the GT40 mini so it's faster.",
      "offset": 3311.119,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "Yeah, let's go to 40 mini. I don't have",
      "offset": 3313.44,
      "duration": 2.8
    },
    {
      "lang": "en",
      "text": "time. No, we don't have time for that",
      "offset": 3315.04,
      "duration": 3.06
    },
    {
      "lang": "en",
      "text": "crap. Yeah.",
      "offset": 3316.24,
      "duration": 3.319
    },
    {
      "lang": "en",
      "text": "[Music]",
      "offset": 3318.1,
      "duration": 4.18
    },
    {
      "lang": "en",
      "text": "Um, let's go",
      "offset": 3319.559,
      "duration": 6.04
    },
    {
      "lang": "en",
      "text": "here. Let's",
      "offset": 3322.28,
      "duration": 3.319
    },
    {
      "lang": "en",
      "text": "go. Cool. Um,",
      "offset": 3326.599,
      "duration": 4.641
    },
    {
      "lang": "en",
      "text": "um, do a simple one and then we'll do a",
      "offset": 3334.88,
      "duration": 5.719
    },
    {
      "lang": "en",
      "text": "really hard one. Yeah.",
      "offset": 3336.72,
      "duration": 3.879
    },
    {
      "lang": "en",
      "text": "It didn't show our",
      "offset": 3341.52,
      "duration": 5.559
    },
    {
      "lang": "en",
      "text": "reasoning. This is the fun part of live",
      "offset": 3343.96,
      "duration": 4.639
    },
    {
      "lang": "en",
      "text": "coding.",
      "offset": 3347.079,
      "duration": 4.52
    },
    {
      "lang": "en",
      "text": "Um, did you see what's going on there?",
      "offset": 3348.599,
      "duration": 4.601
    },
    {
      "lang": "en",
      "text": "Um, you might have to restart the app.",
      "offset": 3351.599,
      "duration": 5.641
    },
    {
      "lang": "en",
      "text": "Just restart the app really fast.",
      "offset": 3353.2,
      "duration": 4.04
    },
    {
      "lang": "en",
      "text": "Also, this is just absolutely wrong. Um,",
      "offset": 3359.359,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "okay.",
      "offset": 3361.76,
      "duration": 5.319
    },
    {
      "lang": "en",
      "text": "How many movies is",
      "offset": 3363.76,
      "duration": 6.4
    },
    {
      "lang": "en",
      "text": "uh Patrick sees and we'll start with a",
      "offset": 3367.079,
      "duration": 6.401
    },
    {
      "lang": "en",
      "text": "simple one.",
      "offset": 3370.16,
      "duration": 3.32
    },
    {
      "lang": "en",
      "text": "Um do you render the reasoning object?",
      "offset": 3376.559,
      "duration": 9.121
    },
    {
      "lang": "en",
      "text": "Uh I think we're trying to. Let's see.",
      "offset": 3381.16,
      "duration": 6.52
    },
    {
      "lang": "en",
      "text": "It's also not getting added to the",
      "offset": 3385.68,
      "duration": 6.28
    },
    {
      "lang": "en",
      "text": "messages stream here.",
      "offset": 3387.68,
      "duration": 4.28
    },
    {
      "lang": "en",
      "text": "Okay. Um, you should just see on the",
      "offset": 3392,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "back end as you're setting it",
      "offset": 3393.76,
      "duration": 2.96
    },
    {
      "lang": "en",
      "text": "up. Okay, so this definitely came",
      "offset": 3406.92,
      "duration": 6.76
    },
    {
      "lang": "en",
      "text": "out.",
      "offset": 3410.68,
      "duration": 3
    },
    {
      "lang": "en",
      "text": "Um, we we'll time box this to like two",
      "offset": 3416.52,
      "duration": 3.799
    },
    {
      "lang": "en",
      "text": "more minutes. If we can't get it",
      "offset": 3419.119,
      "duration": 2.72
    },
    {
      "lang": "en",
      "text": "working, we'll we'll flip to questions",
      "offset": 3420.319,
      "duration": 2.961
    },
    {
      "lang": "en",
      "text": "or people want to start asking",
      "offset": 3421.839,
      "duration": 2.641
    },
    {
      "lang": "en",
      "text": "answering. Well, let's see if we can get",
      "offset": 3423.28,
      "duration": 4.36
    },
    {
      "lang": "en",
      "text": "this working.",
      "offset": 3424.48,
      "duration": 3.16
    },
    {
      "lang": "en",
      "text": "You go to send events.",
      "offset": 3427.92,
      "duration": 3.56
    },
    {
      "lang": "en",
      "text": "No, this one is working. And then what's",
      "offset": 3432.24,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "the event name that you sent it as? Uh",
      "offset": 3434.079,
      "duration": 5.121
    },
    {
      "lang": "en",
      "text": "reasoning.",
      "offset": 3437.68,
      "duration": 2.72
    },
    {
      "lang": "en",
      "text": "Yeah. And then just double check that",
      "offset": 3439.2,
      "duration": 2.919
    },
    {
      "lang": "en",
      "text": "you're actually receiving it as that",
      "offset": 3440.4,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "event in your thing.",
      "offset": 3442.119,
      "duration": 4.041
    },
    {
      "lang": "en",
      "text": "So event reasoning event graph query.",
      "offset": 3467.4,
      "duration": 4.76
    },
    {
      "lang": "en",
      "text": "Okay, so we did get a reasoning event.",
      "offset": 3470.319,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "It's just like a UI bug. Yeah. Oh, see",
      "offset": 3472.16,
      "duration": 4.36
    },
    {
      "lang": "en",
      "text": "Reasoning",
      "offset": 3475.119,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "message. Um,",
      "offset": 3476.52,
      "duration": 5.96
    },
    {
      "lang": "en",
      "text": "oh, you have to set messages.",
      "offset": 3479.119,
      "duration": 5.041
    },
    {
      "lang": "en",
      "text": "Go up to the top and you just miss one",
      "offset": 3482.48,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "line after that. After reasoning",
      "offset": 3484.16,
      "duration": 4.12
    },
    {
      "lang": "en",
      "text": "message, just enter. Oh, yeah. Here we",
      "offset": 3485.76,
      "duration": 7.16
    },
    {
      "lang": "en",
      "text": "go. Great. There you go.",
      "offset": 3488.28,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "Uh, it didn't do the query. It won't do",
      "offset": 3497.04,
      "duration": 4.12
    },
    {
      "lang": "en",
      "text": "it again because it has the answer.",
      "offset": 3498.96,
      "duration": 8.68
    },
    {
      "lang": "en",
      "text": "Yeah. uh in the message context. Yeah.",
      "offset": 3501.16,
      "duration": 6.48
    },
    {
      "lang": "en",
      "text": "Yeah. There we go. So, you could style",
      "offset": 3511.28,
      "duration": 5.839
    },
    {
      "lang": "en",
      "text": "this however you wanted. Um",
      "offset": 3513.04,
      "duration": 7.2
    },
    {
      "lang": "en",
      "text": "um uh I'd love for questions that people",
      "offset": 3517.119,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "have if they want to type into reason",
      "offset": 3520.24,
      "duration": 2.96
    },
    {
      "lang": "en",
      "text": "models. Otherwise, I have a few other",
      "offset": 3522.079,
      "duration": 2.72
    },
    {
      "lang": "en",
      "text": "notes that I think might be worth it to",
      "offset": 3523.2,
      "duration": 6.119
    },
    {
      "lang": "en",
      "text": "talk about, but uh questions first.",
      "offset": 3524.799,
      "duration": 4.52
    },
    {
      "lang": "en",
      "text": "I think I posted mine which is like what",
      "offset": 3531.04,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "are the like ideas we can like condense",
      "offset": 3532.96,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "from all of this because I know we had",
      "offset": 3535.44,
      "duration": 2.72
    },
    {
      "lang": "en",
      "text": "like things thrown in different",
      "offset": 3536.799,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "directions but what would you say is the",
      "offset": 3538.16,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "biggest takeaway? I think the biggest",
      "offset": 3540.079,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "takeaway is really about time management",
      "offset": 3541.92,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "of your engineering team is the biggest",
      "offset": 3544.319,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "thing that I think about which is if you",
      "offset": 3546.48,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "really want to ship something really",
      "offset": 3548.64,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "really fast just throw an 03 model let",
      "offset": 3549.92,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "it do its reasoning and you basically",
      "offset": 3552.88,
      "duration": 3.439
    },
    {
      "lang": "en",
      "text": "save time and you get the generation you",
      "offset": 3554.4,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "want out on average this will be better",
      "offset": 3556.319,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "just like using GPT40 on average will be",
      "offset": 3558.48,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "better than GP40 mini on average a",
      "offset": 3560.72,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "reasoning model will have a slightly",
      "offset": 3563.28,
      "duration": 3.4
    },
    {
      "lang": "en",
      "text": "better",
      "offset": 3565.28,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "curve then of like like if I talk about",
      "offset": 3566.68,
      "duration": 5.08
    },
    {
      "lang": "en",
      "text": "accuracy versus varian A reasoning model",
      "offset": 3569.68,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "will just be slightly less like this",
      "offset": 3571.76,
      "duration": 6.64
    },
    {
      "lang": "en",
      "text": "will if this is 040",
      "offset": 3575.2,
      "duration": 4.639
    },
    {
      "lang": "en",
      "text": "uh then a reasoning model will be",
      "offset": 3578.4,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "slightly le slightly better uh than than",
      "offset": 3579.839,
      "duration": 6.401
    },
    {
      "lang": "en",
      "text": "40. Oh yes, thank you. That's I'll",
      "offset": 3583.52,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "remove that for posterity. Um just I",
      "offset": 3586.24,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "want it to be in the in the whiteboard",
      "offset": 3588.88,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "for when we do the recap. I'll draw it",
      "offset": 3590.559,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "on here. Um the reason model will",
      "offset": 3592.64,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "basically just be like slightly um",
      "offset": 3594.48,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "slightly better like the reason like",
      "offset": 3596.24,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "this. So the correlary here is like if",
      "offset": 3599.04,
      "duration": 4.799
    },
    {
      "lang": "en",
      "text": "you need performance and speed and",
      "offset": 3601.68,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "things like this, then you can go into",
      "offset": 3603.839,
      "duration": 3.121
    },
    {
      "lang": "en",
      "text": "engineering your own version of this.",
      "offset": 3605.52,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "Right. Exactly. Then Exactly. So if you",
      "offset": 3606.96,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "need better speed, you need better",
      "offset": 3609.44,
      "duration": 2.879
    },
    {
      "lang": "en",
      "text": "performance, you need better choice,",
      "offset": 3610.72,
      "duration": 2.96
    },
    {
      "lang": "en",
      "text": "then you can go ahead and go down the",
      "offset": 3612.319,
      "duration": 2.321
    },
    {
      "lang": "en",
      "text": "direction of actually picking the",
      "offset": 3613.68,
      "duration": 2.639
    },
    {
      "lang": "en",
      "text": "reasoning model of your choice. And or",
      "offset": 3614.64,
      "duration": 3.679
    },
    {
      "lang": "en",
      "text": "like if you need to run models on prem",
      "offset": 3616.319,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "and you can't run deepseeek R1 or",
      "offset": 3618.319,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "whatever and you can only run little",
      "offset": 3620.48,
      "duration": 2.879
    },
    {
      "lang": "en",
      "text": "llama models because you're at the edge",
      "offset": 3621.92,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "or something. Exactly. And then the",
      "offset": 3623.359,
      "duration": 3.121
    },
    {
      "lang": "en",
      "text": "other thing you want to note is that",
      "offset": 3625.2,
      "duration": 2.72
    },
    {
      "lang": "en",
      "text": "like De said, not every model will",
      "offset": 3626.48,
      "duration": 2.8
    },
    {
      "lang": "en",
      "text": "support reasoning. So this is how you",
      "offset": 3627.92,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "can leverage almost any model to go get",
      "offset": 3629.28,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "reasoning out of it. Um, and really",
      "offset": 3631.04,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "spending a little bit of time on what",
      "offset": 3634.4,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "the reasoning that you want the model to",
      "offset": 3636.16,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "generate is specifically with like the",
      "offset": 3637.92,
      "duration": 4.28
    },
    {
      "lang": "en",
      "text": "guided prompts that we showed earlier",
      "offset": 3639.76,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "can improve your accuracy of evening",
      "offset": 3642.2,
      "duration": 4.359
    },
    {
      "lang": "en",
      "text": "reasoning models because free form",
      "offset": 3645.04,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "reasoning as good as it is just going to",
      "offset": 3646.559,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "be worse than guided reasoning if you",
      "offset": 3648.64,
      "duration": 5.439
    },
    {
      "lang": "en",
      "text": "know the domain you're operating in.",
      "offset": 3650.16,
      "duration": 5.919
    },
    {
      "lang": "en",
      "text": "Yeah. Right. So like if and that's the",
      "offset": 3654.079,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "example of like asking it to actually",
      "offset": 3656.079,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "like hey when you're reasoning output a",
      "offset": 3657.839,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "cipher query and then review it and then",
      "offset": 3659.92,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "output another one like there's no way",
      "offset": 3661.68,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "to prompt a thinking model to do this",
      "offset": 3663.68,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "other than like by asking it to do this",
      "offset": 3665.44,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "basically like it's not going to come up",
      "offset": 3667.68,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "with this structure probably. Yeah. And",
      "offset": 3668.96,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "this structure might be good it might be",
      "offset": 3671.92,
      "duration": 2.96
    },
    {
      "lang": "en",
      "text": "bad. Obviously this is going to make it",
      "offset": 3673.359,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "way worse for generating cookie recipes.",
      "offset": 3674.88,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "Um, so don't do that. Uh, if you're if",
      "offset": 3677.119,
      "duration": 3.521
    },
    {
      "lang": "en",
      "text": "you need it to generate cookie recipes",
      "offset": 3679.2,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "and this, but if you know that it",
      "offset": 3680.64,
      "duration": 3.679
    },
    {
      "lang": "en",
      "text": "doesn't have to do this, then it can um",
      "offset": 3682.64,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "it can do something kind of I think you",
      "offset": 3684.319,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "can get way better results.",
      "offset": 3686,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "Yeah. See, it's like just gave up and",
      "offset": 3688.4,
      "duration": 3.439
    },
    {
      "lang": "en",
      "text": "said I can't do cookies because of how",
      "offset": 3690.079,
      "duration": 6.121
    },
    {
      "lang": "en",
      "text": "like intense its prompt was.",
      "offset": 3691.839,
      "duration": 4.361
    },
    {
      "lang": "en",
      "text": "Dex and Weber, I have a question here.",
      "offset": 3696.4,
      "duration": 4.52
    },
    {
      "lang": "en",
      "text": "So I understand for",
      "offset": 3698.64,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "the for the normal models we have done",
      "offset": 3700.92,
      "duration": 5.399
    },
    {
      "lang": "en",
      "text": "some kind of prompt engineering where it",
      "offset": 3704.64,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "is where we are asking it to reason over",
      "offset": 3706.319,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "create a cipher then reason over it. Is",
      "offset": 3709.28,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "it the same thing like splitting it into",
      "offset": 3711.599,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "two maybe actor and checker kind of",
      "offset": 3713.599,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "thing? One is acting then creating a",
      "offset": 3715.44,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "loop between these two and refining it.",
      "offset": 3717.52,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "Is that same or what is the difference?",
      "offset": 3720,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "The only thing network curves that's a",
      "offset": 3722.16,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "slightly different thing. Um because the",
      "offset": 3724.24,
      "duration": 5.839
    },
    {
      "lang": "en",
      "text": "way that that is working is",
      "offset": 3726.88,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "um I'm going to go in solid draw and",
      "offset": 3730.079,
      "duration": 2.881
    },
    {
      "lang": "en",
      "text": "just draw what that ends up looking",
      "offset": 3731.92,
      "duration": 2.8
    },
    {
      "lang": "en",
      "text": "like. D I'm going to draw at the bottom.",
      "offset": 3732.96,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "Yep. I'm here. I'm following you. Um so",
      "offset": 3734.72,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "what that ends up looking like is this.",
      "offset": 3737.28,
      "duration": 2.559
    },
    {
      "lang": "en",
      "text": "So you're going to have a model go",
      "offset": 3738.64,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "generate some let's say you have like",
      "offset": 3739.839,
      "duration": 4.52
    },
    {
      "lang": "en",
      "text": "some question by a",
      "offset": 3741.76,
      "duration": 5.599
    },
    {
      "lang": "en",
      "text": "user. I don't know why it's green. Um a",
      "offset": 3744.359,
      "duration": 5.641
    },
    {
      "lang": "en",
      "text": "user will ask a question. Then what",
      "offset": 3747.359,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "you're doing is you're having the model",
      "offset": 3750,
      "duration": 4.359
    },
    {
      "lang": "en",
      "text": "go generate some um some",
      "offset": 3751.119,
      "duration": 5.121
    },
    {
      "lang": "en",
      "text": "response. Then what you're doing is",
      "offset": 3754.359,
      "duration": 3.801
    },
    {
      "lang": "en",
      "text": "you're having another user then you're",
      "offset": 3756.24,
      "duration": 4.559
    },
    {
      "lang": "en",
      "text": "having another model like do like do",
      "offset": 3758.16,
      "duration": 5.639
    },
    {
      "lang": "en",
      "text": "like like a",
      "offset": 3760.799,
      "duration": 5.361
    },
    {
      "lang": "en",
      "text": "checker response. And this is like the",
      "offset": 3763.799,
      "duration": 4.601
    },
    {
      "lang": "en",
      "text": "actor response. This is what you're",
      "offset": 3766.16,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "talking about. This is like LM is judge,",
      "offset": 3768.4,
      "duration": 3.199
    },
    {
      "lang": "en",
      "text": "right? It's like, hey, review the",
      "offset": 3770.4,
      "duration": 2.8
    },
    {
      "lang": "en",
      "text": "question and the answer and see if it",
      "offset": 3771.599,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "makes sense kind of thing, right? And",
      "offset": 3773.2,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "then you kind of do this and like an",
      "offset": 3775.44,
      "duration": 3.119
    },
    {
      "lang": "en",
      "text": "iteration loop. Now, the thing that",
      "offset": 3777.119,
      "duration": 2.96
    },
    {
      "lang": "en",
      "text": "people don't realize when they do this",
      "offset": 3778.559,
      "duration": 4.361
    },
    {
      "lang": "en",
      "text": "is that your costs here are actually",
      "offset": 3780.079,
      "duration": 5.121
    },
    {
      "lang": "en",
      "text": "exponential. So, the first time you call",
      "offset": 3782.92,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "the active response, your cost is just a",
      "offset": 3785.2,
      "duration": 5.919
    },
    {
      "lang": "en",
      "text": "question. When in order to generate the",
      "offset": 3788.2,
      "duration": 4.359
    },
    {
      "lang": "en",
      "text": "uh and I'll make this red so it's a",
      "offset": 3791.119,
      "duration": 3.121
    },
    {
      "lang": "en",
      "text": "little bit more clear. In order to",
      "offset": 3792.559,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "generate the checker response, your cost",
      "offset": 3794.24,
      "duration": 4.76
    },
    {
      "lang": "en",
      "text": "is the question plus the",
      "offset": 3795.839,
      "duration": 6.48
    },
    {
      "lang": "en",
      "text": "checker plus uh uh plus the sorry",
      "offset": 3799,
      "duration": 6.839
    },
    {
      "lang": "en",
      "text": "question plus the actor. Yep. In order",
      "offset": 3802.319,
      "duration": 5.441
    },
    {
      "lang": "en",
      "text": "to generate this next one, it's question",
      "offset": 3805.839,
      "duration": 3.401
    },
    {
      "lang": "en",
      "text": "plus act",
      "offset": 3807.76,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "actor plus checker again. So just to do",
      "offset": 3809.24,
      "duration": 5.72
    },
    {
      "lang": "en",
      "text": "like um just to do like a two-step",
      "offset": 3812.96,
      "duration": 3.359
    },
    {
      "lang": "en",
      "text": "process, you're passing the question",
      "offset": 3814.96,
      "duration": 3.599
    },
    {
      "lang": "en",
      "text": "three times, you're passing the actor",
      "offset": 3816.319,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "twice.",
      "offset": 3818.559,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "So your costs boil up exponentially",
      "offset": 3820.24,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "really fast with this approach and if",
      "offset": 3822.559,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "you're able to do it in line in the same",
      "offset": 3824.96,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "prompt now your cost is basically just",
      "offset": 3827.359,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "once for the question the actor checker",
      "offset": 3829.76,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "actor response like the thing Dex showed",
      "offset": 3831.599,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "in the in the code that he generated",
      "offset": 3834.24,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "with the cipher query that is a single",
      "offset": 3835.92,
      "duration": 6.72
    },
    {
      "lang": "en",
      "text": "cost for all these things but isn't",
      "offset": 3839.28,
      "duration": 6.88
    },
    {
      "lang": "en",
      "text": "sorry isn't every token here like every",
      "offset": 3842.64,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "every token that it's emitting you're",
      "offset": 3846.16,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "still reprocessing the entire thing. So",
      "offset": 3847.92,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "is this just like a context caching kind",
      "offset": 3850.16,
      "duration": 3.679
    },
    {
      "lang": "en",
      "text": "of thing we're taking advantage of",
      "offset": 3852.48,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "models? Yeah, there's an optimization",
      "offset": 3853.839,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "loop that allows them to not price you",
      "offset": 3856.4,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "for that every single time, right?",
      "offset": 3857.92,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "You're not rerunning them into a new",
      "offset": 3859.52,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "request. You're just open pricing you is",
      "offset": 3861.52,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "only for the new tokens that you're",
      "offset": 3865.2,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "generating. If you go back to the other",
      "offset": 3866.72,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "thing, yeah, now OpenAI is pricing you",
      "offset": 3868.24,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "in a way where it's like the question is",
      "offset": 3871.2,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "being priced three different times here",
      "offset": 3872.88,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "because they're all separate requests to",
      "offset": 3875.119,
      "duration": 3.281
    },
    {
      "lang": "en",
      "text": "an LLM and they're treated as separate",
      "offset": 3876.72,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "and it's like re reloading all the Yeah.",
      "offset": 3878.4,
      "duration": 5.679
    },
    {
      "lang": "en",
      "text": "Okay. Exactly. Does that make sense uh",
      "offset": 3881.28,
      "duration": 6.079
    },
    {
      "lang": "en",
      "text": "for the person that asked the question?",
      "offset": 3884.079,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "Yeah. Yep. It does. Perfect. So, there's",
      "offset": 3887.359,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "a benefit of basically cost, accuracy,",
      "offset": 3890.079,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "and latency. In general, with this loop,",
      "offset": 3891.839,
      "duration": 4.881
    },
    {
      "lang": "en",
      "text": "you can get a little bit more control,",
      "offset": 3894.559,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "but your cost will be a lot more and",
      "offset": 3896.72,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "your latency will be a lot more. If",
      "offset": 3898.96,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "you're able to do it in a single system,",
      "offset": 3901.28,
      "duration": 5
    },
    {
      "lang": "en",
      "text": "you might as well.",
      "offset": 3902.88,
      "duration": 3.4
    },
    {
      "lang": "en",
      "text": "Great question. I love that question. I",
      "offset": 3908.96,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "hadn't thought about it this way, but",
      "offset": 3911.28,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "that makes a ton of sense. Um, other",
      "offset": 3912.48,
      "duration": 5.599
    },
    {
      "lang": "en",
      "text": "other key other question also vibe. Does",
      "offset": 3915.68,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "that does this capture all the key",
      "offset": 3918.079,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "takeaways? like basically like time",
      "offset": 3919.2,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "management versus co cost management and",
      "offset": 3921.119,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "like being able to basically do really",
      "offset": 3923.119,
      "duration": 3.801
    },
    {
      "lang": "en",
      "text": "specific guided reasoning better than a",
      "offset": 3924.72,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "generic model that's just trying to like",
      "offset": 3926.92,
      "duration": 4.199
    },
    {
      "lang": "en",
      "text": "spew a lot of nonsense before it",
      "offset": 3929.44,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "answers. Yeah. And then one thing to",
      "offset": 3931.119,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "note remember is that I showed that you",
      "offset": 3932.88,
      "duration": 3.679
    },
    {
      "lang": "en",
      "text": "can always use the combination of a",
      "offset": 3934.319,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "reasoning model with guided reasoning as",
      "offset": 3936.559,
      "duration": 4.921
    },
    {
      "lang": "en",
      "text": "well.",
      "offset": 3938.48,
      "duration": 3
    },
    {
      "lang": "en",
      "text": "We have one more question over here.",
      "offset": 3942.559,
      "duration": 8.961
    },
    {
      "lang": "en",
      "text": "Um while asking LLM I can be wrong about",
      "offset": 3946.119,
      "duration": 7.881
    },
    {
      "lang": "en",
      "text": "many names. Sorry I'm I'm I'm not into",
      "offset": 3951.52,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "movies. I don't know any of the names",
      "offset": 3954,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "but I saw you writing caves or something",
      "offset": 3955.52,
      "duration": 5.319
    },
    {
      "lang": "en",
      "text": "reenu keys or some something like that.",
      "offset": 3958.079,
      "duration": 6.48
    },
    {
      "lang": "en",
      "text": "U if it if it's a wrong typing from the",
      "offset": 3960.839,
      "duration": 6.28
    },
    {
      "lang": "en",
      "text": "user do we actually go and check or is",
      "offset": 3964.559,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "it like LLM correcting on behalf of us",
      "offset": 3967.119,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "first and then generating cipher? How is",
      "offset": 3969.359,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "it working? There's a really interesting",
      "offset": 3971.359,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "blog post that I want to write about",
      "offset": 3973.76,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "this which is how LM are just amazing",
      "offset": 3975.28,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "spell checkers. Um",
      "offset": 3978,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "oftentime if you go back to the code I",
      "offset": 3980.72,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "think it's just easier to show in a",
      "offset": 3982.72,
      "duration": 2.879
    },
    {
      "lang": "en",
      "text": "demo.",
      "offset": 3984,
      "duration": 4.559
    },
    {
      "lang": "en",
      "text": "I understood that point I guess but uh",
      "offset": 3985.599,
      "duration": 6.321
    },
    {
      "lang": "en",
      "text": "think of it in in con uh in perspective",
      "offset": 3988.559,
      "duration": 5.441
    },
    {
      "lang": "en",
      "text": "of organizational data for example",
      "offset": 3991.92,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "employee database right LM has no idea",
      "offset": 3994,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "about it. So if I create a knowledge",
      "offset": 3996.88,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "base let's say skill database of every",
      "offset": 3998.72,
      "duration": 6.079
    },
    {
      "lang": "en",
      "text": "employee and I'm I'm just asking that uh",
      "offset": 4001.039,
      "duration": 6.32
    },
    {
      "lang": "en",
      "text": "graph to give me answer about how many",
      "offset": 4004.799,
      "duration": 4.76
    },
    {
      "lang": "en",
      "text": "are you know skilled on",
      "offset": 4007.359,
      "duration": 6.161
    },
    {
      "lang": "en",
      "text": "BML right and then I say someone uh I",
      "offset": 4009.559,
      "duration": 6.681
    },
    {
      "lang": "en",
      "text": "give it a I give it a name basically and",
      "offset": 4013.52,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "I want to get back all the skills of",
      "offset": 4016.24,
      "duration": 4.559
    },
    {
      "lang": "en",
      "text": "that particular employee from the graph.",
      "offset": 4018.24,
      "duration": 4.799
    },
    {
      "lang": "en",
      "text": "So how does it work? Can you go to the",
      "offset": 4020.799,
      "duration": 4.361
    },
    {
      "lang": "en",
      "text": "can you go to the",
      "offset": 4023.039,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "uh codebase? I want to show a couple",
      "offset": 4025.16,
      "duration": 3.56
    },
    {
      "lang": "en",
      "text": "examples because I think it's going to",
      "offset": 4027.839,
      "duration": 2.321
    },
    {
      "lang": "en",
      "text": "be easier to talk about this with code",
      "offset": 4028.72,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "because I think what is how can I get",
      "offset": 4030.16,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "the model to reason about something in",
      "offset": 4032,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "the case of it like being really unique.",
      "offset": 4034.079,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "So it turns out because LM are really",
      "offset": 4036.4,
      "duration": 4.639
    },
    {
      "lang": "en",
      "text": "really good spell checkers. They will",
      "offset": 4038.799,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "they will not abide by you. And I'm",
      "offset": 4041.039,
      "duration": 2.881
    },
    {
      "lang": "en",
      "text": "going to use like very simple examples",
      "offset": 4042.559,
      "duration": 3.121
    },
    {
      "lang": "en",
      "text": "to make this a point of how you could go",
      "offset": 4043.92,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "do this. So let's say I'm I'm looking at",
      "offset": 4045.68,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "a resume thing. I spelled name wrong.",
      "offset": 4047.68,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "it is going to be virtually impossible",
      "offset": 4050.48,
      "duration": 4.359
    },
    {
      "lang": "en",
      "text": "for me to get the model to spit out",
      "offset": 4052.4,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "NAE. It is going to be really, really,",
      "offset": 4054.839,
      "duration": 4.041
    },
    {
      "lang": "en",
      "text": "really hard. So, if an employes name",
      "offset": 4057.28,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "just has a totally different misspelling",
      "offset": 4058.88,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "of it and it never works, it is going to",
      "offset": 4061.68,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "be really, really, really hard for me to",
      "offset": 4064.64,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "guide the model in that direction,",
      "offset": 4066.48,
      "duration": 5.119
    },
    {
      "lang": "en",
      "text": "right? Um, so how would I actually go do",
      "offset": 4068.88,
      "duration": 4.479
    },
    {
      "lang": "en",
      "text": "this? It turns out the only real way to",
      "offset": 4071.599,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "go do this is you will have to give the",
      "offset": 4073.359,
      "duration": 5.281
    },
    {
      "lang": "en",
      "text": "model a name that it can output and then",
      "offset": 4075.839,
      "duration": 4.801
    },
    {
      "lang": "en",
      "text": "convert it post programmatically into",
      "offset": 4078.64,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "the name that actually generates. So if",
      "offset": 4080.64,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "you a model is just a statistical",
      "offset": 4082.72,
      "duration": 3
    },
    {
      "lang": "en",
      "text": "distribution of",
      "offset": 4084.4,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "tokens. So if an if a thing is just",
      "offset": 4085.72,
      "duration": 5.56
    },
    {
      "lang": "en",
      "text": "statistically super super super super",
      "offset": 4088.96,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "unlikely to be the thing that you want",
      "offset": 4091.28,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "it to be then you have to fall back",
      "offset": 4092.72,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "towards techniques like constraint",
      "offset": 4095.76,
      "duration": 2.959
    },
    {
      "lang": "en",
      "text": "generation. you have to fall back",
      "offset": 4097.44,
      "duration": 3.359
    },
    {
      "lang": "en",
      "text": "towards techniques like aliasing where I",
      "offset": 4098.719,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "let the model see the content that I",
      "offset": 4100.799,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "want to go see it and then that's the",
      "offset": 4102.319,
      "duration": 4.241
    },
    {
      "lang": "en",
      "text": "only real way to navigate that scenario.",
      "offset": 4104.48,
      "duration": 3.759
    },
    {
      "lang": "en",
      "text": "In the case of names, it's a little bit",
      "offset": 4106.56,
      "duration": 5
    },
    {
      "lang": "en",
      "text": "more interesting because",
      "offset": 4108.239,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "like so like I just wrote my name",
      "offset": 4111.56,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "without any",
      "offset": 4113.759,
      "duration": 4.881
    },
    {
      "lang": "en",
      "text": "vowels or actually I'll do this. My last",
      "offset": 4115.96,
      "duration": 5.239
    },
    {
      "lang": "en",
      "text": "name is pretty",
      "offset": 4118.64,
      "duration": 2.559
    },
    {
      "lang": "en",
      "text": "popular and like we'll just see what the",
      "offset": 4122.04,
      "duration": 4.199
    },
    {
      "lang": "en",
      "text": "model thinks when I go and go output",
      "offset": 4124.239,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "name.",
      "offset": 4126.239,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "It might output my name directly. But if",
      "offset": 4128.08,
      "duration": 4.639
    },
    {
      "lang": "en",
      "text": "I use a slightly worse",
      "offset": 4129.759,
      "duration": 2.96
    },
    {
      "lang": "en",
      "text": "model, see if I can get to or let me",
      "offset": 4133.08,
      "duration": 6.599
    },
    {
      "lang": "en",
      "text": "try. Yeah, there you go. You got it. It",
      "offset": 4136.719,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "No, it still output the name correctly.",
      "offset": 4139.679,
      "duration": 3.281
    },
    {
      "lang": "en",
      "text": "So I want I want I want to show like a",
      "offset": 4141.279,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "slightly worse model like doing dumb",
      "offset": 4142.96,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "things with",
      "offset": 4144.719,
      "duration": 2.56
    },
    {
      "lang": "en",
      "text": "like Mitch.",
      "offset": 4151.56,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "Dom",
      "offset": 4157.04,
      "duration": 2.4
    },
    {
      "lang": "en",
      "text": "Smith. So I",
      "offset": 4160.759,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "want",
      "offset": 4162.6,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "smit correct.",
      "offset": 4164.6,
      "duration": 6.079
    },
    {
      "lang": "en",
      "text": "Yeah. Jithgmail.com. And I'll go run",
      "offset": 4166.52,
      "duration": 6.44
    },
    {
      "lang": "en",
      "text": "this. So in this it's actually doing it",
      "offset": 4170.679,
      "duration": 3.721
    },
    {
      "lang": "en",
      "text": "correctly. But you can imagine a much",
      "offset": 4172.96,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "dumber model actually just outputting",
      "offset": 4174.4,
      "duration": 5.279
    },
    {
      "lang": "en",
      "text": "John instead of JHN. And the only real",
      "offset": 4176,
      "duration": 5.199
    },
    {
      "lang": "en",
      "text": "thing you can do in this scenario is",
      "offset": 4179.679,
      "duration": 2.961
    },
    {
      "lang": "en",
      "text": "actually in your codebase just write",
      "offset": 4181.199,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "another system that just checks and says",
      "offset": 4182.64,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "that the name is actually in one of the",
      "offset": 4184.799,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "names that you provided. And if it",
      "offset": 4187.04,
      "duration": 4.119
    },
    {
      "lang": "en",
      "text": "isn't, then I make a smaller query that",
      "offset": 4188.4,
      "duration": 5.839
    },
    {
      "lang": "en",
      "text": "says what is the exact name from this",
      "offset": 4191.159,
      "duration": 5.961
    },
    {
      "lang": "en",
      "text": "list of names that makes sense and",
      "offset": 4194.239,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "actually uh have the model go and",
      "offset": 4197.12,
      "duration": 4.92
    },
    {
      "lang": "en",
      "text": "generate one of those as a corrective",
      "offset": 4199.199,
      "duration": 5.121
    },
    {
      "lang": "en",
      "text": "measure because in case the model",
      "offset": 4202.04,
      "duration": 3.48
    },
    {
      "lang": "en",
      "text": "doesn't output something that's actually",
      "offset": 4204.32,
      "duration": 2.48
    },
    {
      "lang": "en",
      "text": "in your employee database, then you can",
      "offset": 4205.52,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "go double check that. That would be the",
      "offset": 4206.8,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "approach that I would take in this",
      "offset": 4208.88,
      "duration": 2.319
    },
    {
      "lang": "en",
      "text": "approach. And like no amount of",
      "offset": 4210,
      "duration": 2.64
    },
    {
      "lang": "en",
      "text": "reasoning model or something else can go",
      "offset": 4211.199,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "fix this because models are just",
      "offset": 4212.64,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "predictive systems and they will at some",
      "offset": 4215.12,
      "duration": 4.559
    },
    {
      "lang": "en",
      "text": "point be wrong and you have to build",
      "offset": 4217.12,
      "duration": 5.039
    },
    {
      "lang": "en",
      "text": "systems on top of it to make it correct",
      "offset": 4219.679,
      "duration": 5.281
    },
    {
      "lang": "en",
      "text": "not just let it go out and hope that it",
      "offset": 4222.159,
      "duration": 4.281
    },
    {
      "lang": "en",
      "text": "is",
      "offset": 4224.96,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "correct. Does that answer the question",
      "offset": 4226.44,
      "duration": 3.64
    },
    {
      "lang": "en",
      "text": "on above?",
      "offset": 4228.4,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "Yes. Yes, I think it does. One one more",
      "offset": 4230.08,
      "duration": 5.92
    },
    {
      "lang": "en",
      "text": "question here. So I I see a lot of",
      "offset": 4233.28,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "things happening on grounding LLM using",
      "offset": 4236,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "graph and database and especially giving",
      "offset": 4238.32,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "your ontologies and business related or",
      "offset": 4240.64,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "do domain specific things to it. For",
      "offset": 4243.6,
      "duration": 6.16
    },
    {
      "lang": "en",
      "text": "example, I I only have lawyer and super",
      "offset": 4245.84,
      "duration": 6.879
    },
    {
      "lang": "en",
      "text": "lawyer that kind of stuff and then",
      "offset": 4249.76,
      "duration": 6.8
    },
    {
      "lang": "en",
      "text": "letting it decide whether someone is",
      "offset": 4252.719,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "reporting to some other person because",
      "offset": 4256.56,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "these two people are having different",
      "offset": 4258.719,
      "duration": 6.161
    },
    {
      "lang": "en",
      "text": "descriptions on their job post such a",
      "offset": 4261.28,
      "duration": 6.16
    },
    {
      "lang": "en",
      "text": "was was there originally a plan to",
      "offset": 4264.88,
      "duration": 5.48
    },
    {
      "lang": "en",
      "text": "discuss this point as well use to ground",
      "offset": 4267.44,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "LM in this call or no? No, I don't think",
      "offset": 4270.36,
      "duration": 3.96
    },
    {
      "lang": "en",
      "text": "we were going to talk about necessarily",
      "offset": 4273.12,
      "duration": 2.8
    },
    {
      "lang": "en",
      "text": "graph databases or something here. What",
      "offset": 4274.32,
      "duration": 2.96
    },
    {
      "lang": "en",
      "text": "we really wanted to go do is graph",
      "offset": 4275.92,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "databases are a complex type of query.",
      "offset": 4277.28,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "So, we just wanted to use that to show",
      "offset": 4279.36,
      "duration": 2.96
    },
    {
      "lang": "en",
      "text": "off like different reasoning techniques",
      "offset": 4280.64,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "that you could use for graph databases.",
      "offset": 4282.32,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "I'm probably not the best expert. I",
      "offset": 4284.719,
      "duration": 3.201
    },
    {
      "lang": "en",
      "text": "don't know about that, but like I know",
      "offset": 4286.719,
      "duration": 2.561
    },
    {
      "lang": "en",
      "text": "I'm not the best expert on like graph",
      "offset": 4287.92,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "databases and like all the different",
      "offset": 4289.28,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "applications of them. Um, yeah, the idea",
      "offset": 4291.12,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "here is I think like for complex things",
      "offset": 4294.4,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "that reasoning models are really good at",
      "offset": 4296.48,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "like coding and like writing queries and",
      "offset": 4298.32,
      "duration": 4.879
    },
    {
      "lang": "en",
      "text": "doing these structured things. um that",
      "offset": 4300.48,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "there's all these techniques you can use",
      "offset": 4303.199,
      "duration": 3.441
    },
    {
      "lang": "en",
      "text": "and so the the using the graph database",
      "offset": 4304.56,
      "duration": 3.599
    },
    {
      "lang": "en",
      "text": "was more of like here's an example of a",
      "offset": 4306.64,
      "duration": 2.96
    },
    {
      "lang": "en",
      "text": "thing that reasoning models tend to be",
      "offset": 4308.159,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "better at how do we get reasoning model",
      "offset": 4309.6,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "level performance out of a tiny model.",
      "offset": 4311.76,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "Yes. Uh if you if I think if you join",
      "offset": 4314.56,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "the B boundary discord and ask Pashant",
      "offset": 4316.64,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "he has a lot of knowledge about graph",
      "offset": 4318.8,
      "duration": 4.28
    },
    {
      "lang": "en",
      "text": "databases.",
      "offset": 4320.08,
      "duration": 3
    },
    {
      "lang": "en",
      "text": "Thanks. Yeah, happy to bounce ideas. I'm",
      "offset": 4323.36,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "right here on the call but I I'm on BAM",
      "offset": 4325.44,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "and Discord as well.",
      "offset": 4327.04,
      "duration": 2.88
    },
    {
      "lang": "en",
      "text": "Um, other questions from anyone else",
      "offset": 4331.04,
      "duration": 3.119
    },
    {
      "lang": "en",
      "text": "that they might want to have answered",
      "offset": 4333.04,
      "duration": 2.48
    },
    {
      "lang": "en",
      "text": "while we're here. Actually, I I have a",
      "offset": 4334.159,
      "duration": 2.641
    },
    {
      "lang": "en",
      "text": "question Weber. So, just to follow up",
      "offset": 4335.52,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "with this original question above hand.",
      "offset": 4336.8,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "So, I think I had the same thought when",
      "offset": 4338.96,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "he asked that, which is let's say you",
      "offset": 4341.199,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "had a graph database of uh employees and",
      "offset": 4343.04,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "their skills and BAML was one of those",
      "offset": 4345.679,
      "duration": 3.761
    },
    {
      "lang": "en",
      "text": "skills and then you issue a query saying",
      "offset": 4347.44,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "give me all the employees who have the",
      "offset": 4349.44,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "skill BAML but you misspell BAML as BA B",
      "offset": 4351.28,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "A L M. Yeah. Now LLMs will that's a",
      "offset": 4354,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "classic case where the misspelling is a",
      "offset": 4357.04,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "correct term and the correct spelling is",
      "offset": 4358.88,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "the is the misunderstood term right so",
      "offset": 4360.56,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "in that situation your your LLM is going",
      "offset": 4363.199,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "to actually search for bum and it's",
      "offset": 4365.28,
      "duration": 2.56
    },
    {
      "lang": "en",
      "text": "going to fail because you're going to",
      "offset": 4366.719,
      "duration": 2.561
    },
    {
      "lang": "en",
      "text": "get an empty response from that sit from",
      "offset": 4367.84,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "the database t right this would be like",
      "offset": 4369.28,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "if we misspelled ke ree name right",
      "offset": 4371.44,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "search for exist yeah so so the point is",
      "offset": 4375.04,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "I notic in the implementation that you",
      "offset": 4377.44,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "you have decks it's just giving you",
      "offset": 4379.04,
      "duration": 2.8
    },
    {
      "lang": "en",
      "text": "empty results all the time in an",
      "offset": 4380.56,
      "duration": 2.32
    },
    {
      "lang": "en",
      "text": "infinite loop it's just not doing",
      "offset": 4381.84,
      "duration": 3.359
    },
    {
      "lang": "en",
      "text": "anything after the empty result So the",
      "offset": 4382.88,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "right way to handle this would be",
      "offset": 4385.199,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "something like you have a fallback where",
      "offset": 4386.64,
      "duration": 5.039
    },
    {
      "lang": "en",
      "text": "if you don't get like this uh if you get",
      "offset": 4388.719,
      "duration": 4.641
    },
    {
      "lang": "en",
      "text": "an empty result you don't assume that",
      "offset": 4391.679,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "the information does not exist you try",
      "offset": 4393.36,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "the query in a different form uh in a",
      "offset": 4395.36,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "way that the you at least try from a",
      "offset": 4397.52,
      "duration": 2.88
    },
    {
      "lang": "en",
      "text": "different perspective because the issue",
      "offset": 4399.28,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "is that you don't know whether the",
      "offset": 4400.4,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "answer is wrong missing or in uh correct",
      "offset": 4402.96,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "like there's three possibilities right",
      "offset": 4406.08,
      "duration": 3.599
    },
    {
      "lang": "en",
      "text": "exactly so there's no real way for you",
      "offset": 4407.84,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "to know that unless you potentially like",
      "offset": 4409.679,
      "duration": 2.881
    },
    {
      "lang": "en",
      "text": "especially when you have an empty result",
      "offset": 4411.44,
      "duration": 2.08
    },
    {
      "lang": "en",
      "text": "you don't know whether it's wrong or",
      "offset": 4412.56,
      "duration": 1.84
    },
    {
      "lang": "en",
      "text": "missing",
      "offset": 4413.52,
      "duration": 2.4
    },
    {
      "lang": "en",
      "text": "Yeah. So you could come here and check",
      "offset": 4414.4,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "and say like if if the result is empty,",
      "offset": 4415.92,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "you can instead push something into the",
      "offset": 4418.8,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "context that is like you did. Beautiful",
      "offset": 4420.56,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "example. Yeah. Reb had a really good",
      "offset": 4424,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "example of this in the Neo Forj stream",
      "offset": 4425.52,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "that he did with the Neo Forj people. Uh",
      "offset": 4427.44,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "that's something I highly recommend",
      "offset": 4429.52,
      "duration": 2.32
    },
    {
      "lang": "en",
      "text": "whoever's on this call, please go and",
      "offset": 4430.64,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "watch that one because uh the way you",
      "offset": 4431.84,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "handle the retry and you know preventing",
      "offset": 4433.84,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "failure modes when you have misspellings",
      "offset": 4436,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "or typos or whatever other minor issues,",
      "offset": 4437.36,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "those are different ways to think about",
      "offset": 4439.28,
      "duration": 4.6
    },
    {
      "lang": "en",
      "text": "it.",
      "offset": 4440.88,
      "duration": 3
    },
    {
      "lang": "en",
      "text": "Oh, let me try again. Yeah, just making",
      "offset": 4445.12,
      "duration": 5.92
    },
    {
      "lang": "en",
      "text": "an assistant message.",
      "offset": 4448.32,
      "duration": 5.839
    },
    {
      "lang": "en",
      "text": "And now you're kind of done.",
      "offset": 4451.04,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "So, we can actually add like a special",
      "offset": 4454.159,
      "duration": 3.441
    },
    {
      "lang": "en",
      "text": "thing into here that adds that in for",
      "offset": 4455.84,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "the user that says we actually forcibly",
      "offset": 4457.6,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "add this into the context where we say",
      "offset": 4459.92,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "something like, oh, the query didn't",
      "offset": 4462.48,
      "duration": 4.92
    },
    {
      "lang": "en",
      "text": "result return any results. Perhaps it's",
      "offset": 4463.84,
      "duration": 8.52
    },
    {
      "lang": "en",
      "text": "wrong. W wrong or",
      "offset": 4467.4,
      "duration": 7.279
    },
    {
      "lang": "en",
      "text": "misspelled.",
      "offset": 4472.36,
      "duration": 7.319
    },
    {
      "lang": "en",
      "text": "Uh should we ask the user for more?",
      "offset": 4474.679,
      "duration": 8.121
    },
    {
      "lang": "en",
      "text": "Right. You're injecting thoughts",
      "offset": 4479.679,
      "duration": 3.961
    },
    {
      "lang": "en",
      "text": "for",
      "offset": 4482.8,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "more information there. Yeah. This is",
      "offset": 4483.64,
      "duration": 4.28
    },
    {
      "lang": "en",
      "text": "this is kind of what you Yeah. had",
      "offset": 4486.48,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "before. This is a good one. And now what",
      "offset": 4487.92,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "can happen is I'm actually injecting",
      "offset": 4489.84,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "stuff into the context that comes again",
      "offset": 4491.92,
      "duration": 5.799
    },
    {
      "lang": "en",
      "text": "from me from all of us kind of knowing",
      "offset": 4494.239,
      "duration": 7.281
    },
    {
      "lang": "en",
      "text": "upfront that this is a this is a",
      "offset": 4497.719,
      "duration": 5.96
    },
    {
      "lang": "en",
      "text": "contextual application built around",
      "offset": 4501.52,
      "duration": 4.719
    },
    {
      "lang": "en",
      "text": "talking to a graph database and that",
      "offset": 4503.679,
      "duration": 4.841
    },
    {
      "lang": "en",
      "text": "these kinds of things where it's",
      "offset": 4506.239,
      "duration": 5.121
    },
    {
      "lang": "en",
      "text": "empty might",
      "offset": 4508.52,
      "duration": 8.32
    },
    {
      "lang": "en",
      "text": "uh might not not for sure might uh be",
      "offset": 4511.36,
      "duration": 8.48
    },
    {
      "lang": "en",
      "text": "wrong. But you can't do this generically",
      "offset": 4516.84,
      "duration": 6.56
    },
    {
      "lang": "en",
      "text": "if that makes sense.",
      "offset": 4519.84,
      "duration": 3.56
    },
    {
      "lang": "en",
      "text": "Yep. Makes total sense. Cool. You can",
      "offset": 4523.52,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "Yeah.",
      "offset": 4526.56,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "Um cool. Super interesting. What What",
      "offset": 4528.48,
      "duration": 5.64
    },
    {
      "lang": "en",
      "text": "else we got?",
      "offset": 4530.8,
      "duration": 3.32
    },
    {
      "lang": "en",
      "text": "Awesome. Um I think that's it for this",
      "offset": 4534.48,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "time. Uh next week we're going to have a",
      "offset": 4536.239,
      "duration": 3.761
    },
    {
      "lang": "en",
      "text": "really really fun conversation about a",
      "offset": 4537.84,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "topic that I am personally really",
      "offset": 4540,
      "duration": 5.199
    },
    {
      "lang": "en",
      "text": "excited about. Um, you have a thing",
      "offset": 4541.6,
      "duration": 6.24
    },
    {
      "lang": "en",
      "text": "available on under on there uh text.",
      "offset": 4545.199,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "Okay, I'll pull it up. Oh, you want",
      "offset": 4547.84,
      "duration": 2.72
    },
    {
      "lang": "en",
      "text": "Yeah. You want to pull up the uh the",
      "offset": 4549.199,
      "duration": 5.081
    },
    {
      "lang": "en",
      "text": "card? Yeah. Which is I think",
      "offset": 4550.56,
      "duration": 6.08
    },
    {
      "lang": "en",
      "text": "um or are you pulling up? I can pull it",
      "offset": 4554.28,
      "duration": 5.72
    },
    {
      "lang": "en",
      "text": "up. Yeah, go for it. Which I think is",
      "offset": 4556.64,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "going to be something that is really",
      "offset": 4560,
      "duration": 2.48
    },
    {
      "lang": "en",
      "text": "relevant to a lot of people as we go",
      "offset": 4561.04,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "forward, which is people talk a lot",
      "offset": 4562.48,
      "duration": 3.199
    },
    {
      "lang": "en",
      "text": "about like fine-tuning and how we can go",
      "offset": 4564.08,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "do this. Um, this one is going to be a",
      "offset": 4565.679,
      "duration": 3.281
    },
    {
      "lang": "en",
      "text": "lot more conceptual on how we can",
      "offset": 4567.6,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "actually leverage human feedback and how",
      "offset": 4568.96,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "we have to collect data in a way for our",
      "offset": 4571.36,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "AI pipelines so we can fix them with rag",
      "offset": 4573.52,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "versus fine-tuning.",
      "offset": 4576.64,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "That's that's in two weeks, I think.",
      "offset": 4578.48,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "Unless we're switching the schedule",
      "offset": 4580.32,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "around. Oh, sorry. No, no, sorry. Yes,",
      "offset": 4581.52,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "that's the last one. Oh, I I was I was",
      "offset": 4583.6,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "blown away. We're gonna talk about code",
      "offset": 4586.32,
      "duration": 2.8
    },
    {
      "lang": "en",
      "text": "generation. I think code generation will",
      "offset": 4587.679,
      "duration": 6.161
    },
    {
      "lang": "en",
      "text": "be a really fun one. Yeah, I agree. Um,",
      "offset": 4589.12,
      "duration": 6.8
    },
    {
      "lang": "en",
      "text": "but um excited to see you all again.",
      "offset": 4593.84,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "Thank you all for joining. Uh, see you",
      "offset": 4595.92,
      "duration": 3.759
    },
    {
      "lang": "en",
      "text": "again next Tuesday. Yeah. Thanks y'all.",
      "offset": 4597.6,
      "duration": 4.639
    },
    {
      "lang": "en",
      "text": "This was super fun.",
      "offset": 4599.679,
      "duration": 4.721
    },
    {
      "lang": "en",
      "text": "Fun.",
      "offset": 4602.239,
      "duration": 2.161
    }
  ],
  "cleanText": null,
  "dumpedAt": "2025-07-21T18:43:25.418Z"
}