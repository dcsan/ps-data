{
  "episodeId": "tNRhhR54k6I",
  "channelSlug": "@twimlai",
  "title": "Zero-Shot Auto-Labeling: The End of Annotation for Computer Vision [Jason Corso] - 735",
  "publishedAt": "2025-06-10T17:21:17.000Z",
  "rawLines": [
    {
      "lang": "en",
      "text": "Wait a second. What we've been doing as",
      "offset": 0.08,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "annotation, just blindly sending",
      "offset": 1.92,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "everything out for labeling, is not the",
      "offset": 3.52,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "future. We're seeing foundation models",
      "offset": 5.92,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "come along that could indeed actually",
      "offset": 7.68,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "replace a lot of those typical case",
      "offset": 10,
      "duration": 4.639
    },
    {
      "lang": "en",
      "text": "human labels. So if what was annotation",
      "offset": 11.759,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "1.0 blind send me data and get me",
      "offset": 14.639,
      "duration": 4.961
    },
    {
      "lang": "en",
      "text": "labels, annotation 2.0 might only be",
      "offset": 17.279,
      "duration": 5.121
    },
    {
      "lang": "en",
      "text": "human answers questions asked by the by",
      "offset": 19.6,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "the agent, if you will, agentic labeling",
      "offset": 22.4,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "or something like that. To me, we're on",
      "offset": 24.32,
      "duration": 3.119
    },
    {
      "lang": "en",
      "text": "that timeline and we're we're probably",
      "offset": 25.92,
      "duration": 5.119
    },
    {
      "lang": "en",
      "text": "somewhere in the middle of it. All",
      "offset": 27.439,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "right, everyone. Welcome to another",
      "offset": 41.6,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "episode of the TwiML AI podcast. I am of",
      "offset": 43.6,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "course your host Sam Charington. Today",
      "offset": 46.48,
      "duration": 5.599
    },
    {
      "lang": "en",
      "text": "I'm joined by Jason Corso. Jason is",
      "offset": 49.12,
      "duration": 6.56
    },
    {
      "lang": "en",
      "text": "co-founder of Voxil 51 and a professor",
      "offset": 52.079,
      "duration": 6.64
    },
    {
      "lang": "en",
      "text": "at the University of Michigan. Before we",
      "offset": 55.68,
      "duration": 4.559
    },
    {
      "lang": "en",
      "text": "get going, be sure to take a moment to",
      "offset": 58.719,
      "duration": 3.041
    },
    {
      "lang": "en",
      "text": "hit that subscribe button wherever",
      "offset": 60.239,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "you're listening to today's show. Jason,",
      "offset": 61.76,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "welcome to the podcast. Hey Sam, uh,",
      "offset": 64.239,
      "duration": 3.761
    },
    {
      "lang": "en",
      "text": "thanks for having me. It's great to be",
      "offset": 66.88,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "here. Big fan. Absolutely. Thank you so",
      "offset": 68,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "much. I am looking forward to digging",
      "offset": 70.4,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "into our conversation. We're going to be",
      "offset": 72.24,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "talking about some of the work you're",
      "offset": 74.32,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "doing on automated labeling for computer",
      "offset": 76.24,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "vision. Uh, I'd love to have you start",
      "offset": 79.04,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "us off by sharing a little bit about",
      "offset": 81.28,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "your background. Right on. Sounds good.",
      "offset": 82.88,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "Yeah. Yeah. So, as you said, um I'm a",
      "offset": 84.72,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "co-founder at Voxil 51 where where we",
      "offset": 86.56,
      "duration": 5.519
    },
    {
      "lang": "en",
      "text": "make a software dev tool kind of like VS",
      "offset": 89.2,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "code for computer vision or VS code for",
      "offset": 92.079,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "visual AI. Uh my background I go back",
      "offset": 93.92,
      "duration": 6.559
    },
    {
      "lang": "en",
      "text": "you know maybe 10 15 years in research",
      "offset": 97.439,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "in computer vision. Uh most of most of",
      "offset": 100.479,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "my work focuses on high level computer",
      "offset": 103.119,
      "duration": 3.441
    },
    {
      "lang": "en",
      "text": "vision video understanding vision",
      "offset": 104.799,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "language relationship between the",
      "offset": 106.56,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "physical world and and vision so on. And",
      "offset": 108.479,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "through that work at the University of",
      "offset": 110.64,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "Michigan, I realized that there was, you",
      "offset": 112.32,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "know, a huge need for more analysis",
      "offset": 114.479,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "tooling to help support the code",
      "offset": 116.479,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "development of models and data sets",
      "offset": 118.159,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "together. And ultimately that's that's",
      "offset": 120.32,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "that's give given me rise to like the",
      "offset": 121.759,
      "duration": 4.801
    },
    {
      "lang": "en",
      "text": "last five or so years of my life at",
      "offset": 124.479,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "Voxil 51 and and the university",
      "offset": 126.56,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "together. Awesome. And so with Voxil,",
      "offset": 128.399,
      "duration": 5.121
    },
    {
      "lang": "en",
      "text": "who are the intended users of that tool?",
      "offset": 131.12,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "Yeah, Voxil is is pretty much uh the IC",
      "offset": 133.52,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "is a very tech is a technically deep uh",
      "offset": 136.08,
      "duration": 5.92
    },
    {
      "lang": "en",
      "text": "creator of either data sets for visual",
      "offset": 138.8,
      "duration": 6.079
    },
    {
      "lang": "en",
      "text": "problems like uh image, video, 3D point",
      "offset": 142,
      "duration": 6.319
    },
    {
      "lang": "en",
      "text": "clouds, meshes and so on or or model",
      "offset": 144.879,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "developers, right? At our bigger",
      "offset": 148.319,
      "duration": 4.241
    },
    {
      "lang": "en",
      "text": "customers, these tend to be separate",
      "offset": 150.239,
      "duration": 3.441
    },
    {
      "lang": "en",
      "text": "teams where you have like a data",
      "offset": 152.56,
      "duration": 2.48
    },
    {
      "lang": "en",
      "text": "creation team and you have a model",
      "offset": 153.68,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "development team. Whereas at our smaller",
      "offset": 155.04,
      "duration": 4.559
    },
    {
      "lang": "en",
      "text": "customers, typically, you know, a small",
      "offset": 157.28,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "team does does both of that. What what",
      "offset": 159.599,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "we've learned is or you know over the",
      "offset": 161.36,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "years generally like you don't you don't",
      "offset": 163.28,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "just get data dropped into your lap like",
      "offset": 165.92,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "a student does in my computer vision",
      "offset": 167.76,
      "duration": 2.64
    },
    {
      "lang": "en",
      "text": "class right and then you have to train",
      "offset": 169.28,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "the model the real world life in the",
      "offset": 170.4,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "real world is making the data set",
      "offset": 172.64,
      "duration": 3.599
    },
    {
      "lang": "en",
      "text": "alongside making the model and really",
      "offset": 174.4,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "understanding how these things coincide",
      "offset": 176.239,
      "duration": 4.881
    },
    {
      "lang": "en",
      "text": "together um you know and so that's",
      "offset": 177.76,
      "duration": 5.759
    },
    {
      "lang": "en",
      "text": "ultimately that's though that is why we",
      "offset": 181.12,
      "duration": 5.039
    },
    {
      "lang": "en",
      "text": "we released 51 which is the name of our",
      "offset": 183.519,
      "duration": 4.881
    },
    {
      "lang": "en",
      "text": "primary software it's both commercial",
      "offset": 186.159,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "and open source so open source for",
      "offset": 188.4,
      "duration": 3.759
    },
    {
      "lang": "en",
      "text": "single single users, local data, local",
      "offset": 190.08,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "compute. That's really how we got",
      "offset": 192.159,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "started in 2019 when we began uh this",
      "offset": 194,
      "duration": 5.519
    },
    {
      "lang": "en",
      "text": "direction toward toward like dev tool.",
      "offset": 197.519,
      "duration": 5.281
    },
    {
      "lang": "en",
      "text": "Um we released it open source uh both in",
      "offset": 199.519,
      "duration": 4.481
    },
    {
      "lang": "en",
      "text": "the computer vision community and the",
      "offset": 202.8,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "machine learning community. Um and it's",
      "offset": 204,
      "duration": 4.879
    },
    {
      "lang": "en",
      "text": "become a pretty widely adopted tool for",
      "offset": 206.4,
      "duration": 4.559
    },
    {
      "lang": "en",
      "text": "everyday usage. You know, our our",
      "offset": 208.879,
      "duration": 4.561
    },
    {
      "lang": "en",
      "text": "initial charge was, you know, we for the",
      "offset": 210.959,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "the first three things someone does when",
      "offset": 213.44,
      "duration": 2.719
    },
    {
      "lang": "en",
      "text": "they're starting a new computer vision",
      "offset": 214.959,
      "duration": 3.121
    },
    {
      "lang": "en",
      "text": "project, you know, pip install 51 should",
      "offset": 216.159,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "be one of those things, one of those",
      "offset": 218.08,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "first three things. Awesome. And are",
      "offset": 219.84,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "there particular types of projects that",
      "offset": 221.92,
      "duration": 5.039
    },
    {
      "lang": "en",
      "text": "you're seeing uh you know, the most",
      "offset": 223.92,
      "duration": 5.84
    },
    {
      "lang": "en",
      "text": "traction around or where",
      "offset": 226.959,
      "duration": 5.84
    },
    {
      "lang": "en",
      "text": "uh 51 is one of those first tools that",
      "offset": 229.76,
      "duration": 5.119
    },
    {
      "lang": "en",
      "text": "someone is using? I mean, it's a good",
      "offset": 232.799,
      "duration": 4.881
    },
    {
      "lang": "en",
      "text": "question, Sam. I think the,",
      "offset": 234.879,
      "duration": 4.961
    },
    {
      "lang": "en",
      "text": "you know, 51's a pretty flexible piece",
      "offset": 237.68,
      "duration": 3.759
    },
    {
      "lang": "en",
      "text": "of software. It's not intended to tell",
      "offset": 239.84,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "you how to do your work or what to do.",
      "offset": 241.439,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "It's it's think of it kind of like a set",
      "offset": 243.12,
      "duration": 3.679
    },
    {
      "lang": "en",
      "text": "of building blocks and if you know if",
      "offset": 245.439,
      "duration": 3.281
    },
    {
      "lang": "en",
      "text": "you want some annotation or you want",
      "offset": 246.799,
      "duration": 4.241
    },
    {
      "lang": "en",
      "text": "like model performance analysis or you",
      "offset": 248.72,
      "duration": 3.439
    },
    {
      "lang": "en",
      "text": "just want to visualize your embeddings",
      "offset": 251.04,
      "duration": 2.64
    },
    {
      "lang": "en",
      "text": "or whatever, it it can kind of do all",
      "offset": 252.159,
      "duration": 3.521
    },
    {
      "lang": "en",
      "text": "these different pieces for you. So, we",
      "offset": 253.68,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "do have a pretty broad user base. I mean",
      "offset": 255.68,
      "duration": 6.399
    },
    {
      "lang": "en",
      "text": "that said I think the uh you know object",
      "offset": 258.56,
      "duration": 5.359
    },
    {
      "lang": "en",
      "text": "detection is definitely at least amongst",
      "offset": 262.079,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "our commercial users object detection",
      "offset": 263.919,
      "duration": 5.84
    },
    {
      "lang": "en",
      "text": "really uh shines as like a as like a",
      "offset": 265.759,
      "duration": 6.081
    },
    {
      "lang": "en",
      "text": "core task in computer vision that our",
      "offset": 269.759,
      "duration": 4.241
    },
    {
      "lang": "en",
      "text": "users are doing and most typically",
      "offset": 271.84,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "people are starting with an existing",
      "offset": 274,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "model that that either they've trained",
      "offset": 276.96,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "or they've inherited say an offtheshelf",
      "offset": 278.32,
      "duration": 3.599
    },
    {
      "lang": "en",
      "text": "foundation model or something like that",
      "offset": 280.08,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "and their goal is to render that useful",
      "offset": 281.919,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "in their domain for their problem",
      "offset": 284.24,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "whether or not that's you know quality",
      "offset": 285.84,
      "duration": 2.48
    },
    {
      "lang": "en",
      "text": "assurance insurance on the on the",
      "offset": 287.28,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "manufacturing line or pedestrian",
      "offset": 288.32,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "avoidance for mobility or healthcare",
      "offset": 290.88,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "problems like you know from a vertical",
      "offset": 293.6,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "standpoint uh get getting to that uh we",
      "offset": 295.44,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "have lot you know there's no one domain",
      "offset": 298.56,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "actually of of users we have quite a few",
      "offset": 300.8,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "different uh domains in play maybe the",
      "offset": 303.04,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "most exciting one for for me I have",
      "offset": 306.08,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "young kids so but uh is is the we have",
      "offset": 308.24,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "some users that are monitoring marine",
      "offset": 311.44,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "life through through models built in 51",
      "offset": 313.6,
      "duration": 5.92
    },
    {
      "lang": "en",
      "text": "uh and and they use that across uh",
      "offset": 316.56,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "various oceans in the world. Pretty",
      "offset": 319.52,
      "duration": 4.239
    },
    {
      "lang": "en",
      "text": "cool, pretty cool project. I often hear",
      "offset": 321.12,
      "duration": 6.72
    },
    {
      "lang": "en",
      "text": "that one of the uh biggest lift",
      "offset": 323.759,
      "duration": 6.961
    },
    {
      "lang": "en",
      "text": "investments that teams can do is to",
      "offset": 327.84,
      "duration": 5.199
    },
    {
      "lang": "en",
      "text": "build like custom annotation tools",
      "offset": 330.72,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "because every application or use case is",
      "offset": 333.039,
      "duration": 4.481
    },
    {
      "lang": "en",
      "text": "kind of a little bit different versus",
      "offset": 335.44,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "using something off the shelf. Uh do you",
      "offset": 337.52,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "get that that kind of or how do you look",
      "offset": 339.84,
      "duration": 8.639
    },
    {
      "lang": "en",
      "text": "at that kind of um comment and uh is is",
      "offset": 342.56,
      "duration": 9.28
    },
    {
      "lang": "en",
      "text": "51 meant to be used like offtheshelf or",
      "offset": 348.479,
      "duration": 5.681
    },
    {
      "lang": "en",
      "text": "can it be integrated into more",
      "offset": 351.84,
      "duration": 5.359
    },
    {
      "lang": "en",
      "text": "application specific workflows? Yeah, I",
      "offset": 354.16,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "have I have personally fallen prey to",
      "offset": 357.199,
      "duration": 5.361
    },
    {
      "lang": "en",
      "text": "that uh to that to that direction as",
      "offset": 358.88,
      "duration": 6.4
    },
    {
      "lang": "en",
      "text": "well. when I was a posttock uh at UC at",
      "offset": 362.56,
      "duration": 4.479
    },
    {
      "lang": "en",
      "text": "UCLA",
      "offset": 365.28,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "um I built my own 3D I was working in 3D",
      "offset": 367.039,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "medical imaging so there was no 3D",
      "offset": 369.84,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "medical image annotation tool out there",
      "offset": 371.36,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "so I built my own one at at the time um",
      "offset": 372.88,
      "duration": 6.879
    },
    {
      "lang": "en",
      "text": "in fact I think that that notion was so",
      "offset": 377.12,
      "duration": 4.799
    },
    {
      "lang": "en",
      "text": "sort of prevalent in our strategic",
      "offset": 379.759,
      "duration": 6.16
    },
    {
      "lang": "en",
      "text": "thinking early on that uh in within 51",
      "offset": 381.919,
      "duration": 5.921
    },
    {
      "lang": "en",
      "text": "from the very beginning we explicitly",
      "offset": 385.919,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "did not support annotation directly. So",
      "offset": 387.84,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "in in order to annotate in 51 uh we",
      "offset": 390.479,
      "duration": 4.961
    },
    {
      "lang": "en",
      "text": "provided integrations with common",
      "offset": 393.44,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "annotator annotation tools like seat and",
      "offset": 395.44,
      "duration": 6.16
    },
    {
      "lang": "en",
      "text": "label studio label box other annotation",
      "offset": 398.24,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "tools mostly because there were so many",
      "offset": 401.6,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "of them out there and we felt like it",
      "offset": 403.52,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "was going to be hard to distinguish any",
      "offset": 405.6,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "new any tool you know from from any new",
      "offset": 407.28,
      "duration": 5.359
    },
    {
      "lang": "en",
      "text": "tool like ours from another to another",
      "offset": 411.12,
      "duration": 2.96
    },
    {
      "lang": "en",
      "text": "another tool that that was already out",
      "offset": 412.639,
      "duration": 3.761
    },
    {
      "lang": "en",
      "text": "there. We really wanted to emphasize the",
      "offset": 414.08,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "notion at the at the very core of what",
      "offset": 416.4,
      "duration": 5.359
    },
    {
      "lang": "en",
      "text": "we did is like you know you train you",
      "offset": 418.96,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "get some data and you train a model and",
      "offset": 421.759,
      "duration": 3.121
    },
    {
      "lang": "en",
      "text": "then it doesn't work as well as you",
      "offset": 423.44,
      "duration": 2.879
    },
    {
      "lang": "en",
      "text": "think. So you're like what do I do next?",
      "offset": 424.88,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "let me get more data and let me turn you",
      "offset": 426.319,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "kind of iterate this loop and we inject",
      "offset": 428.4,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "51 into the middle of that as like the",
      "offset": 430.639,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "analysis work right so kind of like",
      "offset": 432.96,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "turning the lights on in a dark hallway",
      "offset": 434.56,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "right it's like you get some data train",
      "offset": 436.4,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "some models then you do analysis within",
      "offset": 438.4,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "51 and then you kind of repeat this loop",
      "offset": 440.56,
      "duration": 6.32
    },
    {
      "lang": "en",
      "text": "um so um and that's why we made it",
      "offset": 444,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "flexible though right like because like",
      "offset": 446.88,
      "duration": 3.759
    },
    {
      "lang": "en",
      "text": "that loop is very is very team specific",
      "offset": 448.24,
      "duration": 5.359
    },
    {
      "lang": "en",
      "text": "in fact you know we I used to quip like",
      "offset": 450.639,
      "duration": 4.721
    },
    {
      "lang": "en",
      "text": "you know for every 100 machine learning",
      "offset": 453.599,
      "duration": 3.201
    },
    {
      "lang": "en",
      "text": "engineers out there there are 10,000",
      "offset": 455.36,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "ways of working, right? Because like",
      "offset": 456.8,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "everyone has their own way of doing",
      "offset": 459.199,
      "duration": 4.641
    },
    {
      "lang": "en",
      "text": "things really. So um so you know but but",
      "offset": 460.72,
      "duration": 7.12
    },
    {
      "lang": "en",
      "text": "to your point um we indeed we work with",
      "offset": 463.84,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "um we still maintain the integrations",
      "offset": 467.84,
      "duration": 3.199
    },
    {
      "lang": "en",
      "text": "with other annotation tools. Now even",
      "offset": 469.36,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "though you can annotate within 51 uh now",
      "offset": 471.039,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "at least through this autoleing stuff",
      "offset": 473.28,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "and actually in coming out in the summer",
      "offset": 474.639,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "you will be able to do some annotation",
      "offset": 476.4,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "cla let's say classical annotation",
      "offset": 478.8,
      "duration": 4.959
    },
    {
      "lang": "en",
      "text": "within 51. Um, but we we still integrate",
      "offset": 480.4,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "with all the other tools out there. Uh,",
      "offset": 483.759,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "and I think it's primarily because 51",
      "offset": 486.08,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "has become a little bit of a Rosetta",
      "offset": 489.199,
      "duration": 3.761
    },
    {
      "lang": "en",
      "text": "Stone for visual data formats. You know,",
      "offset": 490.72,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "it's very easy to get your data into 51",
      "offset": 492.96,
      "duration": 3.519
    },
    {
      "lang": "en",
      "text": "format and it's kind of like this",
      "offset": 495.28,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "universal format and then get it out in",
      "offset": 496.479,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "whatever format you want. But mo many of",
      "offset": 498.4,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "our commercial clients",
      "offset": 501.199,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "um do indeed have their own homegrown",
      "offset": 504.08,
      "duration": 4.239
    },
    {
      "lang": "en",
      "text": "annotation toolbox. And so it's",
      "offset": 506.639,
      "duration": 3.441
    },
    {
      "lang": "en",
      "text": "typically like the first the first month",
      "offset": 508.319,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "of the engagement with a new commercial",
      "offset": 510.08,
      "duration": 6.16
    },
    {
      "lang": "en",
      "text": "customer will be you know format um",
      "offset": 512.24,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "merging if you will normalization.",
      "offset": 516.24,
      "duration": 4.799
    },
    {
      "lang": "en",
      "text": "Normalization. Yeah good word. Yeah. Um",
      "offset": 518.24,
      "duration": 6.159
    },
    {
      "lang": "en",
      "text": "so uh but but we don't we we do the",
      "offset": 521.039,
      "duration": 5.601
    },
    {
      "lang": "en",
      "text": "other maybe the other asteris to add is",
      "offset": 524.399,
      "duration": 6.481
    },
    {
      "lang": "en",
      "text": "that um one thing you can do in 51",
      "offset": 526.64,
      "duration": 6.08
    },
    {
      "lang": "en",
      "text": "um which which we're very proud of is",
      "offset": 530.88,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "you can add your own panels. So 51 is",
      "offset": 532.72,
      "duration": 6.96
    },
    {
      "lang": "en",
      "text": "both a Python SDK and a web-based app,",
      "offset": 535.92,
      "duration": 6.4
    },
    {
      "lang": "en",
      "text": "right? And so in the app, you can extend",
      "offset": 539.68,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "the capabilities of the app through what",
      "offset": 542.32,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "we call panels, which are essentially",
      "offset": 544.32,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "plugins that have a visual component to",
      "offset": 545.76,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "them. Um, so we have actually seen some",
      "offset": 547.44,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "of our users and customers ch uh porting",
      "offset": 549.68,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "their their existing annotation",
      "offset": 553.44,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "capabilities directly into a 51 panel so",
      "offset": 555.44,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "that it's an integrated experience. Um,",
      "offset": 558.16,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "you know, I think that's the that's the",
      "offset": 561.04,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "way forward, right? I mean I think the",
      "offset": 563.04,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "indeed no many many u instances of",
      "offset": 564.88,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "problems are like are nuanced so that",
      "offset": 568.24,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "you do have slightly different changes",
      "offset": 570.48,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "and you want to be able to have your",
      "offset": 572.399,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "annotators next to your QA people you",
      "offset": 573.92,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "know next to your consumers downstream",
      "offset": 576.48,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "as model model developers. So having",
      "offset": 578.24,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "them all under one hood is important",
      "offset": 580.48,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "and so you talk about inserting uh",
      "offset": 583.36,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "analysis into that loop. talk a little",
      "offset": 586,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "bit about the nature of that analysis",
      "offset": 588.72,
      "duration": 6.64
    },
    {
      "lang": "en",
      "text": "and how it uh aids the user. Sure. So",
      "offset": 590.72,
      "duration": 7.04
    },
    {
      "lang": "en",
      "text": "like one key use case for that is right",
      "offset": 595.36,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "so you've you have you have a data set",
      "offset": 597.76,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "you have a model um obviously it doesn't",
      "offset": 599.36,
      "duration": 5.84
    },
    {
      "lang": "en",
      "text": "perform perfectly. So what can you do?",
      "offset": 602.24,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "So one question you might want to ask is",
      "offset": 605.2,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "uh what are the corner cases right like",
      "offset": 608,
      "duration": 4.959
    },
    {
      "lang": "en",
      "text": "where is where is it performing poorly",
      "offset": 610.08,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "kind of",
      "offset": 612.959,
      "duration": 5.201
    },
    {
      "lang": "en",
      "text": "exactly yes like and are there",
      "offset": 615.36,
      "duration": 5.599
    },
    {
      "lang": "en",
      "text": "commonalities or is there structure to",
      "offset": 618.16,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "that lack of performance. So we have",
      "offset": 620.959,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "capabilities in the system to for",
      "offset": 623.12,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "example",
      "offset": 625.12,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "um compute what we call hardness or",
      "offset": 626.64,
      "duration": 5.439
    },
    {
      "lang": "en",
      "text": "mistakenness that take your model logits",
      "offset": 629.12,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "on the data and manipulate them in",
      "offset": 632.079,
      "duration": 4.961
    },
    {
      "lang": "en",
      "text": "certain ways to then provide to you",
      "offset": 634.48,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "clusters of outputs that will that you",
      "offset": 637.04,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "can then visually analyze because in our",
      "offset": 639.2,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "view the human expert like the actual",
      "offset": 641.36,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "domain expert or the MLE in the loop is",
      "offset": 643.279,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "the one who is the only one who really",
      "offset": 646,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "can make the decision oh you know like",
      "offset": 647.44,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "whatever we're training like an",
      "offset": 649.04,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "pedestrian avoidance algorithm",
      "offset": 650.48,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "And it turns out there's no there's very",
      "offset": 652.32,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "few examples of suburban parking lots",
      "offset": 654.88,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "for some reason. You know, only the",
      "offset": 656.88,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "human really is going to identify that",
      "offset": 658.8,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "that was the failure mode of of the of",
      "offset": 660.64,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "the problem. So that's one typical",
      "offset": 662.8,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "analysis. Another analysis we use is",
      "offset": 664.8,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "visualization of embeddings. So you can",
      "offset": 668.32,
      "duration": 3.199
    },
    {
      "lang": "en",
      "text": "kind of you compute your embeddings",
      "offset": 670,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "either with a like 51 approved embedding",
      "offset": 671.519,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "model or you kind of bring your own your",
      "offset": 673.92,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "own embedding model for that. Uh and",
      "offset": 675.92,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "then you can visually interact in in the",
      "offset": 678.48,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "app uh to find",
      "offset": 681.04,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "um situations for mislabels on on your",
      "offset": 683.92,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "actual data set, right? So like you",
      "offset": 686.72,
      "duration": 2.88
    },
    {
      "lang": "en",
      "text": "visualize your embeddings, you can",
      "offset": 687.92,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "project the class labels on those",
      "offset": 689.6,
      "duration": 3.359
    },
    {
      "lang": "en",
      "text": "embeddings and ultimately we'll see like",
      "offset": 691.44,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "well this this big big mass of red",
      "offset": 692.959,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "labels here with some blue labels in",
      "offset": 695.279,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "them. Let me see what those blue labels",
      "offset": 697.04,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "are. So let me turn the red mask off,",
      "offset": 698.88,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "the red label off, and then I can get a",
      "offset": 700.72,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "view only into those blue labels. So",
      "offset": 702.72,
      "duration": 3.359
    },
    {
      "lang": "en",
      "text": "it's really kind of this this notion of",
      "offset": 704.24,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "like interactive analysis that is",
      "offset": 706.079,
      "duration": 5.121
    },
    {
      "lang": "en",
      "text": "imperative to to cleaning up your data",
      "offset": 708.72,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "and uh and finding corner cases where",
      "offset": 711.2,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "you might then go need to add more uh",
      "offset": 713.44,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "more labels for you for the task. Talk a",
      "offset": 715.519,
      "duration": 5.921
    },
    {
      "lang": "en",
      "text": "little bit about the evolutionary path",
      "offset": 718.88,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "towards",
      "offset": 721.44,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "uh automating labeling or auto labeling.",
      "offset": 722.959,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "Was this uh something that you started",
      "offset": 726.24,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "out intending to do or is it something",
      "offset": 728.959,
      "duration": 5.601
    },
    {
      "lang": "en",
      "text": "that arose you know as a result of",
      "offset": 731.2,
      "duration": 5.439
    },
    {
      "lang": "en",
      "text": "powerful foundation models for example",
      "offset": 734.56,
      "duration": 5.839
    },
    {
      "lang": "en",
      "text": "or something else? Yeah, I think it's um",
      "offset": 736.639,
      "duration": 5.681
    },
    {
      "lang": "en",
      "text": "I mean I'd be lying if I told you in",
      "offset": 740.399,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "2018 when we were first starting the",
      "offset": 742.32,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "company or 2007 when I started as",
      "offset": 744.079,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "faculty I was going to predict like oh",
      "offset": 746.399,
      "duration": 2.401
    },
    {
      "lang": "en",
      "text": "wait we're not going to need labeling",
      "offset": 747.76,
      "duration": 3.519
    },
    {
      "lang": "en",
      "text": "anymore. um that that that that couldn't",
      "offset": 748.8,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "be true, but it's not a it's not a it's",
      "offset": 751.279,
      "duration": 6.401
    },
    {
      "lang": "en",
      "text": "not necessarily strictly a function of",
      "offset": 754.56,
      "duration": 6.56
    },
    {
      "lang": "en",
      "text": "um just recent development. So",
      "offset": 757.68,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "um",
      "offset": 761.12,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "about maybe like two years ago uh we",
      "offset": 763.2,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "began to see a shift in the types of",
      "offset": 765.68,
      "duration": 4.959
    },
    {
      "lang": "en",
      "text": "conversations we would have with users",
      "offset": 768.88,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "of 51 where they were going from like",
      "offset": 770.639,
      "duration": 5.041
    },
    {
      "lang": "en",
      "text": "I'm strictly I'm sending all of my data",
      "offset": 773.2,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "to annotation to humans to annotate and",
      "offset": 775.68,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "spending just say round number I'm",
      "offset": 778.48,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "spending a million dollars on this and",
      "offset": 779.92,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "then I'm getting it back and instead of",
      "offset": 781.92,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "being able to use it all I'm finding out",
      "offset": 783.92,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "that actually I can only use 10% of it",
      "offset": 785.68,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "or 20% of which I mean dollars for",
      "offset": 788,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "dollars means they're throwing away a",
      "offset": 790.48,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "significant amount of money. And was",
      "offset": 792.16,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "that because of poor labeling",
      "offset": 794.32,
      "duration": 6.959
    },
    {
      "lang": "en",
      "text": "mislabels or No, I I think it's I mean",
      "offset": 797.6,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "obviously there were some mislabels, but",
      "offset": 801.279,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "I think there's just a lot of um similar",
      "offset": 802.88,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "cases being sent for labels and it",
      "offset": 805.68,
      "duration": 4.959
    },
    {
      "lang": "en",
      "text": "wasn't clear that that the right subset",
      "offset": 808.16,
      "duration": 4.799
    },
    {
      "lang": "en",
      "text": "of the data, right? Like data, it's easy",
      "offset": 810.639,
      "duration": 4.961
    },
    {
      "lang": "en",
      "text": "to find like typical plus plus minus a",
      "offset": 812.959,
      "duration": 5.601
    },
    {
      "lang": "en",
      "text": "couple sigma um cases, but what really",
      "offset": 815.6,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "matters is finding data along the",
      "offset": 818.56,
      "duration": 3.519
    },
    {
      "lang": "en",
      "text": "decision boundaries. And that's hard to",
      "offset": 820.8,
      "duration": 2.4
    },
    {
      "lang": "en",
      "text": "do if you don't know what the decision",
      "offset": 822.079,
      "duration": 3.281
    },
    {
      "lang": "en",
      "text": "boundaries are, right? So, so, so the",
      "offset": 823.2,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "conversation shifted over into into sort",
      "offset": 825.36,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "of that direction. And we began to to",
      "offset": 827.279,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "try to sort of think about ways of how",
      "offset": 830,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "are we going to help users even",
      "offset": 831.839,
      "duration": 2.8
    },
    {
      "lang": "en",
      "text": "ourselves? It's a great problem",
      "offset": 833.44,
      "duration": 2.639
    },
    {
      "lang": "en",
      "text": "technically, right? Like how do you find",
      "offset": 834.639,
      "duration": 2.961
    },
    {
      "lang": "en",
      "text": "data? How do you find the boundary",
      "offset": 836.079,
      "duration": 3.281
    },
    {
      "lang": "en",
      "text": "without knowing the boundary? How do you",
      "offset": 837.6,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "get there quickly? Right? So, so I wrote",
      "offset": 839.36,
      "duration": 6.479
    },
    {
      "lang": "en",
      "text": "a blog uh maybe January of 2024 with the",
      "offset": 841.76,
      "duration": 6.96
    },
    {
      "lang": "en",
      "text": "title annotation is dead. Uh and it was",
      "offset": 845.839,
      "duration": 4.961
    },
    {
      "lang": "en",
      "text": "intended to",
      "offset": 848.72,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "start this conversation generally around",
      "offset": 850.8,
      "duration": 3.599
    },
    {
      "lang": "en",
      "text": "like should we really be doing what",
      "offset": 852.8,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "we've been doing. It wasn't so much that",
      "offset": 854.399,
      "duration": 2.721
    },
    {
      "lang": "en",
      "text": "like okay no one's going to need",
      "offset": 856,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "annotated data. Obviously it's a",
      "offset": 857.12,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "welloiled machine. We know how",
      "offset": 859.6,
      "duration": 2.88
    },
    {
      "lang": "en",
      "text": "supervised machine learning works. we",
      "offset": 860.88,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "can measure we somewhat predictable",
      "offset": 862.48,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "performance things like that right but",
      "offset": 864.72,
      "duration": 4.559
    },
    {
      "lang": "en",
      "text": "it was really intended to catalyze this",
      "offset": 866.399,
      "duration": 5.281
    },
    {
      "lang": "en",
      "text": "notion that wait a second what we've",
      "offset": 869.279,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "been doing as annotation just blindly",
      "offset": 871.68,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "sending everything out for labeling is",
      "offset": 873.519,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "not the future the future cannot be that",
      "offset": 876.079,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "way and it just so happened that like",
      "offset": 878.639,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "okay we also be were seeing at that time",
      "offset": 880.399,
      "duration": 5.281
    },
    {
      "lang": "en",
      "text": "like foundation models come along that",
      "offset": 882.959,
      "duration": 4.961
    },
    {
      "lang": "en",
      "text": "could indeed actually replace a lot of",
      "offset": 885.68,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "those typical case human labels um and",
      "offset": 887.92,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "so you don't even need to to do that",
      "offset": 890.8,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "anymore. And so, so if if what was",
      "offset": 892.24,
      "duration": 4.719
    },
    {
      "lang": "en",
      "text": "annotation maybe we call that like",
      "offset": 895.12,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "annotation 1.0 and annotation 2.0 is",
      "offset": 896.959,
      "duration": 6.721
    },
    {
      "lang": "en",
      "text": "like you there's never blind send me",
      "offset": 900.24,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "data and get me labels. Annotation 2.0",
      "offset": 903.68,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "might only be a human answers questions",
      "offset": 905.92,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "asked by the by the agent if you will",
      "offset": 908.8,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "agentic labeling or something like that.",
      "offset": 911.12,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "To me that that's we're on that timeline",
      "offset": 913.12,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "and we're we're probably somewhere in",
      "offset": 915.36,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "the middle of it. Not just we like voxil",
      "offset": 916.72,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "51 but I think the community is",
      "offset": 919.199,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "generally we're moving down the line of",
      "offset": 921.12,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "okay we can expect to get decent labels",
      "offset": 923.839,
      "duration": 5.761
    },
    {
      "lang": "en",
      "text": "for common classes what can we expect",
      "offset": 926.8,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "for less common classes or you know I",
      "offset": 929.6,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "have a automotive scenario can we can",
      "offset": 932.48,
      "duration": 5.919
    },
    {
      "lang": "en",
      "text": "you predict uh my model performance",
      "offset": 935.6,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "without actually labeling the data",
      "offset": 938.399,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "beforehand things like that right and I",
      "offset": 939.76,
      "duration": 3.199
    },
    {
      "lang": "en",
      "text": "think we're right squarely in the middle",
      "offset": 941.519,
      "duration": 4.241
    },
    {
      "lang": "en",
      "text": "moving in in the direction of fewer you",
      "offset": 942.959,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "fewer sort of just here here's the media",
      "offset": 945.76,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "give me that give me the metadata um",
      "offset": 947.839,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "toward toward more like I think this is",
      "offset": 950.24,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "a teddy bear is this really a teddy bear",
      "offset": 952.959,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "you know and these are not technically",
      "offset": 955.44,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "speaking like those are not new",
      "offset": 957.759,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "directions right like people in the",
      "offset": 959.12,
      "duration": 2.88
    },
    {
      "lang": "en",
      "text": "community of machine learning and",
      "offset": 960.959,
      "duration": 2.24
    },
    {
      "lang": "en",
      "text": "computer vision have been looking at",
      "offset": 962,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "this for at least a decade or two right",
      "offset": 963.199,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "semi-s supervised learning is not new",
      "offset": 965.6,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "active learning is not new but I I think",
      "offset": 967.04,
      "duration": 4.799
    },
    {
      "lang": "en",
      "text": "what what we're seeing is that with this",
      "offset": 969.519,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "the creation of these semantically",
      "offset": 971.839,
      "duration": 3.521
    },
    {
      "lang": "en",
      "text": "enriched",
      "offset": 973.759,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "uh foundation models and embedding",
      "offset": 975.36,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "spaces. There's there's more of a",
      "offset": 976.959,
      "duration": 6.081
    },
    {
      "lang": "en",
      "text": "structure underlying structure to the to",
      "offset": 980,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "the the way data is represented in those",
      "offset": 983.04,
      "duration": 4.799
    },
    {
      "lang": "en",
      "text": "embedding spaces that we need to crunch",
      "offset": 985.12,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "on and understand more so that we can",
      "offset": 987.839,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "then go and do a better job of asking",
      "offset": 989.519,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "the right questions.",
      "offset": 991.519,
      "duration": 4.641
    },
    {
      "lang": "en",
      "text": "It strikes me that one of the lynch pins",
      "offset": 993.839,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "in kind of fully getting there, if you",
      "offset": 996.16,
      "duration": 5.679
    },
    {
      "lang": "en",
      "text": "will, is um being able to better",
      "offset": 998.24,
      "duration": 6.48
    },
    {
      "lang": "en",
      "text": "characterize or quantify uncertainty in",
      "offset": 1001.839,
      "duration": 4.881
    },
    {
      "lang": "en",
      "text": "these models. And that's been a a",
      "offset": 1004.72,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "challenge in the community for a really",
      "offset": 1006.72,
      "duration": 2.96
    },
    {
      "lang": "en",
      "text": "long time. Can you talk a little bit",
      "offset": 1008.24,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "about how embeddings and kind of the",
      "offset": 1009.68,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "semantic uh you know modeling that you",
      "offset": 1012.079,
      "duration": 5.841
    },
    {
      "lang": "en",
      "text": "just mentioned helps us maybe overcome",
      "offset": 1015.04,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "or sidestep that challenge. Um it's a",
      "offset": 1017.92,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "good point. I I do think uncertainty is",
      "offset": 1021.04,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "at the core of a lot of this a lot of",
      "offset": 1022.72,
      "duration": 4.959
    },
    {
      "lang": "en",
      "text": "this discussion. Indeed I agree. um you",
      "offset": 1024.88,
      "duration": 6.24
    },
    {
      "lang": "en",
      "text": "know in some sense if we really want a a",
      "offset": 1027.679,
      "duration": 5.841
    },
    {
      "lang": "en",
      "text": "true measure of uncertainty right like a",
      "offset": 1031.12,
      "duration": 4.719
    },
    {
      "lang": "en",
      "text": "classical you know like P of X type",
      "offset": 1033.52,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "uncertainty",
      "offset": 1035.839,
      "duration": 4.881
    },
    {
      "lang": "en",
      "text": "I don't think we have um I still don't",
      "offset": 1037.36,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "think we have made aren't quite there",
      "offset": 1040.72,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "yet yeah we haven't made much progress",
      "offset": 1042.48,
      "duration": 2.88
    },
    {
      "lang": "en",
      "text": "right we don't we still don't really",
      "offset": 1044.16,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "know how to do that but um there is",
      "offset": 1045.36,
      "duration": 6.4
    },
    {
      "lang": "en",
      "text": "enough structure in these embedding",
      "offset": 1049.12,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "spaces that",
      "offset": 1051.76,
      "duration": 6.4
    },
    {
      "lang": "en",
      "text": "um we can start to even leverage some",
      "offset": 1054.08,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "classical ideas. Like for example, we",
      "offset": 1058.16,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "have a tech report that that we've been",
      "offset": 1060.08,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "working on.",
      "offset": 1062.16,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "Um I can I can send you the link after",
      "offset": 1063.84,
      "duration": 7.36
    },
    {
      "lang": "en",
      "text": "the after the podcast here that um is",
      "offset": 1066.32,
      "duration": 7.2
    },
    {
      "lang": "en",
      "text": "able to",
      "offset": 1071.2,
      "duration": 4.479
    },
    {
      "lang": "en",
      "text": "take a take a take a classification",
      "offset": 1073.52,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "problem",
      "offset": 1075.679,
      "duration": 4.561
    },
    {
      "lang": "en",
      "text": "uh and embed it using these contemporary",
      "offset": 1077.36,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "foundation model embeddings. say,",
      "offset": 1080.24,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "you know, like like a ResNet 50 or Reset",
      "offset": 1083.36,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "18 for perceptual space and then",
      "offset": 1086,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "something like um",
      "offset": 1088.4,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "um why am I forgetting the the name of",
      "offset": 1090.96,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "the model now?",
      "offset": 1094.16,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "Not Coco but the very classic vision",
      "offset": 1096.24,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "language embedding model that everyone",
      "offset": 1098.48,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "uses clip sorry. So take a classic tech",
      "offset": 1099.84,
      "duration": 4.959
    },
    {
      "lang": "en",
      "text": "take a classic perceptual embedding like",
      "offset": 1103.12,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "resin 18 concatenate that with a clip",
      "offset": 1104.799,
      "duration": 5.041
    },
    {
      "lang": "en",
      "text": "embedding space uh and model within that",
      "offset": 1107.12,
      "duration": 5.679
    },
    {
      "lang": "en",
      "text": "space. And the problem we set out to ask",
      "offset": 1109.84,
      "duration": 5.839
    },
    {
      "lang": "en",
      "text": "is can we measure the difficulty the",
      "offset": 1112.799,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "expected classification difficulty in",
      "offset": 1115.679,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "that space without training the",
      "offset": 1117.919,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "downstream classifier. Right? Assuming",
      "offset": 1119.28,
      "duration": 4.639
    },
    {
      "lang": "en",
      "text": "say we only had labels on a small subset",
      "offset": 1121.679,
      "duration": 5.441
    },
    {
      "lang": "en",
      "text": "of the data like 100 samples per class",
      "offset": 1123.919,
      "duration": 8.321
    },
    {
      "lang": "en",
      "text": "for example. Um, and we use very simple",
      "offset": 1127.12,
      "duration": 8.16
    },
    {
      "lang": "en",
      "text": "shallow autoenccoders like two two three",
      "offset": 1132.24,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "layers autoenccoders. They're trainable",
      "offset": 1135.28,
      "duration": 5.84
    },
    {
      "lang": "en",
      "text": "in seconds per class. Uh, and if you",
      "offset": 1137.44,
      "duration": 6.16
    },
    {
      "lang": "en",
      "text": "take ratios of reconstruction errors,",
      "offset": 1141.12,
      "duration": 4.559
    },
    {
      "lang": "en",
      "text": "which is a measure of uncertainty to",
      "offset": 1143.6,
      "duration": 4.959
    },
    {
      "lang": "en",
      "text": "some degree, um, you can there are",
      "offset": 1145.679,
      "duration": 5.521
    },
    {
      "lang": "en",
      "text": "certain certain classes of those ratios",
      "offset": 1148.559,
      "duration": 4.961
    },
    {
      "lang": "en",
      "text": "that correlate very strongly with",
      "offset": 1151.2,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "downstream classifier performance. had",
      "offset": 1153.52,
      "duration": 3.279
    },
    {
      "lang": "en",
      "text": "you trained a full classifier on the",
      "offset": 1155.44,
      "duration": 4.239
    },
    {
      "lang": "en",
      "text": "whole data set. Um so so that that's",
      "offset": 1156.799,
      "duration": 4.801
    },
    {
      "lang": "en",
      "text": "what leads me to say that this is",
      "offset": 1159.679,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "evidence if you will right that that",
      "offset": 1161.6,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "there seems to be some structure in",
      "offset": 1163.6,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "these more rich semant semantically",
      "offset": 1165.76,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "enriched embedding spaces that um even",
      "offset": 1167.84,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "though we still don't have the right",
      "offset": 1171.12,
      "duration": 2.88
    },
    {
      "lang": "en",
      "text": "machinery to go and fully compute",
      "offset": 1172.16,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "uncertainty we at least can get say this",
      "offset": 1174,
      "duration": 4.799
    },
    {
      "lang": "en",
      "text": "is using using the term loosely kind of",
      "offset": 1176.88,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "like marginal uncertainty uh in that",
      "offset": 1178.799,
      "duration": 4.481
    },
    {
      "lang": "en",
      "text": "space",
      "offset": 1181.6,
      "duration": 8.92
    },
    {
      "lang": "en",
      "text": "and does that presume to some degree Um",
      "offset": 1183.28,
      "duration": 7.24
    },
    {
      "lang": "en",
      "text": "I'm thinking about like",
      "offset": 1192.08,
      "duration": 6.719
    },
    {
      "lang": "en",
      "text": "uh you know the the big challenge in uh",
      "offset": 1194.48,
      "duration": 6.079
    },
    {
      "lang": "en",
      "text": "in the object detection scenario is",
      "offset": 1198.799,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "going to be like or in the",
      "offset": 1200.559,
      "duration": 3.761
    },
    {
      "lang": "en",
      "text": "classification scenario rather is going",
      "offset": 1202.48,
      "duration": 5.199
    },
    {
      "lang": "en",
      "text": "to be like you know outliers or you know",
      "offset": 1204.32,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "rare things that you're trying to",
      "offset": 1207.679,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "classify. Um you know the kid running",
      "offset": 1209.12,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "out in the street relative to the street",
      "offset": 1211.679,
      "duration": 5.281
    },
    {
      "lang": "en",
      "text": "sign. Um does are there assumptions made",
      "offset": 1213.2,
      "duration": 8
    },
    {
      "lang": "en",
      "text": "on having examples of that rare data in",
      "offset": 1216.96,
      "duration": 9.04
    },
    {
      "lang": "en",
      "text": "your uh in your data set? Yeah. So there",
      "offset": 1221.2,
      "duration": 6.56
    },
    {
      "lang": "en",
      "text": "are no assumptions that that that we",
      "offset": 1226,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "know what that that they that they occur",
      "offset": 1227.76,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "in the data set. Uh but we also can't",
      "offset": 1230.08,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "deduce them. You know there's there's",
      "offset": 1232.32,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "sort of no way to figure those out,",
      "offset": 1233.76,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "right? That those are essentially the",
      "offset": 1235.36,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "the bay risk or the bay uncertainty,",
      "offset": 1237.679,
      "duration": 6.161
    },
    {
      "lang": "en",
      "text": "right? like um I I guess and essentially",
      "offset": 1239.84,
      "duration": 7.76
    },
    {
      "lang": "en",
      "text": "what what we what we've observed is that",
      "offset": 1243.84,
      "duration": 6.88
    },
    {
      "lang": "en",
      "text": "you know again there is the decision",
      "offset": 1247.6,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "boundary is always going to be the",
      "offset": 1250.72,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "challenge here right but like and since",
      "offset": 1251.84,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "we're not in that work for example we're",
      "offset": 1253.76,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "not updating the embedding at all we",
      "offset": 1256,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "don't we don't modulate the embedding to",
      "offset": 1258.32,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "try to pull them apart um if indeed a",
      "offset": 1259.919,
      "duration": 6.481
    },
    {
      "lang": "en",
      "text": "data set is dominated by those rare",
      "offset": 1263.12,
      "duration": 6.72
    },
    {
      "lang": "en",
      "text": "cases that that are hard to disentangle",
      "offset": 1266.4,
      "duration": 6.399
    },
    {
      "lang": "en",
      "text": "from from the the truth. Uh then I then",
      "offset": 1269.84,
      "duration": 6.4
    },
    {
      "lang": "en",
      "text": "it would be a a kryptonite for for our",
      "offset": 1272.799,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "for this modeling that we did. Um but in",
      "offset": 1276.24,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "typical situations",
      "offset": 1278.799,
      "duration": 4.481
    },
    {
      "lang": "en",
      "text": "um the means the mean is the mean,",
      "offset": 1281.28,
      "duration": 3.519
    },
    {
      "lang": "en",
      "text": "right? Like like typical but typical",
      "offset": 1283.28,
      "duration": 4.879
    },
    {
      "lang": "en",
      "text": "samples are typical samples. Um, so,",
      "offset": 1284.799,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "um, I guess what what I'd like to see",
      "offset": 1288.159,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "though, and we haven't done this, is,",
      "offset": 1289.919,
      "duration": 4.561
    },
    {
      "lang": "en",
      "text": "you know, I I've been hearing this",
      "offset": 1292.08,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "notion of like internet scale data sets",
      "offset": 1294.48,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "or re real scale data sets, uh, coming",
      "offset": 1296.4,
      "duration": 4.639
    },
    {
      "lang": "en",
      "text": "up in the vision community a lot in the",
      "offset": 1298.64,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "last couple years. I still don't have a",
      "offset": 1301.039,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "great sense for how to quantify what is",
      "offset": 1303.2,
      "duration": 5.359
    },
    {
      "lang": "en",
      "text": "like a an internet scale data set versus",
      "offset": 1305.919,
      "duration": 5.441
    },
    {
      "lang": "en",
      "text": "a canned off-the-shelf data set. But but",
      "offset": 1308.559,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "I my intuition says that the the closer",
      "offset": 1311.36,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "we get to like large scale internet",
      "offset": 1314.559,
      "duration": 5.041
    },
    {
      "lang": "en",
      "text": "scale data sets the more the mean",
      "offset": 1316.96,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "behavior is going to dominate. Um and I",
      "offset": 1319.6,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "think that's uh I think that's critical.",
      "offset": 1322.4,
      "duration": 4.639
    },
    {
      "lang": "en",
      "text": "Yeah. Again, I guess to maybe answer my",
      "offset": 1324.96,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "own question or comment on my own",
      "offset": 1327.039,
      "duration": 4.801
    },
    {
      "lang": "en",
      "text": "question like or comment rather, uh, you",
      "offset": 1328.72,
      "duration": 6.8
    },
    {
      "lang": "en",
      "text": "know, part of the the core",
      "offset": 1331.84,
      "duration": 6.079
    },
    {
      "lang": "en",
      "text": "value prop going into going back to that",
      "offset": 1335.52,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "initial observation you made is, hey, we",
      "offset": 1337.919,
      "duration": 4.721
    },
    {
      "lang": "en",
      "text": "spent a million dollars on labeling and",
      "offset": 1340.48,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "it wasn't all that useful. It would be",
      "offset": 1342.64,
      "duration": 6.32
    },
    {
      "lang": "en",
      "text": "useful just to autolel the stuff that's",
      "offset": 1344.799,
      "duration": 5.841
    },
    {
      "lang": "en",
      "text": "the same. you don't necessarily have to",
      "offset": 1348.96,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "autolel the the outliers to create",
      "offset": 1350.64,
      "duration": 6.399
    },
    {
      "lang": "en",
      "text": "value.",
      "offset": 1354.32,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "That is um that is the observation I",
      "offset": 1357.039,
      "duration": 5.681
    },
    {
      "lang": "en",
      "text": "think many of us are making you know",
      "offset": 1360.32,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "collectively right like why am I",
      "offset": 1362.72,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "spending this money on things that I'm",
      "offset": 1364.48,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "pretty sure even my own models may do",
      "offset": 1366.32,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "well with already um and I think the",
      "offset": 1368.96,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "challenge is",
      "offset": 1372,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "the I think there are two key challenges",
      "offset": 1374.48,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "really right like one is how can can we",
      "offset": 1375.84,
      "duration": 6.48
    },
    {
      "lang": "en",
      "text": "build a model of using the term model",
      "offset": 1379.28,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "loosely here but like a model of",
      "offset": 1382.32,
      "duration": 4.479
    },
    {
      "lang": "en",
      "text": "predictability right like how much of",
      "offset": 1384.64,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "that auto labeling can I expect to be",
      "offset": 1386.799,
      "duration": 4.721
    },
    {
      "lang": "en",
      "text": "useful? Um, and I think that that's",
      "offset": 1389.12,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "that's a key challenge. And then another",
      "offset": 1391.52,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "one is um given that I've just",
      "offset": 1393.2,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "autolelabeled things, how do I minimize",
      "offset": 1395.919,
      "duration": 5.601
    },
    {
      "lang": "en",
      "text": "the human work needed to do QA on the",
      "offset": 1398.64,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "output of that? Because if I have to",
      "offset": 1401.52,
      "duration": 4.639
    },
    {
      "lang": "en",
      "text": "have humans go and validate 100% of the",
      "offset": 1402.72,
      "duration": 4.959
    },
    {
      "lang": "en",
      "text": "auto labels, then I've not saved any",
      "offset": 1406.159,
      "duration": 3.441
    },
    {
      "lang": "en",
      "text": "time at all. Right? So if you how do we",
      "offset": 1407.679,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "get that number down? I think ultimately",
      "offset": 1409.6,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "that's that's those are those are two",
      "offset": 1411.6,
      "duration": 2.72
    },
    {
      "lang": "en",
      "text": "things that I've been thinking about",
      "offset": 1413.12,
      "duration": 3.679
    },
    {
      "lang": "en",
      "text": "fair amount lately. So yeah. Uh so you",
      "offset": 1414.32,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "guys recently released a report on",
      "offset": 1416.799,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "archive called autolelabeling data for",
      "offset": 1418.96,
      "duration": 8.079
    },
    {
      "lang": "en",
      "text": "object detection as well as a blog post",
      "offset": 1422.559,
      "duration": 7.36
    },
    {
      "lang": "en",
      "text": "uh zeroot autoleabeling rivals human",
      "offset": 1427.039,
      "duration": 5.441
    },
    {
      "lang": "en",
      "text": "performance that kind of captures all of",
      "offset": 1429.919,
      "duration": 6.961
    },
    {
      "lang": "en",
      "text": "these ideas. Can you um you know let's",
      "offset": 1432.48,
      "duration": 7.92
    },
    {
      "lang": "en",
      "text": "maybe start by talking about like how",
      "offset": 1436.88,
      "duration": 5.919
    },
    {
      "lang": "en",
      "text": "you are approaching autoleabeling. Is",
      "offset": 1440.4,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "there a a you know generic setup that",
      "offset": 1442.799,
      "duration": 4.481
    },
    {
      "lang": "en",
      "text": "you're using? Is it very use case",
      "offset": 1445.28,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "specific? Yeah, sounds good. So I I",
      "offset": 1447.28,
      "duration": 6.96
    },
    {
      "lang": "en",
      "text": "think that this this initial report and",
      "offset": 1450.24,
      "duration": 7.36
    },
    {
      "lang": "en",
      "text": "our initial work I guess in it it is",
      "offset": 1454.24,
      "duration": 6.08
    },
    {
      "lang": "en",
      "text": "probably the simplest setup that you can",
      "offset": 1457.6,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "imagine simply because we want I mean",
      "offset": 1460.32,
      "duration": 5.359
    },
    {
      "lang": "en",
      "text": "you know I'm been around for for some",
      "offset": 1463.2,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "time and I think like simple works right",
      "offset": 1465.679,
      "duration": 3.521
    },
    {
      "lang": "en",
      "text": "like you we need to get in the simplest",
      "offset": 1467.52,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "case before we can talk about more",
      "offset": 1469.2,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "complex settings. So basically the the",
      "offset": 1471.6,
      "duration": 5.199
    },
    {
      "lang": "en",
      "text": "assumptions are uh you have a foundation",
      "offset": 1473.76,
      "duration": 6.64
    },
    {
      "lang": "en",
      "text": "model that is relevant to the domain",
      "offset": 1476.799,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "you're operating in general natural",
      "offset": 1480.4,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "images",
      "offset": 1482.559,
      "duration": 4.961
    },
    {
      "lang": "en",
      "text": "whatever uh and then you have a a VLM in",
      "offset": 1484.24,
      "duration": 8.08
    },
    {
      "lang": "en",
      "text": "particular a um I guess a VLM in",
      "offset": 1487.52,
      "duration": 6.96
    },
    {
      "lang": "en",
      "text": "particular because we do prompt it with",
      "offset": 1492.32,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "with with labels. I mean the data sets",
      "offset": 1494.48,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "we work with are VOCC, Coco, BDD and",
      "offset": 1497.36,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "Elvis. So all of our all of our prompts",
      "offset": 1500.48,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "were pretty simple. So you know that's",
      "offset": 1502.96,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "where that's that's why I'm sort of",
      "offset": 1504.799,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "hesitating at VLM in the sense that you",
      "offset": 1506,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "know the foundation models we used are",
      "offset": 1508.72,
      "duration": 4.559
    },
    {
      "lang": "en",
      "text": "like YOLO world yolo e grounding dyno",
      "offset": 1510.24,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "concretely. So so they're not really",
      "offset": 1513.279,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "VLMs but but I mean I think more",
      "offset": 1515.12,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "generally speaking you could say BLM. Um",
      "offset": 1516.96,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "uh and you have a large corpus of",
      "offset": 1519.84,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "unlabelled data basically right and and",
      "offset": 1521.6,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "the idea is okay what would you have",
      "offset": 1524.08,
      "duration": 4.479
    },
    {
      "lang": "en",
      "text": "done in annotation 1.0 right? You would",
      "offset": 1526.4,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "have then sent all of those images to",
      "offset": 1528.559,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "humans to label. Uh you would have taken",
      "offset": 1530.24,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "the output from them and trained your",
      "offset": 1532.799,
      "duration": 3.441
    },
    {
      "lang": "en",
      "text": "model uh your object detector in this",
      "offset": 1534.48,
      "duration": 2.96
    },
    {
      "lang": "en",
      "text": "case. So we're only looking at object",
      "offset": 1536.24,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "detection and then you know computed",
      "offset": 1537.44,
      "duration": 4.719
    },
    {
      "lang": "en",
      "text": "some validation performance on a hold",
      "offset": 1540.64,
      "duration": 2.56
    },
    {
      "lang": "en",
      "text": "out set that was part of those",
      "offset": 1542.159,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "annotations as well. Uh in in our",
      "offset": 1543.2,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "autolelabeling scenario take the same",
      "offset": 1546.159,
      "duration": 4.801
    },
    {
      "lang": "en",
      "text": "unlabelled data take a foundation model",
      "offset": 1547.84,
      "duration": 6.4
    },
    {
      "lang": "en",
      "text": "uh generate those those labels auto auto",
      "offset": 1550.96,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "labels you know we call them now. Um",
      "offset": 1554.24,
      "duration": 6.319
    },
    {
      "lang": "en",
      "text": "similarly train a applesto apples sort",
      "offset": 1556.96,
      "duration": 6.959
    },
    {
      "lang": "en",
      "text": "of object detector uh we use like rtder",
      "offset": 1560.559,
      "duration": 6.24
    },
    {
      "lang": "en",
      "text": "yolo yolo 11 I think we use uh and then",
      "offset": 1563.919,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "compute the same validation performance",
      "offset": 1566.799,
      "duration": 3.521
    },
    {
      "lang": "en",
      "text": "we wanted to make it as apples to apples",
      "offset": 1568.24,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "there's nothing special about the domain",
      "offset": 1570.32,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "or the use case or what have you aside",
      "offset": 1572.32,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "from the fact that we're only using only",
      "offset": 1574.72,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "doing object detection other assumption",
      "offset": 1576.159,
      "duration": 4.801
    },
    {
      "lang": "en",
      "text": "other assumptions we made are only one",
      "offset": 1578.64,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "foundation model for input there's no",
      "offset": 1580.96,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "voting you know like there's there's",
      "offset": 1582.799,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "some recent work Like there was a paper",
      "offset": 1584.799,
      "duration": 4.961
    },
    {
      "lang": "en",
      "text": "um the Florence 2 model at CBPR I think",
      "offset": 1587.12,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "24 uh they had this interesting notion",
      "offset": 1589.76,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "of like a data engine where they're like",
      "offset": 1592,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "waiting over a multiple foundation model",
      "offset": 1593.44,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "outputs um we don't do any of that again",
      "offset": 1595.2,
      "duration": 5.599
    },
    {
      "lang": "en",
      "text": "simple simplest case here uh and we we",
      "offset": 1598,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "wanted to assess given these simple",
      "offset": 1600.799,
      "duration": 6.401
    },
    {
      "lang": "en",
      "text": "settings um you know like",
      "offset": 1603.36,
      "duration": 6.559
    },
    {
      "lang": "en",
      "text": "um what is the cost comparison in terms",
      "offset": 1607.2,
      "duration": 5.599
    },
    {
      "lang": "en",
      "text": "of money and time how well do the auto",
      "offset": 1609.919,
      "duration": 5.521
    },
    {
      "lang": "en",
      "text": "labels match human labels and How well",
      "offset": 1612.799,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "do the do the downstream object detector",
      "offset": 1615.44,
      "duration": 4.479
    },
    {
      "lang": "en",
      "text": "detectors match object detectors that",
      "offset": 1617.679,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "were trained on those human labels?",
      "offset": 1619.919,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "Those really were the three things. U",
      "offset": 1621.6,
      "duration": 5.199
    },
    {
      "lang": "en",
      "text": "and I should say concretely there's no",
      "offset": 1624.08,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "new new architecture here. There's no",
      "offset": 1626.799,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "there's no technical contribution that",
      "offset": 1629.12,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "way. The only parameter we vary is the",
      "offset": 1630.799,
      "duration": 6.401
    },
    {
      "lang": "en",
      "text": "threshold on the model confidence per",
      "offset": 1634.08,
      "duration": 7.36
    },
    {
      "lang": "en",
      "text": "object label per object auto label. uh",
      "offset": 1637.2,
      "duration": 6.079
    },
    {
      "lang": "en",
      "text": "and so we wanted to keep it as simple as",
      "offset": 1641.44,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "possible and just just because I think",
      "offset": 1643.279,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "there's a lot that we could do",
      "offset": 1646,
      "duration": 2.88
    },
    {
      "lang": "en",
      "text": "downstream right like in the future but",
      "offset": 1647.279,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "if we don't have a good baseline uh you",
      "offset": 1648.88,
      "duration": 3.679
    },
    {
      "lang": "en",
      "text": "know and I think concretely we approach",
      "offset": 1650.559,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "it this way not just because it's",
      "offset": 1652.559,
      "duration": 4.881
    },
    {
      "lang": "en",
      "text": "important to do things simple first but",
      "offset": 1654.64,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "we weren't aware of a baseline that",
      "offset": 1657.44,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "actually did this experiment uh you know",
      "offset": 1659.039,
      "duration": 5.201
    },
    {
      "lang": "en",
      "text": "that compares cost to ultimate gain in",
      "offset": 1660.96,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "in downstream performance or what have",
      "offset": 1664.24,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "you so yeah so that that's the way we",
      "offset": 1666.08,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "set it up uh is that clear any questions",
      "offset": 1668.88,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "about uh that setup? No, that's that's",
      "offset": 1671.6,
      "duration": 6.799
    },
    {
      "lang": "en",
      "text": "clear and simple. Okay. Okay. Great. Um",
      "offset": 1674.64,
      "duration": 6.8
    },
    {
      "lang": "en",
      "text": "so so again let me I can enumerate the",
      "offset": 1678.399,
      "duration": 5.361
    },
    {
      "lang": "en",
      "text": "the data sets we used VOCC, Coco, BD,",
      "offset": 1681.44,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "Elvis. Uh the foundation models were",
      "offset": 1683.76,
      "duration": 6.399
    },
    {
      "lang": "en",
      "text": "YOLO E YOLO World and Grounding Dino.",
      "offset": 1686.72,
      "duration": 5.679
    },
    {
      "lang": "en",
      "text": "Downstream models that we trained were",
      "offset": 1690.159,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "different sizes of YOLO 11. So YOLO 11 N",
      "offset": 1692.399,
      "duration": 7.681
    },
    {
      "lang": "en",
      "text": "S M L and X varies from like 2.6 6",
      "offset": 1695.919,
      "duration": 6.48
    },
    {
      "lang": "en",
      "text": "million to 57 million parameters and",
      "offset": 1700.08,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "then RT deer which has 33 million",
      "offset": 1702.399,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "parameters. So in some sense like you",
      "offset": 1704.64,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "know we wanted to take one model",
      "offset": 1706.48,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "architecture vary the its capacity and",
      "offset": 1707.76,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "then completely different model",
      "offset": 1710.72,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "architecture at a mean roughly the mean",
      "offset": 1712.48,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "capacity of the first one is is the way",
      "offset": 1714.48,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "I would think about those.",
      "offset": 1716.32,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "Um and so what what did we find? um you",
      "offset": 1718.399,
      "duration": 5.841
    },
    {
      "lang": "en",
      "text": "know",
      "offset": 1722.32,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "um actually I guess before that so to so",
      "offset": 1724.24,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "to do all this work we ultimately had to",
      "offset": 1726.32,
      "duration": 5.599
    },
    {
      "lang": "en",
      "text": "train on the order of 445",
      "offset": 1728.64,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "different models",
      "offset": 1731.919,
      "duration": 4.561
    },
    {
      "lang": "en",
      "text": "um you know so our our compute node was",
      "offset": 1733.76,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "running for some some month or something",
      "offset": 1736.48,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "like that to to generate all these",
      "offset": 1738.159,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "training experiments and uh the models",
      "offset": 1739.52,
      "duration": 9.039
    },
    {
      "lang": "en",
      "text": "that you know per data set uh we we we",
      "offset": 1743.679,
      "duration": 6.401
    },
    {
      "lang": "en",
      "text": "only use the standard prompts so we",
      "offset": 1748.559,
      "duration": 3.761
    },
    {
      "lang": "en",
      "text": "didn't we didn't do any prompt expansion",
      "offset": 1750.08,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "or generalization in any way. Uh so it",
      "offset": 1752.32,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "was basically you know like you",
      "offset": 1755.2,
      "duration": 2.24
    },
    {
      "lang": "en",
      "text": "generally have to prompt these models",
      "offset": 1756.32,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "with every class label with a period",
      "offset": 1757.44,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "after it. Ultimately that's all we did.",
      "offset": 1759.52,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "Uh so what do we find from a cost",
      "offset": 1762,
      "duration": 6.88
    },
    {
      "lang": "en",
      "text": "standpoint? So um you using offtheshelf",
      "offset": 1763.76,
      "duration": 7.519
    },
    {
      "lang": "en",
      "text": "established numbers for how much things",
      "offset": 1768.88,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "cost to to annotate. So seven cents per",
      "offset": 1771.279,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "box for example. Um, we estimate that",
      "offset": 1773.84,
      "duration": 4.959
    },
    {
      "lang": "en",
      "text": "collectively these four data sets would",
      "offset": 1776.799,
      "duration": 5.041
    },
    {
      "lang": "en",
      "text": "cost about $124,000 to have humans",
      "offset": 1778.799,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "annotate them. Just one pass of humans",
      "offset": 1781.84,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "annotation. So, no QA, nothing like",
      "offset": 1783.919,
      "duration": 5.601
    },
    {
      "lang": "en",
      "text": "that. Um, and that the comparable cost",
      "offset": 1785.919,
      "duration": 8
    },
    {
      "lang": "en",
      "text": "in auto labeling like GPU rental on AWS",
      "offset": 1789.52,
      "duration": 9.68
    },
    {
      "lang": "en",
      "text": "uh was a $118 uh for for an Nvidia L40S.",
      "offset": 1793.919,
      "duration": 9.441
    },
    {
      "lang": "en",
      "text": "A18 total for the 400 something models.",
      "offset": 1799.2,
      "duration": 8.32
    },
    {
      "lang": "en",
      "text": "Dollar 18 total to do yeah a18 total to",
      "offset": 1803.36,
      "duration": 5.679
    },
    {
      "lang": "en",
      "text": "produce all the labels. So for all the",
      "offset": 1807.52,
      "duration": 3.519
    },
    {
      "lang": "en",
      "text": "models well actually no to produce the",
      "offset": 1809.039,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "labels which is only done once not not",
      "offset": 1811.039,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "so inference not the creation of the",
      "offset": 1813.2,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "models not the training of not the",
      "offset": 1815.039,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "training of the models. Okay got it yeah",
      "offset": 1817.6,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "in fact I don't have the number for how",
      "offset": 1819.36,
      "duration": 2.799
    },
    {
      "lang": "en",
      "text": "long it took to train all the models. I",
      "offset": 1820.72,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "mean we have a box we did this on a box",
      "offset": 1822.159,
      "duration": 4.801
    },
    {
      "lang": "en",
      "text": "of six GPU six L40S's",
      "offset": 1824.24,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "and it took about a month so whatever",
      "offset": 1826.96,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "that cost is. So it's it's but that's",
      "offset": 1829.36,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "that's the full research experiment uh",
      "offset": 1831.44,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "not not not the cost analysis. So so",
      "offset": 1833.36,
      "duration": 5.039
    },
    {
      "lang": "en",
      "text": "it's you know six orders of magnitude",
      "offset": 1836.08,
      "duration": 4.479
    },
    {
      "lang": "en",
      "text": "more expensive to have humans label than",
      "offset": 1838.399,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "have models label. So that that's but",
      "offset": 1840.559,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "that's expect so it's not surprising",
      "offset": 1842.799,
      "duration": 4.561
    },
    {
      "lang": "en",
      "text": "that the cost is is greatly different,",
      "offset": 1844.559,
      "duration": 5.201
    },
    {
      "lang": "en",
      "text": "right? 124,000 to to a dollar, right?",
      "offset": 1847.36,
      "duration": 4.559
    },
    {
      "lang": "en",
      "text": "That's that's expected, but but I think",
      "offset": 1849.76,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "quantifying it is is still something",
      "offset": 1851.919,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "that we we weren't aware someone had",
      "offset": 1854,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "done, right? So I think even putting a",
      "offset": 1856.24,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "pin in the ground is important to do in",
      "offset": 1857.76,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "in science. Um ultimately it only",
      "offset": 1859.44,
      "duration": 4.959
    },
    {
      "lang": "en",
      "text": "matters if the labels are good. Exactly.",
      "offset": 1861.84,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "Ultimately only matters if the labels",
      "offset": 1864.399,
      "duration": 5.441
    },
    {
      "lang": "en",
      "text": "are good. Um and I I will get there. But",
      "offset": 1866.08,
      "duration": 7.04
    },
    {
      "lang": "en",
      "text": "one one other aspect is is the time",
      "offset": 1869.84,
      "duration": 5.199
    },
    {
      "lang": "en",
      "text": "though it took as well. Right. So we",
      "offset": 1873.12,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "estimate that it would take about 6,000",
      "offset": 1875.039,
      "duration": 5.441
    },
    {
      "lang": "en",
      "text": "hours of humans to label these four data",
      "offset": 1878,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "sets. And this is based on a paper from",
      "offset": 1880.48,
      "duration": 6.16
    },
    {
      "lang": "en",
      "text": "Kristen Groman's group in I think ICCB",
      "offset": 1884,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "2017 or 2019 that where they were kind",
      "offset": 1886.64,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "of like measuring the value of of",
      "offset": 1889.44,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "labeling or the cost of labeling. Uh so",
      "offset": 1890.72,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "6,000 hours to one hour to one and a",
      "offset": 1892.96,
      "duration": 5.92
    },
    {
      "lang": "en",
      "text": "quarter hours you know so about four",
      "offset": 1895.84,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "orders of magnitude different difference",
      "offset": 1898.88,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "there as well. So you can do it fast and",
      "offset": 1900.159,
      "duration": 5.281
    },
    {
      "lang": "en",
      "text": "you can do it cheaply but does it does",
      "offset": 1902,
      "duration": 6.88
    },
    {
      "lang": "en",
      "text": "it work like does it matter? Um so you",
      "offset": 1905.44,
      "duration": 7.44
    },
    {
      "lang": "en",
      "text": "said 6,000 hours to one hour.",
      "offset": 1908.88,
      "duration": 7.12
    },
    {
      "lang": "en",
      "text": "um that 1 hour is",
      "offset": 1912.88,
      "duration": 6.159
    },
    {
      "lang": "en",
      "text": "spent labeling or",
      "offset": 1916,
      "duration": 6.559
    },
    {
      "lang": "en",
      "text": "600 hours 6,000 hours of human labeling",
      "offset": 1919.039,
      "duration": 7.441
    },
    {
      "lang": "en",
      "text": "to 1.27 hours of GPU labeling of GPU",
      "offset": 1922.559,
      "duration": 7.281
    },
    {
      "lang": "en",
      "text": "inference labeling. Got it. Okay. Um so",
      "offset": 1926.48,
      "duration": 5.919
    },
    {
      "lang": "en",
      "text": "you we're just talking about wall clock",
      "offset": 1929.84,
      "duration": 6.8
    },
    {
      "lang": "en",
      "text": "time as a comparison as opposed to 6,000",
      "offset": 1932.399,
      "duration": 6.081
    },
    {
      "lang": "en",
      "text": "hours as a measure of some cost versus",
      "offset": 1936.64,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "an hour as a measure of some other cost.",
      "offset": 1938.48,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "Exactly. Wall cont very very",
      "offset": 1941.12,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "straightforward. Yeah. Yeah. Okay. So,",
      "offset": 1943.2,
      "duration": 7.52
    },
    {
      "lang": "en",
      "text": "so how how do the models perform? Um is",
      "offset": 1945.84,
      "duration": 6.719
    },
    {
      "lang": "en",
      "text": "we looked at looked at it along two",
      "offset": 1950.72,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "different axes, right? Like one axis is",
      "offset": 1952.559,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "how well can we reproduce",
      "offset": 1954.88,
      "duration": 4.799
    },
    {
      "lang": "en",
      "text": "the human labels which which is",
      "offset": 1957.519,
      "duration": 5.121
    },
    {
      "lang": "en",
      "text": "important, right? Um just as a measure",
      "offset": 1959.679,
      "duration": 4.641
    },
    {
      "lang": "en",
      "text": "of they are in some sense a gold",
      "offset": 1962.64,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "standard. um al although they're not a",
      "offset": 1964.32,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "perfect gold standard you know for",
      "offset": 1967.2,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "example one of one of the one of the",
      "offset": 1968.88,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "data sets has an image of donuts",
      "offset": 1971.6,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "and these the there are these two trays",
      "offset": 1974.64,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "of donuts in in the image I actually",
      "offset": 1976.32,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "forget which data set it comes from",
      "offset": 1978.88,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "maybe Elvis",
      "offset": 1980.32,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "um and in the human labels there are",
      "offset": 1982.08,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "it's a mess actually so if there are",
      "offset": 1985.2,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "something like six dozen donuts per tray",
      "offset": 1987.44,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "across both of them roughly that that's",
      "offset": 1990.32,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "probably about what it is maybe a little",
      "offset": 1992,
      "duration": 2.96
    },
    {
      "lang": "en",
      "text": "less than that four dozen",
      "offset": 1993.6,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "Um humans sometimes",
      "offset": 1994.96,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "this is this is actually this is real",
      "offset": 1997.6,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "data right they will only label three of",
      "offset": 1999.039,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "the donuts um a handful of the donuts",
      "offset": 2001.36,
      "duration": 4.799
    },
    {
      "lang": "en",
      "text": "right um or sounds about right this",
      "offset": 2003.919,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "stuff is tedious it's exactly ted right",
      "offset": 2006.159,
      "duration": 6.161
    },
    {
      "lang": "en",
      "text": "it's so tedious um similarly they might",
      "offset": 2009.519,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "group together six donuts as one donut",
      "offset": 2012.32,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "and actually one one example we have is",
      "offset": 2014.559,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "the whole entire tray essentially the",
      "offset": 2016.48,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "whole image donuts is labeled as donuts",
      "offset": 2018.399,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "right which is just like this is to this",
      "offset": 2020.96,
      "duration": 7.04
    },
    {
      "lang": "en",
      "text": "is like complete ontological failure of",
      "offset": 2023.919,
      "duration": 6.401
    },
    {
      "lang": "en",
      "text": "the of the domain, right? So whereas",
      "offset": 2028,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "like the the auto labels, okay, they",
      "offset": 2030.32,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "miss some of the donuts, but it doesn't",
      "offset": 2032.72,
      "duration": 3.439
    },
    {
      "lang": "en",
      "text": "make the grow the egregious error of",
      "offset": 2034.32,
      "duration": 3.199
    },
    {
      "lang": "en",
      "text": "like grouping them together and so on.",
      "offset": 2036.159,
      "duration": 2.4
    },
    {
      "lang": "en",
      "text": "So that that was that was a great",
      "offset": 2037.519,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "finding, I guess. But so but if if you",
      "offset": 2038.559,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "do assume that human labels are perfect",
      "offset": 2040.799,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "or are the gold standard um we have",
      "offset": 2042.96,
      "duration": 5.439
    },
    {
      "lang": "en",
      "text": "found that um performance does vary",
      "offset": 2045.519,
      "duration": 6.241
    },
    {
      "lang": "en",
      "text": "drastically based on the configuration",
      "offset": 2048.399,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "that we we call it configuration but in",
      "offset": 2051.76,
      "duration": 2.72
    },
    {
      "lang": "en",
      "text": "this case it's essentially what",
      "offset": 2053.359,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "confidence threshold you use. Just say",
      "offset": 2054.48,
      "duration": 5.439
    },
    {
      "lang": "en",
      "text": "it's it's a it's a it's a we keep this R",
      "offset": 2057.44,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "label or not basically. Um so that",
      "offset": 2059.919,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "confidence threshold is coming from the",
      "offset": 2062.56,
      "duration": 3.519
    },
    {
      "lang": "en",
      "text": "model coming straight from the model.",
      "offset": 2064.399,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "yellow or what what have you right",
      "offset": 2066.079,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "without without doing any calibration at",
      "offset": 2068,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "all. So we just again took it took it as",
      "offset": 2070.159,
      "duration": 5.041
    },
    {
      "lang": "en",
      "text": "is black box. Um we did we do notice",
      "offset": 2072.72,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "that grounding dyno has the greatest",
      "offset": 2075.2,
      "duration": 4.639
    },
    {
      "lang": "en",
      "text": "variation in performance uh of the of",
      "offset": 2077.119,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "the three foundation models whereas like",
      "offset": 2079.839,
      "duration": 5.201
    },
    {
      "lang": "en",
      "text": "yolo W and YOLO E are I mean okay maybe",
      "offset": 2081.599,
      "duration": 5.361
    },
    {
      "lang": "en",
      "text": "at the boundaries of the curve that you",
      "offset": 2085.04,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "know it does fall off pretty drastically",
      "offset": 2086.96,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "but from confidence like 3 to 7 it's a",
      "offset": 2088.48,
      "duration": 5.919
    },
    {
      "lang": "en",
      "text": "pretty flat it's a plateaued plateaued",
      "offset": 2091.76,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "performance in terms of like F1 to the",
      "offset": 2094.399,
      "duration": 4.001
    },
    {
      "lang": "en",
      "text": "to the human labeling",
      "offset": 2096.32,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "um so that that I mean that's a good",
      "offset": 2098.4,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "finding right so like in some sense in",
      "offset": 2100.16,
      "duration": 5.679
    },
    {
      "lang": "en",
      "text": "each for each of the three foundation",
      "offset": 2102.96,
      "duration": 6.08
    },
    {
      "lang": "en",
      "text": "models we used, if you're able to find",
      "offset": 2105.839,
      "duration": 6.561
    },
    {
      "lang": "en",
      "text": "the right confidence threshold, you can",
      "offset": 2109.04,
      "duration": 6.559
    },
    {
      "lang": "en",
      "text": "essentially get almost perfect F1 score.",
      "offset": 2112.4,
      "duration": 4.959
    },
    {
      "lang": "en",
      "text": "You maybe that's a little bit reaching.",
      "offset": 2115.599,
      "duration": 3.041
    },
    {
      "lang": "en",
      "text": "You can get very good, let's say",
      "offset": 2117.359,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "comparable F1 score to make it usable.",
      "offset": 2118.64,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "Um the challenge is though in practice",
      "offset": 2121.359,
      "duration": 7.041
    },
    {
      "lang": "en",
      "text": "you don't necessarily have the you you",
      "offset": 2124.4,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "can't calibrate that well but you'll",
      "offset": 2128.4,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "have to get some data labeled to do your",
      "offset": 2130.16,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "calibration of your confidence and then",
      "offset": 2132.4,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "go and hope that that m that that",
      "offset": 2134,
      "duration": 3.359
    },
    {
      "lang": "en",
      "text": "extrapolates to the rest of the data",
      "offset": 2135.68,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "set. Um so so we really think the right",
      "offset": 2137.359,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "measure is the other axis that we",
      "offset": 2140.64,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "measured which was okay take the auto",
      "offset": 2142.079,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "label labels and uh predict their",
      "offset": 2144.4,
      "duration": 5.84
    },
    {
      "lang": "en",
      "text": "downstream or not predict measure their",
      "offset": 2147.839,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "downstream model performance. So this is",
      "offset": 2150.24,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "where we train the 445 models and do the",
      "offset": 2152,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "and do the analysis there. uh and and",
      "offset": 2154.96,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "what we found is that uh in all cases",
      "offset": 2157.68,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "for each of the different three variants",
      "offset": 2160.64,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "of foundation model across all four data",
      "offset": 2162.8,
      "duration": 6.08
    },
    {
      "lang": "en",
      "text": "sets we can get within um relative",
      "offset": 2164.96,
      "duration": 6.24
    },
    {
      "lang": "en",
      "text": "numbers in the in the 80s and 90s",
      "offset": 2168.88,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "performance of whatever like that you",
      "offset": 2171.2,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "know which say yolo 11s human",
      "offset": 2173.52,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "performance is these numbers are not",
      "offset": 2176.56,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "from the paper but like say 60% accuracy",
      "offset": 2178.56,
      "duration": 7.519
    },
    {
      "lang": "en",
      "text": "an autoleabeled autolel trained yolo 11s",
      "offset": 2181.92,
      "duration": 6.08
    },
    {
      "lang": "en",
      "text": "can get like 55% performance or",
      "offset": 2186.079,
      "duration": 2.961
    },
    {
      "lang": "en",
      "text": "something like that. Very close",
      "offset": 2188,
      "duration": 3.359
    },
    {
      "lang": "en",
      "text": "performance. Um, and interestingly there",
      "offset": 2189.04,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "there's there are some interesting",
      "offset": 2191.359,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "findings here. Um, one is that if you're",
      "offset": 2192.4,
      "duration": 5.679
    },
    {
      "lang": "en",
      "text": "willing to like save the money you would",
      "offset": 2195.76,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "have spent on annotation and instead",
      "offset": 2198.079,
      "duration": 5.121
    },
    {
      "lang": "en",
      "text": "train a bigger model for compute and and",
      "offset": 2200.4,
      "duration": 5.84
    },
    {
      "lang": "en",
      "text": "spend that money like over time you can,",
      "offset": 2203.2,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "you know, apples to apples you can",
      "offset": 2206.24,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "actually outperform the smaller model,",
      "offset": 2207.68,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "right? So YOLO 11S has 9 million",
      "offset": 2210.24,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "parameters, YOLO 11N has 2.6 six million",
      "offset": 2212.56,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "parameters. If you're willing to train",
      "offset": 2215.92,
      "duration": 3.679
    },
    {
      "lang": "en",
      "text": "the yellow 11s, you can outperform the",
      "offset": 2217.76,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "yellow 11N um in many of our in many of",
      "offset": 2219.599,
      "duration": 5.041
    },
    {
      "lang": "en",
      "text": "the results we have as well, which is",
      "offset": 2222.72,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "which is a cool result, I think. Um and",
      "offset": 2224.64,
      "duration": 6.24
    },
    {
      "lang": "en",
      "text": "but but even more interestingly that the",
      "offset": 2228.24,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "best downstream model performance comes",
      "offset": 2230.88,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "for confidence thresholds filtering in",
      "offset": 2233.52,
      "duration": 5.599
    },
    {
      "lang": "en",
      "text": "and out the auto labels that is not that",
      "offset": 2236,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "are not aligned with the top F1",
      "offset": 2239.119,
      "duration": 5.441
    },
    {
      "lang": "en",
      "text": "performance. Right? So in the sense that",
      "offset": 2241.04,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "when you're generating auto labels, if",
      "offset": 2244.56,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "you try to maximize your match to human",
      "offset": 2246.72,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "performance, you won't necessarily get",
      "offset": 2249.44,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "the best downstream object detector",
      "offset": 2251.92,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "performance. Instead, what we found is",
      "offset": 2253.76,
      "duration": 5.92
    },
    {
      "lang": "en",
      "text": "that lowering your confidence threshold",
      "offset": 2256.64,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "to somewhat egregiously low numbers like",
      "offset": 2259.68,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "0.12",
      "offset": 2262.16,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "where you will have noisy outputs in the",
      "offset": 2263.839,
      "duration": 4.881
    },
    {
      "lang": "en",
      "text": "auto labels ultimately maps to better",
      "offset": 2266,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "downstream performance. And I thought",
      "offset": 2268.72,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "this was really exciting. It's not it's",
      "offset": 2271.68,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "not necessarily super counterintuitive,",
      "offset": 2273.68,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "but also consistent with",
      "offset": 2276,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "uh other results we're seeing recently",
      "offset": 2279.44,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "with like there was a paper within the",
      "offset": 2281.44,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "past couple weeks about um RL",
      "offset": 2282.96,
      "duration": 4.639
    },
    {
      "lang": "en",
      "text": "fine-tuning. like it doesn't really",
      "offset": 2286,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "matter what the answers are. Like you",
      "offset": 2287.599,
      "duration": 6.721
    },
    {
      "lang": "en",
      "text": "can just and it and the general",
      "offset": 2290.32,
      "duration": 9.36
    },
    {
      "lang": "en",
      "text": "idea is consistent with um you know",
      "offset": 2294.32,
      "duration": 6.799
    },
    {
      "lang": "en",
      "text": "machine learning just seems to perform",
      "offset": 2299.68,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "better when there's the right amount of",
      "offset": 2301.119,
      "duration": 3.441
    },
    {
      "lang": "en",
      "text": "noise like just like dropout and all",
      "offset": 2302.8,
      "duration": 3.279
    },
    {
      "lang": "en",
      "text": "these other things that we've done to",
      "offset": 2304.56,
      "duration": 3.039
    },
    {
      "lang": "en",
      "text": "like create noise when we're training",
      "offset": 2306.079,
      "duration": 4.641
    },
    {
      "lang": "en",
      "text": "models. Um you know so from that",
      "offset": 2307.599,
      "duration": 4.881
    },
    {
      "lang": "en",
      "text": "perspective maybe not surprising but",
      "offset": 2310.72,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "counterintuitive. Absolutely. I think",
      "offset": 2312.48,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "it's just another chip or you know",
      "offset": 2314.48,
      "duration": 6.08
    },
    {
      "lang": "en",
      "text": "another tile in the mosaic of of",
      "offset": 2317.28,
      "duration": 6.16
    },
    {
      "lang": "en",
      "text": "messaging around like machine learning",
      "offset": 2320.56,
      "duration": 6.32
    },
    {
      "lang": "en",
      "text": "need models need data and the data does",
      "offset": 2323.44,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "not have to be perfect but more is",
      "offset": 2326.88,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "better than hike better more is better",
      "offset": 2328.56,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "than better in some sense I don't have",
      "offset": 2330.8,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "the right like mantra yet but but but",
      "offset": 2332.64,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "it's indeed it's pointing in that",
      "offset": 2335.28,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "direction um and and I think you know in",
      "offset": 2336.88,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "some sense what I what I hope for this",
      "offset": 2339.359,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "particular report is that it gets",
      "offset": 2341.04,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "recognized amongst in in the community",
      "offset": 2343.359,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "as rather concrete and up-to-date",
      "offset": 2345.52,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "evidence for for not only that",
      "offset": 2348.079,
      "duration": 4.721
    },
    {
      "lang": "en",
      "text": "counterintuitive nature but but like a",
      "offset": 2350.56,
      "duration": 5.279
    },
    {
      "lang": "en",
      "text": "way of measuring",
      "offset": 2352.8,
      "duration": 6.4
    },
    {
      "lang": "en",
      "text": "um how well these contemporary",
      "offset": 2355.839,
      "duration": 5.601
    },
    {
      "lang": "en",
      "text": "foundation models perform in the context",
      "offset": 2359.2,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "of autoleing. Yeah. Thinking about more",
      "offset": 2361.44,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "is better than better. It's more is",
      "offset": 2364,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "better than better if better is a metric",
      "offset": 2366.4,
      "duration": 4.959
    },
    {
      "lang": "en",
      "text": "of like human label performance. But if",
      "offset": 2368.4,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "better is a measure of like having the",
      "offset": 2371.359,
      "duration": 5.041
    },
    {
      "lang": "en",
      "text": "right data uh meaning outliers and and",
      "offset": 2373.2,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "these other things identified then you",
      "offset": 2376.4,
      "duration": 5.439
    },
    {
      "lang": "en",
      "text": "know that is you know better. Uh, and so",
      "offset": 2378.64,
      "duration": 6.479
    },
    {
      "lang": "en",
      "text": "I'm kind of using that as a segue to",
      "offset": 2381.839,
      "duration": 6.161
    },
    {
      "lang": "en",
      "text": "um to prompt you to kind of circle back",
      "offset": 2385.119,
      "duration": 5.201
    },
    {
      "lang": "en",
      "text": "on this idea of like so now that you",
      "offset": 2388,
      "duration": 5.359
    },
    {
      "lang": "en",
      "text": "know we understand that zeroot",
      "offset": 2390.32,
      "duration": 6.88
    },
    {
      "lang": "en",
      "text": "autoleabeling you know works well like",
      "offset": 2393.359,
      "duration": 7.121
    },
    {
      "lang": "en",
      "text": "if I'm building you know these kind of",
      "offset": 2397.2,
      "duration": 4.879
    },
    {
      "lang": "en",
      "text": "object detection models or I've got an",
      "offset": 2400.48,
      "duration": 3.599
    },
    {
      "lang": "en",
      "text": "application or systems that's using it",
      "offset": 2402.079,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "like how do I take that knowledge and",
      "offset": 2404.079,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "kind of build a system around it that",
      "offset": 2405.76,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "helps me zero in on you know what's",
      "offset": 2407.599,
      "duration": 5.121
    },
    {
      "lang": "en",
      "text": "really important and identify you know",
      "offset": 2410.56,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "these outliers that we've talked about",
      "offset": 2412.72,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "and overall",
      "offset": 2414.32,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "like um you know build a better system",
      "offset": 2416.56,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "like in in light of all the trade-offs",
      "offset": 2419.76,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "that you've kind of me mentioned I think",
      "offset": 2422,
      "duration": 5.359
    },
    {
      "lang": "en",
      "text": "it's a great um",
      "offset": 2424.96,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "great great point or great great segue",
      "offset": 2427.359,
      "duration": 5.601
    },
    {
      "lang": "en",
      "text": "not noting that I think it's the",
      "offset": 2430.16,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "experiment you hinted at right like if",
      "offset": 2432.96,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "if we could get better data at the",
      "offset": 2434.88,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "boundaries then we could really measure",
      "offset": 2437.44,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "how much more is important. Um, how to",
      "offset": 2439.44,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "do that is really hard. Um, but and but",
      "offset": 2442.16,
      "duration": 4.959
    },
    {
      "lang": "en",
      "text": "I but I'd love to spend the next year",
      "offset": 2444.8,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "thinking about that problem. But anyway,",
      "offset": 2447.119,
      "duration": 5.441
    },
    {
      "lang": "en",
      "text": "so so so but I think the",
      "offset": 2448.32,
      "duration": 5.92
    },
    {
      "lang": "en",
      "text": "so so what has this taught us in some",
      "offset": 2452.56,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "sense, right? like okay these",
      "offset": 2454.24,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "experiments are typically like these",
      "offset": 2455.92,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "data sets that we've that we've used in",
      "offset": 2458.56,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "this experiment are are not they're",
      "offset": 2460.24,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "they're mostly like let's say kind of",
      "offset": 2463.68,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "like in in domain data sets if you will",
      "offset": 2465.2,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "right for the foundation models we used",
      "offset": 2467.52,
      "duration": 6.559
    },
    {
      "lang": "en",
      "text": "right so VOC coco even BDD like these mo",
      "offset": 2469.599,
      "duration": 6.161
    },
    {
      "lang": "en",
      "text": "most or all of the classes in those",
      "offset": 2474.079,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "three data sets are are at least covered",
      "offset": 2475.76,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "in some way or another in the training",
      "offset": 2477.599,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "data for the foundation models that were",
      "offset": 2479.04,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "used now the the exact images were not",
      "offset": 2481.28,
      "duration": 3.039
    },
    {
      "lang": "en",
      "text": "used",
      "offset": 2483.359,
      "duration": 3.521
    },
    {
      "lang": "en",
      "text": "But the but the con the concepts were",
      "offset": 2484.319,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "there. Elves I think is a little bit",
      "offset": 2486.88,
      "duration": 3.439
    },
    {
      "lang": "en",
      "text": "different where you know has something",
      "offset": 2488.72,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "like 1,200 classes and we find you know",
      "offset": 2490.319,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "so we we incorporated Elves to measure",
      "offset": 2493.2,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "like limitations of this case right like",
      "offset": 2495.599,
      "duration": 4.801
    },
    {
      "lang": "en",
      "text": "where we find like clearly if there are",
      "offset": 2497.92,
      "duration": 5.199
    },
    {
      "lang": "en",
      "text": "no labels predicted then downstream",
      "offset": 2500.4,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "object object detector performance is",
      "offset": 2503.119,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "not going to be there. Um so you know so",
      "offset": 2504.88,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "that's that's all measured in there. So,",
      "offset": 2507.839,
      "duration": 3.441
    },
    {
      "lang": "en",
      "text": "so a limitation of this notion of",
      "offset": 2509.28,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "autolelabeling is like how do you handle",
      "offset": 2511.28,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "the decision boundary classes or how do",
      "offset": 2514.64,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "you handle complex classes that are out",
      "offset": 2517.04,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "of domain, you know, and I think that",
      "offset": 2518.64,
      "duration": 6.88
    },
    {
      "lang": "en",
      "text": "like basically the key um the key nugget",
      "offset": 2521.04,
      "duration": 8.48
    },
    {
      "lang": "en",
      "text": "here is being able to identify either",
      "offset": 2525.52,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "automatically or semi-automatically with",
      "offset": 2529.52,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "a human in the loop like when these auto",
      "offset": 2531.28,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "labels are should be accepted and when",
      "offset": 2534.24,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "they should be rejected. And so this",
      "offset": 2536.72,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "actually conveniently gets back to that",
      "offset": 2539.68,
      "duration": 3.679
    },
    {
      "lang": "en",
      "text": "method I was mentioning to you earlier.",
      "offset": 2541.2,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "The way the way I think at least the way",
      "offset": 2543.359,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "Voxil 51 is going to be doing it within",
      "offset": 2544.96,
      "duration": 4.639
    },
    {
      "lang": "en",
      "text": "51 is this notion of what we're calling",
      "offset": 2546.96,
      "duration": 5.359
    },
    {
      "lang": "en",
      "text": "verified autoleing. So like you generate",
      "offset": 2549.599,
      "duration": 5.681
    },
    {
      "lang": "en",
      "text": "your auto labels and it's still the onus",
      "offset": 2552.319,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "is still on the human whether or not",
      "offset": 2555.28,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "it's a QA person that you're that's a",
      "offset": 2556.64,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "contract that you're paying from outside",
      "offset": 2558.48,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "the company or a team member an actual",
      "offset": 2559.68,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "trained MLE like someone really should",
      "offset": 2561.52,
      "duration": 4.559
    },
    {
      "lang": "en",
      "text": "be saying yes no yes no yes no but again",
      "offset": 2563.76,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "like you know it's a problem if they",
      "offset": 2566.079,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "have to do that for every image right so",
      "offset": 2568.079,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "so our our approach is to or what we",
      "offset": 2570,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "think will work and we're still working",
      "offset": 2574.079,
      "duration": 3.361
    },
    {
      "lang": "en",
      "text": "on this admittedly but what we think",
      "offset": 2575.28,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "will work is being able to identify",
      "offset": 2577.44,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "uh what what we're thinking of is like",
      "offset": 2580.24,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "green, yellow, and red light. Think of",
      "offset": 2581.599,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "it like a stop light, right? Like",
      "offset": 2583.28,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "clearly these samples are in cluster in",
      "offset": 2585.119,
      "duration": 5.681
    },
    {
      "lang": "en",
      "text": "class, right? Like they they don't vary",
      "offset": 2588.72,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "at all from the mean of the cluster. You",
      "offset": 2590.8,
      "duration": 3.519
    },
    {
      "lang": "en",
      "text": "know, whe whether or not that's measured",
      "offset": 2592.88,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "with the shallow water encoder model I",
      "offset": 2594.319,
      "duration": 4.481
    },
    {
      "lang": "en",
      "text": "talked about earlier or some other there",
      "offset": 2597.04,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "probably are dozens of ways of doing",
      "offset": 2598.8,
      "duration": 3.039
    },
    {
      "lang": "en",
      "text": "that as long as you can do it fast and",
      "offset": 2600.16,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "effectively. Um and then similarly,",
      "offset": 2601.839,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "okay, the red light, right? like these",
      "offset": 2604.96,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "cases are clearly at the decision",
      "offset": 2607.599,
      "duration": 4.641
    },
    {
      "lang": "en",
      "text": "boundary. We can't we're not confident",
      "offset": 2610.64,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "about these, you know, we we don't know",
      "offset": 2612.24,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "what they are. So, let's just throw away",
      "offset": 2614.56,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "those. And then the challenge is the",
      "offset": 2616,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "yellow the cases in the middle, right?",
      "offset": 2618.24,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "Like are there cases where it's it's",
      "offset": 2620.319,
      "duration": 5.121
    },
    {
      "lang": "en",
      "text": "unclear if it is a decision boundary",
      "offset": 2622.8,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "problem like a like the child near the",
      "offset": 2625.44,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "stop light stop sign example you gave",
      "offset": 2627.76,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "earlier or if it's a mislabel from the",
      "offset": 2629.839,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "auto label or something like that. So,",
      "offset": 2632.64,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "let's have humans look at that. So, so",
      "offset": 2633.92,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "ultimately that's the way we're",
      "offset": 2636,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "approaching the problem, you know. So,",
      "offset": 2637.52,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "humans are still I think humans are",
      "offset": 2639.28,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "needed to verify if you can minimize",
      "offset": 2641.359,
      "duration": 4.881
    },
    {
      "lang": "en",
      "text": "that work um and quantify and",
      "offset": 2643.28,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "predictably quantify how much work there",
      "offset": 2646.24,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "would be um I I think that's like when",
      "offset": 2648,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "we get to annotation you know next",
      "offset": 2650.72,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "version of annotation whether it's 1.5",
      "offset": 2652.64,
      "duration": 4.479
    },
    {
      "lang": "en",
      "text": "or 2.0 or whatever. Yeah. Do you have",
      "offset": 2654.4,
      "duration": 5.84
    },
    {
      "lang": "en",
      "text": "any intuition around how this approach",
      "offset": 2657.119,
      "duration": 5.761
    },
    {
      "lang": "en",
      "text": "would perform for out of distribution",
      "offset": 2660.24,
      "duration": 6.16
    },
    {
      "lang": "en",
      "text": "domains? So like I don't know fault",
      "offset": 2662.88,
      "duration": 6.959
    },
    {
      "lang": "en",
      "text": "detection and electron micoscopy images",
      "offset": 2666.4,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "or you know whatever some industrial use",
      "offset": 2669.839,
      "duration": 4.881
    },
    {
      "lang": "en",
      "text": "case that's not represented in cocoa and",
      "offset": 2671.92,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "some of these other data sets. I I don't",
      "offset": 2674.72,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "have a great answer. I mean I think the",
      "offset": 2676.96,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "we just haven't measured it really",
      "offset": 2678.88,
      "duration": 2.4
    },
    {
      "lang": "en",
      "text": "right. I think that's that's something",
      "offset": 2680,
      "duration": 3.359
    },
    {
      "lang": "en",
      "text": "we want to do. I think one way that we",
      "offset": 2681.28,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "would measure that is um the first step",
      "offset": 2683.359,
      "duration": 6.161
    },
    {
      "lang": "en",
      "text": "we probably would do you know and I'd be",
      "offset": 2687.04,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "glad if someone else who's listening",
      "offset": 2689.52,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "would does this work before us. It's",
      "offset": 2691.04,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "fine. This is not a competition, it's a",
      "offset": 2692.72,
      "duration": 3.599
    },
    {
      "lang": "en",
      "text": "cooperation, right? Um like we I would",
      "offset": 2694.24,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "take a data set domain like medical",
      "offset": 2696.319,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "imaging for which there are in-domain",
      "offset": 2698.079,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "foundation models and then use out of",
      "offset": 2700.4,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "domain foundation models like the ones",
      "offset": 2703.359,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "we've used here as well as those indom",
      "offset": 2704.88,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "in-domain ones. Interesting. Yeah. And",
      "offset": 2707.04,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "kind of like predict the performance,",
      "offset": 2708.88,
      "duration": 2.719
    },
    {
      "lang": "en",
      "text": "compare the performance, see see if",
      "offset": 2710.16,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "there's a their distri predictable",
      "offset": 2711.599,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "distributions over them almost like a",
      "offset": 2713.52,
      "duration": 3.599
    },
    {
      "lang": "en",
      "text": "sort of like a foundation model t test",
      "offset": 2715.44,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "if you will that that might be able to",
      "offset": 2717.119,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "do that. um for for truly out of domain",
      "offset": 2718.48,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "or like like even if it's in like",
      "offset": 2721.359,
      "duration": 3.121
    },
    {
      "lang": "en",
      "text": "because out of the main can mean a lot",
      "offset": 2723.28,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "of things, right? What if it's in domain",
      "offset": 2724.48,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "but challenging you know like the the",
      "offset": 2726.48,
      "duration": 5.599
    },
    {
      "lang": "en",
      "text": "old like visual verbs work from Alif for",
      "offset": 2729.04,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "hottie like a decade ago or something",
      "offset": 2732.079,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "like that right like it's better if if",
      "offset": 2733.52,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "you have you know person you have person",
      "offset": 2735.92,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "on horse you have person on bicycle you",
      "offset": 2738.64,
      "duration": 3.439
    },
    {
      "lang": "en",
      "text": "have person climbing or something like",
      "offset": 2740.88,
      "duration": 3.199
    },
    {
      "lang": "en",
      "text": "that right like it's actually what they",
      "offset": 2742.079,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "found was it was better to train",
      "offset": 2744.079,
      "duration": 3.361
    },
    {
      "lang": "en",
      "text": "separate detectors for like the",
      "offset": 2745.599,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "compositions because these models we're",
      "offset": 2747.44,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "training these these faces we're",
      "offset": 2750,
      "duration": 2.56
    },
    {
      "lang": "en",
      "text": "training on and these models these",
      "offset": 2751.359,
      "duration": 2.801
    },
    {
      "lang": "en",
      "text": "features we're leveraging are now",
      "offset": 2752.56,
      "duration": 2.559
    },
    {
      "lang": "en",
      "text": "compositional",
      "offset": 2754.16,
      "duration": 2.959
    },
    {
      "lang": "en",
      "text": "I I still don't think the current",
      "offset": 2755.119,
      "duration": 5.041
    },
    {
      "lang": "en",
      "text": "semantically enriched embedding spaces",
      "offset": 2757.119,
      "duration": 5.601
    },
    {
      "lang": "en",
      "text": "we we we have today are compositional",
      "offset": 2760.16,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "sufficiently compositional still. So,",
      "offset": 2762.72,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "but that's that's one direction of of",
      "offset": 2765.28,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "complexity whereas like truly out of",
      "offset": 2767.28,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "domain like fault faults or like",
      "offset": 2769.359,
      "duration": 4.801
    },
    {
      "lang": "en",
      "text": "manufacturing defects like one of our uh",
      "offset": 2771.28,
      "duration": 4.559
    },
    {
      "lang": "en",
      "text": "customers is looking at that that notion",
      "offset": 2774.16,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "right like how do we find defects in",
      "offset": 2775.839,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "production of like glass for example or",
      "offset": 2779.04,
      "duration": 6.16
    },
    {
      "lang": "en",
      "text": "like microchip microchip type things and",
      "offset": 2781.599,
      "duration": 5.121
    },
    {
      "lang": "en",
      "text": "um",
      "offset": 2785.2,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "you know the the the way the way I joke",
      "offset": 2786.72,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "about that problem is in some sense like",
      "offset": 2789.44,
      "duration": 4.639
    },
    {
      "lang": "en",
      "text": "it's very the way things can go well is",
      "offset": 2791.52,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "you know in terms of performant and like",
      "offset": 2794.079,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "building things on manufacturing lines",
      "offset": 2796.16,
      "duration": 3.439
    },
    {
      "lang": "en",
      "text": "are very few like it's it's correct or",
      "offset": 2797.68,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "it's not correct it's right whereas like",
      "offset": 2799.599,
      "duration": 5.601
    },
    {
      "lang": "en",
      "text": "the way things can go wrong is like this",
      "offset": 2802.56,
      "duration": 5.039
    },
    {
      "lang": "en",
      "text": "really massive and hard to predict space",
      "offset": 2805.2,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "so I don't have a great answer for how",
      "offset": 2807.599,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "we would assess this auto labeling of",
      "offset": 2809.92,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "that domain I mean in general though I",
      "offset": 2812.079,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "think the the way I I I envision you",
      "offset": 2814.8,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "know the future of annotation if you",
      "offset": 2818.079,
      "duration": 4.561
    },
    {
      "lang": "en",
      "text": "will or data set building really",
      "offset": 2820,
      "duration": 7.68
    },
    {
      "lang": "en",
      "text": "um is models will be more like we will",
      "offset": 2822.64,
      "duration": 7.679
    },
    {
      "lang": "en",
      "text": "have agents like almost like embedding",
      "offset": 2827.68,
      "duration": 6.56
    },
    {
      "lang": "en",
      "text": "space agents whose whose who are trained",
      "offset": 2830.319,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "whether or not it's with RL or I don't",
      "offset": 2834.24,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "know but like we'll train to be asking",
      "offset": 2835.839,
      "duration": 5.601
    },
    {
      "lang": "en",
      "text": "the domain experts when they're not sure",
      "offset": 2838.319,
      "duration": 4.561
    },
    {
      "lang": "en",
      "text": "directly right like this like",
      "offset": 2841.44,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "generalizing the notion of uncertainty",
      "offset": 2842.88,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "as used in active learning um for for",
      "offset": 2844.48,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "the situation where you're not",
      "offset": 2847.68,
      "duration": 2.639
    },
    {
      "lang": "en",
      "text": "necessarily training one model",
      "offset": 2848.88,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "downstream you're just kind of enriching",
      "offset": 2850.319,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "the embedding space to ensure that",
      "offset": 2852.16,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "decision boundaries are well separated.",
      "offset": 2854.079,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "I I think that's where the space is",
      "offset": 2856.319,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "going to be going technically. And is",
      "offset": 2857.839,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "there something",
      "offset": 2859.599,
      "duration": 5.681
    },
    {
      "lang": "en",
      "text": "unique about the",
      "offset": 2862.24,
      "duration": 7.599
    },
    {
      "lang": "en",
      "text": "agenticness of that or are you",
      "offset": 2865.28,
      "duration": 6.319
    },
    {
      "lang": "en",
      "text": "uh envisioning",
      "offset": 2869.839,
      "duration": 3.441
    },
    {
      "lang": "en",
      "text": "both",
      "offset": 2871.599,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "you know a technical approach and a user",
      "offset": 2873.28,
      "duration": 5.92
    },
    {
      "lang": "en",
      "text": "interface? like is is the is what you're",
      "offset": 2875.92,
      "duration": 5.919
    },
    {
      "lang": "en",
      "text": "describing any different than you know",
      "offset": 2879.2,
      "duration": 4.639
    },
    {
      "lang": "en",
      "text": "you you have a bunch of low low",
      "offset": 2881.839,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "certainty images and you just send that",
      "offset": 2883.839,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "back to the user for review. Is there",
      "offset": 2885.68,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "some specific thing you're envisioning",
      "offset": 2887.359,
      "duration": 5.361
    },
    {
      "lang": "en",
      "text": "uh",
      "offset": 2890.72,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "you know this core agentic uh behavior?",
      "offset": 2892.72,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "I don't know. We we use we're overusing",
      "offset": 2896.24,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "collectively the term agent a agent or",
      "offset": 2898.24,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "the notion of agent right now. But um I",
      "offset": 2900.16,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "am I am thinking of it in the context of",
      "offset": 2902.559,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "a human in the loop like UX for sure.",
      "offset": 2904.24,
      "duration": 5.599
    },
    {
      "lang": "en",
      "text": "But but I do think that the underlying",
      "offset": 2906.24,
      "duration": 6.319
    },
    {
      "lang": "en",
      "text": "um you know like optimization function",
      "offset": 2909.839,
      "duration": 6.401
    },
    {
      "lang": "en",
      "text": "or cost function that's being optimized",
      "offset": 2912.559,
      "duration": 5.921
    },
    {
      "lang": "en",
      "text": "may need to be evolving based on what",
      "offset": 2916.24,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "the feedback is. And so there may",
      "offset": 2918.48,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "actually be this notion of like a meta",
      "offset": 2921.52,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "model if you will that's that's",
      "offset": 2923.92,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "exploring the space with other models um",
      "offset": 2925.44,
      "duration": 6.32
    },
    {
      "lang": "en",
      "text": "and may need to be refining how the",
      "offset": 2928.88,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "space is being cap characterized",
      "offset": 2931.76,
      "duration": 4.559
    },
    {
      "lang": "en",
      "text": "but that's very high level. I I don't",
      "offset": 2934.4,
      "duration": 5.679
    },
    {
      "lang": "en",
      "text": "have much um much details about that. No",
      "offset": 2936.319,
      "duration": 6.641
    },
    {
      "lang": "en",
      "text": "certainly interesting to think about how",
      "offset": 2940.079,
      "duration": 5.441
    },
    {
      "lang": "en",
      "text": "uh agents would play into this since",
      "offset": 2942.96,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "we're all thinking about agents all the",
      "offset": 2945.52,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "time anyway. Right.",
      "offset": 2947.04,
      "duration": 5.279
    },
    {
      "lang": "en",
      "text": "Right. And so we've talked about a",
      "offset": 2949.68,
      "duration": 6.32
    },
    {
      "lang": "en",
      "text": "handful of kind of next steps for uh for",
      "offset": 2952.319,
      "duration": 6.8
    },
    {
      "lang": "en",
      "text": "this research. Um any any additional",
      "offset": 2956,
      "duration": 6.079
    },
    {
      "lang": "en",
      "text": "ideas that you're excited about? I mean",
      "offset": 2959.119,
      "duration": 5.601
    },
    {
      "lang": "en",
      "text": "I am really excited about",
      "offset": 2962.079,
      "duration": 5.681
    },
    {
      "lang": "en",
      "text": "how to bring this into practice. You",
      "offset": 2964.72,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "know like I keep hearing about I mean I",
      "offset": 2967.76,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "see a lot of papers that try to do some",
      "offset": 2969.52,
      "duration": 4.799
    },
    {
      "lang": "en",
      "text": "form of this or like you know or the",
      "offset": 2971.599,
      "duration": 4.801
    },
    {
      "lang": "en",
      "text": "whole world of semi-supervised ML like",
      "offset": 2974.319,
      "duration": 4.881
    },
    {
      "lang": "en",
      "text": "these these are not really new ideas.",
      "offset": 2976.4,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "Yet I still don't I don't hear people",
      "offset": 2979.2,
      "duration": 5.119
    },
    {
      "lang": "en",
      "text": "like singing from the mountain tops that",
      "offset": 2981.76,
      "duration": 4.799
    },
    {
      "lang": "en",
      "text": "like oh look I've I don't I don't need",
      "offset": 2984.319,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "humans anymore for labeling this and I'm",
      "offset": 2986.559,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "or I've you know my my need for human",
      "offset": 2988.16,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "labeling is 10% as it was last year. So",
      "offset": 2990.4,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "either they've discovered it and they're",
      "offset": 2993.76,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "not talking about it which is a",
      "offset": 2995.68,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "possibility or it's still just in this",
      "offset": 2996.88,
      "duration": 6.959
    },
    {
      "lang": "en",
      "text": "experimental stage. And I I am really",
      "offset": 3000.72,
      "duration": 6.32
    },
    {
      "lang": "en",
      "text": "excited about the impact that these that",
      "offset": 3003.839,
      "duration": 5.361
    },
    {
      "lang": "en",
      "text": "that that these types of results or",
      "offset": 3007.04,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "these types of systems will have in in",
      "offset": 3009.2,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "practice. Um you know I think we we all",
      "offset": 3011.119,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "want to see better AI models or better",
      "offset": 3013.76,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "vision models you know being being",
      "offset": 3016.319,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "trained and being deployed and I'm just",
      "offset": 3018.16,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "hoping that this is one way in that",
      "offset": 3020.64,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "direction for for practical attack. Um I",
      "offset": 3022.079,
      "duration": 7.361
    },
    {
      "lang": "en",
      "text": "think from a u from a like near-term",
      "offset": 3025.28,
      "duration": 7.68
    },
    {
      "lang": "en",
      "text": "technical or more researchy direction",
      "offset": 3029.44,
      "duration": 5.119
    },
    {
      "lang": "en",
      "text": "um",
      "offset": 3032.96,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "you know I think that that notion of how",
      "offset": 3034.559,
      "duration": 5.921
    },
    {
      "lang": "en",
      "text": "you send how you minimize human work but",
      "offset": 3036.88,
      "duration": 6.959
    },
    {
      "lang": "en",
      "text": "still provide some guarantees on it you",
      "offset": 3040.48,
      "duration": 5.359
    },
    {
      "lang": "en",
      "text": "know like this is you know there's a",
      "offset": 3043.839,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "whole area in like controls and other",
      "offset": 3045.839,
      "duration": 4.881
    },
    {
      "lang": "en",
      "text": "other spaces in engineering that have",
      "offset": 3047.839,
      "duration": 5.441
    },
    {
      "lang": "en",
      "text": "models for mechanisms say not models but",
      "offset": 3050.72,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "like mechanisms for measuring",
      "offset": 3053.28,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "that those types of uncertainties or",
      "offset": 3055.44,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "performance guarantees and so on. We",
      "offset": 3056.96,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "just haven't done that in in our space.",
      "offset": 3058.72,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "Uh and I think we as the field matures,",
      "offset": 3060.8,
      "duration": 6.08
    },
    {
      "lang": "en",
      "text": "we will need to mature the types of",
      "offset": 3063.92,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "guarantees that we can offer in the",
      "offset": 3066.88,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "space. Um so I'm pretty excited about",
      "offset": 3068.319,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "about that direction as well. On the",
      "offset": 3070.88,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "topic of you know seeing people out uh",
      "offset": 3073.359,
      "duration": 4.561
    },
    {
      "lang": "en",
      "text": "talking about the application of these",
      "offset": 3076.24,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "types of approaches it does strike me",
      "offset": 3077.92,
      "duration": 5.199
    },
    {
      "lang": "en",
      "text": "that there's a lot of that happening in",
      "offset": 3080.319,
      "duration": 5.921
    },
    {
      "lang": "en",
      "text": "the text domain and in language with the",
      "offset": 3083.119,
      "duration": 6.161
    },
    {
      "lang": "en",
      "text": "use of LLMs like",
      "offset": 3086.24,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "uh",
      "offset": 3089.28,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "you know the a very popular topic is",
      "offset": 3091.04,
      "duration": 5.039
    },
    {
      "lang": "en",
      "text": "eval",
      "offset": 3093.119,
      "duration": 5.521
    },
    {
      "lang": "en",
      "text": "work is being done nowadays with the",
      "offset": 3096.079,
      "duration": 5.921
    },
    {
      "lang": "en",
      "text": "generation of synthetic data sets for uh",
      "offset": 3098.64,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "evaluation.",
      "offset": 3102,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "And I wonder if there's a parallel",
      "offset": 3103.04,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "here. I I'm not an expert in the",
      "offset": 3105.76,
      "duration": 6.24
    },
    {
      "lang": "en",
      "text": "language domain specifically. Um",
      "offset": 3108.4,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "I think there there probably are",
      "offset": 3112,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "similarities, but I think there are also",
      "offset": 3113.44,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "um interesting differences, right? like",
      "offset": 3116,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "um",
      "offset": 3118.8,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "I guess f first of all I'm a little",
      "offset": 3120.8,
      "duration": 5.279
    },
    {
      "lang": "en",
      "text": "worried about using VLMs or or LLMs to",
      "offset": 3122.72,
      "duration": 6.16
    },
    {
      "lang": "en",
      "text": "generate synthetic data sets uh because",
      "offset": 3126.079,
      "duration": 6.321
    },
    {
      "lang": "en",
      "text": "they assume knowledge of the underlying",
      "offset": 3128.88,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "like embedding space or like like the",
      "offset": 3132.4,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "the manifolds in that space and if we we",
      "offset": 3134.16,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "we already know that that we don't have",
      "offset": 3137.2,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "full understanding like those manifolds",
      "offset": 3139.04,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "are not yet sufficiently well defined",
      "offset": 3140.72,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "necessarily right like and and I guess",
      "offset": 3142.96,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "evidence to that point even in the text",
      "offset": 3145.52,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "domain is that although we see LLM being",
      "offset": 3147.52,
      "duration": 6.319
    },
    {
      "lang": "en",
      "text": "used to generate data sets and so on,",
      "offset": 3150.8,
      "duration": 5.519
    },
    {
      "lang": "en",
      "text": "many annotation companies have left the",
      "offset": 3153.839,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "vision space and moved into the tech",
      "offset": 3156.319,
      "duration": 4.561
    },
    {
      "lang": "en",
      "text": "space because of the greater demand for",
      "offset": 3158.16,
      "duration": 4.959
    },
    {
      "lang": "en",
      "text": "more human expertise. And I think why is",
      "offset": 3160.88,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "that happening? Because there's there's",
      "offset": 3163.119,
      "duration": 3.521
    },
    {
      "lang": "en",
      "text": "this rich like semantic structure in",
      "offset": 3164.72,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "language that is sometimes hard to tease",
      "offset": 3166.64,
      "duration": 4.479
    },
    {
      "lang": "en",
      "text": "out. And I think there's still there's",
      "offset": 3169.119,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "still some learning to be done there.",
      "offset": 3171.119,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "Whether or not it's to strictly like",
      "offset": 3173.52,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "when you get when we get to trillions of",
      "offset": 3175.839,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "tokens that will be enough, I don't",
      "offset": 3177.359,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "know. I'll just I'll just shrug my",
      "offset": 3179.839,
      "duration": 2.561
    },
    {
      "lang": "en",
      "text": "shoulders at that. I don't really know.",
      "offset": 3181.119,
      "duration": 3.361
    },
    {
      "lang": "en",
      "text": "May maybe we need a different model. I'm",
      "offset": 3182.4,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "not sure. Um whereas in the visual",
      "offset": 3184.48,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "domain, the types of ambiguities you can",
      "offset": 3186.88,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "find like those types of semantic",
      "offset": 3189.92,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "ambiguities, frankly, I think are less.",
      "offset": 3191.44,
      "duration": 5.119
    },
    {
      "lang": "en",
      "text": "I I don't want to be on on record as",
      "offset": 3194.24,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "saying computer vision is easier than",
      "offset": 3196.559,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "NLP. Um most of my colleagues would",
      "offset": 3198,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "shoot me for saying that. But I but I",
      "offset": 3200.64,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "think it's it's easier in some ways and",
      "offset": 3203.04,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "it's harder in other ways is I think is",
      "offset": 3205.04,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "a simple way to put it, right? Like",
      "offset": 3206.96,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "there are some like lingual visual",
      "offset": 3208.4,
      "duration": 7.28
    },
    {
      "lang": "en",
      "text": "visual like some semantic vision um",
      "offset": 3211.28,
      "duration": 6.4
    },
    {
      "lang": "en",
      "text": "ambiguity is like donut hole. I gave",
      "offset": 3215.68,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "this in a talk like at a CBPR a decade",
      "offset": 3217.68,
      "duration": 2.8
    },
    {
      "lang": "en",
      "text": "ago or something like that, right? Like",
      "offset": 3219.44,
      "duration": 3.679
    },
    {
      "lang": "en",
      "text": "what's a donut hole? Is a is a donut",
      "offset": 3220.48,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "hole actually the gap the part of the",
      "offset": 3223.119,
      "duration": 4.881
    },
    {
      "lang": "en",
      "text": "doughnut that's missing or is a donut",
      "offset": 3225.28,
      "duration": 6.079
    },
    {
      "lang": "en",
      "text": "hole the the like the pop or whatever,",
      "offset": 3228,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "right? like the actual thing that came",
      "offset": 3231.359,
      "duration": 3.281
    },
    {
      "lang": "en",
      "text": "out of there, right? Like um and until",
      "offset": 3232.48,
      "duration": 3.359
    },
    {
      "lang": "en",
      "text": "you've seen some examples, you don't",
      "offset": 3234.64,
      "duration": 2.24
    },
    {
      "lang": "en",
      "text": "necessarily know what that concept",
      "offset": 3235.839,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "means. So, there are certain ambiguities",
      "offset": 3236.88,
      "duration": 5.439
    },
    {
      "lang": "en",
      "text": "in in the visual world like like that.",
      "offset": 3239.359,
      "duration": 5.041
    },
    {
      "lang": "en",
      "text": "And and it's just it the visual world is",
      "offset": 3242.319,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "just much higher dimension and very",
      "offset": 3244.4,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "complex to to process. You could even",
      "offset": 3246.16,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "argue that that's not actually a visual",
      "offset": 3248,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "ambiguity, but it's a linguistic",
      "offset": 3250.4,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "ambiguity. You probably could. Yeah. If",
      "offset": 3252.16,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "you compare the hole and the the donut",
      "offset": 3254.559,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "thing, it's clear that those are",
      "offset": 3256.8,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "different. It's just the language is",
      "offset": 3258.559,
      "duration": 2.641
    },
    {
      "lang": "en",
      "text": "weird.",
      "offset": 3259.92,
      "duration": 2.88
    },
    {
      "lang": "en",
      "text": "Yeah, I think you can probably I think",
      "offset": 3261.2,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "you're probably right there. Um, but I",
      "offset": 3262.8,
      "duration": 3.759
    },
    {
      "lang": "en",
      "text": "guess that's a characteristic of this",
      "offset": 3265.28,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "notion that like",
      "offset": 3266.559,
      "duration": 4.641
    },
    {
      "lang": "en",
      "text": "what what why are why why do we",
      "offset": 3269.28,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "perceive? We perceive to have some like",
      "offset": 3271.2,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "semantic grounding of what we perceive.",
      "offset": 3273.92,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "And I think that that's there's it's",
      "offset": 3276.64,
      "duration": 3.439
    },
    {
      "lang": "en",
      "text": "that bridge that makes it hard. Whereas",
      "offset": 3278.16,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "I think like the visual world is hard in",
      "offset": 3280.079,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "other ways, right? like the way shadows",
      "offset": 3282.079,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "are created or the way like reflections",
      "offset": 3283.839,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "happen or even like you know like my",
      "offset": 3286.559,
      "duration": 2.8
    },
    {
      "lang": "en",
      "text": "eyeglasses for example are highly",
      "offset": 3287.92,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "reflective. Um in fact I have a new pair",
      "offset": 3289.359,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "waiting at the optometrist because it",
      "offset": 3291.44,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "has that problem like like aspects",
      "offset": 3293.119,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "aspects like this right like um so so",
      "offset": 3295.04,
      "duration": 6.24
    },
    {
      "lang": "en",
      "text": "anyway yeah so so good good good good to",
      "offset": 3298.079,
      "duration": 6.081
    },
    {
      "lang": "en",
      "text": "be in research in these problem spaces",
      "offset": 3301.28,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "uh these days because it's such a rich",
      "offset": 3304.16,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "environment. Awesome. Awesome. Well,",
      "offset": 3306,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "Jason, thanks so much for jumping on and",
      "offset": 3308.4,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "sharing a bit about what you've been",
      "offset": 3310.48,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "working on. Thanks a lot, Sam. It was a",
      "offset": 3312,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "great conversation. Thanks for having",
      "offset": 3314.16,
      "duration": 4.679
    },
    {
      "lang": "en",
      "text": "me.",
      "offset": 3315.839,
      "duration": 3
    },
    {
      "lang": "en",
      "text": "[Music]",
      "offset": 3342.01,
      "duration": 3.179
    }
  ],
  "cleanText": "Wait a second. What we've been doing as annotation, just blindly sending everything out for labeling, is not the future. We're seeing foundation models come along that could indeed actually replace a lot of those typical case human labels. So if what was annotation 1.0, blind send me data and get me labels, annotation 2.0 might only be human answers questions asked by the agent, if you will, agentic labeling or something like that. To me, we're on that timeline and we're probably somewhere in the middle of it.\n\nAll right, everyone. Welcome to another episode of the TWIML AI Podcast. I am of course your host Sam Charington. Today I'm joined by Jason Corso. Jason is co-founder of Voxel51 and a professor at the University of Michigan. Before we get going, be sure to take a moment to hit that subscribe button wherever you're listening to today's show. Jason, welcome to the podcast.\n\nHey Sam, uh, thanks for having me. It's great to be here. Big fan. Absolutely. Thank you so much. I am looking forward to digging into our conversation. We're going to be talking about some of the work you're doing on Zero-Shot Auto-Labeling for Computer Vision. Uh, I'd love to have you start us off by sharing a little bit about your background.\n\nRight on. Sounds good. Yeah. Yeah. So, as you said, um I'm a co-founder at Voxel51, where we make a software dev tool kind of like VS code for Computer Vision or VS code for visual AI. Uh my background, I go back, you know, maybe 10, 15 years in research in Computer Vision. Uh most of most of my work focuses on high-level Computer Vision, video understanding, vision language, relationship between the physical world and and vision, so on. And through that work at the University of Michigan, I realized that there was, you know, a huge need for more analysis tooling to help support the code development of models and data sets together. And ultimately that's that's that's given me rise to like the last five or so years of my life at Voxel51 and and the university together.\n\nAwesome. And so with Voxel51, who are the intended users of that tool? Yeah, Voxel51 is is pretty much uh the IC is a very tech is a technically deep uh creator of either data sets for visual problems like uh image, video, 3D point clouds, meshes and so on or or model developers, right? At our bigger customers, these tend to be separate teams where you have like a data creation team and you have a model development team. Whereas at our smaller customers, typically, you know, a small team does does both of that. What what we've learned is or you know over the years generally like you don't you don't just get data dropped into your lap like a student does in my Computer Vision class, right? And then you have to train the model. The real world life in the real world is making the data set alongside making the model and really understanding how these things coincide together. Um, you know, and so that's ultimately that's though that is why we we released FiftyOne, which is the name of our primary software. It's both commercial and open source, so open source for single users, local data, local compute. That's really how we got started in 2019 when we began uh this direction toward toward like dev tool. Um we released it open source uh both in the Computer Vision community and the machine learning community. Um and it's become a pretty widely adopted tool for everyday usage. You know, our our initial charge was, you know, we for the the first three things someone does when they're starting a new Computer Vision project, you know, pip install FiftyOne should be one of those things, one of those first three things.\n\nAwesome. And are there particular types of projects that you're seeing uh, you know, the most traction around or where uh FiftyOne is one of those first tools that someone is using? I mean, it's a good question, Sam. I think the, you know, FiftyOne's a pretty flexible piece of software. It's not intended to tell you how to do your work or what to do. It's it's think of it kind of like a set of building blocks and if you know if you want some annotation or you want like model performance analysis or you just want to visualize your embeddings or whatever, it it can kind of do all these different pieces for you. So, we do have a pretty broad user base. I mean that said I think the uh you know object detection is definitely at least amongst our commercial users object detection really uh shines as like a as like a core task in Computer Vision that our users are doing and most typically people are starting with an existing model that that either they've trained or they've inherited, say, an off-the-shelf foundation model or something like that and their goal is to render that useful in their domain for their problem, whether or not that's you know, quality assurance insurance on the on the manufacturing line or pedestrian avoidance for mobility or healthcare problems like you know from a vertical standpoint uh get getting to that uh we have lot you know there's no one domain actually of of users. We have quite a few different uh domains in play. Maybe the most exciting one for for me, I have young kids, so but uh is is the we have some users that are monitoring marine life through through models built in FiftyOne uh and and they use that across uh various oceans in the world.\n\nPretty cool, pretty cool project. I often hear that one of the uh biggest lift investments that teams can do is to build like custom annotation tools because every application or use case is kind of a little bit different versus using something off the shelf. Uh do you get that that kind of or how do you look at that kind of um comment and uh is is FiftyOne meant to be used like off the shelf or can it be integrated into more application-specific workflows? Yeah, I have I have personally fallen prey to that uh to that to that direction as well. When I was a post-doc uh at UC at UCLA, um I built my own 3D I was working in 3D medical imaging, so there was no 3D medical image annotation tool out there, so I built my own one at at the time. Um in fact, I think that that notion was so sort of prevalent in our strategic thinking early on that uh in within FiftyOne from the very beginning, we explicitly did not support annotation directly. So in in order to annotate in FiftyOne, uh we provided integrations with common annotator annotation tools like Seat and Label Studio, Labelbox, other annotation tools, mostly because there were so many of them out there and we felt like it was going to be hard to distinguish any new any tool, you know, from from any new tool like ours from another to another another tool that that was already out there. We really wanted to emphasize the notion at the at the very core of what we did is like, you know, you train, you get some data and you train a model and then it doesn't work as well as you think. So you're like, what do I do next? Let me get more data and let me turn you kind of iterate this loop and we inject FiftyOne into the middle of that as like the analysis work, right? So kind of like turning the lights on in a dark hallway, right? It's like you get some data, train some models, then you do analysis within FiftyOne and then you kind of repeat this loop. Um, so um and that's why we made it flexible though, right? Because like that loop is very is very team specific. In fact, you know, we I used to quip like, you know, for every 100 machine learning engineers out there, there are 10,000 ways of working, right? Because like everyone has their own way of doing things, really. So um so you know, but but to your point, um we indeed we work with um we still maintain the integrations with other annotation tools. Now even though you can annotate within FiftyOne uh now at least through this auto-labeling stuff and actually in coming out in the summer, you will be able to do some annotation, let's say classical annotation within FiftyOne. Um, but we we still integrate with all the other tools out there. Uh, and I think it's primarily because FiftyOne has become a little bit of a Rosetta Stone for visual data formats. You know, it's very easy to get your data into FiftyOne format and it's kind of like this universal format and then get it out in whatever format you want. But many of our commercial clients um do indeed have their own homegrown annotation toolbox. And so it's typically like the first the first month of the engagement with a new commercial customer will be you know, format um merging, if you will, normalization. Normalization. Yeah, good word. Yeah. Um so uh but but we don't we we do the other maybe the other asteris to add is that um one thing you can do in FiftyOne um which which we're very proud of is you can add your own panels. So FiftyOne is both a Python SDK and a web-based app, right? And so in the app, you can extend the capabilities of the app through what we call panels, which are essentially plugins that have a visual component to them. Um, so we have actually seen some of our users and customers ch uh porting their their existing annotation capabilities directly into a FiftyOne panel so that it's an integrated experience. Um, you know, I think that's the that's the way forward, right? I mean I think the indeed no many many instances of problems are like are nuanced so that you do have slightly different changes and you want to be able to have your annotators next to your QA people, you know, next to your consumers downstream as model model developers. So having them all under one hood is important.\n\nAnd so you talk about inserting uh analysis into that loop. Talk a little bit about the nature of that analysis and how it uh aids the user. Sure. So like one key use case for that is right, so you've you have you have a data set, you have a model, um obviously it doesn't perform perfectly. So what can you do? So one question you might want to ask is uh what are the corner cases, right? Like where is where is it performing poorly?\n\nKind of exactly, yes, like and are there commonalities or is there structure to that lack of performance? So we have capabilities in the system to, for example, um compute what we call hardness or mistakenness that take your model logits on the data and manipulate them in certain ways to then provide to you clusters of outputs that will that you can then visually analyze because in our view, the human expert, like the actual domain expert or the MLE in the loop is the one who is the only one who really can make the decision, oh, you know, like whatever we're training like an pedestrian avoidance algorithm. And it turns out there's no there's very few examples of suburban parking lots for some reason. You know, only the human really is going to identify that that was the failure mode of of the of the problem. So that's one typical analysis. Another analysis we use is visualization of embeddings. So you can kind of you compute your embeddings either with a like FiftyOne approved embedding model or you kind of bring your own your own embedding model for that. Uh and then you can visually interact in in the app uh to find um situations for mislabels on on your actual data set, right? So like you visualize your embeddings, you can project the class labels on those embeddings and ultimately we'll see like, well, this this big big mass of red labels here with some blue labels in them. Let me see what those blue labels are. So let me turn the red mask off, the red label off, and then I can get a view only into those blue labels. So it's really kind of this this notion of like interactive analysis that is imperative to to cleaning up your data and uh and finding corner cases where you might then go need to add more uh more labels for you for the task.\n\nTalk a little bit about the evolutionary path towards uh automating labeling or auto-labeling. Was this uh something that you started out intending to do or is it something that arose, you know, as a result of powerful foundation models, for example, or something else? Yeah, I think it's um I mean I'd be lying if I told you in 2018 when we were first starting the company or 2007 when I started as faculty, I was going to predict like, oh, wait, we're not going to need labeling anymore. um that that that that couldn't be true, but it's not a it's not a it's not necessarily strictly a function of um just recent development. So um about maybe like two years ago, uh we began to see a shift in the types of conversations we would have with users of FiftyOne where they were going from like I'm strictly I'm sending all of my data to annotation to humans to annotate and spending just say round number, I'm spending a million dollars on this and then I'm getting it back and instead of being able to use it all, I'm finding out that actually I can only use 10% of it or 20% of which I mean dollars for dollars means they're throwing away a significant amount of money. And was that because of poor labeling, mislabels or No, I I think it's I mean obviously there were some mislabels, but I think there's just a lot of um similar cases being sent for labels and it wasn't clear that that the right subset of the data, right? Like data, it's easy to find like typical plus plus minus a couple sigma um cases, but what really matters is finding data along the decision boundaries. And that's hard to do if you don't know what the decision boundaries are, right? So, so, so the conversation shifted over into into sort of that direction. And we began to to try to sort of think about ways of how are we going to help users, even ourselves? It's a great problem technically, right? Like how do you find data? How do you find the boundary without knowing the boundary? How do you get there quickly? Right? So, so I wrote a blog uh maybe January of 2024 with the title annotation is dead. Uh and it was intended to start this conversation generally around like should we really be doing what we've been doing. It wasn't so much that like, okay, no one's going to need annotated data. Obviously it's a well-oiled machine. We know how supervised machine learning works. We can measure, we somewhat predictable performance, things like that, right? But it was really intended to catalyze this notion that wait a second, what we've been doing as annotation, just blindly sending everything out for labeling, is not the future. The future cannot be that way. And it just so happened that like, okay, we also be were seeing at that time like foundation models come along that could indeed actually replace a lot of those typical case human labels. Um and so you don't even need to to do that anymore. And so, so if if what was annotation, maybe we call that like annotation 1.0 and annotation 2.0 is like you there's never blind send me data and get me labels. Annotation 2.0 might only be a human answers questions asked by the by the agent, if you will, agentic labeling or something like that. To me that that's we're on that timeline and we're we're probably somewhere in the middle of it. Not just we like Voxel51, but I think the community is generally, we're moving down the line of okay, we can expect to get decent labels for common classes. What can we\n\n\nExpect for less common classes, or, you know, I have an automotive scenario. Can we, can you predict, uh, my model performance without actually labeling the data beforehand, things like that, right? And I think we're right squarely in the middle, moving in the direction of fewer, you, fewer sort of, just here, here's the media, give me that, give me the metadata, um, toward, toward more like, I think this is a teddy bear. Is this really a teddy bear, you know? And these are not technically speaking, like, those are not new directions, right? Like, people in the community of machine learning and computer vision have been looking at this for at least a decade or two, right? Semi-supervised learning is not new. Active learning is not new, but I, I think what, what we're seeing is that with this, the creation of these semantically enriched, uh, foundation models and embedding spaces, there's, there's more of a structure, underlying structure to the, to the, the way data is represented in those embedding spaces that we need to crunch on and understand more so that we can then go and do a better job of asking the right questions.\n\nIt strikes me that one of the lynchpins in kind of fully getting there, if you will, is, um, being able to better characterize or quantify uncertainty in these models. And that's been a, a challenge in the community for a really long time. Can you talk a little bit about how embeddings and kind of the semantic, uh, you know, modeling that you just mentioned helps us maybe overcome or sidestep that challenge? Um, it's a good point. I, I do think uncertainty is at the core of a lot of this, a lot of this discussion. Indeed, I agree. Um, you know, in some sense, if we really want a, a true measure of uncertainty, right? Like a classical, you know, like P of X type uncertainty, I don't think we have, um, I still don't think we have, aren't quite there yet. Yeah, we haven't made much progress, right? We don't, we still don't really know how to do that, but, um, there is enough structure in these embedding spaces that, um, we can start to even leverage some classical ideas. Like, for example, we have a tech report that, that we've been working on. Um, I can, I can send you the link after the, after the podcast here that, um, is able to take a, take a, take a classification problem, uh, and embed it using these contemporary foundation model embeddings. Say, you know, like, like a ResNet 50 or ResNet 18 for perceptual space, and then something like, um, um, why am I forgetting the, the name of the model now? Not Coco, but the very classic vision language embedding model that everyone uses, clip, sorry. So take a classic tech, take a classic perceptual embedding like ResNet 18, concatenate that with a clip embedding space, uh, and model within that space. And the problem we set out to ask is, can we measure the difficulty, the expected classification difficulty in that space without training the downstream classifier, right? Assuming, say, we only had labels on a small subset of the data, like 100 samples per class, for example. Um, and we use very simple shallow autoencoders, like two, two, three layers autoencoders. They're trainable in seconds per class. Uh, and if you take ratios of reconstruction errors, which is a measure of uncertainty to some degree, um, you can, there are certain, certain classes of those ratios that correlate very strongly with downstream classifier performance, had you trained a full classifier on the whole data set. Um, so, so that, that's what leads me to say that this is evidence, if you will, right? That, that there seems to be some structure in these more rich semant, semantically enriched embedding spaces that, um, even though we still don't have the right machinery to go and fully compute uncertainty, we at least can get, say, this is using, using the term loosely, kind of like marginal uncertainty, uh, in that space.\n\nAnd does that presume to some degree, um, I'm thinking about like, uh, you know, the, the big challenge in, uh, in the object detection scenario is going to be like, or in the classification scenario, rather, is going to be like, you know, outliers, or, you know, rare things that you're trying to classify. Um, you know, the kid running out in the street relative to the street sign. Um, does, are there assumptions made on having examples of that rare data in your, uh, in your data set? Yeah. So there are no assumptions that, that, that we know what that, that they, that they occur in the data set. Uh, but we also can't deduce them. You know, there's, there's sort of no way to figure those out, right? That those are essentially the, the bay risk or the bay uncertainty, right? Like, um, I, I guess, and essentially what, what we, what we've observed is that, you know, again, there is the decision boundary is always going to be the challenge here, right? But like, and since we're not in that work, for example, we're not updating the embedding at all, we don't, we don't modulate the embedding to try to pull them apart, um, if indeed a data set is dominated by those rare cases that, that are hard to disentangle from, from the truth, uh, then I, then it would be a kryptonite for, for our, for this modeling that we did. Um, but in typical situations, um, the means, the mean is the mean, right? Like, like typical, but typical samples are typical samples. Um, so, um, I guess what, what I'd like to see though, and we haven't done this, is, you know, I, I've been hearing this notion of like, internet scale data sets or re, real scale data sets, uh, coming up in the vision community a lot in the last couple years. I still don't have a great sense for how to quantify what is like a, an internet scale data set versus a canned off-the-shelf data set. But, but I, my intuition says that the, the closer we get to like large scale internet scale data sets, the more the mean behavior is going to dominate. Um, and I think that's, uh, I think that's critical. Yeah. Again, I guess to maybe answer my own question or comment on my own question, like, or comment, rather, uh, you know, part of the, the core value prop, going into, going back to that initial observation you made is, hey, we spent a million dollars on labeling, and it wasn't all that useful. It would be useful just to autolel the stuff that's the same. You don't necessarily have to autolel the, the outliers to create value.\n\nThat is, um, that is the observation I think many of us are making, you know, collectively, right? Like, why am I spending this money on things that I'm pretty sure even my own models may do well with already? Um, and I think the challenge is, the, I think there are two key challenges, really, right? Like, one is, how can, can we build a model of, using the term model loosely here, but like, a model of predictability, right? Like, how much of that auto labeling can I expect to be useful? Um, and I think that, that's, that's a key challenge. And then another one is, um, given that I've just autolelabeled things, how do I minimize the human work needed to do QA on the output of that? Because if I have to have humans go and validate 100% of the auto labels, then I've not saved any time at all, right? So if you, how do we get that number down? I think ultimately, that's, that's, those are those are two things that I've been thinking about a fair amount lately. So yeah. Uh, so you guys recently released a report on archive called Auto-Labeling Data for Object Detection, as well as a blog post, uh, Zero-Shot Auto-Labeling Rivals Human Performance, that kind of captures all of these ideas. Can you, um, you know, let's maybe start by talking about like, how you are approaching autolelabeling? Is there a, a, you know, generic setup that you're using? Is it very use case specific? Yeah, sounds good. So I, I think that this, this initial report and our initial work, I guess, in it, it is probably the simplest setup that you can imagine, simply because we want, I mean, you know, I've been around for, for some time, and I think like, simple works, right? Like, you, we need to get in the simplest case before we can talk about more complex settings. So basically, the, the assumptions are, uh, you have a foundation model that is relevant to the domain you're operating in, general natural images, whatever, uh, and then you have a, a VLM, in particular, a, um, I guess a VLM in particular, because we do prompt it with, with, with labels. I mean, the data sets we work with are VOC, Coco, BDD, and Elvis. So all of our, all of our prompts were pretty simple. So, you know, that's where, that's, that's why I'm sort of hesitating at VLM, in the sense that, you know, the foundation models we used are like YOLO World, YOLO E, Grounding Dino, concretely. So, so they're not really VLMs, but, but I mean, I think more generally speaking, you could say BLM. Um, uh, and you have a large corpus of unlabelled data, basically, right? And, and the idea is, okay, what would you have done in annotation 1.0, right? You would have then sent all of those images to humans to label. Uh, you would have taken the output from them and trained your model, uh, your object detector in this case. So we're only looking at object detection, and then, you know, computed some validation performance on a hold out set that was part of those annotations as well. Uh, in in our autolelabeling scenario, take the same unlabelled data, take a foundation model, uh, generate those, those labels, auto, auto labels, you know, we call them now. Um, similarly, train a, apples to apples sort of object detector, uh, we use like RT-DETR, YOLO, YOLO 11, I think we use, uh, and then compute the same validation performance. We wanted to make it as apples to apples. There's nothing special about the domain or the use case or what have you, aside from the fact that we're only using, only doing object detection. Other assumption, other assumptions we made are only one foundation model for input. There's no voting, you know, like, there's, there's some recent work. Like, there was a paper, um, the Florence 2 model at CVPR, I think, 24, uh, they had this interesting notion of like a data engine where they're like waiting over a multiple foundation model outputs. Um, we don't do any of that. Again, simple, simplest case here, uh, and we, we wanted to assess, given these simple settings, um, you know, like, um, what is the cost comparison in terms of money and time? How well do the auto labels match human labels? And how well do the, do the downstream object detectors match object detectors that were trained on those human labels? Those really were the three things. U, and I should say, concretely, there's no new, new architecture here. There's no, there's no technical contribution that way. The only parameter we vary is the threshold on the model confidence per object label, per object auto label, uh, and so we wanted to keep it as simple as possible, and just, just because I think there's a lot that we could do downstream, right? Like, in the future, but if we don't have a good baseline, uh, you know, and I think concretely, we approach it this way, not just because it's important to do things simple first, but we weren't aware of a baseline that actually did this experiment, uh, you know, that compares cost to ultimate gain in, in downstream performance or what have you. So yeah, so that, that's the way we set it up. Uh, is that clear? Any questions about, uh, that setup? No, that's, that's clear and simple. Okay. Okay. Great. Um, so, so again, let me, I can enumerate the, the data sets we used: VOC, Coco, BD, Elvis. Uh, the foundation models were YOLO E, YOLO World, and Grounding Dino. Downstream models that we trained were different sizes of YOLO 11. So YOLO 11 N, S, M, L, and X varies from like 2.6, 6 million to 57 million parameters, and then RT-DETR, which has 33 million parameters. So in some sense, like, you know, we wanted to take one model architecture, vary the its capacity, and then completely different model architecture at a mean, roughly the mean capacity of the first one, is, is the way I would think about those.\n\nUm, and so what, what did we find? Um, you know, um, actually, I guess before that, so to, so to do all this work, we ultimately had to train on the order of 445 different models, um, you know, so our, our compute node was running for some, some month or something like that to, to generate all these training experiments, and, uh, the models that, you know, per data set, uh, we, we, we only use the standard prompts, so we didn't, we didn't do any prompt expansion or generalization in any way. Uh, so it was basically, you know, like, you generally have to prompt these models with every class label with a period after it. Ultimately, that's all we did. Uh, so what do we find from a cost standpoint? So, um, you using off-the-shelf established numbers for how much things cost to, to annotate. So seven cents per box, for example. Um, we estimate that collectively these four data sets would cost about $124,000 to have humans annotate them. Just one pass of humans annotation. So, no QA, nothing like that. Um, and that the comparable cost in auto labeling, like GPU rental on AWS, uh, was a $118, uh, for, for an Nvidia L40S. A18 total for the 400 something models. Dollar 18 total to do, yeah, a18 total to produce all the labels. So for all the models, well, actually, no, to produce the labels, which is only done once, not, not, so inference, not the creation of the models, not the training of, not the training of the models. Okay, got it, yeah. In fact, I don't have the number for how long it took to train all the models. I mean, we have a box, we did this on a box of six GPU, six L40S's, and it took about a month, so whatever that cost is. So it's, it's, but that's, that's the full research experiment, uh, not, not, not the cost analysis. So, so it's, you know, six orders of magnitude more expensive to have humans label than have models label. So that, that's, but that's expected, so it's not surprising that the cost is is greatly different, right? 124,000 to to a dollar, right? That's, that's expected, but, but I think quantifying it is is still something that we, we weren't aware someone had done, right? So I think even putting a pin in the ground is important to do in, in science. Um, ultimately, it only matters if the labels are good. Exactly. Ultimately, only matters if the labels are good. Um, and I, I will get there. But one, one other aspect is is the time though it took as well, right? So we estimate that it would take about 6,000 hours of humans to label these four data sets. And this is based on a paper from Kristen Groman's group in, I think, ICCV 2017 or 2019, that where they were kind of like measuring the value of of labeling or the cost of labeling. Uh, so 6,000 hours to one hour, to one and a quarter hours, you know, so about four orders of magnitude different difference there as well. So you can do it fast and you can do it cheaply, but does it, does it work? Like, does it matter? Um, so you said 6,000 hours to one hour.\nUm, that 1 hour is spent labeling or 600 hours, 6,000 hours of human labeling to 1.27 hours of\n\n\nGPU labeling of GPU\ninference labeling.\nGot it.\nOkay.\nUm, so you, we're just talking about wall clock time as a comparison as opposed to 6,000 hours as a measure of some cost versus an hour as a measure of some other cost.\nExactly.\nWall cont very, very straightforward.\nYeah.\nYeah.\nOkay.\nSo, so how, how do the models perform?\nUm, is, we looked at, looked at it along two different axes, right?\nLike one axis is how well can we reproduce the human labels, which, which is important, right?\nUm, just as a measure of they are in some sense a gold standard.\nUm, although they're not a perfect gold standard, you know, for example, one of, one of the, one of the data sets has an image of donuts, and these, the, there are these two trays of donuts in, in the image.\nI actually forget which data set it comes from, maybe Elvis.\nUm, and in the human labels, there are, it's a mess, actually.\nSo if there are something like six dozen donuts per tray across both of them, roughly, that, that's probably about what it is, maybe a little less than that, four dozen.\nUm, humans sometimes, this is, this is actually, this is real data, right?\nThey will only label three of the donuts, um, a handful of the donuts, right?\nUm, or sounds about right.\nThis stuff is tedious, it's exactly ted, right?\nIt's so tedious.\nUm, similarly, they might group together six donuts as one donut, and actually, one, one example we have is the whole entire tray, essentially the whole image, donuts is labeled as donuts, right?\nWhich is just like this is to, this is like complete ontological failure of the, of the domain, right?\nSo whereas like the, the auto labels, okay, they miss some of the donuts, but it doesn't make the, grow the egregious error of like grouping them together and so on.\nSo that, that was, that was a great finding, I guess.\nBut so, but if, if you do assume that human labels are perfect or are the gold standard, um, we have found that, um, performance does vary drastically based on the configuration that we, we call it configuration, but in this case, it's essentially what confidence threshold you use.\nJust say it's, it's a, it's a, it's a, we keep this R label or not, basically.\nUm, so that confidence threshold is coming from the model, coming straight from the model.\nYellow or what have you, right?\nWithout, without doing any calibration at all.\nSo we just again took it, took it as is, black box.\nUm, we did, we do notice that grounding dyno has the greatest variation in performance, uh, of the, of the three foundation models, whereas like YOLO W and YOLO E are, I mean, okay, maybe at the boundaries of the curve that, you know, it does fall off pretty drastically, but from confidence like 0.3 to 0.7, it's a pretty flat, it's a plateaued, plateaued performance in terms of like F1 to the, to the human labeling.\nUm, so that, that, I mean, that's a good finding, right?\nSo like in some sense, in each, for each of the three foundation models we used, if you're able to find the right confidence threshold, you can essentially get almost perfect F1 score.\nYou, maybe that's a little bit reaching.\nYou can get very good, let's say, comparable F1 score to make it usable.\nUm, the challenge is though, in practice, you don't necessarily have the, you, you can't calibrate that well, but you'll have to get some data labeled to do your calibration of your confidence and then go and hope that that m, that that extrapolates to the rest of the data set.\nUm, so, so we really think the right measure is the other axis that we measured, which was, okay, take the auto label labels and, uh, predict their downstream or not predict, measure their downstream model performance.\nSo this is where we train the 445 models and do the, and do the analysis there.\nUh, and, and what we found is that, uh, in all cases, for each of the different three variants of foundation model across all four data sets, we can get within, um, relative numbers in the, in the 80s and 90s performance of whatever, like that, you know, which say YOLO 11s human performance is, these numbers are not from the paper, but like say 60% accuracy, an autoleabeled, autolel trained YOLO 11s can get like 55% performance or something like that.\nVery close performance.\nUm, and interestingly, there, there's, there are some interesting findings here.\nUm, one is that if you're willing to like save the money you would have spent on annotation and instead train a bigger model for compute and and spend that money like over time, you can, you know, apples to apples, you can actually outperform the smaller model, right?\nSo YOLO 11S has 9 million parameters, YOLO 11N has 2.6 six million parameters.\nIf you're willing to train the YOLO 11s, you can outperform the YOLO 11N, um, in many of our, in many of the results we have as well, which is, which is a cool result, I think.\nUm, and but, but even more interestingly, that the best downstream model performance comes for confidence thresholds filtering in and out the auto labels that is not that are not aligned with the top F1 performance.\nRight?\nSo in the sense that when you're generating auto labels, if you try to maximize your match to human performance, you won't necessarily get the best downstream object detector performance.\nInstead, what we found is that lowering your confidence threshold to somewhat egregiously low numbers like 0.12, where you will have noisy outputs in the auto labels ultimately maps to better downstream performance.\nAnd I thought this was really exciting.\nIt's not, it's not necessarily super counterintuitive, but also consistent with, uh, other results we're seeing recently with like, there was a paper within the past couple weeks about, um, RL fine-tuning.\nLike it doesn't really matter what the answers are.\nLike you can just, and it, and the general idea is consistent with, um, you know, machine learning just seems to perform better when there's the right amount of noise, like just like dropout and all these other things that we've done to like create noise when we're training models.\nUm, you know, so from that perspective, maybe not surprising, but counterintuitive.\nAbsolutely.\nI think it's just another chip or, you know, another tile in the mosaic of, of messaging around like machine learning need models, need data, and the data does not have to be perfect, but more is better than hike, better, more is better than better in some sense.\nI don't have the right like mantra yet, but, but, but it's indeed, it's pointing in that direction.\nUm, and, and I think, you know, in some sense, what I, what I hope for this particular report is that it gets recognized amongst in, in the community as rather concrete and up-to-date evidence for, for not only that counterintuitive nature, but, but like a way of measuring, um, how well these contemporary foundation models perform in the context of autoleing.\nYeah.\nThinking about more is better than better.\nIt's more is better than better if better is a metric of like human label performance.\nBut if better is a measure of like having the right data, uh, meaning outliers and and these other things identified, then you know, that is, you know, better.\nUh, and so I'm kind of using that as a segue to, um, to prompt you to kind of circle back on this idea of like, so now that you know, we understand that zero-shot autoleabeling, you know, works well, like if I'm building, you know, these kind of object detection models or I've got an application or systems that's using it, like how do I take that knowledge and kind of build a system around it that helps me zero in on, you know, what's really important and identify, you know, these outliers that we've talked about and overall, like, um, you know, build a better system, like in, in light of all the trade-offs that you've kind of me mentioned.\nI think it's a great, um, great, great point or great, great segue, not noting that I think it's the experiment you hinted at, right?\nLike if, if we could get better data at the boundaries, then we could really measure how much more is important.\nUm, how to do that is really hard.\nUm, but and but I, but I'd love to spend the next year thinking about that problem.\nBut anyway, so, so, so, but I think the, so, so what has this taught us in some sense, right?\nLike, okay, these experiments are typically like these data sets that we've that we've used in this experiment are, are not, they're, they're mostly like, let's say, kind of like in, in domain data sets, if you will, right?\nFor the foundation models we used, right?\nSo VOC, coco, even BDD, like these mo, most or all of the classes in those three data sets are, are at least covered in some way or another in the training data for the foundation models that were used.\nNow the, the exact images were not used.\nBut the, but the con, the concepts were there.\nElves, I think is a little bit different where, you know, has something like 1,200 classes, and we find, you know, so we, we incorporated Elves to measure like limitations of this case, right?\nLike where we find like clearly if there are no labels predicted, then downstream object, object detector performance is not going to be there.\nUm, so you know, so that's, that's all measured in there.\nSo, so a limitation of this notion of autolelabeling is like how do you handle the decision boundary classes or how do you handle complex classes that are out of domain, you know?\nAnd I think that like basically the key, um, the key nugget here is being able to identify either automatically or semi-automatically with a human in the loop, like when these auto labels are should be accepted and when they should be rejected.\nAnd so this actually conveniently gets back to that method I was mentioning to you earlier.\nThe way, the way I think, at least the way Voxel51 is going to be doing it within FiftyOne is this notion of what we're calling verified autoleing.\nSo like you generate your auto labels and it's still the onus is still on the human, whether or not it's a QA person that you're, that's a contract that you're paying from outside the company or a team member, an actual trained MLE, like someone really should be saying yes, no, yes, no, yes, no.\nBut again, like, you know, it's a problem if they have to do that for every image, right?\nSo, so our approach is to, or what we think will work, and we're still working on this, admittedly, but what we think will work is being able to identify, uh, what, what we're thinking of is like green, yellow, and red light.\nThink of it like a stop light, right?\nLike clearly these samples are in cluster in class, right?\nLike they, they don't vary at all from the mean of the cluster.\nYou know, whe, whether or not that's measured with the shallow water encoder model I talked about earlier or some other, there probably are dozens of ways of doing that as long as you can do it fast and effectively.\nUm, and then similarly, okay, the red light, right?\nLike these cases are clearly at the decision boundary.\nWe can't, we're not confident about these, you know, we, we don't know what they are.\nSo, let's just throw away those.\nAnd then the challenge is the yellow, the cases in the middle, right?\nLike are there cases where it's, it's unclear if it is a decision boundary problem, like a, like the child near the stop light, stop sign example you gave earlier, or if it's a mislabel from the auto label or something like that.\nSo, let's have humans look at that.\nSo, so ultimately, that's the way we're approaching the problem, you know.\nSo, humans are still, I think humans are needed to verify if you can minimize that work, um, and quantify and predictably quantify how much work there would be, um, I, I think that's like when we get to annotation, you know, next version of annotation, whether it's 1.5 or 2.0 or whatever.\nYeah.\nDo you have any intuition around how this approach would perform for out of distribution domains?\nSo like, I don't know, fault detection and electron micoscopy images or, you know, whatever, some industrial use case that's not represented in cocoa and some of these other data sets.\nI, I don't have a great answer.\nI mean, I think the, we just haven't measured it, really, right?\nI think that's, that's something we want to do.\nI think one way that we would measure that is, um, the first step we probably would do, you know, and I'd be glad if someone else who's listening would does this work before us.\nIt's fine.\nThis is not a competition, it's a cooperation, right?\nUm, like we, I would take a data set domain like medical imaging for which there are in-domain foundation models and then use out of domain foundation models like the ones we've used here as well as those indom, in-domain ones.\nInteresting.\nYeah.\nAnd kind of like predict the performance, compare the performance, see, see if there's a their distri, predictable distributions over them, almost like a sort of like a foundation model t test, if you will, that that might be able to do that.\nUm, for, for truly out of domain or like, like even if it's in, like, because out of the main can mean a lot of things, right?\nWhat if it's in domain but challenging, you know, like the, the old like visual verbs work from Alif for hottie, like a decade ago or something like that, right?\nLike it's better if, if you have, you know, person, you have person on horse, you have person on bicycle, you have person climbing or something like that, right?\nLike it's actually what they found was it was better to train separate detectors for like the compositions because these models we're training, these, these faces we're training on and these models, these features we're leveraging are now compositional.\nI, I still don't think the current semantically enriched embedding spaces we, we, we have today are compositional, sufficiently compositional still.\nSo, but that's, that's one direction of, of complexity, whereas like truly out of domain, like fault, faults or like manufacturing defects, like one of our, uh, customers is looking at that, that notion, right?\nLike how do we find defects in production of like glass, for example, or like microchip, microchip type things, and, um, you know, the, the, the way, the way I joke about that problem is in some sense, like it's very, the way things can go well is, you know, in terms of performant and like building things on manufacturing lines are very few, like it's, it's correct or it's not correct, it's right, whereas like the way things can go wrong is like this really massive and hard to predict space.\nSo I don't have a great answer for how we would assess this auto labeling of that domain.\nI mean, in general though, I think the, the way I, I, I envision, you know, the future of annotation, if you will, or data set building, really, um, is models will be more like, we will have agents, like almost like embedding space agents whose, whose, who are trained, whether or not it's with RL or I don't know, but like we'll train to be asking the domain experts when they're not sure directly, right?\nLike this, like generalizing the notion of uncertainty as used in active learning, um, for, for the situation where you're not necessarily training one model downstream, you're just kind of enriching the embedding space to ensure that decision boundaries are well separated.\nI, I think that's where the space is going to be going technically.\nAnd is there something unique about the agenticness of that, or are you, uh, envisioning both, you know, a technical approach and a user interface?\nLike, is, is the, is what you're describing any different than, you know, you, you have a bunch of low, low,\n\n\nCertainty images, and you just send that back to the user for review.\nIs there some specific thing you're envisioning, uh, you know, this core agentic uh behavior?\nI don't know.\nWe, we use, we're overusing collectively the term agent, a agent, or the notion of agent right now.\nBut, um, I am, I am thinking of it in the context of a human in the loop, like UX, for sure.\nBut, but I do think that the underlying, um, you know, like optimization function or cost function that's being optimized may need to be evolving based on what the feedback is.\nAnd so there may actually be this notion of like a meta model, if you will, that's that's exploring the space with other models, um, and may need to be refining how the space is being characterized, but that's very high level.\nI, I don't have much, um, much details about that.\nNo, certainly interesting to think about how uh agents would play into this since we're all thinking about agents all the time anyway.\nRight.\nRight.\nAnd so we've talked about a handful of kind of next steps for uh for this research.\nUm, any, any additional ideas that you're excited about?\nI mean, I am really excited about how to bring this into practice.\nYou know, like I keep hearing about, I mean, I see a lot of papers that try to do some form of this or like, you know, or the whole world of semi-supervised ML, like these, these are not really new ideas.\nYet I still don't, I don't hear people like singing from the mountain tops that like, oh, look, I've, I don't, I don't need humans anymore for labeling this, and I'm, or I've, you know, my, my need for human labeling is 10% as it was last year.\nSo either they've discovered it and they're not talking about it, which is a possibility, or it's still just in this experimental stage.\nAnd I, I am really excited about the impact that these, that, that these types of results or these types of systems will have in, in practice.\nUm, you know, I think we, we all want to see better AI models or better vision models, you know, being, being trained and being deployed, and I'm just hoping that this is one way in that direction for, for practical attack.\nUm, I think from a, from a like near-term technical or more researchy direction, um, you know, I think that that notion of how you send, how you minimize human work, but still provide some guarantees on it, you know, like this is, you know, there's a whole area in like controls and other, other spaces in engineering that have models for mechanisms, say, not models, but like mechanisms for measuring that those types of uncertainties or performance guarantees and so on.\nWe just haven't done that in, in our space.\nUh, and I think we, as the field matures, we will need to mature the types of guarantees that we can offer in the space.\nUm, so I'm pretty excited about, about that direction as well.\nOn the topic of, you know, seeing people out, uh, talking about the application of these types of approaches, it does strike me that there's a lot of that happening in the text domain and in language with the use of LLMs, like, uh, you know, the a very popular topic is eval, work is being done nowadays with the generation of synthetic data sets for uh, evaluation.\nAnd I wonder if there's a parallel here.\nI, I'm not an expert in the language domain specifically.\nUm, I think there, there probably are similarities, but I think there are also, um, interesting differences, right?\nLike, um, I guess f first of all, I'm a little worried about using VLMs or or LLMs to generate synthetic data sets, uh, because they assume knowledge of the underlying, like embedding space or like, like the, the manifolds in that space, and if we, we, we already know that that we don't have full understanding, like those manifolds are not yet sufficiently well defined necessarily, right?\nLike, and, and I guess evidence to that point, even in the text domain, is that although we see LLM being used to generate data sets and so on, many annotation companies have left the vision space and moved into the tech space because of the greater demand for more human expertise.\nAnd I think why is that happening?\nBecause there's, there's this rich, like semantic structure in language that is sometimes hard to tease out.\nAnd I think there's still, there's still some learning to be done there.\nWhether or not it's to strictly like, when you get, when we get to trillions of tokens, that will be enough, I don't know.\nI'll just, I'll just shrug my shoulders at that.\nI don't really know.\nMay, maybe we need a different model.\nI'm not sure.\nUm, whereas in the visual domain, the types of ambiguities you can find, like those types of semantic ambiguities, frankly, I think are less.\nI, I don't want to be on on record as saying computer vision is easier than NLP.\nUm, most of my colleagues would shoot me for saying that.\nBut I, but I think it's, it's easier in some ways and it's harder in other ways, is I think is a simple way to put it, right?\nLike there are some like lingual visual, visual, like some semantic vision, um, ambiguity is like donut hole.\nI gave this in a talk like at a CBPR a decade ago or something like that, right?\nLike, what's a donut hole?\nIs a, is a donut hole actually the gap, the part of the doughnut that's missing, or is a donut hole the, the like the pop or whatever, right?\nLike the actual thing that came out of there, right?\nLike, um, and until you've seen some examples, you don't necessarily know what that concept means.\nSo, there are certain ambiguities in, in the visual world like, like that.\nAnd, and it's just, it, the visual world is just much higher dimension and very complex to to process.\nYou could even argue that that's not actually a visual ambiguity, but it's a linguistic ambiguity.\nYou probably could.\nYeah.\nIf you compare the hole and the the donut thing, it's clear that those are different.\nIt's just the language is weird.\nYeah, I think you can probably, I think you're probably right there.\nUm, but I guess that's a characteristic of this notion that like, what, what, why are, why, why do we perceive?\nWe perceive to have some like semantic grounding of what we perceive.\nAnd I think that that's there's, it's that bridge that makes it hard.\nWhereas I think like the visual world is hard in other ways, right?\nLike the way shadows are created or the way like reflections happen or even like, you know, like my eyeglasses, for example, are highly reflective.\nUm, in fact, I have a new pair waiting at the optometrist because it has that problem, like, like aspects, aspects like this, right?\nLike, um, so, so anyway, yeah, so, so good, good, good to be in research in these problem spaces, uh, these days because it's such a rich environment.\nAwesome.\nAwesome.\nWell, Jason, thanks so much for jumping on and sharing a bit about what you've been working on.\nThanks a lot, Sam.\nIt was a great conversation.\nThanks for having me.\n[Music]\n",
  "dumpedAt": "2025-07-21T18:43:26.174Z"
}