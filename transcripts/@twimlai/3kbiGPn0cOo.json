{
  "episodeId": "3kbiGPn0cOo",
  "channelSlug": "@twimlai",
  "title": "Generative Benchmarking with Kelly Hong - 728",
  "publishedAt": "2025-04-23T16:52:07.000Z",
  "rawLines": [
    {
      "lang": "en",
      "text": "If you're familiar with like the",
      "offset": 0.08,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "retrieval space, uh MTB is a pretty",
      "offset": 1.199,
      "duration": 4.001
    },
    {
      "lang": "en",
      "text": "popular benchmark for embedding models.",
      "offset": 3.12,
      "duration": 3.759
    },
    {
      "lang": "en",
      "text": "If you see the release of any new",
      "offset": 5.2,
      "duration": 2.96
    },
    {
      "lang": "en",
      "text": "budding model, you'll probably see",
      "offset": 6.879,
      "duration": 2.881
    },
    {
      "lang": "en",
      "text": "something like, oh, our model achieved",
      "offset": 8.16,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "like this score on MTB. We outperform",
      "offset": 9.76,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "this other model on MTB. And people",
      "offset": 11.84,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "would just kind of take that score and",
      "offset": 14.32,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "assume, okay, this model is better just",
      "offset": 16,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "because it did better on this benchmark.",
      "offset": 17.76,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "But there are so many problems with",
      "offset": 19.92,
      "duration": 5.32
    },
    {
      "lang": "en",
      "text": "these public benchmarks.",
      "offset": 21.6,
      "duration": 3.64
    },
    {
      "lang": "en",
      "text": "All right, everyone. Welcome to another",
      "offset": 36,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "episode of the TwiML AI podcast. I am",
      "offset": 37.68,
      "duration": 4.879
    },
    {
      "lang": "en",
      "text": "your host, Sam Chrington. Today, I'm",
      "offset": 40.16,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "joined by Kelly Hong. Kelly is a",
      "offset": 42.559,
      "duration": 4.801
    },
    {
      "lang": "en",
      "text": "researcher at Chroma. Kelly, welcome to",
      "offset": 44.64,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "the podcast. Thank you so much for",
      "offset": 47.36,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "having me. I'm really looking forward to",
      "offset": 49.28,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "digging into our conversation. We're",
      "offset": 51.44,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "going to be talking about a project you",
      "offset": 53.76,
      "duration": 5.24
    },
    {
      "lang": "en",
      "text": "recently published called generative",
      "offset": 56.16,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "benchmarking. That one really resonated",
      "offset": 59,
      "duration": 4.28
    },
    {
      "lang": "en",
      "text": "with me for a few reasons. It touched on",
      "offset": 61.28,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "themes like synthetic generation data",
      "offset": 63.28,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "for",
      "offset": 65.439,
      "duration": 2.401
    },
    {
      "lang": "en",
      "text": "eval data leakage and overfitting on",
      "offset": 67.96,
      "duration": 5.08
    },
    {
      "lang": "en",
      "text": "public public benchmarks. Uh so a lot of",
      "offset": 70.64,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "interesting themes touched on there.",
      "offset": 73.04,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "Before we dive in, I'd love to have you",
      "offset": 74.96,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "share a little bit about your",
      "offset": 77.36,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "background. Yeah, of course. Um so yeah",
      "offset": 79.04,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "as you mentioned I'm currently doing",
      "offset": 81.52,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "research at Chroma. We're a company",
      "offset": 83.04,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "working on vector databases but we also",
      "offset": 85.6,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "work on research around retrieval as",
      "offset": 87.68,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "well. Um just to give a little bit more",
      "offset": 89.6,
      "duration": 4.559
    },
    {
      "lang": "en",
      "text": "background about myself I started my",
      "offset": 91.52,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "undergrad at uh UC Berkeley around 3",
      "offset": 94.159,
      "duration": 5.121
    },
    {
      "lang": "en",
      "text": "years ago studying CS. Um about two",
      "offset": 96.64,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "years in I got pretty interested in the",
      "offset": 99.28,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "space and like search and retrieval. So",
      "offset": 101.04,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "then I spend some time like building",
      "offset": 103.2,
      "duration": 2.959
    },
    {
      "lang": "en",
      "text": "projects around it, going deeper into",
      "offset": 104.72,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "the research and I would come across",
      "offset": 106.159,
      "duration": 5.041
    },
    {
      "lang": "en",
      "text": "Chromma a lot because um like I would",
      "offset": 108.799,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "use it in my projects but I also saw",
      "offset": 111.2,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "that they did a lot of good research",
      "offset": 112.799,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "around like chunking strategies like",
      "offset": 114.32,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "embedding adopters just ways to make",
      "offset": 116.079,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "your retrieval system better. So I got",
      "offset": 117.92,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "pretty interested in Chroma specifically",
      "offset": 120.479,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "and then I started talking to the team",
      "offset": 122.32,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "got this opportunity and now I'm here.",
      "offset": 124.479,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "So I'm on a gap year right now um from",
      "offset": 126.56,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "school and working here like basically",
      "offset": 129.119,
      "duration": 5.84
    },
    {
      "lang": "en",
      "text": "full-time. Uh and Chroma does come up uh",
      "offset": 131.12,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "particularly in a context of vector",
      "offset": 134.959,
      "duration": 6.241
    },
    {
      "lang": "en",
      "text": "databases and rag and uh rag continues",
      "offset": 136.8,
      "duration": 7.28
    },
    {
      "lang": "en",
      "text": "to be a topic of interest for folks",
      "offset": 141.2,
      "duration": 5.039
    },
    {
      "lang": "en",
      "text": "listening to the podcast and the folks",
      "offset": 144.08,
      "duration": 4.879
    },
    {
      "lang": "en",
      "text": "that I talk to in enterprises. So I",
      "offset": 146.239,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "think this will be an interesting",
      "offset": 148.959,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "conversation in that light as well. Uh",
      "offset": 150.08,
      "duration": 4.879
    },
    {
      "lang": "en",
      "text": "talk a little bit about the origin of",
      "offset": 152.56,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "the project. Was it already framed up",
      "offset": 154.959,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "when you got there or uh did you take",
      "offset": 156.879,
      "duration": 5.841
    },
    {
      "lang": "en",
      "text": "some time to kind of scope it out? Yeah.",
      "offset": 159.599,
      "duration": 4.481
    },
    {
      "lang": "en",
      "text": "Yeah, happy to talk about it. It's",
      "offset": 162.72,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "something that um the team has been",
      "offset": 164.08,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "thinking for a while and I've personally",
      "offset": 166,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "been thinking about like on my own as",
      "offset": 168.16,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "well. It just so happened that like we",
      "offset": 169.68,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "were pretty aligned on the same",
      "offset": 172,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "problems. But when I was like building",
      "offset": 173.44,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "out my own projects, like one thing that",
      "offset": 175.76,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "would constantly come up is how",
      "offset": 177.44,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "difficult it is to like systematically",
      "offset": 179.44,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "evaluate AI systems. Like if you think",
      "offset": 181.12,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "about this analogy with like software",
      "offset": 183.44,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "systems, it's very easy to evaluate",
      "offset": 185.84,
      "duration": 2.96
    },
    {
      "lang": "en",
      "text": "them. You have these like very simple",
      "offset": 187.599,
      "duration": 2.56
    },
    {
      "lang": "en",
      "text": "code tests. You like run them and then",
      "offset": 188.8,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "you get like a deterministic output. But",
      "offset": 190.159,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "if you have like AI systems, all of your",
      "offset": 192.56,
      "duration": 3.679
    },
    {
      "lang": "en",
      "text": "outputs are like probabilistic. You",
      "offset": 194.56,
      "duration": 2.72
    },
    {
      "lang": "en",
      "text": "don't really know what it's going to",
      "offset": 196.239,
      "duration": 2.881
    },
    {
      "lang": "en",
      "text": "output. So then like how do you exactly",
      "offset": 197.28,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "like evaluate them? I think like",
      "offset": 199.12,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "initially when I started building out in",
      "offset": 201.04,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "the space, I would just evaluate based",
      "offset": 202.56,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "off of vibes, which is really bad. You",
      "offset": 204.72,
      "duration": 3.519
    },
    {
      "lang": "en",
      "text": "know, like an output would like either",
      "offset": 206.4,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "feel good or it didn't look good. So",
      "offset": 208.239,
      "duration": 2.801
    },
    {
      "lang": "en",
      "text": "then I might change the prompt a little",
      "offset": 209.84,
      "duration": 2.56
    },
    {
      "lang": "en",
      "text": "bit, maybe change out my embedding",
      "offset": 211.04,
      "duration": 3.759
    },
    {
      "lang": "en",
      "text": "model, but there was really good like no",
      "offset": 212.4,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "good way to like systematically evaluate",
      "offset": 214.799,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "it. So I kind of felt the personal",
      "offset": 216.799,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "frustration there. Um, and that's",
      "offset": 218.48,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "something that Chroma um aimed to target",
      "offset": 220.319,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "uh for a while as well. Like we wanted",
      "offset": 223.04,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "people to be able to systematically",
      "offset": 224.64,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "debug their AI systems. So that's kind",
      "offset": 226.64,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "of where generative benchmarking came",
      "offset": 228.959,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "about. Um, you know, one of like the",
      "offset": 230.799,
      "duration": 4.241
    },
    {
      "lang": "en",
      "text": "main motivations for that was to like",
      "offset": 232.959,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "address this problem of like people not",
      "offset": 235.04,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "being able to evaluate their AI systems",
      "offset": 237.36,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "in like an easy way. If you think about",
      "offset": 239.36,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "like eval as a whole, um, it's not a",
      "offset": 241.439,
      "duration": 4.641
    },
    {
      "lang": "en",
      "text": "very like friendly topic to like a",
      "offset": 244.56,
      "duration": 2.8
    },
    {
      "lang": "en",
      "text": "developer who's just getting started",
      "offset": 246.08,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "with rag, they have to go pretty deep",
      "offset": 247.36,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "into like learning about how eval work,",
      "offset": 249.68,
      "duration": 4.479
    },
    {
      "lang": "en",
      "text": "what a benchmark is, and it's a lot of",
      "offset": 251.439,
      "duration": 4.481
    },
    {
      "lang": "en",
      "text": "work that people don't really spend a",
      "offset": 254.159,
      "duration": 3.441
    },
    {
      "lang": "en",
      "text": "lot of time on, but it's very important",
      "offset": 255.92,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "if you actually want to improve the",
      "offset": 257.6,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "performance of your AI system. So yeah,",
      "offset": 259.12,
      "duration": 4.639
    },
    {
      "lang": "en",
      "text": "one of like the core motivations was to",
      "offset": 261.759,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "just create a really easy way for people",
      "offset": 263.759,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "to evaluate their AI systems and",
      "offset": 265.68,
      "duration": 5.519
    },
    {
      "lang": "en",
      "text": "understand the importance of it. And I",
      "offset": 268.479,
      "duration": 5.761
    },
    {
      "lang": "en",
      "text": "think another motivation for that was to",
      "offset": 271.199,
      "duration": 5.921
    },
    {
      "lang": "en",
      "text": "address the problems of a lot of like uh",
      "offset": 274.24,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "current benchmarking methods. Um if",
      "offset": 277.12,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "you're familiar with like the retrieval",
      "offset": 278.88,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "space, uh MTB is a pretty popular",
      "offset": 280.32,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "benchmark for embedding models. Like if",
      "offset": 282.08,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "you see the release of any new embedding",
      "offset": 284.32,
      "duration": 2.96
    },
    {
      "lang": "en",
      "text": "model, you'll probably see something",
      "offset": 286.08,
      "duration": 2.96
    },
    {
      "lang": "en",
      "text": "like, oh, our model achieved like this",
      "offset": 287.28,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "score on MTU. we outperform this other",
      "offset": 289.04,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "model other model on MTB and people",
      "offset": 291.28,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "would just kind of take that score and",
      "offset": 294.08,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "assume okay this model is better just",
      "offset": 295.68,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "because it did better on this benchmark",
      "offset": 297.44,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "but there are so many problems with",
      "offset": 299.6,
      "duration": 5.039
    },
    {
      "lang": "en",
      "text": "these public benchmarks um I can go into",
      "offset": 301.36,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "these in like a bit more detail as well",
      "offset": 304.639,
      "duration": 3.201
    },
    {
      "lang": "en",
      "text": "but just to give a high level overview",
      "offset": 306.16,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "they're very generic so they don't",
      "offset": 307.84,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "reflect like the domain specific use",
      "offset": 310.16,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "cases of what people see in production",
      "offset": 311.919,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "the data sets are also very clean and",
      "offset": 314.16,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "polished whereas in the real world you",
      "offset": 316.08,
      "duration": 4.2
    },
    {
      "lang": "en",
      "text": "have very messy data",
      "offset": 318.08,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "And a lot of this data has probably been",
      "offset": 320.28,
      "duration": 5.72
    },
    {
      "lang": "en",
      "text": "seen by embedding models before. So you",
      "offset": 323.6,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "don't really know if you're testing for",
      "offset": 326,
      "duration": 3.759
    },
    {
      "lang": "en",
      "text": "like true retrieval or if they're just,",
      "offset": 327.6,
      "duration": 3.72
    },
    {
      "lang": "en",
      "text": "you know, doing this based off of",
      "offset": 329.759,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "memorization. So just kind of like going",
      "offset": 331.32,
      "duration": 4.68
    },
    {
      "lang": "en",
      "text": "off of, you know, all these problems of",
      "offset": 334.16,
      "duration": 3.039
    },
    {
      "lang": "en",
      "text": "people not really knowing how to",
      "offset": 336,
      "duration": 3.039
    },
    {
      "lang": "en",
      "text": "evaluate their A systems and also like",
      "offset": 337.199,
      "duration": 3.041
    },
    {
      "lang": "en",
      "text": "the problems with like a lot of like",
      "offset": 339.039,
      "duration": 2.961
    },
    {
      "lang": "en",
      "text": "public benchmarks kind of inspired this",
      "offset": 340.24,
      "duration": 5.32
    },
    {
      "lang": "en",
      "text": "idea of generative benchmarking. And you",
      "offset": 342,
      "duration": 8.479
    },
    {
      "lang": "en",
      "text": "mentioned that uh vibe uh vibe checking",
      "offset": 345.56,
      "duration": 8.199
    },
    {
      "lang": "en",
      "text": "is the predominant way that developers",
      "offset": 350.479,
      "duration": 5.761
    },
    {
      "lang": "en",
      "text": "are kind of assessing the performance of",
      "offset": 353.759,
      "duration": 6.561
    },
    {
      "lang": "en",
      "text": "their systems. There is a lot of I think",
      "offset": 356.24,
      "duration": 6.56
    },
    {
      "lang": "en",
      "text": "kind of a broad call for folks to take a",
      "offset": 360.32,
      "duration": 4.879
    },
    {
      "lang": "en",
      "text": "more rigorous approach to evaluation in",
      "offset": 362.8,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "the space. How do you see folks evolving",
      "offset": 365.199,
      "duration": 6.961
    },
    {
      "lang": "en",
      "text": "from Vive coding to a more rigorous or",
      "offset": 367.68,
      "duration": 7.68
    },
    {
      "lang": "en",
      "text": "scientific process to evaluating the",
      "offset": 372.16,
      "duration": 6.24
    },
    {
      "lang": "en",
      "text": "performance of their AI apps or rag",
      "offset": 375.36,
      "duration": 5.119
    },
    {
      "lang": "en",
      "text": "apps? What are the steps that folks",
      "offset": 378.4,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "typically take? The first thing that",
      "offset": 380.479,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "people do is they probably look into,",
      "offset": 382.8,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "you know, benchmarks like MTB and they",
      "offset": 384.639,
      "duration": 3.761
    },
    {
      "lang": "en",
      "text": "kind of see scores off of that and then",
      "offset": 386.96,
      "duration": 2.88
    },
    {
      "lang": "en",
      "text": "they make the decision on like which",
      "offset": 388.4,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "embedding model to use. But I think like",
      "offset": 389.84,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "um with these methods of like generative",
      "offset": 393.52,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "benchmarking, what we'll hopefully start",
      "offset": 395.28,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "to see is like people kind of like",
      "offset": 396.96,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "taking advantage of these tools that",
      "offset": 398.8,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "make evaluation like really easy. Like",
      "offset": 400.4,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "you don't really need to know like the",
      "offset": 402.4,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "details of like the entire evaluation",
      "offset": 404.24,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "pipeline. Like the generative",
      "offset": 406.56,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "benchmarking like notebook that we set",
      "offset": 408.4,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "out is just a very simple notebook. You",
      "offset": 410.08,
      "duration": 4.239
    },
    {
      "lang": "en",
      "text": "just upload your data, you fill in like",
      "offset": 412.08,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "the context and then you run a few cells",
      "offset": 414.319,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "in a notebook. It makes the process very",
      "offset": 416.24,
      "duration": 3.679
    },
    {
      "lang": "en",
      "text": "very easy. So I think like hopefully the",
      "offset": 417.919,
      "duration": 3.521
    },
    {
      "lang": "en",
      "text": "trend we'll start to see as people you",
      "offset": 419.919,
      "duration": 3.441
    },
    {
      "lang": "en",
      "text": "know start using these kinds of tools",
      "offset": 421.44,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "that make evals very approachable and I",
      "offset": 423.36,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "hope that like from that people get more",
      "offset": 426.8,
      "duration": 3.679
    },
    {
      "lang": "en",
      "text": "familiar with the idea of doing evals",
      "offset": 428.4,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "and also understand the importance of it",
      "offset": 430.479,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "as well and I think from that people can",
      "offset": 432.24,
      "duration": 4.799
    },
    {
      "lang": "en",
      "text": "get more into the details of like maybe",
      "offset": 435.039,
      "duration": 4.241
    },
    {
      "lang": "en",
      "text": "like aligning their LLM judge or like",
      "offset": 437.039,
      "duration": 3.761
    },
    {
      "lang": "en",
      "text": "adding more like human in the loop",
      "offset": 439.28,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "processes but yeah I think initially",
      "offset": 440.8,
      "duration": 4.799
    },
    {
      "lang": "en",
      "text": "we'll probably see people start to like",
      "offset": 443.44,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "favor more of these like um approachable",
      "offset": 445.599,
      "duration": 5.521
    },
    {
      "lang": "en",
      "text": "like evolve solutions. Yeah. Yeah. So",
      "offset": 448.8,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "you don't see generative benchmarking as",
      "offset": 451.12,
      "duration": 4.479
    },
    {
      "lang": "en",
      "text": "kind of an advanced stage that you",
      "offset": 453.84,
      "duration": 3.759
    },
    {
      "lang": "en",
      "text": "evolve to. It's meant to be kind of an",
      "offset": 455.599,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "easy thing that you can adopt uh pretty",
      "offset": 457.599,
      "duration": 5.281
    },
    {
      "lang": "en",
      "text": "early on. Yeah, for sure. It's kind of",
      "offset": 460.319,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "like um helping people with that first",
      "offset": 462.88,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "step. Uh if they don't have a golden",
      "offset": 465.599,
      "duration": 4.481
    },
    {
      "lang": "en",
      "text": "data set to start with because for a lot",
      "offset": 468,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "of retrieval systems, people probably",
      "offset": 470.08,
      "duration": 3.519
    },
    {
      "lang": "en",
      "text": "don't like log their queries when",
      "offset": 472.16,
      "duration": 2.8
    },
    {
      "lang": "en",
      "text": "they're getting started. they just have",
      "offset": 473.599,
      "duration": 3.361
    },
    {
      "lang": "en",
      "text": "their like set of documents right for",
      "offset": 474.96,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "the retrieval system. So they don't",
      "offset": 476.96,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "really have like a set of like query",
      "offset": 479.039,
      "duration": 3.761
    },
    {
      "lang": "en",
      "text": "document pairs to test their system on.",
      "offset": 480.8,
      "duration": 4.239
    },
    {
      "lang": "en",
      "text": "So we kind of help with like uh starting",
      "offset": 482.8,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "the process of like generating um that",
      "offset": 485.039,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "golden data set so people can start to",
      "offset": 486.8,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "evaluate. But the eventual goal there is",
      "offset": 489.36,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "for people to like continue iterating on",
      "offset": 492.16,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "that data set. You know for example if",
      "offset": 494.24,
      "duration": 3.519
    },
    {
      "lang": "en",
      "text": "they have like incoming user queries",
      "offset": 495.68,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "hopefully they use that to align their",
      "offset": 497.759,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "golden data set even further. maybe like",
      "offset": 499.28,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "improve the reachable system like",
      "offset": 501.759,
      "duration": 3.521
    },
    {
      "lang": "en",
      "text": "overall based on that. Um but yeah, I",
      "offset": 503.199,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "think this sort of more serves as like a",
      "offset": 505.28,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "starting step rather than like the end",
      "offset": 507.199,
      "duration": 6.64
    },
    {
      "lang": "en",
      "text": "um state of evaluation. Yeah, what I've",
      "offset": 510.4,
      "duration": 6.72
    },
    {
      "lang": "en",
      "text": "typically seen uh in my own projects and",
      "offset": 513.839,
      "duration": 4.961
    },
    {
      "lang": "en",
      "text": "in speaking with folks is like you",
      "offset": 517.12,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "mentioned you start with kind of vibe",
      "offset": 518.8,
      "duration": 3.679
    },
    {
      "lang": "en",
      "text": "checks. You you know put some prompts",
      "offset": 520.8,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "in, see what comes out. Uh and then",
      "offset": 522.479,
      "duration": 4.241
    },
    {
      "lang": "en",
      "text": "after you've done that for a while, like",
      "offset": 524.64,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "you collect those and now you have a",
      "offset": 526.72,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "short list of you know evals that you",
      "offset": 528.64,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "can kind of repeat if you want to tweak",
      "offset": 531.44,
      "duration": 4.68
    },
    {
      "lang": "en",
      "text": "change a different model or some",
      "offset": 534.24,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "parameter. Um and it sounds like uh",
      "offset": 536.12,
      "duration": 5.88
    },
    {
      "lang": "en",
      "text": "generative benchmarking might be the the",
      "offset": 539.6,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "next step or historically I'd think of",
      "offset": 542,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "the next step is like uh doing synthetic",
      "offset": 544.64,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "generation. synthetic generation is a",
      "offset": 547.2,
      "duration": 5.319
    },
    {
      "lang": "en",
      "text": "part of the overall generative",
      "offset": 550.08,
      "duration": 5.199
    },
    {
      "lang": "en",
      "text": "benchmarking process but the way you",
      "offset": 552.519,
      "duration": 6.281
    },
    {
      "lang": "en",
      "text": "incorporate synthetic data generation uh",
      "offset": 555.279,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "is you know specifically tailored as",
      "offset": 558.8,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "part of this process. So this might be a",
      "offset": 560.959,
      "duration": 5.361
    },
    {
      "lang": "en",
      "text": "good time for you to kind of talk",
      "offset": 563.76,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "through the overall generative",
      "offset": 566.32,
      "duration": 4.959
    },
    {
      "lang": "en",
      "text": "benchmarking process. At the high level,",
      "offset": 568.56,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "generative benchmarking is essentially",
      "offset": 571.279,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "generating a custom eval set based on",
      "offset": 572.959,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "your own data. And we do this for",
      "offset": 575.44,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "retrieval specifically. So you can kind",
      "offset": 577.36,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "of think of it as like okay, user inputs",
      "offset": 578.88,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "a set of documents, gives it some",
      "offset": 581.2,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "context on what their application is and",
      "offset": 582.8,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "then from that we generate queries to",
      "offset": 584.64,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "test your retrieval system on. And this",
      "offset": 586.32,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "is broken down into two main steps. We",
      "offset": 589.2,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "first do document filtering and then we",
      "offset": 591.6,
      "duration": 4.239
    },
    {
      "lang": "en",
      "text": "do the actual query generation. So I can",
      "offset": 593.92,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "kind of go through these two steps uh in",
      "offset": 595.839,
      "duration": 4.721
    },
    {
      "lang": "en",
      "text": "a bit more detail. before you do that,",
      "offset": 598.08,
      "duration": 5.92
    },
    {
      "lang": "en",
      "text": "why that two-step process as opposed to",
      "offset": 600.56,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "I've got a bunch of documents, give them",
      "offset": 604,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "to an LLM and say, &quot;Hey, generate a",
      "offset": 606,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "bunch of queries and now this becomes my",
      "offset": 608.08,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "uh my generated test set because I've",
      "offset": 610.8,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "got relationships between those",
      "offset": 613.68,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "documents and the queries. Yeah. So, we",
      "offset": 615.04,
      "duration": 4.6
    },
    {
      "lang": "en",
      "text": "have this two-step process of generative",
      "offset": 617.6,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "benchmarking. And we do this because we",
      "offset": 619.64,
      "duration": 4.439
    },
    {
      "lang": "en",
      "text": "realize the document uh filtering step",
      "offset": 622.16,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "which is the first step in our process",
      "offset": 624.079,
      "duration": 3.521
    },
    {
      "lang": "en",
      "text": "is actually very important because",
      "offset": 625.44,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "usually a lot of the time um there are",
      "offset": 627.6,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "cases where a few documents aren't very",
      "offset": 630.24,
      "duration": 3.279
    },
    {
      "lang": "en",
      "text": "relevant to your use case. Like for",
      "offset": 632.16,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "example, we were working with data from",
      "offset": 633.519,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "waste and biases but there are technical",
      "offset": 635.36,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "support bots. So it's basically like",
      "offset": 637.36,
      "duration": 2.88
    },
    {
      "lang": "en",
      "text": "this chatbot where you can talk to waste",
      "offset": 638.72,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "and biases um documentation. We noticed",
      "offset": 640.24,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "there were a few documents in there that",
      "offset": 642.72,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "were talking about like sort of funding",
      "offset": 644.16,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "news or just content that wasn't",
      "offset": 646.24,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "relevant to any kind of like developer",
      "offset": 648.56,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "using this technical chatbot. So we",
      "offset": 650.56,
      "duration": 4.68
    },
    {
      "lang": "en",
      "text": "first want to filter out those documents",
      "offset": 653.04,
      "duration": 4.479
    },
    {
      "lang": "en",
      "text": "because they're not reflective of what",
      "offset": 655.24,
      "duration": 4.599
    },
    {
      "lang": "en",
      "text": "users will actually ask about. And kind",
      "offset": 657.519,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "of the main goal with uh generative",
      "offset": 659.839,
      "duration": 3.361
    },
    {
      "lang": "en",
      "text": "benchmarking is to create a benchmark",
      "offset": 661.44,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "that's representative of your true use",
      "offset": 663.2,
      "duration": 3.759
    },
    {
      "lang": "en",
      "text": "case. So that means you know we want to",
      "offset": 665.12,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "filter out content that users wouldn't",
      "offset": 666.959,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "ask about in the first place. So we find",
      "offset": 668.8,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "that document filtering is a pretty like",
      "offset": 671.04,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "critical step in this. Like we kind of",
      "offset": 673.12,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "compared this to like a naive query",
      "offset": 675.12,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "generation approach where we did no um",
      "offset": 676.72,
      "duration": 4.239
    },
    {
      "lang": "en",
      "text": "document quality filtering, no like",
      "offset": 678.8,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "query string anything and then compared",
      "offset": 680.959,
      "duration": 3.761
    },
    {
      "lang": "en",
      "text": "it with that which I can talk about it",
      "offset": 682.8,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "um like in a bit more detail later on.",
      "offset": 684.72,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "Um but yeah, that's kind of like the",
      "offset": 686.959,
      "duration": 2.88
    },
    {
      "lang": "en",
      "text": "core motivation for breaking down",
      "offset": 688.16,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "breaking this down into two main steps.",
      "offset": 689.839,
      "duration": 3.761
    },
    {
      "lang": "en",
      "text": "like we want to make sure that we're",
      "offset": 691.92,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "selecting for content that users will",
      "offset": 693.6,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "realistically ask about and also",
      "offset": 695.36,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "generate queries in a way that's um",
      "offset": 697.44,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "realistic and reflects like queries that",
      "offset": 699.44,
      "duration": 4.36
    },
    {
      "lang": "en",
      "text": "you'll see in production. And so is that",
      "offset": 701.279,
      "duration": 5.361
    },
    {
      "lang": "en",
      "text": "filtering do you see the filtering step",
      "offset": 703.8,
      "duration": 5.88
    },
    {
      "lang": "en",
      "text": "as in and of itself kind of a core",
      "offset": 706.64,
      "duration": 6.16
    },
    {
      "lang": "en",
      "text": "differentiation for this approach or is",
      "offset": 709.68,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "it you know one of several? I think",
      "offset": 712.8,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "that's definitely one of the core",
      "offset": 715.36,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "differentiators. I say that and the way",
      "offset": 716.48,
      "duration": 4.479
    },
    {
      "lang": "en",
      "text": "that we are generating queries. Um",
      "offset": 718.56,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "because I think like these two parts",
      "offset": 720.959,
      "duration": 4.641
    },
    {
      "lang": "en",
      "text": "combined um kind of like make up what a",
      "offset": 722.64,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "real realistic user query is. Like first",
      "offset": 725.6,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "you have like the content like you want",
      "offset": 727.6,
      "duration": 3.359
    },
    {
      "lang": "en",
      "text": "to be asking about content that would",
      "offset": 729.04,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "actually be relevant for a user that's",
      "offset": 730.959,
      "duration": 3.521
    },
    {
      "lang": "en",
      "text": "using your application and also the",
      "offset": 732.56,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "style that you ask the query in. Like",
      "offset": 734.48,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "for example a lot of users using a",
      "offset": 736.959,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "technical chatbot like the one that way",
      "offset": 738.639,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "and biases has they probably wouldn't be",
      "offset": 740.639,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "asking like queries in complete like",
      "offset": 742.639,
      "duration": 4.801
    },
    {
      "lang": "en",
      "text": "sentences. it's more of like statements",
      "offset": 744.8,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "um which you typically see in a lot of",
      "offset": 747.44,
      "duration": 2.88
    },
    {
      "lang": "en",
      "text": "like chatbot applications like people",
      "offset": 748.959,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "are very vague with their queries it's",
      "offset": 750.32,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "not like super comprehensive so we want",
      "offset": 752.079,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "to reflect that as well so I think these",
      "offset": 753.92,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "two steps um like go hand in hand uh a",
      "offset": 755.92,
      "duration": 5.919
    },
    {
      "lang": "en",
      "text": "big part of the the two steps is",
      "offset": 758.32,
      "duration": 6.88
    },
    {
      "lang": "en",
      "text": "uh injecting the context into both the",
      "offset": 761.839,
      "duration": 5.761
    },
    {
      "lang": "en",
      "text": "filtering and the query generation what",
      "offset": 765.2,
      "duration": 5.319
    },
    {
      "lang": "en",
      "text": "what is that context yeah the context is",
      "offset": 767.6,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "basically like what your rag application",
      "offset": 770.519,
      "duration": 5.56
    },
    {
      "lang": "en",
      "text": "is for so for example in the of ways and",
      "offset": 773.6,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "biases like the context would be",
      "offset": 776.079,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "something like this is a technical",
      "offset": 777.76,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "support bot for ways and biases. A lot",
      "offset": 779.279,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "of the users would be people who are you",
      "offset": 781.44,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "know maybe training models or like using",
      "offset": 783.36,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "these kinds of like platforms. Um so",
      "offset": 785.68,
      "duration": 5.279
    },
    {
      "lang": "en",
      "text": "just giving some context to kind of tell",
      "offset": 788.8,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "a model like what to focus on. It's kind",
      "offset": 790.959,
      "duration": 4.961
    },
    {
      "lang": "en",
      "text": "of like a system prompt. Yeah. Yeah.",
      "offset": 793.6,
      "duration": 4.239
    },
    {
      "lang": "en",
      "text": "Kind of like that. I was thinking about",
      "offset": 795.92,
      "duration": 6.64
    },
    {
      "lang": "en",
      "text": "this process and its applicability to",
      "offset": 797.839,
      "duration": 7.281
    },
    {
      "lang": "en",
      "text": "uh my favorite use case which is I have",
      "offset": 802.56,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "a bunch of podcast transcripts and I",
      "offset": 805.12,
      "duration": 6.48
    },
    {
      "lang": "en",
      "text": "want to create a a rag chatbot for those",
      "offset": 808,
      "duration": 6.16
    },
    {
      "lang": "en",
      "text": "and I'm evaluating this as like oh how",
      "offset": 811.6,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "would this help me? Um, and one question",
      "offset": 814.16,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "that I had was, do you think it's",
      "offset": 817.36,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "applicable",
      "offset": 819.68,
      "duration": 5.279
    },
    {
      "lang": "en",
      "text": "uh to that use case? Because I'm not",
      "offset": 821.36,
      "duration": 6.24
    },
    {
      "lang": "en",
      "text": "sure that filtering is",
      "offset": 824.959,
      "duration": 5.201
    },
    {
      "lang": "en",
      "text": "uh filtering could be interesting at the",
      "offset": 827.6,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "chunk level. It's not necessarily",
      "offset": 830.16,
      "duration": 2.72
    },
    {
      "lang": "en",
      "text": "interesting at the document level.",
      "offset": 831.44,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "There's some chunks, probably a lot of",
      "offset": 832.88,
      "duration": 3.079
    },
    {
      "lang": "en",
      "text": "chunks that don't add a lot of",
      "offset": 834.56,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "information and aren't reflective of",
      "offset": 835.959,
      "duration": 5.081
    },
    {
      "lang": "en",
      "text": "user queries, but the document corpus as",
      "offset": 838.32,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "a whole, those are all relevant",
      "offset": 841.04,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "documents. Um I guess just to clarify",
      "offset": 843.68,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "like we're both doing like chunk",
      "offset": 846,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "filtering and document filtering. So we",
      "offset": 847.36,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "would filter for chunks as well because",
      "offset": 850.079,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "I think um in a lot of cases like even",
      "offset": 851.519,
      "duration": 3.521
    },
    {
      "lang": "en",
      "text": "if a document is relevant like for",
      "offset": 853.519,
      "duration": 4.241
    },
    {
      "lang": "en",
      "text": "example um this case of like podcast",
      "offset": 855.04,
      "duration": 4.479
    },
    {
      "lang": "en",
      "text": "transcripts all documents are relevant",
      "offset": 857.76,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "but there are probably chunks that",
      "offset": 859.519,
      "duration": 3.281
    },
    {
      "lang": "en",
      "text": "wouldn't be good to generate a query",
      "offset": 861.04,
      "duration": 3.599
    },
    {
      "lang": "en",
      "text": "from. Like for example say you have like",
      "offset": 862.8,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "the end of a podcast where um you're",
      "offset": 864.639,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "saying like goodbye or something like",
      "offset": 867.04,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "that. You probably don't Yeah, you",
      "offset": 868.56,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "probably don't want to retrieve that.",
      "offset": 870.56,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "And so we would filter out chunks like",
      "offset": 872.88,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "that because like what kind of question",
      "offset": 874.72,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "would you ask um for a chunk that just",
      "offset": 875.92,
      "duration": 5.599
    },
    {
      "lang": "en",
      "text": "says like goodbye goodbye. So yes um I",
      "offset": 878.32,
      "duration": 4.959
    },
    {
      "lang": "en",
      "text": "think like in this case it would be more",
      "offset": 881.519,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "focused on like filtering at the chunk",
      "offset": 883.279,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "level. You mentioned filtering and that",
      "offset": 885.6,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "second step is query generation. Uh what",
      "offset": 887.839,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "do you do different with the query",
      "offset": 891.12,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "generation part? Yeah for query",
      "offset": 893.519,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "generation is pretty simple. We first",
      "offset": 895.6,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "give it um like the same context that",
      "offset": 897.6,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "you would give to like document",
      "offset": 899.76,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "filtering. So this would just be like",
      "offset": 900.88,
      "duration": 3.759
    },
    {
      "lang": "en",
      "text": "okay this is a technical support bot and",
      "offset": 902.8,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "then etc. And we also give it some",
      "offset": 904.639,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "example queries as well and that's",
      "offset": 907.04,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "mainly for the purposes of kind of",
      "offset": 908.72,
      "duration": 4.559
    },
    {
      "lang": "en",
      "text": "steering the LLM to generate um like",
      "offset": 911.199,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "queries in a realistic style. So like I",
      "offset": 913.279,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "mentioned before a lot of people who use",
      "offset": 915.6,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "these chopout um applications the",
      "offset": 916.959,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "queries are very big. They're not like",
      "offset": 918.88,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "formed as like a complete question with",
      "offset": 921.12,
      "duration": 3.519
    },
    {
      "lang": "en",
      "text": "like a question mark and everything. So",
      "offset": 922.959,
      "duration": 3.201
    },
    {
      "lang": "en",
      "text": "we want to be able to reflect that as",
      "offset": 924.639,
      "duration": 4.801
    },
    {
      "lang": "en",
      "text": "well. So um yeah, we incorporated both",
      "offset": 926.16,
      "duration": 5.039
    },
    {
      "lang": "en",
      "text": "like the context and some example",
      "offset": 929.44,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "queries is the key distinction around",
      "offset": 931.199,
      "duration": 6.281
    },
    {
      "lang": "en",
      "text": "kind of the sample",
      "offset": 934.16,
      "duration": 6.16
    },
    {
      "lang": "en",
      "text": "queries relative to what you see users",
      "offset": 937.48,
      "duration": 6.52
    },
    {
      "lang": "en",
      "text": "doing when they're using LLMs to",
      "offset": 940.32,
      "duration": 7.84
    },
    {
      "lang": "en",
      "text": "generate test queries or is it more",
      "offset": 944,
      "duration": 6.16
    },
    {
      "lang": "en",
      "text": "distinct from what you see in kind of",
      "offset": 948.16,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "the big public uh benchmarks? Are you",
      "offset": 950.16,
      "duration": 5.84
    },
    {
      "lang": "en",
      "text": "asking about like how the example",
      "offset": 953.36,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "queries differ from like public",
      "offset": 956,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "benchmarks? One of the points you",
      "offset": 957.36,
      "duration": 5.039
    },
    {
      "lang": "en",
      "text": "referenced earlier is how with the",
      "offset": 959.839,
      "duration": 5.041
    },
    {
      "lang": "en",
      "text": "public benchmarks, the queries aren't",
      "offset": 962.399,
      "duration": 6.641
    },
    {
      "lang": "en",
      "text": "representative of actual user queries.",
      "offset": 964.88,
      "duration": 7.519
    },
    {
      "lang": "en",
      "text": "Users are um you know they take",
      "offset": 969.04,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "shortcuts. They're not always",
      "offset": 972.399,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "grammatically correct. The public you",
      "offset": 973.6,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "know queries are are more structured in",
      "offset": 976.399,
      "duration": 6.201
    },
    {
      "lang": "en",
      "text": "some some ways. Um, and",
      "offset": 978.8,
      "duration": 7.279
    },
    {
      "lang": "en",
      "text": "I'm asking if if that is the key thing",
      "offset": 982.6,
      "duration": 6.12
    },
    {
      "lang": "en",
      "text": "that you're trying to if kind of the",
      "offset": 986.079,
      "duration": 5.281
    },
    {
      "lang": "en",
      "text": "real user nature of the query is the key",
      "offset": 988.72,
      "duration": 5
    },
    {
      "lang": "en",
      "text": "thing that you're trying to model",
      "offset": 991.36,
      "duration": 4.599
    },
    {
      "lang": "en",
      "text": "or are",
      "offset": 993.72,
      "duration": 5.919
    },
    {
      "lang": "en",
      "text": "you trying in this step to correct",
      "offset": 995.959,
      "duration": 7.24
    },
    {
      "lang": "en",
      "text": "for the way you see developers or",
      "offset": 999.639,
      "duration": 6.841
    },
    {
      "lang": "en",
      "text": "engineers like manually creating sample",
      "offset": 1003.199,
      "duration": 5.521
    },
    {
      "lang": "en",
      "text": "queries to give to an LLM to generate",
      "offset": 1006.48,
      "duration": 5.359
    },
    {
      "lang": "en",
      "text": "more queries We're yeah we're trying to",
      "offset": 1008.72,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "model like what you would actually see",
      "offset": 1011.839,
      "duration": 4.721
    },
    {
      "lang": "en",
      "text": "in production um which is like pretty",
      "offset": 1013.68,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "different from like the public data sets",
      "offset": 1016.56,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "um that I spoke about earlier because I",
      "offset": 1018.48,
      "duration": 6.8
    },
    {
      "lang": "en",
      "text": "think um yeah like in these public data",
      "offset": 1022,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "sets like a lot of questions are very",
      "offset": 1025.28,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "like wellformed and polished so they",
      "offset": 1026.88,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "would contain a lot of like complete",
      "offset": 1028.72,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "questions and they'd be like highly",
      "offset": 1030,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "relevant to the documents as well but in",
      "offset": 1032.16,
      "duration": 4.799
    },
    {
      "lang": "en",
      "text": "like real production um data which we",
      "offset": 1034.72,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "got from like ways and biases like these",
      "offset": 1036.959,
      "duration": 3.281
    },
    {
      "lang": "en",
      "text": "weren't queries that are you know like",
      "offset": 1038.559,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "written by the ways and biases team.",
      "offset": 1040.24,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "There were queries that they actually",
      "offset": 1041.919,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "took from like users who used our",
      "offset": 1043.36,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "technical support bot. So we know that",
      "offset": 1045.039,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "it's reflective of what they will",
      "offset": 1046.72,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "actually see in production. So yeah we",
      "offset": 1048.319,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "wanted to make the distinction between",
      "offset": 1049.84,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "um you know like what you actually see",
      "offset": 1051.919,
      "duration": 5.041
    },
    {
      "lang": "en",
      "text": "in production versus like what um I",
      "offset": 1053.76,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "don't know you was just seeing like a",
      "offset": 1056.96,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "typical benchmark data set. Yeah. Yeah.",
      "offset": 1058.08,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "And I get the distinction between",
      "offset": 1060.72,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "uh the benchmark data set. I'm wondering",
      "offset": 1063.36,
      "duration": 6.96
    },
    {
      "lang": "en",
      "text": "if uh you mentioned that you pulled this",
      "offset": 1066,
      "duration": 6.559
    },
    {
      "lang": "en",
      "text": "information from the you know the",
      "offset": 1070.32,
      "duration": 5.84
    },
    {
      "lang": "en",
      "text": "weights and biases uh like a query log",
      "offset": 1072.559,
      "duration": 5.841
    },
    {
      "lang": "en",
      "text": "and I'm wondering if you have a sense",
      "offset": 1076.16,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "for if uh someone at weights and biases",
      "offset": 1078.4,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "was like building out these queries",
      "offset": 1081.12,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "manually would they be different from",
      "offset": 1082.799,
      "duration": 5.601
    },
    {
      "lang": "en",
      "text": "what they would see in the in the test",
      "offset": 1084.96,
      "duration": 5.92
    },
    {
      "lang": "en",
      "text": "log in the style of queries I imagine it",
      "offset": 1088.4,
      "duration": 4.639
    },
    {
      "lang": "en",
      "text": "would be very similar I think it's",
      "offset": 1090.88,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "pretty easy once you see like a of like",
      "offset": 1093.039,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "actual queries from like users. You can",
      "offset": 1095.28,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "like replicate them. But I think maybe",
      "offset": 1097.039,
      "duration": 5.121
    },
    {
      "lang": "en",
      "text": "one distinction there would be like the",
      "offset": 1099.36,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "content that the queries focused on",
      "offset": 1102.16,
      "duration": 2.56
    },
    {
      "lang": "en",
      "text": "because when we were looking at the",
      "offset": 1103.679,
      "duration": 2.561
    },
    {
      "lang": "en",
      "text": "data, one interesting thing we noticed",
      "offset": 1104.72,
      "duration": 2.72
    },
    {
      "lang": "en",
      "text": "was that there were some queries that",
      "offset": 1106.24,
      "duration": 2.64
    },
    {
      "lang": "en",
      "text": "just could not be answered by any",
      "offset": 1107.44,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "documents in the corpus and if you were",
      "offset": 1108.88,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "just like a waste and biases like",
      "offset": 1111.44,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "engineer like writing queries and you",
      "offset": 1112.799,
      "duration": 5.041
    },
    {
      "lang": "en",
      "text": "wouldn't focus on queries that are not",
      "offset": 1114.96,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "answerable by your document corpus. So I",
      "offset": 1117.84,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "think that was like another interesting",
      "offset": 1120.32,
      "duration": 4.239
    },
    {
      "lang": "en",
      "text": "point that we saw like if you are able",
      "offset": 1121.84,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "to work with like real production data",
      "offset": 1124.559,
      "duration": 4.641
    },
    {
      "lang": "en",
      "text": "then you can also kind of use that to",
      "offset": 1126.32,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "you know evaluate how well your document",
      "offset": 1129.2,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "corpus reflects what your users are",
      "offset": 1131.12,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "asking about. So I think like the style",
      "offset": 1132.72,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "of queries will probably be very similar",
      "offset": 1135.12,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "but maybe the content um that content of",
      "offset": 1136.72,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "queries that users ask about will be",
      "offset": 1139.6,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "pretty different. Again you filter your",
      "offset": 1141.2,
      "duration": 4.479
    },
    {
      "lang": "en",
      "text": "chunks then you generate your queries.",
      "offset": 1143.76,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "What what's next? Yeah, after you",
      "offset": 1145.679,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "generate your queries, you have your",
      "offset": 1147.679,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "query document pairs. So this is how",
      "offset": 1149.36,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "like um evaluation typically works for",
      "offset": 1151.6,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "like evaluating an embedding model. You",
      "offset": 1153.84,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "have a query document pair. You embed",
      "offset": 1155.52,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "like your document corpus. You embed",
      "offset": 1157.76,
      "duration": 2.799
    },
    {
      "lang": "en",
      "text": "your queries and then you see whether",
      "offset": 1159.2,
      "duration": 2.8
    },
    {
      "lang": "en",
      "text": "you retrieve that document in like the",
      "offset": 1160.559,
      "duration": 3.281
    },
    {
      "lang": "en",
      "text": "top K results. Um that's how you get",
      "offset": 1162,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "like recall a K. So then we basically",
      "offset": 1163.84,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "run that evaluation for our generated",
      "offset": 1166.08,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "data set and then we compare to Gren um",
      "offset": 1168.16,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "the ground truth queries as well. that",
      "offset": 1170.16,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "kind of serves as like our ground truth",
      "offset": 1172.559,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "for kind of testing whether our generate",
      "offset": 1174.64,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "queries actually reflect um like what",
      "offset": 1176.88,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "you would see in production. And those",
      "offset": 1179.2,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "ground truth queries are the examples",
      "offset": 1181.12,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "that were given or where did those come",
      "offset": 1183.2,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "from? Oh yeah. So these were the actual",
      "offset": 1186.48,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "queries that were logged um from like",
      "offset": 1188.32,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "their technical biases case. Got it.",
      "offset": 1190.559,
      "duration": 4.721
    },
    {
      "lang": "en",
      "text": "Yes, for waste and biases. So it would",
      "offset": 1193.52,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "be like the log queries and then we um",
      "offset": 1195.28,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "yeah we like manually labeled all the",
      "offset": 1197.919,
      "duration": 3.321
    },
    {
      "lang": "en",
      "text": "data and then use that to test for",
      "offset": 1199.679,
      "duration": 3.281
    },
    {
      "lang": "en",
      "text": "representativeness. But this was mainly",
      "offset": 1201.24,
      "duration": 3.88
    },
    {
      "lang": "en",
      "text": "for um like our research report. But if",
      "offset": 1202.96,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "you are maybe like a developer using",
      "offset": 1205.12,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "this tool, you would just end up with",
      "offset": 1206.4,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "that set of like query document pairs",
      "offset": 1208.24,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "and then use that to evaluate your",
      "offset": 1210.08,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "retrieval system because kind of like",
      "offset": 1211.84,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "from our end we kind of did the work of",
      "offset": 1213.84,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "demonstrating that these are",
      "offset": 1216.32,
      "duration": 2.56
    },
    {
      "lang": "en",
      "text": "representative of what you'll see in",
      "offset": 1217.44,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "production. So then like us users can",
      "offset": 1218.88,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "just take that generated data set and",
      "offset": 1220.88,
      "duration": 4.44
    },
    {
      "lang": "en",
      "text": "use that for evos. Uh and you",
      "offset": 1222.64,
      "duration": 5.84
    },
    {
      "lang": "en",
      "text": "mentioned that one of the things that",
      "offset": 1225.32,
      "duration": 5.88
    },
    {
      "lang": "en",
      "text": "having the an eval system allows you to",
      "offset": 1228.48,
      "duration": 6.88
    },
    {
      "lang": "en",
      "text": "do is to swap out different uh embedding",
      "offset": 1231.2,
      "duration": 6.719
    },
    {
      "lang": "en",
      "text": "models to play with junking strategies",
      "offset": 1235.36,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "that kind of thing. A question that",
      "offset": 1237.919,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "comes up frequently is how much does",
      "offset": 1239.6,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "that stuff really matter? What's your",
      "offset": 1242,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "take on that based on what you've seen?",
      "offset": 1245.28,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "I think it matters a lot. I think we've",
      "offset": 1247.12,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "seen some pretty distinct differences",
      "offset": 1249.36,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "between um embedding models. And I think",
      "offset": 1251.44,
      "duration": 6.239
    },
    {
      "lang": "en",
      "text": "one of the um one of the key things we",
      "offset": 1254.96,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "saw when working with like production",
      "offset": 1257.679,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "data was that um like we saw that Gina",
      "offset": 1259.2,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "AI's model like perform slightly worse",
      "offset": 1262.08,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "than like OpenAI's text embedding large",
      "offset": 1264,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "model. Um which actually conflicted with",
      "offset": 1266,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "like the MTEP scores that they released.",
      "offset": 1267.84,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "So in spite of performing better on the",
      "offset": 1270.24,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "public benchmarks, it performed worse on",
      "offset": 1272.32,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "real world data. Yeah. So that kind of",
      "offset": 1274.88,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "goes to show like oh like these",
      "offset": 1276.96,
      "duration": 3.599
    },
    {
      "lang": "en",
      "text": "performance on like public benchmarks",
      "offset": 1279.039,
      "duration": 3.201
    },
    {
      "lang": "en",
      "text": "don't necessarily translate to your",
      "offset": 1280.559,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "specific use case and yeah we saw some",
      "offset": 1282.24,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "pretty like clear differences between",
      "offset": 1284.799,
      "duration": 3.521
    },
    {
      "lang": "en",
      "text": "like the rankings of embedding models.",
      "offset": 1286.4,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "Um we saw that like voyage uh voyages",
      "offset": 1288.32,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "three large model performed best. So",
      "offset": 1290.559,
      "duration": 3.201
    },
    {
      "lang": "en",
      "text": "like we'd recommend them to use",
      "offset": 1292.32,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "something like that. And um we didn't",
      "offset": 1293.76,
      "duration": 5.84
    },
    {
      "lang": "en",
      "text": "extensively test out like you know like",
      "offset": 1297.28,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "chunking strategies or we have like",
      "offset": 1299.6,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "another report on that and I think there",
      "offset": 1301.28,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "are some other things you can do as well",
      "offset": 1303.44,
      "duration": 2.719
    },
    {
      "lang": "en",
      "text": "like contextual rewriting. We noticed",
      "offset": 1304.72,
      "duration": 2.959
    },
    {
      "lang": "en",
      "text": "that a lot of chunks were missing",
      "offset": 1306.159,
      "duration": 2.801
    },
    {
      "lang": "en",
      "text": "context, which is a pretty common",
      "offset": 1307.679,
      "duration": 2.561
    },
    {
      "lang": "en",
      "text": "problem in a lot of these raw",
      "offset": 1308.96,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "applications. You can just like chunk up",
      "offset": 1310.24,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "documents, but some chunks might um just",
      "offset": 1312.08,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "not be very valuable if they don't have",
      "offset": 1314.96,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "any context on where they came from. And",
      "offset": 1316.48,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "trying to fix like problems like those",
      "offset": 1319.6,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "actually boost retrieval performance a",
      "offset": 1321.12,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "lot. Enthropic did like a research",
      "offset": 1322.72,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "report on that as well. So yeah, these",
      "offset": 1324.4,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "strategies make a pretty big difference",
      "offset": 1326.72,
      "duration": 4.959
    },
    {
      "lang": "en",
      "text": "in um your retrieval performance. Is",
      "offset": 1328.559,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "that typically done in your chunker?",
      "offset": 1331.679,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "just asking an LLM to capture the",
      "offset": 1333.919,
      "duration": 4.961
    },
    {
      "lang": "en",
      "text": "context and uh prepend it to whatever",
      "offset": 1336.159,
      "duration": 4.801
    },
    {
      "lang": "en",
      "text": "the chunk is. I wouldn't say it's super",
      "offset": 1338.88,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "common because it is pretty expensive to",
      "offset": 1340.96,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "do. I mean, you're like passing it into",
      "offset": 1343.36,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "LLM every time. So, it really depends on",
      "offset": 1344.96,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "your use case. If you have like tens of",
      "offset": 1347.6,
      "duration": 3.439
    },
    {
      "lang": "en",
      "text": "thousands of um chunks, probably doesn't",
      "offset": 1349.12,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "make sense. You probably want like a",
      "offset": 1351.039,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "more effective approach to maybe like",
      "offset": 1352.24,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "selectively choose chunks to like",
      "offset": 1354.159,
      "duration": 5.041
    },
    {
      "lang": "en",
      "text": "rewrite. Um but yeah, I guess it really",
      "offset": 1356.08,
      "duration": 6.32
    },
    {
      "lang": "en",
      "text": "depends on the use case. Do you focus on",
      "offset": 1359.2,
      "duration": 6.479
    },
    {
      "lang": "en",
      "text": "a particular set of metrics in uh",
      "offset": 1362.4,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "talking about this work? We mostly",
      "offset": 1365.679,
      "duration": 5.681
    },
    {
      "lang": "en",
      "text": "looked at recall at K. Um just because",
      "offset": 1367.36,
      "duration": 6.24
    },
    {
      "lang": "en",
      "text": "uh there are other scores that are used",
      "offset": 1371.36,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "um in a lot of these like retrieval like",
      "offset": 1373.6,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "research papers like people use like",
      "offset": 1375.36,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "NGCG but like one thing um that has been",
      "offset": 1376.88,
      "duration": 5.84
    },
    {
      "lang": "en",
      "text": "like brought up is that like the ranking",
      "offset": 1380,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "of like chunks in like the context of an",
      "offset": 1382.72,
      "duration": 4.959
    },
    {
      "lang": "en",
      "text": "LLM doesn't really matter. um it doesn't",
      "offset": 1384.88,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "affect the performance of an LLM if you",
      "offset": 1387.679,
      "duration": 3.041
    },
    {
      "lang": "en",
      "text": "have like the relevant chunk and like",
      "offset": 1389.44,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "the beginning versus like the end. So we",
      "offset": 1390.72,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "don't look at NDCG. We just look at like",
      "offset": 1393.2,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "recall which is like was retrieve was a",
      "offset": 1394.96,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "relevant document retrieved or not.",
      "offset": 1397.52,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "Presumably if it's in there somewhere",
      "offset": 1399.76,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "the LLM will find the information it",
      "offset": 1401.76,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "needs and create the right response.",
      "offset": 1403.52,
      "duration": 5.519
    },
    {
      "lang": "en",
      "text": "Yeah. Yeah. So yeah, I think like rather",
      "offset": 1405.76,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "than looking at like the rankings, it's",
      "offset": 1409.039,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "more important to just see like whether",
      "offset": 1410.64,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "it was retrieved or not. Are other",
      "offset": 1412.159,
      "duration": 6.64
    },
    {
      "lang": "en",
      "text": "metrics like groundedness and uh things",
      "offset": 1415.52,
      "duration": 5.519
    },
    {
      "lang": "en",
      "text": "like that are those out of scope for",
      "offset": 1418.799,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "this work? Yeah, we didn't look at",
      "offset": 1421.039,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "groundedness. We purely just looked at",
      "offset": 1422.72,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "um like numerical metrics. I think like",
      "offset": 1424.799,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "for groundedness a lot of people use",
      "offset": 1427.36,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "like LLM judges for that. Um I think for",
      "offset": 1428.72,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "that you do need like a good level of",
      "offset": 1432.24,
      "duration": 3.439
    },
    {
      "lang": "en",
      "text": "like alignment which I think could be",
      "offset": 1434.24,
      "duration": 3.439
    },
    {
      "lang": "en",
      "text": "interesting for um maybe some future",
      "offset": 1435.679,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "extensions of this but yeah we only",
      "offset": 1437.679,
      "duration": 5.201
    },
    {
      "lang": "en",
      "text": "looked at metrics for these. In the",
      "offset": 1440.08,
      "duration": 6.28
    },
    {
      "lang": "en",
      "text": "report you talked about LLM as judge and",
      "offset": 1442.88,
      "duration": 6.799
    },
    {
      "lang": "en",
      "text": "alignedness. Um can you elaborate on",
      "offset": 1446.36,
      "duration": 5.559
    },
    {
      "lang": "en",
      "text": "where that comes into play? Of course.",
      "offset": 1449.679,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "Uh so alignment is a very important part",
      "offset": 1451.919,
      "duration": 5.041
    },
    {
      "lang": "en",
      "text": "of this work. Uh we specifically use",
      "offset": 1454,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "this framework called Ebalgen which is",
      "offset": 1456.96,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "basically like this um I guess like",
      "offset": 1459.36,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "framework for aligning an LLM judge to",
      "offset": 1461.2,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "human preferences. Because if we just",
      "offset": 1463.52,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "blindly use an LLM judge, it's not",
      "offset": 1465.52,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "guaranteed to judge in the way that",
      "offset": 1467.2,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "humans do. For example, when we were",
      "offset": 1468.88,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "first um using an LLM judge to filter",
      "offset": 1470.88,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "our documents, we compared that to like",
      "offset": 1472.96,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "ground truth human labels and I think it",
      "offset": 1474.64,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "only got around like 46% alignment,",
      "offset": 1476.24,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "which is pretty bad. So, we basically",
      "offset": 1478.96,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "use this framework or like eval to like",
      "offset": 1481.6,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "iterate on our LLM criteria and get it",
      "offset": 1483.6,
      "duration": 5.439
    },
    {
      "lang": "en",
      "text": "up to like over 70%. So, I think a",
      "offset": 1485.6,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "mistake that a lot of people make is",
      "offset": 1489.039,
      "duration": 3.281
    },
    {
      "lang": "en",
      "text": "they just blindly use an LLM judge",
      "offset": 1490.48,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "without any alignment just assuming that",
      "offset": 1492.32,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "it is aligned. But I think uh we're too",
      "offset": 1494.24,
      "duration": 5.039
    },
    {
      "lang": "en",
      "text": "far from that right now and we do need",
      "offset": 1497.52,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "some level of like human alignment to",
      "offset": 1499.279,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "actually like confidently put the LLM",
      "offset": 1500.88,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "judge to use. And to dig in on that uh",
      "offset": 1503.2,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "what you're doing there is you're asking",
      "offset": 1506.24,
      "duration": 6.08
    },
    {
      "lang": "en",
      "text": "the LLM to determine whether a chunk or",
      "offset": 1508.32,
      "duration": 6.479
    },
    {
      "lang": "en",
      "text": "document is relevant and that's the",
      "offset": 1512.32,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "filter the filtering process. So",
      "offset": 1514.799,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "basically is is it like good to generate",
      "offset": 1517.12,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "a query from or not based on this use",
      "offset": 1518.799,
      "duration": 5.441
    },
    {
      "lang": "en",
      "text": "case. Before we dig in on Evalgen, I'm",
      "offset": 1520.72,
      "duration": 6.4
    },
    {
      "lang": "en",
      "text": "curious uh how sensitive your results",
      "offset": 1524.24,
      "duration": 5.84
    },
    {
      "lang": "en",
      "text": "were to the prompting that you use for",
      "offset": 1527.12,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "LLM as judge. I guess we like noticed",
      "offset": 1530.08,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "like the prompting strategies like",
      "offset": 1532.32,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "through using evolen. I guess they both",
      "offset": 1533.76,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "kind of go like hand in hand because",
      "offset": 1535.76,
      "duration": 2.799
    },
    {
      "lang": "en",
      "text": "like evolen is like essentially",
      "offset": 1537.2,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "evaluating like how well does like the",
      "offset": 1538.559,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "prompting strategy like allow your LLM",
      "offset": 1540.96,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "judge to be like aligned with your",
      "offset": 1543.279,
      "duration": 4.241
    },
    {
      "lang": "en",
      "text": "preferences. So yeah, we noticed it was",
      "offset": 1544.48,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "pretty sensitive because we were just",
      "offset": 1547.52,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "iterating on like three criteria and",
      "offset": 1548.96,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "based on like how we were wording those",
      "offset": 1551.76,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "criteria or like how we were maybe like",
      "offset": 1553.279,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "taking out one and like adding in like",
      "offset": 1555.6,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "another, it would range like quite a",
      "offset": 1557.12,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "bit. So like um we said in our report it",
      "offset": 1558.88,
      "duration": 5.279
    },
    {
      "lang": "en",
      "text": "improved from like 46% to I think like",
      "offset": 1561.52,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "around somewhere like in the 70s. Um so",
      "offset": 1564.159,
      "duration": 4.481
    },
    {
      "lang": "en",
      "text": "that's a pretty big difference just",
      "offset": 1567.2,
      "duration": 2.959
    },
    {
      "lang": "en",
      "text": "based on like how you're prompting the",
      "offset": 1568.64,
      "duration": 5.039
    },
    {
      "lang": "en",
      "text": "LLM judge. So yes, we did notice that LM",
      "offset": 1570.159,
      "duration": 5.601
    },
    {
      "lang": "en",
      "text": "are very very sensitive to prompting.",
      "offset": 1573.679,
      "duration": 4.961
    },
    {
      "lang": "en",
      "text": "Can you talk about eval in a bit more",
      "offset": 1575.76,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "detail how that process works? Yeah.",
      "offset": 1578.64,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "Yeah, of course. So for evalgen, you",
      "offset": 1580.88,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "basically need um a set of criteria. So",
      "offset": 1583.2,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "in our example, we just use criteria",
      "offset": 1586.32,
      "duration": 4.239
    },
    {
      "lang": "en",
      "text": "like relevance. So like is this relevant",
      "offset": 1588.48,
      "duration": 4.799
    },
    {
      "lang": "en",
      "text": "to our context? We use like completeness",
      "offset": 1590.559,
      "duration": 4.561
    },
    {
      "lang": "en",
      "text": "um which is just you know how is like",
      "offset": 1593.279,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "the overall quality of this LLM judge. I",
      "offset": 1595.12,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "think like one other criteria as well.",
      "offset": 1597.919,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "But yeah, basically you would like write",
      "offset": 1600.24,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "out these criteria and then you would",
      "offset": 1601.6,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "also have um like ground truth labels",
      "offset": 1603.36,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "for your documents. So we had like 200",
      "offset": 1606,
      "duration": 3.679
    },
    {
      "lang": "en",
      "text": "documents and then we manually label",
      "offset": 1607.679,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "them as either like good or bad. So it's",
      "offset": 1609.679,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "very simple. And then for the 200",
      "offset": 1611.6,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "documents, we would pass them into the",
      "offset": 1614.159,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "LLM with their um criteria and just ask",
      "offset": 1615.6,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "it to you know evaluate based on that",
      "offset": 1618.24,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "criteria like does it meet this criteria",
      "offset": 1620.64,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "or not and then we would have a",
      "offset": 1622.88,
      "duration": 3.679
    },
    {
      "lang": "en",
      "text": "threshold as well like if it passed like",
      "offset": 1624.799,
      "duration": 3.521
    },
    {
      "lang": "en",
      "text": "two out of the three criteria then we",
      "offset": 1626.559,
      "duration": 4.881
    },
    {
      "lang": "en",
      "text": "would judge that as um being like a good",
      "offset": 1628.32,
      "duration": 5.599
    },
    {
      "lang": "en",
      "text": "quality document. So that's how we got",
      "offset": 1631.44,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "the um LLM judge labels and once we had",
      "offset": 1633.919,
      "duration": 4.481
    },
    {
      "lang": "en",
      "text": "those labels we would compare them with",
      "offset": 1636.96,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "our ground truth and then that's how we",
      "offset": 1638.4,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "get the alignment score. So based on the",
      "offset": 1640.32,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "alignment score we we would iterate on",
      "offset": 1642.72,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "our criteria. We would also have like",
      "offset": 1645.36,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "criteria specific scores as well. So",
      "offset": 1646.72,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "that kind of helped us to determine like",
      "offset": 1648.4,
      "duration": 3.759
    },
    {
      "lang": "en",
      "text": "if one criteria's alignment score was",
      "offset": 1649.84,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "very low, we would maybe like rewrite",
      "offset": 1652.159,
      "duration": 3.281
    },
    {
      "lang": "en",
      "text": "the criteria or just like take it out",
      "offset": 1653.919,
      "duration": 3.521
    },
    {
      "lang": "en",
      "text": "like altogether. And we would kind of",
      "offset": 1655.44,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "like use that iterative process to you",
      "offset": 1657.44,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "know modify the prompt essentially and",
      "offset": 1659.279,
      "duration": 5
    },
    {
      "lang": "en",
      "text": "increase our score over time.",
      "offset": 1662,
      "duration": 7.679
    },
    {
      "lang": "en",
      "text": "How sensitive was all of this to the the",
      "offset": 1664.279,
      "duration": 8.28
    },
    {
      "lang": "en",
      "text": "document size? Uh or you mentioned",
      "offset": 1669.679,
      "duration": 4.641
    },
    {
      "lang": "en",
      "text": "earlier that you're at least for",
      "offset": 1672.559,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "filtering you were doing it at the",
      "offset": 1674.32,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "document level and the chunk level. Were",
      "offset": 1675.679,
      "duration": 5.441
    },
    {
      "lang": "en",
      "text": "you also judging relevance? That's also",
      "offset": 1677.84,
      "duration": 4.719
    },
    {
      "lang": "en",
      "text": "well that's part of the filtering. So",
      "offset": 1681.12,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "that's also document and chunk level.",
      "offset": 1682.559,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "Oh, we were we were doing the filtering",
      "offset": 1684.96,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "like all all on the chunk level. So all",
      "offset": 1687.279,
      "duration": 5.041
    },
    {
      "lang": "en",
      "text": "on the chunk level. Got it. And so the",
      "offset": 1689.6,
      "duration": 5.439
    },
    {
      "lang": "en",
      "text": "labeling uh of relevance that was all",
      "offset": 1692.32,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "done at the chunk level as well. Yes.",
      "offset": 1695.039,
      "duration": 3.441
    },
    {
      "lang": "en",
      "text": "Yes.",
      "offset": 1696.96,
      "duration": 2.8
    },
    {
      "lang": "en",
      "text": "Yeah. You would pass a chunk into the",
      "offset": 1698.48,
      "duration": 2.96
    },
    {
      "lang": "en",
      "text": "LLM. Yeah. I think maybe I should",
      "offset": 1699.76,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "clarify that because I think a lot of",
      "offset": 1701.44,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "people they don't immediately know like",
      "offset": 1702.96,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "what a chunk is. I would typically just",
      "offset": 1705.6,
      "duration": 5.199
    },
    {
      "lang": "en",
      "text": "say like document. So um yes. So it was",
      "offset": 1707.6,
      "duration": 7.84
    },
    {
      "lang": "en",
      "text": "just a chunk into the LLM judge and the",
      "offset": 1710.799,
      "duration": 6.721
    },
    {
      "lang": "en",
      "text": "chunk size. I'm trying to get a sense",
      "offset": 1715.44,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "for, you know, if someone is looking at",
      "offset": 1717.52,
      "duration": 4.92
    },
    {
      "lang": "en",
      "text": "applying this like what the data",
      "offset": 1719.84,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "labeling process looks like. Are they",
      "offset": 1722.44,
      "duration": 6.28
    },
    {
      "lang": "en",
      "text": "applying a, you know, say you've got,",
      "offset": 1725.44,
      "duration": 6.16
    },
    {
      "lang": "en",
      "text": "you know, 500, you know, actual",
      "offset": 1728.72,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "documents? You then chunk those. What",
      "offset": 1731.6,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "chunk size are you looking at? Does it",
      "offset": 1734,
      "duration": 5.559
    },
    {
      "lang": "en",
      "text": "matter? uh and you know for these",
      "offset": 1735.6,
      "duration": 6.24
    },
    {
      "lang": "en",
      "text": "purposes and how many of those chunks",
      "offset": 1739.559,
      "duration": 5.561
    },
    {
      "lang": "en",
      "text": "are they labeling uh in order to kind of",
      "offset": 1741.84,
      "duration": 6.8
    },
    {
      "lang": "en",
      "text": "kickstart this process? Yeah. Yeah. So",
      "offset": 1745.12,
      "duration": 6.88
    },
    {
      "lang": "en",
      "text": "in our case we had around like 13,000",
      "offset": 1748.64,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "documents and then out of those we would",
      "offset": 1752,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "manually label 200 which is a pretty",
      "offset": 1753.6,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "small percentage like it doesn't require",
      "offset": 1756,
      "duration": 5.679
    },
    {
      "lang": "en",
      "text": "that much human labeling. So um oh I",
      "offset": 1757.679,
      "duration": 6.72
    },
    {
      "lang": "en",
      "text": "should clarify 13,000 chunks of from",
      "offset": 1761.679,
      "duration": 4.801
    },
    {
      "lang": "en",
      "text": "documents and then we would manually",
      "offset": 1764.399,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "label 200 chunks. So um yeah we would do",
      "offset": 1766.48,
      "duration": 6.079
    },
    {
      "lang": "en",
      "text": "that and all the documents were like",
      "offset": 1770.399,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "pre-chunked for us. So we didn't really",
      "offset": 1772.559,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "do any chunking on our end but I say",
      "offset": 1774,
      "duration": 4.76
    },
    {
      "lang": "en",
      "text": "they were typically around maybe",
      "offset": 1776.399,
      "duration": 6.081
    },
    {
      "lang": "en",
      "text": "like 400 tokens like somewhere around",
      "offset": 1778.76,
      "duration": 6.84
    },
    {
      "lang": "en",
      "text": "that range. Um but yeah I think your",
      "offset": 1782.48,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "chunking strategy really depends on your",
      "offset": 1785.6,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "use case as well. like if you have a",
      "offset": 1787.2,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "very like um like information like dense",
      "offset": 1788.64,
      "duration": 5.039
    },
    {
      "lang": "en",
      "text": "uh document then you probably want to",
      "offset": 1792.24,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "have like smaller chunks. So um you're",
      "offset": 1793.679,
      "duration": 4.801
    },
    {
      "lang": "en",
      "text": "able to like kind of like isolate like",
      "offset": 1796.48,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "those like semantic differences. But um",
      "offset": 1798.48,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "I think for like waste and biases like",
      "offset": 1800.88,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "this um chunking strategy made sense for",
      "offset": 1802.48,
      "duration": 5.679
    },
    {
      "lang": "en",
      "text": "them. But yeah basically like out of",
      "offset": 1805.44,
      "duration": 4.479
    },
    {
      "lang": "en",
      "text": "like 13,000 chunks we would manually",
      "offset": 1808.159,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "label 200 and then after we aligned our",
      "offset": 1809.919,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "LLM judge we would extend it to the rest",
      "offset": 1812.559,
      "duration": 4.961
    },
    {
      "lang": "en",
      "text": "of our document collection. you you then",
      "offset": 1814.32,
      "duration": 6.64
    },
    {
      "lang": "en",
      "text": "have your data set um and then you can",
      "offset": 1817.52,
      "duration": 5.759
    },
    {
      "lang": "en",
      "text": "apply this eval kind of repeatedly",
      "offset": 1820.96,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "against your documents. Are there other",
      "offset": 1823.279,
      "duration": 6.161
    },
    {
      "lang": "en",
      "text": "uh steps in the process that you need to",
      "offset": 1826.96,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "do as a engineer trying to apply this?",
      "offset": 1829.44,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "No, that's pretty much it. We try to",
      "offset": 1832.48,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "make it pretty simple for people to",
      "offset": 1834.64,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "follow. So, um it really just comes down",
      "offset": 1836.399,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "to like filtering out your chunks and",
      "offset": 1838.96,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "then um generating queries from them.",
      "offset": 1841.279,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "You mentioned in the report you referred",
      "offset": 1843.84,
      "duration": 7.68
    },
    {
      "lang": "en",
      "text": "to uh Ragus and another tool",
      "offset": 1847.039,
      "duration": 8.481
    },
    {
      "lang": "en",
      "text": "um as kind of you know existing work",
      "offset": 1851.52,
      "duration": 6.879
    },
    {
      "lang": "en",
      "text": "prior work that uh or existing tools and",
      "offset": 1855.52,
      "duration": 5.96
    },
    {
      "lang": "en",
      "text": "prior work that folks use.",
      "offset": 1858.399,
      "duration": 5.481
    },
    {
      "lang": "en",
      "text": "Um, do",
      "offset": 1861.48,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "you",
      "offset": 1863.88,
      "duration": 5.48
    },
    {
      "lang": "en",
      "text": "see generative this generative",
      "offset": 1866.52,
      "duration": 4.759
    },
    {
      "lang": "en",
      "text": "benchmarking like do you see it ever",
      "offset": 1869.36,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "being packaged as a tool or is it more a",
      "offset": 1871.279,
      "duration": 5.921
    },
    {
      "lang": "en",
      "text": "process like you offer it as a it's a",
      "offset": 1874.72,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "library that you import in a notebook",
      "offset": 1877.2,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "and you kind of run through it? Um, do",
      "offset": 1878.799,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "you think it can be more packaged in its",
      "offset": 1881.44,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "delivery? Yeah. Yeah, that's something",
      "offset": 1884.399,
      "duration": 3.441
    },
    {
      "lang": "en",
      "text": "we're definitely thinking about for the",
      "offset": 1886.48,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "future. Right now it's just packaged as",
      "offset": 1887.84,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "a notebook just to like have it along",
      "offset": 1889.6,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "with a report. But I think in the future",
      "offset": 1891.76,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "it makes a lot of sense to have it as",
      "offset": 1893.2,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "like a tool like along with their",
      "offset": 1895.44,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "product as well. Um I think yeah like",
      "offset": 1896.96,
      "duration": 5.839
    },
    {
      "lang": "en",
      "text": "rags and the other tool is um like",
      "offset": 1899.76,
      "duration": 5.84
    },
    {
      "lang": "en",
      "text": "airbench by Gina. Yeah they have a",
      "offset": 1902.799,
      "duration": 4.641
    },
    {
      "lang": "en",
      "text": "pretty similar like motivation as list",
      "offset": 1905.6,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "which was to like um kind of create like",
      "offset": 1907.44,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "a custom eval set based on your data.",
      "offset": 1909.76,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "But I think um I wanted to like",
      "offset": 1912.48,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "emphasize this like a bit more that our",
      "offset": 1914.88,
      "duration": 3.519
    },
    {
      "lang": "en",
      "text": "approaches are pretty different. I think",
      "offset": 1916.64,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "for Ragus and Airbench they focus a lot",
      "offset": 1918.399,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "on like generating a diverse set of",
      "offset": 1920.88,
      "duration": 5.279
    },
    {
      "lang": "en",
      "text": "queries. They don't really do much um",
      "offset": 1923.279,
      "duration": 4.561
    },
    {
      "lang": "en",
      "text": "they don't put much focus on like how",
      "offset": 1926.159,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "representative it is of like your actual",
      "offset": 1927.84,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "um like production data. So I think that",
      "offset": 1930.48,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "was like the main like differentiator",
      "offset": 1933.36,
      "duration": 2.96
    },
    {
      "lang": "en",
      "text": "that we had. Like we know there were a",
      "offset": 1934.88,
      "duration": 2.88
    },
    {
      "lang": "en",
      "text": "lot of like previous methods on like",
      "offset": 1936.32,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "synthetic data set generation. But I",
      "offset": 1937.76,
      "duration": 5.039
    },
    {
      "lang": "en",
      "text": "think um our work is like pretty unique",
      "offset": 1939.6,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "in the fact that it like focused a lot",
      "offset": 1942.799,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "on like how representative the like",
      "offset": 1944.72,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "generated queries are. And again kind of",
      "offset": 1946.64,
      "duration": 6.48
    },
    {
      "lang": "en",
      "text": "going back to this scenario of uh an",
      "offset": 1948.96,
      "duration": 6.079
    },
    {
      "lang": "en",
      "text": "engineer that's starting to work on a",
      "offset": 1953.12,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "system like this or you know a rag based",
      "offset": 1955.039,
      "duration": 6.161
    },
    {
      "lang": "en",
      "text": "system or retrieval oriented AI system",
      "offset": 1957.519,
      "duration": 7.841
    },
    {
      "lang": "en",
      "text": "but they don't have um historical data",
      "offset": 1961.2,
      "duration": 7.44
    },
    {
      "lang": "en",
      "text": "to use is generative benchmarking still",
      "offset": 1965.36,
      "duration": 6.64
    },
    {
      "lang": "en",
      "text": "useful to them yeah I think um that's",
      "offset": 1968.64,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "definitely like one of the key use cases",
      "offset": 1972,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "of this like if you don't have like a",
      "offset": 1974,
      "duration": 2.96
    },
    {
      "lang": "en",
      "text": "set of like queries that you can test",
      "offset": 1975.44,
      "duration": 2.959
    },
    {
      "lang": "en",
      "text": "your reachable system on like we would",
      "offset": 1976.96,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "generate that for you like all you need",
      "offset": 1978.399,
      "duration": 4.961
    },
    {
      "lang": "en",
      "text": "is just like a set of like um like",
      "offset": 1980.24,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "documents that you're using for your",
      "offset": 1983.36,
      "duration": 3.439
    },
    {
      "lang": "en",
      "text": "retrieval system which people already",
      "offset": 1985.12,
      "duration": 4.799
    },
    {
      "lang": "en",
      "text": "have. So like you have all the tools um",
      "offset": 1986.799,
      "duration": 4.641
    },
    {
      "lang": "en",
      "text": "so you just need to like run this and",
      "offset": 1989.919,
      "duration": 3.201
    },
    {
      "lang": "en",
      "text": "then we'll generate the evolve for you.",
      "offset": 1991.44,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "So I think um you know like we were kind",
      "offset": 1993.12,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "of hoping with this that it would be an",
      "offset": 1995.36,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "easy way for people to get started with",
      "offset": 1997.039,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "EVAs just start to like get more",
      "offset": 1998.72,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "familiar with it and like understand",
      "offset": 2000.399,
      "duration": 5.201
    },
    {
      "lang": "en",
      "text": "like why it's important to use. You",
      "offset": 2002.32,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "mentioned that part of the inspiration",
      "offset": 2005.6,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "for this was um things that you ran into",
      "offset": 2007.2,
      "duration": 6.8
    },
    {
      "lang": "en",
      "text": "in your own personal projects. Have you",
      "offset": 2010.72,
      "duration": 5.679
    },
    {
      "lang": "en",
      "text": "tried using it with projects beyond the",
      "offset": 2014,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "weights and biases data set? We've tried",
      "offset": 2016.399,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "it like on our own like Chroma",
      "offset": 2018.399,
      "duration": 3.201
    },
    {
      "lang": "en",
      "text": "documentation as well. Like one thing",
      "offset": 2020.08,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "we're just like um you know testing out",
      "offset": 2021.6,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "for fun was like how well would this",
      "offset": 2023.84,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "perform on like Chroma's um like our",
      "offset": 2025.44,
      "duration": 4.959
    },
    {
      "lang": "en",
      "text": "like Chroma documentation. Um, so yeah,",
      "offset": 2028.24,
      "duration": 3.679
    },
    {
      "lang": "en",
      "text": "we ran like evolves on that for like a",
      "offset": 2030.399,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "few different models and um, yeah, like",
      "offset": 2031.919,
      "duration": 5.441
    },
    {
      "lang": "en",
      "text": "we got some like results for that just",
      "offset": 2035.279,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "to like kind of indicate like which",
      "offset": 2037.36,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "embedding model is like best to use. I",
      "offset": 2038.559,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "haven't tested it out like extensively",
      "offset": 2040.64,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "on like other projects, but um, yeah.",
      "offset": 2042.24,
      "duration": 6.24
    },
    {
      "lang": "en",
      "text": "Did it change anything about the way you",
      "offset": 2045.6,
      "duration": 6.479
    },
    {
      "lang": "en",
      "text": "used uh the way you built a system for",
      "offset": 2048.48,
      "duration": 5.919
    },
    {
      "lang": "en",
      "text": "your own docs? Yeah. Yeah, for us like",
      "offset": 2052.079,
      "duration": 5.121
    },
    {
      "lang": "en",
      "text": "previously we just um used like OpenAI's",
      "offset": 2054.399,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "I think like small model. Uh but after",
      "offset": 2057.2,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "looking at this it actually like",
      "offset": 2060.399,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "performed like it was like one of the",
      "offset": 2061.76,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "worst performing models out of the ones",
      "offset": 2063.679,
      "duration": 4.561
    },
    {
      "lang": "en",
      "text": "that we tested. So um yeah I think like",
      "offset": 2065.839,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "from now on we'll probably go with",
      "offset": 2068.24,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "something like Voyages model which works",
      "offset": 2069.599,
      "duration": 2.881
    },
    {
      "lang": "en",
      "text": "pretty well on like technical",
      "offset": 2071.44,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "documentation like this. So um yeah that",
      "offset": 2072.48,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "was like pretty interesting to see. I",
      "offset": 2075.44,
      "duration": 2.56
    },
    {
      "lang": "en",
      "text": "think like once you actually like test",
      "offset": 2076.8,
      "duration": 2.96
    },
    {
      "lang": "en",
      "text": "on your data, you actually have like",
      "offset": 2078,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "more confidence in like determining like",
      "offset": 2079.76,
      "duration": 3.359
    },
    {
      "lang": "en",
      "text": "which embedding model is best to use for",
      "offset": 2081.44,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "your use case. Any other thoughts on",
      "offset": 2083.119,
      "duration": 6.081
    },
    {
      "lang": "en",
      "text": "what's next for the project? Yeah. Yeah.",
      "offset": 2086,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "I think in terms of next steps, one",
      "offset": 2089.2,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "thing that would always come up is like",
      "offset": 2091.44,
      "duration": 3.679
    },
    {
      "lang": "en",
      "text": "how you would iterate on this generative",
      "offset": 2093.04,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "benchmark like once you you know have",
      "offset": 2095.119,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "like your initial set because I think",
      "offset": 2097.04,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "like I mentioned before, it's not",
      "offset": 2099.2,
      "duration": 2.879
    },
    {
      "lang": "en",
      "text": "necessarily like the end goal. We want",
      "offset": 2100.4,
      "duration": 3.679
    },
    {
      "lang": "en",
      "text": "people to iterate on this further to get",
      "offset": 2102.079,
      "duration": 3.361
    },
    {
      "lang": "en",
      "text": "it like better aligned with what they",
      "offset": 2104.079,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "see in production. So I think like if",
      "offset": 2105.44,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "you are like logging queries like one",
      "offset": 2107.76,
      "duration": 3.359
    },
    {
      "lang": "en",
      "text": "interesting thing you could do is like",
      "offset": 2109.92,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "query alignment. So maybe you could kind",
      "offset": 2111.119,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "of use that to determine like what kind",
      "offset": 2113.44,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "of topics like users mostly ask about",
      "offset": 2115.119,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "align your like eval set closer to that.",
      "offset": 2116.96,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "Also, it could help in like determining",
      "offset": 2119.52,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "like if you have any like information",
      "offset": 2121.28,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "gaps in your document corpus. Like if",
      "offset": 2123.52,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "users are asking about this one topic",
      "offset": 2125.359,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "but your document corpus isn't able to",
      "offset": 2126.96,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "answer that then like people can maybe",
      "offset": 2129.839,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "like proactively um you know act upon",
      "offset": 2131.52,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "that and fix it before like more users",
      "offset": 2134.24,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "run into that problem. I think another",
      "offset": 2136.16,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "thing that came up when we were working",
      "offset": 2139.04,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "with production data was we noticed that",
      "offset": 2140.72,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "retrieval performance drops a lot when",
      "offset": 2142.88,
      "duration": 3.199
    },
    {
      "lang": "en",
      "text": "you're working with these like very",
      "offset": 2144.72,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "domain specific um data sets because uh",
      "offset": 2146.079,
      "duration": 5.361
    },
    {
      "lang": "en",
      "text": "we've spoken to like a few other people",
      "offset": 2150,
      "duration": 3.359
    },
    {
      "lang": "en",
      "text": "who are working on like rock systems as",
      "offset": 2151.44,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "well just maybe for like internal like",
      "offset": 2153.359,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "company documents and things like that",
      "offset": 2154.88,
      "duration": 4.239
    },
    {
      "lang": "en",
      "text": "and these are very very specific",
      "offset": 2156.96,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "compared to like the public benchmarks",
      "offset": 2159.119,
      "duration": 3.041
    },
    {
      "lang": "en",
      "text": "that you see like if you just have like",
      "offset": 2160.64,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "a Wikipedia data it's going to focus on",
      "offset": 2162.16,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "a variety of topics but if you just have",
      "offset": 2163.76,
      "duration": 4.52
    },
    {
      "lang": "en",
      "text": "I don't know like an internal tool that",
      "offset": 2166,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "has that's just focused on like one very",
      "offset": 2168.28,
      "duration": 4.68
    },
    {
      "lang": "en",
      "text": "specific area of your company then it's",
      "offset": 2170.96,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "very hard to like differentiate between",
      "offset": 2172.96,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "like different like chunks right so I",
      "offset": 2175.119,
      "duration": 5.201
    },
    {
      "lang": "en",
      "text": "think one um area that could be",
      "offset": 2178.24,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "interesting to explore is like how can",
      "offset": 2180.32,
      "duration": 3.519
    },
    {
      "lang": "en",
      "text": "we like improve performance in these",
      "offset": 2182.16,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "like very very domain specific use cases",
      "offset": 2183.839,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "because I think this isn't really",
      "offset": 2186,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "revealed in a lot of like public data",
      "offset": 2187.52,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "sets um where retrieval is like a lot",
      "offset": 2189.28,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "easier but yeah in these cases like we",
      "offset": 2191.28,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "see performance drops a lot because of",
      "offset": 2193.2,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "this um it's hard to like disembiguate",
      "offset": 2195.04,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "like between um documents. So I think",
      "offset": 2197.599,
      "duration": 4.641
    },
    {
      "lang": "en",
      "text": "yeah that would be interesting to look",
      "offset": 2200.64,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "into as well. Yeah, I was thinking a",
      "offset": 2202.24,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "similar thought in trying to mentally",
      "offset": 2204.8,
      "duration": 5.08
    },
    {
      "lang": "en",
      "text": "apply this to the podcast",
      "offset": 2206.96,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "transcription use case that I mentioned.",
      "offset": 2209.88,
      "duration": 7.959
    },
    {
      "lang": "en",
      "text": "Like it might be more useful for me to",
      "offset": 2212.24,
      "duration": 7.68
    },
    {
      "lang": "en",
      "text": "change the context on a per transcript",
      "offset": 2217.839,
      "duration": 5.441
    },
    {
      "lang": "en",
      "text": "basis than to tell the LLM, you know,",
      "offset": 2219.92,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "you're trying to judge the relevance of",
      "offset": 2223.28,
      "duration": 6.079
    },
    {
      "lang": "en",
      "text": "documents for a podcast. Yeah. Yeah. I",
      "offset": 2225.92,
      "duration": 6.48
    },
    {
      "lang": "en",
      "text": "think um yeah, context definitely",
      "offset": 2229.359,
      "duration": 5.681
    },
    {
      "lang": "en",
      "text": "improves performance a lot. So I think",
      "offset": 2232.4,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "um yeah, I would recommend like getting",
      "offset": 2235.04,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "as specific as you can. I'm curious",
      "offset": 2236.48,
      "duration": 6.76
    },
    {
      "lang": "en",
      "text": "maybe taking a step back from generative",
      "offset": 2239.2,
      "duration": 8.12
    },
    {
      "lang": "en",
      "text": "benchmarking when you think about",
      "offset": 2243.24,
      "duration": 5.599
    },
    {
      "lang": "en",
      "text": "the",
      "offset": 2247.32,
      "duration": 5.4
    },
    {
      "lang": "en",
      "text": "engineer, the enthusiast who is, you",
      "offset": 2248.839,
      "duration": 7.321
    },
    {
      "lang": "en",
      "text": "know, building a system. Uh still in",
      "offset": 2252.72,
      "duration": 7.72
    },
    {
      "lang": "en",
      "text": "that, you know, vibe. uh vibe check",
      "offset": 2256.16,
      "duration": 8.64
    },
    {
      "lang": "en",
      "text": "regime. Um what are the things that they",
      "offset": 2260.44,
      "duration": 6.52
    },
    {
      "lang": "en",
      "text": "need to you know they're they're you",
      "offset": 2264.8,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "know not an information retrieval you",
      "offset": 2266.96,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "know researcher or anything like that.",
      "offset": 2269.04,
      "duration": 2.96
    },
    {
      "lang": "en",
      "text": "What do they need to understand about",
      "offset": 2270.48,
      "duration": 5.84
    },
    {
      "lang": "en",
      "text": "information retrieval to build really",
      "offset": 2272,
      "duration": 6.68
    },
    {
      "lang": "en",
      "text": "useful systems?",
      "offset": 2276.32,
      "duration": 5.24
    },
    {
      "lang": "en",
      "text": "Um I",
      "offset": 2278.68,
      "duration": 5.08
    },
    {
      "lang": "en",
      "text": "think I think one of the important",
      "offset": 2281.56,
      "duration": 4.039
    },
    {
      "lang": "en",
      "text": "things is like understanding how",
      "offset": 2283.76,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "important retrieval is in the context of",
      "offset": 2285.599,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "your entire like AI system. I mean a lot",
      "offset": 2287.52,
      "duration": 3.599
    },
    {
      "lang": "en",
      "text": "of people just use it for like rag where",
      "offset": 2289.44,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "you like retrieve like relevant",
      "offset": 2291.119,
      "duration": 2.96
    },
    {
      "lang": "en",
      "text": "documents and then you have an LLM",
      "offset": 2292.56,
      "duration": 3.279
    },
    {
      "lang": "en",
      "text": "output. A lot of people just tend to",
      "offset": 2294.079,
      "duration": 4.961
    },
    {
      "lang": "en",
      "text": "focus only on the LLM output. Um just",
      "offset": 2295.839,
      "duration": 4.801
    },
    {
      "lang": "en",
      "text": "like is it performing like good or bad",
      "offset": 2299.04,
      "duration": 2.72
    },
    {
      "lang": "en",
      "text": "and then they might like change your",
      "offset": 2300.64,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "prompting. But maybe like the problem is",
      "offset": 2301.76,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "just in like the retrieval itself if you",
      "offset": 2303.68,
      "duration": 3.439
    },
    {
      "lang": "en",
      "text": "can make that better. maybe your LM",
      "offset": 2305.68,
      "duration": 3.679
    },
    {
      "lang": "en",
      "text": "output performance will increase a lot",
      "offset": 2307.119,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "more too. So I think um maybe like one",
      "offset": 2309.359,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "important thing is to like look at the",
      "offset": 2312.079,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "individual components of your like AI",
      "offset": 2313.44,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "system. Don't just look at like the",
      "offset": 2315.119,
      "duration": 3.201
    },
    {
      "lang": "en",
      "text": "input and output and like try to like",
      "offset": 2316.56,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "figure out your way from there. I think",
      "offset": 2318.32,
      "duration": 3.759
    },
    {
      "lang": "en",
      "text": "there is like a more like systematic",
      "offset": 2320.32,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "approach to this and you know like one",
      "offset": 2322.079,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "of the best ways to just like start off",
      "offset": 2324.4,
      "duration": 2.719
    },
    {
      "lang": "en",
      "text": "is like looking at the outputs of like",
      "offset": 2325.68,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "each component of your system. So if you",
      "offset": 2327.119,
      "duration": 3.521
    },
    {
      "lang": "en",
      "text": "have like rag, look at what documents",
      "offset": 2328.96,
      "duration": 3.119
    },
    {
      "lang": "en",
      "text": "are like actually being retrieved and",
      "offset": 2330.64,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "try to like figure out what's going on",
      "offset": 2332.079,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "from there rather than you know just",
      "offset": 2333.68,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "looking at the output and like seeing",
      "offset": 2335.76,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "what the wipes are. You kind of pointed",
      "offset": 2337.92,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "to the garbage in garbage out scenario",
      "offset": 2339.839,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "where the LLM can't do any better than",
      "offset": 2341.68,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "what it's given. Yeah, exactly. So yeah,",
      "offset": 2343.92,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "I think like yeah, just focusing on like",
      "offset": 2346.96,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "retrieval specifically could be like an",
      "offset": 2349.52,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "important point because yeah, a lot of",
      "offset": 2352.4,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "people just focus on like the final",
      "offset": 2354.72,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "output, but there is a lot more that",
      "offset": 2356.88,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "goes on. Uh, any other thoughts along",
      "offset": 2358.72,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "those lines? One thing that comes up a",
      "offset": 2360.72,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "lot in like rock systems is that like if",
      "offset": 2362.96,
      "duration": 5.92
    },
    {
      "lang": "en",
      "text": "you have um a lot of like distractors in",
      "offset": 2365.52,
      "duration": 6.319
    },
    {
      "lang": "en",
      "text": "your LLM prompt, it leads to very like",
      "offset": 2368.88,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "degraded performance. What's an example",
      "offset": 2371.839,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "of a distractor? You know if we take",
      "offset": 2374,
      "duration": 3.599
    },
    {
      "lang": "en",
      "text": "this example of like a technical support",
      "offset": 2375.92,
      "duration": 5.199
    },
    {
      "lang": "en",
      "text": "bot maybe you just have um let me try to",
      "offset": 2377.599,
      "duration": 6.641
    },
    {
      "lang": "en",
      "text": "think of an example like maybe in like",
      "offset": 2381.119,
      "duration": 4.881
    },
    {
      "lang": "en",
      "text": "Chroma's use case you're asking okay",
      "offset": 2384.24,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "like how do I like create a collection",
      "offset": 2386,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "and then it retrieves like a bunch of",
      "offset": 2387.92,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "like chunks around like you know like",
      "offset": 2390.64,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "creating collections like quering a",
      "offset": 2392.4,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "collection like filtering a collection",
      "offset": 2393.92,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "it has so many um like specific points",
      "offset": 2395.44,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "about like collections in general so",
      "offset": 2399.04,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "then like the LLM might get distracted",
      "offset": 2401.44,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "and it might focus on you know how it",
      "offset": 2402.96,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "might mistake maybe like a function for",
      "offset": 2405.44,
      "duration": 4.639
    },
    {
      "lang": "en",
      "text": "like filtering a collection um when you",
      "offset": 2407.44,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "were really asking about like creating",
      "offset": 2410.079,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "it and we noticed this comes up pretty",
      "offset": 2411.44,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "often. So that's why we think like",
      "offset": 2414.079,
      "duration": 2.561
    },
    {
      "lang": "en",
      "text": "retrieval is like pretty important",
      "offset": 2415.599,
      "duration": 3.201
    },
    {
      "lang": "en",
      "text": "because your LLM can get very distracted",
      "offset": 2416.64,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "by which documents are retrieved. So you",
      "offset": 2418.8,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "know being able to like debug that first",
      "offset": 2421.28,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "is like a pretty important step in",
      "offset": 2422.96,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "actually like yeah improving the overall",
      "offset": 2424.4,
      "duration": 5.88
    },
    {
      "lang": "en",
      "text": "output. Um, have you come across",
      "offset": 2426.96,
      "duration": 6.48
    },
    {
      "lang": "en",
      "text": "useful ways for folks to think about the",
      "offset": 2430.28,
      "duration": 6.839
    },
    {
      "lang": "en",
      "text": "number of retrieved documents to give to",
      "offset": 2433.44,
      "duration": 6.24
    },
    {
      "lang": "en",
      "text": "their LLMs for generation seems related",
      "offset": 2437.119,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "to the problem the distraction problem",
      "offset": 2439.68,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "you are just describing. Yes, that that",
      "offset": 2441.52,
      "duration": 5.599
    },
    {
      "lang": "en",
      "text": "again depends a lot on the use case as",
      "offset": 2444.8,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "well. I think like um you want as like",
      "offset": 2447.119,
      "duration": 5.921
    },
    {
      "lang": "en",
      "text": "few distractors as possible. There's no",
      "offset": 2450.48,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "like one number that I would recommend",
      "offset": 2453.04,
      "duration": 2.799
    },
    {
      "lang": "en",
      "text": "to use. I think like you really just",
      "offset": 2454.4,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "have to like look at your data, test out",
      "offset": 2455.839,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "different K values, uh like different",
      "offset": 2458,
      "duration": 3.599
    },
    {
      "lang": "en",
      "text": "like numbers of like documents to",
      "offset": 2459.92,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "retrieve and then um you know see like",
      "offset": 2461.599,
      "duration": 6.48
    },
    {
      "lang": "en",
      "text": "based on that like if you run like evals",
      "offset": 2465.28,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "like um you can run evals with like",
      "offset": 2468.079,
      "duration": 3.361
    },
    {
      "lang": "en",
      "text": "different like K values. You can do like",
      "offset": 2470,
      "duration": 2.96
    },
    {
      "lang": "en",
      "text": "recall at one, recall at three, recall",
      "offset": 2471.44,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "at 10, see how like the scores differ",
      "offset": 2472.96,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "and maybe like go off of that because it",
      "offset": 2474.96,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "does change a lot for people. Um like",
      "offset": 2476.96,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "for example when we were working with",
      "offset": 2479.119,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "like the public benchmarks we only just",
      "offset": 2480.48,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "had to look at like the recall at one",
      "offset": 2482.8,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "scores um to get like a pretty good idea",
      "offset": 2484.16,
      "duration": 3.439
    },
    {
      "lang": "en",
      "text": "of how they're performing. But for like",
      "offset": 2485.92,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "the waste and biases data the retrieval",
      "offset": 2487.599,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "like performance like went down a lot.",
      "offset": 2490.319,
      "duration": 3.441
    },
    {
      "lang": "en",
      "text": "So we would look at like recall at K I",
      "offset": 2492.079,
      "duration": 3.441
    },
    {
      "lang": "en",
      "text": "mean recall at 10. So it definitely",
      "offset": 2493.76,
      "duration": 3.599
    },
    {
      "lang": "en",
      "text": "differs a lot like based on use case. So",
      "offset": 2495.52,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "definitely like try out like different",
      "offset": 2497.359,
      "duration": 3.521
    },
    {
      "lang": "en",
      "text": "values and like see what works best. And",
      "offset": 2498.8,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "is that because the real world queries",
      "offset": 2500.88,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "are",
      "offset": 2504.4,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "um either less specific or I guess a",
      "offset": 2506,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "point that you mentioned in the work",
      "offset": 2508.64,
      "duration": 7.04
    },
    {
      "lang": "en",
      "text": "itself is that in the benchmarks the",
      "offset": 2510.8,
      "duration": 7.519
    },
    {
      "lang": "en",
      "text": "queries are like taken verbatim out of",
      "offset": 2515.68,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "the benchmarks in many cases or the data",
      "offset": 2518.319,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "sets in many cases. So um it's easier to",
      "offset": 2520.48,
      "duration": 5.599
    },
    {
      "lang": "en",
      "text": "do to recall at one. Yeah, definitely.",
      "offset": 2523.599,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "That's definitely one of the core",
      "offset": 2526.079,
      "duration": 3.201
    },
    {
      "lang": "en",
      "text": "reasons like a lot of real user queries",
      "offset": 2527.28,
      "duration": 6.799
    },
    {
      "lang": "en",
      "text": "are very ambiguous. So in um yeah, in",
      "offset": 2529.28,
      "duration": 6.319
    },
    {
      "lang": "en",
      "text": "like a lot of like the polish data sets",
      "offset": 2534.079,
      "duration": 2.721
    },
    {
      "lang": "en",
      "text": "that you see like the query document",
      "offset": 2535.599,
      "duration": 3.441
    },
    {
      "lang": "en",
      "text": "pairs are highly relevant. So it's very",
      "offset": 2536.8,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "obvious that like a query matches",
      "offset": 2539.04,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "documents whereas in the real world",
      "offset": 2540.64,
      "duration": 4.479
    },
    {
      "lang": "en",
      "text": "maybe a query is only um relevant to",
      "offset": 2542.72,
      "duration": 5.599
    },
    {
      "lang": "en",
      "text": "like the first sentence of a chunk. So",
      "offset": 2545.119,
      "duration": 5.041
    },
    {
      "lang": "en",
      "text": "yeah, that's why reachable is a lot",
      "offset": 2548.319,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "harder because we have these ambiguous",
      "offset": 2550.16,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "queries. the query document and pairs",
      "offset": 2551.92,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "aren't as relevant to each other. Um, so",
      "offset": 2553.76,
      "duration": 6.319
    },
    {
      "lang": "en",
      "text": "yeah, we see that a lot. Um, and we",
      "offset": 2557.44,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "tested this out with like a naive query",
      "offset": 2560.079,
      "duration": 4.561
    },
    {
      "lang": "en",
      "text": "generation method as well where u we",
      "offset": 2561.68,
      "duration": 4.639
    },
    {
      "lang": "en",
      "text": "wouldn't give any like example queries.",
      "offset": 2564.64,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "We wouldn't give it any context. We",
      "offset": 2566.319,
      "duration": 2.561
    },
    {
      "lang": "en",
      "text": "would literally just feed in the chunk",
      "offset": 2567.68,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "and tell the LLM to generate a query.",
      "offset": 2568.88,
      "duration": 4.479
    },
    {
      "lang": "en",
      "text": "And in those cases oftent times it would",
      "offset": 2571.52,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "generate like pretty relevant queries",
      "offset": 2573.359,
      "duration": 4.641
    },
    {
      "lang": "en",
      "text": "like more relevant queries than um like",
      "offset": 2575.28,
      "duration": 5.039
    },
    {
      "lang": "en",
      "text": "real production queries are. And we",
      "offset": 2578,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "noticed a performance like increase by a",
      "offset": 2580.319,
      "duration": 4.641
    },
    {
      "lang": "en",
      "text": "lot which if you're just looking at the",
      "offset": 2582.8,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "numbers it looks good but it's not",
      "offset": 2584.96,
      "duration": 2.8
    },
    {
      "lang": "en",
      "text": "really reflective of what you'll",
      "offset": 2586.4,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "actually see in production. So yeah like",
      "offset": 2587.76,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "what we actually want to see meaning",
      "offset": 2590.88,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "your retrieval performance on that data",
      "offset": 2592.079,
      "duration": 6.641
    },
    {
      "lang": "en",
      "text": "set does well but uh your retrieval",
      "offset": 2594.48,
      "duration": 6.56
    },
    {
      "lang": "en",
      "text": "performance on your real world queries",
      "offset": 2598.72,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "would not be as strong. Yes. Exactly.",
      "offset": 2601.04,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "Like you don't just want to get like",
      "offset": 2603.68,
      "duration": 2.88
    },
    {
      "lang": "en",
      "text": "high numbers like you want something",
      "offset": 2605.2,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "that's more realistic. Yeah. Yeah. In",
      "offset": 2606.56,
      "duration": 5.279
    },
    {
      "lang": "en",
      "text": "that in the section of the report where",
      "offset": 2608.96,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "you talk about the naive query",
      "offset": 2611.839,
      "duration": 4.201
    },
    {
      "lang": "en",
      "text": "generation, you",
      "offset": 2613.359,
      "duration": 7.281
    },
    {
      "lang": "en",
      "text": "um you talk about kind of near identical",
      "offset": 2616.04,
      "duration": 7.72
    },
    {
      "lang": "en",
      "text": "matches between the generated queries",
      "offset": 2620.64,
      "duration": 5.92
    },
    {
      "lang": "en",
      "text": "um that are like reward rewardings of",
      "offset": 2623.76,
      "duration": 5.839
    },
    {
      "lang": "en",
      "text": "the ground truth queries. Yeah. So that",
      "offset": 2626.56,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "was when we were working with like",
      "offset": 2629.599,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "public data sets because we wanted to",
      "offset": 2631.2,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "first demonstrate that our generate",
      "offset": 2633.839,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "queries were like representative of",
      "offset": 2635.599,
      "duration": 3.881
    },
    {
      "lang": "en",
      "text": "these um like widely accepted",
      "offset": 2637.359,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "benchmarks. So um yeah, one thing that",
      "offset": 2639.48,
      "duration": 4.599
    },
    {
      "lang": "en",
      "text": "we initially tried doing was just giving",
      "offset": 2642.079,
      "duration": 4.481
    },
    {
      "lang": "en",
      "text": "like the chunk to an LLM and telling it",
      "offset": 2644.079,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "to um you know generate a query. And",
      "offset": 2646.56,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "when we did that we noticed in a lot of",
      "offset": 2649.119,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "cases the LLM would generate like",
      "offset": 2650.8,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "identical queries and um identical",
      "offset": 2653.119,
      "duration": 4.641
    },
    {
      "lang": "en",
      "text": "queries or like near identical queries",
      "offset": 2656.16,
      "duration": 2.88
    },
    {
      "lang": "en",
      "text": "which basically meant that the queries",
      "offset": 2657.76,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "were like rewarded and this basically",
      "offset": 2659.04,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "shows that like the LMS identical",
      "offset": 2661.2,
      "duration": 4.639
    },
    {
      "lang": "en",
      "text": "queries to to what? Oh identical queries",
      "offset": 2663.04,
      "duration": 5.84
    },
    {
      "lang": "en",
      "text": "to like the original um public data set.",
      "offset": 2665.839,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "So for example like the Wikipedia data",
      "offset": 2668.88,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "set it comes with like the query",
      "offset": 2671.119,
      "duration": 5.441
    },
    {
      "lang": "en",
      "text": "document pairs. So if you fed that like",
      "offset": 2672.96,
      "duration": 6.159
    },
    {
      "lang": "en",
      "text": "um document/chunk into the LLM it would",
      "offset": 2676.56,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "generate the exact same query that would",
      "offset": 2679.119,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "appear in um like the journal like",
      "offset": 2680.88,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "hugging face data set. The example that",
      "offset": 2683.04,
      "duration": 6.079
    },
    {
      "lang": "en",
      "text": "you give for that is from the Wikipedia",
      "offset": 2685.68,
      "duration": 6.32
    },
    {
      "lang": "en",
      "text": "data set and",
      "offset": 2689.119,
      "duration": 5.361
    },
    {
      "lang": "en",
      "text": "um you show that the ground truth query",
      "offset": 2692,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "is like where was the movie deliverance",
      "offset": 2694.48,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "filmed and the generate generated query",
      "offset": 2696.079,
      "duration": 5.441
    },
    {
      "lang": "en",
      "text": "was where was the film deliverance shot",
      "offset": 2698.48,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "um but the target documents like the",
      "offset": 2701.52,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "very first thing it talks about is where",
      "offset": 2703.76,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "the film was shot and so it seemed like",
      "offset": 2705.28,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "an obvious query to generate and didn't",
      "offset": 2707.52,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "strike me as proof that there was like",
      "offset": 2710.96,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "some kind of data leak package. Yeah,",
      "offset": 2713.04,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "that's a good point. I think like we",
      "offset": 2715.76,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "showed that example just to demonstrate",
      "offset": 2717.68,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "what like a near identical query was,",
      "offset": 2719.52,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "but uh we provide some like examples in",
      "offset": 2721.52,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "our appendix appendex where it shows",
      "offset": 2723.68,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "like like identical queries that were",
      "offset": 2725.839,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "generated like word for word where that",
      "offset": 2727.92,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "isn't necessarily where it's less",
      "offset": 2730.16,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "obvious from the document itself. Yes,",
      "offset": 2731.68,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "like the LLM could have asked about",
      "offset": 2734.56,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "anything, but like if you see like",
      "offset": 2736.4,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "constant patterns um of like identically",
      "offset": 2739.04,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "generated queries, then I think that's a",
      "offset": 2742.16,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "pretty good sign that like the LLM has",
      "offset": 2744.56,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "seen this data set before. And did you",
      "offset": 2746.24,
      "duration": 5.56
    },
    {
      "lang": "en",
      "text": "find that different",
      "offset": 2748.72,
      "duration": 7.48
    },
    {
      "lang": "en",
      "text": "um different LLMs had different degrees",
      "offset": 2751.8,
      "duration": 8.36
    },
    {
      "lang": "en",
      "text": "of you know presumably exposure to the",
      "offset": 2756.2,
      "duration": 7.399
    },
    {
      "lang": "en",
      "text": "to the various benchmarks. We didn't do",
      "offset": 2760.16,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "much extensive work on that. We mainly",
      "offset": 2763.599,
      "duration": 5.841
    },
    {
      "lang": "en",
      "text": "use quad. Um so I can't speak to um",
      "offset": 2765.52,
      "duration": 6.24
    },
    {
      "lang": "en",
      "text": "speak much on that but I I wouldn't be",
      "offset": 2769.44,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "surprised if it also did memorize a lot",
      "offset": 2771.76,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "of these data sets. you have a chart in",
      "offset": 2774.4,
      "duration": 6.08
    },
    {
      "lang": "en",
      "text": "there where you're trying to demonstrate",
      "offset": 2777.2,
      "duration": 6.8
    },
    {
      "lang": "en",
      "text": "that um the generated queries are",
      "offset": 2780.48,
      "duration": 6.04
    },
    {
      "lang": "en",
      "text": "representative of the ground truth",
      "offset": 2784,
      "duration": 6.68
    },
    {
      "lang": "en",
      "text": "and you do that by showing that",
      "offset": 2786.52,
      "duration": 6.599
    },
    {
      "lang": "en",
      "text": "um that like they're they're similar",
      "offset": 2790.68,
      "duration": 5
    },
    {
      "lang": "en",
      "text": "relative performance across the",
      "offset": 2793.119,
      "duration": 4.801
    },
    {
      "lang": "en",
      "text": "embedding models. Can you explain that",
      "offset": 2795.68,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "methodology a little bit? Yeah. Yeah. So",
      "offset": 2797.92,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "we yeah that's one of the methods that",
      "offset": 2800.8,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "we show representativeness is like do",
      "offset": 2802.48,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "does our generated like eval set",
      "offset": 2805.44,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "generate like the same ranking of",
      "offset": 2807.2,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "embedding models when we run the",
      "offset": 2808.8,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "retrieval task over them. So yeah",
      "offset": 2810.4,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "basically how this would work is we have",
      "offset": 2812.8,
      "duration": 2.799
    },
    {
      "lang": "en",
      "text": "our ground truth data set and then we",
      "offset": 2814.319,
      "duration": 3.201
    },
    {
      "lang": "en",
      "text": "have our generated data set. So for each",
      "offset": 2815.599,
      "duration": 3.281
    },
    {
      "lang": "en",
      "text": "of those we would like run the retrieval",
      "offset": 2817.52,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "task and we would get scores like recall",
      "offset": 2818.88,
      "duration": 4.239
    },
    {
      "lang": "en",
      "text": "at K and we would like compare those",
      "offset": 2820.8,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "scores um and you can see in the charts",
      "offset": 2823.119,
      "duration": 3.121
    },
    {
      "lang": "en",
      "text": "there we kind of compare like the scores",
      "offset": 2824.56,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "for generate queries the scores for",
      "offset": 2826.24,
      "duration": 2.8
    },
    {
      "lang": "en",
      "text": "ground truth queries and then we do that",
      "offset": 2827.76,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "for each embedding model and we see that",
      "offset": 2829.04,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "we have like consistent rankings for",
      "offset": 2830.96,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "embedding models like regardless of",
      "offset": 2833.04,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "whether you're looking at the ground",
      "offset": 2834.8,
      "duration": 2.96
    },
    {
      "lang": "en",
      "text": "truth queries or generate queries",
      "offset": 2836.24,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "because ultimately this is what matters",
      "offset": 2837.76,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "um to like a developer building a rag",
      "offset": 2840.48,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "application is just like which embedding",
      "offset": 2842.8,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "model should I use. So if there is no",
      "offset": 2844.16,
      "duration": 5.4
    },
    {
      "lang": "en",
      "text": "like if they started switching positions",
      "offset": 2846.56,
      "duration": 5.759
    },
    {
      "lang": "en",
      "text": "and something you know performed really",
      "offset": 2849.56,
      "duration": 4.44
    },
    {
      "lang": "en",
      "text": "well on a generated set but not on the",
      "offset": 2852.319,
      "duration": 4.641
    },
    {
      "lang": "en",
      "text": "real world set or a vice versa or ground",
      "offset": 2854,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "truth versus generated or vice versa",
      "offset": 2856.96,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "then that would not be good for choosing",
      "offset": 2858.88,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "an embedding model. Yeah. Like we want",
      "offset": 2861.68,
      "duration": 3.679
    },
    {
      "lang": "en",
      "text": "to see similar performance on the",
      "offset": 2863.68,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "generated and ground truth data set. So",
      "offset": 2865.359,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "because like we saw like similar",
      "offset": 2867.92,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "rankings um we saw like similar scores",
      "offset": 2869.599,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "um yeah that kind of like supported our",
      "offset": 2872.319,
      "duration": 3.361
    },
    {
      "lang": "en",
      "text": "like argument that our queries were",
      "offset": 2873.76,
      "duration": 3.96
    },
    {
      "lang": "en",
      "text": "representative. Yeah. One of the things",
      "offset": 2875.68,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "that I saw pop up a little bit in the",
      "offset": 2877.72,
      "duration": 5.8
    },
    {
      "lang": "en",
      "text": "commentary around this work was the",
      "offset": 2881.04,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "suggestion that it was like auto eval uh",
      "offset": 2883.52,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "that you would hit the easy button then",
      "offset": 2886.72,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "this you know this generative",
      "offset": 2888.64,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "benchmarking process would like just",
      "offset": 2890.72,
      "duration": 5.599
    },
    {
      "lang": "en",
      "text": "generate uh you know hands off hands off",
      "offset": 2893.04,
      "duration": 6.559
    },
    {
      "lang": "en",
      "text": "lights off kind of benchmarking data for",
      "offset": 2896.319,
      "duration": 4.961
    },
    {
      "lang": "en",
      "text": "you from your data set. Is that how you",
      "offset": 2899.599,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "think about it? No. And I think that's a",
      "offset": 2901.28,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "very common misconception that people",
      "offset": 2903.359,
      "duration": 3.121
    },
    {
      "lang": "en",
      "text": "have like if you just hear generate",
      "offset": 2905.04,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "benchmarking you might just think that",
      "offset": 2906.48,
      "duration": 3.119
    },
    {
      "lang": "en",
      "text": "okay I just need to like press a button",
      "offset": 2908.24,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "and then I it generates like an email",
      "offset": 2909.599,
      "duration": 3.361
    },
    {
      "lang": "en",
      "text": "for me but that's definitely not the",
      "offset": 2911.52,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "case. We do need some like human in the",
      "offset": 2912.96,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "loop to actually make this process like",
      "offset": 2914.88,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "more reliable um in terms of like how",
      "offset": 2916.72,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "aligned it is to like human judgment.",
      "offset": 2918.8,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "And this um kind of takes form in like a",
      "offset": 2921.2,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "few ways like one is like the user",
      "offset": 2923.92,
      "duration": 3.199
    },
    {
      "lang": "en",
      "text": "provided like context and example",
      "offset": 2925.52,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "queries that helps like steer the LLM in",
      "offset": 2927.119,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "a way to generate realistic queries.",
      "offset": 2929.2,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "Otherwise, if you just ask the LLM to",
      "offset": 2931.44,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "generate queries, it's going to generate",
      "offset": 2933.119,
      "duration": 3.361
    },
    {
      "lang": "en",
      "text": "queries in a way that is probably not",
      "offset": 2934.64,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "reflective of what your users will",
      "offset": 2936.48,
      "duration": 3.599
    },
    {
      "lang": "en",
      "text": "actually ask. And we also have some like",
      "offset": 2938,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "human alignment in the whole like LLM",
      "offset": 2940.079,
      "duration": 3.201
    },
    {
      "lang": "en",
      "text": "judge process as well where you're",
      "offset": 2941.92,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "filtering um document chunks. Yeah. So,",
      "offset": 2943.28,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "I think like if we didn't have that like",
      "offset": 2946.079,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "as we saw initially, we only had like",
      "offset": 2948.48,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "46% alignment. That's not very",
      "offset": 2950,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "reflective of like how um you would want",
      "offset": 2952.319,
      "duration": 5.121
    },
    {
      "lang": "en",
      "text": "to evaluate your system. So, um yeah,",
      "offset": 2954.72,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "like we definitely have like human in",
      "offset": 2957.44,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "the loop in this entire process. So it's",
      "offset": 2959.119,
      "duration": 5.121
    },
    {
      "lang": "en",
      "text": "not 100% autogenerated. Like we do have",
      "offset": 2961.44,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "some generation, but we still need a",
      "offset": 2964.24,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "good level of like human involvement to",
      "offset": 2966.48,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "you know make this evaluation process",
      "offset": 2968.559,
      "duration": 4.641
    },
    {
      "lang": "en",
      "text": "like truly reflective of um like your",
      "offset": 2970.48,
      "duration": 5.16
    },
    {
      "lang": "en",
      "text": "retrieval system. It's interesting",
      "offset": 2973.2,
      "duration": 6.72
    },
    {
      "lang": "en",
      "text": "that you're going for multi-party",
      "offset": 2975.64,
      "duration": 7.56
    },
    {
      "lang": "en",
      "text": "alignment and it makes me think uh it",
      "offset": 2979.92,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "makes me curious about whether there's",
      "offset": 2983.2,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "specific research on like how to align",
      "offset": 2985.92,
      "duration": 6.32
    },
    {
      "lang": "en",
      "text": "an LLM not just to a particular uh party",
      "offset": 2988.48,
      "duration": 6.72
    },
    {
      "lang": "en",
      "text": "but to two parties in this case the the",
      "offset": 2992.24,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "user that's issuing queries you're",
      "offset": 2995.2,
      "duration": 4.879
    },
    {
      "lang": "en",
      "text": "aligning to that user through the real",
      "offset": 2997.04,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "world query data set but then you're",
      "offset": 3000.079,
      "duration": 5.361
    },
    {
      "lang": "en",
      "text": "also aligning to the creator of the",
      "offset": 3001.68,
      "duration": 6.84
    },
    {
      "lang": "en",
      "text": "system and their you",
      "offset": 3005.44,
      "duration": 7.52
    },
    {
      "lang": "en",
      "text": "know their input to the LLM as judge uh",
      "offset": 3008.52,
      "duration": 6.44
    },
    {
      "lang": "en",
      "text": "part. Yeah, that's interesting to think",
      "offset": 3012.96,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "about. I don't think there's been or at",
      "offset": 3014.96,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "least from like what I've seen there",
      "offset": 3017.04,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "hasn't been a lot of work in like um",
      "offset": 3018.4,
      "duration": 4.959
    },
    {
      "lang": "en",
      "text": "like LLM alignment on like multiple like",
      "offset": 3020.88,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "parties as you mentioned. Yeah, I've not",
      "offset": 3023.359,
      "duration": 3.041
    },
    {
      "lang": "en",
      "text": "come across it uh either. I'm going to",
      "offset": 3024.72,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "look forward that, you know, just the",
      "offset": 3026.4,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "question kind of opens up thinking about",
      "offset": 3028,
      "duration": 3.599
    },
    {
      "lang": "en",
      "text": "like yeah, you know, game theory",
      "offset": 3029.68,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "implications and all kinds of",
      "offset": 3031.599,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "potentially interesting stuff that could",
      "offset": 3033.28,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "come out of it. Yeah. Yeah. I'd",
      "offset": 3035.119,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "definitely be curious to like hear about",
      "offset": 3037.28,
      "duration": 2.96
    },
    {
      "lang": "en",
      "text": "it further. But I think yeah, that's",
      "offset": 3038.8,
      "duration": 2.64
    },
    {
      "lang": "en",
      "text": "definitely like an important area of",
      "offset": 3040.24,
      "duration": 3.359
    },
    {
      "lang": "en",
      "text": "work because I think um you know like",
      "offset": 3041.44,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "some of the research that I see like a",
      "offset": 3043.599,
      "duration": 2.801
    },
    {
      "lang": "en",
      "text": "lot of people just use like full",
      "offset": 3045.04,
      "duration": 2.96
    },
    {
      "lang": "en",
      "text": "automation like without any human",
      "offset": 3046.4,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "involvement. But I think like you know",
      "offset": 3048,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "like the trend we're like starting to",
      "offset": 3049.92,
      "duration": 3.199
    },
    {
      "lang": "en",
      "text": "see is like you know we do have more",
      "offset": 3051.28,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "like human in the loop in like all these",
      "offset": 3053.119,
      "duration": 5.361
    },
    {
      "lang": "en",
      "text": "like um like processes. So yeah I think",
      "offset": 3054.88,
      "duration": 6.239
    },
    {
      "lang": "en",
      "text": "like definitely like multi-party um like",
      "offset": 3058.48,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "alignment would be interesting to see",
      "offset": 3061.119,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "for sure. Yeah. Yeah. I guess thinking",
      "offset": 3062.88,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "about it more, you could argue that or",
      "offset": 3065.359,
      "duration": 5.521
    },
    {
      "lang": "en",
      "text": "it may be the case that like a lot of",
      "offset": 3068,
      "duration": 4.28
    },
    {
      "lang": "en",
      "text": "the",
      "offset": 3070.88,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "core LLM alignment work is fundamentally",
      "offset": 3072.28,
      "duration": 6.6
    },
    {
      "lang": "en",
      "text": "multi-party in the sense that like if",
      "offset": 3076.16,
      "duration": 4.919
    },
    {
      "lang": "en",
      "text": "you think about like instruction",
      "offset": 3078.88,
      "duration": 6.08
    },
    {
      "lang": "en",
      "text": "following, you want to",
      "offset": 3081.079,
      "duration": 7.24
    },
    {
      "lang": "en",
      "text": "uh follow the developer instructions",
      "offset": 3084.96,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "um but you also want to be useful to the",
      "offset": 3088.319,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "user like so folks are thinking about",
      "offset": 3090.96,
      "duration": 6.72
    },
    {
      "lang": "en",
      "text": "this uh I I'm so curious about like uh",
      "offset": 3093.599,
      "duration": 6.081
    },
    {
      "lang": "en",
      "text": "you know research formulations of it as",
      "offset": 3097.68,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "a multi-party problem. But yeah, I'm",
      "offset": 3099.68,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "curious like what kind of research is",
      "offset": 3102,
      "duration": 2.64
    },
    {
      "lang": "en",
      "text": "being done in the space because I feel",
      "offset": 3103.2,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "like um you know you can't just look at",
      "offset": 3104.64,
      "duration": 5.439
    },
    {
      "lang": "en",
      "text": "like one like component of this. You",
      "offset": 3107.44,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "kind of have to maybe look at like the",
      "offset": 3110.079,
      "duration": 2.881
    },
    {
      "lang": "en",
      "text": "isolated parts of like each party like",
      "offset": 3111.359,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "how do you you know kind of like",
      "offset": 3112.96,
      "duration": 3.119
    },
    {
      "lang": "en",
      "text": "approach that in a more like systematic",
      "offset": 3114.559,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "way. I think that's a yeah definitely",
      "offset": 3116.079,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "interesting to think about. And so is",
      "offset": 3118.319,
      "duration": 4.961
    },
    {
      "lang": "en",
      "text": "this um the future steps that we",
      "offset": 3120.319,
      "duration": 6.081
    },
    {
      "lang": "en",
      "text": "mentioned, are those your near-term",
      "offset": 3123.28,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "focus areas at Chroma or are there other",
      "offset": 3126.4,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "research projects that you're involved",
      "offset": 3128.48,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "in there? Yeah. Um so currently we're",
      "offset": 3130.4,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "working on another research project. I",
      "offset": 3133.44,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "think like there are some interesting",
      "offset": 3135.28,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "directions of this which um you know",
      "offset": 3136.96,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "we've been talking to a few people about",
      "offset": 3138.8,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "but um I think yeah like immediately",
      "offset": 3140.48,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "after this we're looking more into like",
      "offset": 3143.92,
      "duration": 5.679
    },
    {
      "lang": "en",
      "text": "um agent memory. Uh, I won't go too deep",
      "offset": 3146.24,
      "duration": 4.879
    },
    {
      "lang": "en",
      "text": "into it yet, but it sounds like you",
      "offset": 3149.599,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "don't want to spill the beans, but I",
      "offset": 3151.119,
      "duration": 4.801
    },
    {
      "lang": "en",
      "text": "think like memory memory is becoming a",
      "offset": 3153.359,
      "duration": 4.641
    },
    {
      "lang": "en",
      "text": "very like hot topic nowadays. I mean,",
      "offset": 3155.92,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "you just saw like Chachi PT memory like",
      "offset": 3158,
      "duration": 3.359
    },
    {
      "lang": "en",
      "text": "everyone's like very excited about it.",
      "offset": 3159.52,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "Um there's a lot of work around just",
      "offset": 3161.359,
      "duration": 6.76
    },
    {
      "lang": "en",
      "text": "like memory in general but um we want to",
      "offset": 3163.52,
      "duration": 7.68
    },
    {
      "lang": "en",
      "text": "do I guess kind of like a more like",
      "offset": 3168.119,
      "duration": 5.641
    },
    {
      "lang": "en",
      "text": "robust like research into like how you",
      "offset": 3171.2,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "know Asian memory is implemented like",
      "offset": 3173.76,
      "duration": 2.88
    },
    {
      "lang": "en",
      "text": "what are like the best practices and",
      "offset": 3175.28,
      "duration": 5.92
    },
    {
      "lang": "en",
      "text": "that and um yeah just like Asian memory",
      "offset": 3176.64,
      "duration": 6.4
    },
    {
      "lang": "en",
      "text": "broadly but yeah hopefully you'll see",
      "offset": 3181.2,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "that in the coming months. Well, Kelly,",
      "offset": 3183.04,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "thanks so much for sharing a bit about",
      "offset": 3185.359,
      "duration": 5.841
    },
    {
      "lang": "en",
      "text": "the generative benchmarking project and",
      "offset": 3187.92,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "what you've been working on there. Yeah,",
      "offset": 3191.2,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "thank you so much for having me. It's",
      "offset": 3193.2,
      "duration": 5.72
    },
    {
      "lang": "en",
      "text": "great talking. Thank you.",
      "offset": 3194.48,
      "duration": 4.44
    },
    {
      "lang": "en",
      "text": "[Music]",
      "offset": 3204.55,
      "duration": 3.059
    },
    {
      "lang": "en",
      "text": "[Music]",
      "offset": 3222.08,
      "duration": 3.19
    }
  ],
  "cleanText": null,
  "dumpedAt": "2025-07-21T18:43:24.593Z"
}