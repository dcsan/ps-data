{
  "episodeId": "jOukzhFwiCo",
  "channelSlug": "@stratechery",
  "title": "DeepSeek FAQ",
  "publishedAt": "2025-02-03T14:00:51.000Z",
  "rawLines": [
    {
      "lang": "en",
      "text": "deep seek FAQ was published on Monday",
      "offset": 1,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "January 27th",
      "offset": 3.76,
      "duration": 5.64
    },
    {
      "lang": "en",
      "text": "2025 it's Monday January 27th why",
      "offset": 5.56,
      "duration": 6.92
    },
    {
      "lang": "en",
      "text": "haven't you written about deep seek yet",
      "offset": 9.4,
      "duration": 6.239
    },
    {
      "lang": "en",
      "text": "I did I wrote about R1 last Tuesday I",
      "offset": 12.48,
      "duration": 6.08
    },
    {
      "lang": "en",
      "text": "totally forgot about that I take",
      "offset": 15.639,
      "duration": 4.961
    },
    {
      "lang": "en",
      "text": "responsibility I stand by the post",
      "offset": 18.56,
      "duration": 3.559
    },
    {
      "lang": "en",
      "text": "including the two biggest takeaways that",
      "offset": 20.6,
      "duration": 3.56
    },
    {
      "lang": "en",
      "text": "I highlighted emerging Chain of Thought",
      "offset": 22.119,
      "duration": 3.801
    },
    {
      "lang": "en",
      "text": "via pure reinforcement learning and the",
      "offset": 24.16,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "power of distillation and I mentioned",
      "offset": 25.92,
      "duration": 4.359
    },
    {
      "lang": "en",
      "text": "the low cost which I expanded on sharp",
      "offset": 28,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "Tech and Chip band implications but",
      "offset": 30.279,
      "duration": 4.44
    },
    {
      "lang": "en",
      "text": "those observations were too localized to",
      "offset": 32.88,
      "duration": 3.999
    },
    {
      "lang": "en",
      "text": "the current state-of-the-art in AI what",
      "offset": 34.719,
      "duration": 4.041
    },
    {
      "lang": "en",
      "text": "I totally failed to anticipate were the",
      "offset": 36.879,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "broader implications this news would",
      "offset": 38.76,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "have to the overall meta discussion",
      "offset": 40.559,
      "duration": 4.121
    },
    {
      "lang": "en",
      "text": "particularly in terms of the US and",
      "offset": 42.84,
      "duration": 4.76
    },
    {
      "lang": "en",
      "text": "China is there precedence for such a",
      "offset": 44.68,
      "duration": 6.8
    },
    {
      "lang": "en",
      "text": "Miss there is in September 2023 huwei",
      "offset": 47.6,
      "duration": 5.799
    },
    {
      "lang": "en",
      "text": "announced the mate 60 Pro with a smick",
      "offset": 51.48,
      "duration": 5.16
    },
    {
      "lang": "en",
      "text": "manufactured 7 NM chip the existence of",
      "offset": 53.399,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "this chip wasn't a surprise for those",
      "offset": 56.64,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "paying close attention SMI had made a 7",
      "offset": 58.199,
      "duration": 5
    },
    {
      "lang": "en",
      "text": "NM chip a year earlier the existence of",
      "offset": 60.559,
      "duration": 5.001
    },
    {
      "lang": "en",
      "text": "which I had noted even earlier than that",
      "offset": 63.199,
      "duration": 4.481
    },
    {
      "lang": "en",
      "text": "and tsmc had shipped 7 NM chips in",
      "offset": 65.56,
      "duration": 4.76
    },
    {
      "lang": "en",
      "text": "volume using nothing but duv lithography",
      "offset": 67.68,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "later iterations of 7 nmet were the",
      "offset": 70.32,
      "duration": 4.839
    },
    {
      "lang": "en",
      "text": "first to use euv Intel had also made 10",
      "offset": 72.24,
      "duration": 5.8
    },
    {
      "lang": "en",
      "text": "nmet chips the equivalent of tsmc 7 nmet",
      "offset": 75.159,
      "duration": 5.081
    },
    {
      "lang": "en",
      "text": "chips years earlier using nothing but",
      "offset": 78.04,
      "duration": 4.52
    },
    {
      "lang": "en",
      "text": "duv but couldn't do so with profitable",
      "offset": 80.24,
      "duration": 4.879
    },
    {
      "lang": "en",
      "text": "yields the idea that smick could ship 7",
      "offset": 82.56,
      "duration": 4.199
    },
    {
      "lang": "en",
      "text": "nmet chips using their existing",
      "offset": 85.119,
      "duration": 3.32
    },
    {
      "lang": "en",
      "text": "equipment particularly if they didn't",
      "offset": 86.759,
      "duration": 3.521
    },
    {
      "lang": "en",
      "text": "care about yields wasn't remotely",
      "offset": 88.439,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "surprising to me anyways what I totally",
      "offset": 90.28,
      "duration": 5.479
    },
    {
      "lang": "en",
      "text": "failed to anticipate was the overwrought",
      "offset": 93.479,
      "duration": 4.92
    },
    {
      "lang": "en",
      "text": "reaction in Washington DC their dramatic",
      "offset": 95.759,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "expansion in the chip band that",
      "offset": 98.399,
      "duration": 3.281
    },
    {
      "lang": "en",
      "text": "culminated in the Biden Administration",
      "offset": 99.68,
      "duration": 3.439
    },
    {
      "lang": "en",
      "text": "transforming chip sales to a",
      "offset": 101.68,
      "duration": 3.24
    },
    {
      "lang": "en",
      "text": "permission-based structure was",
      "offset": 103.119,
      "duration": 3.64
    },
    {
      "lang": "en",
      "text": "Downstream from people not understanding",
      "offset": 104.92,
      "duration": 4.04
    },
    {
      "lang": "en",
      "text": "the intricacies of Chip production and",
      "offset": 106.759,
      "duration": 4.121
    },
    {
      "lang": "en",
      "text": "being totally blindsided by the Huawei",
      "offset": 108.96,
      "duration": 4.439
    },
    {
      "lang": "en",
      "text": "mate 60 Pro I get the sense that",
      "offset": 110.88,
      "duration": 3.879
    },
    {
      "lang": "en",
      "text": "something similar has happened over the",
      "offset": 113.399,
      "duration": 3.881
    },
    {
      "lang": "en",
      "text": "last 72 hours the details of what deep",
      "offset": 114.759,
      "duration": 4.441
    },
    {
      "lang": "en",
      "text": "seek has accomplished and what they have",
      "offset": 117.28,
      "duration": 4.68
    },
    {
      "lang": "en",
      "text": "not are less important than the reaction",
      "offset": 119.2,
      "duration": 4.12
    },
    {
      "lang": "en",
      "text": "and what that reaction says about",
      "offset": 121.96,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "people's pre-existing",
      "offset": 123.32,
      "duration": 5.359
    },
    {
      "lang": "en",
      "text": "assumptions so what did deep seek",
      "offset": 125.32,
      "duration": 5.88
    },
    {
      "lang": "en",
      "text": "announce the most proximate announcement",
      "offset": 128.679,
      "duration": 5.081
    },
    {
      "lang": "en",
      "text": "to this weekend's meltdown was R1 a",
      "offset": 131.2,
      "duration": 4.28
    },
    {
      "lang": "en",
      "text": "reasoning model that is similar to open",
      "offset": 133.76,
      "duration": 5.24
    },
    {
      "lang": "en",
      "text": "AI 01 however many of the revelations",
      "offset": 135.48,
      "duration": 5.16
    },
    {
      "lang": "en",
      "text": "that contributed to the Meltdown",
      "offset": 139,
      "duration": 3.879
    },
    {
      "lang": "en",
      "text": "including deep seeks training costs",
      "offset": 140.64,
      "duration": 3.959
    },
    {
      "lang": "en",
      "text": "actually accompanied the V3 announcement",
      "offset": 142.879,
      "duration": 4.521
    },
    {
      "lang": "en",
      "text": "over Christmas moreover many of the",
      "offset": 144.599,
      "duration": 4.441
    },
    {
      "lang": "en",
      "text": "breakthroughs that underg guarded V3",
      "offset": 147.4,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "were actually revealed with the release",
      "offset": 149.04,
      "duration": 4.36
    },
    {
      "lang": "en",
      "text": "of the V2 model last January is this",
      "offset": 150.76,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "model naming convention the greatest",
      "offset": 153.4,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "crime that open AI has committed second",
      "offset": 155.48,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "greatest we'll get to the greatest",
      "offset": 158.2,
      "duration": 4.759
    },
    {
      "lang": "en",
      "text": "momentarily let's work backwards what",
      "offset": 160.2,
      "duration": 5.16
    },
    {
      "lang": "en",
      "text": "was the V2 model and why was it",
      "offset": 162.959,
      "duration": 5.121
    },
    {
      "lang": "en",
      "text": "important the Deep seek V2 model",
      "offset": 165.36,
      "duration": 4.84
    },
    {
      "lang": "en",
      "text": "introduced two important breakthroughs",
      "offset": 168.08,
      "duration": 6.04
    },
    {
      "lang": "en",
      "text": "deep seeke and deep seek MLA thee and",
      "offset": 170.2,
      "duration": 6.92
    },
    {
      "lang": "en",
      "text": "deep seek M refers to mixture of experts",
      "offset": 174.12,
      "duration": 6.399
    },
    {
      "lang": "en",
      "text": "some models like GPT 3.5 activate the",
      "offset": 177.12,
      "duration": 5.119
    },
    {
      "lang": "en",
      "text": "entire model during both training and",
      "offset": 180.519,
      "duration": 4.481
    },
    {
      "lang": "en",
      "text": "inference it turns out however that not",
      "offset": 182.239,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "every part of the model is necessary for",
      "offset": 185,
      "duration": 4.599
    },
    {
      "lang": "en",
      "text": "the topic at hande Splits the model into",
      "offset": 186.64,
      "duration": 5.64
    },
    {
      "lang": "en",
      "text": "multiple experts and only activates the",
      "offset": 189.599,
      "duration": 5.841
    },
    {
      "lang": "en",
      "text": "ones that are necessary gp4 was Ane",
      "offset": 192.28,
      "duration": 4.959
    },
    {
      "lang": "en",
      "text": "model that was believed to have 16",
      "offset": 195.44,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "experts with approximately 110 billion",
      "offset": 197.239,
      "duration": 5.601
    },
    {
      "lang": "en",
      "text": "parameters each deep seek Moe as",
      "offset": 199.599,
      "duration": 5.681
    },
    {
      "lang": "en",
      "text": "implemented in V2 introduced important",
      "offset": 202.84,
      "duration": 4.52
    },
    {
      "lang": "en",
      "text": "Innovations on this concept including",
      "offset": 205.28,
      "duration": 3.599
    },
    {
      "lang": "en",
      "text": "differentiating between more finely",
      "offset": 207.36,
      "duration": 3.879
    },
    {
      "lang": "en",
      "text": "grained specialized experts and shared",
      "offset": 208.879,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "experts with more generalized",
      "offset": 211.239,
      "duration": 4.881
    },
    {
      "lang": "en",
      "text": "capabilities critically deep seek M also",
      "offset": 212.879,
      "duration": 4.881
    },
    {
      "lang": "en",
      "text": "introduced new approaches to load",
      "offset": 216.12,
      "duration": 4.039
    },
    {
      "lang": "en",
      "text": "balancing and routing during training",
      "offset": 217.76,
      "duration": 3.759
    },
    {
      "lang": "en",
      "text": "traditionally Moe increased",
      "offset": 220.159,
      "duration": 3.201
    },
    {
      "lang": "en",
      "text": "Communications overhead in training in",
      "offset": 221.519,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "exchange for efficient inference but",
      "offset": 223.36,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "deep seeks approach made training more",
      "offset": 225.599,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "efficient as well deep seek MLA was an",
      "offset": 227.36,
      "duration": 4.84
    },
    {
      "lang": "en",
      "text": "even bigger breakthrough one of the",
      "offset": 230.319,
      "duration": 3.56
    },
    {
      "lang": "en",
      "text": "biggest limitations on inference is the",
      "offset": 232.2,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "sheer amount of memory required you both",
      "offset": 233.879,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "need to load the model into memory and",
      "offset": 236.36,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "also load the entire context with window",
      "offset": 238.2,
      "duration": 4.239
    },
    {
      "lang": "en",
      "text": "context windows are particularly",
      "offset": 240.68,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "expensive in terms of memory as every",
      "offset": 242.439,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "token requires both a key and",
      "offset": 244.68,
      "duration": 4.639
    },
    {
      "lang": "en",
      "text": "corresponding value deep seek MLA or",
      "offset": 246.439,
      "duration": 5.121
    },
    {
      "lang": "en",
      "text": "multi-head Laten attention makes it",
      "offset": 249.319,
      "duration": 4.601
    },
    {
      "lang": "en",
      "text": "possible to compress the key Value Store",
      "offset": 251.56,
      "duration": 4.2
    },
    {
      "lang": "en",
      "text": "dramatically decreasing memory usage",
      "offset": 253.92,
      "duration": 4.2
    },
    {
      "lang": "en",
      "text": "during inference M I'm not sure I",
      "offset": 255.76,
      "duration": 4.92
    },
    {
      "lang": "en",
      "text": "understood any of that the key",
      "offset": 258.12,
      "duration": 4.28
    },
    {
      "lang": "en",
      "text": "implications of these breakthroughs and",
      "offset": 260.68,
      "duration": 3.72
    },
    {
      "lang": "en",
      "text": "the part you need to understand only",
      "offset": 262.4,
      "duration": 4.239
    },
    {
      "lang": "en",
      "text": "became apparent with V3 which added a",
      "offset": 264.4,
      "duration": 4.04
    },
    {
      "lang": "en",
      "text": "new approach to load balancing further",
      "offset": 266.639,
      "duration": 3.56
    },
    {
      "lang": "en",
      "text": "reducing Communications overhead head",
      "offset": 268.44,
      "duration": 3.8
    },
    {
      "lang": "en",
      "text": "and multi-token prediction in training",
      "offset": 270.199,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "further densifying each training step",
      "offset": 272.24,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "again reducing overhead V3 was",
      "offset": 274.28,
      "duration": 4.639
    },
    {
      "lang": "en",
      "text": "shockingly cheap to train deep seek",
      "offset": 276.72,
      "duration": 4.479
    },
    {
      "lang": "en",
      "text": "claimed the model training took",
      "offset": 278.919,
      "duration": 6.28
    },
    {
      "lang": "en",
      "text": "2788 h800 GPU hours which at a cost of",
      "offset": 281.199,
      "duration": 7.681
    },
    {
      "lang": "en",
      "text": "$2 per GPU hour comes out to a mere $",
      "offset": 285.199,
      "duration": 5.761
    },
    {
      "lang": "en",
      "text": "5.57",
      "offset": 288.88,
      "duration": 5.92
    },
    {
      "lang": "en",
      "text": "million that seems impossibly low deep",
      "offset": 290.96,
      "duration": 5.72
    },
    {
      "lang": "en",
      "text": "seek is clear that these costs are only",
      "offset": 294.8,
      "duration": 3.88
    },
    {
      "lang": "en",
      "text": "for the final training run and exclude",
      "offset": 296.68,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "all other expenses",
      "offset": 298.68,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "from the V3 paper lastly we emphasize",
      "offset": 300.28,
      "duration": 6.04
    },
    {
      "lang": "en",
      "text": "again the economical training costs of",
      "offset": 303.96,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "deep seek V3 summarized in table one",
      "offset": 306.32,
      "duration": 4.92
    },
    {
      "lang": "en",
      "text": "achieved through our optimized codesign",
      "offset": 309.32,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "of algorithms Frameworks and Hardware",
      "offset": 311.24,
      "duration": 4.92
    },
    {
      "lang": "en",
      "text": "during the pre-training stage training",
      "offset": 314.12,
      "duration": 4.68
    },
    {
      "lang": "en",
      "text": "deep seek V3 on each trillion tokens",
      "offset": 316.16,
      "duration": 7.24
    },
    {
      "lang": "en",
      "text": "requires only 180,000 h800 GPU hours I.E",
      "offset": 318.8,
      "duration": 9.44
    },
    {
      "lang": "en",
      "text": "3.7 days on our cluster with 248 h800",
      "offset": 323.4,
      "duration": 7.88
    },
    {
      "lang": "en",
      "text": "gpus consequ ly our pre-training stage",
      "offset": 328.24,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "is completed in less than 2 months and",
      "offset": 331.28,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "cost",
      "offset": 333.52,
      "duration": 5.239
    },
    {
      "lang": "en",
      "text": "2,664 th000 GPU hours combined with",
      "offset": 334.56,
      "duration": 7.16
    },
    {
      "lang": "en",
      "text": "119,000 GPU hours for the context length",
      "offset": 338.759,
      "duration": 5.921
    },
    {
      "lang": "en",
      "text": "extension and 5,000 GPU hours for post",
      "offset": 341.72,
      "duration": 6.64
    },
    {
      "lang": "en",
      "text": "trainining deepik V3 costs only 2.78",
      "offset": 344.68,
      "duration": 7.04
    },
    {
      "lang": "en",
      "text": "million GPU hours for its full training",
      "offset": 348.36,
      "duration": 5.559
    },
    {
      "lang": "en",
      "text": "assuming the rental price of the h800",
      "offset": 351.72,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "GPU is $2 per GPU hour our total",
      "offset": 353.919,
      "duration": 6.801
    },
    {
      "lang": "en",
      "text": "training costs amount to only 5.57 $6",
      "offset": 357.16,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "million note that the aformentioned",
      "offset": 360.72,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "costs include only the official training",
      "offset": 362.84,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "of deep seek V3 excluding the costs",
      "offset": 365.44,
      "duration": 4.92
    },
    {
      "lang": "en",
      "text": "associated with prior research and",
      "offset": 368.36,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "ablation experiments on architectures",
      "offset": 370.36,
      "duration": 5.279
    },
    {
      "lang": "en",
      "text": "algorithms or data so no you can't",
      "offset": 372.68,
      "duration": 5
    },
    {
      "lang": "en",
      "text": "replicate deep seek the company for $",
      "offset": 375.639,
      "duration": 4.201
    },
    {
      "lang": "en",
      "text": "5.57 six",
      "offset": 377.68,
      "duration": 4.68
    },
    {
      "lang": "en",
      "text": "million I still don't believe that",
      "offset": 379.84,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "number actually the burden of proof is",
      "offset": 382.36,
      "duration": 4.119
    },
    {
      "lang": "en",
      "text": "on the doubters at least once you",
      "offset": 384.8,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "understand the V3 architecture remember",
      "offset": 386.479,
      "duration": 6.081
    },
    {
      "lang": "en",
      "text": "that bit about deep seek mle V3 has 671",
      "offset": 388.8,
      "duration": 6.04
    },
    {
      "lang": "en",
      "text": "billion parameters but only 37 billion",
      "offset": 392.56,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "parameters in the active expert are",
      "offset": 394.84,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "computed per token this equates to",
      "offset": 396.56,
      "duration": 4.28
    },
    {
      "lang": "en",
      "text": "333.33 or fp32 Precision they were",
      "offset": 406.28,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "reduced to fp8 Precision for",
      "offset": 409.919,
      "duration": 5.481
    },
    {
      "lang": "en",
      "text": "calculations 248 h800 gpus have a",
      "offset": 411.96,
      "duration": 7.959
    },
    {
      "lang": "en",
      "text": "capacity of 3.97 XLE flops I 3.9 7",
      "offset": 415.4,
      "duration": 6.96
    },
    {
      "lang": "en",
      "text": "billion billion flops the training set",
      "offset": 419.919,
      "duration": 4.68
    },
    {
      "lang": "en",
      "text": "meanwhile consisted of 14.8 trillion",
      "offset": 422.36,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "tokens once you do all the math it",
      "offset": 424.599,
      "duration": 4.961
    },
    {
      "lang": "en",
      "text": "becomes apparent that 2.8 million h800",
      "offset": 427,
      "duration": 5.479
    },
    {
      "lang": "en",
      "text": "hours is sufficient for training V3",
      "offset": 429.56,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "again this was just the final run not",
      "offset": 432.479,
      "duration": 4.521
    },
    {
      "lang": "en",
      "text": "the total cost but it's a plausible",
      "offset": 435.08,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "number scale AI CEO Alexander Wong said",
      "offset": 437,
      "duration": 6.4
    },
    {
      "lang": "en",
      "text": "they have 50,000",
      "offset": 440.52,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "h100s I don't know where Wong got his",
      "offset": 443.4,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "information I'm guessing he's referring",
      "offset": 445.56,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "to this November 2024 tweet from Dylan",
      "offset": 447.4,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "Batel which says that deep seek had",
      "offset": 449.8,
      "duration": 6.119
    },
    {
      "lang": "en",
      "text": "quote over 50,000 Hopper gpus h800",
      "offset": 451.96,
      "duration": 6.28
    },
    {
      "lang": "en",
      "text": "however are hopper gpus they just have",
      "offset": 455.919,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "much more constrained memory bandwidth",
      "offset": 458.24,
      "duration": 4.359
    },
    {
      "lang": "en",
      "text": "than h100s because of us sanctions",
      "offset": 459.759,
      "duration": 4.761
    },
    {
      "lang": "en",
      "text": "here's the thing a huge number of the",
      "offset": 462.599,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "Innovations I explained above are about",
      "offset": 464.52,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "overcoming the lack of memory bandwidth",
      "offset": 466.199,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "implied in using h800 instead of",
      "offset": 467.96,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "h100s moreover if you actually did the",
      "offset": 470.52,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "math on the previous question you would",
      "offset": 473.08,
      "duration": 3.559
    },
    {
      "lang": "en",
      "text": "realize that deep seek actually had an",
      "offset": 474.919,
      "duration": 3.96
    },
    {
      "lang": "en",
      "text": "excess of computing that's because deep",
      "offset": 476.639,
      "duration": 4.721
    },
    {
      "lang": "en",
      "text": "seek actually program 20 of the 132",
      "offset": 478.879,
      "duration": 5
    },
    {
      "lang": "en",
      "text": "processing units on each h800",
      "offset": 481.36,
      "duration": 4.559
    },
    {
      "lang": "en",
      "text": "specifically to manage cross chip",
      "offset": 483.879,
      "duration": 4.641
    },
    {
      "lang": "en",
      "text": "Communications this is actually some of",
      "offset": 485.919,
      "duration": 4.921
    },
    {
      "lang": "en",
      "text": "this stuff is impossible to do in Cuda",
      "offset": 488.52,
      "duration": 4.239
    },
    {
      "lang": "en",
      "text": "deep seek Engineers had to drop down a",
      "offset": 490.84,
      "duration": 3.96
    },
    {
      "lang": "en",
      "text": "PTX a low-level instruction set for",
      "offset": 492.759,
      "duration": 4.201
    },
    {
      "lang": "en",
      "text": "NVIDIA gpus that is basically like",
      "offset": 494.8,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "Assembly Language this is an insane",
      "offset": 496.96,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "level of optimization that only makes",
      "offset": 499.199,
      "duration": 5.161
    },
    {
      "lang": "en",
      "text": "sense if you using H 800s meanwhile deep",
      "offset": 500.8,
      "duration": 5.119
    },
    {
      "lang": "en",
      "text": "seek also makes their models available",
      "offset": 504.36,
      "duration": 3.399
    },
    {
      "lang": "en",
      "text": "for inference that requires a whole",
      "offset": 505.919,
      "duration": 3.801
    },
    {
      "lang": "en",
      "text": "bunch of gpus above and beyond what ever",
      "offset": 507.759,
      "duration": 3.441
    },
    {
      "lang": "en",
      "text": "was used for",
      "offset": 509.72,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "training so was this a violation of the",
      "offset": 511.2,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "chip",
      "offset": 513.8,
      "duration": 4.599
    },
    {
      "lang": "en",
      "text": "band nope h100s were prohibited by the",
      "offset": 515.039,
      "duration": 6.041
    },
    {
      "lang": "en",
      "text": "chip band but not H 800s everyone",
      "offset": 518.399,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "assumed that training Leading Edge",
      "offset": 521.08,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "models required more inter chip memory",
      "offset": 522.56,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "bandwidth but that is exactly what deep",
      "offset": 524.44,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "seek optimize both their model structure",
      "offset": 526.399,
      "duration": 4.841
    },
    {
      "lang": "en",
      "text": "and infrastructure around again just to",
      "offset": 528.279,
      "duration": 5.201
    },
    {
      "lang": "en",
      "text": "emphasize this point all the decisions",
      "offset": 531.24,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "deep seek made in the design of this",
      "offset": 533.48,
      "duration": 3
    },
    {
      "lang": "en",
      "text": "model only makes sense if you are",
      "offset": 535.08,
      "duration": 4.12
    },
    {
      "lang": "en",
      "text": "constrained to the h800 if deep seek had",
      "offset": 536.48,
      "duration": 4.84
    },
    {
      "lang": "en",
      "text": "access ACC to h100s they probably would",
      "offset": 539.2,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "have used a larger training cluster with",
      "offset": 541.32,
      "duration": 4.04
    },
    {
      "lang": "en",
      "text": "much fewer optimizations specifically",
      "offset": 543.04,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "focused on overcoming the lack of",
      "offset": 545.36,
      "duration": 6.32
    },
    {
      "lang": "en",
      "text": "bandwidth so V3 is a Leading Edge",
      "offset": 547.6,
      "duration": 6.32
    },
    {
      "lang": "en",
      "text": "model it's definitely competitive with",
      "offset": 551.68,
      "duration": 5.64
    },
    {
      "lang": "en",
      "text": "open AI 40 in anthropics Sonet 3.5 and",
      "offset": 553.92,
      "duration": 4.68
    },
    {
      "lang": "en",
      "text": "appears to be better than llama's",
      "offset": 557.32,
      "duration": 3.4
    },
    {
      "lang": "en",
      "text": "biggest model what does seem likely is",
      "offset": 558.6,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "that deep seek was able to distill those",
      "offset": 560.72,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "models to give V3 highquality tokens to",
      "offset": 562.44,
      "duration": 5.079
    },
    {
      "lang": "en",
      "text": "train on what is",
      "offset": 564.64,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "distillation distillation is a means of",
      "offset": 567.519,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "extracting understanding from another",
      "offset": 569.68,
      "duration": 3.599
    },
    {
      "lang": "en",
      "text": "model you can send inputs to the teacher",
      "offset": 571.2,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "model and record the outputs and use",
      "offset": 573.279,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "that to train the student model this is",
      "offset": 575.2,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "how you get models like gp4 Turbo from",
      "offset": 577.36,
      "duration": 5.039
    },
    {
      "lang": "en",
      "text": "GPT 4 distillation is easier for a",
      "offset": 579.519,
      "duration": 4.76
    },
    {
      "lang": "en",
      "text": "company to do on its own models because",
      "offset": 582.399,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "they have full access but you can still",
      "offset": 584.279,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "do distillation in a somewhat more",
      "offset": 586.32,
      "duration": 4.68
    },
    {
      "lang": "en",
      "text": "unwieldy way VIA API or even if you get",
      "offset": 587.88,
      "duration": 6.24
    },
    {
      "lang": "en",
      "text": "creative via check clients distillation",
      "offset": 591,
      "duration": 4.6
    },
    {
      "lang": "en",
      "text": "obviously violates the terms of service",
      "offset": 594.12,
      "duration": 3.48
    },
    {
      "lang": "en",
      "text": "of various models but the only way to",
      "offset": 595.6,
      "duration": 3.799
    },
    {
      "lang": "en",
      "text": "stop it is to actually cut off access",
      "offset": 597.6,
      "duration": 5.359
    },
    {
      "lang": "en",
      "text": "access via IP Banning rate limiting Etc",
      "offset": 599.399,
      "duration": 5.241
    },
    {
      "lang": "en",
      "text": "it's assumed to be widespread in terms",
      "offset": 602.959,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "of model training and is why there are",
      "offset": 604.64,
      "duration": 3.72
    },
    {
      "lang": "en",
      "text": "an ever increasing number of models",
      "offset": 606.64,
      "duration": 4.439
    },
    {
      "lang": "en",
      "text": "converging on GPT 40 quality this",
      "offset": 608.36,
      "duration": 4.36
    },
    {
      "lang": "en",
      "text": "doesn't mean that we know for a fact",
      "offset": 611.079,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "that deep seek distilled 40 or clawed",
      "offset": 612.72,
      "duration": 4.679
    },
    {
      "lang": "en",
      "text": "but frankly it would be odd if they",
      "offset": 614.839,
      "duration": 5.161
    },
    {
      "lang": "en",
      "text": "didn't distillation seems terrible for",
      "offset": 617.399,
      "duration": 4.281
    },
    {
      "lang": "en",
      "text": "Leading Edge",
      "offset": 620,
      "duration": 4.839
    },
    {
      "lang": "en",
      "text": "models it is on the positive side open",
      "offset": 621.68,
      "duration": 5
    },
    {
      "lang": "en",
      "text": "Ai and anthropic and Google are almost",
      "offset": 624.839,
      "duration": 3.721
    },
    {
      "lang": "en",
      "text": "certainly using distillation to optimize",
      "offset": 626.68,
      "duration": 3.719
    },
    {
      "lang": "en",
      "text": "the models they use for inference for",
      "offset": 628.56,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "their consumer facing apps on the",
      "offset": 630.399,
      "duration": 3.721
    },
    {
      "lang": "en",
      "text": "negative side they are effectively",
      "offset": 632.48,
      "duration": 3.24
    },
    {
      "lang": "en",
      "text": "bearing the entire cost of training the",
      "offset": 634.12,
      "duration": 3.279
    },
    {
      "lang": "en",
      "text": "Leading Edge while everyone else is",
      "offset": 635.72,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "freew writing on their investment indeed",
      "offset": 637.399,
      "duration": 4.361
    },
    {
      "lang": "en",
      "text": "this is probably the core economic",
      "offset": 640.12,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "Factor undering the slow divorce of",
      "offset": 641.76,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "Microsoft in open AI Microsoft is",
      "offset": 643.56,
      "duration": 4.04
    },
    {
      "lang": "en",
      "text": "interested in providing inference to its",
      "offset": 646,
      "duration": 3.8
    },
    {
      "lang": "en",
      "text": "customers but much less enthused about",
      "offset": 647.6,
      "duration": 4.44
    },
    {
      "lang": "en",
      "text": "funding $100 billion data centers to",
      "offset": 649.8,
      "duration": 3.719
    },
    {
      "lang": "en",
      "text": "train Leading Edge models that are",
      "offset": 652.04,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "likely to be commoditized long before",
      "offset": 653.519,
      "duration": 5.361
    },
    {
      "lang": "en",
      "text": "that $100 billion is depreciated is this",
      "offset": 655.72,
      "duration": 6.2
    },
    {
      "lang": "en",
      "text": "why all of the big Tech stock prices are",
      "offset": 658.88,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "down in the long run model",
      "offset": 661.92,
      "duration": 4.359
    },
    {
      "lang": "en",
      "text": "commoditization and cheaper inference",
      "offset": 664.32,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "which deep seek has also demonstrated is",
      "offset": 666.279,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "great for big Tech a world where",
      "offset": 668.48,
      "duration": 3.88
    },
    {
      "lang": "en",
      "text": "Microsoft gets to provide inference to",
      "offset": 670.6,
      "duration": 3.88
    },
    {
      "lang": "en",
      "text": "its customers for a fraction of the cost",
      "offset": 672.36,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "means that Microsoft has to spend less",
      "offset": 674.48,
      "duration": 4.28
    },
    {
      "lang": "en",
      "text": "on data centers in gpus or just as",
      "offset": 676.12,
      "duration": 4.839
    },
    {
      "lang": "en",
      "text": "likely sees dramatically higher usage",
      "offset": 678.76,
      "duration": 4.639
    },
    {
      "lang": "en",
      "text": "given that inference is so much cheaper",
      "offset": 680.959,
      "duration": 5.041
    },
    {
      "lang": "en",
      "text": "another big winner is Amazon aws's buy",
      "offset": 683.399,
      "duration": 4.041
    },
    {
      "lang": "en",
      "text": "and large failed to make their own",
      "offset": 686,
      "duration": 3.32
    },
    {
      "lang": "en",
      "text": "quality model but that doesn't matter",
      "offset": 687.44,
      "duration": 3.32
    },
    {
      "lang": "en",
      "text": "matter if there are very high quality",
      "offset": 689.32,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "open- Source models that they can serve",
      "offset": 690.76,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "at far lower costs than expected apple",
      "offset": 692.6,
      "duration": 4.84
    },
    {
      "lang": "en",
      "text": "is also a big winner dramatically",
      "offset": 695.56,
      "duration": 3.32
    },
    {
      "lang": "en",
      "text": "decreased memory requirements for",
      "offset": 697.44,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "inference make Edge inference much more",
      "offset": 698.88,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "viable and Apple has the best hardware",
      "offset": 700.88,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "for exactly that Apple silic uses",
      "offset": 703.04,
      "duration": 4.799
    },
    {
      "lang": "en",
      "text": "unified memory which means that the CPU",
      "offset": 705.6,
      "duration": 5.32
    },
    {
      "lang": "en",
      "text": "GPU and npu neuro Processing Unit have",
      "offset": 707.839,
      "duration": 5.24
    },
    {
      "lang": "en",
      "text": "access to a shared pool of memory this",
      "offset": 710.92,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "means that Apple's high-end Hardware",
      "offset": 713.079,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "actually has the best consumer chip for",
      "offset": 715,
      "duration": 4.44
    },
    {
      "lang": "en",
      "text": "inference Nvidia gaming gpus max out at",
      "offset": 716.68,
      "duration": 5.48
    },
    {
      "lang": "en",
      "text": "32 GB of vram while Apple's chips go up",
      "offset": 719.44,
      "duration": 6.56
    },
    {
      "lang": "en",
      "text": "to 192 GB of RAM meta meanwhile is the",
      "offset": 722.16,
      "duration": 5.919
    },
    {
      "lang": "en",
      "text": "biggest winner of all I already laid out",
      "offset": 726,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "last fall how every aspect of meta's",
      "offset": 728.079,
      "duration": 4.841
    },
    {
      "lang": "en",
      "text": "business benefits from AI a big barrier",
      "offset": 730.32,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "to realizing that vision is the cost of",
      "offset": 732.92,
      "duration": 3.599
    },
    {
      "lang": "en",
      "text": "inference which means that dramatically",
      "offset": 734.56,
      "duration": 3.8
    },
    {
      "lang": "en",
      "text": "cheaper inference and dramatically",
      "offset": 736.519,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "cheaper training given the need for meta",
      "offset": 738.36,
      "duration": 3.96
    },
    {
      "lang": "en",
      "text": "to stay on The Cutting Edge makes that",
      "offset": 740.36,
      "duration": 4.719
    },
    {
      "lang": "en",
      "text": "Vision much more achievable Google",
      "offset": 742.32,
      "duration": 5.4
    },
    {
      "lang": "en",
      "text": "meanwhile is probably in worse shape a",
      "offset": 745.079,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "world of decreased Hardware require",
      "offset": 747.72,
      "duration": 3.16
    },
    {
      "lang": "en",
      "text": "ironment lessens the relative Advantage",
      "offset": 749.16,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "they have from tpus more importantly a",
      "offset": 750.88,
      "duration": 4.84
    },
    {
      "lang": "en",
      "text": "world of zeroc cost inference increases",
      "offset": 753.56,
      "duration": 4.6
    },
    {
      "lang": "en",
      "text": "the viability and likelihood of products",
      "offset": 755.72,
      "duration": 5.239
    },
    {
      "lang": "en",
      "text": "that display search granted Google gets",
      "offset": 758.16,
      "duration": 4.919
    },
    {
      "lang": "en",
      "text": "lower costs as well but any change from",
      "offset": 760.959,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "the status quo is probably a net",
      "offset": 763.079,
      "duration": 5.841
    },
    {
      "lang": "en",
      "text": "negative I asked why the stock prices",
      "offset": 766.639,
      "duration": 5.041
    },
    {
      "lang": "en",
      "text": "are down you just painted a positive",
      "offset": 768.92,
      "duration": 5.24
    },
    {
      "lang": "en",
      "text": "picture my picture is of the long run",
      "offset": 771.68,
      "duration": 4.04
    },
    {
      "lang": "en",
      "text": "today is the short run and it seems",
      "offset": 774.16,
      "duration": 3
    },
    {
      "lang": "en",
      "text": "likely the market is working through the",
      "offset": 775.72,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "shock of r1's existence",
      "offset": 777.16,
      "duration": 7
    },
    {
      "lang": "en",
      "text": "wait you haven't even talked about R1",
      "offset": 780.04,
      "duration": 7.479
    },
    {
      "lang": "en",
      "text": "yet R1 is a reasoning model like open AI",
      "offset": 784.16,
      "duration": 5.799
    },
    {
      "lang": "en",
      "text": "01 it has the ability to think through a",
      "offset": 787.519,
      "duration": 4.201
    },
    {
      "lang": "en",
      "text": "problem producing much higher quality",
      "offset": 789.959,
      "duration": 3.56
    },
    {
      "lang": "en",
      "text": "results particularly in areas like",
      "offset": 791.72,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "coding math and logic but I repeat",
      "offset": 793.519,
      "duration": 7.56
    },
    {
      "lang": "en",
      "text": "myself is this more impressive than",
      "offset": 797.16,
      "duration": 6.679
    },
    {
      "lang": "en",
      "text": "V3 actually the reason why spent so much",
      "offset": 801.079,
      "duration": 5
    },
    {
      "lang": "en",
      "text": "time on V3 is that that was the model",
      "offset": 803.839,
      "duration": 4.12
    },
    {
      "lang": "en",
      "text": "that actually demonstrated a lot of the",
      "offset": 806.079,
      "duration": 3.641
    },
    {
      "lang": "en",
      "text": "Dynamics that seemed to be generating so",
      "offset": 807.959,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "much surprise and controversy R1 is",
      "offset": 809.72,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "notable however because o1 stood alone",
      "offset": 812.279,
      "duration": 3.881
    },
    {
      "lang": "en",
      "text": "as the only reasoning model on the",
      "offset": 814.68,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "market and the clearest sign that open",
      "offset": 816.16,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "AI was the market leader R1 undoes the O",
      "offset": 818.12,
      "duration": 5.719
    },
    {
      "lang": "en",
      "text": "mythology in a couple of important ways",
      "offset": 821.44,
      "duration": 4.92
    },
    {
      "lang": "en",
      "text": "first there is the fact that it exists",
      "offset": 823.839,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "open AI does not have some sort of",
      "offset": 826.36,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "Special Sauce that can't be replicated",
      "offset": 828.079,
      "duration": 5.521
    },
    {
      "lang": "en",
      "text": "second R1 like all of deep seeks models",
      "offset": 830.36,
      "duration": 5.399
    },
    {
      "lang": "en",
      "text": "has open weights the problem with saying",
      "offset": 833.6,
      "duration": 3.64
    },
    {
      "lang": "en",
      "text": "open source is that we don't have the",
      "offset": 835.759,
      "duration": 3.64
    },
    {
      "lang": "en",
      "text": "data that went into creating it this",
      "offset": 837.24,
      "duration": 4.039
    },
    {
      "lang": "en",
      "text": "means that instead of paying open AI to",
      "offset": 839.399,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "get reasoning you can run R1 on the",
      "offset": 841.279,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "server of your choice or even locally at",
      "offset": 843.399,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "dramatically lower",
      "offset": 845.839,
      "duration": 5.841
    },
    {
      "lang": "en",
      "text": "cost how did deep seek make",
      "offset": 847.56,
      "duration": 4.12
    },
    {
      "lang": "en",
      "text": "R1 deep seek actually made two models R1",
      "offset": 851.959,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "and",
      "offset": 855.68,
      "duration": 3.56
    },
    {
      "lang": "en",
      "text": "r10 I actually think that r10 is the",
      "offset": 856.36,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "bigger deal as I noted above it was my",
      "offset": 859.24,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "biggest focused in last Tuesday's update",
      "offset": 861.8,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "quote r10 though is the bigger deal in",
      "offset": 864.36,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "my mind from the paper",
      "offset": 867.32,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "in this paper we take the first step",
      "offset": 869.56,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "toward improving language model",
      "offset": 871.88,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "reasoning capabilities using pure",
      "offset": 873.32,
      "duration": 5.8
    },
    {
      "lang": "en",
      "text": "reinforcement learning RL our goal is to",
      "offset": 875.56,
      "duration": 5.8
    },
    {
      "lang": "en",
      "text": "explore the potential of llms to develop",
      "offset": 879.12,
      "duration": 4.519
    },
    {
      "lang": "en",
      "text": "reasoning capabilities without any",
      "offset": 881.36,
      "duration": 4.68
    },
    {
      "lang": "en",
      "text": "supervised data focusing on their",
      "offset": 883.639,
      "duration": 6.281
    },
    {
      "lang": "en",
      "text": "self-evolution through a pure RL process",
      "offset": 886.04,
      "duration": 6.88
    },
    {
      "lang": "en",
      "text": "specifically we use deep seek V3 Bas as",
      "offset": 889.92,
      "duration": 6.76
    },
    {
      "lang": "en",
      "text": "the base model and employ grpo as the RL",
      "offset": 892.92,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "framework to improve model performance",
      "offset": 896.68,
      "duration": 5.079
    },
    {
      "lang": "en",
      "text": "in res reasoning during training deep",
      "offset": 898.6,
      "duration": 6.28
    },
    {
      "lang": "en",
      "text": "seek r10 naturally emerged with numerous",
      "offset": 901.759,
      "duration": 5.08
    },
    {
      "lang": "en",
      "text": "powerful and interesting reasoning",
      "offset": 904.88,
      "duration": 5.199
    },
    {
      "lang": "en",
      "text": "behaviors after thousands of RL steps",
      "offset": 906.839,
      "duration": 6.641
    },
    {
      "lang": "en",
      "text": "deep seek r10 exhibits super performance",
      "offset": 910.079,
      "duration": 6.32
    },
    {
      "lang": "en",
      "text": "on reasoning benchmarks for instance the",
      "offset": 913.48,
      "duration": 7
    },
    {
      "lang": "en",
      "text": "pass at one score on AIM 2024 increases",
      "offset": 916.399,
      "duration": 8.041
    },
    {
      "lang": "en",
      "text": "from 15.6% to 71% and with majority",
      "offset": 920.48,
      "duration": 6.96
    },
    {
      "lang": "en",
      "text": "voting the score further improves to",
      "offset": 924.44,
      "duration": 7.92
    },
    {
      "lang": "en",
      "text": "86.7% matching the performance of openi",
      "offset": 927.44,
      "duration": 4.92
    },
    {
      "lang": "en",
      "text": "0192 reinforcement learning is a",
      "offset": 932.56,
      "duration": 3.959
    },
    {
      "lang": "en",
      "text": "technique where a machine learning model",
      "offset": 934.959,
      "duration": 3.481
    },
    {
      "lang": "en",
      "text": "is given a bunch of data and a reward",
      "offset": 936.519,
      "duration": 5.041
    },
    {
      "lang": "en",
      "text": "function the classic example is Alpha go",
      "offset": 938.44,
      "duration": 4.639
    },
    {
      "lang": "en",
      "text": "where Deep Mind gave the model the rules",
      "offset": 941.56,
      "duration": 3
    },
    {
      "lang": "en",
      "text": "of Go with the reward function of",
      "offset": 943.079,
      "duration": 3.56
    },
    {
      "lang": "en",
      "text": "winning the game and then let the model",
      "offset": 944.56,
      "duration": 4.44
    },
    {
      "lang": "en",
      "text": "figure everything else out on its own",
      "offset": 946.639,
      "duration": 4.2
    },
    {
      "lang": "en",
      "text": "this famously ended up working better",
      "offset": 949,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "than other more human-guided",
      "offset": 950.839,
      "duration": 4.641
    },
    {
      "lang": "en",
      "text": "techniques llms to date however have",
      "offset": 952.68,
      "duration": 4.279
    },
    {
      "lang": "en",
      "text": "relied on reinforcement learning with",
      "offset": 955.48,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "human feedback humans are in the loop to",
      "offset": 956.959,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "help guide the model navigate difficult",
      "offset": 959.24,
      "duration": 4.76
    },
    {
      "lang": "en",
      "text": "choices where rewards aren't obvious Etc",
      "offset": 961.199,
      "duration": 4.681
    },
    {
      "lang": "en",
      "text": "rhf was the key innovation in",
      "offset": 964,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "transforming gpt3 into chat GPT with",
      "offset": 965.88,
      "duration": 5.319
    },
    {
      "lang": "en",
      "text": "well-formed paragraphs answers that were",
      "offset": 969.12,
      "duration": 3.279
    },
    {
      "lang": "en",
      "text": "concise and didn't troll off into",
      "offset": 971.199,
      "duration": 5.32
    },
    {
      "lang": "en",
      "text": "gibberish Etc r10 however drops the HF",
      "offset": 972.399,
      "duration": 6.56
    },
    {
      "lang": "en",
      "text": "part it's just reinforcement learning",
      "offset": 976.519,
      "duration": 4.601
    },
    {
      "lang": "en",
      "text": "deep seek gave the model a set of math",
      "offset": 978.959,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "code and logic questions and set two",
      "offset": 981.12,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "reward functions one for the right",
      "offset": 983.279,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "answer and one for the right format that",
      "offset": 985.519,
      "duration": 4.68
    },
    {
      "lang": "en",
      "text": "utilized a thinking process moreover the",
      "offset": 987.36,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "technique was a simple one instead of",
      "offset": 990.199,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "trying to evaluate stepbystep process",
      "offset": 992.24,
      "duration": 4.76
    },
    {
      "lang": "en",
      "text": "supervision or doing a search of all",
      "offset": 994.839,
      "duration": 4.881
    },
    {
      "lang": "en",
      "text": "possible answers allaha Alpha go deep",
      "offset": 997,
      "duration": 4.6
    },
    {
      "lang": "en",
      "text": "seek encouraged the model to try several",
      "offset": 999.72,
      "duration": 3.4
    },
    {
      "lang": "en",
      "text": "different answers at a time and then",
      "offset": 1001.6,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "graded them according to the two reward",
      "offset": 1003.12,
      "duration": 4.36
    },
    {
      "lang": "en",
      "text": "functions what emerged is a model that",
      "offset": 1005.12,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "developed reasoning and chains of",
      "offset": 1007.48,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "thought on its own including what deep",
      "offset": 1008.959,
      "duration": 5.281
    },
    {
      "lang": "en",
      "text": "seat called aha",
      "offset": 1011,
      "duration": 3.24
    },
    {
      "lang": "en",
      "text": "moments a particularly intriguing",
      "offset": 1014.36,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "phenomenon observed during the training",
      "offset": 1016.839,
      "duration": 5.281
    },
    {
      "lang": "en",
      "text": "of deep seek r10 is the occurrence of an",
      "offset": 1018.6,
      "duration": 7.199
    },
    {
      "lang": "en",
      "text": "quote aha moment end quote this moment",
      "offset": 1022.12,
      "duration": 6.36
    },
    {
      "lang": "en",
      "text": "as Illustrated in table 3 occurs in an",
      "offset": 1025.799,
      "duration": 5.561
    },
    {
      "lang": "en",
      "text": "intermediate version of the model during",
      "offset": 1028.48,
      "duration": 5.719
    },
    {
      "lang": "en",
      "text": "this phase deep seek r10 learns to",
      "offset": 1031.36,
      "duration": 5
    },
    {
      "lang": "en",
      "text": "allocate more thinking time to a problem",
      "offset": 1034.199,
      "duration": 5.041
    },
    {
      "lang": "en",
      "text": "by re-evaluating its initial approach",
      "offset": 1036.36,
      "duration": 4.719
    },
    {
      "lang": "en",
      "text": "the behavior is not only a testament to",
      "offset": 1039.24,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "the model's growing reasoning",
      "offset": 1041.079,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "capabilities but also a captivating",
      "offset": 1042.36,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "example of how reinforcement learning",
      "offset": 1044.76,
      "duration": 3.88
    },
    {
      "lang": "en",
      "text": "can lead to unexpected and sophisticated",
      "offset": 1046.439,
      "duration": 5.24
    },
    {
      "lang": "en",
      "text": "out outcomes the moment is not only an",
      "offset": 1048.64,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "aha moment for the model but also for",
      "offset": 1051.679,
      "duration": 5.201
    },
    {
      "lang": "en",
      "text": "the researchers observing Its Behavior",
      "offset": 1054.16,
      "duration": 4.44
    },
    {
      "lang": "en",
      "text": "it underscores the power and beauty of",
      "offset": 1056.88,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "reinforcement learning rather than",
      "offset": 1058.6,
      "duration": 4.36
    },
    {
      "lang": "en",
      "text": "explicitly teaching the model on how to",
      "offset": 1060.96,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "solve a problem we simply provide it",
      "offset": 1062.96,
      "duration": 4.36
    },
    {
      "lang": "en",
      "text": "with the right incentives and it",
      "offset": 1065.28,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "autonomously develops Advanced problem",
      "offset": 1067.32,
      "duration": 5.359
    },
    {
      "lang": "en",
      "text": "solving strategies the aha moment serves",
      "offset": 1069.44,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "as a powerful reminder of the potential",
      "offset": 1072.679,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "of RL to unlock new levels of",
      "offset": 1074.4,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "intelligence in artificial intelligence",
      "offset": 1076.52,
      "duration": 4.6
    },
    {
      "lang": "en",
      "text": "Paving the way for more autonomous and",
      "offset": 1079.12,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "adaptive models in the future this is",
      "offset": 1081.12,
      "duration": 4.679
    },
    {
      "lang": "en",
      "text": "one of the most powerful affirmations",
      "offset": 1084,
      "duration": 3.88
    },
    {
      "lang": "en",
      "text": "yet of the bitter lesson you don't need",
      "offset": 1085.799,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "to teach the a how to reason you can",
      "offset": 1087.88,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "just give it enough compute and data and",
      "offset": 1089.96,
      "duration": 5.599
    },
    {
      "lang": "en",
      "text": "it will teach itself well almost r10",
      "offset": 1091.96,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "reasons but in a way that humans have",
      "offset": 1095.559,
      "duration": 5.081
    },
    {
      "lang": "en",
      "text": "trouble understanding back to the",
      "offset": 1097.32,
      "duration": 6.52
    },
    {
      "lang": "en",
      "text": "introduction however deep seek r10",
      "offset": 1100.64,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "encounters challenges such as poor",
      "offset": 1103.84,
      "duration": 4.68
    },
    {
      "lang": "en",
      "text": "readability and language mixing to",
      "offset": 1105.52,
      "duration": 4.639
    },
    {
      "lang": "en",
      "text": "address address these issues and further",
      "offset": 1108.52,
      "duration": 3.8
    },
    {
      "lang": "en",
      "text": "enhance reasoning performance we",
      "offset": 1110.159,
      "duration": 4.441
    },
    {
      "lang": "en",
      "text": "introduce deep seek R1 which",
      "offset": 1112.32,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "incorporates a small amount of cold",
      "offset": 1114.6,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "start data in a multi-stage training",
      "offset": 1116.48,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "pipeline specifically We Begin by",
      "offset": 1119,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "collecting thousands of cold data to",
      "offset": 1121.76,
      "duration": 5.24
    },
    {
      "lang": "en",
      "text": "fine-tune the Deep seek V3 base model",
      "offset": 1124.12,
      "duration": 5.24
    },
    {
      "lang": "en",
      "text": "following this we perform reasoning",
      "offset": 1127,
      "duration": 4.679
    },
    {
      "lang": "en",
      "text": "oriented RL like deep seek",
      "offset": 1129.36,
      "duration": 5.72
    },
    {
      "lang": "en",
      "text": "r10 upon nearing convergence in the RL",
      "offset": 1131.679,
      "duration": 6.561
    },
    {
      "lang": "en",
      "text": "process we create new sft data through",
      "offset": 1135.08,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "rejection sampling on the RL checkpoint",
      "offset": 1138.24,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "combined with supervised data from Deep",
      "offset": 1141.08,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "seek V3 in domains such as writing",
      "offset": 1142.96,
      "duration": 4.44
    },
    {
      "lang": "en",
      "text": "factual QA and",
      "offset": 1145.48,
      "duration": 4.199
    },
    {
      "lang": "en",
      "text": "self-cognition and then retrain the Deep",
      "offset": 1147.4,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "seek V3 base model after fine-tuning",
      "offset": 1149.679,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "with the new data the checkpoint under",
      "offset": 1152.84,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "goes an additional RL process taking",
      "offset": 1155.039,
      "duration": 5
    },
    {
      "lang": "en",
      "text": "into account prompts from all",
      "offset": 1157.88,
      "duration": 4.919
    },
    {
      "lang": "en",
      "text": "scenarios after these steps we obtained",
      "offset": 1160.039,
      "duration": 5.561
    },
    {
      "lang": "en",
      "text": "a checkpoint referred to as deep seek R1",
      "offset": 1162.799,
      "duration": 4.441
    },
    {
      "lang": "en",
      "text": "which achieves performance on par with",
      "offset": 1165.6,
      "duration": 5.48
    },
    {
      "lang": "en",
      "text": "open aai 012 17 this sounds a lot like",
      "offset": 1167.24,
      "duration": 6.48
    },
    {
      "lang": "en",
      "text": "what open AI did for 01 deep seek",
      "offset": 1171.08,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "started the model out with a bunch of",
      "offset": 1173.72,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "examples of Chain of Thought thinking so",
      "offset": 1175.24,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "it could learn the proper format for",
      "offset": 1177.08,
      "duration": 3.32
    },
    {
      "lang": "en",
      "text": "human consumption and then did the",
      "offset": 1178.52,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "reinforcement learning to enhance its",
      "offset": 1180.4,
      "duration": 3.759
    },
    {
      "lang": "en",
      "text": "reasoning along with a number of editing",
      "offset": 1181.96,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "and refinement steps the output is a",
      "offset": 1184.159,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "model that appears to be very",
      "offset": 1186.44,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "competitive with 01 end quote here again",
      "offset": 1187.679,
      "duration": 5
    },
    {
      "lang": "en",
      "text": "it seems plausible that deep seek",
      "offset": 1191.08,
      "duration": 3.64
    },
    {
      "lang": "en",
      "text": "benefited from distillation particularly",
      "offset": 1192.679,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "in terms of training R1 that though is",
      "offset": 1194.72,
      "duration": 4.6
    },
    {
      "lang": "en",
      "text": "itself an important take",
      "offset": 1197.559,
      "duration": 3.641
    },
    {
      "lang": "en",
      "text": "we have a situation where AI models are",
      "offset": 1199.32,
      "duration": 4.12
    },
    {
      "lang": "en",
      "text": "teaching AI models and where AI models",
      "offset": 1201.2,
      "duration": 4.28
    },
    {
      "lang": "en",
      "text": "are teaching themselves we are watching",
      "offset": 1203.44,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "the Assembly of an AI takeoff scenario",
      "offset": 1205.48,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "in real",
      "offset": 1207.52,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "time so are we close to",
      "offset": 1209,
      "duration": 6.52
    },
    {
      "lang": "en",
      "text": "AGI it definitely seems like it this",
      "offset": 1212.72,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "also explains why SoftBank and whatever",
      "offset": 1215.52,
      "duration": 4.519
    },
    {
      "lang": "en",
      "text": "investors masu Yoshi son brings together",
      "offset": 1217.6,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "would provide the funding for open AI",
      "offset": 1220.039,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "that Microsoft will not the belief that",
      "offset": 1221.679,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "we are reaching a takeoff point where",
      "offset": 1223.88,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "there will in fact be real returns",
      "offset": 1225.52,
      "duration": 4.84
    },
    {
      "lang": "en",
      "text": "towards being first but isn't R1 now in",
      "offset": 1227.32,
      "duration": 3.8
    },
    {
      "lang": "en",
      "text": "the",
      "offset": 1230.36,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "lead I don't think so this has been",
      "offset": 1231.12,
      "duration": 5.24
    },
    {
      "lang": "en",
      "text": "overstated R1 is competitive with o1",
      "offset": 1233.72,
      "duration": 4.36
    },
    {
      "lang": "en",
      "text": "although there do seem to be some holes",
      "offset": 1236.36,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "in its capability that point towards",
      "offset": 1238.08,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "some amount of distillation from 01 Pro",
      "offset": 1240.12,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "open AI meanwhile has demonstrated 03 a",
      "offset": 1242.64,
      "duration": 5.399
    },
    {
      "lang": "en",
      "text": "far more powerful reasoning model deep",
      "offset": 1245.64,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "seek is absolutely the leader in",
      "offset": 1248.039,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "efficiency but that is different than",
      "offset": 1249.48,
      "duration": 3.88
    },
    {
      "lang": "en",
      "text": "being the leader",
      "offset": 1251.159,
      "duration": 5.201
    },
    {
      "lang": "en",
      "text": "overall so why is everyone freaking",
      "offset": 1253.36,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "out I think there are multiple factors",
      "offset": 1256.36,
      "duration": 4.679
    },
    {
      "lang": "en",
      "text": "first there is the shock that China has",
      "offset": 1259.36,
      "duration": 3.88
    },
    {
      "lang": "en",
      "text": "caught up to the leading us Labs despite",
      "offset": 1261.039,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "the widespread assumption that China",
      "offset": 1263.24,
      "duration": 4.2
    },
    {
      "lang": "en",
      "text": "isn't as good at software as the US this",
      "offset": 1264.72,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "is probably the biggest thing I missed",
      "offset": 1267.44,
      "duration": 3.64
    },
    {
      "lang": "en",
      "text": "in my surprise over the reaction the",
      "offset": 1269.039,
      "duration": 3.721
    },
    {
      "lang": "en",
      "text": "reality is that China has an extremely",
      "offset": 1271.08,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "proficient software industry generally",
      "offset": 1272.76,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "and a very good track record in AI model",
      "offset": 1274.76,
      "duration": 4.36
    },
    {
      "lang": "en",
      "text": "building specifically second is the low",
      "offset": 1276.679,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "training cost for V3 and deep seeks low",
      "offset": 1279.12,
      "duration": 3.96
    },
    {
      "lang": "en",
      "text": "inference costs this part was a big",
      "offset": 1281,
      "duration": 4.12
    },
    {
      "lang": "en",
      "text": "surprise for me as well to be sure but",
      "offset": 1283.08,
      "duration": 4.28
    },
    {
      "lang": "en",
      "text": "the numbers are plausible this by",
      "offset": 1285.12,
      "duration": 4.36
    },
    {
      "lang": "en",
      "text": "extension probably has everyone nervous",
      "offset": 1287.36,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "about Nvidia which obviously has a big",
      "offset": 1289.48,
      "duration": 4.559
    },
    {
      "lang": "en",
      "text": "impact on the market third is the fact",
      "offset": 1291.6,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "that deep seek pulled this off despite",
      "offset": 1294.039,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "the chip band again though while there",
      "offset": 1295.6,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "are big loopholes in the chip van it",
      "offset": 1297.88,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "seems likely to me that deep seek",
      "offset": 1300.08,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "accomplished this with legal",
      "offset": 1301.799,
      "duration": 5.201
    },
    {
      "lang": "en",
      "text": "chips I own Nvidia am I",
      "offset": 1303.6,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "screwed there are real challenges this",
      "offset": 1307,
      "duration": 4.559
    },
    {
      "lang": "en",
      "text": "news presents to the Nvidia story Nvidia",
      "offset": 1309.12,
      "duration": 4.679
    },
    {
      "lang": "en",
      "text": "has two big Moes Cuda is the language of",
      "offset": 1311.559,
      "duration": 3.641
    },
    {
      "lang": "en",
      "text": "choice for anyone programming these",
      "offset": 1313.799,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "models and Cuda only works on Nvidia",
      "offset": 1315.2,
      "duration": 4.28
    },
    {
      "lang": "en",
      "text": "chips and Nvidia has a massive lead in",
      "offset": 1317.159,
      "duration": 3.961
    },
    {
      "lang": "en",
      "text": "terms of its ability to combine multiple",
      "offset": 1319.48,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "chips together into one large virtual",
      "offset": 1321.12,
      "duration": 5.559
    },
    {
      "lang": "en",
      "text": "GPU these two mes work together I noted",
      "offset": 1323.32,
      "duration": 5
    },
    {
      "lang": "en",
      "text": "above that if deep seek had access to",
      "offset": 1326.679,
      "duration": 3.561
    },
    {
      "lang": "en",
      "text": "h100s they probably would have used a",
      "offset": 1328.32,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "larger cluster to train their model",
      "offset": 1330.24,
      "duration": 3.24
    },
    {
      "lang": "en",
      "text": "simply because that would have been the",
      "offset": 1332.159,
      "duration": 3.801
    },
    {
      "lang": "en",
      "text": "easier option the fact they didn't and",
      "offset": 1333.48,
      "duration": 4.679
    },
    {
      "lang": "en",
      "text": "were bandwidth constraint drove a lot of",
      "offset": 1335.96,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "their decisions in terms of both model",
      "offset": 1338.159,
      "duration": 3.4
    },
    {
      "lang": "en",
      "text": "architecture and their training",
      "offset": 1339.88,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "infrastructure just look at the US labs",
      "offset": 1341.559,
      "duration": 3.801
    },
    {
      "lang": "en",
      "text": "they haven't spent much time on",
      "offset": 1344.12,
      "duration": 2.919
    },
    {
      "lang": "en",
      "text": "optimization because Nvidia has been",
      "offset": 1345.36,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "aggressively shipping ever more capable",
      "offset": 1347.039,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "systems that accommodate their needs the",
      "offset": 1348.88,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "route of least resistance has simply",
      "offset": 1351.12,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "been to pay Nvidia deep seek however",
      "offset": 1352.799,
      "duration": 4.721
    },
    {
      "lang": "en",
      "text": "just demonstrated that another route is",
      "offset": 1355.76,
      "duration": 4.279
    },
    {
      "lang": "en",
      "text": "available heavy optimization can produce",
      "offset": 1357.52,
      "duration": 4.44
    },
    {
      "lang": "en",
      "text": "remarkable results on weaker hardware",
      "offset": 1360.039,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "and with lower memory bandwidth simply",
      "offset": 1361.96,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "paying Nvidia more isn't the only way to",
      "offset": 1364.279,
      "duration": 4.921
    },
    {
      "lang": "en",
      "text": "make better models that noted there are",
      "offset": 1366.279,
      "duration": 5.201
    },
    {
      "lang": "en",
      "text": "three factors still in nvidia's favor",
      "offset": 1369.2,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "first how capable might deep seeks",
      "offset": 1371.48,
      "duration": 4.36
    },
    {
      "lang": "en",
      "text": "approach be if applied to h100s or",
      "offset": 1373.6,
      "duration": 5
    },
    {
      "lang": "en",
      "text": "upcoming GB 100s just because they found",
      "offset": 1375.84,
      "duration": 4.52
    },
    {
      "lang": "en",
      "text": "a more efficient way to use compute",
      "offset": 1378.6,
      "duration": 3.24
    },
    {
      "lang": "en",
      "text": "doesn't mean that more compute wouldn't",
      "offset": 1380.36,
      "duration": 4.559
    },
    {
      "lang": "en",
      "text": "be useful second lower inference cost",
      "offset": 1381.84,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "should in the long run Drive greater",
      "offset": 1384.919,
      "duration": 5.481
    },
    {
      "lang": "en",
      "text": "usage Microsoft C sadella in a late",
      "offset": 1387.2,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "night tweet almost assuredly directed at",
      "offset": 1390.4,
      "duration": 5
    },
    {
      "lang": "en",
      "text": "the market said exactly that javon's",
      "offset": 1392.24,
      "duration": 6.2
    },
    {
      "lang": "en",
      "text": "Paradox strikes again as AI gets more",
      "offset": 1395.4,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "efficient and accessible we will see its",
      "offset": 1398.44,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "use Skyrocket turning it into a",
      "offset": 1400.52,
      "duration": 4.92
    },
    {
      "lang": "en",
      "text": "commodity we just can't get enough",
      "offset": 1402.6,
      "duration": 6.48
    },
    {
      "lang": "en",
      "text": "of third reasoning models like R1 and 01",
      "offset": 1405.44,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "derive their Superior performance from",
      "offset": 1409.08,
      "duration": 4.04
    },
    {
      "lang": "en",
      "text": "using more compute to the extent that",
      "offset": 1410.64,
      "duration": 4.2
    },
    {
      "lang": "en",
      "text": "increasing the power and capabilities of",
      "offset": 1413.12,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "AI depend on more compute is the extent",
      "offset": 1414.84,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "that Nvidia stands to benefit still it's",
      "offset": 1417.039,
      "duration": 5.361
    },
    {
      "lang": "en",
      "text": "not all Rosy at a minimum deep seeks",
      "offset": 1419.88,
      "duration": 4.52
    },
    {
      "lang": "en",
      "text": "efficiency and Broad availability cast",
      "offset": 1422.4,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "significant doubts on the most",
      "offset": 1424.4,
      "duration": 3.56
    },
    {
      "lang": "en",
      "text": "optimistic Nvidia growth story at least",
      "offset": 1426,
      "duration": 4.2
    },
    {
      "lang": "en",
      "text": "in the near- term the payoffs from both",
      "offset": 1427.96,
      "duration": 4.199
    },
    {
      "lang": "en",
      "text": "model and infrastructure optimization",
      "offset": 1430.2,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "also suggest there are significant gains",
      "offset": 1432.159,
      "duration": 4.041
    },
    {
      "lang": "en",
      "text": "to be had from exploring alternative",
      "offset": 1434.36,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "approaches to inference in particular",
      "offset": 1436.2,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "for example it might be much more",
      "offset": 1438.6,
      "duration": 3.079
    },
    {
      "lang": "en",
      "text": "plausible to run inference on a",
      "offset": 1440.44,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "standalone AMD GPU completely sidest",
      "offset": 1441.679,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "stepping amd's inferior chipto chip",
      "offset": 1444.2,
      "duration": 4.04
    },
    {
      "lang": "en",
      "text": "Communications capability reasoning",
      "offset": 1446.08,
      "duration": 3.8
    },
    {
      "lang": "en",
      "text": "models also increase the payoff for",
      "offset": 1448.24,
      "duration": 3.319
    },
    {
      "lang": "en",
      "text": "inference only chips that are even more",
      "offset": 1449.88,
      "duration": 4.76
    },
    {
      "lang": "en",
      "text": "specialized than nvidia's gpus in short",
      "offset": 1451.559,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "Nvidia isn't going anywhere the Nvidia",
      "offset": 1454.64,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "stock however is suddenly facing a lot",
      "offset": 1456.919,
      "duration": 3.481
    },
    {
      "lang": "en",
      "text": "more uncertainty that hasn't been priced",
      "offset": 1458.72,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "in and that by extension is going to",
      "offset": 1460.4,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "drag everyone",
      "offset": 1462.799,
      "duration": 5.281
    },
    {
      "lang": "en",
      "text": "down so what about the chip band the",
      "offset": 1464.48,
      "duration": 5.319
    },
    {
      "lang": "en",
      "text": "easy argument to make is that the",
      "offset": 1468.08,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "importance of the chip band has only",
      "offset": 1469.799,
      "duration": 3.561
    },
    {
      "lang": "en",
      "text": "been accentuated given the US's rapidly",
      "offset": 1471.12,
      "duration": 4.679
    },
    {
      "lang": "en",
      "text": "evaporating lead in software software",
      "offset": 1473.36,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "and know how can't be embargoed we've",
      "offset": 1475.799,
      "duration": 3.48
    },
    {
      "lang": "en",
      "text": "had these debates and realizations",
      "offset": 1477.76,
      "duration": 3.639
    },
    {
      "lang": "en",
      "text": "before but chips are physical objects",
      "offset": 1479.279,
      "duration": 3.88
    },
    {
      "lang": "en",
      "text": "and the US is Justified in keeping them",
      "offset": 1481.399,
      "duration": 4.52
    },
    {
      "lang": "en",
      "text": "away from China at the same time there",
      "offset": 1483.159,
      "duration": 4.361
    },
    {
      "lang": "en",
      "text": "should be some humility about the fact",
      "offset": 1485.919,
      "duration": 3.281
    },
    {
      "lang": "en",
      "text": "that earlier iterations of the chip band",
      "offset": 1487.52,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "seem to have directly led to deep seeks",
      "offset": 1489.2,
      "duration": 4.479
    },
    {
      "lang": "en",
      "text": "Innovations those Innovations moreover",
      "offset": 1491.12,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "would extend to not just smuggled Nvidia",
      "offset": 1493.679,
      "duration": 4.801
    },
    {
      "lang": "en",
      "text": "chips or nerfed ones like the h800 but",
      "offset": 1496,
      "duration": 5.24
    },
    {
      "lang": "en",
      "text": "hallways Ascend chips as well indeed you",
      "offset": 1498.48,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "can very much make the case that the",
      "offset": 1501.24,
      "duration": 3.24
    },
    {
      "lang": "en",
      "text": "primary outcome of the chip ban is",
      "offset": 1502.96,
      "duration": 4.28
    },
    {
      "lang": "en",
      "text": "today's crash in nvidia's stock price",
      "offset": 1504.48,
      "duration": 4.559
    },
    {
      "lang": "en",
      "text": "what concerns me is the mindset under",
      "offset": 1507.24,
      "duration": 3.72
    },
    {
      "lang": "en",
      "text": "ging something like the chip band",
      "offset": 1509.039,
      "duration": 3.401
    },
    {
      "lang": "en",
      "text": "instead of competing through innovation",
      "offset": 1510.96,
      "duration": 3.4
    },
    {
      "lang": "en",
      "text": "in the future the US is competing",
      "offset": 1512.44,
      "duration": 4.119
    },
    {
      "lang": "en",
      "text": "through the denial of innovation in the",
      "offset": 1514.36,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "past yes this may help in the short term",
      "offset": 1516.559,
      "duration": 4.921
    },
    {
      "lang": "en",
      "text": "again deep seek would be even more",
      "offset": 1519.48,
      "duration": 4.36
    },
    {
      "lang": "en",
      "text": "effective with more Computing but in the",
      "offset": 1521.48,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "long run it simply sews the seeds for",
      "offset": 1523.84,
      "duration": 4.12
    },
    {
      "lang": "en",
      "text": "competition in an industry chips and",
      "offset": 1525.88,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "semic conductor equipment over which the",
      "offset": 1527.96,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "US has a dominant",
      "offset": 1530.039,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "position like AI",
      "offset": 1531.799,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "models AI models are a great example I",
      "offset": 1534.44,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "mentioned above that I would get to open",
      "offset": 1537.399,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "ai's greatest crime which I consider to",
      "offset": 1539.08,
      "duration": 5.4
    },
    {
      "lang": "en",
      "text": "be the 2023 Biden executive order on AI",
      "offset": 1541.32,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "I wrote in attenuating Innovation quote",
      "offset": 1544.48,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "the point is is this if",
      "offset": 1547,
      "duration": 7.039
    },
    {
      "lang": "en",
      "text": "you INB then it that the early AI winers",
      "offset": 1549.6,
      "duration": 6.48
    },
    {
      "lang": "en",
      "text": "the most invested in generating alarm in",
      "offset": 1554.039,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "Washington DC about about a despite the",
      "offset": 1556.08,
      "duration": 4.199
    },
    {
      "lang": "en",
      "text": "fact that their concern is apparently",
      "offset": 1558.919,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "not high to if you accept the premise",
      "offset": 1560.279,
      "duration": 4.201
    },
    {
      "lang": "en",
      "text": "that regulation locks an Inc no they are",
      "offset": 1562.679,
      "duration": 3.88
    },
    {
      "lang": "en",
      "text": "the responsible ones the ones who care",
      "offset": 1564.48,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "enough to call for regulation all the",
      "offset": 1566.559,
      "duration": 3.881
    },
    {
      "lang": "en",
      "text": "better if concerns about imagined harms",
      "offset": 1568.64,
      "duration": 5.399
    },
    {
      "lang": "en",
      "text": "kneecap inevitable competitors end quote",
      "offset": 1570.44,
      "duration": 5.08
    },
    {
      "lang": "en",
      "text": "that paragraph was about open AI",
      "offset": 1574.039,
      "duration": 2.76
    },
    {
      "lang": "en",
      "text": "specifically and the broader San",
      "offset": 1575.52,
      "duration": 3.56
    },
    {
      "lang": "en",
      "text": "Francisco AI Community generally for",
      "offset": 1576.799,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "years now we have been subject to hand",
      "offset": 1579.08,
      "duration": 3.319
    },
    {
      "lang": "en",
      "text": "ringing about the dangers of AI by the",
      "offset": 1580.559,
      "duration": 3.441
    },
    {
      "lang": "en",
      "text": "exact same people committed to building",
      "offset": 1582.399,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "it and controlling it these alleged",
      "offset": 1584,
      "duration": 5
    },
    {
      "lang": "en",
      "text": "dangers were the impetus for ey becoming",
      "offset": 1586.799,
      "duration": 5.48
    },
    {
      "lang": "en",
      "text": "closed back in 2019 with the release of",
      "offset": 1589,
      "duration": 5.559
    },
    {
      "lang": "en",
      "text": "gpt2 due to concerns about large",
      "offset": 1592.279,
      "duration": 4.28
    },
    {
      "lang": "en",
      "text": "language models being used to generate",
      "offset": 1594.559,
      "duration": 4.6
    },
    {
      "lang": "en",
      "text": "deceptive biased or abusive language at",
      "offset": 1596.559,
      "duration": 4.961
    },
    {
      "lang": "en",
      "text": "scale we are only releasing a much",
      "offset": 1599.159,
      "duration": 4.601
    },
    {
      "lang": "en",
      "text": "smaller version of gpt2 along with",
      "offset": 1601.52,
      "duration": 5
    },
    {
      "lang": "en",
      "text": "sampling code we are not releasing the",
      "offset": 1603.76,
      "duration": 5.72
    },
    {
      "lang": "en",
      "text": "data set training code or gpt2 model",
      "offset": 1606.52,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "weights we are aware that some",
      "offset": 1609.48,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "researchers have the technical capacity",
      "offset": 1611.64,
      "duration": 5.08
    },
    {
      "lang": "en",
      "text": "to reproduce and open source our results",
      "offset": 1613.64,
      "duration": 5.08
    },
    {
      "lang": "en",
      "text": "we believe our release strategy limits",
      "offset": 1616.72,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "the initial set of organizations who may",
      "offset": 1618.72,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "choose to do this and gives the AI",
      "offset": 1620.64,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "Community more time to have a discussion",
      "offset": 1622.72,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "about the implications of such systems",
      "offset": 1624.64,
      "duration": 4.2
    },
    {
      "lang": "en",
      "text": "we also think governments should",
      "offset": 1627.52,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "consider expanding or commencing",
      "offset": 1628.84,
      "duration": 3.719
    },
    {
      "lang": "en",
      "text": "initiatives to more systematically",
      "offset": 1630.72,
      "duration": 4.04
    },
    {
      "lang": "en",
      "text": "monitor the societal impact and",
      "offset": 1632.559,
      "duration": 4.561
    },
    {
      "lang": "en",
      "text": "diffusion of AI Technologies and to",
      "offset": 1634.76,
      "duration": 3.639
    },
    {
      "lang": "en",
      "text": "measure the progression in the",
      "offset": 1637.12,
      "duration": 4.84
    },
    {
      "lang": "en",
      "text": "capabilities of such systems if pursued",
      "offset": 1638.399,
      "duration": 5.121
    },
    {
      "lang": "en",
      "text": "these efforts could yield a better",
      "offset": 1641.96,
      "duration": 3.88
    },
    {
      "lang": "en",
      "text": "evidence-base for Decisions by AI labs",
      "offset": 1643.52,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "and governments regarding publication",
      "offset": 1645.84,
      "duration": 5
    },
    {
      "lang": "en",
      "text": "DEC decisions and AI policy more",
      "offset": 1647.919,
      "duration": 5.201
    },
    {
      "lang": "en",
      "text": "broadly the arrogance in this statement",
      "offset": 1650.84,
      "duration": 4.68
    },
    {
      "lang": "en",
      "text": "is only surpassed by the futility here",
      "offset": 1653.12,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "we are 6 years later and the entire",
      "offset": 1655.52,
      "duration": 3.279
    },
    {
      "lang": "en",
      "text": "world has access to the weights of a",
      "offset": 1657.279,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "dramatically Superior model open AI",
      "offset": 1658.799,
      "duration": 4.801
    },
    {
      "lang": "en",
      "text": "Gambit for control enforced by the US",
      "offset": 1661.36,
      "duration": 4.84
    },
    {
      "lang": "en",
      "text": "government has utterly failed in the",
      "offset": 1663.6,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "meantime how much innovation has been",
      "offset": 1666.2,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "foregone by virtue of Leading Edge",
      "offset": 1668,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "models not having open weights more",
      "offset": 1669.64,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "generally how much time and energy has",
      "offset": 1671.919,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "been spent lobbying for a government",
      "offset": 1674.12,
      "duration": 3.399
    },
    {
      "lang": "en",
      "text": "enforced moat that deep seek just",
      "offset": 1675.6,
      "duration": 3.64
    },
    {
      "lang": "en",
      "text": "obliterated that would have been better",
      "offset": 1677.519,
      "duration": 3.201
    },
    {
      "lang": "en",
      "text": "devoted to actual",
      "offset": 1679.24,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "Innovation so you're not worried about",
      "offset": 1680.72,
      "duration": 3.559
    },
    {
      "lang": "en",
      "text": "AI Doom",
      "offset": 1682.84,
      "duration": 3.679
    },
    {
      "lang": "en",
      "text": "scenarios I definitely understand the",
      "offset": 1684.279,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "concern and just noted above that we are",
      "offset": 1686.519,
      "duration": 3.361
    },
    {
      "lang": "en",
      "text": "reaching the stage where AIS are",
      "offset": 1688.44,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "training AIS and learning reasoning on",
      "offset": 1689.88,
      "duration": 4.44
    },
    {
      "lang": "en",
      "text": "their own I recognize though that there",
      "offset": 1691.88,
      "duration": 5.279
    },
    {
      "lang": "en",
      "text": "is no stopping this train more than that",
      "offset": 1694.32,
      "duration": 4.719
    },
    {
      "lang": "en",
      "text": "this is exactly why openness is so",
      "offset": 1697.159,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "important we need more AIS in the world",
      "offset": 1699.039,
      "duration": 5.441
    },
    {
      "lang": "en",
      "text": "not an unaccountable board ruling all of",
      "offset": 1701.559,
      "duration": 5.84
    },
    {
      "lang": "en",
      "text": "us wait why is China open sourcing their",
      "offset": 1704.48,
      "duration": 6.72
    },
    {
      "lang": "en",
      "text": "model well deep seek is to be clear CEO",
      "offset": 1707.399,
      "duration": 5.561
    },
    {
      "lang": "en",
      "text": "leang Wen fun said in a must-read",
      "offset": 1711.2,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "interview that open source is key to",
      "offset": 1712.96,
      "duration": 3.16
    },
    {
      "lang": "en",
      "text": "attracting",
      "offset": 1714.64,
      "duration": 3.879
    },
    {
      "lang": "en",
      "text": "talent in the face of disruptive",
      "offset": 1716.12,
      "duration": 4.679
    },
    {
      "lang": "en",
      "text": "Technologies modes created by closed",
      "offset": 1718.519,
      "duration": 5.16
    },
    {
      "lang": "en",
      "text": "sources are temporary even opening eyes",
      "offset": 1720.799,
      "duration": 4.6
    },
    {
      "lang": "en",
      "text": "closed Source approach can prevent",
      "offset": 1723.679,
      "duration": 4.441
    },
    {
      "lang": "en",
      "text": "others from catching up so we anchor our",
      "offset": 1725.399,
      "duration": 5.16
    },
    {
      "lang": "en",
      "text": "value in our team our colleagues grow",
      "offset": 1728.12,
      "duration": 4.84
    },
    {
      "lang": "en",
      "text": "through the process accumulate knowhow",
      "offset": 1730.559,
      "duration": 4.441
    },
    {
      "lang": "en",
      "text": "and form an organization and culture",
      "offset": 1732.96,
      "duration": 5.24
    },
    {
      "lang": "en",
      "text": "capable of innovation that's our moat",
      "offset": 1735,
      "duration": 5.799
    },
    {
      "lang": "en",
      "text": "open- Source publishing papers in fact",
      "offset": 1738.2,
      "duration": 5
    },
    {
      "lang": "en",
      "text": "do not cost us anything for technical",
      "offset": 1740.799,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "Talent having others follow your",
      "offset": 1743.2,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "Innovation gives a great sense of",
      "offset": 1744.96,
      "duration": 4.599
    },
    {
      "lang": "en",
      "text": "accomplishment in fact open source is",
      "offset": 1746.88,
      "duration": 4.6
    },
    {
      "lang": "en",
      "text": "more of a cultural Behavior than a",
      "offset": 1749.559,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "commercial one and contributing to it",
      "offset": 1751.48,
      "duration": 5
    },
    {
      "lang": "en",
      "text": "earns a respect there's also a cultural",
      "offset": 1753.64,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "attraction for a company to do",
      "offset": 1756.48,
      "duration": 6.039
    },
    {
      "lang": "en",
      "text": "this question deep seek right now has a",
      "offset": 1758.6,
      "duration": 6.36
    },
    {
      "lang": "en",
      "text": "kind of idealistic AA reminiscent of the",
      "offset": 1762.519,
      "duration": 5.841
    },
    {
      "lang": "en",
      "text": "early days of openi and its open source",
      "offset": 1764.96,
      "duration": 6.24
    },
    {
      "lang": "en",
      "text": "will you change to Clos Source later on",
      "offset": 1768.36,
      "duration": 5.439
    },
    {
      "lang": "en",
      "text": "both open Ai and mraw move from open",
      "offset": 1771.2,
      "duration": 6.12
    },
    {
      "lang": "en",
      "text": "source to closed Source answer we will",
      "offset": 1773.799,
      "duration": 6.041
    },
    {
      "lang": "en",
      "text": "not change to close Source We Believe",
      "offset": 1777.32,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "having a strong technical ecosystem",
      "offset": 1779.84,
      "duration": 5.079
    },
    {
      "lang": "en",
      "text": "first is more important this actually",
      "offset": 1781.88,
      "duration": 5.039
    },
    {
      "lang": "en",
      "text": "makes sense Beyond idealism if models",
      "offset": 1784.919,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "are Commodities and they are certainly",
      "offset": 1786.919,
      "duration": 3.401
    },
    {
      "lang": "en",
      "text": "looking that way then long-term",
      "offset": 1788.519,
      "duration": 3.201
    },
    {
      "lang": "en",
      "text": "differentiation comes from having a",
      "offset": 1790.32,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "superior cost structure that is exactly",
      "offset": 1791.72,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "what deep seek has delivered which",
      "offset": 1794.08,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "itself is resonant of how China has come",
      "offset": 1795.799,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "to dominate other Industries this is",
      "offset": 1797.6,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "also contrary to how most us companies",
      "offset": 1800.279,
      "duration": 3.801
    },
    {
      "lang": "en",
      "text": "think about differentiation which is",
      "offset": 1802.32,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "through having differentiated products",
      "offset": 1804.08,
      "duration": 3.319
    },
    {
      "lang": "en",
      "text": "that can sustain larger",
      "offset": 1805.76,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "margins so is opening ey",
      "offset": 1807.399,
      "duration": 6.841
    },
    {
      "lang": "en",
      "text": "screwed not necessarily chat GPT made",
      "offset": 1810.88,
      "duration": 5.159
    },
    {
      "lang": "en",
      "text": "openai The Accidental consumer tech",
      "offset": 1814.24,
      "duration": 3.319
    },
    {
      "lang": "en",
      "text": "company which is to say A Product",
      "offset": 1816.039,
      "duration": 3.441
    },
    {
      "lang": "en",
      "text": "Company there is a route to building a",
      "offset": 1817.559,
      "duration": 3.441
    },
    {
      "lang": "en",
      "text": "sustainable consumer business on",
      "offset": 1819.48,
      "duration": 3.199
    },
    {
      "lang": "en",
      "text": "commoditized models through some",
      "offset": 1821,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "combination of subscriptions and",
      "offset": 1822.679,
      "duration": 3.88
    },
    {
      "lang": "en",
      "text": "advertisements and of course there is",
      "offset": 1824.2,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "the bet on winning the race to a I",
      "offset": 1826.559,
      "duration": 4.561
    },
    {
      "lang": "en",
      "text": "takeoff anthropic on the other hand is",
      "offset": 1828.44,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "probably the biggest loser of the",
      "offset": 1831.12,
      "duration": 3.559
    },
    {
      "lang": "en",
      "text": "weekend deep seek made it to number one",
      "offset": 1832.36,
      "duration": 4.36
    },
    {
      "lang": "en",
      "text": "in the App Store simply highlighting how",
      "offset": 1834.679,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "Claude in contrast hasn't gotten any",
      "offset": 1836.72,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "traction outside of San Francisco the",
      "offset": 1839.159,
      "duration": 4.52
    },
    {
      "lang": "en",
      "text": "API business is doing better but API",
      "offset": 1841.36,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "businesses in general are the most",
      "offset": 1843.679,
      "duration": 3.24
    },
    {
      "lang": "en",
      "text": "susceptible to the commoditization",
      "offset": 1845.279,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "trends that seem inevitable and do note",
      "offset": 1846.919,
      "duration": 4.561
    },
    {
      "lang": "en",
      "text": "that open Ai and anthropics inference",
      "offset": 1849.519,
      "duration": 3.961
    },
    {
      "lang": "en",
      "text": "costs look a lot higher than deep seek",
      "offset": 1851.48,
      "duration": 3.199
    },
    {
      "lang": "en",
      "text": "because they were capturing a lot of",
      "offset": 1853.48,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "margin that's going away so this is all",
      "offset": 1854.679,
      "duration": 6.401
    },
    {
      "lang": "en",
      "text": "pretty depressing then actually no I",
      "offset": 1857.72,
      "duration": 4.799
    },
    {
      "lang": "en",
      "text": "think that deep seek has provided a",
      "offset": 1861.08,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "massive gift to nearly everyone the",
      "offset": 1862.519,
      "duration": 3.481
    },
    {
      "lang": "en",
      "text": "biggest winners are consumers and",
      "offset": 1864.6,
      "duration": 3.319
    },
    {
      "lang": "en",
      "text": "businesses who can anticipate a future",
      "offset": 1866,
      "duration": 3.72
    },
    {
      "lang": "en",
      "text": "of effectively free AI products and",
      "offset": 1867.919,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "services javon's Paradox will rule the",
      "offset": 1869.72,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "day in the long run and everyone who",
      "offset": 1872.32,
      "duration": 4.28
    },
    {
      "lang": "en",
      "text": "uses AI will be the biggest winners",
      "offset": 1874.039,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "another set of winners are the big",
      "offset": 1876.6,
      "duration": 3.48
    },
    {
      "lang": "en",
      "text": "consumer tech companies a world of free",
      "offset": 1877.799,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "AI is a world where product and",
      "offset": 1880.08,
      "duration": 3.64
    },
    {
      "lang": "en",
      "text": "distribution matters most and those",
      "offset": 1881.639,
      "duration": 4.28
    },
    {
      "lang": "en",
      "text": "companies already won that game the end",
      "offset": 1883.72,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "of the beginning was right China is also",
      "offset": 1885.919,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "a big winner in ways that I suspect will",
      "offset": 1888.6,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "only become apparent over time not only",
      "offset": 1890.799,
      "duration": 4.201
    },
    {
      "lang": "en",
      "text": "does the country have access to deep",
      "offset": 1893.48,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "seek but I suspect that deep seeks",
      "offset": 1895,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "relative success to America's leading AI",
      "offset": 1897,
      "duration": 4.519
    },
    {
      "lang": "en",
      "text": "Labs will result in a further unleashing",
      "offset": 1899.24,
      "duration": 3.96
    },
    {
      "lang": "en",
      "text": "of Chinese Innovation as they realize",
      "offset": 1901.519,
      "duration": 2.601
    },
    {
      "lang": "en",
      "text": "they can",
      "offset": 1903.2,
      "duration": 3.439
    },
    {
      "lang": "en",
      "text": "compete that leaves America and a choice",
      "offset": 1904.12,
      "duration": 4.919
    },
    {
      "lang": "en",
      "text": "we have to make we could for very",
      "offset": 1906.639,
      "duration": 4.561
    },
    {
      "lang": "en",
      "text": "logical reasons double down on defensive",
      "offset": 1909.039,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "measures like massively expanding the",
      "offset": 1911.2,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "chip band and imposing a",
      "offset": 1913.12,
      "duration": 3
    },
    {
      "lang": "en",
      "text": "permission-based regulatory regime on",
      "offset": 1914.32,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "chips and semiconductor equipment that",
      "offset": 1916.12,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "mirrors the eu's approach to Tech",
      "offset": 1918.399,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "alternatively we could realize that we",
      "offset": 1920.84,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "have real competition and actually give",
      "offset": 1922.799,
      "duration": 4.521
    },
    {
      "lang": "en",
      "text": "oursel permission to compete stop",
      "offset": 1925.159,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "ringing our hands stop campaigning for",
      "offset": 1927.32,
      "duration": 4.959
    },
    {
      "lang": "en",
      "text": "regulations indeed go the other way and",
      "offset": 1929.639,
      "duration": 4.841
    },
    {
      "lang": "en",
      "text": "cut out all the Cru in our companies",
      "offset": 1932.279,
      "duration": 4.441
    },
    {
      "lang": "en",
      "text": "that has nothing to do with winning if",
      "offset": 1934.48,
      "duration": 4.439
    },
    {
      "lang": "en",
      "text": "we choose to compete we can still win",
      "offset": 1936.72,
      "duration": 4.12
    },
    {
      "lang": "en",
      "text": "and if we do we will have a Chinese",
      "offset": 1938.919,
      "duration": 5.521
    },
    {
      "lang": "en",
      "text": "company to think",
      "offset": 1940.84,
      "duration": 3.6
    }
  ],
  "cleanText": null,
  "dumpedAt": "2025-07-21T18:43:25.772Z"
}