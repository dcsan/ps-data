{
  "episodeId": "LCEmiRjPEtQ",
  "channelSlug": "@ycombinator",
  "title": "Andrej Karpathy: Software Is Changing (Again)",
  "publishedAt": "2025-06-19T01:05:19.000Z",
  "rawLines": [
    {
      "lang": "en",
      "text": "Please welcome former director of AI",
      "offset": 1.12,
      "duration": 6.05
    },
    {
      "lang": "en",
      "text": "Tesla Andre Carpathy.",
      "offset": 4,
      "duration": 7.44
    },
    {
      "lang": "en",
      "text": "[Music]",
      "offset": 7.17,
      "duration": 7.27
    },
    {
      "lang": "en",
      "text": "Hello.",
      "offset": 11.44,
      "duration": 3
    },
    {
      "lang": "en",
      "text": "[Music]",
      "offset": 14.77,
      "duration": 3.08
    },
    {
      "lang": "en",
      "text": "Wow, a lot of people here. Hello.",
      "offset": 19.039,
      "duration": 5.761
    },
    {
      "lang": "en",
      "text": "Um, okay. Yeah. So I'm excited to be",
      "offset": 22.8,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "here today to talk to you about software",
      "offset": 24.8,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "in the era of AI. And I'm told that many",
      "offset": 27.199,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "of you are students like bachelors,",
      "offset": 30.56,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "masters, PhD and so on. And you're about",
      "offset": 32.559,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "to enter the industry. And I think it's",
      "offset": 34.399,
      "duration": 3.361
    },
    {
      "lang": "en",
      "text": "actually like an extremely unique and",
      "offset": 36.399,
      "duration": 2.561
    },
    {
      "lang": "en",
      "text": "very interesting time to enter the",
      "offset": 37.76,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "industry right now. And I think",
      "offset": 38.96,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "fundamentally the reason for that is",
      "offset": 41.36,
      "duration": 6.24
    },
    {
      "lang": "en",
      "text": "that um software is changing uh again.",
      "offset": 43.04,
      "duration": 6.88
    },
    {
      "lang": "en",
      "text": "And I say again because I actually gave",
      "offset": 47.6,
      "duration": 4.959
    },
    {
      "lang": "en",
      "text": "this talk already. Um but the problem is",
      "offset": 49.92,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "that software keeps changing. So I",
      "offset": 52.559,
      "duration": 2.64
    },
    {
      "lang": "en",
      "text": "actually have a lot of material to",
      "offset": 54.079,
      "duration": 2.64
    },
    {
      "lang": "en",
      "text": "create new talks and I think it's",
      "offset": 55.199,
      "duration": 2.961
    },
    {
      "lang": "en",
      "text": "changing quite fundamentally. I think",
      "offset": 56.719,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "roughly speaking software has not",
      "offset": 58.16,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "changed much on such a fundamental level",
      "offset": 60.32,
      "duration": 4.239
    },
    {
      "lang": "en",
      "text": "for 70 years. And then it's changed I",
      "offset": 62,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "think about twice quite rapidly in the",
      "offset": 64.559,
      "duration": 4.001
    },
    {
      "lang": "en",
      "text": "last few years. And so there's just a",
      "offset": 66.88,
      "duration": 2.96
    },
    {
      "lang": "en",
      "text": "huge amount of work to do a huge amount",
      "offset": 68.56,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "of software to write and rewrite. So",
      "offset": 69.84,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "let's take a look at maybe the realm of",
      "offset": 72.32,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "software. So if we kind of think of this",
      "offset": 74.159,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "as like the map of software this is a",
      "offset": 76.08,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "really cool tool called map of GitHub.",
      "offset": 77.759,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "Um this is kind of like all the software",
      "offset": 80,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "that's written. Uh these are",
      "offset": 81.92,
      "duration": 2.72
    },
    {
      "lang": "en",
      "text": "instructions to the computer for",
      "offset": 83.36,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "carrying out tasks in the digital space.",
      "offset": 84.64,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "So if you zoom in here, these are all",
      "offset": 86.4,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "different kinds of repositories and this",
      "offset": 88,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "is all the code that has been written.",
      "offset": 90.08,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "And a few years ago I kind of observed",
      "offset": 91.68,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "that um software was kind of changing",
      "offset": 93.6,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "and there was kind of like a new type of",
      "offset": 95.84,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "software around and I called this",
      "offset": 97.759,
      "duration": 4.561
    },
    {
      "lang": "en",
      "text": "software 2.0 at the time and the idea",
      "offset": 99.68,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "here was that software 1.0 is the code",
      "offset": 102.32,
      "duration": 4.479
    },
    {
      "lang": "en",
      "text": "you write for the computer. Software 2.0",
      "offset": 104.64,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "know are basically neural networks and",
      "offset": 106.799,
      "duration": 3.521
    },
    {
      "lang": "en",
      "text": "in particular the weights of a neural",
      "offset": 108.799,
      "duration": 4.481
    },
    {
      "lang": "en",
      "text": "network and you're not writing this code",
      "offset": 110.32,
      "duration": 5.119
    },
    {
      "lang": "en",
      "text": "directly you are most you are more kind",
      "offset": 113.28,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "of like tuning the data sets and then",
      "offset": 115.439,
      "duration": 2.96
    },
    {
      "lang": "en",
      "text": "you're running an optimizer to create to",
      "offset": 116.88,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "create the parameters of this neural net",
      "offset": 118.399,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "and I think like at the time neural nets",
      "offset": 120.88,
      "duration": 2.72
    },
    {
      "lang": "en",
      "text": "were kind of seen as like just a",
      "offset": 122.56,
      "duration": 2.239
    },
    {
      "lang": "en",
      "text": "different kind of classifier like a",
      "offset": 123.6,
      "duration": 2.64
    },
    {
      "lang": "en",
      "text": "decision tree or something like that and",
      "offset": 124.799,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "so I think it was kind of like um I",
      "offset": 126.24,
      "duration": 3.999
    },
    {
      "lang": "en",
      "text": "think this framing was a lot more",
      "offset": 129.039,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "appropriate and now actually what we",
      "offset": 130.239,
      "duration": 3.281
    },
    {
      "lang": "en",
      "text": "have is kind of like an equivalent of",
      "offset": 132.239,
      "duration": 3.521
    },
    {
      "lang": "en",
      "text": "GitHub in the realm of software 2.0 And",
      "offset": 133.52,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "I think the hugging face is basically",
      "offset": 135.76,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "equivalent of GitHub in software 2.0.",
      "offset": 138.08,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "And there's also model atlas and you can",
      "offset": 140.72,
      "duration": 3.519
    },
    {
      "lang": "en",
      "text": "visualize all the code written there. In",
      "offset": 142.4,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "case you're curious, by the way, the",
      "offset": 144.239,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "giant circle, the point in the middle,",
      "offset": 145.44,
      "duration": 5.439
    },
    {
      "lang": "en",
      "text": "uh these are the parameters of flux, the",
      "offset": 148.319,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "image generator. And so anytime someone",
      "offset": 150.879,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "tunes a on top of a flux model, you",
      "offset": 152.879,
      "duration": 4.241
    },
    {
      "lang": "en",
      "text": "basically create a git commit uh in this",
      "offset": 154.959,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "space and uh you create a different kind",
      "offset": 157.12,
      "duration": 4.479
    },
    {
      "lang": "en",
      "text": "of a image generator. So basically what",
      "offset": 159.12,
      "duration": 4.479
    },
    {
      "lang": "en",
      "text": "we have is software 1.0 is the computer",
      "offset": 161.599,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "code that programs a computer. Software",
      "offset": 163.599,
      "duration": 5.121
    },
    {
      "lang": "en",
      "text": "2.0 are the weights which program neural",
      "offset": 165.92,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "networks. Uh and here's an example of",
      "offset": 168.72,
      "duration": 4.799
    },
    {
      "lang": "en",
      "text": "Alexet image recognizer neural network.",
      "offset": 170.72,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "Now so far all of the neural networks",
      "offset": 173.519,
      "duration": 2.881
    },
    {
      "lang": "en",
      "text": "that we've been familiar with until",
      "offset": 175.04,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "recently where kind of like fixed",
      "offset": 176.4,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "function computers image to categories",
      "offset": 178.16,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "or something like that. And I think",
      "offset": 181.68,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "what's changed and I think is a quite",
      "offset": 183.44,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "fundamental change is that neural",
      "offset": 185.2,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "networks became programmable with large",
      "offset": 186.72,
      "duration": 5.439
    },
    {
      "lang": "en",
      "text": "language models. And so I I see this as",
      "offset": 189.599,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "quite new, unique. It's a new kind of a",
      "offset": 192.159,
      "duration": 5.841
    },
    {
      "lang": "en",
      "text": "computer and uh so in my mind it's uh",
      "offset": 194.959,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "worth giving it a new designation of",
      "offset": 198,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "software 3.0. And basically your prompts",
      "offset": 199.599,
      "duration": 6.081
    },
    {
      "lang": "en",
      "text": "are now programs that program the LLM.",
      "offset": 202.159,
      "duration": 6.16
    },
    {
      "lang": "en",
      "text": "And uh remarkably uh these uh prompts",
      "offset": 205.68,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "are written in English. So it's kind of",
      "offset": 208.319,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "a very interesting programming language.",
      "offset": 210.4,
      "duration": 6.399
    },
    {
      "lang": "en",
      "text": "Um so maybe uh to summarize the",
      "offset": 213.599,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "difference if you're doing sentiment",
      "offset": 216.799,
      "duration": 2.641
    },
    {
      "lang": "en",
      "text": "classification for example you can",
      "offset": 217.92,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "imagine writing some uh amount of Python",
      "offset": 219.44,
      "duration": 4.799
    },
    {
      "lang": "en",
      "text": "to to basically do sentiment",
      "offset": 222.48,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "classification or you can train a neural",
      "offset": 224.239,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "net or you can prompt a large language",
      "offset": 226,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "model. Uh so here this is a few short",
      "offset": 227.84,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "prompt and you can imagine changing it",
      "offset": 230,
      "duration": 2.799
    },
    {
      "lang": "en",
      "text": "and programming the computer in a",
      "offset": 231.28,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "slightly different way. So basically we",
      "offset": 232.799,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "have software 1.0 software 2.0 and I",
      "offset": 234.64,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "think we're seeing maybe you've seen a",
      "offset": 237.599,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "lot of GitHub code is not just like code",
      "offset": 239.68,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "anymore. there's a bunch of like English",
      "offset": 241.92,
      "duration": 3.519
    },
    {
      "lang": "en",
      "text": "interspersed with code and so I think",
      "offset": 243.519,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "kind of there's a growing category of",
      "offset": 245.439,
      "duration": 3.761
    },
    {
      "lang": "en",
      "text": "new kind of code. So not only is it a",
      "offset": 247.36,
      "duration": 3.519
    },
    {
      "lang": "en",
      "text": "new programming paradigm, it's also",
      "offset": 249.2,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "remarkable to me that it's in our native",
      "offset": 250.879,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "language of English. And so when this",
      "offset": 252.72,
      "duration": 5.199
    },
    {
      "lang": "en",
      "text": "blew my mind a few uh I guess years ago",
      "offset": 254.879,
      "duration": 6.001
    },
    {
      "lang": "en",
      "text": "now I tweeted this and um I think it",
      "offset": 257.919,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "captured the attention of a lot of",
      "offset": 260.88,
      "duration": 2.319
    },
    {
      "lang": "en",
      "text": "people and this is my currently pinned",
      "offset": 261.919,
      "duration": 3.441
    },
    {
      "lang": "en",
      "text": "tweet uh is that remarkably we're now",
      "offset": 263.199,
      "duration": 4.961
    },
    {
      "lang": "en",
      "text": "programming computers in English. Now,",
      "offset": 265.36,
      "duration": 6.24
    },
    {
      "lang": "en",
      "text": "when I was at uh Tesla, um we were",
      "offset": 268.16,
      "duration": 6.8
    },
    {
      "lang": "en",
      "text": "working on the uh autopilot and uh we",
      "offset": 271.6,
      "duration": 5.84
    },
    {
      "lang": "en",
      "text": "were trying to get the car to drive and",
      "offset": 274.96,
      "duration": 4.959
    },
    {
      "lang": "en",
      "text": "I sort of showed this slide at the time",
      "offset": 277.44,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "where you can imagine that the inputs to",
      "offset": 279.919,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "the car are on the bottom and they're",
      "offset": 281.68,
      "duration": 2.959
    },
    {
      "lang": "en",
      "text": "going through a software stack to",
      "offset": 283.199,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "produce the steering and acceleration",
      "offset": 284.639,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "and I made the observation at the time",
      "offset": 287.04,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "that there was a ton of C++ code around",
      "offset": 288.56,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "in the autopilot which was the software",
      "offset": 291.12,
      "duration": 3.359
    },
    {
      "lang": "en",
      "text": "1.0 code and then there was some neural",
      "offset": 292.72,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "nets in there doing image recognition",
      "offset": 294.479,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "and uh I kind of observed that over time",
      "offset": 296.96,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "as we made the autopilot better",
      "offset": 298.8,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "basically the neural network grew in",
      "offset": 300.88,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "capability and size and in addition to",
      "offset": 302.72,
      "duration": 5.84
    },
    {
      "lang": "en",
      "text": "that all the C++ code was being deleted",
      "offset": 305.84,
      "duration": 6.24
    },
    {
      "lang": "en",
      "text": "and kind of like was um and a lot of the",
      "offset": 308.56,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "kind of capabilities and functionality",
      "offset": 312.08,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "that was originally written in 1.0 was",
      "offset": 314.56,
      "duration": 4.479
    },
    {
      "lang": "en",
      "text": "migrated to 2.0. So as an example, a lot",
      "offset": 316.479,
      "duration": 4.241
    },
    {
      "lang": "en",
      "text": "of the stitching up of information",
      "offset": 319.039,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "across images from the different cameras",
      "offset": 320.72,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "and across time was done by a neural",
      "offset": 322.639,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "network and we were able to delete a lot",
      "offset": 324.96,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "of code and so the software 2.0 stack",
      "offset": 326.479,
      "duration": 6.081
    },
    {
      "lang": "en",
      "text": "quite literally ate through the software",
      "offset": 329.84,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "stack of the autopilot. So I thought",
      "offset": 332.56,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "this was really remarkable at the time",
      "offset": 334.16,
      "duration": 2.879
    },
    {
      "lang": "en",
      "text": "and I think we're seeing the same thing",
      "offset": 335.68,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "again where uh basically we have a new",
      "offset": 337.039,
      "duration": 3.761
    },
    {
      "lang": "en",
      "text": "kind of software and it's eating through",
      "offset": 339.36,
      "duration": 3.119
    },
    {
      "lang": "en",
      "text": "the stack. We have three completely",
      "offset": 340.8,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "different programming paradigms and I",
      "offset": 342.479,
      "duration": 3.121
    },
    {
      "lang": "en",
      "text": "think if you're entering the industry",
      "offset": 344.4,
      "duration": 2.96
    },
    {
      "lang": "en",
      "text": "it's a very good idea to be fluent in",
      "offset": 345.6,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "all of them because they all have slight",
      "offset": 347.36,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "pros and cons and you may want to",
      "offset": 349.36,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "program some functionality in 1.0 or 2.0",
      "offset": 350.8,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "or 3.0. Are you going to train",
      "offset": 353.12,
      "duration": 2.48
    },
    {
      "lang": "en",
      "text": "neurallet? Are you going to just prompt",
      "offset": 354.4,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "an LLM? Should this be a piece of code",
      "offset": 355.6,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "that's explicit etc. So we all have to",
      "offset": 357.44,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "make these decisions and actually",
      "offset": 359.36,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "potentially uh fluidly trans transition",
      "offset": 360.56,
      "duration": 6.24
    },
    {
      "lang": "en",
      "text": "between these paradigms. So what I",
      "offset": 363.52,
      "duration": 6.239
    },
    {
      "lang": "en",
      "text": "wanted to get into now is first I want",
      "offset": 366.8,
      "duration": 4.959
    },
    {
      "lang": "en",
      "text": "to in the first part talk about LLMs and",
      "offset": 369.759,
      "duration": 3.761
    },
    {
      "lang": "en",
      "text": "how to kind of like think of this new",
      "offset": 371.759,
      "duration": 3.361
    },
    {
      "lang": "en",
      "text": "paradigm and the ecosystem and what that",
      "offset": 373.52,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "looks like. Uh like what are what is",
      "offset": 375.12,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "this new computer? What does it look",
      "offset": 377.44,
      "duration": 2.8
    },
    {
      "lang": "en",
      "text": "like and what does the ecosystem look",
      "offset": 378.72,
      "duration": 5.039
    },
    {
      "lang": "en",
      "text": "like? Um I was struck by this quote from",
      "offset": 380.24,
      "duration": 5.519
    },
    {
      "lang": "en",
      "text": "Anduring actually uh many years ago now",
      "offset": 383.759,
      "duration": 3.761
    },
    {
      "lang": "en",
      "text": "I think and I think Andrew is going to",
      "offset": 385.759,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "be speaking right after me. Uh but he",
      "offset": 387.52,
      "duration": 3.119
    },
    {
      "lang": "en",
      "text": "said at the time AI is the new",
      "offset": 389.44,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "electricity and I do think that it um",
      "offset": 390.639,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "kind of captures something very",
      "offset": 393.36,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "interesting in that LLMs certainly feel",
      "offset": 394.639,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "like they have properties of utilities",
      "offset": 396.72,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "right now. So",
      "offset": 398.96,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "um LLM labs like OpenAI, Gemini,",
      "offset": 401.6,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "Enthropic etc. They spend capex to train",
      "offset": 404.24,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "the LLMs and this is kind of equivalent",
      "offset": 407.12,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "to building out a grid and then there's",
      "offset": 408.88,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "opex to serve that intelligence over",
      "offset": 411.12,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "APIs to all of us and this is done",
      "offset": 413.039,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "through metered access where we pay per",
      "offset": 416.4,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "million tokens or something like that",
      "offset": 418.639,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "and we have a lot of demands that are",
      "offset": 420.4,
      "duration": 3.519
    },
    {
      "lang": "en",
      "text": "very utility- like demands out of this",
      "offset": 421.919,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "API we demand low latency high uptime",
      "offset": 423.919,
      "duration": 5.041
    },
    {
      "lang": "en",
      "text": "consistent quality etc. In electricity,",
      "offset": 426.24,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "you would have a transfer switch. So you",
      "offset": 428.96,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "can transfer your electricity source",
      "offset": 430.8,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "from like grid and solar or battery or",
      "offset": 432.4,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "generator. In LLM, we have maybe open",
      "offset": 434.4,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "router and easily switch between the",
      "offset": 436.8,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "different types of LLMs that exist.",
      "offset": 438.56,
      "duration": 4.479
    },
    {
      "lang": "en",
      "text": "Because the LLM are software, they don't",
      "offset": 440.639,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "compete for physical space. So it's okay",
      "offset": 443.039,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "to have basically like six electricity",
      "offset": 445.039,
      "duration": 3.121
    },
    {
      "lang": "en",
      "text": "providers and you can switch between",
      "offset": 446.72,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "them, right? Because they don't compete",
      "offset": 448.16,
      "duration": 3.759
    },
    {
      "lang": "en",
      "text": "in such a direct way. And I think what's",
      "offset": 449.84,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "also a little fascinating and we saw",
      "offset": 451.919,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "this in the last few days actually a lot",
      "offset": 453.68,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "of the LLMs went down and people were",
      "offset": 456.479,
      "duration": 4.641
    },
    {
      "lang": "en",
      "text": "kind of like stuck and unable to work.",
      "offset": 458.8,
      "duration": 3.679
    },
    {
      "lang": "en",
      "text": "And uh I think it's kind of fascinating",
      "offset": 461.12,
      "duration": 2.639
    },
    {
      "lang": "en",
      "text": "to me that when the state-of-the-art",
      "offset": 462.479,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "LLMs go down, it's actually kind of like",
      "offset": 463.759,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "an intelligence brownout in the world.",
      "offset": 465.759,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "It's kind of like when the voltage is",
      "offset": 467.759,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "unreliable in the grid and uh the planet",
      "offset": 469.36,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "just gets dumber the more reliance we",
      "offset": 472.08,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "have on these models, which already is",
      "offset": 475.12,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "like really dramatic and I think will",
      "offset": 476.72,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "continue to grow. But LLM's don't only",
      "offset": 478.4,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "have properties of utilities. I think",
      "offset": 480.8,
      "duration": 2.72
    },
    {
      "lang": "en",
      "text": "it's also fair to say that they have",
      "offset": 482.24,
      "duration": 4.239
    },
    {
      "lang": "en",
      "text": "some properties of fabs. And the reason",
      "offset": 483.52,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "for this is that the capex required for",
      "offset": 486.479,
      "duration": 5.761
    },
    {
      "lang": "en",
      "text": "building LLM is actually quite large. Uh",
      "offset": 489.52,
      "duration": 4.799
    },
    {
      "lang": "en",
      "text": "it's not just like building some uh",
      "offset": 492.24,
      "duration": 3.679
    },
    {
      "lang": "en",
      "text": "power station or something like that,",
      "offset": 494.319,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "right? You're investing a huge amount of",
      "offset": 495.919,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "money and I think the tech tree and uh",
      "offset": 497.599,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "for the technology is growing quite",
      "offset": 500,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "rapidly. So we're in a world where we",
      "offset": 502.479,
      "duration": 4.481
    },
    {
      "lang": "en",
      "text": "have sort of deep tech trees, research",
      "offset": 504.4,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "and development secrets that are",
      "offset": 506.96,
      "duration": 5.439
    },
    {
      "lang": "en",
      "text": "centralizing inside the LLM labs. Um and",
      "offset": 508.96,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "but I think the analogy muddies a little",
      "offset": 512.399,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "bit also because as I mentioned this is",
      "offset": 514.24,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "software and software is a bit less",
      "offset": 516.24,
      "duration": 4.719
    },
    {
      "lang": "en",
      "text": "defensible because it is so malleable.",
      "offset": 518.159,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "And so um I think it's just an",
      "offset": 520.959,
      "duration": 3.361
    },
    {
      "lang": "en",
      "text": "interesting kind of thing to think about",
      "offset": 523.039,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "potentially. There's many analogy",
      "offset": 524.32,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "analogies you can make like a 4",
      "offset": 526.64,
      "duration": 2.96
    },
    {
      "lang": "en",
      "text": "nanometer process node maybe is",
      "offset": 528.16,
      "duration": 2.88
    },
    {
      "lang": "en",
      "text": "something like a cluster with certain",
      "offset": 529.6,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "max flops. You can think about when",
      "offset": 531.04,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "you're use when you're using Nvidia GPUs",
      "offset": 533.04,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "and you're only doing the software and",
      "offset": 534.8,
      "duration": 2.32
    },
    {
      "lang": "en",
      "text": "you're not doing the hardware. That's",
      "offset": 536.08,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "kind of like the fabless model. But if",
      "offset": 537.12,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "you're actually also building your own",
      "offset": 539.12,
      "duration": 2.88
    },
    {
      "lang": "en",
      "text": "hardware and you're training on TPUs if",
      "offset": 540.32,
      "duration": 2.959
    },
    {
      "lang": "en",
      "text": "you're Google, that's kind of like the",
      "offset": 542,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "Intel model where you own your fab. So I",
      "offset": 543.279,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "think there's some analogies here that",
      "offset": 545.2,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "make sense. But actually I think the",
      "offset": 546.399,
      "duration": 3.361
    },
    {
      "lang": "en",
      "text": "analogy that makes the most sense",
      "offset": 548.24,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "perhaps is that in my mind LLM have very",
      "offset": 549.76,
      "duration": 5.519
    },
    {
      "lang": "en",
      "text": "strong kind of analogies to operating",
      "offset": 552.48,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "systems. Uh in that this is not just",
      "offset": 555.279,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "electricity or water. It's not something",
      "offset": 557.76,
      "duration": 3.199
    },
    {
      "lang": "en",
      "text": "that comes out of the tap as a",
      "offset": 559.519,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "commodity. uh this is these are now",
      "offset": 560.959,
      "duration": 4.961
    },
    {
      "lang": "en",
      "text": "increasingly complex software ecosystems",
      "offset": 562.959,
      "duration": 5.761
    },
    {
      "lang": "en",
      "text": "right so uh they're not just like simple",
      "offset": 565.92,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "commodities like electricity and it's",
      "offset": 568.72,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "kind of interesting to me that the",
      "offset": 570.88,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "ecosystem is shaping in a very similar",
      "offset": 572,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "kind of way where you have a few closed",
      "offset": 573.92,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "source providers like Windows or Mac OS",
      "offset": 576.16,
      "duration": 3.679
    },
    {
      "lang": "en",
      "text": "and then you have an open source",
      "offset": 578.56,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "alternative like Linux and I think for u",
      "offset": 579.839,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "neural for LLMs as well we have a kind",
      "offset": 582.72,
      "duration": 4.799
    },
    {
      "lang": "en",
      "text": "of a few competing closed source",
      "offset": 585.519,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "providers and then maybe the llama",
      "offset": 587.519,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "ecosystem is currently like maybe a",
      "offset": 589.2,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "close approximation to something that",
      "offset": 591.44,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "may grow into something like Linux.",
      "offset": 593.12,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "Again, I think it's still very early",
      "offset": 595.12,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "because these are just simple LLMs, but",
      "offset": 596.48,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "we're starting to see that these are",
      "offset": 598.16,
      "duration": 2.96
    },
    {
      "lang": "en",
      "text": "going to get a lot more complicated.",
      "offset": 599.6,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "It's not just about the LLM itself. It's",
      "offset": 601.12,
      "duration": 2.8
    },
    {
      "lang": "en",
      "text": "about all the tool use and the",
      "offset": 602.8,
      "duration": 2.719
    },
    {
      "lang": "en",
      "text": "multiodalities and how all of that",
      "offset": 603.92,
      "duration": 3.359
    },
    {
      "lang": "en",
      "text": "works. And so when I sort of had this",
      "offset": 605.519,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "realization a while back, I tried to",
      "offset": 607.279,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "sketch it out and it kind of seemed to",
      "offset": 609.36,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "me like LLMs are kind of like a new",
      "offset": 611.2,
      "duration": 4.639
    },
    {
      "lang": "en",
      "text": "operating system, right? So the LLM is a",
      "offset": 612.8,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "new kind of a computer. It's sitting",
      "offset": 615.839,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "it's kind of like the CPU equivalent. uh",
      "offset": 617.6,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "the context windows are kind of like the",
      "offset": 619.76,
      "duration": 4.639
    },
    {
      "lang": "en",
      "text": "memory and then the LLM is orchestrating",
      "offset": 621.519,
      "duration": 5.121
    },
    {
      "lang": "en",
      "text": "memory and compute uh for problem",
      "offset": 624.399,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "solving um using all of these uh",
      "offset": 626.64,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "capabilities here and so definitely if",
      "offset": 629.839,
      "duration": 4.481
    },
    {
      "lang": "en",
      "text": "you look at it looks very much like",
      "offset": 632.64,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "operating system from that perspective.",
      "offset": 634.32,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "Um, a few more analogies. For example,",
      "offset": 636.48,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "if you want to download an app, say I go",
      "offset": 638.88,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "to VS Code and I go to download, you can",
      "offset": 641.2,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "download VS Code and you can run it on",
      "offset": 643.68,
      "duration": 6.48
    },
    {
      "lang": "en",
      "text": "Windows, Linux or or Mac in the same way",
      "offset": 646.24,
      "duration": 6.88
    },
    {
      "lang": "en",
      "text": "as you can take an LLM app like cursor",
      "offset": 650.16,
      "duration": 5.359
    },
    {
      "lang": "en",
      "text": "and you can run it on GPT or cloud or",
      "offset": 653.12,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "Gemini series, right? It's just a drop",
      "offset": 655.519,
      "duration": 3.521
    },
    {
      "lang": "en",
      "text": "down. So, it's kind of like similar in",
      "offset": 657.44,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "that way as well.",
      "offset": 659.04,
      "duration": 3.359
    },
    {
      "lang": "en",
      "text": "uh more analogies that I think strike me",
      "offset": 660.72,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "is that we're kind of like in this",
      "offset": 662.399,
      "duration": 3.521
    },
    {
      "lang": "en",
      "text": "1960sish",
      "offset": 664.32,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "era where LLM compute is still very",
      "offset": 665.92,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "expensive for this new kind of a",
      "offset": 669.04,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "computer and that forces the LLMs to be",
      "offset": 670.72,
      "duration": 5.119
    },
    {
      "lang": "en",
      "text": "centralized in the cloud and we're all",
      "offset": 673.44,
      "duration": 4.959
    },
    {
      "lang": "en",
      "text": "just uh sort of thing clients that",
      "offset": 675.839,
      "duration": 4.481
    },
    {
      "lang": "en",
      "text": "interact with it over the network and",
      "offset": 678.399,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "none of us have full utilization of",
      "offset": 680.32,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "these computers and therefore it makes",
      "offset": 682.079,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "sense to use time sharing where we're",
      "offset": 684.16,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "all just you know a dimension of the",
      "offset": 686.399,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "batch when they're running the computer",
      "offset": 688.32,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "in the cloud. And this is very much what",
      "offset": 690,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "computers used to look like at during",
      "offset": 692,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "this time. The operating systems were in",
      "offset": 693.44,
      "duration": 2.72
    },
    {
      "lang": "en",
      "text": "the cloud. Everything was streamed",
      "offset": 695.04,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "around and there was batching. And so",
      "offset": 696.16,
      "duration": 5.359
    },
    {
      "lang": "en",
      "text": "the p the personal computing revolution",
      "offset": 699.6,
      "duration": 3.359
    },
    {
      "lang": "en",
      "text": "hasn't happened yet because it's just",
      "offset": 701.519,
      "duration": 3.041
    },
    {
      "lang": "en",
      "text": "not economical. It doesn't make sense.",
      "offset": 702.959,
      "duration": 3.761
    },
    {
      "lang": "en",
      "text": "But I think some people are trying. And",
      "offset": 704.56,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "it turns out that Mac minis, for",
      "offset": 706.72,
      "duration": 3.679
    },
    {
      "lang": "en",
      "text": "example, are a very good fit for some of",
      "offset": 708.399,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "the LLMs because it's all if you're",
      "offset": 710.399,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "doing batch one inference, this is all",
      "offset": 712.32,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "super memory bound. So this actually",
      "offset": 713.839,
      "duration": 3.041
    },
    {
      "lang": "en",
      "text": "works.",
      "offset": 715.36,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "And uh I think these are some early",
      "offset": 716.88,
      "duration": 3.519
    },
    {
      "lang": "en",
      "text": "indications maybe of personal computing.",
      "offset": 718.72,
      "duration": 3.359
    },
    {
      "lang": "en",
      "text": "Uh but this hasn't really happened yet.",
      "offset": 720.399,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "It's not clear what this looks like.",
      "offset": 722.079,
      "duration": 3.121
    },
    {
      "lang": "en",
      "text": "Maybe some of you get to invent what",
      "offset": 723.519,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "what this is or how it works or uh what",
      "offset": 725.2,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "this should what this should be. Maybe",
      "offset": 728.079,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "one more analogy that I'll mention is",
      "offset": 730.32,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "whenever I talk to Chach or some LLM",
      "offset": 732.16,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "directly in text, I feel like I'm",
      "offset": 734.56,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "talking to an operating system through",
      "offset": 736.48,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "the terminal. Like it's just it's it's",
      "offset": 738.399,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "text. It's direct access to the",
      "offset": 741.04,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "operating system. And I think a guey",
      "offset": 742.639,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "hasn't yet really been invented in like",
      "offset": 744.72,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "a general way like should chatt have a",
      "offset": 746.72,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "guey like different than just a tech",
      "offset": 749.68,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "bubbles. Uh certainly some of the apps",
      "offset": 751.44,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "that we're going to go into in a bit",
      "offset": 753.44,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "have guey but there's no like guey",
      "offset": 755.36,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "across all the tasks if that makes",
      "offset": 758.48,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "sense. Um there are some ways in which",
      "offset": 760.24,
      "duration": 5.279
    },
    {
      "lang": "en",
      "text": "LLMs are different from kind of",
      "offset": 763.44,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "operating systems in some fairly unique",
      "offset": 765.519,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "way and from early computing. And I",
      "offset": 767.44,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "wrote about uh this one particular",
      "offset": 769.839,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "property that strikes me as very",
      "offset": 772.88,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "different uh this time around. It's that",
      "offset": 774.24,
      "duration": 5.599
    },
    {
      "lang": "en",
      "text": "LLMs like flip they flip the direction",
      "offset": 777.12,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "of technology diffusion uh that is",
      "offset": 779.839,
      "duration": 5.521
    },
    {
      "lang": "en",
      "text": "usually uh present in technology. So for",
      "offset": 782,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "example with electricity, cryptography,",
      "offset": 785.36,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "computing, flight, internet, GPS, lots",
      "offset": 787.04,
      "duration": 3.599
    },
    {
      "lang": "en",
      "text": "of new transformative technologies that",
      "offset": 789.12,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "have not been around. Typically it is",
      "offset": 790.639,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "the government and corporations that are",
      "offset": 792.32,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "the first users because it's new and",
      "offset": 794.32,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "expensive etc. and it only later",
      "offset": 796.72,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "diffuses to consumer. Uh, but I feel",
      "offset": 798.72,
      "duration": 3.359
    },
    {
      "lang": "en",
      "text": "like LLMs are kind of like flipped",
      "offset": 800.72,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "around. So maybe with early computers,",
      "offset": 802.079,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "it was all about ballistics and military",
      "offset": 804,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "use, but with LLMs, it's all about how",
      "offset": 806,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "do you boil an egg or something like",
      "offset": 809.04,
      "duration": 2.96
    },
    {
      "lang": "en",
      "text": "that. This is certainly like a lot of my",
      "offset": 810.32,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "use. And so it's really fascinating to",
      "offset": 812,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "me that we have a new magical computer",
      "offset": 813.6,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "and it's like helping me boil an egg.",
      "offset": 815.6,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "It's not helping the government do",
      "offset": 817.36,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "something really crazy like some",
      "offset": 818.88,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "military ballistics or some special",
      "offset": 820.72,
      "duration": 3.119
    },
    {
      "lang": "en",
      "text": "technology. Indeed, corporations are",
      "offset": 822.16,
      "duration": 2.96
    },
    {
      "lang": "en",
      "text": "governments are lagging behind the",
      "offset": 823.839,
      "duration": 3.361
    },
    {
      "lang": "en",
      "text": "adoption of all of us, of all of these",
      "offset": 825.12,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "technologies. So, it's just backwards",
      "offset": 827.2,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "and I think it informs maybe some of the",
      "offset": 828.959,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "uses of how we want to use this",
      "offset": 830.48,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "technology or like where are some of the",
      "offset": 832.399,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "first apps and so on.",
      "offset": 833.6,
      "duration": 7.44
    },
    {
      "lang": "en",
      "text": "So, in summary so far, LLM labs LLMs. I",
      "offset": 836.079,
      "duration": 7.601
    },
    {
      "lang": "en",
      "text": "think it's accurate language to use, but",
      "offset": 841.04,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "LLMs are complicated operating systems.",
      "offset": 843.68,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "They're circa 1960s in computing and",
      "offset": 846.48,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "we're redoing computing all over again.",
      "offset": 848.56,
      "duration": 3.279
    },
    {
      "lang": "en",
      "text": "and they're currently available via time",
      "offset": 850.24,
      "duration": 3.599
    },
    {
      "lang": "en",
      "text": "sharing and distributed like a utility.",
      "offset": 851.839,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "What is new and unprecedented is that",
      "offset": 853.839,
      "duration": 3.521
    },
    {
      "lang": "en",
      "text": "they're not in the hands of a few",
      "offset": 856,
      "duration": 2.88
    },
    {
      "lang": "en",
      "text": "governments and corporations. They're in",
      "offset": 857.36,
      "duration": 2.88
    },
    {
      "lang": "en",
      "text": "the hands of all of us because we all",
      "offset": 858.88,
      "duration": 2.72
    },
    {
      "lang": "en",
      "text": "have a computer and it's all just",
      "offset": 860.24,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "software and Chaship was beamed down to",
      "offset": 861.6,
      "duration": 5.039
    },
    {
      "lang": "en",
      "text": "our computers like billions of people",
      "offset": 864.32,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "like instantly and overnight and this is",
      "offset": 866.639,
      "duration": 4.241
    },
    {
      "lang": "en",
      "text": "insane. Uh and it's kind of insane to me",
      "offset": 868.32,
      "duration": 4.959
    },
    {
      "lang": "en",
      "text": "that this is the case and now it is our",
      "offset": 870.88,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "time to enter the industry and program",
      "offset": 873.279,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "these computers. This is crazy. So I",
      "offset": 874.959,
      "duration": 4.721
    },
    {
      "lang": "en",
      "text": "think this is quite remarkable. Before",
      "offset": 877.279,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "we program LLMs, we have to kind of like",
      "offset": 879.68,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "spend some time to think about what",
      "offset": 882.079,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "these things are. And I especially like",
      "offset": 883.519,
      "duration": 4.801
    },
    {
      "lang": "en",
      "text": "to kind of talk about their psychology.",
      "offset": 885.839,
      "duration": 4.641
    },
    {
      "lang": "en",
      "text": "So the way I like to think about LLMs is",
      "offset": 888.32,
      "duration": 3.199
    },
    {
      "lang": "en",
      "text": "that they're kind of like people",
      "offset": 890.48,
      "duration": 3.599
    },
    {
      "lang": "en",
      "text": "spirits. Um they are stoastic",
      "offset": 891.519,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "simulations of people. Um and the",
      "offset": 894.079,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "simulator in this case happens to be an",
      "offset": 896.399,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "auto reggressive transformer. So",
      "offset": 898,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "transformer is a neural net. Uh it's and",
      "offset": 899.839,
      "duration": 4.961
    },
    {
      "lang": "en",
      "text": "it just kind of like is goes on the",
      "offset": 902.72,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "level of tokens. It goes chunk chunk",
      "offset": 904.8,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "chunk chunk chunk. And there's an almost",
      "offset": 906.48,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "equal amount of compute for every single",
      "offset": 908.32,
      "duration": 6.4
    },
    {
      "lang": "en",
      "text": "chunk. Um and um this simulator of",
      "offset": 910.16,
      "duration": 6.799
    },
    {
      "lang": "en",
      "text": "course is is just is basically there's",
      "offset": 914.72,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "some weights involved and we fit it to",
      "offset": 916.959,
      "duration": 3.521
    },
    {
      "lang": "en",
      "text": "all of text that we have on the internet",
      "offset": 919.04,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "and so on. And you end up with this kind",
      "offset": 920.48,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "of a simulator and because it is trained",
      "offset": 922.16,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "on humans, it's got this emergent",
      "offset": 924.24,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "psychology that is humanlike. So the",
      "offset": 926.24,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "first thing you'll notice is of course",
      "offset": 928.399,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "uh LLM have encyclopedic knowledge and",
      "offset": 930.639,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "memory. uh and they can remember lots of",
      "offset": 932.56,
      "duration": 3.519
    },
    {
      "lang": "en",
      "text": "things, a lot more than any single",
      "offset": 934.639,
      "duration": 2.961
    },
    {
      "lang": "en",
      "text": "individual human can because they read",
      "offset": 936.079,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "so many things. It's it actually kind of",
      "offset": 937.6,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "reminds me of this movie Rainman, which",
      "offset": 939.839,
      "duration": 3.201
    },
    {
      "lang": "en",
      "text": "I actually really recommend people",
      "offset": 941.68,
      "duration": 2.8
    },
    {
      "lang": "en",
      "text": "watch. It's an amazing movie. I love",
      "offset": 943.04,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "this movie. Um and Dustin Hoffman here",
      "offset": 944.48,
      "duration": 4.719
    },
    {
      "lang": "en",
      "text": "is an autistic savant who has almost",
      "offset": 946.72,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "perfect memory. So, he can read a he can",
      "offset": 949.199,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "read like a phone book and remember all",
      "offset": 951.6,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "of the names and phone numbers. And I",
      "offset": 953.279,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "kind of feel like LM are kind of like",
      "offset": 955.36,
      "duration": 3.599
    },
    {
      "lang": "en",
      "text": "very similar. They can remember Shaw",
      "offset": 957.199,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "hashes and lots of different kinds of",
      "offset": 958.959,
      "duration": 3.521
    },
    {
      "lang": "en",
      "text": "things very very easily. So they",
      "offset": 960.399,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "certainly have superpowers in some set",
      "offset": 962.48,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "in some respects. But they also have a",
      "offset": 964.399,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "bunch of I would say cognitive deficits.",
      "offset": 966.24,
      "duration": 5.519
    },
    {
      "lang": "en",
      "text": "So they hallucinate quite a bit. Um and",
      "offset": 968.8,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "they kind of make up stuff and don't",
      "offset": 971.759,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "have a very good uh sort of internal",
      "offset": 973.12,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "model of self-nowledge, not sufficient",
      "offset": 975.279,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "at least. And this has gotten better but",
      "offset": 977.68,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "not perfect. They display jagged",
      "offset": 979.36,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "intelligence. So they're going to be",
      "offset": 981.6,
      "duration": 2.88
    },
    {
      "lang": "en",
      "text": "superhuman in some problems solving",
      "offset": 982.8,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "domains. And then they're going to make",
      "offset": 984.48,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "mistakes that basically no human will",
      "offset": 986,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "make. like you know they will insist",
      "offset": 987.68,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "that 9.11 is greater than 9.9 or that",
      "offset": 989.92,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "there are two Rs in strawberry these are",
      "offset": 992.56,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "some famous examples but basically there",
      "offset": 994.24,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "are rough edges that you can trip on so",
      "offset": 996.16,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "that's kind of I think also kind of",
      "offset": 998.88,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "unique um they also kind of suffer from",
      "offset": 1000.32,
      "duration": 6.56
    },
    {
      "lang": "en",
      "text": "entrograde amnesia um so uh and I think",
      "offset": 1003.279,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "I'm alluding to the fact that if you",
      "offset": 1006.88,
      "duration": 2.399
    },
    {
      "lang": "en",
      "text": "have a co-orker who joins your",
      "offset": 1008.079,
      "duration": 3.361
    },
    {
      "lang": "en",
      "text": "organization this co-orker will over",
      "offset": 1009.279,
      "duration": 4.881
    },
    {
      "lang": "en",
      "text": "time learn your organization and uh they",
      "offset": 1011.44,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "will understand and gain like a huge",
      "offset": 1014.16,
      "duration": 3.599
    },
    {
      "lang": "en",
      "text": "amount of context on the organization",
      "offset": 1015.92,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "and they go home and they sleep and they",
      "offset": 1017.759,
      "duration": 3.361
    },
    {
      "lang": "en",
      "text": "consolidate knowledge and they develop",
      "offset": 1019.6,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "expertise over time. LLMs don't natively",
      "offset": 1021.12,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "do this and this is not something that",
      "offset": 1023.44,
      "duration": 2.96
    },
    {
      "lang": "en",
      "text": "has really been solved in the R&amp;D of",
      "offset": 1024.64,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "LLM. I think um and so context windows",
      "offset": 1026.4,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "are really kind of like working memory",
      "offset": 1029.28,
      "duration": 2.72
    },
    {
      "lang": "en",
      "text": "and you have to sort of program the",
      "offset": 1030.559,
      "duration": 3.041
    },
    {
      "lang": "en",
      "text": "working memory quite directly because",
      "offset": 1032,
      "duration": 3.039
    },
    {
      "lang": "en",
      "text": "they don't just kind of like get smarter",
      "offset": 1033.6,
      "duration": 3.439
    },
    {
      "lang": "en",
      "text": "by uh by default and I think a lot of",
      "offset": 1035.039,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "people get tripped up by the analogies",
      "offset": 1037.039,
      "duration": 5.201
    },
    {
      "lang": "en",
      "text": "uh in this way. Uh in popular culture I",
      "offset": 1039.039,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "recommend people watch these two movies",
      "offset": 1042.24,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "uh Momento and 51st dates. In both of",
      "offset": 1043.919,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "these movies, the protagonists, their",
      "offset": 1046.079,
      "duration": 3.761
    },
    {
      "lang": "en",
      "text": "weights are fixed and their context",
      "offset": 1047.76,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "windows gets wiped every single morning",
      "offset": 1049.84,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "and it's really problematic to go to",
      "offset": 1052.16,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "work or have relationships when this",
      "offset": 1054.24,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "happens and this happens to all the",
      "offset": 1055.76,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "time. I guess one more thing I would",
      "offset": 1057.52,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "point to is security kind of related",
      "offset": 1059.6,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "limitations of the use of LLM. So for",
      "offset": 1062.32,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "example, LLMs are quite gullible. Uh",
      "offset": 1064.32,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "they are susceptible to prompt injection",
      "offset": 1066.4,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "risks. They might leak your data etc.",
      "offset": 1068.24,
      "duration": 4.559
    },
    {
      "lang": "en",
      "text": "And so um and there's many other",
      "offset": 1070.799,
      "duration": 4.481
    },
    {
      "lang": "en",
      "text": "considerations uh security related. So,",
      "offset": 1072.799,
      "duration": 4.721
    },
    {
      "lang": "en",
      "text": "so basically long story short, you have",
      "offset": 1075.28,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "to load your you have to load your you",
      "offset": 1077.52,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "have to simultaneously think through",
      "offset": 1080,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "this superhuman thing that has a bunch",
      "offset": 1081.28,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "of cognitive deficits and issues. How do",
      "offset": 1083.2,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "we and yet they are extremely like",
      "offset": 1085.44,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "useful and so how do we program them and",
      "offset": 1087.76,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "how do we work around their deficits and",
      "offset": 1090.64,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "enjoy their superhuman powers.",
      "offset": 1092.4,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "So what I want to switch to now is talk",
      "offset": 1095.76,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "about the opportunities of how do we use",
      "offset": 1097.44,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "these models and what are some of the",
      "offset": 1098.96,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "biggest opportunities. This is not a",
      "offset": 1100.72,
      "duration": 2.8
    },
    {
      "lang": "en",
      "text": "comprehensive list just some of the",
      "offset": 1102.4,
      "duration": 2.24
    },
    {
      "lang": "en",
      "text": "things that I thought were interesting",
      "offset": 1103.52,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "for this talk. The first thing I'm kind",
      "offset": 1104.64,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "of excited about is what I would call",
      "offset": 1106.88,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "partial autonomy apps. So for example,",
      "offset": 1109.28,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "let's work with the example of coding.",
      "offset": 1112.16,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "You can certainly go to chacht directly",
      "offset": 1114.24,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "and you can start copy pasting code",
      "offset": 1116.559,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "around and copyping bug reports and",
      "offset": 1118.08,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "stuff around and getting code and copy",
      "offset": 1120.96,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "pasting everything around. Why would you",
      "offset": 1122.4,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "why would you do that? Why would you go",
      "offset": 1124.16,
      "duration": 2.96
    },
    {
      "lang": "en",
      "text": "directly to the operating system? It",
      "offset": 1125.44,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "makes a lot more sense to have an app",
      "offset": 1127.12,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "dedicated for this. And so I think many",
      "offset": 1128.48,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "of you uh use uh cursor. I do as well.",
      "offset": 1130.72,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "And uh cursor is kind of like the thing",
      "offset": 1133.76,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "you want instead. You don't want to just",
      "offset": 1136.32,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "directly go to the chash apt. And I",
      "offset": 1137.76,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "think cursor is a very good example of",
      "offset": 1139.76,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "an early LLM app that has a bunch of",
      "offset": 1141.44,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "properties that I think are um useful",
      "offset": 1143.76,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "across all the LLM apps. So in",
      "offset": 1146.16,
      "duration": 3.519
    },
    {
      "lang": "en",
      "text": "particular, you will notice that we have",
      "offset": 1148,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "a traditional interface that allows a",
      "offset": 1149.679,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "human to go in and do all the work",
      "offset": 1152,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "manually just as before. But in addition",
      "offset": 1153.84,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "to that, we now have this LLM",
      "offset": 1156.48,
      "duration": 2.88
    },
    {
      "lang": "en",
      "text": "integration that allows us to go in",
      "offset": 1157.84,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "bigger chunks. And so some of the",
      "offset": 1159.36,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "properties of LLM apps that I think are",
      "offset": 1161.919,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "shared and useful to point out. Number",
      "offset": 1163.52,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "one, the LLMs basically do a ton of the",
      "offset": 1165.84,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "context management. Um, number two, they",
      "offset": 1168.08,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "orchestrate multiple calls to LLMs,",
      "offset": 1171.2,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "right? So in the case of cursor, there's",
      "offset": 1173.2,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "under the hood embedding models for all",
      "offset": 1174.96,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "your files, the actual chat models,",
      "offset": 1176.96,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "models that apply diffs to the code, and",
      "offset": 1179.2,
      "duration": 4.719
    },
    {
      "lang": "en",
      "text": "this is all orchestrated for you. A",
      "offset": 1181.84,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "really big one that uh I think also",
      "offset": 1183.919,
      "duration": 4.561
    },
    {
      "lang": "en",
      "text": "maybe not fully appreciated always is",
      "offset": 1186.08,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "application specific uh GUI and the",
      "offset": 1188.48,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "importance of it. Um because you don't",
      "offset": 1190.48,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "just want to talk to the operating",
      "offset": 1193.12,
      "duration": 3.439
    },
    {
      "lang": "en",
      "text": "system directly in text. Text is very",
      "offset": 1194.559,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "hard to read, interpret, understand and",
      "offset": 1196.559,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "also like you don't want to take some of",
      "offset": 1199.039,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "these actions natively in text. So it's",
      "offset": 1200.48,
      "duration": 4.559
    },
    {
      "lang": "en",
      "text": "much better to just see a diff as like",
      "offset": 1203.12,
      "duration": 3.679
    },
    {
      "lang": "en",
      "text": "red and green change and you can see",
      "offset": 1205.039,
      "duration": 3.441
    },
    {
      "lang": "en",
      "text": "what's being added is subtracted. It's",
      "offset": 1206.799,
      "duration": 3.441
    },
    {
      "lang": "en",
      "text": "much easier to just do command Y to",
      "offset": 1208.48,
      "duration": 3.439
    },
    {
      "lang": "en",
      "text": "accept or command N to reject. I",
      "offset": 1210.24,
      "duration": 2.88
    },
    {
      "lang": "en",
      "text": "shouldn't have to type it in text,",
      "offset": 1211.919,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "right? So, a guey allows a human to",
      "offset": 1213.12,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "audit the work of these fallible systems",
      "offset": 1215.52,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "and to go faster. I'm going to come back",
      "offset": 1217.84,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "to this point a little bit uh later as",
      "offset": 1220,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "well. And the last kind of feature I",
      "offset": 1221.76,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "want to point out is that there's what I",
      "offset": 1223.84,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "call the autonomy slider. So, for",
      "offset": 1225.2,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "example, in cursor, you can just do tap",
      "offset": 1227.679,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "completion. You're mostly in charge. You",
      "offset": 1229.44,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "can select a chunk of code and command K",
      "offset": 1231.52,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "to change just that chunk of code. You",
      "offset": 1233.6,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "can do command L to change the entire",
      "offset": 1236,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "file. Or you can do command I which just",
      "offset": 1237.919,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "you know let it rip do whatever you want",
      "offset": 1240.4,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "in the entire repo and that's the sort",
      "offset": 1242.159,
      "duration": 4.241
    },
    {
      "lang": "en",
      "text": "of full autonomy agent agentic version",
      "offset": 1244.08,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "and so you are in charge of the autonomy",
      "offset": 1246.4,
      "duration": 3.759
    },
    {
      "lang": "en",
      "text": "slider and depending on the complexity",
      "offset": 1248.32,
      "duration": 4.719
    },
    {
      "lang": "en",
      "text": "of the task at hand you can uh tune the",
      "offset": 1250.159,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "amount of autonomy that you're willing",
      "offset": 1253.039,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "to give up uh for that task maybe to",
      "offset": 1254.32,
      "duration": 4.239
    },
    {
      "lang": "en",
      "text": "show one more example of a fairly",
      "offset": 1257.12,
      "duration": 5.919
    },
    {
      "lang": "en",
      "text": "successful LLM app uh perplexity um it",
      "offset": 1258.559,
      "duration": 6.081
    },
    {
      "lang": "en",
      "text": "also has very similar features to what",
      "offset": 1263.039,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "I've just pointed out to in cursor uh it",
      "offset": 1264.64,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "packages up a lot of the information. It",
      "offset": 1267.2,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "orchestrates multiple LLMs. It's got a",
      "offset": 1268.72,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "GUI that allows you to audit some of its",
      "offset": 1270.96,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "work. So, for example, it will site",
      "offset": 1273.44,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "sources and you can imagine inspecting",
      "offset": 1275.6,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "them. And it's got an autonomy slider.",
      "offset": 1277.28,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "You can either just do a quick search or",
      "offset": 1278.96,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "you can do research or you can do deep",
      "offset": 1280.64,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "research and come back 10 minutes later.",
      "offset": 1282.32,
      "duration": 3.359
    },
    {
      "lang": "en",
      "text": "So, this is all just varying levels of",
      "offset": 1284.32,
      "duration": 3.359
    },
    {
      "lang": "en",
      "text": "autonomy that you give up to the tool.",
      "offset": 1285.679,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "So, I guess my question is I feel like a",
      "offset": 1287.679,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "lot of software will become partially",
      "offset": 1290.159,
      "duration": 3.361
    },
    {
      "lang": "en",
      "text": "autonomous. I'm trying to think through",
      "offset": 1292,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "like what does that look like? And for",
      "offset": 1293.52,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "many of you who maintain products and",
      "offset": 1295.28,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "services, how are you going to make your",
      "offset": 1296.96,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "products and services partially",
      "offset": 1298.96,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "autonomous? Can an LLM see everything",
      "offset": 1300.24,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "that a human can see? Can an LLM act in",
      "offset": 1302.72,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "all the ways that a human could act? And",
      "offset": 1305.12,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "can humans supervise and stay in the",
      "offset": 1307.039,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "loop of this activity? Because again,",
      "offset": 1309.44,
      "duration": 2.88
    },
    {
      "lang": "en",
      "text": "these are fallible systems that aren't",
      "offset": 1310.88,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "yet perfect. And what does a diff look",
      "offset": 1312.32,
      "duration": 4.239
    },
    {
      "lang": "en",
      "text": "like in Photoshop or something like",
      "offset": 1314.88,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "that? You know, and also a lot of the",
      "offset": 1316.559,
      "duration": 3.521
    },
    {
      "lang": "en",
      "text": "traditional software right now, it has",
      "offset": 1318.799,
      "duration": 3.041
    },
    {
      "lang": "en",
      "text": "all these switches and all this kind of",
      "offset": 1320.08,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "stuff that's all designed for human. All",
      "offset": 1321.84,
      "duration": 2.88
    },
    {
      "lang": "en",
      "text": "of this has to change and become",
      "offset": 1323.36,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "accessible to LLMs.",
      "offset": 1324.72,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "So, one thing I want to stress with a",
      "offset": 1327.76,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "lot of these LLM apps that I'm not sure",
      "offset": 1329.52,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "gets as much attention as it should is",
      "offset": 1331.12,
      "duration": 5.679
    },
    {
      "lang": "en",
      "text": "um we we're now kind of like cooperating",
      "offset": 1334.24,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "with AIS and usually they are doing the",
      "offset": 1336.799,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "generation and we as humans are doing",
      "offset": 1338.64,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "the verification. It is in our interest",
      "offset": 1340.159,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "to make this loop go as fast as",
      "offset": 1342.559,
      "duration": 3.201
    },
    {
      "lang": "en",
      "text": "possible. So, we're getting a lot of",
      "offset": 1344.48,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "work done. There are two major ways that",
      "offset": 1345.76,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "I think uh this can be done. Number one,",
      "offset": 1348,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "you can speed up verification a lot. Um,",
      "offset": 1350.4,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "and I think guies, for example, are",
      "offset": 1352.72,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "extremely important to this because a",
      "offset": 1354.24,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "guey utilizes your computer vision GPU",
      "offset": 1356.08,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "in all of our head. Reading text is",
      "offset": 1359.28,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "effortful and it's not fun, but looking",
      "offset": 1361.36,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "at stuff is fun and it's it's just a",
      "offset": 1363.2,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "kind of like a highway to your brain.",
      "offset": 1365.76,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "So, I think guies are very useful for",
      "offset": 1367.44,
      "duration": 4.239
    },
    {
      "lang": "en",
      "text": "auditing systems and visual",
      "offset": 1369.679,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "representations in general. And number",
      "offset": 1371.679,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "two, I would say is we have to keep the",
      "offset": 1373.6,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "AI on the leash. We I think a lot of",
      "offset": 1376.08,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "people are getting way over excited with",
      "offset": 1378.88,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "AI agents and uh it's not useful to me",
      "offset": 1380.64,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "to get a diff of 10,000 lines of code to",
      "offset": 1383.6,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "my repo. Like I have to I'm still the",
      "offset": 1385.84,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "bottleneck, right? Even though that",
      "offset": 1387.919,
      "duration": 3.201
    },
    {
      "lang": "en",
      "text": "10,00 lines come out instantly, I have",
      "offset": 1389.2,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "to make sure that this thing is not",
      "offset": 1391.12,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "introducing bugs. It's just like and",
      "offset": 1392.24,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "that it's doing the correct thing,",
      "offset": 1395.36,
      "duration": 2.48
    },
    {
      "lang": "en",
      "text": "right? And that there's no security",
      "offset": 1396.559,
      "duration": 6.321
    },
    {
      "lang": "en",
      "text": "issues and so on. So um I think that um",
      "offset": 1397.84,
      "duration": 7.6
    },
    {
      "lang": "en",
      "text": "yeah basically you we have to sort of",
      "offset": 1402.88,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "like it's in our interest to make the",
      "offset": 1405.44,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "the flow of these two go very very fast",
      "offset": 1408.24,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "and we have to somehow keep the AI on",
      "offset": 1410.32,
      "duration": 2.8
    },
    {
      "lang": "en",
      "text": "the leash because it gets way too",
      "offset": 1412.159,
      "duration": 3.121
    },
    {
      "lang": "en",
      "text": "overreactive. It's uh it's kind of like",
      "offset": 1413.12,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "this. This is how I feel when I do AI",
      "offset": 1415.28,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "assisted coding. If I'm just bite coding",
      "offset": 1417.28,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "everything is nice and great but if I'm",
      "offset": 1419.2,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "actually trying to get work done it's",
      "offset": 1420.88,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "not so great to have an overreactive uh",
      "offset": 1422.4,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "agent doing all this kind of stuff. So",
      "offset": 1424.72,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "this slide is not very good. I'm sorry,",
      "offset": 1427.28,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "but I guess I'm trying to develop like",
      "offset": 1428.799,
      "duration": 5.041
    },
    {
      "lang": "en",
      "text": "many of you some ways of utilizing these",
      "offset": 1431.12,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "agents in my coding workflow and to do",
      "offset": 1433.84,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "AI assisted coding. And in my own work,",
      "offset": 1435.76,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "I'm always scared to get way too big",
      "offset": 1438.08,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "diffs. I always go in small incremental",
      "offset": 1439.84,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "chunks. I want to make sure that",
      "offset": 1442.24,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "everything is good. I want to spin this",
      "offset": 1444.159,
      "duration": 4.961
    },
    {
      "lang": "en",
      "text": "loop very very fast and um I sort of",
      "offset": 1446.159,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "work on small chunks of single concrete",
      "offset": 1449.12,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "thing. Uh and so I think many of you",
      "offset": 1450.799,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "probably are developing similar ways of",
      "offset": 1453.2,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "working with the with LLMs.",
      "offset": 1454.64,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "Um, I also saw a number of blog posts",
      "offset": 1457.6,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "that try to develop these best practices",
      "offset": 1459.6,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "for working with LLMs. And here's one",
      "offset": 1462.24,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "that I read recently and I thought was",
      "offset": 1464,
      "duration": 2.799
    },
    {
      "lang": "en",
      "text": "quite good. And it kind of discussed",
      "offset": 1465.36,
      "duration": 2.88
    },
    {
      "lang": "en",
      "text": "some techniques and some of them have to",
      "offset": 1466.799,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "do with how you keep the AI on the",
      "offset": 1468.24,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "leash. And so, as an example, if you are",
      "offset": 1469.919,
      "duration": 5.041
    },
    {
      "lang": "en",
      "text": "prompting, if your prompt is vague, then",
      "offset": 1472,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "uh the AI might not do exactly what you",
      "offset": 1474.96,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "wanted and in that case, verification",
      "offset": 1476.96,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "will fail. You're going to ask for",
      "offset": 1478.88,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "something else. If a verification fails,",
      "offset": 1480.24,
      "duration": 3.439
    },
    {
      "lang": "en",
      "text": "then you're going to start spinning. So",
      "offset": 1482.08,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "it makes a lot more sense to spend a bit",
      "offset": 1483.679,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "more time to be more concrete in your",
      "offset": 1485.12,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "prompts which increases the probability",
      "offset": 1486.799,
      "duration": 3.441
    },
    {
      "lang": "en",
      "text": "of successful verification and you can",
      "offset": 1488.48,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "move forward. And so I think a lot of us",
      "offset": 1490.24,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "are going to end up finding um kind of",
      "offset": 1492.08,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "techniques like this. I think in my own",
      "offset": 1494.08,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "work as well I'm currently interested in",
      "offset": 1496.32,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "uh what education looks like in um",
      "offset": 1497.84,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "together with kind of like now that we",
      "offset": 1500.08,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "have AI uh and LLMs what does education",
      "offset": 1501.84,
      "duration": 5.199
    },
    {
      "lang": "en",
      "text": "look like? And I think a a large amount",
      "offset": 1504.48,
      "duration": 5.199
    },
    {
      "lang": "en",
      "text": "of thought for me goes into how we keep",
      "offset": 1507.039,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "AI on the leash. I don't think it just",
      "offset": 1509.679,
      "duration": 3.521
    },
    {
      "lang": "en",
      "text": "works to go to chat and be like, &quot;Hey,",
      "offset": 1511.44,
      "duration": 3.359
    },
    {
      "lang": "en",
      "text": "teach me physics.&quot; I don't think this",
      "offset": 1513.2,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "works because the AI is like gets lost",
      "offset": 1514.799,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "in the woods. And so for me, this is",
      "offset": 1516.88,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "actually two separate apps. For example,",
      "offset": 1518.799,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "there's an app for a teacher that",
      "offset": 1520.88,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "creates courses and then there's an app",
      "offset": 1522.64,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "that takes courses and serves them to",
      "offset": 1524.88,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "students. And in both cases, we now have",
      "offset": 1526.48,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "this intermediate artifact of a course",
      "offset": 1529.12,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "that is auditable and we can make sure",
      "offset": 1531.2,
      "duration": 2.64
    },
    {
      "lang": "en",
      "text": "it's good. We can make sure it's",
      "offset": 1532.72,
      "duration": 3.199
    },
    {
      "lang": "en",
      "text": "consistent. and the AI is kept on the",
      "offset": 1533.84,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "leash with respect to a certain",
      "offset": 1535.919,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "syllabus, a certain like um progression",
      "offset": 1537.12,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "of projects and so on. And so this is",
      "offset": 1540.24,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "one way of keeping the AI on leash and I",
      "offset": 1542.64,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "think has a much higher likelihood of",
      "offset": 1544.159,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "working and the AI is not getting lost",
      "offset": 1545.76,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "in the woods.",
      "offset": 1547.76,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "One more kind of analogy I wanted to",
      "offset": 1549.919,
      "duration": 4.561
    },
    {
      "lang": "en",
      "text": "sort of allude to is I'm not I'm no",
      "offset": 1551.919,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "stranger to partial autonomy and I kind",
      "offset": 1554.48,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "of worked on this I think for five years",
      "offset": 1556.159,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "at Tesla and this is also a partial",
      "offset": 1557.84,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "autonomy product and shares a lot of the",
      "offset": 1560.24,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "features like for example right there in",
      "offset": 1561.919,
      "duration": 3.521
    },
    {
      "lang": "en",
      "text": "the instrument panel is the GUI of the",
      "offset": 1563.52,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "autopilot so it's showing me what the",
      "offset": 1565.44,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "what the neural network sees and so on",
      "offset": 1567.6,
      "duration": 3.199
    },
    {
      "lang": "en",
      "text": "and we have the autonomy slider where",
      "offset": 1569.2,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "over the course of my tenure there we",
      "offset": 1570.799,
      "duration": 4.801
    },
    {
      "lang": "en",
      "text": "did more and more autonomous tasks for",
      "offset": 1573.44,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "the user and maybe the story that I",
      "offset": 1575.6,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "wanted to tell very briefly is uh",
      "offset": 1578.32,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "actually the first time I drove a",
      "offset": 1581.12,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "self-driving vehicle was in 2013 and I",
      "offset": 1582.64,
      "duration": 4.639
    },
    {
      "lang": "en",
      "text": "had a friend who worked at Whimo and uh",
      "offset": 1585.2,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "he offered to give me a drive around",
      "offset": 1587.279,
      "duration": 4.241
    },
    {
      "lang": "en",
      "text": "Palo Alto. I took this picture using",
      "offset": 1589.12,
      "duration": 4.799
    },
    {
      "lang": "en",
      "text": "Google Glass at the time and many of you",
      "offset": 1591.52,
      "duration": 3.759
    },
    {
      "lang": "en",
      "text": "are so young that you might not even",
      "offset": 1593.919,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "know what that is. Uh but uh yeah, this",
      "offset": 1595.279,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "was like all the rage at the time. And",
      "offset": 1597.279,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "we got into this car and we went for",
      "offset": 1599.44,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "about a 30-minute drive around Palo Alto",
      "offset": 1600.96,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "highways uh streets and so on. And this",
      "offset": 1602.96,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "drive was perfect. There was zero",
      "offset": 1605.12,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "interventions and this was 2013 which is",
      "offset": 1606.96,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "now 12 years ago. And it kind of struck",
      "offset": 1609.84,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "me because at the time when I had this",
      "offset": 1612.48,
      "duration": 3.679
    },
    {
      "lang": "en",
      "text": "perfect drive, this perfect demo, I felt",
      "offset": 1614,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "like, wow, self-driving is imminent",
      "offset": 1616.159,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "because this just worked. This is",
      "offset": 1619.52,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "incredible. Um, but here we are 12 years",
      "offset": 1620.799,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "later and we are still working on",
      "offset": 1623.44,
      "duration": 3.599
    },
    {
      "lang": "en",
      "text": "autonomy. Um, we are still working on",
      "offset": 1624.88,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "driving agents and even now we haven't",
      "offset": 1627.039,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "actually like really solved the problem.",
      "offset": 1629.2,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "like you may see Whimos going around and",
      "offset": 1630.799,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "they look driverless but you know",
      "offset": 1632.88,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "there's still a lot of teleoperation and",
      "offset": 1634.96,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "a lot of human in the loop of a lot of",
      "offset": 1636.799,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "this driving so we still haven't even",
      "offset": 1638.72,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "like declared success but I think it's",
      "offset": 1640.96,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "definitely like going to succeed at this",
      "offset": 1642.559,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "point but it just took a long time and",
      "offset": 1644.4,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "so I think like like this is software is",
      "offset": 1646.559,
      "duration": 5.041
    },
    {
      "lang": "en",
      "text": "really tricky I think in the same way",
      "offset": 1649.36,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "that driving is tricky and so when I see",
      "offset": 1651.6,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "things like oh 2025 is the year of",
      "offset": 1654.72,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "agents I get very concerned and I kind",
      "offset": 1656.48,
      "duration": 4.559
    },
    {
      "lang": "en",
      "text": "of feel like you know this is the decade",
      "offset": 1658.72,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "of agents and this is going to be quite",
      "offset": 1661.039,
      "duration": 4.721
    },
    {
      "lang": "en",
      "text": "some time. We need humans in the loop.",
      "offset": 1664.08,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "We need to do this carefully. This is",
      "offset": 1665.76,
      "duration": 5.279
    },
    {
      "lang": "en",
      "text": "software. Let's be serious here. One",
      "offset": 1667.2,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "more kind of analogy that I always think",
      "offset": 1671.039,
      "duration": 5.041
    },
    {
      "lang": "en",
      "text": "through is the Iron Man suit. Uh I think",
      "offset": 1672.88,
      "duration": 5.279
    },
    {
      "lang": "en",
      "text": "this is I always love Iron Man. I think",
      "offset": 1676.08,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "it's like so um correct in a bunch of",
      "offset": 1678.159,
      "duration": 4.721
    },
    {
      "lang": "en",
      "text": "ways with respect to technology and how",
      "offset": 1681.36,
      "duration": 3.039
    },
    {
      "lang": "en",
      "text": "it will play out. And what I love about",
      "offset": 1682.88,
      "duration": 3.039
    },
    {
      "lang": "en",
      "text": "the Iron Man suit is that it's both an",
      "offset": 1684.399,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "augmentation and Tony Stark can drive it",
      "offset": 1685.919,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "and it's also an agent. And in some of",
      "offset": 1688.72,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "the movies, the Iron Man suit is quite",
      "offset": 1690.32,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "autonomous and can fly around and find",
      "offset": 1691.84,
      "duration": 3.439
    },
    {
      "lang": "en",
      "text": "Tony and all this kind of stuff. And so",
      "offset": 1693.6,
      "duration": 3.679
    },
    {
      "lang": "en",
      "text": "this is the autonomy slider is we can be",
      "offset": 1695.279,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "we can build augmentations or we can",
      "offset": 1697.279,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "build agents and we kind of want to do a",
      "offset": 1699.039,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "bit of both. But at this stage I would",
      "offset": 1701.2,
      "duration": 4.719
    },
    {
      "lang": "en",
      "text": "say working with fallible LLMs and so",
      "offset": 1703.44,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "on. I would say you know it's less Iron",
      "offset": 1705.919,
      "duration": 5.681
    },
    {
      "lang": "en",
      "text": "Man robots and more Iron Man suits that",
      "offset": 1709.12,
      "duration": 4.559
    },
    {
      "lang": "en",
      "text": "you want to build. It's less like",
      "offset": 1711.6,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "building flashy demos of autonomous",
      "offset": 1713.679,
      "duration": 3.041
    },
    {
      "lang": "en",
      "text": "agents and more building partial",
      "offset": 1715.12,
      "duration": 4.559
    },
    {
      "lang": "en",
      "text": "autonomy products. And these products",
      "offset": 1716.72,
      "duration": 5.199
    },
    {
      "lang": "en",
      "text": "have custom gueies and UIUX. And we're",
      "offset": 1719.679,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "trying to um and this is done so that",
      "offset": 1721.919,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "the generation verification loop of the",
      "offset": 1723.84,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "human is very very fast. But we are not",
      "offset": 1725.52,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "losing the sight of the fact that it is",
      "offset": 1728.159,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "in principle possible to automate this",
      "offset": 1729.52,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "work. And there should be an autonomy",
      "offset": 1731.279,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "slider in your product. And you should",
      "offset": 1732.96,
      "duration": 2.959
    },
    {
      "lang": "en",
      "text": "be thinking about how you can slide that",
      "offset": 1734.559,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "autonomy slider and make your product uh",
      "offset": 1735.919,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "sort of um more autonomous over time.",
      "offset": 1738.559,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "But this is kind of how I think there's",
      "offset": 1741.279,
      "duration": 2.961
    },
    {
      "lang": "en",
      "text": "lots of opportunities in these kinds of",
      "offset": 1742.72,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "products. I want to now switch gears a",
      "offset": 1744.24,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "little bit and talk about one other",
      "offset": 1746.559,
      "duration": 3.281
    },
    {
      "lang": "en",
      "text": "dimension that I think is very unique.",
      "offset": 1748.159,
      "duration": 3.281
    },
    {
      "lang": "en",
      "text": "Not only is there a new type of",
      "offset": 1749.84,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "programming language that allows for",
      "offset": 1751.44,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "autonomy in software but also as I",
      "offset": 1752.96,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "mentioned it's programmed in English",
      "offset": 1755.279,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "which is this natural interface and",
      "offset": 1756.64,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "suddenly everyone is a programmer",
      "offset": 1759.039,
      "duration": 3.201
    },
    {
      "lang": "en",
      "text": "because everyone speaks natural language",
      "offset": 1760.559,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "like English. So this is extremely",
      "offset": 1762.24,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "bullish and very interesting to me and",
      "offset": 1764.64,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "also completely unprecedented. I would",
      "offset": 1766.159,
      "duration": 3.361
    },
    {
      "lang": "en",
      "text": "say it it used to be the case that you",
      "offset": 1768,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "need to spend five to 10 years studying",
      "offset": 1769.52,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "something to be able to do something in",
      "offset": 1771.44,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "software. this is not the case anymore.",
      "offset": 1772.88,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "So, I don't know if by any chance anyone",
      "offset": 1775.2,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "has heard of vibe coding.",
      "offset": 1777.12,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "Uh, this this is the tweet that kind of",
      "offset": 1780.64,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "like introduced this, but I'm told that",
      "offset": 1782.48,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "this is now like a major meme. Um, fun",
      "offset": 1784.24,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "story about this is that I've been on",
      "offset": 1786.72,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "Twitter for like 15 years or something",
      "offset": 1789.6,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "like that at this point and I still have",
      "offset": 1791.2,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "no clue which tweet will become viral",
      "offset": 1793.52,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "and which tweet like fizzles and no one",
      "offset": 1796.32,
      "duration": 4.479
    },
    {
      "lang": "en",
      "text": "cares. And I thought that this tweet was",
      "offset": 1798,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "going to be the latter. I don't know. It",
      "offset": 1800.799,
      "duration": 2.561
    },
    {
      "lang": "en",
      "text": "was just like a shower of thoughts. But",
      "offset": 1801.84,
      "duration": 3.439
    },
    {
      "lang": "en",
      "text": "this became like a total meme and I",
      "offset": 1803.36,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "really just can't tell. But I guess like",
      "offset": 1805.279,
      "duration": 3.201
    },
    {
      "lang": "en",
      "text": "it struck a chord and it gave a name to",
      "offset": 1806.72,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "something that everyone was feeling but",
      "offset": 1808.48,
      "duration": 4.799
    },
    {
      "lang": "en",
      "text": "couldn't quite say in words. So now",
      "offset": 1810.559,
      "duration": 6.72
    },
    {
      "lang": "en",
      "text": "there's a Wikipedia page and everything.",
      "offset": 1813.279,
      "duration": 5.361
    },
    {
      "lang": "en",
      "text": "This is like",
      "offset": 1817.279,
      "duration": 8.64
    },
    {
      "lang": "en",
      "text": "[Applause]",
      "offset": 1818.64,
      "duration": 8.96
    },
    {
      "lang": "en",
      "text": "yeah this is like a major contribution",
      "offset": 1825.919,
      "duration": 4.801
    },
    {
      "lang": "en",
      "text": "now or something like that. So,",
      "offset": 1827.6,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "um, so Tom Wolf from HuggingFace shared",
      "offset": 1830.72,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "this beautiful video that I really love.",
      "offset": 1832.96,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "Um,",
      "offset": 1834.96,
      "duration": 6.76
    },
    {
      "lang": "en",
      "text": "these are kids vibe coding.",
      "offset": 1837.76,
      "duration": 3.96
    },
    {
      "lang": "en",
      "text": "And I find that this is such a wholesome",
      "offset": 1842.64,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "video. Like, I love this video. Like,",
      "offset": 1844.399,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "how can you look at this video and feel",
      "offset": 1846.72,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "bad about the future? The future is",
      "offset": 1848.08,
      "duration": 4.479
    },
    {
      "lang": "en",
      "text": "great.",
      "offset": 1849.84,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "I think this will end up being like a",
      "offset": 1852.559,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "gateway drug to software development.",
      "offset": 1853.919,
      "duration": 5.281
    },
    {
      "lang": "en",
      "text": "Um, I'm not a doomer about the future of",
      "offset": 1856.64,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "the generation and I think yeah, I love",
      "offset": 1859.2,
      "duration": 5.599
    },
    {
      "lang": "en",
      "text": "this video. So, I tried by coding a",
      "offset": 1862.24,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "little bit uh as well because it's so",
      "offset": 1864.799,
      "duration": 4.561
    },
    {
      "lang": "en",
      "text": "fun. Uh, so bike coding is so great when",
      "offset": 1867.12,
      "duration": 3.679
    },
    {
      "lang": "en",
      "text": "you want to build something super duper",
      "offset": 1869.36,
      "duration": 3.039
    },
    {
      "lang": "en",
      "text": "custom that doesn't appear to exist and",
      "offset": 1870.799,
      "duration": 2.88
    },
    {
      "lang": "en",
      "text": "you just want to wing it because it's a",
      "offset": 1872.399,
      "duration": 3.121
    },
    {
      "lang": "en",
      "text": "Saturday or something like that. So, I",
      "offset": 1873.679,
      "duration": 5.041
    },
    {
      "lang": "en",
      "text": "built this uh iOS app and I don't I",
      "offset": 1875.52,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "can't actually program in Swift, but I",
      "offset": 1878.72,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "was really shocked that I was able to",
      "offset": 1880.64,
      "duration": 2.72
    },
    {
      "lang": "en",
      "text": "build like a super basic app and I'm not",
      "offset": 1881.76,
      "duration": 2.96
    },
    {
      "lang": "en",
      "text": "going to explain it. It's really uh",
      "offset": 1883.36,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "dumb, but uh I kind of like this was",
      "offset": 1884.72,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "just like a day of work and this was",
      "offset": 1887.36,
      "duration": 2.96
    },
    {
      "lang": "en",
      "text": "running on my phone like later that day",
      "offset": 1888.72,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "and I was like, &quot;Wow, this is amazing.&quot;",
      "offset": 1890.32,
      "duration": 3.599
    },
    {
      "lang": "en",
      "text": "I didn't have to like read through Swift",
      "offset": 1892.32,
      "duration": 3.599
    },
    {
      "lang": "en",
      "text": "for like five days or something like",
      "offset": 1893.919,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "that to like get started. I also",
      "offset": 1895.919,
      "duration": 4.561
    },
    {
      "lang": "en",
      "text": "vipcoded this app called Menu Genen. And",
      "offset": 1898.159,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "this is live. You can try it in",
      "offset": 1900.48,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "menu.app. And I basically had this",
      "offset": 1901.76,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "problem where I show up at a restaurant,",
      "offset": 1904.08,
      "duration": 2.56
    },
    {
      "lang": "en",
      "text": "I read through the menu, and I have no",
      "offset": 1905.44,
      "duration": 3.119
    },
    {
      "lang": "en",
      "text": "idea what any of the things are. And I",
      "offset": 1906.64,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "need pictures. So this doesn't exist. So",
      "offset": 1908.559,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "I was like, &quot;Hey, I'm going to bite code",
      "offset": 1911.6,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "it.&quot; So, um, this is what it looks like.",
      "offset": 1912.96,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "You go to menu.app,",
      "offset": 1915.919,
      "duration": 5.521
    },
    {
      "lang": "en",
      "text": "um, and, uh, you take a picture of a of",
      "offset": 1918.24,
      "duration": 5.039
    },
    {
      "lang": "en",
      "text": "a menu and then menu generates the",
      "offset": 1921.44,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "images and everyone gets $5 in credits",
      "offset": 1923.279,
      "duration": 4.721
    },
    {
      "lang": "en",
      "text": "for free when you sign up. And",
      "offset": 1926.24,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "therefore, this is a major cost center",
      "offset": 1928,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "in my life. So, this is a negative",
      "offset": 1930.48,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "negative uh, revenue app for me right",
      "offset": 1933.76,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "now.",
      "offset": 1936.24,
      "duration": 2.96
    },
    {
      "lang": "en",
      "text": "I've lost a huge amount of money on",
      "offset": 1937.84,
      "duration": 3.439
    },
    {
      "lang": "en",
      "text": "menu.",
      "offset": 1939.2,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "Okay. But the fascinating thing about",
      "offset": 1941.279,
      "duration": 6.88
    },
    {
      "lang": "en",
      "text": "menu genen for me is that the code of",
      "offset": 1943.36,
      "duration": 6.88
    },
    {
      "lang": "en",
      "text": "the v the vite coding part the code was",
      "offset": 1948.159,
      "duration": 4.561
    },
    {
      "lang": "en",
      "text": "actually the easy part of v of v coding",
      "offset": 1950.24,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "menu and most of it actually was when I",
      "offset": 1952.72,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "tried to make it real so that you can",
      "offset": 1955.12,
      "duration": 2.48
    },
    {
      "lang": "en",
      "text": "actually have authentication and",
      "offset": 1956.48,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "payments and the domain name and averal",
      "offset": 1957.6,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "deployment. This was really hard and all",
      "offset": 1959.6,
      "duration": 4.559
    },
    {
      "lang": "en",
      "text": "of this was not code. All of this devops",
      "offset": 1961.919,
      "duration": 5.201
    },
    {
      "lang": "en",
      "text": "stuff was in me in the browser clicking",
      "offset": 1964.159,
      "duration": 5.681
    },
    {
      "lang": "en",
      "text": "stuff and this was extreme slo and took",
      "offset": 1967.12,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "another week. So it was really",
      "offset": 1969.84,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "fascinating that I had the menu genen um",
      "offset": 1971.519,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "basically demo working on my laptop in a",
      "offset": 1974.64,
      "duration": 4.639
    },
    {
      "lang": "en",
      "text": "few hours and then it took me a week",
      "offset": 1977.279,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "because I was trying to make it real and",
      "offset": 1979.279,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "the reason for this is this was just",
      "offset": 1981.2,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "really annoying. Um, so for example, if",
      "offset": 1982.88,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "you try to add Google login to your web",
      "offset": 1985.6,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "page, I know this is very small, but",
      "offset": 1987.279,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "just a huge amount of instructions of",
      "offset": 1989.2,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "this clerk library telling me how to",
      "offset": 1991.679,
      "duration": 3.521
    },
    {
      "lang": "en",
      "text": "integrate this. And this is crazy. Like",
      "offset": 1993.6,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "it's telling me go to this URL, click on",
      "offset": 1995.2,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "this dropdown, choose this, go to this,",
      "offset": 1997.519,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "and click on that. And it's like telling",
      "offset": 1999.76,
      "duration": 2.88
    },
    {
      "lang": "en",
      "text": "me what to do. Like a computer is",
      "offset": 2001.2,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "telling me the actions I should be",
      "offset": 2002.64,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "taking. Like you do it. Why am I doing",
      "offset": 2004.88,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "this?",
      "offset": 2006.64,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "What the hell?",
      "offset": 2008.64,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "I had to follow all these instructions.",
      "offset": 2011.76,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "This was crazy. So I think the last part",
      "offset": 2013.84,
      "duration": 5.679
    },
    {
      "lang": "en",
      "text": "of my talk therefore focuses on can we",
      "offset": 2016.159,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "just build for agents? I don't want to",
      "offset": 2019.519,
      "duration": 4.721
    },
    {
      "lang": "en",
      "text": "do this work. Can agents do this? Thank",
      "offset": 2021.679,
      "duration": 4.641
    },
    {
      "lang": "en",
      "text": "you.",
      "offset": 2024.24,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "Okay. So roughly speaking, I think",
      "offset": 2026.32,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "there's a new category of consumer and",
      "offset": 2028.64,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "manipulator of digital information. It",
      "offset": 2030.88,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "used to be just humans through GUIs or",
      "offset": 2033.12,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "computers through APIs. And now we have",
      "offset": 2035.44,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "a completely new thing and agents are",
      "offset": 2037.519,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "they're computers but they are humanlike",
      "offset": 2040.24,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "kind of right they're people spirits",
      "offset": 2042.799,
      "duration": 2.801
    },
    {
      "lang": "en",
      "text": "there's people spirits on the internet",
      "offset": 2044.32,
      "duration": 2.4
    },
    {
      "lang": "en",
      "text": "and they need to interact with our",
      "offset": 2045.6,
      "duration": 2.72
    },
    {
      "lang": "en",
      "text": "software infrastructure like can we",
      "offset": 2046.72,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "build for them it's a new thing so as an",
      "offset": 2048.32,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "example you can have robots.txt on your",
      "offset": 2050.639,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "domain and you can instruct uh or like",
      "offset": 2052.96,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "advise I suppose um uh web crawlers on",
      "offset": 2055.119,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "how to behave on your website in the",
      "offset": 2058.32,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "same way you can have maybe lm.txt txt",
      "offset": 2059.839,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "file which is just a simple markdown",
      "offset": 2061.52,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "that's telling LLMs what this domain is",
      "offset": 2063.359,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "about and this is very readable to a to",
      "offset": 2065.679,
      "duration": 4.881
    },
    {
      "lang": "en",
      "text": "an LLM. If it had to instead get the",
      "offset": 2068.079,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "HTML of your web page and try to parse",
      "offset": 2070.56,
      "duration": 3.279
    },
    {
      "lang": "en",
      "text": "it, this is very errorprone and",
      "offset": 2072.48,
      "duration": 3.199
    },
    {
      "lang": "en",
      "text": "difficult and will screw it up and it's",
      "offset": 2073.839,
      "duration": 2.961
    },
    {
      "lang": "en",
      "text": "not going to work. So we can just",
      "offset": 2075.679,
      "duration": 2.72
    },
    {
      "lang": "en",
      "text": "directly speak to the LLM. It's worth",
      "offset": 2076.8,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "it. Um a huge amount of documentation is",
      "offset": 2078.399,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "currently written for people. So you",
      "offset": 2081.28,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "will see things like lists and bold and",
      "offset": 2082.72,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "pictures and this is not directly",
      "offset": 2085.599,
      "duration": 5.601
    },
    {
      "lang": "en",
      "text": "accessible by an LLM. So I see some of",
      "offset": 2087.76,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "the services now are transitioning a lot",
      "offset": 2091.2,
      "duration": 3.679
    },
    {
      "lang": "en",
      "text": "of the their docs to be specifically for",
      "offset": 2092.8,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "LLMs. So Versell and Stripe as an",
      "offset": 2094.879,
      "duration": 4.561
    },
    {
      "lang": "en",
      "text": "example are early movers here but there",
      "offset": 2097.04,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "are a few more that I've seen already",
      "offset": 2099.44,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "and they offer their documentation in",
      "offset": 2101.92,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "markdown. Markdown is super easy for LMS",
      "offset": 2104.16,
      "duration": 5.919
    },
    {
      "lang": "en",
      "text": "to understand. This is great. Um maybe",
      "offset": 2106.72,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "one simple example from from uh my",
      "offset": 2110.079,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "experience as well. Maybe some of you",
      "offset": 2112.32,
      "duration": 3.279
    },
    {
      "lang": "en",
      "text": "know three blue one brown. He makes",
      "offset": 2114.079,
      "duration": 5.281
    },
    {
      "lang": "en",
      "text": "beautiful animation videos on YouTube.",
      "offset": 2115.599,
      "duration": 7.04
    },
    {
      "lang": "en",
      "text": "[Applause]",
      "offset": 2119.36,
      "duration": 3.279
    },
    {
      "lang": "en",
      "text": "Yeah, I love this library. So that he",
      "offset": 2123.2,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "wrote uh Manon and I wanted to make my",
      "offset": 2125.04,
      "duration": 5.039
    },
    {
      "lang": "en",
      "text": "own and uh there's extensive",
      "offset": 2127.44,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "documentations on how to use manon and",
      "offset": 2130.079,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "so I didn't want to actually read",
      "offset": 2132.64,
      "duration": 2.719
    },
    {
      "lang": "en",
      "text": "through it. So I copy pasted the whole",
      "offset": 2134,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "thing to an LLM and I described what I",
      "offset": 2135.359,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "wanted and it just worked out of the box",
      "offset": 2137.44,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "like LLM just bcoded me an animation",
      "offset": 2139.2,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "exactly what I wanted and I was like wow",
      "offset": 2141.44,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "this is amazing. So if we can make docs",
      "offset": 2143.28,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "legible to LLMs, it's going to unlock a",
      "offset": 2145.839,
      "duration": 5.361
    },
    {
      "lang": "en",
      "text": "huge amount of um kind of use and um I",
      "offset": 2148.16,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "think this is wonderful and should",
      "offset": 2151.2,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "should happen more. The other thing I",
      "offset": 2152.4,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "wanted to point out is that you do",
      "offset": 2155.119,
      "duration": 2.561
    },
    {
      "lang": "en",
      "text": "unfortunately have to it's not just",
      "offset": 2156.24,
      "duration": 2.72
    },
    {
      "lang": "en",
      "text": "about taking your docs and making them",
      "offset": 2157.68,
      "duration": 2.96
    },
    {
      "lang": "en",
      "text": "appear in markdown. That's the easy",
      "offset": 2158.96,
      "duration": 2.96
    },
    {
      "lang": "en",
      "text": "part. We actually have to change the",
      "offset": 2160.64,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "docs because anytime your docs say click",
      "offset": 2161.92,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "this is bad. An LLM will not be able to",
      "offset": 2164.72,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "natively take this action right now. So,",
      "offset": 2166.8,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "Verscell, for example, is replacing",
      "offset": 2169.92,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "every occurrence of click with an",
      "offset": 2171.52,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "equivalent curl command that your LM",
      "offset": 2173.52,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "agent could take on your behalf. Um, and",
      "offset": 2175.359,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "so I think this is very interesting. And",
      "offset": 2178.24,
      "duration": 3.119
    },
    {
      "lang": "en",
      "text": "then, of course, there's a model context",
      "offset": 2179.76,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "protocol from Enthropic. And this is",
      "offset": 2181.359,
      "duration": 3.521
    },
    {
      "lang": "en",
      "text": "also another way, it's a protocol of",
      "offset": 2183.04,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "speaking directly to agents as this new",
      "offset": 2184.88,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "consumer and manipulator of digital",
      "offset": 2186.72,
      "duration": 2.96
    },
    {
      "lang": "en",
      "text": "information. So, I'm very bullish on",
      "offset": 2188.16,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "these ideas. The other thing I really",
      "offset": 2189.68,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "like is a number of little tools here",
      "offset": 2191.52,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "and there that are helping ingest data",
      "offset": 2193.52,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "that in like very LLM friendly formats.",
      "offset": 2196.64,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "So for example, when I go to a GitHub",
      "offset": 2198.72,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "repo like my nanoGPT repo, I can't feed",
      "offset": 2200.16,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "this to an LLM and ask questions about",
      "offset": 2202.72,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "it uh because it's you know this is a",
      "offset": 2204.32,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "human interface on GitHub. So when you",
      "offset": 2206.72,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "just change the URL from GitHub to get",
      "offset": 2208.88,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "ingest then uh this will actually",
      "offset": 2210.48,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "concatenate all the files into a single",
      "offset": 2212.32,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "giant text and it will create a",
      "offset": 2214.16,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "directory structure etc. And this is",
      "offset": 2215.92,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "ready to be copy pasted into your",
      "offset": 2217.52,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "favorite LLM and you can do stuff. Maybe",
      "offset": 2219.04,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "even more dramatic example of this is",
      "offset": 2221.52,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "deep wiki where it's not just the raw",
      "offset": 2223.44,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "content of these files. uh this is from",
      "offset": 2225.44,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "Devon but also like they have Devon",
      "offset": 2228.64,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "basically do analysis of the GitHub repo",
      "offset": 2230.96,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "and Devon basically builds up a whole",
      "offset": 2232.88,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "docs uh pages just for your repo and you",
      "offset": 2234.64,
      "duration": 5.199
    },
    {
      "lang": "en",
      "text": "can imagine that this is even more",
      "offset": 2238,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "helpful to copy paste into your LLM. So",
      "offset": 2239.839,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "I love all the little tools that",
      "offset": 2242.079,
      "duration": 2.881
    },
    {
      "lang": "en",
      "text": "basically where you just change the URL",
      "offset": 2243.44,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "and it makes something accessible to an",
      "offset": 2244.96,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "LLM. So this is all well and great and u",
      "offset": 2246.56,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "I think there should be a lot more of",
      "offset": 2249.52,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "it. One more note I wanted to make is",
      "offset": 2250.72,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "that it is absolutely possible that in",
      "offset": 2252.72,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "the future LLMs will be able to this is",
      "offset": 2255.28,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "not even future this is today they'll be",
      "offset": 2258,
      "duration": 2.8
    },
    {
      "lang": "en",
      "text": "able to go around and they'll be able to",
      "offset": 2259.599,
      "duration": 3.041
    },
    {
      "lang": "en",
      "text": "click stuff and so on but I still think",
      "offset": 2260.8,
      "duration": 5.279
    },
    {
      "lang": "en",
      "text": "it's very worth u basically meeting LLM",
      "offset": 2262.64,
      "duration": 5.92
    },
    {
      "lang": "en",
      "text": "halfway LLM's halfway and making it",
      "offset": 2266.079,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "easier for them to access all this",
      "offset": 2268.56,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "information uh because this is still",
      "offset": 2269.92,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "fairly expensive I would say to use and",
      "offset": 2271.68,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "uh a lot more difficult and so I do",
      "offset": 2274.4,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "think that lots of software there will",
      "offset": 2276.64,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "be a long tail where it won't like adapt",
      "offset": 2278.24,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "apps because these are not like live",
      "offset": 2280.64,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "player sort of repositories or digital",
      "offset": 2282.16,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "infrastructure and we will need these",
      "offset": 2284.48,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "tools. Uh but I think for everyone else",
      "offset": 2286.24,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "I think it's very worth kind of like",
      "offset": 2288.4,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "meeting in some middle point. So I'm",
      "offset": 2289.68,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "bullish on both if that makes sense.",
      "offset": 2291.76,
      "duration": 5.359
    },
    {
      "lang": "en",
      "text": "So in summary, what an amazing time to",
      "offset": 2294.64,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "get into the industry. We need to",
      "offset": 2297.119,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "rewrite a ton of code. A ton of code",
      "offset": 2298.64,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "will be written by professionals and by",
      "offset": 2300.72,
      "duration": 4.879
    },
    {
      "lang": "en",
      "text": "coders. These LLMs are kind of like",
      "offset": 2303.04,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "utilities, kind of like fabs, but",
      "offset": 2305.599,
      "duration": 3.201
    },
    {
      "lang": "en",
      "text": "they're kind of especially like",
      "offset": 2307.52,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "operating systems. But it's so early.",
      "offset": 2308.8,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "It's like 1960s of operating systems and",
      "offset": 2310.96,
      "duration": 5.119
    },
    {
      "lang": "en",
      "text": "uh and I think a lot of the analogies",
      "offset": 2314.32,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "cross over. Um and these LMS are kind of",
      "offset": 2316.079,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "like these fallible uh you know people",
      "offset": 2318.96,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "spirits that we have to learn to work",
      "offset": 2321.599,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "with. And in order to do that properly,",
      "offset": 2323.359,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "we need to adjust our infrastructure",
      "offset": 2325.599,
      "duration": 3.361
    },
    {
      "lang": "en",
      "text": "towards it. So when you're building",
      "offset": 2327.68,
      "duration": 2.96
    },
    {
      "lang": "en",
      "text": "these LLM apps, I describe some of the",
      "offset": 2328.96,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "ways of working effectively with these",
      "offset": 2330.64,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "LLMs and some of the tools that make",
      "offset": 2332.8,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "that uh kind of possible and how you can",
      "offset": 2334.72,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "spin this loop very very quickly and",
      "offset": 2337.04,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "basically create partial tunneling",
      "offset": 2339.04,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "products and then um yeah, a lot of code",
      "offset": 2340.8,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "has to also be written for the agents",
      "offset": 2343.52,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "more directly. But in any case, going",
      "offset": 2344.88,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "back to the Iron Man suit analogy, I",
      "offset": 2347.2,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "think what we'll see over the next",
      "offset": 2349.52,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "decade roughly is we're going to take",
      "offset": 2350.88,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "the slider from left to right. And I'm",
      "offset": 2352.72,
      "duration": 4.879
    },
    {
      "lang": "en",
      "text": "very interesting. It's going to be very",
      "offset": 2355.92,
      "duration": 3.439
    },
    {
      "lang": "en",
      "text": "interesting to see what that looks like.",
      "offset": 2357.599,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "And I can't wait to build it with all of",
      "offset": 2359.359,
      "duration": 6.281
    },
    {
      "lang": "en",
      "text": "you. Thank you.",
      "offset": 2361.52,
      "duration": 4.12
    }
  ],
  "cleanText": "Please welcome former director of AI, Andrej Karpathy, of Tesla.\n\n[Music]\n\nHello.\n\n[Music]\n\nWow, a lot of people here.\nHello.\nUm, okay.\nYeah.\nSo I'm excited to be here today to talk to you about software in the era of AI.\nAnd I'm told that many of you are students, like bachelors, masters, PhD, and so on.\nAnd you're about to enter the industry.\nAnd I think it's actually like an extremely unique and very interesting time to enter the industry right now.\nAnd I think fundamentally the reason for that is that, um, software is changing, uh, again.\nAnd I say again because I actually gave this talk already.\nUm, but the problem is that software keeps changing.\nSo I actually have a lot of material to create new talks, and I think it's changing quite fundamentally.\nI think, roughly speaking, software has not changed much on such a fundamental level for 70 years.\nAnd then it's changed, I think, about twice quite rapidly in the last few years.\nAnd so there's just a huge amount of work to do, a huge amount of software to write and rewrite.\nSo let's take a look at maybe the realm of software.\nSo if we kind of think of this as like the map of software, this is a really cool tool called map of GitHub.\nUm, this is kind of like all the software that's written.\nUh, these are instructions to the computer for carrying out tasks in the digital space.\nSo if you zoom in here, these are all different kinds of repositories, and this is all the code that has been written.\nAnd a few years ago, I kind of observed that, um, software was kind of changing, and there was kind of like a new type of software around, and I called this Software 2.0 at the time.\nAnd the idea here was that software 1.0 is the code you write for the computer.\nSoftware 2.0 now are basically neural networks, and in particular, the weights of a neural network, and you're not writing this code directly.\nYou are most, you are more kind of like tuning the data sets, and then you're running an optimizer to create, to create the parameters of this neural net.\nAnd I think, like, at the time, neural nets were kind of seen as like just a different kind of classifier, like a decision tree or something like that.\nAnd so I think it was kind of like, um, I think this framing was a lot more appropriate.\nAnd now actually what we have is kind of like an equivalent of GitHub in the realm of Software 2.0.\nAnd I think the hugging face is basically equivalent of GitHub in Software 2.0.\nAnd there's also model atlas, and you can visualize all the code written there.\nIn case you're curious, by the way, the giant circle, the point in the middle, uh, these are the parameters of flux, the image generator.\nAnd so anytime someone tunes a on top of a flux model, you basically create a git commit, uh, in this space, and, uh, you create a different kind of a image generator.\nSo basically what we have is software 1.0 is the computer code that programs a computer.\nSoftware 2.0 are the weights which program neural networks.\nUh, and here's an example of AlexNet image recognizer neural network.\nNow, so far, all of the neural networks that we've been familiar with until recently were kind of like fixed function computers, image to categories or something like that.\nAnd I think what's changed, and I think is a quite fundamental change, is that neural networks became programmable with large language models.\nAnd so I, I see this as quite new, unique.\nIt's a new kind of a computer, and, uh, so in my mind, it's, uh, worth giving it a new designation of Software 3.0.\nAnd basically your prompts are now programs that program the LLM.\nAnd, uh, remarkably, uh, these, uh, prompts are written in English.\nSo it's kind of a very interesting programming language.\nUm, so maybe, uh, to summarize the difference, if you're doing sentiment classification, for example, you can imagine writing some, uh, amount of Python to, to basically do sentiment classification, or you can train a neural net, or you can prompt a large language model.\nUh, so here this is a few short prompt, and you can imagine changing it and programming the computer in a slightly different way.\nSo basically we have software 1.0, software 2.0, and I think we're seeing maybe you've seen a lot of GitHub code is not just like code anymore.\nThere's a bunch of like English interspersed with code, and so I think kind of there's a growing category of new kind of code.\nSo not only is it a new programming paradigm, it's also remarkable to me that it's in our native language of English.\nAnd so when this blew my mind a few, uh, I guess years ago now, I tweeted this, and, um, I think it captured the attention of a lot of people, and this is my currently pinned tweet, uh, is that remarkably we're now programming computers in English.\nNow, when I was at, uh, Tesla, um, we were working on the, uh, autopilot, and, uh, we were trying to get the car to drive, and I sort of showed this slide at the time where you can imagine that the inputs to the car are on the bottom, and they're going through a software stack to produce the steering and acceleration.\nAnd I made the observation at the time that there was a ton of C++ code around in the autopilot, which was the software 1.0 code, and then there was some neural nets in there doing image recognition, and, uh, I kind of observed that over time as we made the autopilot better, basically the neural network grew in capability and size, and in addition to that, all the C++ code was being deleted, and kind of like was, um, and a lot of the kind of capabilities and functionality that was originally written in 1.0 was migrated to 2.0.\nSo as an example, a lot of the stitching up of information across images from the different cameras and across time was done by a neural network, and we were able to delete a lot of code.\nAnd so the software 2.0 stack quite literally ate through the software stack of the autopilot.\nSo I thought this was really remarkable at the time, and I think we're seeing the same thing again where, uh, basically we have a new kind of software, and it's eating through the stack.\nWe have three completely different programming paradigms, and I think if you're entering the industry, it's a very good idea to be fluent in all of them because they all have slight pros and cons, and you may want to program some functionality in 1.0 or 2.0 or 3.0.\nAre you going to train a neural net?\nAre you going to just prompt an LLM?\nShould this be a piece of code that's explicit, etc.?\nSo we all have to make these decisions and actually potentially, uh, fluidly transition between these paradigms.\nSo what I wanted to get into now is first, I want to, in the first part, talk about LLMs and how to kind of like think of this new paradigm and the ecosystem and what that looks like.\nUh, like what are, what is this new computer?\nWhat does it look like, and what does the ecosystem look like?\nUm, I was struck by this quote from Andrej Karpathy, actually, uh, many years ago now, I think, and I think Andrej is going to be speaking right after me.\nUh, but he said at the time, \"AI is the new electricity,\" and I do think that it, um, kind of captures something very interesting in that LLMs certainly feel like they have properties of utilities right now.\nSo, um, LLM labs, like OpenAI, Gemini, Anthropic, etc., they spend capex to train the LLMs, and this is kind of equivalent to building out a grid, and then there's opex to serve that intelligence over APIs to all of us, and this is done through metered access where we pay per million tokens or something like that.\nAnd we have a lot of demands that are very utility-like demands out of this API.\nWe demand low latency, high uptime, consistent quality, etc.\nIn electricity, you would have a transfer switch.\nSo you can transfer your electricity source from like grid and solar or battery or generator.\nIn LLM, we have maybe open router and easily switch between the different types of LLMs that exist.\nBecause the LLMs are software, they don't compete for physical space.\nSo it's okay to have basically like six electricity providers, and you can switch between them, right?\nBecause they don't compete in such a direct way.\nAnd I think what's also a little fascinating, and we saw this in the last few days actually, a lot of the LLMs went down, and people were kind of like stuck and unable to work.\nAnd, uh, I think it's kind of fascinating to me that when the state-of-the-art LLMs go down, it's actually kind of like an intelligence brownout in the world.\nIt's kind of like when the voltage is unreliable in the grid, and, uh, the planet just gets dumber the more reliance we have on these models, which already is like really dramatic, and I think will continue to grow.\nBut LLMs don't only have properties of utilities.\nI think it's also fair to say that they have some properties of fabs.\nAnd the reason for this is that the capex required for building LLM is actually quite large.\nUh, it's not just like building some, uh, power station or something like that, right?\nYou're investing a huge amount of money, and I think the tech tree and, uh, for the technology is growing quite rapidly.\nSo we're in a world where we have sort of deep tech trees, research and development secrets that are centralizing inside the LLM labs.\nUm, and but I think the analogy muddies a little bit also because as I mentioned, this is software, and software is a bit less defensible because it is so malleable.\nAnd so, um, I think it's just an interesting kind of thing to think about potentially.\nThere's many analogy analogies you can make, like a 4-nanometer process node maybe is something like a cluster with certain max flops.\nYou can think about when you're use, when you're using Nvidia GPUs and you're only doing the software and you're not doing the hardware.\nThat's kind of like the fabless model.\nBut if you're actually also building your own hardware and you're training on TPUs if you're Google, that's kind of like the Intel model where you own your fab.\nSo I think there's some analogies here that make sense.\nBut actually, I think the analogy that makes the most sense perhaps is that in my mind, LLMs have very strong kind of analogies to operating systems.\nUh, in that this is not just electricity or water.\nIt's not something that comes out of the tap as a commodity.\nUh, this is, these are now increasingly complex software ecosystems, right?\nSo, uh, they're not just like simple commodities like electricity, and it's kind of interesting to me that the ecosystem is shaping in a very similar kind of way where you have a few closed source providers like Windows or Mac OS, and then you have an open source alternative like Linux.\nAnd I think for, uh, neural, for LLMs as well, we have a kind of a few competing closed source providers, and then maybe the llama ecosystem is currently like maybe a close approximation to something that may grow into something like Linux.\nAgain, I think it's still very early because these are just simple LLMs, but we're starting to see that these are going to get a lot more complicated.\nIt's not just about the LLM itself.\nIt's about all the tool use and the multimodalities and how all of that works.\nAnd so when I sort of had this realization a while back, I tried to sketch it out, and it kind of seemed to me like LLMs are kind of like a new operating system, right?\nSo the LLM is a new kind of a computer.\nIt's sitting, it's kind of like the CPU equivalent.\nUh, the context windows are kind of like the memory, and then the LLM is orchestrating memory and compute, uh, for problem solving, um, using all of these, uh, capabilities here.\nAnd so definitely if you look at it, it looks very much like an operating system from that perspective.\nUm, a few more analogies.\nFor example, if you want to download an app, say I go to VS Code and I go to download, you can download VS Code and you can run it on Windows, Linux, or Mac in the same way as you can take an LLM app like cursor and you can run it on GPT or cloud or Gemini series, right?\nIt's just a drop down.\nSo, it's kind of like similar in that way as well.\nUh, more analogies that I think strike me is that we're kind of like in this 1960s-ish era where LLM compute is still very expensive for this new kind of a computer, and that forces the LLMs to be centralized in the cloud, and we're all just, uh, sort of thing clients that interact with it over the network, and none of us have full utilization of these computers, and therefore it makes sense to use time sharing where we're all just, you know, a dimension of the batch when they're running the computer in the cloud.\nAnd this is very much what computers used to look like at during this time.\nThe operating systems were in the cloud.\nEverything was streamed around, and there was batching.\nAnd so the p, the personal computing revolution hasn't happened yet because it's just not economical.\nIt doesn't make sense.\nBut I think some people are trying.\nAnd it turns out that Mac minis, for example, are a very good fit for some of the LLMs because it's all, if you're doing batch one inference, this is all super memory bound.\nSo this actually works.\nAnd, uh, I think these are some early indications maybe of personal computing.\nUh, but this hasn't really happened yet.\nIt's not clear what this looks like.\nMaybe some of you get to invent what, what this is or how it works or, uh, what this should, what this should be.\nMaybe one more analogy that I'll mention is whenever I talk to ChatGPT or some LLM directly in text, I feel like I'm talking to an operating system through the terminal.\nLike it's just, it's text.\nIt's direct access to the operating system.\nAnd I think a GUI hasn't yet really been invented in like a general way, like should ChatGPT have a GUI like different than just a tech bubbles?\nUh, certainly some of the apps that we're going to go into in a bit have GUIs, but there's no like GUI across all the tasks, if that makes sense.\nUm, there are some ways in which LLMs are different from kind of operating systems in some fairly unique way and from early computing.\nAnd I wrote about, uh, this one particular property that strikes me as very different, uh, this time around.\nIt's that LLMs like flip, they flip the direction of technology diffusion, uh, that is usually, uh, present in technology.\nSo for example, with electricity, cryptography, computing, flight, internet, GPS, lots of new transformative technologies that have not been around.\nTypically it is the government and corporations that are the first users because it's new and expensive, etc., and it only later diffuses to consumers.\nUh, but I feel like LLMs are kind of like flipped around.\nSo maybe with early computers, it was all about ballistics and military use, but with LLMs, it's all about how do you boil an egg or something like that.\nThis is certainly like a lot of my use.\nAnd so it's really fascinating to me that we have a new magical computer, and it's like helping me boil an egg.\nIt's not helping the government do something really crazy like some military ball.\n\n\nStatistics or some special technology.\nIndeed, corporations and governments are lagging behind the adoption of all of us, of all of these technologies.\nSo, it's just backwards, and I think it informs maybe some of the uses of how we want to use this technology or like where are some of the first apps and so on.\n\nSo, in summary so far, LLM labs, LLMs.\nI think it's accurate language to use, but LLMs are complicated operating systems.\nThey're circa 1960s in computing, and we're redoing computing all over again, and they're currently available via time sharing and distributed like a utility.\nWhat is new and unprecedented is that they're not in the hands of a few governments and corporations.\nThey're in the hands of all of us because we all have a computer, and it's all just software, and Chaship was beamed down to our computers like billions of people like instantly and overnight, and this is insane.\nUh, and it's kind of insane to me that this is the case, and now it is our time to enter the industry and program these computers.\nThis is crazy.\nSo I think this is quite remarkable.\nBefore we program LLMs, we have to kind of like spend some time to think about what these things are.\nAnd I especially like to kind of talk about their psychology.\nSo the way I like to think about LLMs is that they're kind of like people spirits.\nUm, they are stoastic simulations of people.\nUm, and the simulator in this case happens to be an auto regressive transformer.\nSo transformer is a neural net.\nUh, it's and it just kind of like is goes on the level of tokens.\nIt goes chunk chunk chunk chunk chunk.\nAnd there's an almost equal amount of compute for every single chunk.\nUm, and um, this simulator of course is is just is basically there's some weights involved, and we fit it to all of text that we have on the internet and so on.\nAnd you end up with this kind of a simulator, and because it is trained on humans, it's got this emergent psychology that is humanlike.\nSo the first thing you'll notice is of course, uh, LLMs have encyclopedic knowledge and memory.\nUh, and they can remember lots of things, a lot more than any single individual human can because they read so many things.\nIt's it actually kind of reminds me of this movie Rainman, which I actually really recommend people watch.\nIt's an amazing movie.\nI love this movie.\nUm, and Dustin Hoffman here is an autistic savant who has almost perfect memory.\nSo, he can read a he can read like a phone book and remember all of the names and phone numbers.\nAnd I kind of feel like LLMs are kind of like very similar.\nThey can remember Shaw hashes and lots of different kinds of things very, very easily.\nSo they certainly have superpowers in some set in some respects.\nBut they also have a bunch of I would say cognitive deficits.\nSo they hallucinate quite a bit.\nUm, and they kind of make up stuff and don't have a very good uh sort of internal model of self-nowledge, not sufficient at least.\nAnd this has gotten better but not perfect.\nThey display jagged intelligence.\nSo they're going to be superhuman in some problems solving domains.\nAnd then they're going to make mistakes that basically no human will make.\nLike you know they will insist that 9.11 is greater than 9.9 or that there are two Rs in strawberry, these are some famous examples, but basically there are rough edges that you can trip on, so that's kind of I think also kind of unique.\nUm, they also kind of suffer from entrograde amnesia.\nUm, so uh, and I think I'm alluding to the fact that if you have a co-orker who joins your organization, this co-orker will over time learn your organization and uh, they will understand and gain like a huge amount of context on the organization, and they go home and they sleep and they consolidate knowledge and they develop expertise over time.\nLLMs don't natively do this, and this is not something that has really been solved in the R&D of LLM.\nI think um, and so context windows are really kind of like working memory, and you have to sort of program the working memory quite directly because they don't just kind of like get smarter by uh by default, and I think a lot of people get tripped up by the analogies uh in this way.\nUh, in popular culture, I recommend people watch these two movies, uh, Momento and 51st dates.\nIn both of these movies, the protagonists, their weights are fixed and their context windows gets wiped every single morning, and it's really problematic to go to work or have relationships when this happens, and this happens to all the time.\nI guess one more thing I would point to is security kind of related limitations of the use of LLM.\nSo for example, LLMs are quite gullible.\nUh, they are susceptible to prompt injection risks.\nThey might leak your data, etc.\nAnd so um, and there's many other considerations uh security related.\nSo, so basically long story short, you have to load your you have to load your you have to simultaneously think through this superhuman thing that has a bunch of cognitive deficits and issues.\nHow do we and yet they are extremely like useful, and so how do we program them and how do we work around their deficits and enjoy their superhuman powers?\n\nSo what I want to switch to now is talk about the opportunities of how do we use these models and what are some of the biggest opportunities.\nThis is not a comprehensive list, just some of the things that I thought were interesting for this talk.\nThe first thing I'm kind of excited about is what I would call partial autonomy apps.\nSo for example, let's work with the example of coding.\nYou can certainly go to chacht directly and you can start copy pasting code around and copyping bug reports and stuff around and getting code and copy pasting everything around.\nWhy would you why would you do that?\nWhy would you go directly to the operating system?\nIt makes a lot more sense to have an app dedicated for this.\nAnd so I think many of you uh use uh cursor.\nI do as well.\nAnd uh cursor is kind of like the thing you want instead.\nYou don't want to just directly go to the chash apt.\nAnd I think cursor is a very good example of an early LLM app that has a bunch of properties that I think are um useful across all the LLM apps.\nSo in particular, you will notice that we have a traditional interface that allows a human to go in and do all the work manually just as before.\nBut in addition to that, we now have this LLM integration that allows us to go in bigger chunks.\nAnd so some of the properties of LLM apps that I think are shared and useful to point out.\nNumber one, the LLMs basically do a ton of the context management.\nUm, number two, they orchestrate multiple calls to LLMs, right?\nSo in the case of cursor, there's under the hood embedding models for all your files, the actual chat models, models that apply diffs to the code, and this is all orchestrated for you.\nA really big one that uh I think also maybe not fully appreciated always is application specific uh GUI and the importance of it.\nUm, because you don't just want to talk to the operating system directly in text.\nText is very hard to read, interpret, understand and also like you don't want to take some of these actions natively in text.\nSo it's much better to just see a diff as like red and green change and you can see what's being added is subtracted.\nIt's much easier to just do command Y to accept or command N to reject.\nI shouldn't have to type it in text, right?\nSo, a GUI allows a human to audit the work of these fallible systems and to go faster.\nI'm going to come back to this point a little bit uh later as well.\nAnd the last kind of feature I want to point out is that there's what I call the autonomy slider.\nSo, for example, in cursor, you can just do tap completion.\nYou're mostly in charge.\nYou can select a chunk of code and command K to change just that chunk of code.\nYou can do command L to change the entire file.\nOr you can do command I which just you know let it rip do whatever you want in the entire repo, and that's the sort of full autonomy agent agentic version, and so you are in charge of the autonomy slider, and depending on the complexity of the task at hand, you can uh tune the amount of autonomy that you're willing to give up uh for that task.\nMaybe to show one more example of a fairly successful LLM app, uh, perplexity, um, it also has very similar features to what I've just pointed out to in cursor.\nUh, it packages up a lot of the information.\nIt orchestrates multiple LLMs.\nIt's got a GUI that allows you to audit some of its work.\nSo, for example, it will cite sources and you can imagine inspecting them.\nAnd it's got an autonomy slider.\nYou can either just do a quick search or you can do research or you can do deep research and come back 10 minutes later.\nSo, this is all just varying levels of autonomy that you give up to the tool.\nSo, I guess my question is I feel like a lot of software will become partially autonomous.\nI'm trying to think through like what does that look like?\nAnd for many of you who maintain products and services, how are you going to make your products and services partially autonomous?\nCan an LLM see everything that a human can see?\nCan an LLM act in all the ways that a human could act?\nAnd can humans supervise and stay in the loop of this activity?\nBecause again, these are fallible systems that aren't yet perfect.\nAnd what does a diff look like in Photoshop or something like that?\nYou know, and also a lot of the traditional software right now, it has all these switches and all this kind of stuff that's all designed for human.\nAll of this has to change and become accessible to LLMs.\n\nSo, one thing I want to stress with a lot of these LLM apps that I'm not sure gets as much attention as it should is um we we're now kind of like cooperating with AIs, and usually they are doing the generation and we as humans are doing the verification.\nIt is in our interest to make this loop go as fast as possible.\nSo, we're getting a lot of work done.\nThere are two major ways that I think uh this can be done.\nNumber one, you can speed up verification a lot.\nUm, and I think GUIs, for example, are extremely important to this because a GUI utilizes your computer vision GPU in all of our head.\nReading text is effortful and it's not fun, but looking at stuff is fun and it's it's just a kind of like a highway to your brain.\nSo, I think GUIs are very useful for auditing systems and visual representations in general.\nAnd number two, I would say is we have to keep the AI on the leash.\nWe I think a lot of people are getting way over excited with AI agents and uh it's not useful to me to get a diff of 10,000 lines of code to my repo.\nLike I have to I'm still the bottleneck, right?\nEven though that 10,00 lines come out instantly, I have to make sure that this thing is not introducing bugs.\nIt's just like and that it's doing the correct thing, right?\nAnd that there's no security issues and so on.\nSo um I think that um yeah basically you we have to sort of like it's in our interest to make the the flow of these two go very, very fast, and we have to somehow keep the AI on the leash because it gets way too overreactive.\nIt's uh it's kind of like this.\nThis is how I feel when I do AI assisted coding.\nIf I'm just bite coding, everything is nice and great, but if I'm actually trying to get work done, it's not so great to have an overreactive uh agent doing all this kind of stuff.\nSo this slide is not very good.\nI'm sorry, but I guess I'm trying to develop like many of you some ways of utilizing these agents in my coding workflow and to do AI assisted coding.\nAnd in my own work, I'm always scared to get way too big diffs.\nI always go in small incremental chunks.\nI want to make sure that everything is good.\nI want to spin this loop very, very fast, and um I sort of work on small chunks of single concrete thing.\nUh, and so I think many of you probably are developing similar ways of working with the with LLMs.\nUm, I also saw a number of blog posts that try to develop these best practices for working with LLMs.\nAnd here's one that I read recently and I thought was quite good.\nAnd it kind of discussed some techniques and some of them have to do with how you keep the AI on the leash.\nAnd so, as an example, if you are prompting, if your prompt is vague, then uh the AI might not do exactly what you wanted, and in that case, verification will fail.\nYou're going to ask for something else.\nIf a verification fails, then you're going to start spinning.\nSo it makes a lot more sense to spend a bit more time to be more concrete in your prompts which increases the probability of successful verification and you can move forward.\nAnd so I think a lot of us are going to end up finding um kind of techniques like this.\nI think in my own work as well I'm currently interested in uh what education looks like in um together with kind of like now that we have AI uh and LLMs what does education look like?\nAnd I think a a large amount of thought for me goes into how we keep AI on the leash.\nI don't think it just works to go to chat and be like, \"Hey, teach me physics.\"\nI don't think this works because the AI is like gets lost in the woods.\nAnd so for me, this is actually two separate apps.\nFor example, there's an app for a teacher that creates courses and then there's an app that takes courses and serves them to students.\nAnd in both cases, we now have this intermediate artifact of a course that is auditable and we can make sure it's good.\nWe can make sure it's consistent.\nAnd the AI is kept on the leash with respect to a certain syllabus, a certain like um progression of projects and so on.\nAnd so this is one way of keeping the AI on leash and I think has a much higher likelihood of working and the AI is not getting lost in the woods.\nOne more kind of analogy I wanted to sort of allude to is I'm not I'm no stranger to partial autonomy, and I kind of worked on this I think for five years at Tesla, and this is also a partial autonomy product and shares a lot of the features like for example right there in the instrument panel is the GUI of the autopilot, so it's showing me what the what the neural network sees and so on, and we have the autonomy slider where over the course of my tenure there we did more and more autonomous tasks for the user, and maybe the story that I wanted to tell very briefly is uh actually the first time I drove a self-driving vehicle was in 2013, and I had a friend who worked at Whimo and uh he offered to give me a drive around Palo Alto.\nI took this picture using Google Glass at the time, and many of you are so young that\n\n\nYou might not even know what that is.\nUh, but uh, yeah, this was like all the rage at the time.\nAnd we got into this car, and we went for about a 30-minute drive around Palo Alto, highways, uh, streets, and so on.\nAnd this drive was perfect.\nThere were zero interventions, and this was 2013, which is now 12 years ago.\nAnd it kind of struck me because at the time when I had this perfect drive, this perfect demo, I felt like, \"Wow, self-driving is imminent because this just worked.\nThis is incredible.\"\nUm, but here we are 12 years later, and we are still working on autonomy.\nUm, we are still working on driving agents, and even now, we haven't actually like really solved the problem.\nLike you may see Whimos going around, and they look driverless, but you know, there's still a lot of teleoperation and a lot of human in the loop of a lot of this driving, so we still haven't even like declared success, but I think it's definitely like going to succeed at this point, but it just took a long time.\nAnd so I think like, like this is software is really tricky.\nI think in the same way that driving is tricky.\nAnd so when I see things like, \"Oh, 2025 is the year of agents,\" I get very concerned, and I kind of feel like, you know, this is the decade of agents, and this is going to be quite some time.\nWe need humans in the loop.\nWe need to do this carefully.\nThis is software.\nLet's be serious here.\nOne more kind of analogy that I always think through is the Iron Man suit.\nUh, I think this is, I always love Iron Man.\nI think it's like so um, correct in a bunch of ways with respect to technology and how it will play out.\nAnd what I love about the Iron Man suit is that it's both an augmentation, and Tony Stark can drive it, and it's also an agent.\nAnd in some of the movies, the Iron Man suit is quite autonomous and can fly around and find Tony and all this kind of stuff.\nAnd so this is the autonomy slider: we can be, we can build augmentations, or we can build agents, and we kind of want to do a bit of both.\nBut at this stage, I would say working with fallible LLMs and so on, I would say, you know, it's less Iron Man robots and more Iron Man suits that you want to build.\nIt's less like building flashy demos of autonomous agents and more building partial autonomy products.\nAnd these products have custom GUIs and UI/UX.\nAnd we're trying to um, and this is done so that the generation verification loop of the human is very, very fast.\nBut we are not losing sight of the fact that it is in principle possible to automate this work.\nAnd there should be an autonomy slider in your product.\nAnd you should be thinking about how you can slide that autonomy slider and make your product, uh, sort of um, more autonomous over time.\nBut this is kind of how I think there's lots of opportunities in these kinds of products.\nI want to now switch gears a little bit and talk about one other dimension that I think is very unique.\nNot only is there a new type of programming language that allows for autonomy in software, but also, as I mentioned, it's programmed in English, which is this natural interface, and suddenly everyone is a programmer because everyone speaks natural language like English.\nSo this is extremely bullish and very interesting to me and also completely unprecedented.\nI would say it, it used to be the case that you need to spend five to 10 years studying something to be able to do something in software.\nThis is not the case anymore.\nSo, I don't know if by any chance anyone has heard of Vibe Coding.\nUh, this, this is the tweet that kind of like introduced this, but I'm told that this is now like a major meme.\nUm, fun story about this is that I've been on Twitter for like 15 years or something like that at this point, and I still have no clue which tweet will become viral and which tweet like fizzles and no one cares.\nAnd I thought that this tweet was going to be the latter.\nI don't know.\nIt was just like a shower of thoughts.\nBut this became like a total meme, and I really just can't tell.\nBut I guess like it struck a chord, and it gave a name to something that everyone was feeling but couldn't quite say in words.\nSo now there's a Wikipedia page and everything.\nThis is like\n[Applause]\nyeah, this is like a major contribution now or something like that.\nSo, um, so Tom Wolf from HuggingFace shared this beautiful video that I really love.\nUm, these are kids vibe coding.\nAnd I find that this is such a wholesome video.\nLike, I love this video.\nLike, how can you look at this video and feel bad about the future?\nThe future is great.\nI think this will end up being like a gateway drug to software development.\nUm, I'm not a doomer about the future of the generation, and I think, yeah, I love this video.\nSo, I tried by coding a little bit, uh, as well because it's so fun.\nUh, so bike coding is so great when you want to build something super duper custom that doesn't appear to exist, and you just want to wing it because it's a Saturday or something like that.\nSo, I built this, uh, iOS app, and I don't, I can't actually program in Swift, but I was really shocked that I was able to build like a super basic app, and I'm not going to explain it.\nIt's really, uh, dumb, but uh, I kind of like this was just like a day of work, and this was running on my phone like later that day, and I was like, \"Wow, this is amazing.\"\nI didn't have to like read through Swift for like five days or something like that to like get started.\nI also vibe-coded this app called MenuGen.\nAnd this is live.\nYou can try it in menu.app.\nAnd I basically had this problem where I show up at a restaurant, I read through the menu, and I have no idea what any of the things are.\nAnd I need pictures.\nSo this doesn't exist.\nSo I was like, \"Hey, I'm going to bite code it.\"\nSo, um, this is what it looks like.\nYou go to menu.app, um, and, uh, you take a picture of a menu, and then menu generates the images, and everyone gets $5 in credits for free when you sign up.\nAnd therefore, this is a major cost center in my life.\nSo, this is a negative, negative, uh, revenue app for me right now.\nI've lost a huge amount of money on menu.\nOkay.\nBut the fascinating thing about MenuGen for me is that the code of the v, the vibe coding part, the code was actually the easy part of v of v coding menu, and most of it actually was when I tried to make it real so that you can actually have authentication and payments and the domain name and averal deployment.\nThis was really hard, and all of this was not code.\nAll of this devops stuff was in me in the browser clicking stuff, and this was extreme slo, and took another week.\nSo it was really fascinating that I had the MenuGen, um, basically demo working on my laptop in a few hours, and then it took me a week because I was trying to make it real, and the reason for this is this was just really annoying.\nUm, so for example, if you try to add Google login to your web page, I know this is very small, but just a huge amount of instructions of this clerk library telling me how to integrate this.\nAnd this is crazy.\nLike it's telling me go to this URL, click on this dropdown, choose this, go to this, and click on that.\nAnd it's like telling me what to do.\nLike a computer is telling me the actions I should be taking.\nLike you do it.\nWhy am I doing this?\nWhat the hell?\nI had to follow all these instructions.\nThis was crazy.\nSo I think the last part of my talk therefore focuses on can we just build for agents?\nI don't want to do this work.\nCan agents do this?\nThank you.\nOkay.\nSo roughly speaking, I think there's a new category of consumer and manipulator of digital information.\nIt used to be just humans through GUIs or computers through APIs.\nAnd now we have a completely new thing, and agents are, they're computers, but they are human-like kind of, right?\nThey're people spirits, there's people spirits on the internet, and they need to interact with our software infrastructure.\nLike, can we build for them?\nIt's a new thing.\nSo as an example, you can have robots.txt on your domain, and you can instruct, uh, or like advise, I suppose, um, uh, web crawlers on how to behave on your website.\nIn the same way, you can have maybe lm.txt txt file, which is just a simple markdown that's telling LLMs what this domain is about, and this is very readable to a to an LLM.\nIf it had to instead get the HTML of your web page and try to parse it, this is very error-prone and difficult and will screw it up, and it's not going to work.\nSo we can just directly speak to the LLM.\nIt's worth it.\nUm, a huge amount of documentation is currently written for people.\nSo you will see things like lists and bold and pictures, and this is not directly accessible by an LLM.\nSo I see some of the services now are transitioning a lot of their docs to be specifically for LLMs.\nSo Versel and Stripe, as an example, are early movers here, but there are a few more that I've seen already, and they offer their documentation in markdown.\nMarkdown is super easy for LMS to understand.\nThis is great.\nUm, maybe one simple example from, from, uh, my experience as well.\nMaybe some of you know three blue one brown.\nHe makes beautiful animation videos on YouTube.\n[Applause]\nYeah, I love this library.\nSo that he wrote, uh, Manon, and I wanted to make my own, and, uh, there's extensive documentations on how to use Manon, and so I didn't want to actually read through it.\nSo I copy pasted the whole thing to an LLM, and I described what I wanted, and it just worked out of the box.\nLike LLM just bcoded me an animation exactly what I wanted, and I was like, \"Wow, this is amazing.\"\nSo if we can make docs legible to LLMs, it's going to unlock a huge amount of um, kind of use, and um, I think this is wonderful and should, should happen more.\nThe other thing I wanted to point out is that you do, unfortunately, have to, it's not just about taking your docs and making them appear in markdown.\nThat's the easy part.\nWe actually have to change the docs because anytime your docs say click this is bad.\nAn LLM will not be able to natively take this action right now.\nSo, Verscell, for example, is replacing every occurrence of click with an equivalent curl command that your LM agent could take on your behalf.\nUm, and so I think this is very interesting.\nAnd then, of course, there's a model context protocol from Enthropic.\nAnd this is also another way, it's a protocol of speaking directly to agents as this new consumer and manipulator of digital information.\nSo, I'm very bullish on these ideas.\nThe other thing I really like is a number of little tools here and there that are helping ingest data that in like very LLM friendly formats.\nSo for example, when I go to a GitHub repo like my nanoGPT repo, I can't feed this to an LLM and ask questions about it, uh, because it's, you know, this is a human interface on GitHub.\nSo when you just change the URL from GitHub to get ingest, then, uh, this will actually concatenate all the files into a single giant text, and it will create a directory structure, etc.\nAnd this is ready to be copy pasted into your favorite LLM, and you can do stuff.\nMaybe even more dramatic example of this is deep wiki, where it's not just the raw content of these files, uh, this is from Devon, but also like they have Devon basically do analysis of the GitHub repo, and Devon basically builds up a whole docs, uh, pages just for your repo, and you can imagine that this is even more helpful to copy paste into your LLM.\nSo I love all the little tools that basically where you just change the URL and it makes something accessible to an LLM.\nSo this is all well and great, and u, I think there should be a lot more of it.\nOne more note I wanted to make is that it is absolutely possible that in the future LLMs will be able to, this is not even future, this is today, they'll be able to go around and they'll be able to click stuff and so on, but I still think it's very worth u basically meeting LLM halfway, LLM's halfway and making it easier for them to access all this information, uh, because this is still fairly expensive, I would say to use, and uh, a lot more difficult, and so I do think that lots of software, there will be a long tail where it won't like adapt apps because these are not like live player sort of repositories or digital infrastructure, and we will need these tools.\nUh, but I think for everyone else, I think it's very worth kind of like meeting in some middle point.\nSo I'm bullish on both, if that makes sense.\nSo in summary, what an amazing time to get into the industry.\nWe need to rewrite a ton of code.\nA ton of code will be written by professionals and by coders.\nThese LLMs are kind of like utilities, kind of like fabs, but they're kind of especially like operating systems.\nBut it's so early.\nIt's like 1960s of operating systems, and uh, and I think a lot of the analogies cross over.\nUm, and these LMS are kind of like these fallible, uh, you know, people spirits that we have to learn to work with.\nAnd in order to do that properly, we need to adjust our infrastructure towards it.\nSo when you're building these LLM apps, I describe some of the ways of working effectively with these LLMs and some of the tools that make that, uh, kind of possible and how you can spin this loop very, very quickly and basically create partial tunneling products, and then, um, yeah, a lot of code has to also be written for the agents more directly.\nBut in any case, going back to the Iron Man suit analogy, I think what we'll see over the next decade roughly is we're going to take the slider from left to right.\nAnd I'm very interesting.\nIt's going to be very interesting to see what that looks like.\nAnd I can't wait to build it with all of you.\nThank you.\n",
  "dumpedAt": "2025-07-21T18:43:25.876Z"
}