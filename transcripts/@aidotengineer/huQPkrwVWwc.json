{
  "episodeId": "huQPkrwVWwc",
  "channelSlug": "@aidotengineer",
  "title": "Design like Karpathy is watching - Zeke Sikelianos, Replicate",
  "publishedAt": "2025-07-19T16:15:06.000Z",
  "rawLines": [
    {
      "lang": "en",
      "text": "[Music]",
      "offset": 3.54,
      "duration": 5.11
    },
    {
      "lang": "en",
      "text": "How many of you know who Andre Carpathy",
      "offset": 15.599,
      "duration": 4.481
    },
    {
      "lang": "en",
      "text": "is? Raise your hand.",
      "offset": 17.84,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "Okay, maybe half of you. Raise your hand",
      "offset": 20.08,
      "duration": 6.16
    },
    {
      "lang": "en",
      "text": "if you are not Andre Karpathy.",
      "offset": 22.56,
      "duration": 4.799
    },
    {
      "lang": "en",
      "text": "Just trying to gauge audience",
      "offset": 26.24,
      "duration": 3.199
    },
    {
      "lang": "en",
      "text": "participation here. Okay, so I got 80%",
      "offset": 27.359,
      "duration": 3.521
    },
    {
      "lang": "en",
      "text": "there. or something like that. Got a lot",
      "offset": 29.439,
      "duration": 4.561
    },
    {
      "lang": "en",
      "text": "of Andre's in the room right now. Um,",
      "offset": 30.88,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "raise your hand if you work at",
      "offset": 34,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "Replicate.",
      "offset": 35.36,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "All right, so if you want to talk to any",
      "offset": 37.84,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "Replicate folks, there's there's your",
      "offset": 39.12,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "group right there. All right, so um for",
      "offset": 41.04,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "those who don't know who Andre Carpathi",
      "offset": 43.52,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "is, I will jump into that and explain",
      "offset": 45.52,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "that. Um,",
      "offset": 46.96,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "these are my uh there's a GitHub repo",
      "offset": 49.52,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "that corresponds to this um these",
      "offset": 51.76,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "slides. So if you want to grab that,",
      "offset": 54.32,
      "duration": 2.96
    },
    {
      "lang": "en",
      "text": "this will I'll put this slide up at the",
      "offset": 55.68,
      "duration": 5.039
    },
    {
      "lang": "en",
      "text": "end too, so you can um track down any",
      "offset": 57.28,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "URLs or anything that I mention in the",
      "offset": 60.719,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "talk. Uh my name is Zeke. I am Zeke on",
      "offset": 62.64,
      "duration": 6.72
    },
    {
      "lang": "en",
      "text": "GitHub. Um Zeke on X as well. Um and I",
      "offset": 65.439,
      "duration": 7.521
    },
    {
      "lang": "en",
      "text": "work for Replicate. So uh Replicate is a",
      "offset": 69.36,
      "duration": 6.32
    },
    {
      "lang": "en",
      "text": "cloud platform that lets you run AI",
      "offset": 72.96,
      "duration": 7.68
    },
    {
      "lang": "en",
      "text": "models with an a API. So we have um you",
      "offset": 75.68,
      "duration": 7.439
    },
    {
      "lang": "en",
      "text": "know open source models like all the",
      "offset": 80.64,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "great flux models from Black Forest Labs",
      "offset": 83.119,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "but we also have you know proprietary",
      "offset": 85.84,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "models from Anthropic, OpenAI,",
      "offset": 87.759,
      "duration": 5.441
    },
    {
      "lang": "en",
      "text": "Google etc. Um and of course you can",
      "offset": 90.56,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "also run your own custom public and",
      "offset": 93.2,
      "duration": 5.599
    },
    {
      "lang": "en",
      "text": "private models on replicate as well. So",
      "offset": 95.28,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "let's get to the point. Who is Andre",
      "offset": 98.799,
      "duration": 5.601
    },
    {
      "lang": "en",
      "text": "Karpathy? Well, he's an AI re he's an AI",
      "offset": 100.64,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "researcher who's worked at all these big",
      "offset": 104.4,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "uh companies and organizations. Google,",
      "offset": 106.32,
      "duration": 8.4
    },
    {
      "lang": "en",
      "text": "OpenAI, Tesla, OpenAI, Eureka Labs. Um",
      "offset": 109.04,
      "duration": 7.759
    },
    {
      "lang": "en",
      "text": "Eureka Labs is his new thing uh an",
      "offset": 114.72,
      "duration": 5.439
    },
    {
      "lang": "en",
      "text": "educational uh platform. Uh, but most",
      "offset": 116.799,
      "duration": 5.121
    },
    {
      "lang": "en",
      "text": "importantly to me, he is a YouTube",
      "offset": 120.159,
      "duration": 5.361
    },
    {
      "lang": "en",
      "text": "educator and does some really amazing",
      "offset": 121.92,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "talks that are highly accessible that",
      "offset": 125.52,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "explain how AI and machine learning",
      "offset": 127.28,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "works for general audiences. Um, he",
      "offset": 129.28,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "coined the term vibe coding a few months",
      "offset": 132.48,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "ago and of course that's taken the world",
      "offset": 134.48,
      "duration": 3.119
    },
    {
      "lang": "en",
      "text": "by storm. We're all really interested in",
      "offset": 136.08,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "that now and subscribes to the idea that",
      "offset": 137.599,
      "duration": 5.121
    },
    {
      "lang": "en",
      "text": "the hottest new programming language is",
      "offset": 140.16,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "English. Um, kind of a hot take. Um, he",
      "offset": 142.72,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "also wrote something called the software",
      "offset": 145.52,
      "duration": 6.4
    },
    {
      "lang": "en",
      "text": "2.0 know manifesto which was um now",
      "offset": 146.879,
      "duration": 7.521
    },
    {
      "lang": "en",
      "text": "seven years ago kind of a eternity in",
      "offset": 151.92,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "machine learning time uh basically",
      "offset": 154.4,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "predicting this world in which uh",
      "offset": 156.56,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "machine learning models would write code",
      "offset": 159.36,
      "duration": 4.959
    },
    {
      "lang": "en",
      "text": "for us um and that it would be they",
      "offset": 161.92,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "would be better at it than than humans",
      "offset": 164.319,
      "duration": 5.121
    },
    {
      "lang": "en",
      "text": "and so of course here we are. Um so",
      "offset": 166.08,
      "duration": 4.799
    },
    {
      "lang": "en",
      "text": "today I want to talk about menu genen.",
      "offset": 169.44,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "So, Menuugen",
      "offset": 170.879,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "is um an app that Andre created recently",
      "offset": 172.64,
      "duration": 5.679
    },
    {
      "lang": "en",
      "text": "at a I think he was at a hackathon doing",
      "offset": 175.599,
      "duration": 5.201
    },
    {
      "lang": "en",
      "text": "like a a vibe coding experiment. So,",
      "offset": 178.319,
      "duration": 5.441
    },
    {
      "lang": "en",
      "text": "Menuguen is basically this u web app",
      "offset": 180.8,
      "duration": 6.159
    },
    {
      "lang": "en",
      "text": "where you take photos of a menu at a",
      "offset": 183.76,
      "duration": 6.08
    },
    {
      "lang": "en",
      "text": "restaurant that's all in a text format",
      "offset": 186.959,
      "duration": 6.481
    },
    {
      "lang": "en",
      "text": "and it generates image representations",
      "offset": 189.84,
      "duration": 6.08
    },
    {
      "lang": "en",
      "text": "of the contents of the menu for you. So",
      "offset": 193.44,
      "duration": 5.519
    },
    {
      "lang": "en",
      "text": "if you don't know what the words mean or",
      "offset": 195.92,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "English isn't your first language or you",
      "offset": 198.959,
      "duration": 4.801
    },
    {
      "lang": "en",
      "text": "just like to see tantalizing photos of",
      "offset": 201.36,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "food that may be good. Um that was the",
      "offset": 203.76,
      "duration": 5.839
    },
    {
      "lang": "en",
      "text": "idea behind it. So he was actually able",
      "offset": 206.56,
      "duration": 5.679
    },
    {
      "lang": "en",
      "text": "to build this app which he described as",
      "offset": 209.599,
      "duration": 5.761
    },
    {
      "lang": "en",
      "text": "an exhilarating and fun escapade as a",
      "offset": 212.239,
      "duration": 5.92
    },
    {
      "lang": "en",
      "text": "local demo but a bit of a painful slog",
      "offset": 215.36,
      "duration": 4.959
    },
    {
      "lang": "en",
      "text": "as a deployed real app. So you've",
      "offset": 218.159,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "probably many of you have probably",
      "offset": 220.319,
      "duration": 3.521
    },
    {
      "lang": "en",
      "text": "experienced this where you are working",
      "offset": 221.84,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "on something locally you have it running",
      "offset": 223.84,
      "duration": 3.679
    },
    {
      "lang": "en",
      "text": "on your machine oh cool it really works",
      "offset": 225.28,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "it's amazing and then you try to deploy",
      "offset": 227.519,
      "duration": 4.561
    },
    {
      "lang": "en",
      "text": "it to you know versell or cloudflare or",
      "offset": 229.04,
      "duration": 5.279
    },
    {
      "lang": "en",
      "text": "something like that and that's where a",
      "offset": 232.08,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "lot of the the pain begins um so we're",
      "offset": 234.319,
      "duration": 6.161
    },
    {
      "lang": "en",
      "text": "going to talk about that so",
      "offset": 237.12,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "um",
      "offset": 240.48,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "Andre kind of wrote this blog post about",
      "offset": 242.4,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "the experience of creating menu genen um",
      "offset": 244.72,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "and saying you know I was able to make",
      "offset": 248,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "this thing, publish it, get it online,",
      "offset": 249.76,
      "duration": 5.839
    },
    {
      "lang": "en",
      "text": "uh, add payments for it, and it's a",
      "offset": 253.12,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "working functioning app that people can",
      "offset": 255.599,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "pay for, and it was super fun to build.",
      "offset": 257.12,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "However, it kind of rakes all these",
      "offset": 259.28,
      "duration": 4.639
    },
    {
      "lang": "en",
      "text": "different companies over the coals",
      "offset": 261.6,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "because of the sort of developer",
      "offset": 263.919,
      "duration": 3.361
    },
    {
      "lang": "en",
      "text": "experience challenges of working with",
      "offset": 265.919,
      "duration": 2.961
    },
    {
      "lang": "en",
      "text": "all of them. So for me it was cool",
      "offset": 267.28,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "because it was like okay replicate is",
      "offset": 268.88,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "mentioned among all these big hot shot",
      "offset": 271.12,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "companies like OpenAI and Verscell. Um",
      "offset": 272.88,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "but we also all have work to do to",
      "offset": 275.68,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "improve our products to make them",
      "offset": 277.84,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "better. So here's a blur about kind of",
      "offset": 280,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "what he what he experienced when he",
      "offset": 283.28,
      "duration": 4.639
    },
    {
      "lang": "en",
      "text": "started using replicate API. So the",
      "offset": 285.12,
      "duration": 5.359
    },
    {
      "lang": "en",
      "text": "LLM's knowledge of replicate was",
      "offset": 287.919,
      "duration": 5.681
    },
    {
      "lang": "en",
      "text": "outdated. The docs on replicate were out",
      "offset": 290.479,
      "duration": 5.521
    },
    {
      "lang": "en",
      "text": "of date. Um there were changes in the",
      "offset": 293.6,
      "duration": 6.24
    },
    {
      "lang": "en",
      "text": "API. he experienced rate limiting and it",
      "offset": 296,
      "duration": 5.759
    },
    {
      "lang": "en",
      "text": "was harder to get started with a new",
      "offset": 299.84,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "legitimate paid account. So, this is",
      "offset": 301.759,
      "duration": 4.641
    },
    {
      "lang": "en",
      "text": "kind of embarrassing, but it's also kind",
      "offset": 304.8,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "of like an opportunity to fix our",
      "offset": 306.4,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "product and make it better and really",
      "offset": 309.52,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "listen to, you know, the kind of voices",
      "offset": 311.52,
      "duration": 5.519
    },
    {
      "lang": "en",
      "text": "that are loud and correct about the",
      "offset": 314,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "problems with our products. So, what can",
      "offset": 317.039,
      "duration": 5.761
    },
    {
      "lang": "en",
      "text": "Replicate do better? Um, one of them is",
      "offset": 319.52,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "embracing llm.text. llm.text text is",
      "offset": 322.8,
      "duration": 6.72
    },
    {
      "lang": "en",
      "text": "this thing where you can uh basically",
      "offset": 325.28,
      "duration": 7.6
    },
    {
      "lang": "en",
      "text": "uh modify your website or your API or",
      "offset": 329.52,
      "duration": 7.519
    },
    {
      "lang": "en",
      "text": "existing services to um render textbased",
      "offset": 332.88,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "or markdownbased versions of your",
      "offset": 337.039,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "documentation in a format that is",
      "offset": 338.88,
      "duration": 6.319
    },
    {
      "lang": "en",
      "text": "friendly for language models to consume",
      "offset": 341.039,
      "duration": 5.681
    },
    {
      "lang": "en",
      "text": "more friendly than like the HTML",
      "offset": 345.199,
      "duration": 7.121
    },
    {
      "lang": "en",
      "text": "contents of a web page. So said tired",
      "offset": 346.72,
      "duration": 7.52
    },
    {
      "lang": "en",
      "text": "elaborate docs pages with fancy color",
      "offset": 352.32,
      "duration": 3.599
    },
    {
      "lang": "en",
      "text": "palettes, branding, animations,",
      "offset": 354.24,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "transitions, dark mode, wired one single",
      "offset": 355.919,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "docs markdown file and a copy to",
      "offset": 359.44,
      "duration": 6.479
    },
    {
      "lang": "en",
      "text": "clipboard button. So it sounds simple um",
      "offset": 361.199,
      "duration": 6.161
    },
    {
      "lang": "en",
      "text": "and maybe not the most glamorous thing,",
      "offset": 365.919,
      "duration": 2.881
    },
    {
      "lang": "en",
      "text": "but it is actually the thing that your",
      "offset": 367.36,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "language models want to consume. So in",
      "offset": 368.8,
      "duration": 4.959
    },
    {
      "lang": "en",
      "text": "response to this, we added a new feature",
      "offset": 371.759,
      "duration": 3.361
    },
    {
      "lang": "en",
      "text": "on the replicate website where you're",
      "offset": 373.759,
      "duration": 3.361
    },
    {
      "lang": "en",
      "text": "viewing any model page. You have a",
      "offset": 375.12,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "button to copy the contents of that page",
      "offset": 377.12,
      "duration": 5.519
    },
    {
      "lang": "en",
      "text": "uh as markdown for a language model or",
      "offset": 379.68,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "to",
      "offset": 382.639,
      "duration": 5.201
    },
    {
      "lang": "en",
      "text": "send the page directly to Claude to have",
      "offset": 384.24,
      "duration": 6.079
    },
    {
      "lang": "en",
      "text": "an interaction with the contents of the",
      "offset": 387.84,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "model page to learn more about what the",
      "offset": 390.319,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "model can do. Similarly, we added that",
      "offset": 392.16,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "support for linking to chat GPT. You",
      "offset": 394.24,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "basically just say I'm on a model page.",
      "offset": 397.52,
      "duration": 3.679
    },
    {
      "lang": "en",
      "text": "You jump into chat GPT and you start",
      "offset": 399.52,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "having a conversation about the model.",
      "offset": 401.199,
      "duration": 3.761
    },
    {
      "lang": "en",
      "text": "So, it's a lot more interactive than",
      "offset": 402.88,
      "duration": 5.599
    },
    {
      "lang": "en",
      "text": "just going to a web page and",
      "offset": 404.96,
      "duration": 4.799
    },
    {
      "lang": "en",
      "text": "reading and trying to find the most",
      "offset": 408.479,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "relevant content.",
      "offset": 409.759,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "Of course, we also just dump the",
      "offset": 412.08,
      "duration": 2.72
    },
    {
      "lang": "en",
      "text": "markdown here, too. So, if you're using",
      "offset": 413.44,
      "duration": 5.039
    },
    {
      "lang": "en",
      "text": "a a tool like cursor or wind surf, grab",
      "offset": 414.8,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "this content, put it into your editor,",
      "offset": 418.479,
      "duration": 4.881
    },
    {
      "lang": "en",
      "text": "and it knows how to run this model.",
      "offset": 420.4,
      "duration": 5.84
    },
    {
      "lang": "en",
      "text": "So, next thing, this was not necessarily",
      "offset": 423.36,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "from the blog post, but this is from I'm",
      "offset": 426.24,
      "duration": 4.799
    },
    {
      "lang": "en",
      "text": "grabbing some quotes from recent uh",
      "offset": 428.56,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "tweets from Andre Carpathy. So, LLMs",
      "offset": 431.039,
      "duration": 6.801
    },
    {
      "lang": "en",
      "text": "don't like to click, they like to curl.",
      "offset": 434,
      "duration": 7.36
    },
    {
      "lang": "en",
      "text": "So, love it or love it or hate it, curl",
      "offset": 437.84,
      "duration": 7.759
    },
    {
      "lang": "en",
      "text": "is um a tool that is here to stay. It's",
      "offset": 441.36,
      "duration": 6.399
    },
    {
      "lang": "en",
      "text": "developed, it's been around for, I don't",
      "offset": 445.599,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "know, since the 90s maybe. um it's",
      "offset": 447.759,
      "duration": 4.241
    },
    {
      "lang": "en",
      "text": "installed on everyone's machine and it",
      "offset": 450,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "is basically a standardized way to be",
      "offset": 452,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "able to make API calls without any",
      "offset": 454.08,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "specialized tooling. So let's look at",
      "offset": 457.28,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "this curl command. Maybe it looks ugly,",
      "offset": 459.44,
      "duration": 5.84
    },
    {
      "lang": "en",
      "text": "right? It's there's a lot of syntax.",
      "offset": 462.96,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "It's not it's not glamorous, but it",
      "offset": 465.28,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "covers everything that you or that a",
      "offset": 468,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "language model needs to know about how",
      "offset": 470.56,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "to make an API request. What is the HTTP",
      "offset": 472,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "method? What is the JSON payload? How do",
      "offset": 474.96,
      "duration": 5.84
    },
    {
      "lang": "en",
      "text": "you send your credentials? What kind of",
      "offset": 478,
      "duration": 4.479
    },
    {
      "lang": "en",
      "text": "response type do you want? Do you want",
      "offset": 480.8,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "to make a blocking request or a an",
      "offset": 482.479,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "asynchronous request? What is the API",
      "offset": 484.4,
      "duration": 4.479
    },
    {
      "lang": "en",
      "text": "endpoint? That's all covered in this one",
      "offset": 486.8,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "little line of code. And this is exactly",
      "offset": 488.879,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "the kind of thing that LLMs want to",
      "offset": 490.639,
      "duration": 4.481
    },
    {
      "lang": "en",
      "text": "consume. If you give this content to an",
      "offset": 492.639,
      "duration": 4.881
    },
    {
      "lang": "en",
      "text": "LLM, it now knows how to make API",
      "offset": 495.12,
      "duration": 4.639
    },
    {
      "lang": "en",
      "text": "requests to your service. So, it's",
      "offset": 497.52,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "really powerful.",
      "offset": 499.759,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "So, we have a tool called Cog at",
      "offset": 501.84,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "cog.run, run, which is an open source",
      "offset": 504.639,
      "duration": 4.481
    },
    {
      "lang": "en",
      "text": "tool that you can use to package machine",
      "offset": 506.8,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "learning models in productionready",
      "offset": 509.12,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "Docker containers. It creates a",
      "offset": 511.44,
      "duration": 5.039
    },
    {
      "lang": "en",
      "text": "standardized API around your model um",
      "offset": 513.039,
      "duration": 5.521
    },
    {
      "lang": "en",
      "text": "with standard inputs and outputs using",
      "offset": 516.479,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "Open API. So, we took all of Cog's",
      "offset": 518.56,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "documentation and stuffed it into a",
      "offset": 521.839,
      "duration": 5.841
    },
    {
      "lang": "en",
      "text": "single llm.ext file at cog.run. And what",
      "offset": 524,
      "duration": 6.48
    },
    {
      "lang": "en",
      "text": "you can do with that is drop it into",
      "offset": 527.68,
      "duration": 4.719
    },
    {
      "lang": "en",
      "text": "your editor",
      "offset": 530.48,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "on an existing project. Let's say you've",
      "offset": 532.399,
      "duration": 4.241
    },
    {
      "lang": "en",
      "text": "cloned some open source cog model and",
      "offset": 534.399,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "you're like, I don't even really know",
      "offset": 536.64,
      "duration": 2.639
    },
    {
      "lang": "en",
      "text": "how this code works, but I want to",
      "offset": 537.839,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "change it. You open up the model, you",
      "offset": 539.279,
      "duration": 5.361
    },
    {
      "lang": "en",
      "text": "drop a reference to that llm.ext,",
      "offset": 541.92,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "and",
      "offset": 544.64,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "your editor knows how to consume that",
      "offset": 546.56,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "content, bring it into context, and use",
      "offset": 548.72,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "it to write code.",
      "offset": 551.36,
      "duration": 6.4
    },
    {
      "lang": "en",
      "text": "So, pretty powerful stuff.",
      "offset": 554.48,
      "duration": 5.84
    },
    {
      "lang": "en",
      "text": "All right. So the primary audience of",
      "offset": 557.76,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "your thing, your product, service,",
      "offset": 560.32,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "library, etc. is now an LLM, not a",
      "offset": 562.64,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "human.",
      "offset": 565.92,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "This might be like a tough pill to",
      "offset": 568.08,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "swallow, but I think it's the world that",
      "offset": 569.68,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "we're in right now.",
      "offset": 571.76,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "Um, so if you've been at this conference",
      "offset": 574.64,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "for a couple days, you probably heard",
      "offset": 577.12,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "everybody talking about MCP, right? It's",
      "offset": 578.32,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "like such a big deal. But what even is",
      "offset": 580.959,
      "duration": 5.281
    },
    {
      "lang": "en",
      "text": "it? Like how many of you actually feel",
      "offset": 583.44,
      "duration": 6.399
    },
    {
      "lang": "en",
      "text": "like you really know what MCP is?",
      "offset": 586.24,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "Okay, I like the honesty here. Like",
      "offset": 589.839,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "there's like eight hands going up. Okay,",
      "offset": 592,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "so I'm going to explain this for you",
      "offset": 594.16,
      "duration": 6.64
    },
    {
      "lang": "en",
      "text": "hopefully. So open API is this thing",
      "offset": 596.64,
      "duration": 7.28
    },
    {
      "lang": "en",
      "text": "where you write a JSON schema that",
      "offset": 600.8,
      "duration": 5.84
    },
    {
      "lang": "en",
      "text": "defines the behavior of your HTTP API.",
      "offset": 603.92,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "It's basically just a giant JSON file",
      "offset": 606.64,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "that says here are the paths, here are",
      "offset": 609.04,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "the endpoints, here are the query",
      "offset": 611.04,
      "duration": 4.799
    },
    {
      "lang": "en",
      "text": "parameters, here's the payload for the",
      "offset": 612.56,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "body, here's how you run this thing,",
      "offset": 615.839,
      "duration": 3.361
    },
    {
      "lang": "en",
      "text": "here's how you create a prediction,",
      "offset": 617.44,
      "duration": 3.519
    },
    {
      "lang": "en",
      "text": "here's how you get your predictions,",
      "offset": 619.2,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "here's how you search, all that sort of",
      "offset": 620.959,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "stuff. And it's just one big giant JSON",
      "offset": 622.72,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "file that describes your whole behavior",
      "offset": 625.36,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "of your API. So, we have that on",
      "offset": 628,
      "duration": 5.279
    },
    {
      "lang": "en",
      "text": "replicate. And when you go to our HTTP",
      "offset": 629.76,
      "duration": 6.48
    },
    {
      "lang": "en",
      "text": "API page, all the content on this page",
      "offset": 633.279,
      "duration": 5.441
    },
    {
      "lang": "en",
      "text": "is generated from that schema. So we",
      "offset": 636.24,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "just have a template that renders it all",
      "offset": 638.72,
      "duration": 5.359
    },
    {
      "lang": "en",
      "text": "out as a human friendly representation",
      "offset": 641.12,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "of how to use our API. Here's an example",
      "offset": 644.079,
      "duration": 6.481
    },
    {
      "lang": "en",
      "text": "where you can search for models. So",
      "offset": 646.32,
      "duration": 8.079
    },
    {
      "lang": "en",
      "text": "here's where the MCP part comes in. So",
      "offset": 650.56,
      "duration": 6.16
    },
    {
      "lang": "en",
      "text": "MCP is basically a way of taking an open",
      "offset": 654.399,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "API schema",
      "offset": 656.72,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "and stuffing it into a format where a",
      "offset": 658.72,
      "duration": 6.239
    },
    {
      "lang": "en",
      "text": "language model knows what to do with it.",
      "offset": 661.76,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "So we now have an MCP server for",
      "offset": 664.959,
      "duration": 4.801
    },
    {
      "lang": "en",
      "text": "replicate which you can install very",
      "offset": 667.36,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "easily. You basically open up cloud code",
      "offset": 669.76,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "for example cloud desktop not the web",
      "offset": 673.12,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "app.",
      "offset": 675.36,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "um go into your developer settings, add",
      "offset": 677.04,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "this tiny little line of JSON,",
      "offset": 679.519,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "and all of a sudden, Claude now knows",
      "offset": 682.56,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "how to do everything that the Replicate",
      "offset": 685.279,
      "duration": 6.401
    },
    {
      "lang": "en",
      "text": "API can do, and it has an API token. So,",
      "offset": 687.68,
      "duration": 5.599
    },
    {
      "lang": "en",
      "text": "you didn't have to install any software.",
      "offset": 691.68,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "All you had to do is go get a token from",
      "offset": 693.279,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "the Replicate website, and Claude takes",
      "offset": 694.8,
      "duration": 4.719
    },
    {
      "lang": "en",
      "text": "care of the installation of the MCP",
      "offset": 697.44,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "server locally. And now you can see on",
      "offset": 699.519,
      "duration": 6.56
    },
    {
      "lang": "en",
      "text": "this page",
      "offset": 703.12,
      "duration": 4.719
    },
    {
      "lang": "en",
      "text": "you can actually have an interaction",
      "offset": 706.079,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "with cloud",
      "offset": 707.839,
      "duration": 5.841
    },
    {
      "lang": "en",
      "text": "where it's able to run API requests on",
      "offset": 710.16,
      "duration": 6.4
    },
    {
      "lang": "en",
      "text": "replicate for you. So there's a few",
      "offset": 713.68,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "factors here. There's you can use this",
      "offset": 716.56,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "for discovery. So, you don't know how to",
      "offset": 719.12,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "use a product yet and you want to know",
      "offset": 722,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "what it's capable of or you want to use",
      "offset": 723.279,
      "duration": 4.641
    },
    {
      "lang": "en",
      "text": "a language model to do searches for you",
      "offset": 725.44,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "or you want to start um kind of",
      "offset": 727.92,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "scaffolding out the beginning of a",
      "offset": 731.12,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "project",
      "offset": 732.72,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "and you want your language model to help",
      "offset": 734.32,
      "duration": 2.959
    },
    {
      "lang": "en",
      "text": "you with that. So, that's exactly what",
      "offset": 735.76,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "MCP is for. It's a way of connecting",
      "offset": 737.279,
      "duration": 6.721
    },
    {
      "lang": "en",
      "text": "tools to your language model so that it",
      "offset": 741.12,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "can do all sorts of powerful things. And",
      "offset": 744,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "I want to emphasize here that",
      "offset": 746.32,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "at Replicate all we really had to do to",
      "offset": 749.2,
      "duration": 5.199
    },
    {
      "lang": "en",
      "text": "make this possible was invest in having",
      "offset": 751.6,
      "duration": 5.359
    },
    {
      "lang": "en",
      "text": "an open API schema that was very well",
      "offset": 754.399,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "written, very well documented",
      "offset": 756.959,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "that um covered everything that our API",
      "offset": 759.519,
      "duration": 5.521
    },
    {
      "lang": "en",
      "text": "is capable of doing and the process of",
      "offset": 762.639,
      "duration": 5.041
    },
    {
      "lang": "en",
      "text": "turning that into an MCP server that can",
      "offset": 765.04,
      "duration": 6.64
    },
    {
      "lang": "en",
      "text": "then connect with tools like Claude, uh",
      "offset": 767.68,
      "duration": 6.8
    },
    {
      "lang": "en",
      "text": "GitHub Copilot and Visual Studio Code.",
      "offset": 771.68,
      "duration": 5.839
    },
    {
      "lang": "en",
      "text": "Um, and now actually I think OpenAI",
      "offset": 774.48,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "added MCP support to their agents SDK",
      "offset": 777.519,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "earlier this week. So MCP is just going",
      "offset": 780.24,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "to be all over the map and it's a way to",
      "offset": 782.079,
      "duration": 5.521
    },
    {
      "lang": "en",
      "text": "really accommodate language models",
      "offset": 784.32,
      "duration": 6.72
    },
    {
      "lang": "en",
      "text": "helping you do things. So",
      "offset": 787.6,
      "duration": 7.76
    },
    {
      "lang": "en",
      "text": "um this is sort of a note to self uh for",
      "offset": 791.04,
      "duration": 6.479
    },
    {
      "lang": "en",
      "text": "the things that we got wrong for Andre",
      "offset": 795.36,
      "duration": 3.599
    },
    {
      "lang": "en",
      "text": "and the things that we want to fix. Some",
      "offset": 797.519,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "of them we've already addressed as I",
      "offset": 798.959,
      "duration": 3.201
    },
    {
      "lang": "en",
      "text": "showed in this talk. Some of them we",
      "offset": 800.639,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "still need to get right. So maybe kind",
      "offset": 802.16,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "of a no-brainer, accept payments. Okay,",
      "offset": 804.959,
      "duration": 6.161
    },
    {
      "lang": "en",
      "text": "so Andre went on the website, he signed",
      "offset": 807.92,
      "duration": 6.64
    },
    {
      "lang": "en",
      "text": "up for an API key, he entered his credit",
      "offset": 811.12,
      "duration": 5.92
    },
    {
      "lang": "en",
      "text": "card info in replicate, you know,",
      "offset": 814.56,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "basically legitimate user, and then he",
      "offset": 817.04,
      "duration": 4.479
    },
    {
      "lang": "en",
      "text": "started hammering replicate with API",
      "offset": 819.68,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "requests to generate images of French",
      "offset": 821.519,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "toast. and",
      "offset": 823.6,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "whatever for whatever reason the way he",
      "offset": 825.92,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "was doing it he was making a ton of API",
      "offset": 827.92,
      "duration": 3.599
    },
    {
      "lang": "en",
      "text": "requests and he triggered some kind of",
      "offset": 829.76,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "abuse mechanism in our website that said",
      "offset": 831.519,
      "duration": 4.641
    },
    {
      "lang": "en",
      "text": "oh well this users only existed for one",
      "offset": 834.32,
      "duration": 2.959
    },
    {
      "lang": "en",
      "text": "hour and they've already sent us a",
      "offset": 836.16,
      "duration": 2.479
    },
    {
      "lang": "en",
      "text": "thousand requests something must be",
      "offset": 837.279,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "wrong so we blocked him and this isn't",
      "offset": 838.639,
      "duration": 5.921
    },
    {
      "lang": "en",
      "text": "something you want to do right you want",
      "offset": 842.639,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "to let your power users come to your",
      "offset": 844.56,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "product dive right in they know what",
      "offset": 846.48,
      "duration": 3.599
    },
    {
      "lang": "en",
      "text": "they're doing they know what they want",
      "offset": 848.48,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "and don't get in their way luckily uh",
      "offset": 850.079,
      "duration": 5.521
    },
    {
      "lang": "en",
      "text": "our CEO saw this, you know, blog post",
      "offset": 853.12,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "from Andre and immediately contacted him",
      "offset": 855.6,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "and, you know, unblocked his account.",
      "offset": 858.16,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "But not everyone has the power of being",
      "offset": 860.56,
      "duration": 3.519
    },
    {
      "lang": "en",
      "text": "able to write a blog post and have",
      "offset": 862.72,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "everybody in the world see it and know",
      "offset": 864.079,
      "duration": 5.521
    },
    {
      "lang": "en",
      "text": "about it. So the lesson here for us is",
      "offset": 865.92,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "replicate should accept",
      "offset": 869.6,
      "duration": 6.479
    },
    {
      "lang": "en",
      "text": "um payments for credit. So if I go on a",
      "offset": 871.92,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "website, I should be able to say,",
      "offset": 876.079,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "\"Here's 500 bucks. Let me go nuts, do",
      "offset": 877.36,
      "duration": 6.479
    },
    {
      "lang": "en",
      "text": "whatever I want, and don't ban me.\" So,",
      "offset": 879.92,
      "duration": 5.039
    },
    {
      "lang": "en",
      "text": "we're working on that. We're going to",
      "offset": 883.839,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "fix that. Uh, next, document your",
      "offset": 884.959,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "Literally, just when you ship features",
      "offset": 888.079,
      "duration": 5.041
    },
    {
      "lang": "en",
      "text": "on your product, don't just merge the",
      "offset": 890.959,
      "duration": 4.481
    },
    {
      "lang": "en",
      "text": "pull request and walk away. It's not",
      "offset": 893.12,
      "duration": 6.48
    },
    {
      "lang": "en",
      "text": "done until it's documented and the world",
      "offset": 895.44,
      "duration": 6.8
    },
    {
      "lang": "en",
      "text": "knows about it. And an LLM can consume",
      "offset": 899.6,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "the content and put it to use. So,",
      "offset": 902.24,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "always document everything, especially",
      "offset": 904.88,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "now that LLMs are in charge. We're still",
      "offset": 907.04,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "in charge, but you know what I mean. Um,",
      "offset": 910.32,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "okay. Okay, so feed the machines that",
      "offset": 912.16,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "basically is just a matter of um",
      "offset": 914,
      "duration": 6.72
    },
    {
      "lang": "en",
      "text": "producing content in forms that language",
      "offset": 916.8,
      "duration": 6.159
    },
    {
      "lang": "en",
      "text": "models can understand and consume more",
      "offset": 920.72,
      "duration": 7.04
    },
    {
      "lang": "en",
      "text": "easily than traditional HTML web pages.",
      "offset": 922.959,
      "duration": 8.56
    },
    {
      "lang": "en",
      "text": "Use boring technology. So this means um",
      "offset": 927.76,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "if a technology has been around for a",
      "offset": 931.519,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "long time, SQL SQL statements have been",
      "offset": 933.44,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "around since",
      "offset": 935.6,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "I don't know longer than some of us have",
      "offset": 937.839,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "been alive.",
      "offset": 940.56,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "That means that the language models know",
      "offset": 942.16,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "how to how to write SQL because they've",
      "offset": 944.24,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "encountered so much of it. So when",
      "offset": 946.56,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "you're building products, be sure to",
      "offset": 948.56,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "keep in mind that your language models",
      "offset": 950.88,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "are going to have a better chance of",
      "offset": 953.44,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "writing these this software and using it",
      "offset": 955.92,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "if it's a well-established technology",
      "offset": 958.72,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "that doesn't change a lot.",
      "offset": 960.32,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "And lastly, practice good API hygiene.",
      "offset": 962.88,
      "duration": 5.84
    },
    {
      "lang": "en",
      "text": "This means when you're writing your HTTP",
      "offset": 965.68,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "service and you're designing what the",
      "offset": 968.72,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "JSON response should look like, keep in",
      "offset": 971.12,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "mind that it's probably going to be",
      "offset": 973.68,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "going into the context window of a",
      "offset": 975.92,
      "duration": 3.599
    },
    {
      "lang": "en",
      "text": "language model. Now, that has",
      "offset": 977.92,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "limitations. So instead of dumping a",
      "offset": 979.519,
      "duration": 6.481
    },
    {
      "lang": "en",
      "text": "JSON payload response that has",
      "offset": 982.24,
      "duration": 5.599
    },
    {
      "lang": "en",
      "text": "everything about all the models under",
      "offset": 986,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "the sun, consider making it a more",
      "offset": 987.839,
      "duration": 7.201
    },
    {
      "lang": "en",
      "text": "small, slim down,",
      "offset": 991.68,
      "duration": 6.56
    },
    {
      "lang": "en",
      "text": "information dense version of what an LLM",
      "offset": 995.04,
      "duration": 6.08
    },
    {
      "lang": "en",
      "text": "wants to see.",
      "offset": 998.24,
      "duration": 7.839
    },
    {
      "lang": "en",
      "text": "That's all I got. Thank you.",
      "offset": 1001.12,
      "duration": 8.159
    },
    {
      "lang": "en",
      "text": "It looks like I've got two minutes if",
      "offset": 1006.079,
      "duration": 6.76
    },
    {
      "lang": "en",
      "text": "anybody has questions.",
      "offset": 1009.279,
      "duration": 3.56
    },
    {
      "lang": "en",
      "text": "Maybe",
      "offset": 1017.6,
      "duration": 3.599
    },
    {
      "lang": "en",
      "text": "no questions. Okay, I answered",
      "offset": 1019.279,
      "duration": 5.8
    },
    {
      "lang": "en",
      "text": "everything. Here we go.",
      "offset": 1021.199,
      "duration": 3.88
    },
    {
      "lang": "en",
      "text": "Yeah, the question is what are some",
      "offset": 1034.959,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "recommendations for generating docs? So,",
      "offset": 1036.559,
      "duration": 5.441
    },
    {
      "lang": "en",
      "text": "first thing to do just start by",
      "offset": 1039.439,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "generating your own a open API schema.",
      "offset": 1042,
      "duration": 5.199
    },
    {
      "lang": "en",
      "text": "Write schemas in YAML or JSON that",
      "offset": 1044.559,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "describe the behavior of your API.",
      "offset": 1047.199,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "There's a ton of tools out there. Um,",
      "offset": 1049.039,
      "duration": 6.721
    },
    {
      "lang": "en",
      "text": "there's Docsaur Docasaurus, there's uh",
      "offset": 1051.679,
      "duration": 6.961
    },
    {
      "lang": "en",
      "text": "read the docs, there's readme, what is",
      "offset": 1055.76,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "it? Readme.com. There's a whole bunch of",
      "offset": 1058.64,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "these services that know how to take an",
      "offset": 1060.48,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "open API schema and turn it into not",
      "offset": 1063.76,
      "duration": 4.799
    },
    {
      "lang": "en",
      "text": "only documentation, but also you know",
      "offset": 1066.16,
      "duration": 4.639
    },
    {
      "lang": "en",
      "text": "SDKs, um, clients in different",
      "offset": 1068.559,
      "duration": 5.201
    },
    {
      "lang": "en",
      "text": "programming languages, all that stuff.",
      "offset": 1070.799,
      "duration": 5.961
    },
    {
      "lang": "en",
      "text": "Yeah.",
      "offset": 1073.76,
      "duration": 3
    },
    {
      "lang": "en",
      "text": "Uh yeah. So the question was are we",
      "offset": 1084,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "thinking about discovery as the LLM",
      "offset": 1085.679,
      "duration": 3.761
    },
    {
      "lang": "en",
      "text": "start to make purchasing decisions? Was",
      "offset": 1087.84,
      "duration": 4.76
    },
    {
      "lang": "en",
      "text": "that it?",
      "offset": 1089.44,
      "duration": 3.16
    },
    {
      "lang": "en",
      "text": "I think the key to that is making sure",
      "offset": 1095.44,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "that our API um has really good search",
      "offset": 1097.039,
      "duration": 4.801
    },
    {
      "lang": "en",
      "text": "capabilities and that a lot of the",
      "offset": 1100.32,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "information that users need to make",
      "offset": 1101.84,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "informed decisions is actually available",
      "offset": 1103.84,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "via API. So for example with replicate",
      "offset": 1105.6,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "models right now um the pricing is",
      "offset": 1108.4,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "currently something that you have to go",
      "offset": 1111.28,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "to the web page to look at either on the",
      "offset": 1112.64,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "pricing page or on the individual model",
      "offset": 1114.64,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "pages. If we expose pricing um you know",
      "offset": 1116.16,
      "duration": 6.56
    },
    {
      "lang": "en",
      "text": "as a JSON structure that our API can",
      "offset": 1119.76,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "consume that a public user can consume",
      "offset": 1122.72,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "then it becomes a lot easier for you to",
      "offset": 1124.88,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "do something like jump into a session",
      "offset": 1126.32,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "with claude and say oh look I'm",
      "offset": 1128.72,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "evaluating all the video models I'm",
      "offset": 1130.72,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "looking at you know Imagen and or uh you",
      "offset": 1132.48,
      "duration": 6.16
    },
    {
      "lang": "en",
      "text": "know VO and cling and minax and all the",
      "offset": 1135.44,
      "duration": 5.359
    },
    {
      "lang": "en",
      "text": "other things that are out there. Show me",
      "offset": 1138.64,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "a comparison of which models are the",
      "offset": 1140.799,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "most expensive, which ones are the",
      "offset": 1143.76,
      "duration": 2.96
    },
    {
      "lang": "en",
      "text": "fastest, which ones can produce the",
      "offset": 1145.2,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "highest quality output, etc. And if the",
      "offset": 1146.72,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "language model has access to the",
      "offset": 1149.28,
      "duration": 2.96
    },
    {
      "lang": "en",
      "text": "structured data to answer those",
      "offset": 1150.88,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "questions, then it's going to be a lot",
      "offset": 1152.24,
      "duration": 5.559
    },
    {
      "lang": "en",
      "text": "easier to make those decisions.",
      "offset": 1154.08,
      "duration": 3.719
    },
    {
      "lang": "en",
      "text": "All right, thanks y'all.",
      "offset": 1158.799,
      "duration": 3.641
    },
    {
      "lang": "en",
      "text": "[Music]",
      "offset": 1164.4,
      "duration": 2.639
    }
  ],
  "cleanText": "[Music]\nHow many of you know who Andrej Karpathy is? Raise your hand.\nOkay, maybe half of you.\nRaise your hand if you are not Andrej Karpathy.\nJust trying to gauge audience participation here.\nOkay, so I got 80% there or something like that.\nGot a lot of Andrej's in the room right now.\nUm, raise your hand if you work at Replicate.\nAll right, so if you want to talk to any Replicate folks, there's your group right there.\nAll right, so um for those who don't know who Andrej Karpathy is, I will jump into that and explain that.\nUm, these are my uh there's a GitHub repo that corresponds to this um these slides.\nSo if you want to grab that, this will I'll put this slide up at the end too, so you can um track down any URLs or anything that I mention in the talk.\nUh my name is Zeke.\nI am Zeke on GitHub.\nUm Zeke on X as well.\nUm and I work for Replicate.\nSo uh Replicate is a cloud platform that lets you run AI models with an API.\nSo we have um you know open source models like all the great flux models from Black Forest Labs, but we also have you know proprietary models from Anthropic, OpenAI, Google etc.\nUm and of course you can also run your own custom public and private models on Replicate as well.\nSo let's get to the point.\nWho is Andrej Karpathy?\nWell, he's an AI researcher who's worked at all these big uh companies and organizations: Google, OpenAI, Tesla, OpenAI, Eureka Labs.\nUm Eureka Labs is his new thing, an educational uh platform.\nUh, but most importantly to me, he is a YouTube educator and does some really amazing talks that are highly accessible that explain how AI and machine learning works for general audiences.\nUm, he coined the term vibe coding a few months ago and of course that's taken the world by storm.\nWe're all really interested in that now and subscribes to the idea that the hottest new programming language is English.\nUm, kind of a hot take.\nUm, he also wrote something called the software 2.0 manifesto, which was um now seven years ago, kind of an eternity in machine learning time, uh basically predicting this world in which uh machine learning models would write code for us um and that it would be they would be better at it than than humans and so of course here we are.\nUm so today I want to talk about MenuGen.\nSo, MenuGen is um an app that Andrej created recently at a I think he was at a hackathon doing like a a vibe coding experiment.\nSo, MenuGen is basically this web app where you take photos of a menu at a restaurant that's all in a text format and it generates image representations of the contents of the menu for you.\nSo if you don't know what the words mean or English isn't your first language or you just like to see tantalizing photos of food that may be good, um that was the idea behind it.\nSo he was actually able to build this app, which he described as an exhilarating and fun escapade as a local demo but a bit of a painful slog as a deployed real app.\nSo you've probably many of you have probably experienced this where you are working on something locally, you have it running on your machine, oh cool, it really works, it's amazing, and then you try to deploy it to you know, Vercel or Cloudflare or something like that, and that's where a lot of the the pain begins.\nUm so we're going to talk about that.\nSo um Andrej kind of wrote this blog post about the experience of creating MenuGen um and saying, you know, I was able to make this thing, publish it, get it online, uh, add payments for it, and it's a working functioning app that people can pay for, and it was super fun to build.\nHowever, it kind of rakes all these different companies over the coals because of the sort of developer experience challenges of working with all of them.\nSo for me it was cool because it was like, okay, Replicate is mentioned among all these big hot shot companies like OpenAI and Vercel.\nUm, but we also all have work to do to improve our products to make them better.\nSo here's a blur about kind of what he what he experienced when he started using Replicate API.\nSo the LLM's knowledge of Replicate was outdated.\nThe docs on Replicate were out of date.\nUm there were changes in the API.\nHe experienced rate limiting and it was harder to get started with a new legitimate paid account.\nSo, this is kind of embarrassing, but it's also kind of like an opportunity to fix our product and make it better and really listen to, you know, the kind of voices that are loud and correct about the problems with our products.\nSo, what can Replicate do better?\nUm, one of them is embracing llm.text.\nllm.text is this thing where you can uh basically uh modify your website or your API or existing services to um render text-based or markdown-based versions of your documentation in a format that is friendly for language models to consume, more friendly than like the HTML contents of a web page.\nSo said tired elaborate docs pages with fancy color palettes, branding, animations, transitions, dark mode, wired one single docs markdown file and a copy to clipboard button.\nSo it sounds simple um and maybe not the most glamorous thing, but it is actually the thing that your language models want to consume.\nSo in response to this, we added a new feature on the Replicate website where you're viewing any model page.\nYou have a button to copy the contents of that page uh as markdown for a language model or to send the page directly to Claude to have an interaction with the contents of the model page to learn more about what the model can do.\nSimilarly, we added that support for linking to chat GPT.\nYou basically just say I'm on a model page.\nYou jump into chat GPT and you start having a conversation about the model.\nSo, it's a lot more interactive than just going to a web page and reading and trying to find the most relevant content.\nOf course, we also just dump the markdown here, too.\nSo, if you're using a tool like Cursor or Wind Surf, grab this content, put it into your editor, and it knows how to run this model.\nSo, next thing, this was not necessarily from the blog post, but this is from I'm grabbing some quotes from recent uh tweets from Andrej Karpathy.\nSo, LLMs don't like to click, they like to curl.\nSo, love it or love it or hate it, curl is um a tool that is here to stay.\nIt's developed, it's been around for, I don't know, since the 90s maybe.\nUm it's installed on everyone's machine and it is basically a standardized way to be able to make API calls without any specialized tooling.\nSo let's look at this curl command.\nMaybe it looks ugly, right?\nIt's there's a lot of syntax.\nIt's not it's not glamorous, but it covers everything that you or that a language model needs to know about how to make an API request.\nWhat is the HTTP method?\nWhat is the JSON payload?\nHow do you send your credentials?\nWhat kind of response type do you want?\nDo you want to make a blocking request or a an asynchronous request?\nWhat is the API endpoint?\nThat's all covered in this one little line of code.\nAnd this is exactly the kind of thing that LLMs want to consume.\nIf you give this content to an LLM, it now knows how to make API requests to your service.\nSo, it's really powerful.\nSo, we have a tool called Cog at cog.run, which is an open source tool that you can use to package machine learning models in production-ready Docker containers.\nIt creates a standardized API around your model um with standard inputs and outputs using Open API.\nSo, we took all of Cog's documentation and stuffed it into a single llm.ext file at cog.run.\nAnd what you can do with that is drop it into your editor on an existing project.\nLet's say you've cloned some open source cog model and you're like, I don't even really know how this code works, but I want to change it.\nYou open up the model, you drop a reference to that llm.ext, and your editor knows how to consume that content, bring it into context, and use it to write code.\nSo, pretty powerful stuff.\nAll right.\nSo the primary audience of your thing, your product, service, library, etc. is now an LLM, not a human.\nThis might be like a tough pill to swallow, but I think it's the world that we're in right now.\nUm, so if you've been at this conference for a couple days, you probably heard everybody talking about MCP, right?\nIt's like such a big deal.\nBut what even is it?\nLike how many of you actually feel like you really know what MCP is?\nOkay, I like the honesty here.\nLike there's like eight hands going up.\nOkay, so I'm going to explain this for you hopefully.\nSo open API is this thing where you write a JSON schema that defines the behavior of your HTTP API.\nIt's basically just a giant JSON file that says here are the paths, here are the endpoints, here are the query parameters, here's the payload for the body, here's how you run this thing, here's how you create a prediction, here's how you get your predictions, here's how you search, all that sort of stuff.\nAnd it's just one big giant JSON file that describes your whole behavior of your API.\nSo, we have that on Replicate.\nAnd when you go to our HTTP API page, all the content on this page is generated from that schema.\nSo we just have a template that renders it all out as a human friendly representation of how to use our API.\nHere's an example where you can search for models.\nSo here's where the MCP part comes in.\nSo MCP is basically a way of taking an open API schema and stuffing it into a format where a language model knows what to do with it.\nSo we now have an MCP server for Replicate which you can install very easily.\nYou basically open up cloud code, for example, cloud desktop, not the web app.\nUm go into your developer settings, add this tiny little line of JSON, and all of a sudden, Claude now knows how to do everything that the Replicate API can do, and it has an API token.\nSo, you didn't have to install any software.\nAll you had to do is go get a token from the Replicate website, and Claude takes care of the installation of the MCP server locally.\nAnd now you can see on this page you can actually have an interaction with cloud where it's able to run API requests on Replicate for you.\nSo there's a few factors here.\nThere's you can use this for discovery.\nSo, you don't know how to use a product yet and you want to know what it's capable of or you want to use a language model to do searches for you or you want to start um kind of scaffolding out the beginning of a project and you want your language model to help you with that.\nSo, that's exactly what MCP is for.\nIt's a way of connecting tools to your language model so that it can do all sorts of powerful things.\nAnd I want to emphasize here that at Replicate all we really had to do to make this possible was invest in having an open API schema that was very well written, very well documented that um covered everything that our API is capable of doing and the process of turning that into an MCP server that can then connect with tools like Claude, uh GitHub Copilot and Visual Studio Code.\nUm, and now actually I think OpenAI added MCP support to their agents SDK earlier this week.\nSo MCP is just going to be all over the map and it's a way to really accommodate language models helping you do things.\nSo um this is sort of a note to self uh for the things that we got wrong for Andrej and the things that we want to fix.\nSome of them we've already addressed as I showed in this talk.\nSome of them we still need to get right.\nSo maybe kind of a no-brainer, accept payments.\nOkay, so Andrej went on the website, he signed up for an API key, he entered his credit card info in Replicate, you know, basically legitimate user, and then he started hammering Replicate with API requests to generate images of French toast and whatever for whatever reason the way he was doing it he was making a ton of API requests and he triggered some kind of abuse mechanism in our website that said, oh well this users only existed for one hour and they've already sent us a thousand requests, something must be wrong, so we blocked him, and this isn't something you want to do, right?\nYou want to let your power users come to your product, dive right in, they know what they're doing, they know what they want, and don't get in their way.\nLuckily, our CEO saw this, you know, blog post from Andrej and immediately contacted him and, you know, unblocked his account.\nBut not everyone has the power of being able to write a blog post and have everybody in the world see it and know about it.\nSo the lesson here for us is Replicate should accept um payments for credit.\nSo if I go on a website, I should be able to say, \"Here's 500 bucks.\nLet me go nuts, do whatever I want, and don't ban me.\"\nSo, we're working on that.\nWe're going to fix that.\nUh, next, document your.\nLiterally, just when you ship features on your product, don't just merge the pull request and walk away.\nIt's not done until it's documented and the world knows about it.\nAnd an LLM can consume the content and put it to use.\nSo, always document everything, especially now that LLMs are in charge.\nWe're still in charge, but you know what I mean.\nUm, okay.\nOkay, so feed the machines that basically is just a matter of um producing content in forms that language models can understand and consume more easily than traditional HTML web pages.\nUse boring technology.\nSo this means um if a technology has been around for a long time, SQL SQL statements have been around since I don't know, longer than some of us have been alive.\nThat means that the language models know how to how to write SQL because they've encountered so much of it.\nSo when you're building products, be sure to keep in mind that your language models are going to have a better chance of writing these this software and using it if it's a well-established technology that doesn't change a lot.\nAnd lastly, practice good API hygiene.\nThis means when you're writing your HTTP service and you're designing what the JSON response should look like, keep in mind that it's probably going to be going into the context window of a language model.\nNow, that has limitations.\nSo instead of dumping a JSON payload response that has everything about all the models under the sun, consider making it a more small, slim down, information dense version of what an LLM wants to see.\nThat's all I got.\nThank you.\n\n\nIt looks like I've got two minutes if anybody has questions.\nMaybe no questions.\nOkay, I answered everything.\nHere we go.\nYeah, the question is, what are some recommendations for generating docs?\nSo, first thing to do, just start by generating your own open API schema.\nWrite schemas in YAML or JSON that describe the behavior of your API.\nThere's a ton of tools out there.\nUm, there's Docsaur, there's Docasaurus, there's uh read the docs, there's readme, what is it?\nReadme.com.\nThere's a whole bunch of these services that know how to take an open API schema and turn it into not only documentation, but also you know SDKs, um, clients in different programming languages, all that stuff.\nYeah.\nUh yeah.\nSo the question was, are we thinking about discovery as the LLM start to make purchasing decisions?\nWas that it?\nI think the key to that is making sure that our API um has really good search capabilities and that a lot of the information that users need to make informed decisions is actually available via API.\nSo for example with Replicate models right now um the pricing is currently something that you have to go to the web page to look at either on the pricing page or on the individual model pages.\nIf we expose pricing um you know as a JSON structure that our API can consume, that a public user can consume, then it becomes a lot easier for you to do something like jump into a session with Claude and say, \"Oh look, I'm evaluating all the video models.\nI'm looking at you know Imagen and or uh you know VO and cling and minax and all the other things that are out there.\nShow me a comparison of which models are the most expensive, which ones are the fastest, which ones can produce the highest quality output, etc.\"\nAnd if the language model has access to the structured data to answer those questions, then it's going to be a lot easier to make those decisions.\nAll right, thanks y'all.\n[Music]\n",
  "dumpedAt": "2025-07-21T18:43:25.309Z"
}