{
  "episodeId": "_FKeSzM9fPc",
  "channelSlug": "@aidotengineer",
  "title": "ComfyUI Full Workshop â€” first workshop from ComfyAnonymous himself!",
  "publishedAt": "2025-07-19T16:30:06.000Z",
  "rawLines": [
    {
      "lang": "en",
      "text": "[Music]",
      "offset": 4.16,
      "duration": 3.099
    },
    {
      "lang": "en",
      "text": "Uh, good morning everyone. I am Yedri",
      "offset": 15.36,
      "duration": 7.04
    },
    {
      "lang": "en",
      "text": "Kosinski and this is Yeah. Hello. I am",
      "offset": 17.84,
      "duration": 7.519
    },
    {
      "lang": "en",
      "text": "known online as a comfy anonymous, the",
      "offset": 22.4,
      "duration": 7.24
    },
    {
      "lang": "en",
      "text": "original creator of Comfy UI.",
      "offset": 25.359,
      "duration": 4.281
    },
    {
      "lang": "en",
      "text": "and we are part of the Comfy or the",
      "offset": 30.56,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "organization that uh is in charge of",
      "offset": 33.44,
      "duration": 4.639
    },
    {
      "lang": "en",
      "text": "Comfy UI.",
      "offset": 35.52,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "So uh I guess now I have a mic. I'll ask",
      "offset": 38.079,
      "duration": 6.761
    },
    {
      "lang": "en",
      "text": "again who here has heard of Comfy UI?",
      "offset": 40,
      "duration": 4.84
    },
    {
      "lang": "en",
      "text": "All right. All right. This half of the",
      "offset": 44.879,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "room very knowledgeable, very nice, very",
      "offset": 46.719,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "nice. Um, for those unaware, we are an",
      "offset": 48.559,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "open- source note-based design canvas",
      "offset": 51.039,
      "duration": 5.281
    },
    {
      "lang": "en",
      "text": "intended for generative AI purposes for",
      "offset": 53.199,
      "duration": 7.68
    },
    {
      "lang": "en",
      "text": "uh multimodal um creative applications.",
      "offset": 56.32,
      "duration": 6.96
    },
    {
      "lang": "en",
      "text": "We support image, video, audio, 3D,",
      "offset": 60.879,
      "duration": 8.081
    },
    {
      "lang": "en",
      "text": "text, and more uh generative AI models.",
      "offset": 63.28,
      "duration": 7.839
    },
    {
      "lang": "en",
      "text": "Um, Comfy UI supports the absolute",
      "offset": 68.96,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "bleeding edge of generally itch on day",
      "offset": 71.119,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "one. We have Comfy Anonymous here",
      "offset": 73.28,
      "duration": 6.479
    },
    {
      "lang": "en",
      "text": "implementing it from not quite scratch",
      "offset": 76.479,
      "duration": 6.241
    },
    {
      "lang": "en",
      "text": "but it is redesigned from the original",
      "offset": 79.759,
      "duration": 5.281
    },
    {
      "lang": "en",
      "text": "implementations. Uh, we offer open-",
      "offset": 82.72,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "source locally hosted models that",
      "offset": 85.04,
      "duration": 5.119
    },
    {
      "lang": "en",
      "text": "support Nvidia, AMD and Intel hardware.",
      "offset": 87.2,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "And we also support closed source API",
      "offset": 90.159,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "accessible models that we as the name",
      "offset": 92.32,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "suggests just use an API to deliver to",
      "offset": 94.479,
      "duration": 3.521
    },
    {
      "lang": "en",
      "text": "the user.",
      "offset": 96.64,
      "duration": 2.64
    },
    {
      "lang": "en",
      "text": "All this functionality is also",
      "offset": 98,
      "duration": 2.88
    },
    {
      "lang": "en",
      "text": "extendable with community supported",
      "offset": 99.28,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "custom notepads. So anything we do not",
      "offset": 100.88,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "have the time to get to ourselves, the",
      "offset": 103.119,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "community does for us.",
      "offset": 105.36,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "A big part of what makes Comfy UI",
      "offset": 109.119,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "special is the sharability of the",
      "offset": 111.04,
      "duration": 5.359
    },
    {
      "lang": "en",
      "text": "workflows. Any image or video that was",
      "offset": 113.2,
      "duration": 5.519
    },
    {
      "lang": "en",
      "text": "generated by Comfy UI has embedded",
      "offset": 116.399,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "metadata that lets you drag it back into",
      "offset": 118.719,
      "duration": 4.961
    },
    {
      "lang": "en",
      "text": "the canvas and brings you the original",
      "offset": 120.719,
      "duration": 4.881
    },
    {
      "lang": "en",
      "text": "workflow with all of the parameters that",
      "offset": 123.68,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "was used to generate it.",
      "offset": 125.6,
      "duration": 6.96
    },
    {
      "lang": "en",
      "text": "Uh this sort of sharability and virality",
      "offset": 128.8,
      "duration": 6.64
    },
    {
      "lang": "en",
      "text": "has really helped Comfy UI's traction.",
      "offset": 132.56,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "If you do a simple Google search on uh",
      "offset": 135.44,
      "duration": 4.799
    },
    {
      "lang": "en",
      "text": "Comfy UI workflows, you will find pages",
      "offset": 137.76,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "and pages and pages of results from the",
      "offset": 140.239,
      "duration": 4.801
    },
    {
      "lang": "en",
      "text": "past year and a half, most of which are",
      "offset": 142.64,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "still compatible with modern Comfy UI",
      "offset": 145.04,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "versions.",
      "offset": 147.28,
      "duration": 3.679
    },
    {
      "lang": "en",
      "text": "Um,",
      "offset": 149.28,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "in terms of pure numbers, uh, this sort",
      "offset": 150.959,
      "duration": 5.601
    },
    {
      "lang": "en",
      "text": "of share billion virality has over the",
      "offset": 153.76,
      "duration": 5.759
    },
    {
      "lang": "en",
      "text": "past two years taken us to the position",
      "offset": 156.56,
      "duration": 5.92
    },
    {
      "lang": "en",
      "text": "of top 150 most popular GitHub repos of",
      "offset": 159.519,
      "duration": 8.44
    },
    {
      "lang": "en",
      "text": "all time with 78,000 stars.",
      "offset": 162.48,
      "duration": 5.479
    },
    {
      "lang": "en",
      "text": "Any comments? Comfy? Uh, no. All right.",
      "offset": 168.959,
      "duration": 6.161
    },
    {
      "lang": "en",
      "text": "All right.",
      "offset": 172.4,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "uh with more of the traction numbers. We",
      "offset": 175.12,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "have 3 to four million active users. We",
      "offset": 177.76,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "have 20K daily downloads. We have 22,000",
      "offset": 180.08,
      "duration": 5.84
    },
    {
      "lang": "en",
      "text": "custom nodes made by 3,000 public",
      "offset": 183.44,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "developers that we enable in our",
      "offset": 185.92,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "ecosystem. And we've been adopted by",
      "offset": 187.44,
      "duration": 4.879
    },
    {
      "lang": "en",
      "text": "Amazon, Apple, Tensson, Netflix, and",
      "offset": 189.92,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "more. And pretty much any startup these",
      "offset": 192.319,
      "duration": 5.761
    },
    {
      "lang": "en",
      "text": "days built around visual generative AI",
      "offset": 195.92,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "probably has come UI working somewhere",
      "offset": 198.08,
      "duration": 5.439
    },
    {
      "lang": "en",
      "text": "on their back end.",
      "offset": 200.08,
      "duration": 6.64
    },
    {
      "lang": "en",
      "text": "Um, why is Comfy UI popular? Um, it",
      "offset": 203.519,
      "duration": 5.841
    },
    {
      "lang": "en",
      "text": "gives maximal control. You can go beyond",
      "offset": 206.72,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "prompts and interact with models that",
      "offset": 209.36,
      "duration": 6.56
    },
    {
      "lang": "en",
      "text": "give you access to depth maps, line art,",
      "offset": 211.76,
      "duration": 7.52
    },
    {
      "lang": "en",
      "text": "uh, masks, anything like that that is",
      "offset": 215.92,
      "duration": 5.599
    },
    {
      "lang": "en",
      "text": "out in the space. If it's if it's open",
      "offset": 219.28,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "source, we probably either support it",
      "offset": 221.519,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "directly or the community has uh, made",
      "offset": 223.12,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "it possible. We are an all-in-one",
      "offset": 225.84,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "platform for both exploration for",
      "offset": 228.4,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "creatives and automation for developers.",
      "offset": 230.159,
      "duration": 4.961
    },
    {
      "lang": "en",
      "text": "Sometimes those roles can also be",
      "offset": 233.04,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "switched where developers want to",
      "offset": 235.12,
      "duration": 4.479
    },
    {
      "lang": "en",
      "text": "explore tweaking models and seeing how",
      "offset": 236.72,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "things can be extended. And so we offer",
      "offset": 239.599,
      "duration": 5.121
    },
    {
      "lang": "en",
      "text": "that as well through our custom node uh",
      "offset": 242.08,
      "duration": 5.439
    },
    {
      "lang": "en",
      "text": "feature. And because we are open source,",
      "offset": 244.72,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "we do not only depend on the output of",
      "offset": 247.519,
      "duration": 4.241
    },
    {
      "lang": "en",
      "text": "the core team. We can trust the",
      "offset": 250,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "community to let us know anything they'd",
      "offset": 251.76,
      "duration": 5.039
    },
    {
      "lang": "en",
      "text": "want us to work on.",
      "offset": 255.12,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "and also make anything we do not have",
      "offset": 256.799,
      "duration": 6.561
    },
    {
      "lang": "en",
      "text": "the time to work on on our team.",
      "offset": 259.84,
      "duration": 7.68
    },
    {
      "lang": "en",
      "text": "Any comments? Comfy? Uh well I think uh",
      "offset": 263.36,
      "duration": 6.8
    },
    {
      "lang": "en",
      "text": "yeah I think we haven't shown the",
      "offset": 267.52,
      "duration": 5.119
    },
    {
      "lang": "en",
      "text": "interface yet. So yes we have only shown",
      "offset": 270.16,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "one screenshot of the interface at the",
      "offset": 272.639,
      "duration": 4.801
    },
    {
      "lang": "en",
      "text": "very start. We will uh show that off as",
      "offset": 274.8,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "well.",
      "offset": 277.44,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "You want to do it just do it later.",
      "offset": 279.36,
      "duration": 6.559
    },
    {
      "lang": "en",
      "text": "Yeah. All right. Story behind comei.",
      "offset": 282,
      "duration": 6.16
    },
    {
      "lang": "en",
      "text": "the quick stories that uh basically",
      "offset": 285.919,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "confuse. I started as my own personal",
      "offset": 288.16,
      "duration": 6.64
    },
    {
      "lang": "en",
      "text": "project and then I and then uh yeah and",
      "offset": 290.24,
      "duration": 8
    },
    {
      "lang": "en",
      "text": "then which yeah I started in January",
      "offset": 294.8,
      "duration": 7.36
    },
    {
      "lang": "en",
      "text": "January 2023 and then",
      "offset": 298.24,
      "duration": 6.16
    },
    {
      "lang": "en",
      "text": "six months later I was hired at",
      "offset": 302.16,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "stability AI. So I spent one year at",
      "offset": 304.4,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "stability AI. they were using Comfy for",
      "offset": 307.36,
      "duration": 6.48
    },
    {
      "lang": "en",
      "text": "uh for more uh like experimentation",
      "offset": 310.08,
      "duration": 6.88
    },
    {
      "lang": "en",
      "text": "with uh internal experimentation with",
      "offset": 313.84,
      "duration": 6.639
    },
    {
      "lang": "en",
      "text": "the models and then I left stability AI",
      "offset": 316.96,
      "duration": 7.6
    },
    {
      "lang": "en",
      "text": "in June 2024 and then I joined up with",
      "offset": 320.479,
      "duration": 8.641
    },
    {
      "lang": "en",
      "text": "Yolan and Robin and we uh we made like",
      "offset": 324.56,
      "duration": 10.079
    },
    {
      "lang": "en",
      "text": "the comfy company and uh yeah that's uh",
      "offset": 329.12,
      "duration": 7.68
    },
    {
      "lang": "en",
      "text": "things have been going pretty well since",
      "offset": 334.639,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "then. So,",
      "offset": 336.8,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "yep. And this picture was taken on the",
      "offset": 338.96,
      "duration": 5.519
    },
    {
      "lang": "en",
      "text": "Yeah, we we went uh that that picture we",
      "offset": 342.16,
      "duration": 6.879
    },
    {
      "lang": "en",
      "text": "went on top of Mount Fuji uh which uh I",
      "offset": 344.479,
      "duration": 8.081
    },
    {
      "lang": "en",
      "text": "don't recommend. It's uh very very",
      "offset": 349.039,
      "duration": 7.041
    },
    {
      "lang": "en",
      "text": "difficult, but uh yeah, but we did it.",
      "offset": 352.56,
      "duration": 6.56
    },
    {
      "lang": "en",
      "text": "So, yeah, I lucked out and my flight to",
      "offset": 356.08,
      "duration": 7.28
    },
    {
      "lang": "en",
      "text": "Japan uh got rerouted to Alaska for 24",
      "offset": 359.12,
      "duration": 8.72
    },
    {
      "lang": "en",
      "text": "hours. So I landed in Tokyo 5 hours",
      "offset": 363.36,
      "duration": 6.64
    },
    {
      "lang": "en",
      "text": "before they were going to be waking up",
      "offset": 367.84,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "to go to Mount Fuji. So I got to Yeah.",
      "offset": 370,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "So you you missed the fun. I missed the",
      "offset": 372.88,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "fun and then still got sick for a week",
      "offset": 375.6,
      "duration": 6.68
    },
    {
      "lang": "en",
      "text": "right afterwards. Yeah.",
      "offset": 377.84,
      "duration": 4.44
    },
    {
      "lang": "en",
      "text": "Yeah. All right. And like to know that",
      "offset": 382.4,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "Comfyorg is indeed hiring. Uh you can",
      "offset": 384.639,
      "duration": 4.241
    },
    {
      "lang": "en",
      "text": "look at any opportunities on",
      "offset": 387.68,
      "duration": 4.2
    },
    {
      "lang": "en",
      "text": "Comfy.orgcareers.",
      "offset": 388.88,
      "duration": 3
    },
    {
      "lang": "en",
      "text": "Yeah. Yeah. We yeah, we're hiring for a",
      "offset": 392.16,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "bunch of stuff. So, if you're interested",
      "offset": 394.88,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "in joining us, if you're interested in",
      "offset": 396.88,
      "duration": 5.439
    },
    {
      "lang": "en",
      "text": "opensource uh generative AI, well,",
      "offset": 399.28,
      "duration": 7.12
    },
    {
      "lang": "en",
      "text": "that's uh maybe uh yeah, maybe we have a",
      "offset": 402.319,
      "duration": 8.241
    },
    {
      "lang": "en",
      "text": "a spot for you on our team. So,",
      "offset": 406.4,
      "duration": 5.919
    },
    {
      "lang": "en",
      "text": "you haven't checked out the website.",
      "offset": 410.56,
      "duration": 4.639
    },
    {
      "lang": "en",
      "text": "That is all for the official slides, but",
      "offset": 412.319,
      "duration": 6.561
    },
    {
      "lang": "en",
      "text": "now is the fun part of showing the UI",
      "offset": 415.199,
      "duration": 8.201
    },
    {
      "lang": "en",
      "text": "and taking any questions you may have.",
      "offset": 418.88,
      "duration": 4.52
    },
    {
      "lang": "en",
      "text": "Nice. I'm sure many on this side of the",
      "offset": 428.8,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "room who are familiar with Comfy UI know",
      "offset": 431.52,
      "duration": 6.079
    },
    {
      "lang": "en",
      "text": "this standard uh galaxy bottle workflow.",
      "offset": 433.44,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "Unfortunately, this spoils the results.",
      "offset": 437.599,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "I'll just shake up the seed.",
      "offset": 439.44,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "Anyone not familiar with Comfy UI? This",
      "offset": 442.639,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "is all being locally rendered. Yeah, but",
      "offset": 444.56,
      "duration": 5.359
    },
    {
      "lang": "en",
      "text": "this is a very old model. This is SD",
      "offset": 447.199,
      "duration": 5.201
    },
    {
      "lang": "en",
      "text": "1.5. Yes, this is so that's why the",
      "offset": 449.919,
      "duration": 4.881
    },
    {
      "lang": "en",
      "text": "results are not not very good. Yes, this",
      "offset": 452.4,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "model was I think the one that inspired",
      "offset": 454.8,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "your initial work on comfy UI at the",
      "offset": 457.52,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "time. Yeah. Well, fine-tunes of this",
      "offset": 460.4,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "model. This is the base model which",
      "offset": 462.88,
      "duration": 6.24
    },
    {
      "lang": "en",
      "text": "isn't very good. But yeah, this is but",
      "offset": 466.16,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "it's very fast. So, it's very fast but",
      "offset": 469.12,
      "duration": 6.479
    },
    {
      "lang": "en",
      "text": "it is ancient tech at this point.",
      "offset": 471.68,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "Yeah, it's almost three years old at",
      "offset": 475.599,
      "duration": 5.361
    },
    {
      "lang": "en",
      "text": "this point. Yeah,",
      "offset": 477.68,
      "duration": 6.28
    },
    {
      "lang": "en",
      "text": "ancient.",
      "offset": 480.96,
      "duration": 3
    },
    {
      "lang": "en",
      "text": "All right. And there's the UI like",
      "offset": 486.08,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "you're you're you're looking at it.",
      "offset": 487.599,
      "duration": 7.841
    },
    {
      "lang": "en",
      "text": "Yeah. So, basically what Comfy does for",
      "offset": 491.52,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "those who are not familiar, it kind of",
      "offset": 495.44,
      "duration": 5.039
    },
    {
      "lang": "en",
      "text": "splits the whole diffusion pipeline into",
      "offset": 497.28,
      "duration": 6.4
    },
    {
      "lang": "en",
      "text": "these different components. like a",
      "offset": 500.479,
      "duration": 6.16
    },
    {
      "lang": "en",
      "text": "stable diffusion model is a diffusion",
      "offset": 503.68,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "model, a text encoder and a VAE, which",
      "offset": 506.639,
      "duration": 7.921
    },
    {
      "lang": "en",
      "text": "is why you have those three things",
      "offset": 509.68,
      "duration": 8.32
    },
    {
      "lang": "en",
      "text": "right here. So yeah model diffusion",
      "offset": 514.56,
      "duration": 8.64
    },
    {
      "lang": "en",
      "text": "model clip is the text encoder VA the VA",
      "offset": 518,
      "duration": 9.76
    },
    {
      "lang": "en",
      "text": "and then so have the sampler",
      "offset": 523.2,
      "duration": 9.12
    },
    {
      "lang": "en",
      "text": "VA decode and save image and that's",
      "offset": 527.76,
      "duration": 7.36
    },
    {
      "lang": "en",
      "text": "basically a basic uh diffusion model",
      "offset": 532.32,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "pipeline",
      "offset": 535.12,
      "duration": 5.279
    },
    {
      "lang": "en",
      "text": "and what that lets you do is you can",
      "offset": 536.88,
      "duration": 7.92
    },
    {
      "lang": "en",
      "text": "check which models you have on here.",
      "offset": 540.399,
      "duration": 8.081
    },
    {
      "lang": "en",
      "text": "Not many. Oh, maybe SDXL is Yeah, that",
      "offset": 544.8,
      "duration": 7.84
    },
    {
      "lang": "en",
      "text": "one should work for the I can uh type",
      "offset": 548.48,
      "duration": 8.2
    },
    {
      "lang": "en",
      "text": "those numbers in for you.",
      "offset": 552.64,
      "duration": 4.04
    },
    {
      "lang": "en",
      "text": "My uh rookie mistake of turning off my",
      "offset": 559.12,
      "duration": 6.04
    },
    {
      "lang": "en",
      "text": "num lock.",
      "offset": 561.839,
      "duration": 3.321
    },
    {
      "lang": "en",
      "text": "Let's see how quick my disc drive is.",
      "offset": 571.68,
      "duration": 7.04
    },
    {
      "lang": "en",
      "text": "Yeah, this is all running on the laptop.",
      "offset": 576.24,
      "duration": 7.36
    },
    {
      "lang": "en",
      "text": "That's why it's uh a bit slow, but",
      "offset": 578.72,
      "duration": 9.239
    },
    {
      "lang": "en",
      "text": "once it samples, we'll get there.",
      "offset": 583.6,
      "duration": 4.359
    },
    {
      "lang": "en",
      "text": "So, yeah. So, this does look a lot",
      "offset": 599.2,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "better than that. Yeah, this model is",
      "offset": 601.12,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "still also ancient. I think this one's",
      "offset": 602.88,
      "duration": 4.959
    },
    {
      "lang": "en",
      "text": "two years old at this point. This one's",
      "offset": 604.88,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "two years old.",
      "offset": 607.839,
      "duration": 4.961
    },
    {
      "lang": "en",
      "text": "Yeah, we have more exciting workflows",
      "offset": 610.16,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "though. If we browse the templates, if",
      "offset": 612.8,
      "duration": 5.84
    },
    {
      "lang": "en",
      "text": "you want to go a little advanced,",
      "offset": 615.12,
      "duration": 6.08
    },
    {
      "lang": "en",
      "text": "we've got There we go. This will not run",
      "offset": 618.64,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "because I do not have like 60 gigabytes",
      "offset": 621.2,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "worth of models,",
      "offset": 623.6,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "but here's what that workflow looks",
      "offset": 625.6,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "like. Yeah, this is what a video",
      "offset": 627.6,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "workflow looks like which you you can",
      "offset": 629.76,
      "duration": 5.759
    },
    {
      "lang": "en",
      "text": "see it's very similar from a from one of",
      "offset": 632.88,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "the image workflows. It's just you still",
      "offset": 635.519,
      "duration": 5.281
    },
    {
      "lang": "en",
      "text": "have the",
      "offset": 638.48,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "the sampling",
      "offset": 640.8,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "node with different settings",
      "offset": 642.72,
      "duration": 8.4
    },
    {
      "lang": "en",
      "text": "and same VA code node which is kind of",
      "offset": 646.32,
      "duration": 6.88
    },
    {
      "lang": "en",
      "text": "hidden here",
      "offset": 651.12,
      "duration": 6.159
    },
    {
      "lang": "en",
      "text": "and yeah so",
      "offset": 653.2,
      "duration": 8
    },
    {
      "lang": "en",
      "text": "so this is this is the the one 2.1 model",
      "offset": 657.279,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "that's probably the best open video",
      "offset": 661.2,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "model at the moment and you can see the",
      "offset": 663.279,
      "duration": 4.881
    },
    {
      "lang": "en",
      "text": "the pipeline is still very similar to",
      "offset": 665.44,
      "duration": 6.24
    },
    {
      "lang": "en",
      "text": "even the first uh stable diffusion 1.5",
      "offset": 668.16,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "model that was that we were presenting",
      "offset": 671.68,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "earlier.",
      "offset": 673.92,
      "duration": 7.44
    },
    {
      "lang": "en",
      "text": "So yeah, but what that lets you",
      "offset": 676.32,
      "duration": 8.24
    },
    {
      "lang": "en",
      "text": "do the fact that you can uh you can go",
      "offset": 681.36,
      "duration": 8.08
    },
    {
      "lang": "en",
      "text": "and change things like say if I want to",
      "offset": 684.56,
      "duration": 7.88
    },
    {
      "lang": "en",
      "text": "uh",
      "offset": 689.44,
      "duration": 3
    },
    {
      "lang": "en",
      "text": "like this is one of a technique that uh",
      "offset": 694.88,
      "duration": 7.199
    },
    {
      "lang": "en",
      "text": "this is basically this node that I just",
      "offset": 698.959,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "added. What it does is it u it's a what",
      "offset": 702.079,
      "duration": 7.361
    },
    {
      "lang": "en",
      "text": "I call a cfg trick. So it it will add",
      "offset": 704.959,
      "duration": 9.12
    },
    {
      "lang": "en",
      "text": "something to the uh to the sampling to",
      "offset": 709.44,
      "duration": 6.72
    },
    {
      "lang": "en",
      "text": "the cfg calculations of the sampling",
      "offset": 714.079,
      "duration": 6.88
    },
    {
      "lang": "en",
      "text": "code. So basically it's you can easily",
      "offset": 716.16,
      "duration": 10.96
    },
    {
      "lang": "en",
      "text": "write these nodes which uh which will",
      "offset": 720.959,
      "duration": 9.041
    },
    {
      "lang": "en",
      "text": "change. So you can go and just patch the",
      "offset": 727.12,
      "duration": 6.399
    },
    {
      "lang": "en",
      "text": "pipeline this way just by add just by",
      "offset": 730,
      "duration": 6.48
    },
    {
      "lang": "en",
      "text": "either writing your own nodes or using",
      "offset": 733.519,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "nodes that already exist. And for anyone",
      "offset": 736.48,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "unfamiliar with CFG, it is a",
      "offset": 738.639,
      "duration": 6.481
    },
    {
      "lang": "en",
      "text": "AI trick where you take the positive",
      "offset": 742.16,
      "duration": 6.08
    },
    {
      "lang": "en",
      "text": "prompt, you sample on that, you take the",
      "offset": 745.12,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "negative prompt, in this case text and",
      "offset": 748.24,
      "duration": 4.719
    },
    {
      "lang": "en",
      "text": "watermark, you sample on that, and with",
      "offset": 750.16,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "the magic of AI, you literally subtract",
      "offset": 752.959,
      "duration": 5.761
    },
    {
      "lang": "en",
      "text": "the results from each other, and that in",
      "offset": 755.76,
      "duration": 5.199
    },
    {
      "lang": "en",
      "text": "some way improves the image result.",
      "offset": 758.72,
      "duration": 5.679
    },
    {
      "lang": "en",
      "text": "Yeah, I think we can Yeah, I think we",
      "offset": 760.959,
      "duration": 6.801
    },
    {
      "lang": "en",
      "text": "can take Does anyone have any questions",
      "offset": 764.399,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "about anything",
      "offset": 767.76,
      "duration": 5.519
    },
    {
      "lang": "en",
      "text": "like or anything in general related to",
      "offset": 770.399,
      "duration": 8.44
    },
    {
      "lang": "en",
      "text": "comfy UI? We have a question right here.",
      "offset": 773.279,
      "duration": 5.56
    },
    {
      "lang": "en",
      "text": "Yeah.",
      "offset": 781.68,
      "duration": 3
    },
    {
      "lang": "en",
      "text": "Uh yeah, those are basically those clip.",
      "offset": 785.279,
      "duration": 7.601
    },
    {
      "lang": "en",
      "text": "You know what clip is? Yeah. It's uh",
      "offset": 789.36,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "basically the diffusion models they use",
      "offset": 792.88,
      "duration": 5.519
    },
    {
      "lang": "en",
      "text": "the text encoder part of the clip model",
      "offset": 795.12,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "to",
      "offset": 798.399,
      "duration": 4.481
    },
    {
      "lang": "en",
      "text": "it's instead of so instead of passing",
      "offset": 800.16,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "the text directly to the model they use",
      "offset": 802.88,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "this uh a text encoder because that way",
      "offset": 805.36,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "the model doesn't have to the diffusion",
      "offset": 808.56,
      "duration": 4.959
    },
    {
      "lang": "en",
      "text": "model doesn't have to learn like all the",
      "offset": 811.12,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "to understand human language. it can",
      "offset": 813.519,
      "duration": 5.201
    },
    {
      "lang": "en",
      "text": "just learn the output embeddings of",
      "offset": 816.56,
      "duration": 6.48
    },
    {
      "lang": "en",
      "text": "whatever text encoder you use. So yeah,",
      "offset": 818.72,
      "duration": 8.32
    },
    {
      "lang": "en",
      "text": "so the this is uh basically the clip in",
      "offset": 823.04,
      "duration": 6.72
    },
    {
      "lang": "en",
      "text": "comfy UI represents the text encoder.",
      "offset": 827.04,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "The reason it's named clip is because",
      "offset": 829.76,
      "duration": 5.759
    },
    {
      "lang": "en",
      "text": "before like on the stable diffusion",
      "offset": 832.48,
      "duration": 5.84
    },
    {
      "lang": "en",
      "text": "models they were only using clip as the",
      "offset": 835.519,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "text encoder",
      "offset": 838.32,
      "duration": 5.84
    },
    {
      "lang": "en",
      "text": "but in later models it's more they start",
      "offset": 840.079,
      "duration": 6.481
    },
    {
      "lang": "en",
      "text": "later models started using different",
      "offset": 844.16,
      "duration": 5.359
    },
    {
      "lang": "en",
      "text": "text encoders that were not clips. So",
      "offset": 846.56,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "the name I should yeah the name should",
      "offset": 849.519,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "be changed but uh yeah so what this does",
      "offset": 852.56,
      "duration": 5.519
    },
    {
      "lang": "en",
      "text": "is it essentially what this note does is",
      "offset": 855.519,
      "duration": 5.281
    },
    {
      "lang": "en",
      "text": "it passes the text through the text",
      "offset": 858.079,
      "duration": 5.521
    },
    {
      "lang": "en",
      "text": "encoder and then the output would",
      "offset": 860.8,
      "duration": 5.599
    },
    {
      "lang": "en",
      "text": "essentially be the output embeddings of",
      "offset": 863.6,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "or the last hidden the last hidden state",
      "offset": 866.399,
      "duration": 5.921
    },
    {
      "lang": "en",
      "text": "essentially of the text encoder and",
      "offset": 869.6,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "that's usually well it depends it's",
      "offset": 872.32,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "slightly different for every for every",
      "offset": 875.36,
      "duration": 5.039
    },
    {
      "lang": "en",
      "text": "model But essentially it's the most of",
      "offset": 877.92,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "them it's the last hidden state or the",
      "offset": 880.399,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "penultimate hidden state that is passed",
      "offset": 882.88,
      "duration": 6.6
    },
    {
      "lang": "en",
      "text": "to the diffusion model.",
      "offset": 885.279,
      "duration": 4.201
    },
    {
      "lang": "en",
      "text": "Yeah. Because this is a positive and",
      "offset": 891.6,
      "duration": 8.4
    },
    {
      "lang": "en",
      "text": "negative prompt. This is how the CF like",
      "offset": 895.44,
      "duration": 8.079
    },
    {
      "lang": "en",
      "text": "because the models how you sample most",
      "offset": 900,
      "duration": 6.16
    },
    {
      "lang": "en",
      "text": "of these diffusion models is with a",
      "offset": 903.519,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "positive and a negative prompt and",
      "offset": 906.16,
      "duration": 6.64
    },
    {
      "lang": "en",
      "text": "that's a using CFG something called",
      "offset": 908.959,
      "duration": 7.201
    },
    {
      "lang": "en",
      "text": "classifier free guidance CFG",
      "offset": 912.8,
      "duration": 6.64
    },
    {
      "lang": "en",
      "text": "and what it basically the the idea is",
      "offset": 916.16,
      "duration": 6.56
    },
    {
      "lang": "en",
      "text": "that if you only sample with a positive",
      "offset": 919.44,
      "duration": 8.56
    },
    {
      "lang": "en",
      "text": "prompt so yeah if I put cfg G to one.",
      "offset": 922.72,
      "duration": 8.32
    },
    {
      "lang": "en",
      "text": "That's essentially just sampling with a",
      "offset": 928,
      "duration": 5.839
    },
    {
      "lang": "en",
      "text": "positive prompt. And you you can see",
      "offset": 931.04,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "what happens when you you only sample",
      "offset": 933.839,
      "duration": 6.481
    },
    {
      "lang": "en",
      "text": "with a positive prompt. It's a",
      "offset": 935.92,
      "duration": 8.32
    },
    {
      "lang": "en",
      "text": "you can see that the image is wait this",
      "offset": 940.32,
      "duration": 6.879
    },
    {
      "lang": "en",
      "text": "is worse than well. Okay. It's because I",
      "offset": 944.24,
      "duration": 6.24
    },
    {
      "lang": "en",
      "text": "have this node. Well, this is worse than",
      "offset": 947.199,
      "duration": 6.241
    },
    {
      "lang": "en",
      "text": "it should be. But uh",
      "offset": 950.48,
      "duration": 6.32
    },
    {
      "lang": "en",
      "text": "Okay. Yeah. If I Yeah. If I sample with",
      "offset": 953.44,
      "duration": 6.48
    },
    {
      "lang": "en",
      "text": "just uh",
      "offset": 956.8,
      "duration": 6.64
    },
    {
      "lang": "en",
      "text": "just the posit you see that it's uh the",
      "offset": 959.92,
      "duration": 7.12
    },
    {
      "lang": "en",
      "text": "image is not very well defined.",
      "offset": 963.44,
      "duration": 6.88
    },
    {
      "lang": "en",
      "text": "It's very chaotic if you only So what",
      "offset": 967.04,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "CFG does it's a trick because if you",
      "offset": 970.32,
      "duration": 5.92
    },
    {
      "lang": "en",
      "text": "think of all the possibilities of what",
      "offset": 973.04,
      "duration": 8
    },
    {
      "lang": "en",
      "text": "the model can generate it's kind if you",
      "offset": 976.24,
      "duration": 8.48
    },
    {
      "lang": "en",
      "text": "it's kind of a way to push for like the",
      "offset": 981.04,
      "duration": 7.599
    },
    {
      "lang": "en",
      "text": "CFG scale does when sampling it does",
      "offset": 984.72,
      "duration": 6.88
    },
    {
      "lang": "en",
      "text": "positive minus negative prompt and it's",
      "offset": 988.639,
      "duration": 7.361
    },
    {
      "lang": "en",
      "text": "a way to push the sampling very more",
      "offset": 991.6,
      "duration": 7.12
    },
    {
      "lang": "en",
      "text": "towards your positive and away from your",
      "offset": 996,
      "duration": 5.759
    },
    {
      "lang": "en",
      "text": "negative. So the higher the scale, the",
      "offset": 998.72,
      "duration": 7.2
    },
    {
      "lang": "en",
      "text": "more it will do that, which means you",
      "offset": 1001.759,
      "duration": 7.681
    },
    {
      "lang": "en",
      "text": "get a more defined image.",
      "offset": 1005.92,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "I don't know if uh my explanation makes",
      "offset": 1009.44,
      "duration": 8.28
    },
    {
      "lang": "en",
      "text": "sense, but uh Yep. Yep.",
      "offset": 1011.92,
      "duration": 5.8
    },
    {
      "lang": "en",
      "text": "Yeah. the VA is because the what made",
      "offset": 1021.519,
      "duration": 6.721
    },
    {
      "lang": "en",
      "text": "stable diffusion be ex work extremely",
      "offset": 1024.4,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "well",
      "offset": 1028.24,
      "duration": 4.719
    },
    {
      "lang": "en",
      "text": "and uh yeah what what made stable",
      "offset": 1030,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "diffusion be extremely popular is the",
      "offset": 1032.959,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "fact that the the image generation",
      "offset": 1035.12,
      "duration": 6.719
    },
    {
      "lang": "en",
      "text": "happens in compressed latent space. So",
      "offset": 1038.079,
      "duration": 7.201
    },
    {
      "lang": "en",
      "text": "instead of doing it in pixel space on a",
      "offset": 1041.839,
      "duration": 7.601
    },
    {
      "lang": "en",
      "text": "like let's say a 5 thou a 512 x 512",
      "offset": 1045.28,
      "duration": 7.12
    },
    {
      "lang": "en",
      "text": "image in pixel space that's that's a lot",
      "offset": 1049.44,
      "duration": 5.599
    },
    {
      "lang": "en",
      "text": "of pixels or some earlier diffusion",
      "offset": 1052.4,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "models did that but they were pretty",
      "offset": 1055.039,
      "duration": 6.561
    },
    {
      "lang": "en",
      "text": "slow. stable diffusion. It did this in a",
      "offset": 1058,
      "duration": 6.24
    },
    {
      "lang": "en",
      "text": "latent space which uh for a stable",
      "offset": 1061.6,
      "duration": 5.84
    },
    {
      "lang": "en",
      "text": "diffusion the VAE is 8x compressed on",
      "offset": 1064.24,
      "duration": 6.24
    },
    {
      "lang": "en",
      "text": "every uh on every on the two two",
      "offset": 1067.44,
      "duration": 7.599
    },
    {
      "lang": "en",
      "text": "dimensions. So yeah, so instead of uh",
      "offset": 1070.48,
      "duration": 9.439
    },
    {
      "lang": "en",
      "text": "sampling a uh yeah, a 512* 512, you",
      "offset": 1075.039,
      "duration": 9.361
    },
    {
      "lang": "en",
      "text": "would be sampling a 64* 64 image, which",
      "offset": 1079.919,
      "duration": 8.321
    },
    {
      "lang": "en",
      "text": "is which is why these models are got so",
      "offset": 1084.4,
      "duration": 6.48
    },
    {
      "lang": "en",
      "text": "popular because they were a lot more",
      "offset": 1088.24,
      "duration": 6.64
    },
    {
      "lang": "en",
      "text": "efficient than what came before.",
      "offset": 1090.88,
      "duration": 6.32
    },
    {
      "lang": "en",
      "text": "So yeah, so that's what the VA the VA is",
      "offset": 1094.88,
      "duration": 6.159
    },
    {
      "lang": "en",
      "text": "just a Yeah, it's a VAE. In input is",
      "offset": 1097.2,
      "duration": 7.28
    },
    {
      "lang": "en",
      "text": "like 512 * 512 * 3 channel and output",
      "offset": 1101.039,
      "duration": 8.64
    },
    {
      "lang": "en",
      "text": "would be uh would be yeah 64 * 64 * 4",
      "offset": 1104.48,
      "duration": 9.52
    },
    {
      "lang": "en",
      "text": "channel in the case of uh of this model.",
      "offset": 1109.679,
      "duration": 8.201
    },
    {
      "lang": "en",
      "text": "Awesome. Thank you so much.",
      "offset": 1114,
      "duration": 3.88
    },
    {
      "lang": "en",
      "text": "All right, we have a question right here",
      "offset": 1123.2,
      "duration": 6.04
    },
    {
      "lang": "en",
      "text": "and I'll I'll give you the mic.",
      "offset": 1125.2,
      "duration": 4.04
    },
    {
      "lang": "en",
      "text": "Thank you. So, um, Kofio is really in a",
      "offset": 1133.36,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "lot of the examples is focused on the",
      "offset": 1137.12,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "image generation as such, you know, kind",
      "offset": 1138.64,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "of all kind of cool plugins. Um, I",
      "offset": 1140.72,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "wonder if you have good suggestions or",
      "offset": 1143.36,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "ideas about evaluating the results kind",
      "offset": 1145.6,
      "duration": 4.959
    },
    {
      "lang": "en",
      "text": "of like verifying or kind of like saying",
      "offset": 1148.32,
      "duration": 5.359
    },
    {
      "lang": "en",
      "text": "this is good image or not a good image",
      "offset": 1150.559,
      "duration": 5.761
    },
    {
      "lang": "en",
      "text": "uh to to kind of automate that workflow",
      "offset": 1153.679,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "as well.",
      "offset": 1156.32,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "Uh that's uh that's a difficult thing to",
      "offset": 1157.679,
      "duration": 7.521
    },
    {
      "lang": "en",
      "text": "do usually because if uh it's the",
      "offset": 1161.12,
      "duration": 7.679
    },
    {
      "lang": "en",
      "text": "problem where like how do you define a",
      "offset": 1165.2,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "good image",
      "offset": 1168.799,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "because uh yeah",
      "offset": 1170.72,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "that there's some problems with uh",
      "offset": 1173.679,
      "duration": 4.961
    },
    {
      "lang": "en",
      "text": "because people's taste is very",
      "offset": 1176.08,
      "duration": 6.959
    },
    {
      "lang": "en",
      "text": "subjective. So what is a good image for",
      "offset": 1178.64,
      "duration": 7.84
    },
    {
      "lang": "en",
      "text": "one person might not be good image for",
      "offset": 1183.039,
      "duration": 6.88
    },
    {
      "lang": "en",
      "text": "another person. So yeah, it's a it's a",
      "offset": 1186.48,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "problem they have. It's actually a big",
      "offset": 1189.919,
      "duration": 4.721
    },
    {
      "lang": "en",
      "text": "problem with the like user people who do",
      "offset": 1191.76,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "who train these diffusion models like",
      "offset": 1194.64,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "user preference.",
      "offset": 1196.96,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "They uh when they when they actually add",
      "offset": 1199.12,
      "duration": 6.48
    },
    {
      "lang": "en",
      "text": "the user preference data, their results",
      "offset": 1202,
      "duration": 7.919
    },
    {
      "lang": "en",
      "text": "get a bit worse because users like",
      "offset": 1205.6,
      "duration": 6.72
    },
    {
      "lang": "en",
      "text": "like the average user likes a certain",
      "offset": 1209.919,
      "duration": 5.921
    },
    {
      "lang": "en",
      "text": "type of image which is not maybe might",
      "offset": 1212.32,
      "duration": 8.08
    },
    {
      "lang": "en",
      "text": "not be what uh what most what most",
      "offset": 1215.84,
      "duration": 10
    },
    {
      "lang": "en",
      "text": "people want. So it's uh yeah",
      "offset": 1220.4,
      "duration": 7.6
    },
    {
      "lang": "en",
      "text": "but uh",
      "offset": 1225.84,
      "duration": 5.16
    },
    {
      "lang": "en",
      "text": "any",
      "offset": 1228,
      "duration": 3
    },
    {
      "lang": "en",
      "text": "models that you bring in or you kind of",
      "offset": 1232.64,
      "duration": 6.32
    },
    {
      "lang": "en",
      "text": "have a prompt that looks at the image uh",
      "offset": 1235.919,
      "duration": 4.801
    },
    {
      "lang": "en",
      "text": "like a multimodel but anyway if there's",
      "offset": 1238.96,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "not yeah there's yeah I yeah we've had",
      "offset": 1240.72,
      "duration": 4.959
    },
    {
      "lang": "en",
      "text": "like at least back when I was at",
      "offset": 1244,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "stability we did have some uh we did",
      "offset": 1245.679,
      "duration": 6.801
    },
    {
      "lang": "en",
      "text": "experiment with some models that tried",
      "offset": 1248.88,
      "duration": 8.08
    },
    {
      "lang": "en",
      "text": "to just see oh like get the output",
      "offset": 1252.48,
      "duration": 6.72
    },
    {
      "lang": "en",
      "text": "output the image from the workflow get",
      "offset": 1256.96,
      "duration": 6.079
    },
    {
      "lang": "en",
      "text": "some kind of rating from a model but uh",
      "offset": 1259.2,
      "duration": 8.24
    },
    {
      "lang": "en",
      "text": "it didn't work that well so it's okay",
      "offset": 1263.039,
      "duration": 7.64
    },
    {
      "lang": "en",
      "text": "good question",
      "offset": 1267.44,
      "duration": 3.239
    },
    {
      "lang": "en",
      "text": "all right do we have any other questions",
      "offset": 1272.32,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "right now from anyone",
      "offset": 1274.08,
      "duration": 7.64
    },
    {
      "lang": "en",
      "text": "raise your hand so I can see",
      "offset": 1277.6,
      "duration": 4.12
    },
    {
      "lang": "en",
      "text": "Do you have another one? Awesome.",
      "offset": 1282.159,
      "duration": 4.281
    },
    {
      "lang": "en",
      "text": "So, this is predominantly a workflow and",
      "offset": 1289.6,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "once you kind of like uh develop it, you",
      "offset": 1292,
      "duration": 5.84
    },
    {
      "lang": "en",
      "text": "do it in the UI. Um any good tools",
      "offset": 1294.4,
      "duration": 7.04
    },
    {
      "lang": "en",
      "text": "around then uh running this more",
      "offset": 1297.84,
      "duration": 5.92
    },
    {
      "lang": "en",
      "text": "headless and kind of scaling this out",
      "offset": 1301.44,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "and maybe building this into an app for",
      "offset": 1303.76,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "kind of people using it.",
      "offset": 1306,
      "duration": 6.64
    },
    {
      "lang": "en",
      "text": "Yeah, this is uh just uh yeah, this is",
      "offset": 1308.24,
      "duration": 8.16
    },
    {
      "lang": "en",
      "text": "one thing that uh because well",
      "offset": 1312.64,
      "duration": 6.88
    },
    {
      "lang": "en",
      "text": "is this what comfy UI is it's actually",
      "offset": 1316.4,
      "duration": 5.279
    },
    {
      "lang": "en",
      "text": "you have this interface but you also",
      "offset": 1319.52,
      "duration": 6.399
    },
    {
      "lang": "en",
      "text": "have a powerful backend behind it which",
      "offset": 1321.679,
      "duration": 7.12
    },
    {
      "lang": "en",
      "text": "executes the workflows and right now",
      "offset": 1325.919,
      "duration": 6.561
    },
    {
      "lang": "en",
      "text": "there's there's actually a lot of uh a",
      "offset": 1328.799,
      "duration": 5.841
    },
    {
      "lang": "en",
      "text": "lot of different inference service for",
      "offset": 1332.48,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "these workflows and eventually we'll be",
      "offset": 1334.64,
      "duration": 6.64
    },
    {
      "lang": "en",
      "text": "building our own. So, and yeah, and",
      "offset": 1337.2,
      "duration": 7.04
    },
    {
      "lang": "en",
      "text": "there's there's already some uh a lot of",
      "offset": 1341.28,
      "duration": 6.32
    },
    {
      "lang": "en",
      "text": "uh third-party services that I saw that",
      "offset": 1344.24,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "you can take your workflow, make an app",
      "offset": 1347.6,
      "duration": 6.24
    },
    {
      "lang": "en",
      "text": "out of it, and uh yeah, so you can",
      "offset": 1349.84,
      "duration": 8.24
    },
    {
      "lang": "en",
      "text": "already you can already do that, but uh",
      "offset": 1353.84,
      "duration": 6.959
    },
    {
      "lang": "en",
      "text": "just there's no just no official way of",
      "offset": 1358.08,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "doing it, but there might uh there might",
      "offset": 1360.799,
      "duration": 5.601
    },
    {
      "lang": "en",
      "text": "be one in in the future. So, okay.",
      "offset": 1363.28,
      "duration": 6.399
    },
    {
      "lang": "en",
      "text": "Thanks for clarifying.",
      "offset": 1366.4,
      "duration": 6.92
    },
    {
      "lang": "en",
      "text": "Thank you for the question.",
      "offset": 1369.679,
      "duration": 3.641
    },
    {
      "lang": "en",
      "text": "All right. Any questions? Because we'll",
      "offset": 1379.84,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "keep on talking about other stuff if",
      "offset": 1381.84,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "there are no more questions. So, be",
      "offset": 1383.28,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "prepared.",
      "offset": 1384.88,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "All righty. Uh, one of the more recent",
      "offset": 1387.44,
      "duration": 4.479
    },
    {
      "lang": "en",
      "text": "additions to come for UI. For a long",
      "offset": 1389.6,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "time, we only supported open-source",
      "offset": 1391.919,
      "duration": 5.681
    },
    {
      "lang": "en",
      "text": "local models. In the past month, we've",
      "offset": 1394.4,
      "duration": 5.759
    },
    {
      "lang": "en",
      "text": "introduced API nodes, which for paid",
      "offset": 1397.6,
      "duration": 7.199
    },
    {
      "lang": "en",
      "text": "credits allow you to generate remotely.",
      "offset": 1400.159,
      "duration": 6.321
    },
    {
      "lang": "en",
      "text": "Um,",
      "offset": 1404.799,
      "duration": 4.801
    },
    {
      "lang": "en",
      "text": "let's open up a template",
      "offset": 1406.48,
      "duration": 6.24
    },
    {
      "lang": "en",
      "text": "we can do. There we go. One of the",
      "offset": 1409.6,
      "duration": 5.84
    },
    {
      "lang": "en",
      "text": "models that recently came out was a",
      "offset": 1412.72,
      "duration": 6.72
    },
    {
      "lang": "en",
      "text": "Black Forest Labs context model. uh",
      "offset": 1415.44,
      "duration": 7.04
    },
    {
      "lang": "en",
      "text": "currently not out for open source usage",
      "offset": 1419.44,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "in terms of being able to run locally",
      "offset": 1422.48,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "but they have made the APIs available.",
      "offset": 1424.88,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "Yeah, eventually they're supposed to",
      "offset": 1427.28,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "release an open source version which uh",
      "offset": 1429.2,
      "duration": 6.32
    },
    {
      "lang": "en",
      "text": "well we we already support they just",
      "offset": 1432.24,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "haven't haven't released it. Yes, we are",
      "offset": 1435.52,
      "duration": 6.92
    },
    {
      "lang": "en",
      "text": "waiting for the green light. Yeah.",
      "offset": 1438,
      "duration": 4.44
    },
    {
      "lang": "en",
      "text": "And I would run this but I have no",
      "offset": 1442.48,
      "duration": 3.199
    },
    {
      "lang": "en",
      "text": "internet connection and that's one of",
      "offset": 1444.24,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "the limitations of API notes. you need",
      "offset": 1445.679,
      "duration": 6.24
    },
    {
      "lang": "en",
      "text": "to, you know, they're not ran locally.",
      "offset": 1447.44,
      "duration": 7.76
    },
    {
      "lang": "en",
      "text": "Yeah. So,",
      "offset": 1451.919,
      "duration": 6.921
    },
    {
      "lang": "en",
      "text": "there's some interesting",
      "offset": 1455.2,
      "duration": 3.64
    },
    {
      "lang": "en",
      "text": "Yeah. So, we have u",
      "offset": 1459.679,
      "duration": 6.161
    },
    {
      "lang": "en",
      "text": "Yeah. Yeah. We have a lot of different",
      "offset": 1463.279,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "uh so the models that so that we support",
      "offset": 1465.84,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "image, video,",
      "offset": 1468.799,
      "duration": 6.801
    },
    {
      "lang": "en",
      "text": "yeah, 3D. So, we have a basic support",
      "offset": 1471.52,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "for like",
      "offset": 1475.6,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "Hunion 3D model which is uh basically",
      "offset": 1477.52,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "it's an interesting model. So it",
      "offset": 1481.6,
      "duration": 9.16
    },
    {
      "lang": "en",
      "text": "basically outputs a voxal type uh",
      "offset": 1483.52,
      "duration": 7.24
    },
    {
      "lang": "en",
      "text": "like the the 3D model all these output",
      "offset": 1490.96,
      "duration": 7.12
    },
    {
      "lang": "en",
      "text": "is a kind of a voxal format and then you",
      "offset": 1494.08,
      "duration": 6.56
    },
    {
      "lang": "en",
      "text": "and then so that's why in the workflow",
      "offset": 1498.08,
      "duration": 7.839
    },
    {
      "lang": "en",
      "text": "there's a yeah there's some uh",
      "offset": 1500.64,
      "duration": 8.24
    },
    {
      "lang": "en",
      "text": "code to so but the problem with these",
      "offset": 1505.919,
      "duration": 4.801
    },
    {
      "lang": "en",
      "text": "models since it's kind of it generates",
      "offset": 1508.88,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "some voxal format and then and you need",
      "offset": 1510.72,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "to use an algorithm to convert it to",
      "offset": 1513.12,
      "duration": 4.799
    },
    {
      "lang": "en",
      "text": "mesh is that the mesh isn't very high",
      "offset": 1515.2,
      "duration": 6.959
    },
    {
      "lang": "en",
      "text": "quality, but it's still uh pretty",
      "offset": 1517.919,
      "duration": 6.081
    },
    {
      "lang": "en",
      "text": "impressive. I do not have any of these",
      "offset": 1522.159,
      "duration": 6.041
    },
    {
      "lang": "en",
      "text": "models coming. Yeah.",
      "offset": 1524,
      "duration": 4.2
    },
    {
      "lang": "en",
      "text": "And we're currently, I guess, not we",
      "offset": 1532.08,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "have local support for LLM. Well, there",
      "offset": 1535.279,
      "duration": 4.801
    },
    {
      "lang": "en",
      "text": "there's a bunch of custom nodes with",
      "offset": 1537.84,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "local LM support. It's just not a core",
      "offset": 1540.08,
      "duration": 7.199
    },
    {
      "lang": "en",
      "text": "comfy thing yet. It's just we're more",
      "offset": 1542.96,
      "duration": 9.36
    },
    {
      "lang": "en",
      "text": "focused on uh on like image and video",
      "offset": 1547.279,
      "duration": 8.4
    },
    {
      "lang": "en",
      "text": "and all these uh more visual",
      "offset": 1552.32,
      "duration": 6.16
    },
    {
      "lang": "en",
      "text": "or we also support audio and audio model",
      "offset": 1555.679,
      "duration": 6.281
    },
    {
      "lang": "en",
      "text": "now. So",
      "offset": 1558.48,
      "duration": 3.48
    },
    {
      "lang": "en",
      "text": "yeah, it's not as good as some of the",
      "offset": 1562.48,
      "duration": 5.679
    },
    {
      "lang": "en",
      "text": "proprietary models out there, but it's",
      "offset": 1565.52,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "uh yeah, it's pretty fun to play with.",
      "offset": 1568.159,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "And there were some more I think uh",
      "offset": 1571.2,
      "duration": 4.479
    },
    {
      "lang": "en",
      "text": "audio models that came out. Yeah. But",
      "offset": 1573.279,
      "duration": 6.081
    },
    {
      "lang": "en",
      "text": "those those are texttospech models.",
      "offset": 1575.679,
      "duration": 6.721
    },
    {
      "lang": "en",
      "text": "Gotcha. Yeah. Those which we we may",
      "offset": 1579.36,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "support. We'll we'll have to see if uh",
      "offset": 1582.4,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "because they're they're already",
      "offset": 1585.12,
      "duration": 5.679
    },
    {
      "lang": "en",
      "text": "supported as custom nodes but uh yeah",
      "offset": 1586.559,
      "duration": 6.321
    },
    {
      "lang": "en",
      "text": "before to",
      "offset": 1590.799,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "yeah it's just to integrate them in core",
      "offset": 1592.88,
      "duration": 5.679
    },
    {
      "lang": "en",
      "text": "comfy there needs to be like a reason to",
      "offset": 1594.96,
      "duration": 8.8
    },
    {
      "lang": "en",
      "text": "like if uh give them extra control or",
      "offset": 1598.559,
      "duration": 10.641
    },
    {
      "lang": "en",
      "text": "some extra like extra knobs to turn or",
      "offset": 1603.76,
      "duration": 9.96
    },
    {
      "lang": "en",
      "text": "else there's not much point.",
      "offset": 1609.2,
      "duration": 4.52
    },
    {
      "lang": "en",
      "text": "I'm interested in any questions from",
      "offset": 1614.799,
      "duration": 4.721
    },
    {
      "lang": "en",
      "text": "this side of the room that maybe wasn't",
      "offset": 1616.799,
      "duration": 5.441
    },
    {
      "lang": "en",
      "text": "too familiar with Comfy at the start.",
      "offset": 1619.52,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "Uh, do you have any questions, comments,",
      "offset": 1622.24,
      "duration": 5.08
    },
    {
      "lang": "en",
      "text": "inquiries?",
      "offset": 1624.32,
      "duration": 3
    },
    {
      "lang": "en",
      "text": "All right, I will hand you the mic.",
      "offset": 1627.679,
      "duration": 4.521
    },
    {
      "lang": "en",
      "text": "Sorry, it's me again. So does comfort UI",
      "offset": 1634.159,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "have the use case for the virtual tryon",
      "offset": 1637.279,
      "duration": 4.561
    },
    {
      "lang": "en",
      "text": "where you know we upload the image of",
      "offset": 1639.679,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "the model uh the manqueen and the",
      "offset": 1641.84,
      "duration": 5.199
    },
    {
      "lang": "en",
      "text": "garment the clothes so that it generate",
      "offset": 1644.799,
      "duration": 5.601
    },
    {
      "lang": "en",
      "text": "the virtual trion images. Yeah, like for",
      "offset": 1647.039,
      "duration": 6.801
    },
    {
      "lang": "en",
      "text": "example, the new flux context model can",
      "offset": 1650.4,
      "duration": 7.2
    },
    {
      "lang": "en",
      "text": "can do that. Uh I think so there yeah",
      "offset": 1653.84,
      "duration": 5.439
    },
    {
      "lang": "en",
      "text": "there's a few different there's some",
      "offset": 1657.6,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "opensource ways and there's some uh some",
      "offset": 1659.279,
      "duration": 7.76
    },
    {
      "lang": "en",
      "text": "ways using uh the API nodes but uh yeah",
      "offset": 1662.72,
      "duration": 6.88
    },
    {
      "lang": "en",
      "text": "virtual trans it's something that seems",
      "offset": 1667.039,
      "duration": 4.961
    },
    {
      "lang": "en",
      "text": "very popular. So there are there are a",
      "offset": 1669.6,
      "duration": 5.679
    },
    {
      "lang": "en",
      "text": "bunch of workflows for it. Okay. So we",
      "offset": 1672,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "can find it on the comfort UI and try it",
      "offset": 1675.279,
      "duration": 4.561
    },
    {
      "lang": "en",
      "text": "out. Uh yeah. Yeah. If you if you",
      "offset": 1677.12,
      "duration": 6.24
    },
    {
      "lang": "en",
      "text": "search, you can find uh you can probably",
      "offset": 1679.84,
      "duration": 6.16
    },
    {
      "lang": "en",
      "text": "easily find a workflow for it. The only",
      "offset": 1683.36,
      "duration": 5.84
    },
    {
      "lang": "en",
      "text": "thing you might uh it's just some of the",
      "offset": 1686,
      "duration": 6.72
    },
    {
      "lang": "en",
      "text": "it's just that the field evolves so fast",
      "offset": 1689.2,
      "duration": 7.839
    },
    {
      "lang": "en",
      "text": "that uh sometimes uh workflows you find",
      "offset": 1692.72,
      "duration": 8.8
    },
    {
      "lang": "en",
      "text": "might be slightly outdated. So, but if I",
      "offset": 1697.039,
      "duration": 6.481
    },
    {
      "lang": "en",
      "text": "was doing that, I would first try the",
      "offset": 1701.52,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "new flux context model since that seems",
      "offset": 1703.52,
      "duration": 5.519
    },
    {
      "lang": "en",
      "text": "to be uh",
      "offset": 1706.72,
      "duration": 6.16
    },
    {
      "lang": "en",
      "text": "the best one for that. But uh",
      "offset": 1709.039,
      "duration": 7.441
    },
    {
      "lang": "en",
      "text": "yeah, uh the name is new conf uh what's",
      "offset": 1712.88,
      "duration": 7.679
    },
    {
      "lang": "en",
      "text": "the model name? New uh flux concept.",
      "offset": 1716.48,
      "duration": 6.64
    },
    {
      "lang": "en",
      "text": "Flux concept context. Yeah, I keep Okay.",
      "offset": 1720.559,
      "duration": 5.921
    },
    {
      "lang": "en",
      "text": "Yeah, flex. Sorry. Flux context. K.",
      "offset": 1723.12,
      "duration": 6.24
    },
    {
      "lang": "en",
      "text": "Yeah, context with a K.",
      "offset": 1726.48,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "So, thank you. Thank you so much. And to",
      "offset": 1729.36,
      "duration": 5.439
    },
    {
      "lang": "en",
      "text": "also follow up on that, um, right now,",
      "offset": 1732.08,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "yeah, right now it's an API node only,",
      "offset": 1734.799,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "but they're they should release the, uh,",
      "offset": 1736.72,
      "duration": 6.16
    },
    {
      "lang": "en",
      "text": "the opensource version soon. So, yeah.",
      "offset": 1738.96,
      "duration": 6.16
    },
    {
      "lang": "en",
      "text": "So, once that's once that's released,",
      "offset": 1742.88,
      "duration": 5.039
    },
    {
      "lang": "en",
      "text": "you'll be able to run it on your on your",
      "offset": 1745.12,
      "duration": 6.32
    },
    {
      "lang": "en",
      "text": "on your machine with the comfy UI. Yeah.",
      "offset": 1747.919,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "To follow up on virtual tryon, this is",
      "offset": 1751.44,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "actually something that people have in",
      "offset": 1753.279,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "workflows in the past year. When we were",
      "offset": 1754.64,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "in Japan, when we had a meet and greet",
      "offset": 1756.559,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "there, there were some people who",
      "offset": 1758.96,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "actually made workflows specifically for",
      "offset": 1760.24,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "that. Back then, there weren't",
      "offset": 1762,
      "duration": 5.279
    },
    {
      "lang": "en",
      "text": "some of the models like context now are",
      "offset": 1765.6,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "very good at a hey, change this one",
      "offset": 1767.279,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "thing. At the time, there weren't. So",
      "offset": 1769.12,
      "duration": 5.279
    },
    {
      "lang": "en",
      "text": "the workflows you'd find probably have a",
      "offset": 1771.36,
      "duration": 6.559
    },
    {
      "lang": "en",
      "text": "few dozen nodes basically finding using",
      "offset": 1774.399,
      "duration": 6.64
    },
    {
      "lang": "en",
      "text": "a one model to find the masks of like",
      "offset": 1777.919,
      "duration": 5.441
    },
    {
      "lang": "en",
      "text": "what to change then another model to",
      "offset": 1781.039,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "inpaint those masks of the actual thing",
      "offset": 1783.36,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "you want to change. Now the models are a",
      "offset": 1785.12,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "bit more uh advanced where you can just",
      "offset": 1787.36,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "say hey I want to edit this and it does",
      "offset": 1790.24,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "it. And you of course combine up the",
      "offset": 1792.24,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "masks as well. In case the model gets a",
      "offset": 1794.08,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "little",
      "offset": 1796.64,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "uh a little rowdy and tries to change",
      "offset": 1798.24,
      "duration": 2.96
    },
    {
      "lang": "en",
      "text": "things you don't want, you can always",
      "offset": 1799.84,
      "duration": 6.04
    },
    {
      "lang": "en",
      "text": "add masks to keep it contained.",
      "offset": 1801.2,
      "duration": 4.68
    },
    {
      "lang": "en",
      "text": "Any more questions on this side of the",
      "offset": 1806.88,
      "duration": 4.6
    },
    {
      "lang": "en",
      "text": "room?",
      "offset": 1808.48,
      "duration": 3
    },
    {
      "lang": "en",
      "text": "So sorry I joined the session very late",
      "offset": 1816.399,
      "duration": 6.88
    },
    {
      "lang": "en",
      "text": "late but um if you want to generate any",
      "offset": 1819.44,
      "duration": 7.119
    },
    {
      "lang": "en",
      "text": "kind of image I think this allows us to",
      "offset": 1823.279,
      "duration": 6.481
    },
    {
      "lang": "en",
      "text": "write a prompt and then it allows us to",
      "offset": 1826.559,
      "duration": 6.561
    },
    {
      "lang": "en",
      "text": "generate image. Is that correct? Yes.",
      "offset": 1829.76,
      "duration": 7.68
    },
    {
      "lang": "en",
      "text": "Okay. So for example, if you want to",
      "offset": 1833.12,
      "duration": 7.76
    },
    {
      "lang": "en",
      "text": "have a tool that automate",
      "offset": 1837.44,
      "duration": 5.839
    },
    {
      "lang": "en",
      "text": "building multiple images based on let's",
      "offset": 1840.88,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "say character like if if I want to have",
      "offset": 1843.279,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "define a character and if if I want to",
      "offset": 1846.24,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "generate a stories based on the",
      "offset": 1847.919,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "characters does this allow it?",
      "offset": 1849.84,
      "duration": 6.16
    },
    {
      "lang": "en",
      "text": "Yes. Well, you what you need is there's",
      "offset": 1852.799,
      "duration": 5.841
    },
    {
      "lang": "en",
      "text": "a few different ways to because I assume",
      "offset": 1856,
      "duration": 5.039
    },
    {
      "lang": "en",
      "text": "yeah, you want to generate a consistent",
      "offset": 1858.64,
      "duration": 5.759
    },
    {
      "lang": "en",
      "text": "character is depending on what you want.",
      "offset": 1861.039,
      "duration": 7.201
    },
    {
      "lang": "en",
      "text": "You can either uh train a lora for your",
      "offset": 1864.399,
      "duration": 6.721
    },
    {
      "lang": "en",
      "text": "character or use one of the newer model",
      "offset": 1868.24,
      "duration": 6.799
    },
    {
      "lang": "en",
      "text": "like uh like the flux context model like",
      "offset": 1871.12,
      "duration": 7.12
    },
    {
      "lang": "en",
      "text": "these uh like very recently there's all",
      "offset": 1875.039,
      "duration": 6.64
    },
    {
      "lang": "en",
      "text": "these edit models that have what I call",
      "offset": 1878.24,
      "duration": 7.2
    },
    {
      "lang": "en",
      "text": "edit models which are basically uh they",
      "offset": 1881.679,
      "duration": 6.801
    },
    {
      "lang": "en",
      "text": "they got very inspired with what the 40",
      "offset": 1885.44,
      "duration": 4.959
    },
    {
      "lang": "en",
      "text": "was doing.",
      "offset": 1888.48,
      "duration": 4.799
    },
    {
      "lang": "en",
      "text": "So which one do you suggest? What which",
      "offset": 1890.399,
      "duration": 4.961
    },
    {
      "lang": "en",
      "text": "one do you suggest?",
      "offset": 1893.279,
      "duration": 4.561
    },
    {
      "lang": "en",
      "text": "Uh right now the the best one is uh the",
      "offset": 1895.36,
      "duration": 6.64
    },
    {
      "lang": "en",
      "text": "flex uh the yeah the flex uh context",
      "offset": 1897.84,
      "duration": 6.16
    },
    {
      "lang": "en",
      "text": "model",
      "offset": 1902,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "but uh like I said it's only right now",
      "offset": 1904,
      "duration": 5.679
    },
    {
      "lang": "en",
      "text": "it's only available through an API and",
      "offset": 1906.96,
      "duration": 7.36
    },
    {
      "lang": "en",
      "text": "but uh should be open source soon and",
      "offset": 1909.679,
      "duration": 7.84
    },
    {
      "lang": "en",
      "text": "then there's some other ones too but uh",
      "offset": 1914.32,
      "duration": 8
    },
    {
      "lang": "en",
      "text": "at one yeah what you can do with uh with",
      "offset": 1917.519,
      "duration": 9.52
    },
    {
      "lang": "en",
      "text": "the the context text is just like some",
      "offset": 1922.32,
      "duration": 7.199
    },
    {
      "lang": "en",
      "text": "you give it a reference image of a",
      "offset": 1927.039,
      "duration": 4.801
    },
    {
      "lang": "en",
      "text": "character and you say, \"Oh, make that",
      "offset": 1929.519,
      "duration": 4.961
    },
    {
      "lang": "en",
      "text": "character do this.\" And it actually",
      "offset": 1931.84,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "keeps the character consistency",
      "offset": 1934.48,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "extremely well.",
      "offset": 1937.36,
      "duration": 6.88
    },
    {
      "lang": "en",
      "text": "Just uh so there is there is a way to uh",
      "offset": 1939.6,
      "duration": 7.12
    },
    {
      "lang": "en",
      "text": "maintain character throughout the story",
      "offset": 1944.24,
      "duration": 5.439
    },
    {
      "lang": "en",
      "text": "generation, right? Yes. Yeah. Well, what",
      "offset": 1946.72,
      "duration": 5.839
    },
    {
      "lang": "en",
      "text": "you would do is you would have a Yeah.",
      "offset": 1949.679,
      "duration": 6.88
    },
    {
      "lang": "en",
      "text": "First you generate a your character of",
      "offset": 1952.559,
      "duration": 6.161
    },
    {
      "lang": "en",
      "text": "an image of your character that you're",
      "offset": 1956.559,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "happy with and then you would uh you",
      "offset": 1958.72,
      "duration": 6.4
    },
    {
      "lang": "en",
      "text": "would pass it to this model and say oh",
      "offset": 1961.519,
      "duration": 6.16
    },
    {
      "lang": "en",
      "text": "put this character in this scene put",
      "offset": 1965.12,
      "duration": 4.799
    },
    {
      "lang": "en",
      "text": "this character in that scene and then",
      "offset": 1967.679,
      "duration": 5.201
    },
    {
      "lang": "en",
      "text": "you generate your image is based on this",
      "offset": 1969.919,
      "duration": 6.081
    },
    {
      "lang": "en",
      "text": "reference image of the character.",
      "offset": 1972.88,
      "duration": 6.08
    },
    {
      "lang": "en",
      "text": "Okay thank you.",
      "offset": 1976,
      "duration": 4.559
    },
    {
      "lang": "en",
      "text": "And to follow up on that, one of the",
      "offset": 1978.96,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "advantages of a nodebased system is with",
      "offset": 1980.559,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "the way that is set up, all you can",
      "offset": 1983.44,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "currently edit in it are some of the",
      "offset": 1985.519,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "parameters and the text prompts, but you",
      "offset": 1987.2,
      "duration": 6.64
    },
    {
      "lang": "en",
      "text": "could also apply the Lauras Lauras are",
      "offset": 1989.919,
      "duration": 7.201
    },
    {
      "lang": "en",
      "text": "uh low rank adaptations to the model.",
      "offset": 1993.84,
      "duration": 5.679
    },
    {
      "lang": "en",
      "text": "Um, and because it's node based, you can",
      "offset": 1997.12,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "also mask the specific area each of",
      "offset": 1999.519,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "those low rank adaptations would apply",
      "offset": 2001.519,
      "duration": 3.441
    },
    {
      "lang": "en",
      "text": "to. So let's say you have two Laura",
      "offset": 2003.039,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "strained, one for character A, one for",
      "offset": 2004.96,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "character B.",
      "offset": 2007.279,
      "duration": 3.441
    },
    {
      "lang": "en",
      "text": "uh what our nodebased system allows is",
      "offset": 2008.799,
      "duration": 4.801
    },
    {
      "lang": "en",
      "text": "to say hey in this area of the image I'd",
      "offset": 2010.72,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "like this Laura to be active maybe at",
      "offset": 2013.6,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "this strength you could even schedule it",
      "offset": 2015.84,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "in terms of that and on the other area",
      "offset": 2017.76,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "of an image you can have oh I want this",
      "offset": 2020.159,
      "duration": 4.801
    },
    {
      "lang": "en",
      "text": "other character Laura to be active so if",
      "offset": 2022,
      "duration": 5.919
    },
    {
      "lang": "en",
      "text": "even if you uh if like an all-in-one",
      "offset": 2024.96,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "model like context doesn't quite do what",
      "offset": 2027.919,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "you want there are multiple ways you can",
      "offset": 2029.84,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "sort of coersse these models to kind of",
      "offset": 2032.08,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "do it with a basic uh promptbased",
      "offset": 2034.48,
      "duration": 5.84
    },
    {
      "lang": "en",
      "text": "system. There are of course limitations,",
      "offset": 2037.6,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "but because we are node based, you can",
      "offset": 2040.32,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "do, you know, there's two things for the",
      "offset": 2042.64,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "prompts there. You could set that up to",
      "offset": 2045.36,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "be 10 nodes, and some of those nodes",
      "offset": 2047.039,
      "duration": 3.761
    },
    {
      "lang": "en",
      "text": "apply a specific Laura to a particular",
      "offset": 2048.96,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "image, sorry, to a particular area of an",
      "offset": 2050.8,
      "duration": 5.16
    },
    {
      "lang": "en",
      "text": "image.",
      "offset": 2052.96,
      "duration": 3
    },
    {
      "lang": "en",
      "text": "Do you also recommend Laura or uh the",
      "offset": 2058.48,
      "duration": 7.119
    },
    {
      "lang": "en",
      "text": "other one? Um, if you don't have uh like",
      "offset": 2061.44,
      "duration": 6.08
    },
    {
      "lang": "en",
      "text": "much experience in the space, I'd",
      "offset": 2065.599,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "recommend the context model mainly",
      "offset": 2067.52,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "because you just you just have to type",
      "offset": 2070.079,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "in the prompt and it does the work for",
      "offset": 2071.76,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "you. The other one, especially back",
      "offset": 2073.359,
      "duration": 5.681
    },
    {
      "lang": "en",
      "text": "before the sort of, you know, edit via",
      "offset": 2076.159,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "text models existed was sort of a brute",
      "offset": 2079.04,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "force way of getting what you want, but",
      "offset": 2081.119,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "you could really get what you want",
      "offset": 2083.2,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "because you could train it on anything",
      "offset": 2084.72,
      "duration": 3.199
    },
    {
      "lang": "en",
      "text": "you want. The models don't have to be",
      "offset": 2086.32,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "aware of what it is. And the the only",
      "offset": 2087.919,
      "duration": 5.361
    },
    {
      "lang": "en",
      "text": "disadvantage is you need to have enough",
      "offset": 2091.44,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "training images. So like between 10 to",
      "offset": 2093.28,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "30 to actually get your subject to",
      "offset": 2096.48,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "appear the way you want them to. With",
      "offset": 2098.48,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "these newer edited models, you only to",
      "offset": 2100.24,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "give the one image.",
      "offset": 2102.16,
      "duration": 6.28
    },
    {
      "lang": "en",
      "text": "No problem.",
      "offset": 2105.2,
      "duration": 3.24
    },
    {
      "lang": "en",
      "text": "All right. Any questions here?",
      "offset": 2109.359,
      "duration": 6.561
    },
    {
      "lang": "en",
      "text": "Or back on that area of the room? I can",
      "offset": 2113.52,
      "duration": 5.4
    },
    {
      "lang": "en",
      "text": "walk.",
      "offset": 2115.92,
      "duration": 3
    },
    {
      "lang": "en",
      "text": "All righty, come. What do you want to",
      "offset": 2120.079,
      "duration": 4.721
    },
    {
      "lang": "en",
      "text": "talk about next? Oh, well, yeah. Yeah.",
      "offset": 2121.2,
      "duration": 6.24
    },
    {
      "lang": "en",
      "text": "Well, we since we mentioned Lauras, like",
      "offset": 2124.8,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "Lauras are one of the basically what",
      "offset": 2127.44,
      "duration": 7.04
    },
    {
      "lang": "en",
      "text": "they what they are is a a patch on I",
      "offset": 2130.32,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "call them a Yeah, they're basically a",
      "offset": 2134.48,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "patch on the model weights, which is or",
      "offset": 2136.32,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "a more efficient way to train a concept",
      "offset": 2139.2,
      "duration": 7.6
    },
    {
      "lang": "en",
      "text": "or multiple concept in in a in a model.",
      "offset": 2142.32,
      "duration": 6.96
    },
    {
      "lang": "en",
      "text": "And yeah, right now we don't it's",
      "offset": 2146.8,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "basically just if you want to train a",
      "offset": 2149.28,
      "duration": 4.799
    },
    {
      "lang": "en",
      "text": "model instead of training the full",
      "offset": 2151.92,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "model, you would train this small patch",
      "offset": 2154.079,
      "duration": 8.641
    },
    {
      "lang": "en",
      "text": "on the model. And this allows you to",
      "offset": 2157.68,
      "duration": 8.88
    },
    {
      "lang": "en",
      "text": "well you can train styles, specific",
      "offset": 2162.72,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "characters,",
      "offset": 2166.56,
      "duration": 3.279
    },
    {
      "lang": "en",
      "text": "anything.",
      "offset": 2168.16,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "So yeah, we can we can skip showing it",
      "offset": 2169.839,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "off. This was for the uh Japan",
      "offset": 2173.44,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "presentation where this this Laura is",
      "offset": 2175.599,
      "duration": 5.041
    },
    {
      "lang": "en",
      "text": "for for a anime character that goes hard",
      "offset": 2178.24,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "in Japan. Probably doesn't go very hard",
      "offset": 2180.64,
      "duration": 5.88
    },
    {
      "lang": "en",
      "text": "at a AI conference.",
      "offset": 2182.64,
      "duration": 3.88
    },
    {
      "lang": "en",
      "text": "But this is how you would do it. You",
      "offset": 2187.2,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "would just chain the model there.",
      "offset": 2188.8,
      "duration": 7.72
    },
    {
      "lang": "en",
      "text": "And these are",
      "offset": 2192.8,
      "duration": 3.72
    },
    {
      "lang": "en",
      "text": "uh do I have any SDX? I do not. Okay.",
      "offset": 2196.64,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "This is for 1.5.",
      "offset": 2200.16,
      "duration": 6.8
    },
    {
      "lang": "en",
      "text": "Yes. And uh they're for Japan. I mean,",
      "offset": 2202.4,
      "duration": 6.8
    },
    {
      "lang": "en",
      "text": "we can still show them off, but uh All",
      "offset": 2206.96,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "right, we can try. Yeah. Oh, and these",
      "offset": 2209.2,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "would probably look very poorly on these",
      "offset": 2211.92,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "models, but we can give it a shot. Well,",
      "offset": 2213.92,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "I used the anime one.",
      "offset": 2216.56,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "Okay, we can use an anime one. Okay,",
      "offset": 2219.92,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "that's the anime one. Yeah, it works.",
      "offset": 2221.76,
      "duration": 6.52
    },
    {
      "lang": "en",
      "text": "So, yeah, just",
      "offset": 2224.4,
      "duration": 3.88
    },
    {
      "lang": "en",
      "text": "I mean, if you try that prompt, it's",
      "offset": 2228.32,
      "duration": 6.96
    },
    {
      "lang": "en",
      "text": "probably not gonna",
      "offset": 2232.56,
      "duration": 5.039
    },
    {
      "lang": "en",
      "text": "Yeah, we can uh we we can do that in a",
      "offset": 2235.28,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "bit. All right.",
      "offset": 2237.599,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "Okay. What else would you like to talk",
      "offset": 2240.8,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "about?",
      "offset": 2242,
      "duration": 8.16
    },
    {
      "lang": "en",
      "text": "Uh yeah, can just try see. Yeah. Well,",
      "offset": 2244.96,
      "duration": 8.159
    },
    {
      "lang": "en",
      "text": "we can press run and I I don't know if",
      "offset": 2250.16,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "we should I don't know if we should",
      "offset": 2253.119,
      "duration": 5.841
    },
    {
      "lang": "en",
      "text": "press run. Yeah. Well,",
      "offset": 2254.8,
      "duration": 6.96
    },
    {
      "lang": "en",
      "text": "okay. Yeah, we can. Yeah, this is a",
      "offset": 2258.96,
      "duration": 7.159
    },
    {
      "lang": "en",
      "text": "assignment to do at home, I suppose.",
      "offset": 2261.76,
      "duration": 4.359
    },
    {
      "lang": "en",
      "text": "But we have other models that we",
      "offset": 2267.599,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "support. Let's see. Yeah, apologies that",
      "offset": 2269.68,
      "duration": 7.439
    },
    {
      "lang": "en",
      "text": "we do not have much live demos. Uh",
      "offset": 2273.119,
      "duration": 6.641
    },
    {
      "lang": "en",
      "text": "uh there were some setup last minute in",
      "offset": 2277.119,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "terms of us attending the conference.",
      "offset": 2279.76,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "So,",
      "offset": 2281.44,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "but we are here.",
      "offset": 2283.68,
      "duration": 6.6
    },
    {
      "lang": "en",
      "text": "Sorry about that.",
      "offset": 2286.8,
      "duration": 3.48
    },
    {
      "lang": "en",
      "text": "Oh, here are some control net examples",
      "offset": 2293.68,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "where",
      "offset": 2295.76,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "can't show the inputs, but we can",
      "offset": 2297.44,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "actually I guess we can we can trust the",
      "offset": 2298.88,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "template system to kind of show what",
      "offset": 2301.839,
      "duration": 3.441
    },
    {
      "lang": "en",
      "text": "that's about. Yeah, control nets are",
      "offset": 2303.28,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "just one of the many ways to have more",
      "offset": 2305.28,
      "duration": 7.36
    },
    {
      "lang": "en",
      "text": "control of these uh of the the models.",
      "offset": 2308,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "Yeah. So the examples here would be the",
      "offset": 2312.64,
      "duration": 2.719
    },
    {
      "lang": "en",
      "text": "inputs that were used to actually",
      "offset": 2314,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "generate these images, but those might",
      "offset": 2315.359,
      "duration": 5.841
    },
    {
      "lang": "en",
      "text": "be like control nets might no longer be",
      "offset": 2317.92,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "very useful because now there's all",
      "offset": 2321.2,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "these edit models that are coming out.",
      "offset": 2323.2,
      "duration": 6.639
    },
    {
      "lang": "en",
      "text": "So yeah, it just means that the space is",
      "offset": 2326,
      "duration": 8.48
    },
    {
      "lang": "en",
      "text": "uh is evolving. But uh",
      "offset": 2329.839,
      "duration": 7.76
    },
    {
      "lang": "en",
      "text": "uh so here's a more advanced workflow",
      "offset": 2334.48,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "where it applies I believe different",
      "offset": 2337.599,
      "duration": 4.881
    },
    {
      "lang": "en",
      "text": "prompts to different areas of the image.",
      "offset": 2340.48,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "Yeah, this is a different prompts to",
      "offset": 2342.48,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "different areas. Yeah, we can actually",
      "offset": 2344.88,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "make this one go on the default SD 1.5",
      "offset": 2346.96,
      "duration": 7.2
    },
    {
      "lang": "en",
      "text": "model. That one will will work.",
      "offset": 2349.68,
      "duration": 6.56
    },
    {
      "lang": "en",
      "text": "Okay. Ah, yes. This is the old way of",
      "offset": 2354.16,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "prompting things when the models kind of",
      "offset": 2356.24,
      "duration": 7.879
    },
    {
      "lang": "en",
      "text": "had to really coers them.",
      "offset": 2359.44,
      "duration": 4.679
    },
    {
      "lang": "en",
      "text": "We will fix the seed.",
      "offset": 2364.64,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "Okay. And let's see how the laptop",
      "offset": 2367.92,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "handles. Yes.",
      "offset": 2370.4,
      "duration": 4.719
    },
    {
      "lang": "en",
      "text": "See, assuming there's no loaded images,",
      "offset": 2372.8,
      "duration": 5.039
    },
    {
      "lang": "en",
      "text": "this should just work. Yeah, at least",
      "offset": 2375.119,
      "duration": 6.921
    },
    {
      "lang": "en",
      "text": "half the workflow should work.",
      "offset": 2377.839,
      "duration": 4.201
    },
    {
      "lang": "en",
      "text": "Yeah.",
      "offset": 2387.2,
      "duration": 3
    },
    {
      "lang": "en",
      "text": "Yeah, this is a very old workflow, but",
      "offset": 2396,
      "duration": 6.72
    },
    {
      "lang": "en",
      "text": "uh I think it's still works on even the",
      "offset": 2398.96,
      "duration": 7.48
    },
    {
      "lang": "en",
      "text": "most recent models",
      "offset": 2402.72,
      "duration": 3.72
    },
    {
      "lang": "en",
      "text": "and we can uh we can change the prompts.",
      "offset": 2414.24,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "Maybe it's more obvious, but I believe",
      "offset": 2416,
      "duration": 2.96
    },
    {
      "lang": "en",
      "text": "the prompts are basically doing a",
      "offset": 2417.44,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "different time of day on some of these.",
      "offset": 2418.96,
      "duration": 4.639
    },
    {
      "lang": "en",
      "text": "Yeah. Yeah, it's basically different",
      "offset": 2421.04,
      "duration": 8.2
    },
    {
      "lang": "en",
      "text": "time of day on like if you go",
      "offset": 2423.599,
      "duration": 5.641
    },
    {
      "lang": "en",
      "text": "Yeah. top is like night and bottom is",
      "offset": 2430.16,
      "duration": 6.56
    },
    {
      "lang": "en",
      "text": "daytime.",
      "offset": 2433.76,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "Yeah. Just uh",
      "offset": 2436.72,
      "duration": 5.119
    },
    {
      "lang": "en",
      "text": "Yeah. So, this is just one of many ways",
      "offset": 2439.52,
      "duration": 5.599
    },
    {
      "lang": "en",
      "text": "you can get like more control. This is",
      "offset": 2441.839,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "just a way of applying different prompts",
      "offset": 2445.119,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "in different areas of the image. Like I",
      "offset": 2447.359,
      "duration": 5.601
    },
    {
      "lang": "en",
      "text": "said, I think it it still works even on",
      "offset": 2449.839,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "the most recent models. Yep. Yeah.",
      "offset": 2452.96,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "Everything that basically started from",
      "offset": 2455.839,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "the foundation at Comfy set up two years",
      "offset": 2457.92,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "ago, most of those any of those tricks",
      "offset": 2460.16,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "or applications still apply to newer",
      "offset": 2462.72,
      "duration": 3.599
    },
    {
      "lang": "en",
      "text": "models. Yeah. Because they're general",
      "offset": 2464.72,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "like diffusion model tricks and we're",
      "offset": 2466.319,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "still using diffusion. So you Yeah. So",
      "offset": 2469.04,
      "duration": 7.12
    },
    {
      "lang": "en",
      "text": "that's what makes Comfy nice is that if",
      "offset": 2472.079,
      "duration": 6.321
    },
    {
      "lang": "en",
      "text": "once if a new diffusion model is",
      "offset": 2476.16,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "implemented, usually you can use all the",
      "offset": 2478.4,
      "duration": 4.719
    },
    {
      "lang": "en",
      "text": "old tricks if you want. Some of them",
      "offset": 2481.04,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "might not be useful anymore, but you can",
      "offset": 2483.119,
      "duration": 5.121
    },
    {
      "lang": "en",
      "text": "still use them. Yeah, the models have",
      "offset": 2486.48,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "also gotten bigger and harder to run",
      "offset": 2488.24,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "locally in some cases on some hardware.",
      "offset": 2490.96,
      "duration": 5.359
    },
    {
      "lang": "en",
      "text": "So, uh, some of these tricks would, you",
      "offset": 2493.2,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "know, make things run quite a bit",
      "offset": 2496.319,
      "duration": 6.641
    },
    {
      "lang": "en",
      "text": "slower. Um in the early days of image",
      "offset": 2498.8,
      "duration": 6.48
    },
    {
      "lang": "en",
      "text": "generation a lot of the improvements",
      "offset": 2502.96,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "were with community fine-tunes who would",
      "offset": 2505.28,
      "duration": 4.559
    },
    {
      "lang": "en",
      "text": "take you know vast data sets and improve",
      "offset": 2507.359,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "the base model. You may have noticed I",
      "offset": 2509.839,
      "duration": 5.201
    },
    {
      "lang": "en",
      "text": "was a little nervous running a model",
      "offset": 2511.76,
      "duration": 5.359
    },
    {
      "lang": "en",
      "text": "a few minutes ago. The reason for that",
      "offset": 2515.04,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "that was one of those fine that was one",
      "offset": 2517.119,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "of the sort of days of back of community",
      "offset": 2518.96,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "fine tunes. uh the data sets they used",
      "offset": 2521.04,
      "duration": 7.92
    },
    {
      "lang": "en",
      "text": "may not always produce uh the the most",
      "offset": 2524.64,
      "duration": 6.32
    },
    {
      "lang": "en",
      "text": "uh conference friendly content. Yeah,",
      "offset": 2528.96,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "there's there's some interesting things",
      "offset": 2530.96,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "that happen when a model is slightly",
      "offset": 2532.64,
      "duration": 6.16
    },
    {
      "lang": "en",
      "text": "broken because since it's a diffusion",
      "offset": 2535.52,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "model, if it's slightly broken and",
      "offset": 2538.8,
      "duration": 6.64
    },
    {
      "lang": "en",
      "text": "you're generating a like a a character,",
      "offset": 2541.2,
      "duration": 6.8
    },
    {
      "lang": "en",
      "text": "the first like the first step might",
      "offset": 2545.44,
      "duration": 6.399
    },
    {
      "lang": "en",
      "text": "produce a like a skin color blob, which",
      "offset": 2548,
      "duration": 7.599
    },
    {
      "lang": "en",
      "text": "means it might converge to to a naked",
      "offset": 2551.839,
      "duration": 8.161
    },
    {
      "lang": "en",
      "text": "person basically. So yeah. Yeah. And",
      "offset": 2555.599,
      "duration": 5.921
    },
    {
      "lang": "en",
      "text": "given there are community fine tunes",
      "offset": 2560,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "that basically everyone trusted to",
      "offset": 2561.52,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "produce better quality images, those are",
      "offset": 2563.2,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "usually generations that you first",
      "offset": 2566.16,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "review and then show rather than press Q",
      "offset": 2568.56,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "and then uh yeah but that's the power of",
      "offset": 2571.92,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "running things locally. You don't have",
      "offset": 2574.16,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "any problem. You can do whatever you",
      "offset": 2576.64,
      "duration": 4.959
    },
    {
      "lang": "en",
      "text": "want. So",
      "offset": 2579.2,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "yeah newer models and bigger ones the",
      "offset": 2581.599,
      "duration": 4.641
    },
    {
      "lang": "en",
      "text": "training sets are a bit more",
      "offset": 2584.4,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "constrained. So you you have the pro the",
      "offset": 2586.24,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "pro pros and cons of that. It's just",
      "offset": 2588.319,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "they're they're better. They make less",
      "offset": 2589.68,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "random mistakes. Yeah. You can be more",
      "offset": 2591.839,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "you can trust more that when you put in",
      "offset": 2594.48,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "a specific prompt it will not",
      "offset": 2596,
      "duration": 5.48
    },
    {
      "lang": "en",
      "text": "hallucinate as much.",
      "offset": 2597.52,
      "duration": 3.96
    },
    {
      "lang": "en",
      "text": "All right. So in terms of we mentioned",
      "offset": 2608.16,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "that we are hiring. I believe we're",
      "offset": 2610.319,
      "duration": 4.721
    },
    {
      "lang": "en",
      "text": "looking for positions on well everything",
      "offset": 2612,
      "duration": 7.52
    },
    {
      "lang": "en",
      "text": "pretty much back end front end yeah core",
      "offset": 2615.04,
      "duration": 8.48
    },
    {
      "lang": "en",
      "text": "cloud deployment inference uh that cloud",
      "offset": 2619.52,
      "duration": 6.88
    },
    {
      "lang": "en",
      "text": "yeah just yeah go look at our carriers",
      "offset": 2623.52,
      "duration": 6.4
    },
    {
      "lang": "en",
      "text": "page and uh yeah it's it's comfy.orgcers",
      "offset": 2626.4,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "org/creat. Yeah. And if you haven't",
      "offset": 2629.92,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "tried the software, go try it. You can",
      "offset": 2631.92,
      "duration": 5.84
    },
    {
      "lang": "en",
      "text": "just if you all you need is a a decent",
      "offset": 2634.16,
      "duration": 6.56
    },
    {
      "lang": "en",
      "text": "GPU and you can run it locally or you",
      "offset": 2637.76,
      "duration": 7.52
    },
    {
      "lang": "en",
      "text": "can use the API nodes and Yeah. Yeah.",
      "offset": 2640.72,
      "duration": 6.08
    },
    {
      "lang": "en",
      "text": "People have gotten some of the early",
      "offset": 2645.28,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "models to work on extremely old GPUs",
      "offset": 2646.8,
      "duration": 6.799
    },
    {
      "lang": "en",
      "text": "like Yeah. 80-y old GPS. Yeah. Yeah. One",
      "offset": 2650.64,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "of the strengths of com is that pretty",
      "offset": 2653.599,
      "duration": 5.921
    },
    {
      "lang": "en",
      "text": "much any hardware well any Nvidia",
      "offset": 2656.4,
      "duration": 6.08
    },
    {
      "lang": "en",
      "text": "hardware the model will",
      "offset": 2659.52,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "usually run. It might be extremely slow",
      "offset": 2662.48,
      "duration": 5.599
    },
    {
      "lang": "en",
      "text": "but it will usually run.",
      "offset": 2664.72,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "So",
      "offset": 2668.079,
      "duration": 6.481
    },
    {
      "lang": "en",
      "text": "yeah. So are there any final questions?",
      "offset": 2669.76,
      "duration": 8.24
    },
    {
      "lang": "en",
      "text": "Oh right there.",
      "offset": 2674.56,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "Uh hold up. I'll give you the mic.",
      "offset": 2678,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "There's a process to this thing. Thank",
      "offset": 2679.52,
      "duration": 5.839
    },
    {
      "lang": "en",
      "text": "you. Um, I've tried using Comfy and I",
      "offset": 2682.24,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "was just wondering like if you could",
      "offset": 2685.359,
      "duration": 3.441
    },
    {
      "lang": "en",
      "text": "give us like a quick synopsis of what do",
      "offset": 2686.24,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "you think about Comfy versus the",
      "offset": 2688.8,
      "duration": 2.88
    },
    {
      "lang": "en",
      "text": "alternatives that exist? Like why would",
      "offset": 2690.079,
      "duration": 2.961
    },
    {
      "lang": "en",
      "text": "you sort of say Comfy is the one that",
      "offset": 2691.68,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "people should start with or stick to? I",
      "offset": 2693.04,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "have no idea like of the depth of it. So",
      "offset": 2695.28,
      "duration": 2.88
    },
    {
      "lang": "en",
      "text": "just give me like a seminar of that",
      "offset": 2696.88,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "please. Uh, Comfy is uh you should use",
      "offset": 2698.16,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "it because it's the it's the most",
      "offset": 2701.04,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "basically it's the most powerful one. So",
      "offset": 2703.2,
      "duration": 7.04
    },
    {
      "lang": "en",
      "text": "if you uh like everyone who like it's",
      "offset": 2705.28,
      "duration": 8.799
    },
    {
      "lang": "en",
      "text": "basically the the end game for for these",
      "offset": 2710.24,
      "duration": 6.48
    },
    {
      "lang": "en",
      "text": "these types of interfaces. So there",
      "offset": 2714.079,
      "duration": 4.801
    },
    {
      "lang": "en",
      "text": "there's nothing that gives you more",
      "offset": 2716.72,
      "duration": 5.119
    },
    {
      "lang": "en",
      "text": "control that has more community support",
      "offset": 2718.88,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "that has more extensions.",
      "offset": 2721.839,
      "duration": 5.921
    },
    {
      "lang": "en",
      "text": "So the only downside it has right now is",
      "offset": 2724.88,
      "duration": 6.88
    },
    {
      "lang": "en",
      "text": "it's uh it's a bit difficult to get into",
      "offset": 2727.76,
      "duration": 7.599
    },
    {
      "lang": "en",
      "text": "but we are working on that. So, thank",
      "offset": 2731.76,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "you.",
      "offset": 2735.359,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "Node based systems, especially if you're",
      "offset": 2737.52,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "not used to them at first, can be quite",
      "offset": 2739.119,
      "duration": 5.761
    },
    {
      "lang": "en",
      "text": "intimidating. And as uh Comfy mentioned,",
      "offset": 2741.359,
      "duration": 7.201
    },
    {
      "lang": "en",
      "text": "one of the greatest assets of Comfy UI",
      "offset": 2744.88,
      "duration": 6.719
    },
    {
      "lang": "en",
      "text": "is that it is community extendable and",
      "offset": 2748.56,
      "duration": 5.519
    },
    {
      "lang": "en",
      "text": "it is open source in that anything that",
      "offset": 2751.599,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "the core team may not be able to get to,",
      "offset": 2754.079,
      "duration": 3.361
    },
    {
      "lang": "en",
      "text": "there probably exists a community",
      "offset": 2755.92,
      "duration": 3.199
    },
    {
      "lang": "en",
      "text": "solution for that or to do something",
      "offset": 2757.44,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "like like we mentioned the slide, there",
      "offset": 2759.119,
      "duration": 5.841
    },
    {
      "lang": "en",
      "text": "are I believe 22,000",
      "offset": 2761.2,
      "duration": 6.56
    },
    {
      "lang": "en",
      "text": "custom nodes within like 3,000 note",
      "offset": 2764.96,
      "duration": 4.879
    },
    {
      "lang": "en",
      "text": "packs made by you know 3,000 separate",
      "offset": 2767.76,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "developers who are all passionate",
      "offset": 2769.839,
      "duration": 5.601
    },
    {
      "lang": "en",
      "text": "If you go to other places, you will not",
      "offset": 2772.4,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "always have you know the certainty as oh",
      "offset": 2775.44,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "can I run this locally? Do I know all my",
      "offset": 2777.52,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "data safe in ter if you are in a for",
      "offset": 2780.24,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "example enterprise setting data security",
      "offset": 2783.2,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "might be a big thing to avoid becoming",
      "offset": 2785.28,
      "duration": 3.039
    },
    {
      "lang": "en",
      "text": "the next headline in terms of a data",
      "offset": 2786.88,
      "duration": 4.479
    },
    {
      "lang": "en",
      "text": "leak or a ransomware attack. So being",
      "offset": 2788.319,
      "duration": 4.641
    },
    {
      "lang": "en",
      "text": "being able to actually look at the",
      "offset": 2791.359,
      "duration": 3.121
    },
    {
      "lang": "en",
      "text": "source code that's your thing or having",
      "offset": 2792.96,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "your team be able to look at the source",
      "offset": 2794.48,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "code. You can contribute any fixes. is",
      "offset": 2796,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "uh in terms of optimization and",
      "offset": 2798.319,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "performance we are pretty much",
      "offset": 2800,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "state-of-the-art uh comfy over there",
      "offset": 2802.48,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "when the new model comes out and he",
      "offset": 2805.28,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "hears that there is a way to run it",
      "offset": 2807.28,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "faster he implements it or one of us on",
      "offset": 2809.04,
      "duration": 7.079
    },
    {
      "lang": "en",
      "text": "the team implements it so",
      "offset": 2811.52,
      "duration": 4.599
    },
    {
      "lang": "en",
      "text": "um there's a discord channel that we",
      "offset": 2818,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "have for comfyorg we also as we post the",
      "offset": 2819.44,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "slides if you just Google comfy there",
      "offset": 2823.2,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "will be most likely thousands of YouTube",
      "offset": 2825.44,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "videos. Um there's even some people who",
      "offset": 2827.28,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "have taken uh they've seen the",
      "offset": 2830.96,
      "duration": 3.359
    },
    {
      "lang": "en",
      "text": "opportunity of the difficulty of come",
      "offset": 2832.96,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "for UI. Um and they are for example",
      "offset": 2834.319,
      "duration": 5.841
    },
    {
      "lang": "en",
      "text": "having paid uh tutoring classes for it",
      "offset": 2836.8,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "which is a bit of a eye openener for us",
      "offset": 2840.16,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "because that says we should probably do",
      "offset": 2842.48,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "a better job onboarding users if uh",
      "offset": 2843.68,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "people are you know making money that",
      "offset": 2846.16,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "way but there should be a lot of",
      "offset": 2847.92,
      "duration": 5.32
    },
    {
      "lang": "en",
      "text": "resources out there for you.",
      "offset": 2849.44,
      "duration": 3.8
    },
    {
      "lang": "en",
      "text": "All right any other questions?",
      "offset": 2854.48,
      "duration": 6.2
    },
    {
      "lang": "en",
      "text": "All right. Over there.",
      "offset": 2857.119,
      "duration": 3.561
    },
    {
      "lang": "en",
      "text": "Is there currently a published product",
      "offset": 2866.48,
      "duration": 4.76
    },
    {
      "lang": "en",
      "text": "roadmap?",
      "offset": 2868.24,
      "duration": 3
    },
    {
      "lang": "en",
      "text": "Uh if you mean what we are currently um",
      "offset": 2871.68,
      "duration": 7.76
    },
    {
      "lang": "en",
      "text": "well we haven't started really started",
      "offset": 2875.76,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "actually started yet but eventually",
      "offset": 2879.44,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "we'll have a solution to run these",
      "offset": 2881.2,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "workflows in the cloud.",
      "offset": 2884.16,
      "duration": 6.08
    },
    {
      "lang": "en",
      "text": "And uh yeah, how exactly it's going to",
      "offset": 2886.4,
      "duration": 7.199
    },
    {
      "lang": "en",
      "text": "work because we the the thing is before",
      "offset": 2890.24,
      "duration": 5.839
    },
    {
      "lang": "en",
      "text": "doing that we want to fix there's a a",
      "offset": 2893.599,
      "duration": 5.121
    },
    {
      "lang": "en",
      "text": "few issues we have to fix like the for",
      "offset": 2896.079,
      "duration": 4.881
    },
    {
      "lang": "en",
      "text": "example we want to make it installing",
      "offset": 2898.72,
      "duration": 5.92
    },
    {
      "lang": "en",
      "text": "and dealing with the custom node that",
      "offset": 2900.96,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "you install. We want to make that a lot",
      "offset": 2904.64,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "smoother, make uh the interface better.",
      "offset": 2906.64,
      "duration": 7.04
    },
    {
      "lang": "en",
      "text": "add a Yeah, we're what we're going to do",
      "offset": 2910.64,
      "duration": 6.56
    },
    {
      "lang": "en",
      "text": "is uh improve the interface",
      "offset": 2913.68,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "key. Well, the there's always going to",
      "offset": 2917.2,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "be the node interface, but uh we are",
      "offset": 2919.04,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "most likely going to add an other layer",
      "offset": 2922.16,
      "duration": 6.72
    },
    {
      "lang": "en",
      "text": "on top of it where you can have a more",
      "offset": 2924.8,
      "duration": 6.88
    },
    {
      "lang": "en",
      "text": "build a more traditional interface out",
      "offset": 2928.88,
      "duration": 7.439
    },
    {
      "lang": "en",
      "text": "of your workflow graph. and that will",
      "offset": 2931.68,
      "duration": 7.2
    },
    {
      "lang": "en",
      "text": "fit in with the well with the cloud",
      "offset": 2936.319,
      "duration": 4.481
    },
    {
      "lang": "en",
      "text": "stuff that we're going to be doing",
      "offset": 2938.88,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "eventually. So yeah, so that's that's",
      "offset": 2940.8,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "the direction where we're going in. But",
      "offset": 2943.92,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "uh the thing is in this space is that",
      "offset": 2946.8,
      "duration": 6.24
    },
    {
      "lang": "en",
      "text": "things change a lot. So a new model that",
      "offset": 2949.44,
      "duration": 6.32
    },
    {
      "lang": "en",
      "text": "comes out tomorrow might uh might mean",
      "offset": 2953.04,
      "duration": 5.92
    },
    {
      "lang": "en",
      "text": "we need to uh pivot a bit. So that's why",
      "offset": 2955.76,
      "duration": 6.559
    },
    {
      "lang": "en",
      "text": "I'm not uh I'm not giving any promises.",
      "offset": 2958.96,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "So yeah, because like the first thing",
      "offset": 2962.319,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "that went to my mind is we had the",
      "offset": 2964.96,
      "duration": 2.639
    },
    {
      "lang": "en",
      "text": "gentleman ask a question about can we",
      "offset": 2966.16,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "serve these workflows up? So it's like",
      "offset": 2967.599,
      "duration": 3.281
    },
    {
      "lang": "en",
      "text": "if you can access a workflow through an",
      "offset": 2969.28,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "API, you can have like a single power",
      "offset": 2970.88,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "user building out massive templates.",
      "offset": 2972.64,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "Yeah. That maintain like style and brand",
      "offset": 2974.4,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "guidelines or or story or character",
      "offset": 2976.4,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "design and then be like role-based",
      "offset": 2978.88,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "access control. You could have like just",
      "offset": 2980.64,
      "duration": 3.199
    },
    {
      "lang": "en",
      "text": "a general user in there saying, \"Hey, I",
      "offset": 2982,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "need to generate this workflow based on",
      "offset": 2983.839,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "these parameters. I can't touch anything",
      "offset": 2986.079,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "else in there.\" like is that is like",
      "offset": 2987.599,
      "duration": 5.921
    },
    {
      "lang": "en",
      "text": "being more enterprise or team? Yeah,",
      "offset": 2990.319,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "team ready. This is one of this is a",
      "offset": 2993.52,
      "duration": 5.599
    },
    {
      "lang": "en",
      "text": "direction we are going into. So like",
      "offset": 2996.319,
      "duration": 5.441
    },
    {
      "lang": "en",
      "text": "having uh just the the basics for that",
      "offset": 2999.119,
      "duration": 5.281
    },
    {
      "lang": "en",
      "text": "would be first a good cloud inference",
      "offset": 3001.76,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "service where you can run workflows very",
      "offset": 3004.4,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "well and have all the custom nodes work",
      "offset": 3006.96,
      "duration": 5.84
    },
    {
      "lang": "en",
      "text": "and once we solve that then all that",
      "offset": 3010.16,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "other all that other service becomes a",
      "offset": 3012.8,
      "duration": 5.92
    },
    {
      "lang": "en",
      "text": "lot easier. So yeah, thank you. Y and to",
      "offset": 3014.8,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "follow up on that at the end of the",
      "offset": 3018.72,
      "duration": 3.119
    },
    {
      "lang": "en",
      "text": "week, we will have a blog post about",
      "offset": 3020.16,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "some of the things we are working on um",
      "offset": 3021.839,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "for the because we are planning to allow",
      "offset": 3024,
      "duration": 5.119
    },
    {
      "lang": "en",
      "text": "cloud services, but first as uh Comfy",
      "offset": 3026.16,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "said, we need to work out dependency",
      "offset": 3029.119,
      "duration": 3.521
    },
    {
      "lang": "en",
      "text": "issues. So we'll have a bunch of",
      "offset": 3030.8,
      "duration": 3.279
    },
    {
      "lang": "en",
      "text": "features being announced there. For",
      "offset": 3032.64,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "example, we'll have a subgraph option",
      "offset": 3034.079,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "where you can combine a bunch of nodes,",
      "offset": 3035.76,
      "duration": 4.559
    },
    {
      "lang": "en",
      "text": "put it into one node, and you can double",
      "offset": 3038.24,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "click into it as like a separate",
      "offset": 3040.319,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "workflow. uh solving dependency issues",
      "offset": 3041.76,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "where custom nodes right now can request",
      "offset": 3044,
      "duration": 4.559
    },
    {
      "lang": "en",
      "text": "different Python packages. Making sure",
      "offset": 3046.24,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "all of those could get either properly",
      "offset": 3048.559,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "isolated or have more ways for them to",
      "offset": 3050.4,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "report their compatibility because once",
      "offset": 3052.559,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "local becomes much better to run that",
      "offset": 3054.96,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "means our life trying to get this as a",
      "offset": 3056.96,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "cloud product will also become smoother.",
      "offset": 3059.28,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "Yeah, I think yeah we are out of time",
      "offset": 3061.76,
      "duration": 5.359
    },
    {
      "lang": "en",
      "text": "now. So would uh would like to thank",
      "offset": 3063.92,
      "duration": 7.52
    },
    {
      "lang": "en",
      "text": "everyone for coming. We uh Yeah. And I",
      "offset": 3067.119,
      "duration": 7.921
    },
    {
      "lang": "en",
      "text": "hope you uh you learned something. Yeah.",
      "offset": 3071.44,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "Thank you for all the questions. Greatly",
      "offset": 3075.04,
      "duration": 5.96
    },
    {
      "lang": "en",
      "text": "appreciated. Yeah.",
      "offset": 3076.88,
      "duration": 4.12
    },
    {
      "lang": "en",
      "text": "[Music]",
      "offset": 3082.75,
      "duration": 3.719
    }
  ],
  "cleanText": "[Music]\nUh, good morning, everyone.\nI am Yedri Kosinski, and this is Yeah.\nHello.\nI am known online as ComfyAnonymous, the original creator of ComfyUI, and we are part of the Comfy or the organization that is in charge of ComfyUI.\nSo, uh, I guess now I have a mic.\nI'll ask again, who here has heard of ComfyUI?\nAll right.\nAll right.\nThis half of the room, very knowledgeable, very nice, very nice.\nUm, for those unaware, we are an open-source note-based design canvas intended for generative AI purposes for, uh, multimodal, um, creative applications.\nWe support image, video, audio, 3D, text, and more, uh, generative AI models.\nUm, ComfyUI supports the absolute bleeding edge of generally itch on day one.\nWe have ComfyAnonymous here implementing it from not quite scratch, but it is redesigned from the original implementations.\nUh, we offer open-source locally hosted models that support Nvidia, AMD, and Intel hardware.\nAnd we also support closed-source API accessible models that, as the name suggests, just use an API to deliver to the user.\nAll this functionality is also extendable with community-supported custom notepads.\nSo anything we do not have the time to get to ourselves, the community does for us.\nA big part of what makes ComfyUI special is the sharability of the workflows.\nAny image or video that was generated by ComfyUI has embedded metadata that lets you drag it back into the canvas and brings you the original workflow with all of the parameters that was used to generate it.\nUh, this sort of sharability and virality has really helped ComfyUI's traction.\nIf you do a simple Google search on, uh, ComfyUI workflows, you will find pages and pages and pages of results from the past year and a half, most of which are still compatible with modern ComfyUI versions.\nUm, in terms of pure numbers, uh, this sort of share billion virality has, over the past two years, taken us to the position of top 150 most popular GitHub repos of all time with 78,000 stars.\nAny comments?\nComfy?\nUh, no.\nAll right.\nAll right.\nUh, with more of the traction numbers, we have three to four million active users.\nWe have 20K daily downloads.\nWe have 22,000 custom nodes made by 3,000 public developers that we enable in our ecosystem.\nAnd we've been adopted by Amazon, Apple, Tensson, Netflix, and more.\nAnd pretty much any startup these days built around visual generative AI probably has ComfyUI working somewhere on their back end.\nUm, why is ComfyUI popular?\nUm, it gives maximal control.\nYou can go beyond prompts and interact with models that give you access to depth maps, line art, uh, masks, anything like that that is out in the space.\nIf it's open source, we probably either support it directly or the community has, uh, made it possible.\nWe are an all-in-one platform for both exploration for creatives and automation for developers.\nSometimes those roles can also be switched where developers want to explore tweaking models and seeing how things can be extended.\nAnd so we offer that as well through our custom node, uh, feature.\nAnd because we are open source, we do not only depend on the output of the core team.\nWe can trust the community to let us know anything they'd want us to work on and also make anything we do not have the time to work on on our team.\nAny comments?\nComfy?\nUh, well, I think, uh, yeah, I think we haven't shown the interface yet.\nSo yes, we have only shown one screenshot of the interface at the very start.\nWe will, uh, show that off as well.\nYou want to do it?\nJust do it later.\nYeah.\nAll right.\nStory behind Comfy.\nThe quick story is that, uh, basically, I started as my own personal project, and then I, and then, uh, yeah, and then, which, yeah, I started in January, January 2023, and then six months later, I was hired at Stability AI.\nSo I spent one year at Stability AI.\nThey were using Comfy for, uh, for more, uh, like experimentation with, uh, internal experimentation with the models, and then I left Stability AI in June 2024, and then I joined up with Yolan and Robin, and we, uh, we made like the comfy company, and, uh, yeah, that's, uh, things have been going pretty well since then.\nSo, yep.\nAnd this picture was taken on the Yeah, we, we went, uh, that, that picture, we went on top of Mount Fuji, uh, which, uh, I don't recommend.\nIt's, uh, very, very difficult, but, uh, yeah, but we did it.\nSo, yeah, I lucked out, and my flight to Japan, uh, got rerouted to Alaska for 24 hours.\nSo I landed in Tokyo five hours before they were going to be waking up to go to Mount Fuji.\nSo I got to Yeah.\nSo you, you missed the fun.\nI missed the fun and then still got sick for a week right afterwards.\nYeah.\nYeah.\nAll right.\nAnd like to know that Comfy.org is indeed hiring.\nUh, you can look at any opportunities on Comfy.org/careers.\nYeah.\nYeah.\nWe, yeah, we're hiring for a bunch of stuff.\nSo, if you're interested in joining us, if you're interested in open-source, uh, generative AI, well, that's, uh, maybe, uh, yeah, maybe we have a spot for you on our team.\nSo, you haven't checked out the website.\nThat is all for the official slides, but now is the fun part of showing the UI and taking any questions you may have.\nNice.\nI'm sure many on this side of the room who are familiar with ComfyUI know this standard, uh, galaxy bottle workflow.\nUnfortunately, this spoils the results.\nI'll just shake up the seed.\nAnyone not familiar with ComfyUI?\nThis is all being locally rendered.\nYeah, but this is a very old model.\nThis is SD 1.5.\nYes, this is, so that's why the results are not, not very good.\nYes, this model was, I think, the one that inspired your initial work on ComfyUI at the time.\nYeah.\nWell, fine-tunes of this model.\nThis is the base model, which isn't very good.\nBut yeah, this is, but it's very fast.\nSo, it's very fast, but it is ancient tech at this point.\nYeah, it's almost three years old at this point.\nYeah, ancient.\nAll right.\nAnd there's the UI, like you're, you're, you're looking at it.\nYeah.\nSo, basically, what Comfy does, for those who are not familiar, it kind of splits the whole diffusion pipeline into these different components, like a stable diffusion model is a diffusion model, a text encoder, and a VAE, which is why you have those three things right here.\nSo, yeah, model, diffusion model, clip is the text encoder, VA, the VA, and then, so have the sampler, VA decode, and save image, and that's basically a basic, uh, diffusion model pipeline.\nAnd what that lets you do is you can check which models you have on here.\nNot many.\nOh, maybe SDXL is.\nYeah, that one should work for the.\nI can, uh, type those numbers in for you.\nMy, uh, rookie mistake of turning off my num lock.\nLet's see how quick my disc drive is.\nYeah, this is all running on the laptop.\nThat's why it's, uh, a bit slow, but once it samples, we'll get there.\nSo, yeah.\nSo, this does look a lot better than that.\nYeah, this model is still also ancient.\nI think this one's two years old at this point.\nThis one's two years old.\nYeah, we have more exciting workflows, though.\nIf we browse the templates, if you want to go a little advanced, we've got There we go.\nThis will not run because I do not have like 60 gigabytes worth of models, but here's what that workflow looks like.\nYeah, this is what a video workflow looks like, which you, you can see it's very similar from a, from one of the image workflows.\nIt's just you still have the sampling node with different settings and same VA code node, which is kind of hidden here.\nAnd yeah, so, so this is, this is the, the one 2.1 model that's probably the best open video model at the moment, and you can see the, the pipeline is still very similar to even the first, uh, stable diffusion 1.5 model that was, that we were presenting earlier.\nSo yeah, but what that lets you do, the fact that you can, uh, you can go and change things like, say, if I want to, uh, like this is one of a technique that, uh, this is basically this node that I just added.\nWhat it does is it, u, it's a what I call a CFG trick.\nSo it, it will add something to the, uh, to the sampling, to the CFG calculations of the sampling code.\nSo basically, it's you can easily write these nodes which, uh, which will change.\nSo you can go and just patch the pipeline this way just by add, just by either writing your own nodes or using nodes that already exist.\nAnd for anyone unfamiliar with CFG, it is a AI trick where you take the positive prompt, you sample on that, you take the negative prompt, in this case, text and watermark, you sample on that, and with the magic of AI, you literally subtract the results from each other, and that in some way improves the image result.\nYeah, I think we can.\nYeah, I think we can take.\nDoes anyone have any questions about anything, like, or anything in general related to ComfyUI?\nWe have a question right here.\nYeah.\nUh, yeah, those are basically those clip.\nYou know what clip is?\nYeah.\nIt's, uh, basically the diffusion models, they use the text encoder part of the clip model to, it's instead of, so instead of passing the text directly to the model, they use this, uh, a text encoder because that way the model doesn't have to, the diffusion model doesn't have to learn like all the, to understand human language.\nIt can just learn the output embeddings of whatever text encoder you use.\nSo yeah, so the, this is, uh, basically the clip in ComfyUI represents the text encoder.\nThe reason it's named clip is because before, like on the stable diffusion models, they were only using clip as the text encoder, but in later models, it's more, they start, later models started using different text encoders that were not clips.\nSo the name, I should, yeah, the name should be changed, but, uh, yeah, so what this does is it essentially, what this note does is it passes the text through the text encoder, and then the output would essentially be the output embeddings of, or the last hidden, the last hidden state, essentially, of the text encoder, and that's usually, well, it depends, it's slightly different for every, for every model.\nBut essentially, it's the most of them, it's the last hidden state or the penultimate hidden state that is passed to the diffusion model.\nYeah.\nBecause this is a positive and negative prompt.\nThis is how the CF, like, because the models, how you sample most of these diffusion models is with a positive and a negative prompt, and that's a using CFG, something called classifier-free guidance, CFG.\nAnd what it basically, the, the idea is that if you only sample with a positive prompt, so yeah, if I put CFG G to one.\nThat's essentially just sampling with a positive prompt.\nAnd you, you can see what happens when you, you only sample with a positive prompt.\nIt's a, you can see that the image is, wait, this is worse than, well.\nOkay.\nIt's because I have this node.\nWell, this is worse than it should be.\nBut, uh, okay.\nYeah.\nIf I, yeah, if I sample with just, uh, just the posit, you see that it's, uh, the image is not very well defined.\nIt's very chaotic if you only.\nSo what CFG does, it's a trick because if you think of all the possibilities of what the model can generate, it's kind, if you, it's kind of a way to push for, like, the CFG scale does when sampling, it does positive minus negative prompt, and it's a way to push the sampling very more towards your positive and away from your negative.\nSo the higher the scale, the more it will do that, which means you get a more defined image.\nI don't know if, uh, my explanation makes sense, but, uh, yep.\nYep.\nYeah.\nThe VA is because the, what made stable diffusion be ex work extremely well, and, uh, yeah, what, what made stable diffusion be extremely popular is the fact that the, the image generation happens in compressed latent space.\nSo instead of doing it in pixel space on a, like, let's say, a 5 thou, a 512 x 512 image in pixel space, that's, that's a lot of pixels, or some earlier diffusion models did that, but they were pretty slow.\nStable diffusion, it did this in a latent space, which, uh, for a stable diffusion, the VAE is 8x compressed on every, uh, on every, on the two, two dimensions.\nSo yeah, so instead of, uh, sampling a, uh, yeah, a 512 * 512, you would be sampling a 64 * 64 image, which is, which is why these models are got so popular because they were a lot more efficient than what came before.\nSo yeah, so that's what the VA, the VA is just a.\nYeah, it's a VAE.\nIn input is like 512 * 512 * 3 channel, and output would be, uh, would be, yeah, 64 * 64 * 4 channel in the case of, uh, of this model.\nAwesome.\nThank you so much.\nAll right, we have a question right here, and I'll, I'll give you the mic.\nThank you.\nSo, um, Kofio is really in a lot of the examples is focused on the image generation as such, you know, kind of all kind of cool plugins.\nUm, I wonder if you have good suggestions or ideas about evaluating the results, kind of like verifying or kind of like saying this is a good image or not a good image, uh, to, to kind of automate that workflow as well.\nUh, that's, uh, that's a difficult thing to do usually because if, uh, it's the problem where, like, how do you define a good image, because, uh, yeah, that there's some problems with, uh, because people's taste is very subjective.\nSo what is a good image for one person might not be a good image for another person.\nSo yeah, it's a, it's a problem they have.\nIt's actually a big problem with the, like, user, people who do, who train these diffusion models, like user preference.\nThey, uh, when they, when they actually add the user preference data, their results get a bit worse because users like, like the average user likes a certain type of image, which is not maybe might not be what, uh, what most, what most people want.\nSo it's, uh, yeah, but, uh, any models that you bring in or you kind of have a prompt that looks at the image, uh, like a multimodel, but anyway, if there's not, yeah, there's, yeah, I, yeah, we've had, like, at least back when I was at Stability, we did have some, uh, we did experiment with some models that tried to just see, oh, like, get the output, output the image from the workflow, get some kind of rating from a model, but, uh, it didn't work that well.\nSo it's okay, good question.\nAll right, do we have any other questions right now from anyone?\nRaise your hand so I can see.\nDo you have another one?\nAwesome.\nSo, this is predominantly a workflow, and once you kind of like, uh, develop it, you do it in the UI.\nUm, any good tools around then, uh, running this more headless and\n\n\nKind of scaling this out and maybe building this into an app for kind of people using it.\nYeah, this is uh just uh yeah, this is one thing that uh because well, is this what ComfyUI is? It's actually you have this interface, but you also have a powerful backend behind it, which executes the workflows. And right now, there's there's actually a lot of uh a lot of different inference services for these workflows, and eventually, we'll be building our own.\nSo, and yeah, and there's there's already some uh a lot of uh third-party services that I saw that you can take your workflow, make an app out of it, and uh yeah, so you can already you can already do that, but uh just there's no just no official way of doing it, but there might uh there might be one in in the future.\nSo, okay.\nThanks for clarifying.\nThank you for the question.\nAll right.\nAny questions?\nBecause we'll keep on talking about other stuff if there are no more questions.\nSo, be prepared.\nAll righty.\nUh, one of the more recent additions to come for ComfyUI.\nFor a long time, we only supported open-source local models.\nIn the past month, we've introduced API nodes, which for paid credits allow you to generate remotely.\nUm, let's open up a template we can do.\nThere we go.\nOne of the models that recently came out was a Black Forest Labs context model.\nUh, currently not out for open source usage in terms of being able to run locally, but they have made the APIs available.\nYeah, eventually they're supposed to release an open source version, which uh well, we we already support, they just haven't haven't released it.\nYes, we are waiting for the green light.\nYeah.\nAnd I would run this, but I have no internet connection, and that's one of the limitations of API notes.\nYou need to, you know, they're not ran locally.\nYeah.\nSo, there's some interesting.\nYeah.\nSo, we have uh.\nYeah.\nYeah, we have a lot of different uh so the models that so that we support image, video, yeah, 3D.\nSo, we have a basic support for like Hunion 3D model, which is uh basically it's an interesting model.\nSo, it basically outputs a voxal type uh like the the 3D model, all these output is a kind of a voxal format, and then you and then so that's why in the workflow there's a yeah, there's some uh code to.\nSo, but the problem with these models, since it's kind of it generates some voxal format, and then and you need to use an algorithm to convert it to mesh, is that the mesh isn't very high quality, but it's still uh pretty impressive.\nI do not have any of these models coming.\nYeah.\nAnd we're currently, I guess, not we have local support for LLM.\nWell, there there's a bunch of custom nodes with local LM support.\nIt's just not a core ComfyUI thing yet.\nIt's just we're more focused on uh on like image and video and all these uh more visual or we also support audio and audio model now.\nSo, yeah, it's not as good as some of the proprietary models out there, but it's uh yeah, it's pretty fun to play with.\nAnd there were some more I think uh audio models that came out.\nYeah.\nBut those those are texttospeech models.\nGotcha.\nYeah.\nThose which we we may support.\nWe'll we'll have to see if uh because they're they're already supported as custom nodes, but uh yeah, before to yeah, it's just to integrate them in core ComfyUI, there needs to be like a reason to, like if uh give them extra control or some extra like extra knobs to turn, or else there's not much point.\nI'm interested in any questions from this side of the room that maybe wasn't too familiar with ComfyUI at the start.\nUh, do you have any questions, comments, inquiries?\nAll right, I will hand you the mic.\nSorry, it's me again.\nSo, does ComfyUI have the use case for the virtual tryon where you know we upload the image of the model uh the manqueen and the garment, the clothes, so that it generate the virtual trion images?\nYeah, like for example, the new flux context model can can do that.\nUh, I think so there yeah, there's a few different there's some opensource ways and there's some uh some ways using uh the API nodes, but uh yeah, virtual trans, it's something that seems very popular.\nSo, there are there are a bunch of workflows for it.\nOkay.\nSo, we can find it on the ComfyUI and try it out.\nUh yeah.\nYeah.\nIf you if you search, you can find uh you can probably easily find a workflow for it.\nThe only thing you might uh it's just some of the it's just that the field evolves so fast that uh sometimes uh workflows you find might be slightly outdated.\nSo, but if I was doing that, I would first try the new flux context model since that seems to be uh the best one for that.\nBut uh yeah, uh the name is new conf uh what's the model name?\nNew uh flux concept.\nFlux concept context.\nYeah, I keep Okay.\nYeah, flex.\nSorry.\nFlux context.\nK.\nYeah, context with a K.\nSo, thank you.\nThank you so much.\nAnd to also follow up on that, um, right now, yeah, right now it's an API node only, but they're they should release the, uh, the opensource version soon.\nSo, yeah.\nSo, once that's once that's released, you'll be able to run it on your on your on your machine with the ComfyUI.\nYeah.\nTo follow up on virtual tryon, this is actually something that people have in workflows in the past year.\nWhen we were in Japan, when we had a meet and greet there, there were some people who actually made workflows specifically for that.\nBack then, there weren't some of the models like context now are very good at a hey, change this one thing.\nAt the time, there weren't.\nSo, the workflows you'd find probably have a few dozen nodes basically finding using a one model to find the masks of like what to change, then another model to inpaint those masks of the actual thing you want to change.\nNow the models are a bit more uh advanced where you can just say hey I want to edit this and it does it.\nAnd you of course combine up the masks as well.\nIn case the model gets a little uh a little rowdy and tries to change things you don't want, you can always add masks to keep it contained.\nAny more questions on this side of the room?\nSo sorry I joined the session very late late, but um if you want to generate any kind of image, I think this allows us to write a prompt and then it allows us to generate image.\nIs that correct?\nYes.\nOkay.\nSo, for example, if you want to have a tool that automate building multiple images based on let's say character, like if if I want to have define a character and if if I want to generate a stories based on the characters, does this allow it?\nYes.\nWell, you what you need is there's a few different ways to because I assume yeah, you want to generate a consistent character is depending on what you want.\nYou can either uh train a lora for your character or use one of the newer model like uh like the flux context model, like these uh like very recently there's all these edit models that have what I call edit models, which are basically uh they they got very inspired with what the 40 was doing.\nSo, which one do you suggest?\nWhat which one do you suggest?\nUh right now the the best one is uh the flex uh the yeah the flex uh context model, but uh like I said, it's only right now it's only available through an API and but uh should be open source soon and then there's some other ones too, but uh at one yeah, what you can do with uh with the the context text is just like some you give it a reference image of a character and you say, \"Oh, make that character do this.\"\nAnd it actually keeps the character consistency extremely well.\nJust uh so there is there is a way to uh maintain character throughout the story generation, right?\nYes.\nYeah.\nWell, what you would do is you would have a Yeah.\nFirst you generate a your character of an image of your character that you're happy with and then you would uh you would pass it to this model and say oh put this character in this scene, put this character in that scene and then you generate your image is based on this reference image of the character.\nOkay, thank you.\nAnd to follow up on that, one of the advantages of a nodebased system is with the way that is set up, all you can currently edit in it are some of the parameters and the text prompts, but you could also apply the Lauras.\nLauras are uh low rank adaptations to the model.\nUm, and because it's node based, you can also mask the specific area each of those low rank adaptations would apply to.\nSo let's say you have two Laura strained, one for character A, one for character B.\nUh what our nodebased system allows is to say hey in this area of the image I'd like this Laura to be active maybe at this strength, you could even schedule it in terms of that and on the other area of an image you can have oh I want this other character Laura to be active so if even if you uh if like an all-in-one model like context doesn't quite do what you want, there are multiple ways you can sort of coersse these models to kind of do it with a basic uh promptbased system.\nThere are of course limitations, but because we are node based, you can do, you know, there's two things for the prompts there.\nYou could set that up to be 10 nodes, and some of those nodes apply a specific Laura to a particular image, sorry, to a particular area of an image.\nDo you also recommend Laura or uh the other one?\nUm, if you don't have uh like much experience in the space, I'd recommend the context model mainly because you just you just have to type in the prompt and it does the work for you.\nThe other one, especially back before the sort of, you know, edit via text models existed was sort of a brute force way of getting what you want, but you could really get what you want because you could train it on anything you want.\nThe models don't have to be aware of what it is.\nAnd the the only disadvantage is you need to have enough training images.\nSo like between 10 to 30 to actually get your subject to appear the way you want them to.\nWith these newer edited models, you only to give the one image.\nNo problem.\nAll right.\nAny questions here?\nOr back on that area of the room?\nI can walk.\nAll righty, come.\nWhat do you want to talk about next?\nOh, well, yeah.\nYeah.\nWell, we since we mentioned Lauras, like Lauras are one of the basically what they what they are is a a patch on I call them a Yeah, they're basically a patch on the model weights, which is or a more efficient way to train a concept or multiple concept in in a in a model.\nAnd yeah, right now we don't it's basically just if you want to train a model instead of training the full model, you would train this small patch on the model.\nAnd this allows you to well you can train styles, specific characters, anything.\nSo yeah, we can we can skip showing it off.\nThis was for the uh Japan presentation where this this Laura is for for a anime character that goes hard in Japan.\nProbably doesn't go very hard at a AI conference.\nBut this is how you would do it.\nYou would just chain the model there.\nAnd these are uh do I have any SDX?\nI do not.\nOkay.\nThis is for 1.5.\nYes.\nAnd uh they're for Japan.\nI mean, we can still show them off, but uh All right, we can try.\nYeah.\nOh, and these would probably look very poorly on these models, but we can give it a shot.\nWell, I used the anime one.\nOkay, we can use an anime one.\nOkay, that's the anime one.\nYeah, it works.\nSo, yeah, just I mean, if you try that prompt, it's probably not gonna.\nYeah, we can uh we we can do that in a bit.\nAll right.\nOkay.\nWhat else would you like to talk about?\nUh yeah, can just try see.\nYeah.\nWell, we can press run and I I don't know if we should I don't know if we should press run.\nYeah.\nWell, okay.\nYeah, we can.\nYeah, this is a assignment to do at home, I suppose.\nBut we have other models that we support.\nLet's see.\nYeah, apologies that we do not have much live demos.\nUh uh there were some setup last minute in terms of us attending the conference.\nSo, but we are here.\nSorry about that.\nOh, here are some control net examples where can't show the inputs, but we can actually I guess we can we can trust the template system to kind of show what that's about.\nYeah, control nets are just one of the many ways to have more control of these uh of the the models.\nYeah.\nSo the examples here would be the inputs that were used to actually generate these images, but those might be like control nets might no longer be very useful because now there's all these edit models that are coming out.\nSo yeah, it just means that the space is uh is evolving.\nBut uh uh so here's a more advanced workflow where it applies I believe different prompts to different areas of the image.\nYeah, this is a different prompts to different areas.\nYeah, we can actually make this one go on the default SD 1.5 model.\nThat one will will work.\nOkay.\nAh, yes.\nThis is the old way of prompting things when the models kind of had to really coers them.\nWe will fix the seed.\nOkay.\nAnd let's see how the laptop handles.\nYes.\nSee, assuming there's no loaded images, this should just work.\nYeah, at least half the workflow should work.\nYeah.\nYeah, this is a very old workflow, but uh I think it's still works on even the most recent models and we can uh we can change the prompts.\nMaybe it's more obvious, but I believe the prompts are basically doing a different time of day on some of these.\nYeah.\nYeah, it's basically different time of day on like if you go Yeah.\nTop is like night and bottom is daytime.\nYeah.\nJust uh Yeah.\nSo, this is just one of many ways you can get like more control.\nThis is just a way of applying different prompts in different areas of the image.\nLike I said, I think it it still works even on the most recent models.\nYep.\nYeah.\nEverything that basically started from the foundation at Comfy set up two years ago, most of those any of those tricks or applications still apply to newer models.\nYeah.\nBecause they're general like diffusion model tricks and we're still using diffusion.\nSo you Yeah.\nSo that's what makes Comfy nice is that if once if a new diffusion model is implemented, usually you can use all the old tricks if you want.\nSome of them might not be useful anymore, but you can still use\n\n\nThe models have also gotten bigger and harder to run locally in some cases on some hardware. So, uh, some of these tricks would, you know, make things run quite a bit slower. In the early days of image generation, a lot of the improvements were with community fine-tunes who would take, you know, vast data sets and improve the base model. You may have noticed I was a little nervous running a model a few minutes ago. The reason for that was one of those fine, that was one of the sort of days of back of community fine tunes. The data sets they used may not always produce the most conference-friendly content. Yeah, there's some interesting things that happen when a model is slightly broken because since it's a diffusion model, if it's slightly broken and you're generating a like a character, the first step might produce a like a skin color blob, which means it might converge to a naked person basically. So yeah. And given there are community fine tunes that basically everyone trusted to produce better quality images, those are usually generations that you first review and then show rather than press Q and then, uh, yeah, but that's the power of running things locally. You don't have any problem. You can do whatever you want. So, yeah, newer models and bigger ones, the training sets are a bit more constrained. So you have the pros and cons of that. It's just they're better. They make less random mistakes. You can be more, you can trust more that when you put in a specific prompt, it will not hallucinate as much.\n\nAll right. So in terms of, we mentioned that we are hiring. I believe we're looking for positions on, well, everything, pretty much, back end, front end, core, cloud deployment, inference, that cloud, yeah, just, yeah, go look at our carriers page and, uh, yeah, it's comfy.org/careers. Yeah. And if you haven't tried the software, go try it. You can just, if you all you need is a decent GPU and you can run it locally or you can use the API nodes and Yeah. People have gotten some of the early models to work on extremely old GPUs like Yeah. 80-year-old GPUs. Yeah. One of the strengths of ComfyUI is that pretty much any hardware, well, any Nvidia hardware, the model will usually run. It might be extremely slow, but it will usually run.\n\nSo, yeah. So are there any final questions? Oh, right there. Uh, hold up. I'll give you the mic. There's a process to this thing. Thank you. Um, I've tried using ComfyUI and I was just wondering like if you could give us like a quick synopsis of what do you think about ComfyUI versus the alternatives that exist? Like why would you sort of say ComfyUI is the one that people should start with or stick to? I have no idea like of the depth of it. So just give me like a seminar of that, please. Uh, ComfyUI is, uh, you should use it because it's the, it's the most, basically, it's the most powerful one. So if you, uh, like everyone who, like it's basically the end game for these types of interfaces. So there, there's nothing that gives you more control, that has more community support, that has more extensions.\n\nSo the only downside it has right now is it's a bit difficult to get into, but we are working on that. So, thank you. Node-based systems, especially if you're not used to them at first, can be quite intimidating. And as ComfyUI mentioned, one of the greatest assets of ComfyUI is that it is community extendable and it is open source in that anything that the core team may not be able to get to, there probably exists a community solution for that or to do something like, like we mentioned the slide, there are I believe 22,000 custom nodes within like 3,000 note packs made by, you know, 3,000 separate developers who are all passionate. If you go to other places, you will not always have, you know, the certainty as, oh, can I run this locally? Do I know all my data safe? If you are in a, for example, enterprise setting, data security might be a big thing to avoid becoming the next headline in terms of a data leak or a ransomware attack. So being able to actually look at the source code, that's your thing, or having your team be able to look at the source code. You can contribute any fixes. is, uh, in terms of optimization and performance, we are pretty much state-of-the-art, uh, ComfyUI over there. When the new model comes out and he hears that there is a way to run it faster, he implements it or one of us on the team implements it. So, um, there's a Discord channel that we have for comfy.org. We also, as we post the slides, if you just Google ComfyUI, there will be most likely thousands of YouTube videos. Um, there's even some people who have taken, uh, they've seen the opportunity of the difficulty of ComfyUI. Um, and they are, for example, having paid, uh, tutoring classes for it, which is a bit of an eye-opener for us because that says we should probably do a better job onboarding users if people are, you know, making money that way, but there should be a lot of resources out there for you.\n\nAll right, any other questions? All right. Over there. Is there currently a published product roadmap? Uh, if you mean what we are currently, um, well, we haven't started, really started, actually started yet, but eventually we'll have a solution to run these workflows in the cloud. And, uh, yeah, how exactly it's going to work because we, the thing is, before doing that, we want to fix, there's a few issues we have to fix, like the, for example, we want to make it installing and dealing with the custom node that you install. We want to make that a lot smoother, make the interface better, add a Yeah, we're what we're going to do is improve the interface key. Well, the, there's always going to be the node interface, but, uh, we are most likely going to add another layer on top of it where you can have a more, build a more traditional interface out of your workflow graph. And that will fit in with the, well, with the cloud stuff that we're going to be doing eventually. So yeah, so that's that's the direction where we're going in. But, uh, the thing is in this space is that things change a lot. So a new model that comes out tomorrow might, uh, might mean we need to, uh, pivot a bit. So that's why I'm not, uh, I'm not giving any promises. So yeah, because like the first thing that went to my mind is we had the gentleman ask a question about can we serve these workflows up? So it's like if you can access a workflow through an API, you can have like a single power user building out massive templates. Yeah. That maintain like style and brand guidelines or or story or character design and then be like role-based access control. You could have like just a general user in there saying, \"Hey, I need to generate this workflow based on these parameters. I can't touch anything else in there.\" like is that is like being more enterprise or team? Yeah, team ready. This is one of this is a direction we are going into. So like having, uh, just the the basics for that would be first a good cloud inference service where you can run workflows very well and have all the custom nodes work and once we solve that, then all that other, all that other service becomes a lot easier. So yeah, thank you. And to follow up on that, at the end of the week, we will have a blog post about some of the things we are working on, um, for the, because we are planning to allow cloud services, but first, as ComfyUI said, we need to work out dependency issues. So we'll have a bunch of features being announced there. For example, we'll have a subgraph option where you can combine a bunch of nodes, put it into one node, and you can double click into it as like a separate workflow. Uh, solving dependency issues where custom nodes right now can request different Python packages. Making sure all of those could get either properly isolated or have more ways for them to report their compatibility because once local becomes much better to run, that means our life trying to get this as a cloud product will also become smoother. Yeah, I think, yeah, we are out of time now. So would, uh, would like to thank everyone for coming. We, uh, Yeah. And I hope you, uh, you learned something. Yeah. Thank you for all the questions. Greatly appreciated. Yeah.\n[Music]\n",
  "dumpedAt": "2025-07-21T18:43:25.793Z"
}