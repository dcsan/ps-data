{
  "episodeId": "wAQK7O3WGEE",
  "channelSlug": "@aidotengineer",
  "title": "Agents reported thousands of bugs, how many were real? - Ian Butler and Nick Gregory",
  "publishedAt": "2025-06-03T22:22:29.000Z",
  "rawLines": [
    {
      "lang": "en",
      "text": "A agents for software engineering have",
      "offset": 0.24,
      "duration": 2.88
    },
    {
      "lang": "en",
      "text": "been exploding in popularity over the",
      "offset": 1.76,
      "duration": 2.96
    },
    {
      "lang": "en",
      "text": "last year and we wanted to find out just",
      "offset": 3.12,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "how good are they at finding and fixing",
      "offset": 4.72,
      "duration": 3.119
    },
    {
      "lang": "en",
      "text": "bugs. Can you even rely on them for",
      "offset": 6.16,
      "duration": 2.72
    },
    {
      "lang": "en",
      "text": "maintenance? Well, that's what we're",
      "offset": 7.839,
      "duration": 2.241
    },
    {
      "lang": "en",
      "text": "going to tell you here today at a",
      "offset": 8.88,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "engineers world fair. Uh, hey guys,",
      "offset": 10.08,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "we're Bismouth and we've been working on",
      "offset": 12.16,
      "duration": 2.479
    },
    {
      "lang": "en",
      "text": "software agents for the last year in",
      "offset": 13.36,
      "duration": 2.72
    },
    {
      "lang": "en",
      "text": "some change. My name is Ian and I'm the",
      "offset": 14.639,
      "duration": 3.121
    },
    {
      "lang": "en",
      "text": "CEO of Bismouth. So, my background was",
      "offset": 16.08,
      "duration": 2.88
    },
    {
      "lang": "en",
      "text": "in data engineering, machine learning,",
      "offset": 17.76,
      "duration": 2.88
    },
    {
      "lang": "en",
      "text": "and search. Previously, I was at Zillow",
      "offset": 18.96,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "as a senior edge on the AB testing",
      "offset": 20.64,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "platform. Uh, and this is my second time",
      "offset": 22.08,
      "duration": 3.439
    },
    {
      "lang": "en",
      "text": "working deeply on dev tooling at a",
      "offset": 24,
      "duration": 3.599
    },
    {
      "lang": "en",
      "text": "startup. Um, I started with technical",
      "offset": 25.519,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "documentation search in 2019 along with",
      "offset": 27.599,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "Nick here building an index of hundreds",
      "offset": 29.679,
      "duration": 3.121
    },
    {
      "lang": "en",
      "text": "of millions of technical documents for",
      "offset": 31.279,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "inline IDE use along with AI",
      "offset": 32.8,
      "duration": 3.439
    },
    {
      "lang": "en",
      "text": "summarization for internal knowledge",
      "offset": 34.559,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "bases. Hey, so I'm Nick, CTO of",
      "offset": 36.239,
      "duration": 4.241
    },
    {
      "lang": "en",
      "text": "Bismouth. Um, I was primarily in the",
      "offset": 38.559,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "software security space before starting",
      "offset": 40.48,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "Bismouth with Ian. Um, I was at Google",
      "offset": 42.399,
      "duration": 5.041
    },
    {
      "lang": "en",
      "text": "just prior on an internal tools team",
      "offset": 45.44,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "building endpoint security software and",
      "offset": 47.44,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "before that I was a research scientist",
      "offset": 49.68,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "focused on detecting software",
      "offset": 51.76,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "exploitation. Um there's a lot of tools",
      "offset": 53.92,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "and techniques from that space that",
      "offset": 56.16,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "transfer to building intelligent agentic",
      "offset": 57.68,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "code tools. It turns out before we get",
      "offset": 59.84,
      "duration": 3.359
    },
    {
      "lang": "en",
      "text": "started just want to shout out base 10",
      "offset": 61.84,
      "duration": 2.8
    },
    {
      "lang": "en",
      "text": "for helping provide credits and compute",
      "offset": 63.199,
      "duration": 2.801
    },
    {
      "lang": "en",
      "text": "for running our benchmark across both",
      "offset": 64.64,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "DeepSec R1 and Llama for Maverick.",
      "offset": 66,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "Thanks guys. We really appreciate it.",
      "offset": 68,
      "duration": 2.28
    },
    {
      "lang": "en",
      "text": "Thank",
      "offset": 69.28,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "you. So to dive right in, we wanted to",
      "offset": 70.28,
      "duration": 4.76
    },
    {
      "lang": "en",
      "text": "share with you all the benchmark we've",
      "offset": 73.04,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "been building for a few months now to",
      "offset": 75.04,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "explore just how good software agents",
      "offset": 76.88,
      "duration": 4.239
    },
    {
      "lang": "en",
      "text": "are at coding tasks outside of the",
      "offset": 78.96,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "normal feature development. There's a",
      "offset": 81.119,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "handful of benchmarks already to measure",
      "offset": 83.04,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "how effective LLMs are for writing code.",
      "offset": 84.72,
      "duration": 4.12
    },
    {
      "lang": "en",
      "text": "Human",
      "offset": 87.68,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "evaluator's polyglot benchmark uh and",
      "offset": 88.84,
      "duration": 5
    },
    {
      "lang": "en",
      "text": "live codebench just to name a few. But",
      "offset": 91.6,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "of course that's only one part of the",
      "offset": 93.84,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "software development life cycle and what",
      "offset": 95.6,
      "duration": 4.479
    },
    {
      "lang": "en",
      "text": "developers do. So what about the rest of",
      "offset": 97.28,
      "duration": 5.839
    },
    {
      "lang": "en",
      "text": "the SDLC? Well, uh initial scoping and",
      "offset": 100.079,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "planning is kind of an entirely",
      "offset": 103.119,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "different task, right? It requires",
      "offset": 104.799,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "broader business context, knowledge of",
      "offset": 106.399,
      "duration": 4.241
    },
    {
      "lang": "en",
      "text": "existing systems and designs, exploring",
      "offset": 108.159,
      "duration": 5.121
    },
    {
      "lang": "en",
      "text": "potential existing solutions and so on.",
      "offset": 110.64,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "Um, it's basically a completely",
      "offset": 113.28,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "different task from development. Um,",
      "offset": 115.2,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "next we have the feature dev and testing",
      "offset": 117.84,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "which are already pretty well covered by",
      "offset": 119.92,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "the existing benchmarks. Um, and then",
      "offset": 121.52,
      "duration": 4.959
    },
    {
      "lang": "en",
      "text": "there's the code review process which is",
      "offset": 124.079,
      "duration": 4.481
    },
    {
      "lang": "en",
      "text": "pretty much unbenchmarked by existing",
      "offset": 126.479,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "work even though we're seeing more and",
      "offset": 128.56,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "more LLM based tools in the space. Uh",
      "offset": 130.239,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "and this is actually the first part of",
      "offset": 133.52,
      "duration": 2.2
    },
    {
      "lang": "en",
      "text": "our",
      "offset": 134.959,
      "duration": 3.041
    },
    {
      "lang": "en",
      "text": "benchmark. Deployment is a pretty",
      "offset": 135.72,
      "duration": 4.44
    },
    {
      "lang": "en",
      "text": "separate task requiring not just writing",
      "offset": 138,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "configuration but also setting up",
      "offset": 140.16,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "monitoring, integrating with other",
      "offset": 141.76,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "existing systems, etc. It's also pretty",
      "offset": 143.28,
      "duration": 6.16
    },
    {
      "lang": "en",
      "text": "distinct. Um last and le last and not",
      "offset": 146,
      "duration": 5.599
    },
    {
      "lang": "en",
      "text": "least though we have software",
      "offset": 149.44,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "maintenance tasks. So think things like",
      "offset": 151.599,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "bug fixes, dependency upgrades,",
      "offset": 154.16,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "migrations, etc. Um, this is another",
      "offset": 156.239,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "part of the SLC that at its core is",
      "offset": 159.04,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "still generally writing code but is in a",
      "offset": 160.879,
      "duration": 6.041
    },
    {
      "lang": "en",
      "text": "distinctly different way than feature",
      "offset": 164.08,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "development. So the ability to reason",
      "offset": 166.92,
      "duration": 4.36
    },
    {
      "lang": "en",
      "text": "through a codebase deeply defined bugs",
      "offset": 169.44,
      "duration": 3.519
    },
    {
      "lang": "en",
      "text": "is directly transferable to being able",
      "offset": 171.28,
      "duration": 3.679
    },
    {
      "lang": "en",
      "text": "to produce features. You can think about",
      "offset": 172.959,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "how like when you're dividing a feature,",
      "offset": 174.959,
      "duration": 2.64
    },
    {
      "lang": "en",
      "text": "you're going to learn the architecture",
      "offset": 176.56,
      "duration": 2.48
    },
    {
      "lang": "en",
      "text": "of the codebase. You're going to learn,",
      "offset": 177.599,
      "duration": 2.561
    },
    {
      "lang": "en",
      "text": "you know, how everything connects, the",
      "offset": 179.04,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "data flow and stuff like that. So that's",
      "offset": 180.16,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "the same for finding bugs. In both",
      "offset": 182.56,
      "duration": 2.8
    },
    {
      "lang": "en",
      "text": "cases, you need an understanding of the",
      "offset": 184.08,
      "duration": 2.84
    },
    {
      "lang": "en",
      "text": "system architecture and its",
      "offset": 185.36,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "connectedness. Um, in the case of",
      "offset": 186.92,
      "duration": 3.959
    },
    {
      "lang": "en",
      "text": "finding bugs, you even often need to",
      "offset": 189.36,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "understand the system more deeply than",
      "offset": 190.879,
      "duration": 2.961
    },
    {
      "lang": "en",
      "text": "when you originally wrote the feature in",
      "offset": 192.4,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "the first place. Um, to that end,",
      "offset": 193.84,
      "duration": 3.759
    },
    {
      "lang": "en",
      "text": "maintenance requires the ability to",
      "offset": 196.48,
      "duration": 2.479
    },
    {
      "lang": "en",
      "text": "first deeply reason through a system and",
      "offset": 197.599,
      "duration": 2.56
    },
    {
      "lang": "en",
      "text": "identify if bugs are potentially",
      "offset": 198.959,
      "duration": 3.041
    },
    {
      "lang": "en",
      "text": "present. We found agents struggle with",
      "offset": 200.159,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "holistic evaluation of files and",
      "offset": 202,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "systems, only finding subsets of bugs",
      "offset": 203.519,
      "duration": 3.761
    },
    {
      "lang": "en",
      "text": "per run. Thinking models alleviate this",
      "offset": 205.2,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "somewhat, but reasoning appears to be",
      "offset": 207.28,
      "duration": 2.959
    },
    {
      "lang": "en",
      "text": "somewhat narrow, only exploring a",
      "offset": 208.72,
      "duration": 3.439
    },
    {
      "lang": "en",
      "text": "limited number of potential avenues at a",
      "offset": 210.239,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "single time. This is translated directly",
      "offset": 212.159,
      "duration": 4.241
    },
    {
      "lang": "en",
      "text": "to LLM's missing bugs that human",
      "offset": 214.64,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "developers would pick up almost",
      "offset": 216.4,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "immediately and confirming bugs that",
      "offset": 217.68,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "human developers would discard almost",
      "offset": 219.76,
      "duration": 3.759
    },
    {
      "lang": "en",
      "text": "immediately. While there is value here,",
      "offset": 221.44,
      "duration": 5.24
    },
    {
      "lang": "en",
      "text": "the ability is clearly still in its",
      "offset": 223.519,
      "duration": 5.201
    },
    {
      "lang": "en",
      "text": "infancy. When it comes to patching of",
      "offset": 226.68,
      "duration": 3.639
    },
    {
      "lang": "en",
      "text": "these bugs, because of the relative",
      "offset": 228.72,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "simplicity that we have seen from them,",
      "offset": 230.319,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "they usually get it uh without much of",
      "offset": 231.92,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "an effort. But again, because the bugs",
      "offset": 233.599,
      "duration": 3.041
    },
    {
      "lang": "en",
      "text": "themselves are not particularly complex,",
      "offset": 235.2,
      "duration": 3.56
    },
    {
      "lang": "en",
      "text": "this isn't really saying much.",
      "offset": 236.64,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "Yeah. So there are some existing bug",
      "offset": 238.76,
      "duration": 4.839
    },
    {
      "lang": "en",
      "text": "detection benchmarks from the software",
      "offset": 241.68,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "security space, but there's some big",
      "offset": 243.599,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "limitations that don't really make them",
      "offset": 245.76,
      "duration": 3.679
    },
    {
      "lang": "en",
      "text": "suitable for evaluating these new",
      "offset": 247.439,
      "duration": 4.561
    },
    {
      "lang": "en",
      "text": "agentic AI systems since they were built",
      "offset": 249.439,
      "duration": 4.561
    },
    {
      "lang": "en",
      "text": "to benchmark kind of classic static",
      "offset": 252,
      "duration": 4.479
    },
    {
      "lang": "en",
      "text": "analysis or program repair tools. Uh",
      "offset": 254,
      "duration": 5.199
    },
    {
      "lang": "en",
      "text": "they focus on relatively simplistic bugs",
      "offset": 256.479,
      "duration": 5.681
    },
    {
      "lang": "en",
      "text": "in common patterns, things like null",
      "offset": 259.199,
      "duration": 5.041
    },
    {
      "lang": "en",
      "text": "pointer dreerences, buffer overflows,",
      "offset": 262.16,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "maybe SQL injection in a web app, which",
      "offset": 264.24,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "could all be found statically. Um, a lot",
      "offset": 266.56,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "of the benchmarks are also really",
      "offset": 269.28,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "limited in the languages that they pull",
      "offset": 270.479,
      "duration": 6.081
    },
    {
      "lang": "en",
      "text": "from. So many of them are only Java for",
      "offset": 272.88,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "instance because that's where the vast",
      "offset": 276.56,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "majority of enterprise complicated",
      "offset": 278.24,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "software was and honestly still is",
      "offset": 280.72,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "written. Um, there's also a bias towards",
      "offset": 283.52,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "security issues in the existing",
      "offset": 286.16,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "benchmarks partly as a result of that",
      "offset": 287.6,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "being where the classic static analysis",
      "offset": 290.08,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "tools are focused. Um, but bugs appear",
      "offset": 292.4,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "in many more ways than just security",
      "offset": 295.44,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "defects, right? Copy paste bugs are a",
      "offset": 297.28,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "really simple example where they don't",
      "offset": 299.52,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "often result in an off bypass, for",
      "offset": 302.24,
      "duration": 4.799
    },
    {
      "lang": "en",
      "text": "example, but it breaks the software to",
      "offset": 304.56,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "end users all the same, right? So, how",
      "offset": 307.039,
      "duration": 4.681
    },
    {
      "lang": "en",
      "text": "does our benchmark SM",
      "offset": 309.68,
      "duration": 4.799
    },
    {
      "lang": "en",
      "text": "compare? So, we painstakingly gathered",
      "offset": 311.72,
      "duration": 4.919
    },
    {
      "lang": "en",
      "text": "100 bugs that we triaged, validated, and",
      "offset": 314.479,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "classified in over 84 public",
      "offset": 316.639,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "repositories. These are bugs that have",
      "offset": 318.32,
      "duration": 2.96
    },
    {
      "lang": "en",
      "text": "all been remediated already but are",
      "offset": 319.919,
      "duration": 2.881
    },
    {
      "lang": "en",
      "text": "represented in the wild and work in open",
      "offset": 321.28,
      "duration": 4.6
    },
    {
      "lang": "en",
      "text": "source by various developers across all",
      "offset": 322.8,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "levels. Our goal when assembling these",
      "offset": 325.88,
      "duration": 3.8
    },
    {
      "lang": "en",
      "text": "bugs was to provide a range of issue",
      "offset": 328,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "types from obvious low specific domain",
      "offset": 329.68,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "knowledge all the way to senior staff",
      "offset": 331.84,
      "duration": 3.199
    },
    {
      "lang": "en",
      "text": "level engineering knowledge with",
      "offset": 333.84,
      "duration": 2.96
    },
    {
      "lang": "en",
      "text": "significant depth of understanding for a",
      "offset": 335.039,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "given project. We also wanted to make",
      "offset": 336.8,
      "duration": 3.679
    },
    {
      "lang": "en",
      "text": "sure we provide a multi- language",
      "offset": 339.039,
      "duration": 3.201
    },
    {
      "lang": "en",
      "text": "benchmark as LMS have notably different",
      "offset": 340.479,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "performance across them. Here we focused",
      "offset": 342.24,
      "duration": 4.239
    },
    {
      "lang": "en",
      "text": "on Python, TypeScript, JavaScript, and",
      "offset": 344.479,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "Go first because Python and Typescript",
      "offset": 346.479,
      "duration": 4.241
    },
    {
      "lang": "en",
      "text": "JavaScript are languages that are the",
      "offset": 349.199,
      "duration": 3.361
    },
    {
      "lang": "en",
      "text": "most popular and LMS are supposedly",
      "offset": 350.72,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "better at performing on them. Then we",
      "offset": 352.56,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "chose Go as kind of a control to balance",
      "offset": 354.639,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "performance on a low-level systems",
      "offset": 356.8,
      "duration": 3.239
    },
    {
      "lang": "en",
      "text": "engineering",
      "offset": 358.24,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "language. So looking ahead, here's an",
      "offset": 360.039,
      "duration": 5.081
    },
    {
      "lang": "en",
      "text": "example of what we mean by an objective",
      "offset": 363.6,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "bug. Um, this is anything an explicit",
      "offset": 365.12,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "security issue or logical issue that",
      "offset": 367.28,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "could cause data loss or system crashes.",
      "offset": 369.039,
      "duration": 3.521
    },
    {
      "lang": "en",
      "text": "The reason we went for these types of",
      "offset": 371.36,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "bugs is it removes anything uh that is",
      "offset": 372.56,
      "duration": 4.639
    },
    {
      "lang": "en",
      "text": "ambiguous um or harmless in the context",
      "offset": 374.72,
      "duration": 5.199
    },
    {
      "lang": "en",
      "text": "of the system uh or performs correctly",
      "offset": 377.199,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "if you look one level up and the thing",
      "offset": 379.919,
      "duration": 3.521
    },
    {
      "lang": "en",
      "text": "that calls it kind of bounds the problem",
      "offset": 381.759,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "anyway. Um an example of this uh is a",
      "offset": 383.44,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "function that doesn't check bounds uh",
      "offset": 386.16,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "but the code is called uh but the code",
      "offset": 387.759,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "that it's called from ensures the input",
      "offset": 389.68,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "never goes over those bounds anyway. So",
      "offset": 391.68,
      "duration": 3.359
    },
    {
      "lang": "en",
      "text": "in isolation that's a bug but in the",
      "offset": 393.28,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "context of the system there's there's no",
      "offset": 395.039,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "failure point. Um, we explicitly did not",
      "offset": 396.88,
      "duration": 6.24
    },
    {
      "lang": "en",
      "text": "include feature requests, optimization,",
      "offset": 401.039,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "style formatting or design decisions.",
      "offset": 403.12,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "Uh, this is also to reduce ambiguity.",
      "offset": 405.12,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "Uh, frankly, humans still debate these",
      "offset": 407.84,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "to today. There's no actual objective",
      "offset": 409.44,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "kind of discourse around them. It's",
      "offset": 411.12,
      "duration": 4.639
    },
    {
      "lang": "en",
      "text": "whatever your like uh codra decides they",
      "offset": 412.56,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "want to use. It also helps make it",
      "offset": 415.759,
      "duration": 4.481
    },
    {
      "lang": "en",
      "text": "reproducible across evaluations. And as",
      "offset": 418.16,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "alluded to earlier, uh we annotated each",
      "offset": 420.24,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "bug with metadata such as the severity",
      "offset": 422.56,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "and context where it was defined and",
      "offset": 424.72,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "called. Uh how much system specific",
      "offset": 426.8,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "domain knowledge a human would require",
      "offset": 428.88,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "to find the bug. How difficult even with",
      "offset": 430.4,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "said knowledge it would be to find it.",
      "offset": 432.96,
      "duration": 2.72
    },
    {
      "lang": "en",
      "text": "So even if you're an expert in the",
      "offset": 434.4,
      "duration": 2.48
    },
    {
      "lang": "en",
      "text": "system, how long it would take you to",
      "offset": 435.68,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "navigate and get that bug and finally",
      "offset": 436.88,
      "duration": 3.599
    },
    {
      "lang": "en",
      "text": "the implication of the bug itself. Was",
      "offset": 438.96,
      "duration": 3.359
    },
    {
      "lang": "en",
      "text": "it a data loss? Was it a crash? Is it a",
      "offset": 440.479,
      "duration": 4.641
    },
    {
      "lang": "en",
      "text": "security exploit? Etc.",
      "offset": 442.319,
      "duration": 4.561
    },
    {
      "lang": "en",
      "text": "These classifications allow us to",
      "offset": 445.12,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "understand what level of bugs these AI",
      "offset": 446.88,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "agents are capable of finding regularly.",
      "offset": 449.28,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "We note that every once in a while they",
      "offset": 452,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "surprise us such in that recent blog",
      "offset": 453.68,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "post where 03 was able to find um a zero",
      "offset": 455.12,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "day exploit. Uh but notably there it",
      "offset": 457.28,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "took about a 100 runs to actually get it",
      "offset": 459.199,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "over the same context each time. Um so",
      "offset": 460.88,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "while that's still useful to know",
      "offset": 463.599,
      "duration": 2.641
    },
    {
      "lang": "en",
      "text": "they're possible, it's more useful to",
      "offset": 464.72,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "know in everyday usage how are they",
      "offset": 466.24,
      "duration": 5.359
    },
    {
      "lang": "en",
      "text": "capable um on just everyday tasks.",
      "offset": 468.08,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "So for each system that we benchmarked,",
      "offset": 471.599,
      "duration": 3.761
    },
    {
      "lang": "en",
      "text": "there's four numbers to get out of the",
      "offset": 473.68,
      "duration": 3.519
    },
    {
      "lang": "en",
      "text": "benchmark. The first is just can the",
      "offset": 475.36,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "system discover the bugs without any",
      "offset": 477.199,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "prior knowledge. Uh we call this the",
      "offset": 479.52,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "needle in the haystack result. And we'll",
      "offset": 481.52,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "talk a bit more about the specifics of",
      "offset": 483.28,
      "duration": 3.039
    },
    {
      "lang": "en",
      "text": "our methodology for this in just a",
      "offset": 484.8,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "second. Um of course though, when the",
      "offset": 486.319,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "agents produce a list of bugs, there's a",
      "offset": 488.4,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "lot more than just the one that we're",
      "offset": 490.479,
      "duration": 4.641
    },
    {
      "lang": "en",
      "text": "looking for. So we also manually measure",
      "offset": 492.16,
      "duration": 5.439
    },
    {
      "lang": "en",
      "text": "the false positive rate of the bugs that",
      "offset": 495.12,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "come out to get an overall sense of how",
      "offset": 497.599,
      "duration": 6.561
    },
    {
      "lang": "en",
      "text": "effective it is broadly. Um we also look",
      "offset": 499.68,
      "duration": 7.68
    },
    {
      "lang": "en",
      "text": "at whether the system can find the bug",
      "offset": 504.16,
      "duration": 6.319
    },
    {
      "lang": "en",
      "text": "at the time of introduction. So given",
      "offset": 507.36,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "the pull request or commit that",
      "offset": 510.479,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "introduces the bug, can the agent point",
      "offset": 512.24,
      "duration": 5.039
    },
    {
      "lang": "en",
      "text": "it out at that point? Um, of course here",
      "offset": 514.479,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "the agent doesn't have to go searching",
      "offset": 517.279,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "to find issues and has a lot more kind",
      "offset": 518.959,
      "duration": 5.041
    },
    {
      "lang": "en",
      "text": "of immediate context around it. So with",
      "offset": 521.039,
      "duration": 4.721
    },
    {
      "lang": "en",
      "text": "a bit more of an optimistic starting",
      "offset": 524,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "point, how good can they be? Um, and",
      "offset": 525.76,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "finally, we still do want to see how the",
      "offset": 528.64,
      "duration": 4.879
    },
    {
      "lang": "en",
      "text": "agents uh do with suggesting",
      "offset": 531.44,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "remediations for the things that it",
      "offset": 533.519,
      "duration": 4.721
    },
    {
      "lang": "en",
      "text": "identifies. Uh and so for each bug that",
      "offset": 535.76,
      "duration": 5.519
    },
    {
      "lang": "en",
      "text": "it discovers, we ask it to fix the bug",
      "offset": 538.24,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "uh and see if the result does indeed fix",
      "offset": 541.279,
      "duration": 4.481
    },
    {
      "lang": "en",
      "text": "the bug without breaking the rest of the",
      "offset": 544,
      "duration": 5.279
    },
    {
      "lang": "en",
      "text": "codebase. Oh yeah, by far. So jumping",
      "offset": 545.76,
      "duration": 6.079
    },
    {
      "lang": "en",
      "text": "back uh to needle in the haststack now",
      "offset": 549.279,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "we don't want to just tell agents you",
      "offset": 551.839,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "know go find bugs somewhere in the",
      "offset": 553.36,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "repository because frankly most of the",
      "offset": 555.68,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "things that we're measuring are big",
      "offset": 557.92,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "enough we're exploring all of the code",
      "offset": 559.68,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "to find the single bug that we're",
      "offset": 562.16,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "interested in would take way too long.",
      "offset": 564.08,
      "duration": 5.759
    },
    {
      "lang": "en",
      "text": "Uh and we also don't though want to hint",
      "offset": 567.2,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "at what the actual bug is in the",
      "offset": 569.839,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "evaluation. We don't want to bias them",
      "offset": 571.92,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "in any way. So how do we solve this? uh",
      "offset": 573.519,
      "duration": 5.121
    },
    {
      "lang": "en",
      "text": "well we've broken up the repositories",
      "offset": 576.56,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "into subsystems containing files that",
      "offset": 578.64,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "are likely all interrelated. So think",
      "offset": 581.12,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "you know maybe part of a front end or",
      "offset": 583.2,
      "duration": 6.319
    },
    {
      "lang": "en",
      "text": "some specific uh API uh point. We then",
      "offset": 585.12,
      "duration": 7.12
    },
    {
      "lang": "en",
      "text": "feed the list of files in that subsystem",
      "offset": 589.519,
      "duration": 4.561
    },
    {
      "lang": "en",
      "text": "uh or sorry we then filter the",
      "offset": 592.24,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "subsystems that were that contain the",
      "offset": 594.08,
      "duration": 5.439
    },
    {
      "lang": "en",
      "text": "files that were modified kind of in the",
      "offset": 597.6,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "golden PR commit and just feed the files",
      "offset": 599.519,
      "duration": 7.921
    },
    {
      "lang": "en",
      "text": "in those subsystems to the LLM. So it's",
      "offset": 603.36,
      "duration": 8
    },
    {
      "lang": "en",
      "text": "getting a reduced list of files in the",
      "offset": 607.44,
      "duration": 4.92
    },
    {
      "lang": "en",
      "text": "entire",
      "offset": 611.36,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "repository. This way we're not biasing",
      "offset": 612.36,
      "duration": 4.76
    },
    {
      "lang": "en",
      "text": "it in any way, but we're still scoping",
      "offset": 615.36,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "it down so it doesn't have to look",
      "offset": 617.12,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "through everything. Uh, and we can still",
      "offset": 619.279,
      "duration": 4.961
    },
    {
      "lang": "en",
      "text": "get an idea of what this works or how",
      "offset": 621.92,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "well this works in like a nonbenchmark",
      "offset": 624.24,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "capacity. It's just looking at one part",
      "offset": 626.56,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "of the code, but that in its entirety.",
      "offset": 628.24,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "Okay. So, what does it take to actually",
      "offset": 630.959,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "get a system up to a level of beating",
      "offset": 632.64,
      "duration": 2.8
    },
    {
      "lang": "en",
      "text": "some of the biggest companies and labs",
      "offset": 634.079,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "in the world? So, basic implementations",
      "offset": 635.44,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "are trivial. Give it a shell tool, sir,",
      "offset": 638.079,
      "duration": 4.641
    },
    {
      "lang": "en",
      "text": "replace, think, report bug, you know, a",
      "offset": 640.24,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "finish tool, put it in a loop, and press",
      "offset": 642.72,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "play. So, you do have an agent here.",
      "offset": 644.399,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "It's running. It's looking at code",
      "offset": 646.48,
      "duration": 3.039
    },
    {
      "lang": "en",
      "text": "files. Um, and you might even find some",
      "offset": 647.839,
      "duration": 3.361
    },
    {
      "lang": "en",
      "text": "bugs. We actually found five or six in",
      "offset": 649.519,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "the basic loop here. Uh, but they also",
      "offset": 651.2,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "had a 97% false positive rate. So,",
      "offset": 653.279,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "almost every basic agent that just",
      "offset": 655.68,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "equipped with these tools from like the",
      "offset": 657.279,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "anthropic model card releases or open AI",
      "offset": 659.04,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "methodology releases, um, are not up to",
      "offset": 661.12,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "the task of really finding bugs and",
      "offset": 663.44,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "triaging systems.",
      "offset": 665.2,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "So, it's actually really hard to build a",
      "offset": 667.2,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "good agent for identifying bugs and",
      "offset": 670.64,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "working on code. It's a combination of",
      "offset": 672.24,
      "duration": 5.279
    },
    {
      "lang": "en",
      "text": "model, system, prompting, information,",
      "offset": 674.48,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "the way you feed that information to a",
      "offset": 677.519,
      "duration": 3.241
    },
    {
      "lang": "en",
      "text": "model, and navigation",
      "offset": 679.12,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "strategy. Um, if you look at our numbers",
      "offset": 680.76,
      "duration": 5
    },
    {
      "lang": "en",
      "text": "for performance comparisons, you can see",
      "offset": 683.76,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "right off the bat that Bismouth leads",
      "offset": 685.76,
      "duration": 3.759
    },
    {
      "lang": "en",
      "text": "the pack for needle in a haststack. Um,",
      "offset": 687.76,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "we found 10 of our needles. Uh, the next",
      "offset": 689.519,
      "duration": 5.681
    },
    {
      "lang": "en",
      "text": "leading solution finding seven. So we do",
      "offset": 692.72,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "note off the bat there's a lot of room",
      "offset": 695.2,
      "duration": 2.8
    },
    {
      "lang": "en",
      "text": "to grow here but if anything we're",
      "offset": 696.72,
      "duration": 2.72
    },
    {
      "lang": "en",
      "text": "excited that we found an unsaturated",
      "offset": 698,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "benchmark to work on uh as we build our",
      "offset": 699.44,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "product and as other labs build theirs.",
      "offset": 702.16,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "I will say we are starting to see some",
      "offset": 704.16,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "exciting things on true positive rate",
      "offset": 706,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "and detection though uh with claude code",
      "offset": 708.16,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "starting out at 16% us at 25% in second",
      "offset": 710.16,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "place and codeex at 45%. You'll also",
      "offset": 712.88,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "note that for these three solutions I",
      "offset": 715.6,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "just mentioned we find significantly",
      "offset": 717.2,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "less like random nonsense compared to",
      "offset": 719.2,
      "duration": 5.199
    },
    {
      "lang": "en",
      "text": "the rest of the pack. like we just have",
      "offset": 723.2,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "a tighter scoping. Uh Devon, cursor",
      "offset": 724.399,
      "duration": 5.761
    },
    {
      "lang": "en",
      "text": "agent uh and cosign all found between",
      "offset": 727.44,
      "duration": 6.079
    },
    {
      "lang": "en",
      "text": "900 and 1,200 items or 1300 items for",
      "offset": 730.16,
      "duration": 7.04
    },
    {
      "lang": "en",
      "text": "cursor uh with between a 3 and 10% true",
      "offset": 733.519,
      "duration": 6.56
    },
    {
      "lang": "en",
      "text": "positive rate. So there's a lot of um",
      "offset": 737.2,
      "duration": 6.24
    },
    {
      "lang": "en",
      "text": "headway for those agents to go on PR",
      "offset": 740.079,
      "duration": 5.921
    },
    {
      "lang": "en",
      "text": "review. Uh codeex was quite strong uh",
      "offset": 743.44,
      "duration": 4.959
    },
    {
      "lang": "en",
      "text": "with 20 uh 27% of the needle in",
      "offset": 746,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "haststack found then devon at 21 and",
      "offset": 748.399,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "then us at 17. So, one thing to note",
      "offset": 750.72,
      "duration": 5.84
    },
    {
      "lang": "en",
      "text": "there is that those do not include any",
      "offset": 754.399,
      "duration": 4.801
    },
    {
      "lang": "en",
      "text": "false positives that had been found uh",
      "offset": 756.56,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "during those PR reviews. This is just",
      "offset": 759.2,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "did it find the needle in the haystack.",
      "offset": 761.2,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "And even there, you'll note that the",
      "offset": 763.12,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "best model only got 27. So about a",
      "offset": 764.8,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "third, uh there's a long way to go on",
      "offset": 767.12,
      "duration": 5.519
    },
    {
      "lang": "en",
      "text": "both PR review and bug detection.",
      "offset": 768.959,
      "duration": 7.201
    },
    {
      "lang": "en",
      "text": "I want to note that given the models",
      "offset": 772.639,
      "duration": 6.961
    },
    {
      "lang": "en",
      "text": "here uh bismouth itself is agnostic uh",
      "offset": 776.16,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "but we typically run on top of anthro",
      "offset": 779.6,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "anthropic models and they've been easier",
      "offset": 781.76,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "to serve for our customers from vertex",
      "offset": 783.68,
      "duration": 4.719
    },
    {
      "lang": "en",
      "text": "uh in this instance our solution was",
      "offset": 786.16,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "able to beat uh their own solution cloud",
      "offset": 788.399,
      "duration": 5.921
    },
    {
      "lang": "en",
      "text": "code in multiple categories uh while",
      "offset": 791.36,
      "duration": 4.599
    },
    {
      "lang": "en",
      "text": "improving on their base",
      "offset": 794.32,
      "duration": 5.199
    },
    {
      "lang": "en",
      "text": "model. So let's move on to looking at",
      "offset": 795.959,
      "duration": 5.56
    },
    {
      "lang": "en",
      "text": "what we call basic agents. Uh these are",
      "offset": 799.519,
      "duration": 3.201
    },
    {
      "lang": "en",
      "text": "agents that are the simple loop we",
      "offset": 801.519,
      "duration": 3.361
    },
    {
      "lang": "en",
      "text": "described earlier. And we were able to",
      "offset": 802.72,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "actually look at a couple open source",
      "offset": 804.88,
      "duration": 3.759
    },
    {
      "lang": "en",
      "text": "models here as well. And we'll note just",
      "offset": 806.32,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "off the bat um open source has a long",
      "offset": 808.639,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "way to come in this space. Um R1 only",
      "offset": 810.72,
      "duration": 5.359
    },
    {
      "lang": "en",
      "text": "had a 1% true positive rate uh over what",
      "offset": 813.04,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "like hundreds uh yeah yeah over hundreds",
      "offset": 816.079,
      "duration": 5.041
    },
    {
      "lang": "en",
      "text": "of bugs. Um same with Lava Maverick at a",
      "offset": 818.56,
      "duration": 5.839
    },
    {
      "lang": "en",
      "text": "2%. Um R1 did manage to find um a needle",
      "offset": 821.12,
      "duration": 5.839
    },
    {
      "lang": "en",
      "text": "in a hay stack. Um but both of these",
      "offset": 824.399,
      "duration": 5.601
    },
    {
      "lang": "en",
      "text": "were lapped by sonnet 4 and 03 in a loop",
      "offset": 826.959,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "um where sonnet 4 found six uh and 03",
      "offset": 830,
      "duration": 6.8
    },
    {
      "lang": "en",
      "text": "found two with a 3% and 6% uh false uh",
      "offset": 832.959,
      "duration": 6.24
    },
    {
      "lang": "en",
      "text": "true positive rate respectively. The",
      "offset": 836.8,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "hard truth here is that the highest",
      "offset": 839.199,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "popular agent score outside of us who",
      "offset": 841.6,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "are just launching now uh scored 7% on",
      "offset": 843.519,
      "duration": 5.841
    },
    {
      "lang": "en",
      "text": "SM 100. Um that means the most used",
      "offset": 846.48,
      "duration": 5.359
    },
    {
      "lang": "en",
      "text": "agents in the world are the worst at",
      "offset": 849.36,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "finding and fixing complex bugs. Uh this",
      "offset": 851.839,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "is a problem for the industry that we're",
      "offset": 854.56,
      "duration": 2.719
    },
    {
      "lang": "en",
      "text": "hoping to bring to light and we're",
      "offset": 856.079,
      "duration": 2.56
    },
    {
      "lang": "en",
      "text": "hoping to see that these teams will",
      "offset": 857.279,
      "duration": 3.041
    },
    {
      "lang": "en",
      "text": "begin to work on this to increase their",
      "offset": 858.639,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "score in what represents the back 90% of",
      "offset": 860.32,
      "duration": 4.759
    },
    {
      "lang": "en",
      "text": "work for software",
      "offset": 863.199,
      "duration": 4.241
    },
    {
      "lang": "en",
      "text": "engineering. It's also important to note",
      "offset": 865.079,
      "duration": 5.161
    },
    {
      "lang": "en",
      "text": "that three out of six agents got 10% or",
      "offset": 867.44,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "less true positives out of a massive",
      "offset": 870.24,
      "duration": 6.159
    },
    {
      "lang": "en",
      "text": "number of reports. Uh on one issue, an",
      "offset": 872.8,
      "duration": 6.96
    },
    {
      "lang": "en",
      "text": "agent gave us an astounding 70 reports",
      "offset": 876.399,
      "duration": 5.281
    },
    {
      "lang": "en",
      "text": "and nobody's going to actually sift",
      "offset": 879.76,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "through that many, right? Like no",
      "offset": 881.68,
      "duration": 3.279
    },
    {
      "lang": "en",
      "text": "engineer is going to look through 70",
      "offset": 883.6,
      "duration": 2.88
    },
    {
      "lang": "en",
      "text": "bugs and be like, &quot;Oh yeah, that one for",
      "offset": 884.959,
      "duration": 3.361
    },
    {
      "lang": "en",
      "text": "sure is the right one.&quot; So there's a",
      "offset": 886.48,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "long way to go on tightening how much",
      "offset": 888.32,
      "duration": 3.759
    },
    {
      "lang": "en",
      "text": "information these agents are reporting",
      "offset": 890.32,
      "duration": 5.639
    },
    {
      "lang": "en",
      "text": "and the accuracy of that information",
      "offset": 892.079,
      "duration": 7.481
    },
    {
      "lang": "en",
      "text": "itself. I think that you know in",
      "offset": 895.959,
      "duration": 7.24
    },
    {
      "lang": "en",
      "text": "context that even some simple bugs are",
      "offset": 899.56,
      "duration": 6.6
    },
    {
      "lang": "en",
      "text": "missed. um only two agents bismouth and",
      "offset": 903.199,
      "duration": 5.601
    },
    {
      "lang": "en",
      "text": "codeex found this state issue and the",
      "offset": 906.16,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "consequence of the state issue is pretty",
      "offset": 908.8,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "simple right when you submit a form um",
      "offset": 910.24,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "usually they clear in this particular",
      "offset": 912.32,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "case uh is dirty was never set to false",
      "offset": 913.92,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "uh so it would never clear the form and",
      "offset": 917.36,
      "duration": 2.88
    },
    {
      "lang": "en",
      "text": "it would say you still had things filled",
      "offset": 918.8,
      "duration": 3.599
    },
    {
      "lang": "en",
      "text": "out you know that's not the biggest bug",
      "offset": 920.24,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "in the world but that has real",
      "offset": 922.399,
      "duration": 2.481
    },
    {
      "lang": "en",
      "text": "consequences for users and user",
      "offset": 923.36,
      "duration": 2.96
    },
    {
      "lang": "en",
      "text": "experience and that's the type of things",
      "offset": 924.88,
      "duration": 3.319
    },
    {
      "lang": "en",
      "text": "a human developer would immediately",
      "offset": 926.32,
      "duration": 4.879
    },
    {
      "lang": "en",
      "text": "catch so we think there is a large way",
      "offset": 928.199,
      "duration": 5.481
    },
    {
      "lang": "en",
      "text": "to go",
      "offset": 931.199,
      "duration": 5.121
    },
    {
      "lang": "en",
      "text": "So after examining uh all of the",
      "offset": 933.68,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "performance across all these different",
      "offset": 936.32,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "agents, there was a notable commonality",
      "offset": 938,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "between them. These agents are very",
      "offset": 940.16,
      "duration": 3.679
    },
    {
      "lang": "en",
      "text": "narrow in their thinking. Even when",
      "offset": 942.48,
      "duration": 2.64
    },
    {
      "lang": "en",
      "text": "using thinking models, this is actually",
      "offset": 943.839,
      "duration": 2.641
    },
    {
      "lang": "en",
      "text": "a problem. It's more of a problem on",
      "offset": 945.12,
      "duration": 2.88
    },
    {
      "lang": "en",
      "text": "non-thinking models, but thinking models",
      "offset": 946.48,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "themselves are very narrow in the types",
      "offset": 948,
      "duration": 3.759
    },
    {
      "lang": "en",
      "text": "of things they're evaluating. And we",
      "offset": 949.92,
      "duration": 3.599
    },
    {
      "lang": "en",
      "text": "find that even with that narrowness,",
      "offset": 951.759,
      "duration": 4.681
    },
    {
      "lang": "en",
      "text": "they don't go deep enough. So from our",
      "offset": 953.519,
      "duration": 6.24
    },
    {
      "lang": "en",
      "text": "perspective, broader thinking chains and",
      "offset": 956.44,
      "duration": 6.199
    },
    {
      "lang": "en",
      "text": "deeper thinking along selected chains is",
      "offset": 959.759,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "going to be required to actually find",
      "offset": 962.639,
      "duration": 5.521
    },
    {
      "lang": "en",
      "text": "bugs in these files. It's also",
      "offset": 965.759,
      "duration": 4.961
    },
    {
      "lang": "en",
      "text": "interesting to note that on a perr run",
      "offset": 968.16,
      "duration": 5.359
    },
    {
      "lang": "en",
      "text": "basis, the total number of bugs remains",
      "offset": 970.72,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "roughly consistent, but the bugs",
      "offset": 973.519,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "themselves change. So that means from",
      "offset": 975.68,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "any one particular run an LLM is not",
      "offset": 977.92,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "looking holistically at a file and",
      "offset": 980.56,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "inventorying everything that's",
      "offset": 982.8,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "happening. Um we suspect there's",
      "offset": 984.48,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "different biases occurring uh in that",
      "offset": 986.56,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "and that the models themselves you know",
      "offset": 988.8,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "through whatever context have been",
      "offset": 990.88,
      "duration": 3.199
    },
    {
      "lang": "en",
      "text": "provided are looking at a file one way",
      "offset": 992.24,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "and not another way. Um there's",
      "offset": 994.079,
      "duration": 3.521
    },
    {
      "lang": "en",
      "text": "methodologies we thought of to solve",
      "offset": 996.16,
      "duration": 3.039
    },
    {
      "lang": "en",
      "text": "that but right now it seems like that is",
      "offset": 997.6,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "a pervasive problem across every agent",
      "offset": 999.199,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "in the industry and no one has quite",
      "offset": 1001.04,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "solved that. So there's a broader",
      "offset": 1002.88,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "problem here, right? Despite 60 to 70%",
      "offset": 1005.6,
      "duration": 4.799
    },
    {
      "lang": "en",
      "text": "80% in some cases scores on Sweet",
      "offset": 1008.48,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "Edenge, agents still struggle with SM",
      "offset": 1010.399,
      "duration": 5.041
    },
    {
      "lang": "en",
      "text": "100. What does that mean? Existing",
      "offset": 1012.88,
      "duration": 4.639
    },
    {
      "lang": "en",
      "text": "agents are able to create software",
      "offset": 1015.44,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "upfront, but to manage and fix software",
      "offset": 1017.519,
      "duration": 5.281
    },
    {
      "lang": "en",
      "text": "after it's been deployed will be a major",
      "offset": 1020.32,
      "duration": 4.639
    },
    {
      "lang": "en",
      "text": "struggle as far as we see it. And this",
      "offset": 1022.8,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "is a hard problem that teams are working",
      "offset": 1024.959,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "on across the board, us included. But it",
      "offset": 1027.36,
      "duration": 5.719
    },
    {
      "lang": "en",
      "text": "demands targeted search, better program",
      "offset": 1029.839,
      "duration": 5.921
    },
    {
      "lang": "en",
      "text": "comprehension, crossfile reasoning, bug",
      "offset": 1033.079,
      "duration": 4.76
    },
    {
      "lang": "en",
      "text": "pattern recognition that we just don't",
      "offset": 1035.76,
      "duration": 4.679
    },
    {
      "lang": "en",
      "text": "see in deep capacity from many of these",
      "offset": 1037.839,
      "duration": 5.441
    },
    {
      "lang": "en",
      "text": "solutions. Now, we're hopeful here",
      "offset": 1040.439,
      "duration": 5.88
    },
    {
      "lang": "en",
      "text": "because codecs, for instance, and us are",
      "offset": 1043.28,
      "duration": 5.519
    },
    {
      "lang": "en",
      "text": "starting to show tighter narrow tighter,",
      "offset": 1046.319,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "more narrow bands of the bugs that it's",
      "offset": 1048.799,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "solving. We do get some complex issues.",
      "offset": 1050.64,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "We are one of the two agents that found",
      "offset": 1053.12,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "that bug I mentioned earlier. So, as we",
      "offset": 1055.12,
      "duration": 4.559
    },
    {
      "lang": "en",
      "text": "progress here, we hope the industry",
      "offset": 1058.16,
      "duration": 3.879
    },
    {
      "lang": "en",
      "text": "evolves and focuses more on this",
      "offset": 1059.679,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "problem. So, to wrap things up, we know",
      "offset": 1062.039,
      "duration": 4.121
    },
    {
      "lang": "en",
      "text": "that the most frequently used agents",
      "offset": 1064.559,
      "duration": 3.441
    },
    {
      "lang": "en",
      "text": "today have a high risk of introducing",
      "offset": 1066.16,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "bugs. Though, as we just said, a few of",
      "offset": 1068,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "the newer agents as part of this new",
      "offset": 1070.32,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "generation, including us, are starting",
      "offset": 1072,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "to show an increased ability to reason",
      "offset": 1074.4,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "through code and more effectively use",
      "offset": 1076.48,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "their context to evaluate concerns.",
      "offset": 1078.72,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "Stability is nent, but so far what we've",
      "offset": 1081.44,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "seen has been encouraging. Uh and with",
      "offset": 1083.84,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "this benchmark, we can now clearly show",
      "offset": 1085.76,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "as things progress. Um with effort and",
      "offset": 1088,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "some different techniques, you can do",
      "offset": 1091.52,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "better and improvements here will have",
      "offset": 1093.52,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "benefits across the entire industry. We",
      "offset": 1095.36,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "have many things that we want to try and",
      "offset": 1098.64,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "I'm sure other labs do. Uh and we're",
      "offset": 1100.64,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "really excited to be on the forefront of",
      "offset": 1102.88,
      "duration": 4.76
    },
    {
      "lang": "en",
      "text": "this new generation of",
      "offset": 1104.799,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "agents. So, thanks for watching. Uh you",
      "offset": 1107.64,
      "duration": 3.64
    },
    {
      "lang": "en",
      "text": "can dive into numbers and get more",
      "offset": 1109.919,
      "duration": 3.201
    },
    {
      "lang": "en",
      "text": "details on the benchmark uh at the",
      "offset": 1111.28,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "website. Uh, and be sure to check us out",
      "offset": 1113.12,
      "duration": 2.76
    },
    {
      "lang": "en",
      "text": "at",
      "offset": 1114.96,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "bismouth.sh. Thank you. Thanks.",
      "offset": 1115.88,
      "duration": 4.12
    }
  ],
  "cleanText": "Agents for software engineering have been exploding in popularity over the last year, and we wanted to find out just how good they are at finding and fixing bugs. Can you even rely on them for maintenance? Well, that's what we're going to tell you here today at a engineers world fair.\n\nUh, hey guys, we're Bismuth, and we've been working on software agents for the last year in some change. My name is Ian, and I'm the CEO of Bismuth. So, my background was in data engineering, machine learning, and search. Previously, I was at Zillow as a senior edge on the AB testing platform. Uh, and this is my second time working deeply on dev tooling at a startup. Um, I started with technical documentation search in 2019 along with Nick here, building an index of hundreds of millions of technical documents for inline IDE use along with AI summarization for internal knowledge bases.\n\nHey, so I'm Nick, CTO of Bismuth. Um, I was primarily in the software security space before starting Bismuth with Ian. Um, I was at Google just prior on an internal tools team building endpoint security software, and before that I was a research scientist focused on detecting software exploitation. Um, there's a lot of tools and techniques from that space that transfer to building intelligent agentic code tools.\n\nIt turns out, before we get started, just want to shout out base 10 for helping provide credits and compute for running our benchmark across both DeepSec R1 and Llama for Maverick. Thanks guys. We really appreciate it. Thank you.\n\nSo, to dive right in, we wanted to share with you all the benchmark we've been building for a few months now to explore just how good software agents are at coding tasks outside of the normal feature development. There's a handful of benchmarks already to measure how effective LLMs are for writing code: Human evaluator's polyglot benchmark, uh, and live codebench, just to name a few. But of course, that's only one part of the software development life cycle and what developers do. So what about the rest of the SDLC?\n\nWell, uh, initial scoping and planning is kind of an entirely different task, right? It requires broader business context, knowledge of existing systems and designs, exploring potential existing solutions, and so on. Um, it's basically a completely different task from development. Um, next we have the feature dev and testing, which are already pretty well covered by the existing benchmarks. Um, and then there's the code review process, which is pretty much unbenchmarked by existing work, even though we're seeing more and more LLM-based tools in the space. Uh, and this is actually the first part of our benchmark. Deployment is a pretty separate task, requiring not just writing configuration but also setting up monitoring, integrating with other existing systems, etc. It's also pretty distinct.\n\nUm, last and, and not least, though, we have software maintenance tasks. So think things like bug fixes, dependency upgrades, migrations, etc. Um, this is another part of the SLC that, at its core, is still generally writing code but is in a distinctly different way than feature development. So the ability to reason through a codebase deeply, defined bugs is directly transferable to being able to produce features. You can think about how, like, when you're dividing a feature, you're going to learn the architecture of the codebase. You're going to learn, you know, how everything connects, the data flow, and stuff like that. So that's the same for finding bugs. In both cases, you need an understanding of the system architecture and its connectedness. Um, in the case of finding bugs, you even often need to understand the system more deeply than when you originally wrote the feature in the first place. Um, to that end, maintenance requires the ability to first deeply reason through a system and identify if bugs are potentially present.\n\nWe found agents struggle with holistic evaluation of files and systems, only finding subsets of bugs per run. Thinking models alleviate this somewhat, but reasoning appears to be somewhat narrow, only exploring a limited number of potential avenues at a single time. This is translated directly to LLM's missing bugs that human developers would pick up almost immediately and confirming bugs that human developers would discard almost immediately. While there is value here, the ability is clearly still in its infancy. When it comes to patching of these bugs, because of the relative simplicity that we have seen from them, they usually get it, uh, without much of an effort. But again, because the bugs themselves are not particularly complex, this isn't really saying much.\n\nYeah. So there are some existing bug detection benchmarks from the software security space, but there's some big limitations that don't really make them suitable for evaluating these new agentic AI systems since they were built to benchmark kind of classic static analysis or program repair tools. Uh, they focus on relatively simplistic bugs in common patterns, things like null pointer dereferences, buffer overflows, maybe SQL injection in a web app, which could all be found statically. Um, a lot of the benchmarks are also really limited in the languages that they pull from. So many of them are only Java, for instance, because that's where the vast majority of enterprise complicated software was, and honestly, still is, written. Um, there's also a bias towards security issues in the existing benchmarks, partly as a result of that being where the classic static analysis tools are focused. Um, but bugs appear in many more ways than just security defects, right? Copy-paste bugs are a really simple example where they don't often result in an off bypass, for example, but it breaks the software to end users all the same, right?\n\nSo, how does our benchmark SM-100 compare? So, we painstakingly gathered 100 bugs that we triaged, validated, and classified in over 84 public repositories. These are bugs that have all been remediated already but are represented in the wild and work in open source by various developers across all levels. Our goal when assembling these bugs was to provide a range of issue types from obvious low specific domain knowledge all the way to senior staff level engineering knowledge with significant depth of understanding for a given project. We also wanted to make sure we provide a multi-language benchmark as LLMs have notably different performance across them. Here we focused on Python, TypeScript, JavaScript, and Go first because Python and Typescript JavaScript are languages that are the most popular and LLMs are supposedly better at performing on them. Then we chose Go as kind of a control to balance performance on a low-level systems engineering language.\n\nSo looking ahead, here's an example of what we mean by an objective bug. Um, this is anything an explicit security issue or logical issue that could cause data loss or system crashes. The reason we went for these types of bugs is it removes anything, uh, that is ambiguous, um, or harmless in the context of the system, uh, or performs correctly if you look one level up and the thing that calls it kind of bounds the problem anyway. Um, an example of this, uh, is a function that doesn't check bounds, uh, but the code is called, uh, but the code that it's called from ensures the input never goes over those bounds anyway. So in isolation, that's a bug, but in the context of the system, there's, there's no failure point. Um, we explicitly did not include feature requests, optimization, style formatting, or design decisions. Uh, this is also to reduce ambiguity. Uh, frankly, humans still debate these to today. There's no actual objective kind of discourse around them. It's whatever your like, uh, codra decides they want to use. It also helps make it reproducible across evaluations. And as alluded to earlier, uh, we annotated each bug with metadata such as the severity and context where it was defined and called. Uh, how much system-specific domain knowledge a human would require to find the bug. How difficult, even with said knowledge, it would be to find it. So even if you're an expert in the system, how long it would take you to navigate and get that bug and finally the implication of the bug itself. Was it a data loss? Was it a crash? Is it a security exploit? Etc.\n\nThese classifications allow us to understand what level of bugs these AI agents are capable of finding regularly. We note that every once in a while they surprise us, such in that recent blog post where 03 was able to find, um, a zero-day exploit. Uh, but notably there, it took about a 100 runs to actually get it over the same context each time. Um, so while that's still useful to know they're possible, it's more useful to know in everyday usage how are they capable, um, on just everyday tasks.\n\nSo for each system that we benchmarked, there's four numbers to get out of the benchmark. The first is just, can the system discover the bugs without any prior knowledge? Uh, we call this the needle in the haystack result. And we'll talk a bit more about the specifics of our methodology for this in just a second. Um, of course, though, when the agents produce a list of bugs, there's a lot more than just the one that we're looking for. So we also manually measure the false positive rate of the bugs that come out to get an overall sense of how effective it is broadly. Um, we also look at whether the system can find the bug at the time of introduction. So given the pull request or commit that introduces the bug, can the agent point it out at that point? Um, of course, here the agent doesn't have to go searching to find issues and has a lot more kind of immediate context around it. So with a bit more of an optimistic starting point, how good can they be? Um, and finally, we still do want to see how the agents, uh, do with suggesting remediations for the things that it identifies. Uh, and so for each bug that it discovers, we ask it to fix the bug, uh, and see if the result does indeed fix the bug without breaking the rest of the codebase.\n\nOh yeah, by far. So jumping back, uh, to needle in the haystack now, we don't want to just tell agents, you know, go find bugs somewhere in the repository because, frankly, most of the things that we're measuring are big enough, we're exploring all of the code to find the single bug that we're interested in would take way too long. Uh, and we also don't, though, want to hint at what the actual bug is in the evaluation. We don't want to bias them in any way. So how do we solve this? Uh, well, we've broken up the repositories into subsystems containing files that are likely all interrelated. So think, you know, maybe part of a front end or some specific, uh, API, uh, point. We then feed the list of files in that subsystem, uh, or sorry, we then filter the subsystems that were that contain the files that were modified kind of in the golden PR commit and just feed the files in those subsystems to the LLM. So it's getting a reduced list of files in the entire repository. This way we're not biasing it in any way, but we're still scoping it down so it doesn't have to look through everything. Uh, and we can still get an idea of what this works or how well this works in like a non-benchmark capacity. It's just looking at one part of the code, but that in its entirety.\n\nOkay. So, what does it take to actually get a system up to a level of beating some of the biggest companies and labs in the world? So, basic implementations are trivial. Give it a shell tool, sir, replace, think, report bug, you know, a finish tool, put it in a loop, and press play. So, you do have an agent here. It's running. It's looking at code files. Um, and you might even find some bugs. We actually found five or six in the basic loop here. Uh, but they also had a 97% false positive rate. So, almost every basic agent that just equipped with these tools from like the anthropic model card releases or open AI methodology releases, um, are not up to the task of really finding bugs and triaging systems.\n\nSo, it's actually really hard to build a good agent for identifying bugs and working on code. It's a combination of model, system, prompting, information, the way you feed that information to a model, and navigation strategy. Um, if you look at our numbers for performance comparisons, you can see right off the bat that Bismuth leads the pack for needle in a haystack. Um, we found 10 of our needles. Uh, the next leading solution finding seven. So we do note off the bat there's a lot of room to grow here, but if anything, we're excited that we found an unsaturated benchmark to work on, uh, as we build our product and as other labs build theirs.\n\nI will say we are starting to see some exciting things on true positive rate and detection, though, uh, with Claude Code starting out at 16%, us at 25% in second place, and CodeEx at 45%. You'll also note that for these three solutions I just mentioned, we find significantly less like random nonsense compared to the rest of the pack. Like we just have a tighter scoping. Uh, Devon, cursor agent, uh, and cosign all found between 900 and 1,200 items or 1,300 items for cursor, uh, with between a 3 and 10% true positive rate. So there's a lot of, um, headway for those agents to go on PR review. Uh, CodeEx was quite strong, uh, with 20, uh, 27% of the needle in haystack found, then Devon at 21, and then us at 17. So, one thing to note there is that those do not include any false positives that had been found, uh, during those PR reviews. This is just, did it find the needle in the haystack. And even there, you'll note that the best model only got 27. So about a third, uh, there's a long way to go on both PR review and bug detection.\n\nI want to note that, given the models here, Bismuth itself is agnostic, uh, but we typically run on top of anthropic models, and they've been easier to serve for our customers from vertex. Uh, in this instance, our solution was able to beat, uh, their own solution, Claude Code, in multiple categories, uh, while improving on their base model.\n\nSo let's move on to looking at what we call basic agents. Uh, these are agents that are the simple loop we described earlier. And we were able to actually look at a couple open source models here as well. And we'll note just off the bat, um, open source has a long way to come in this space. Um, R1 only had a 1% true positive rate, uh, over what, like hundreds, uh, yeah, yeah, over hundreds of bugs. Um, same with Lava Maverick at a 2%. Um, R1 did manage to find, um, a needle in a hay stack. Um, but both of these were lapped by Sonnet 4 and 03 in a loop, um, where Sonnet 4 found six, uh, and 03 found two with a 3% and 6% uh, false, uh, true positive rate, respectively. The hard truth here is that the highest popular agent score outside of us, who are just launching now, uh, scored 7% on SM-100. Um, that means the most used agents in the world are the worst at finding and fixing complex bugs. Uh, this is a problem for the industry that we're hoping to bring to light, and we're hoping to see that these teams will begin to work on this to increase their score in what represents the back 90% of work for software engineering.\n\n\nAlso important to note that three out of six agents got 10% or less true positives out of a massive number of reports.\nUh, on one issue, an agent gave us an astounding 70 reports, and nobody's going to actually sift through that many, right?\nLike no engineer is going to look through 70 bugs and be like, \"Oh yeah, that one for sure is the right one.\"\nSo there's a long way to go on tightening how much information these agents are reporting and the accuracy of that information itself.\nI think that you know in context that even some simple bugs are missed.\nUm, only two agents, Bismuth and CodeEx, found this state issue, and the consequence of the state issue is pretty simple, right?\nWhen you submit a form, um, usually they clear.\nIn this particular case, uh, is dirty was never set to false, uh, so it would never clear the form, and it would say you still had things filled out.\nYou know, that's not the biggest bug in the world, but that has real consequences for users and user experience, and that's the type of things a human developer would immediately catch.\nSo we think there is a large way to go.\n\nSo after examining uh all of the performance across all these different agents, there was a notable commonality between them.\nThese agents are very narrow in their thinking.\nEven when using thinking models, this is actually a problem.\nIt's more of a problem on non-thinking models, but thinking models themselves are very narrow in the types of things they're evaluating.\nAnd we find that even with that narrowness, they don't go deep enough.\nSo from our perspective, broader thinking chains and deeper thinking along selected chains is going to be required to actually find bugs in these files.\nIt's also interesting to note that on a per run basis, the total number of bugs remains roughly consistent, but the bugs themselves change.\nSo that means from any one particular run an LLM is not looking holistically at a file and inventorying everything that's happening.\nUm, we suspect there's different biases occurring uh in that and that the models themselves, you know, through whatever context have been provided, are looking at a file one way and not another way.\nUm, there's methodologies we thought of to solve that, but right now it seems like that is a pervasive problem across every agent in the industry, and no one has quite solved that.\nSo there's a broader problem here, right?\nDespite 60 to 70%, 80% in some cases scores on Sweet Edenge, agents still struggle with SM-100.\nWhat does that mean?\nExisting agents are able to create software upfront, but to manage and fix software after it's been deployed will be a major struggle as far as we see it.\nAnd this is a hard problem that teams are working on across the board, us included.\nBut it demands targeted search, better program comprehension, crossfile reasoning, bug pattern recognition that we just don't see in deep capacity from many of these solutions.\nNow, we're hopeful here because CodeEx, for instance, and us are starting to show tighter narrow tighter, more narrow bands of the bugs that it's solving.\nWe do get some complex issues.\nWe are one of the two agents that found that bug I mentioned earlier.\nSo, as we progress here, we hope the industry evolves and focuses more on this problem.\nSo, to wrap things up, we know that the most frequently used agents today have a high risk of introducing bugs.\nThough, as we just said, a few of the newer agents as part of this new generation, including us, are starting to show an increased ability to reason through code and more effectively use their context to evaluate concerns.\nStability is nent, but so far what we've seen has been encouraging.\nUh, and with this benchmark, we can now clearly show as things progress.\nUm, with effort and some different techniques, you can do better and improvements here will have benefits across the entire industry.\nWe have many things that we want to try and I'm sure other labs do.\nUh, and we're really excited to be on the forefront of this new generation of agents.\nSo, thanks for watching.\nUh, you can dive into numbers and get more details on the benchmark uh at the website.\nUh, and be sure to check us out at bismuth.sh.\nThank you.\nThanks.\n",
  "dumpedAt": "2025-07-21T18:43:24.371Z"
}