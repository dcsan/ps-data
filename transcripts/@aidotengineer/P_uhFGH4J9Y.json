{
  "episodeId": "P_uhFGH4J9Y",
  "channelSlug": "@aidotengineer",
  "title": "New York Times' Connections: A Case Study on NLP in Word Games — Shafik Quoraishee, NYT Games",
  "publishedAt": "2025-07-05T22:41:15.000Z",
  "rawLines": [
    {
      "lang": "en",
      "text": "[Music]",
      "offset": 3.54,
      "duration": 5.11
    },
    {
      "lang": "en",
      "text": "Uh, yes, AI and a case study on the New",
      "offset": 14.32,
      "duration": 4.799
    },
    {
      "lang": "en",
      "text": "York Times connections, which is um the",
      "offset": 16.8,
      "duration": 4.479
    },
    {
      "lang": "en",
      "text": "team that I work on is our games team",
      "offset": 19.119,
      "duration": 6.481
    },
    {
      "lang": "en",
      "text": "and I work on our popular games. Um, if",
      "offset": 21.279,
      "duration": 6.481
    },
    {
      "lang": "en",
      "text": "anyone's uh heard of Connections before",
      "offset": 25.6,
      "duration": 5.439
    },
    {
      "lang": "en",
      "text": "or played Connections um or not, since",
      "offset": 27.76,
      "duration": 6.319
    },
    {
      "lang": "en",
      "text": "some people might have. So, um again, a",
      "offset": 31.039,
      "duration": 4.481
    },
    {
      "lang": "en",
      "text": "little bit about me, a game developer at",
      "offset": 34.079,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "the times. I worked previously in media",
      "offset": 35.52,
      "duration": 6.4
    },
    {
      "lang": "en",
      "text": "for most of my career. Um and uh I have",
      "offset": 38.079,
      "duration": 5.281
    },
    {
      "lang": "en",
      "text": "a background in machine learning, mobile",
      "offset": 41.92,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "development, and data science. So, the",
      "offset": 43.36,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "majority of this talk is going to",
      "offset": 46.32,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "probably involve a little bit of all of",
      "offset": 47.84,
      "duration": 4.879
    },
    {
      "lang": "en",
      "text": "those. So caveats about what you're",
      "offset": 49.36,
      "duration": 5.359
    },
    {
      "lang": "en",
      "text": "about to see and I'll get through as",
      "offset": 52.719,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "much of it as I can because it's some of",
      "offset": 54.719,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "it's a little bit dense but this is my",
      "offset": 56.239,
      "duration": 3.521
    },
    {
      "lang": "en",
      "text": "own independent research and",
      "offset": 58.399,
      "duration": 3.281
    },
    {
      "lang": "en",
      "text": "experimentation. Um it's not based on",
      "offset": 59.76,
      "duration": 3.599
    },
    {
      "lang": "en",
      "text": "our internal research. We do have",
      "offset": 61.68,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "internal research and just need to",
      "offset": 63.359,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "clarify that separation. Um the results",
      "offset": 65.36,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "of this work are preliminary and subject",
      "offset": 67.76,
      "duration": 3.359
    },
    {
      "lang": "en",
      "text": "to refinement uh with additional",
      "offset": 69.36,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "experimentation.",
      "offset": 71.119,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "And the purpose of this work is",
      "offset": 73.2,
      "duration": 3.599
    },
    {
      "lang": "en",
      "text": "investigating investigatory not",
      "offset": 74.479,
      "duration": 5.361
    },
    {
      "lang": "en",
      "text": "authoritative. So it's mostly me trying",
      "offset": 76.799,
      "duration": 7.36
    },
    {
      "lang": "en",
      "text": "to kind of look into the realm of uh AI",
      "offset": 79.84,
      "duration": 6.639
    },
    {
      "lang": "en",
      "text": "problem solving in the game space",
      "offset": 84.159,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "through our games and it's mostly like a",
      "offset": 86.479,
      "duration": 4.881
    },
    {
      "lang": "en",
      "text": "fun exercise. Um there does exist third",
      "offset": 88.479,
      "duration": 5.121
    },
    {
      "lang": "en",
      "text": "party research in AI as it resolves as",
      "offset": 91.36,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "it relates to solving connections and",
      "offset": 93.6,
      "duration": 3.519
    },
    {
      "lang": "en",
      "text": "other games but and that's an",
      "offset": 95.6,
      "duration": 3.199
    },
    {
      "lang": "en",
      "text": "inspiration here for this project but",
      "offset": 97.119,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "the processes and everything that I'm",
      "offset": 98.799,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "describing here I did on my own with my",
      "offset": 100.159,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "own research. So, um, for those of you",
      "offset": 102.72,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "who are not familiar with the game,",
      "offset": 105.119,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "Connections was launched by the New York",
      "offset": 106.799,
      "duration": 5.121
    },
    {
      "lang": "en",
      "text": "Times in, uh, June of 2023 into beta and",
      "offset": 108.399,
      "duration": 6.241
    },
    {
      "lang": "en",
      "text": "officially released in August of 2023 to",
      "offset": 111.92,
      "duration": 4.559
    },
    {
      "lang": "en",
      "text": "the greater world. Uh, the game is",
      "offset": 114.64,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "edited by Waloo, who's a awesome editor",
      "offset": 116.479,
      "duration": 4.801
    },
    {
      "lang": "en",
      "text": "at the times that I work with um on",
      "offset": 119.28,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "games and she creates the puzzles for",
      "offset": 121.28,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "uh, connections. Um, it quickly became",
      "offset": 123.6,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "one of the New York Times most played",
      "offset": 126.24,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "games, second only to Wordle with",
      "offset": 128,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "hundreds of millions of plays within its",
      "offset": 129.84,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "first year. And um just to mention all",
      "offset": 131.28,
      "duration": 4.959
    },
    {
      "lang": "en",
      "text": "the connections, puzzles and game",
      "offset": 134.8,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "itself, game the game mechanics and the",
      "offset": 136.239,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "programming etc are humanmade now and",
      "offset": 139.12,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "forever. So um all of our properties",
      "offset": 140.879,
      "duration": 4.481
    },
    {
      "lang": "en",
      "text": "fall into that category. So the game is",
      "offset": 143.2,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "on the right in case um you have your",
      "offset": 145.36,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "mobile apps want to download it. So how",
      "offset": 147.04,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "connections works uh each so you have a",
      "offset": 149.2,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "daily puzzle and each puzzle provides 16",
      "offset": 151.84,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "words to be grouped. The visualization",
      "offset": 154.8,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "on the right is kind of demonstrating",
      "offset": 156.64,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "play. The goal is to form four groups of",
      "offset": 158.16,
      "duration": 4.799
    },
    {
      "lang": "en",
      "text": "words of four groups of four related",
      "offset": 160.56,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "words. Uh each word belongs only to one",
      "offset": 162.959,
      "duration": 5.201
    },
    {
      "lang": "en",
      "text": "group. No overlaps and players can make",
      "offset": 165.84,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "up to four incorrect guesses before",
      "offset": 168.16,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "losing. So um you can see that uh as the",
      "offset": 170,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "game finishes this particular situation,",
      "offset": 173.12,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "the person has won the game. So this is",
      "offset": 175.28,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "where the AI and data science and etc",
      "offset": 178,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "start to come into play. There's a",
      "offset": 180.08,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "difficulty structure to connections. So",
      "offset": 181.44,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "people who play the game probably know",
      "offset": 183.44,
      "duration": 4.879
    },
    {
      "lang": "en",
      "text": "that the easiest category is yellow",
      "offset": 185.76,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "where yellow is like the most obvious",
      "offset": 188.319,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "when you actually solve the game the",
      "offset": 190.72,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "most obvious connections are within the",
      "offset": 192.4,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "yellow category. Green is the slightly",
      "offset": 193.92,
      "duration": 4.959
    },
    {
      "lang": "en",
      "text": "less obvious connections where you have",
      "offset": 197.12,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "to kind of stretch a little to think but",
      "offset": 198.879,
      "duration": 3.521
    },
    {
      "lang": "en",
      "text": "once you get those it's kind of like oh",
      "offset": 200.64,
      "duration": 4.239
    },
    {
      "lang": "en",
      "text": "okay this is kind of obvious um why how",
      "offset": 202.4,
      "duration": 5.119
    },
    {
      "lang": "en",
      "text": "these things are related. Uh the blue",
      "offset": 204.879,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "category is trickier themes where you",
      "offset": 207.519,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "have things like sayings, um idiomatic,",
      "offset": 209.519,
      "duration": 4.561
    },
    {
      "lang": "en",
      "text": "lexical or trivia based themes. And then",
      "offset": 211.68,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "purple is the infamous purple for those",
      "offset": 214.08,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "of who you think of the game as a",
      "offset": 216,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "difficult game. Uh is the category that",
      "offset": 218,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "usually trips up most people from a",
      "offset": 220.48,
      "duration": 3.759
    },
    {
      "lang": "en",
      "text": "perfect win. And that's because there's",
      "offset": 222.08,
      "duration": 5.519
    },
    {
      "lang": "en",
      "text": "a a concept of decoy overlap misleads",
      "offset": 224.239,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "that are associated with the purple",
      "offset": 227.599,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "category.",
      "offset": 228.879,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "Um so why is it an interesting game uh",
      "offset": 230.799,
      "duration": 5.841
    },
    {
      "lang": "en",
      "text": "via via AI analysis and standards? So it",
      "offset": 233.28,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "uh can actually challenge AI's ability",
      "offset": 236.64,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "to abstractly reason. And now at some",
      "offset": 238.56,
      "duration": 4.879
    },
    {
      "lang": "en",
      "text": "point in time we all believe that LLMs",
      "offset": 241.92,
      "duration": 3.519
    },
    {
      "lang": "en",
      "text": "can do absolutely everything. Um and",
      "offset": 243.439,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "some people think that's true. But uh",
      "offset": 245.439,
      "duration": 3.281
    },
    {
      "lang": "en",
      "text": "one thing that Connections has done",
      "offset": 247.28,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "throughout the course of its time period",
      "offset": 248.72,
      "duration": 4.239
    },
    {
      "lang": "en",
      "text": "is actually challenged LLMs to um",
      "offset": 250.48,
      "duration": 5.039
    },
    {
      "lang": "en",
      "text": "actually have a 100% solve rate. Um the",
      "offset": 252.959,
      "duration": 4.881
    },
    {
      "lang": "en",
      "text": "game's intentional decoys tests whether",
      "offset": 255.519,
      "duration": 4.801
    },
    {
      "lang": "en",
      "text": "AI can over avoid overfitting or",
      "offset": 257.84,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "superficial similarities. Um each",
      "offset": 260.32,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "solution requires clean and explainable",
      "offset": 262.56,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "well aligned with AI transparency. So",
      "offset": 264.96,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "like for example if you want to figure",
      "offset": 267.52,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "out how AI reasoned through a game. This",
      "offset": 269.04,
      "duration": 4.719
    },
    {
      "lang": "en",
      "text": "is an actual good like process because",
      "offset": 271.36,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "you do need some sort of reasoning and",
      "offset": 273.759,
      "duration": 4.481
    },
    {
      "lang": "en",
      "text": "perhaps abstract reasoning to solve like",
      "offset": 276.16,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "the difficult or purple category and you",
      "offset": 278.24,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "have get to see how AI thinks about",
      "offset": 280.96,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "that. Um there's fixed input solutions",
      "offset": 282.639,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "make it a reproducible and scalable test",
      "offset": 285.36,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "bed. So one of the interesting things",
      "offset": 287.04,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "that I like about this game particularly",
      "offset": 288.88,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "is because it is a could be a potential",
      "offset": 291.12,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "benchmarking tool and people have uses",
      "offset": 293.44,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "as such to test the capabilities of AI",
      "offset": 295.52,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "and since the puzzles are the same and",
      "offset": 297.52,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "playable you can repeat this process and",
      "offset": 299.6,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "this is just me entering the puzzle in",
      "offset": 302.32,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "Chad GPT and Chad GPT giving the wrong",
      "offset": 303.84,
      "duration": 4.799
    },
    {
      "lang": "en",
      "text": "solution. This is sort of like um unfair",
      "offset": 306.24,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "comparison because this is the 40 model.",
      "offset": 308.639,
      "duration": 3.201
    },
    {
      "lang": "en",
      "text": "the higher models do give better",
      "offset": 310.4,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "reasoning, but that's not exactly uh",
      "offset": 311.84,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "I'll go into that a little later if I",
      "offset": 314.32,
      "duration": 4.879
    },
    {
      "lang": "en",
      "text": "get the time. Um, and so how do humans",
      "offset": 315.68,
      "duration": 5.359
    },
    {
      "lang": "en",
      "text": "solve connections? Uh, there's the",
      "offset": 319.199,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "concept of system one versus system two",
      "offset": 321.039,
      "duration": 5.121
    },
    {
      "lang": "en",
      "text": "thinking. Uh, I'm guessing many people",
      "offset": 323.12,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "might be familiar with this concept. It",
      "offset": 326.16,
      "duration": 6.4
    },
    {
      "lang": "en",
      "text": "uh came out in uh the n the '9s. And um",
      "offset": 328,
      "duration": 6.639
    },
    {
      "lang": "en",
      "text": "it's so system one thinking is when",
      "offset": 332.56,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "you're trying to intuitit relationships",
      "offset": 334.639,
      "duration": 4.241
    },
    {
      "lang": "en",
      "text": "very fast. when you see two things that",
      "offset": 336.8,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "are obviously part of the same category,",
      "offset": 338.88,
      "duration": 3.039
    },
    {
      "lang": "en",
      "text": "you don't have to think so much. Your",
      "offset": 340.56,
      "duration": 3.199
    },
    {
      "lang": "en",
      "text": "your brain sort of makes that automatic",
      "offset": 341.919,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "judgment. Um, system two, which is slow",
      "offset": 343.759,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "and deliberate thinking, is where you",
      "offset": 346.639,
      "duration": 3.761
    },
    {
      "lang": "en",
      "text": "have like the sort of deep kind of",
      "offset": 348.639,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "reasoning which you need to perform. And",
      "offset": 350.4,
      "duration": 2.88
    },
    {
      "lang": "en",
      "text": "that's where you're like, &quot;Oh, I'm",
      "offset": 352.24,
      "duration": 2.16
    },
    {
      "lang": "en",
      "text": "struggling. I don't know if this belongs",
      "offset": 353.28,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "to one or two. Let me use my knowledge",
      "offset": 354.4,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "base.&quot; Um and then in order to solve the",
      "offset": 356.32,
      "duration": 6.4
    },
    {
      "lang": "en",
      "text": "games uh uh most effectively most people",
      "offset": 359.28,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "use a high strategy where they've used",
      "offset": 362.72,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "both the fast intuitive thinking and",
      "offset": 364.96,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "then the slow deep thinking. And that's",
      "offset": 366.96,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "what takes a lot of time in the actual",
      "offset": 368.96,
      "duration": 3.359
    },
    {
      "lang": "en",
      "text": "playing of the game. And then you can",
      "offset": 370.56,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "suffer from canonical failures like",
      "offset": 372.319,
      "duration": 4.241
    },
    {
      "lang": "en",
      "text": "system one failures. You you thought it",
      "offset": 374.56,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "looked obvious but you messed up because",
      "offset": 376.56,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "it wasn't actually obvious. Stuff",
      "offset": 378.639,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "belonged to a different category or",
      "offset": 380.16,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "system two thinking where you're like I",
      "offset": 382.24,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "thought too deeply about this but it was",
      "offset": 383.84,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "actually the obvious one. And so, you",
      "offset": 385.36,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "know, you overthought that one. So,",
      "offset": 387.36,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "that's one of the fun parts of the game",
      "offset": 388.96,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "if you think that's fun. Um, so",
      "offset": 390.56,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "connection studies and benchmarks do",
      "offset": 394.08,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "exist. There's several benchmarks uh for",
      "offset": 395.68,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "solving connections with the later",
      "offset": 398.24,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "models that are come out that have come",
      "offset": 400.16,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "out. They're not by us. They're",
      "offset": 402,
      "duration": 2.96
    },
    {
      "lang": "en",
      "text": "thirdparty benchmarks, but they do",
      "offset": 403.44,
      "duration": 3.599
    },
    {
      "lang": "en",
      "text": "demonstrate progressive capability of",
      "offset": 404.96,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "LLMs to uh solve the game, but it's",
      "offset": 407.039,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "still not perfect. And as I mentioned",
      "offset": 409.52,
      "duration": 2.72
    },
    {
      "lang": "en",
      "text": "before, there are caveats to that",
      "offset": 410.88,
      "duration": 2.879
    },
    {
      "lang": "en",
      "text": "solvability.",
      "offset": 412.24,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "So there's now I'm going into the like",
      "offset": 413.759,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "deeper part and I'm going to see how far",
      "offset": 416,
      "duration": 2.88
    },
    {
      "lang": "en",
      "text": "I get through the rest of this because",
      "offset": 417.36,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "this is where my AI analysis goes into",
      "offset": 418.88,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "play. So um if this mathematics this is",
      "offset": 421.12,
      "duration": 5.199
    },
    {
      "lang": "en",
      "text": "your chances of winning the game if",
      "offset": 424.88,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "you're guessing randomly right if you",
      "offset": 426.319,
      "duration": 4.241
    },
    {
      "lang": "en",
      "text": "use no intuition whatsoever. So um if",
      "offset": 428,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "you're totally randomly guessing you",
      "offset": 430.56,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "have uh if you have the complete initial",
      "offset": 432.16,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "board you have about a 0% chance of",
      "offset": 434.639,
      "duration": 4.721
    },
    {
      "lang": "en",
      "text": "winning. Then the mathematics or",
      "offset": 437.28,
      "duration": 4.639
    },
    {
      "lang": "en",
      "text": "combinatorics of the connections board",
      "offset": 439.36,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "uh indicate that after maybe if you get",
      "offset": 441.919,
      "duration": 3.761
    },
    {
      "lang": "en",
      "text": "one category right and you still need to",
      "offset": 444.24,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "randomly guess through the next three",
      "offset": 445.68,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "you have about a one in 5,000 one in",
      "offset": 447.36,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "6,000 chance of winning which is tiny",
      "offset": 449.52,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "but it's you know you could maybe do it",
      "offset": 451.84,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "I don't know and then um most people get",
      "offset": 453.599,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "stuck on the third and fourth category",
      "offset": 455.919,
      "duration": 3.201
    },
    {
      "lang": "en",
      "text": "where it's like oh I don't know like I",
      "offset": 457.52,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "got two and now all these words how do",
      "offset": 459.12,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "they relate to each other? So, if you're",
      "offset": 460.88,
      "duration": 2.8
    },
    {
      "lang": "en",
      "text": "like screw it, I'm going to guess",
      "offset": 462.56,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "randomly. Uh, then you have a one in 35%",
      "offset": 463.68,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "chance. One in 35 chance of winning or",
      "offset": 466.56,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "about% chance. And that means that okay,",
      "offset": 468.72,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "well, you're doing pretty good, I think.",
      "offset": 471.36,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "Um, now the graph coloring problem.",
      "offset": 473.84,
      "duration": 3.759
    },
    {
      "lang": "en",
      "text": "We're going to go into a little bit of",
      "offset": 476.56,
      "duration": 2.88
    },
    {
      "lang": "en",
      "text": "CS. Uh, who's familiar with the graph",
      "offset": 477.599,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "coloring problem? Okay, great. We have",
      "offset": 479.44,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "CS people here. Yes. So, graph coloring",
      "offset": 481.44,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "involves assigning colors to vertices of",
      "offset": 484.24,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "a graph. The graph is the structure on",
      "offset": 486.24,
      "duration": 3.679
    },
    {
      "lang": "en",
      "text": "the right, which is basically a bunch of",
      "offset": 488.16,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "nodes and edges. um there's some number",
      "offset": 489.919,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "associated with the graph. Not going to",
      "offset": 491.84,
      "duration": 3.359
    },
    {
      "lang": "en",
      "text": "get too deep into that, but that I'm",
      "offset": 493.199,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "doing that chromatic number is",
      "offset": 495.199,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "important. Um and when you want to solve",
      "offset": 496.639,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "a graph coloring problem, you use",
      "offset": 499.36,
      "duration": 3.679
    },
    {
      "lang": "en",
      "text": "algorithms that are popularly known,",
      "offset": 501.039,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "backtracking, greedy coloring. And the",
      "offset": 503.039,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "graph coloring problem just for interest",
      "offset": 505.759,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "has um applications in all kinds of",
      "offset": 507.919,
      "duration": 5.281
    },
    {
      "lang": "en",
      "text": "areas outside of um you know just",
      "offset": 510.319,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "science, scheduling, frequency",
      "offset": 513.2,
      "duration": 3.759
    },
    {
      "lang": "en",
      "text": "assignment, wireless networks and in",
      "offset": 514.719,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "connections. that you can model",
      "offset": 516.959,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "connections as a graph coloring an",
      "offset": 518.64,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "augmented graph coloring problem. So",
      "offset": 520.64,
      "duration": 3.519
    },
    {
      "lang": "en",
      "text": "this is a connection solver that I built",
      "offset": 522.56,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "on the right that a bunch of puzzles and",
      "offset": 524.159,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "attempts to organize them into graph",
      "offset": 526.08,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "coloring um groups. So each of the words",
      "offset": 528,
      "duration": 5.279
    },
    {
      "lang": "en",
      "text": "16 words and connections can be a vertex",
      "offset": 530.88,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "in this graph. There hidden categories",
      "offset": 533.279,
      "duration": 4.721
    },
    {
      "lang": "en",
      "text": "that we already went over. They're",
      "offset": 536.08,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "colorcoded. And the goal is to color",
      "offset": 538,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "each word node with one of the four",
      "offset": 540.399,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "categories such that all four words",
      "offset": 541.839,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "belong to a specific category receive",
      "offset": 543.839,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "the same color. And then the edge is the",
      "offset": 545.519,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "strength of the connection that it's",
      "offset": 547.68,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "thought of to exist between words. So",
      "offset": 549.36,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "that is basically how related they are",
      "offset": 551.04,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "is the edge. So the reason why that's",
      "offset": 553.12,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "important is because that creates the",
      "offset": 555.44,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "search space for an algorithm or an AI",
      "offset": 557.76,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "to actually you know play the game",
      "offset": 560,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "effectively um or solve the game",
      "offset": 561.92,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "effectively. Without that it's falling",
      "offset": 564,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "into the random range of gra of sorting",
      "offset": 565.6,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "words and it becomes much more",
      "offset": 567.92,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "difficult. So we have this idea of",
      "offset": 569.12,
      "duration": 5.279
    },
    {
      "lang": "en",
      "text": "semantic similarity. It's not enough. I",
      "offset": 572.16,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "I wish I I've renamed it semantic",
      "offset": 574.399,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "similarity is not all you need if you",
      "offset": 576.56,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "get the transformer joke. Um so this is",
      "offset": 578.48,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "like it's hard to see here but there's a",
      "offset": 582.16,
      "duration": 3.119
    },
    {
      "lang": "en",
      "text": "tree of word relationships between",
      "offset": 583.68,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "different words. For example, anagrams",
      "offset": 585.279,
      "duration": 4.481
    },
    {
      "lang": "en",
      "text": "are related uh could be a a type of",
      "offset": 587.68,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "category called orthography of words. So",
      "offset": 589.76,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "um you know that could be an entire",
      "offset": 592.24,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "category. morphology meaning things like",
      "offset": 593.839,
      "duration": 5.041
    },
    {
      "lang": "en",
      "text": "that have the same uh suffix like",
      "offset": 596.24,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "something like kingdom fifom or",
      "offset": 598.88,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "connectedness um things like that. Then",
      "offset": 601.6,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "you have other semantic relationships",
      "offset": 604.56,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "that are not so obvious which are could",
      "offset": 605.92,
      "duration": 3.039
    },
    {
      "lang": "en",
      "text": "be things like encyclopedic",
      "offset": 607.76,
      "duration": 3.519
    },
    {
      "lang": "en",
      "text": "relationships like for example globe",
      "offset": 608.959,
      "duration": 4.481
    },
    {
      "lang": "en",
      "text": "mirror post and sun are all part of the",
      "offset": 611.279,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "newspaper category and then you have",
      "offset": 613.44,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "things like associative relationships",
      "offset": 615.36,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "things that are red or things that are",
      "offset": 617.2,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "green right strawberry rose Mars etc.",
      "offset": 618.56,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "And so again um the most I just going",
      "offset": 621.44,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "back to this policy things that can like",
      "offset": 623.6,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "for example what a mole can be an animal",
      "offset": 625.839,
      "duration": 5.921
    },
    {
      "lang": "en",
      "text": "birthark spy or unit uh that is where",
      "offset": 628.16,
      "duration": 5.679
    },
    {
      "lang": "en",
      "text": "the connections actually just for",
      "offset": 631.76,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "interest sake is the most complicated",
      "offset": 633.839,
      "duration": 4.481
    },
    {
      "lang": "en",
      "text": "for most AIs and people because that's",
      "offset": 635.76,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "the the poly multiple meaning section is",
      "offset": 638.32,
      "duration": 4.639
    },
    {
      "lang": "en",
      "text": "where on a base level people get tripped",
      "offset": 640.88,
      "duration": 4.639
    },
    {
      "lang": "en",
      "text": "up any intelligence can get tripped up.",
      "offset": 642.959,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "So you have this concept of relational",
      "offset": 645.519,
      "duration": 4.641
    },
    {
      "lang": "en",
      "text": "alignment. So relational alignment is if",
      "offset": 647.279,
      "duration": 4.881
    },
    {
      "lang": "en",
      "text": "you can create a metric that associates",
      "offset": 650.16,
      "duration": 3.679
    },
    {
      "lang": "en",
      "text": "two words together, you can have a",
      "offset": 652.16,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "relational alignment score. So there's",
      "offset": 653.839,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "different metrics that are associated",
      "offset": 656,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "with a relational alignment. And so I",
      "offset": 658.16,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "created this heat map simulation on the",
      "offset": 659.76,
      "duration": 3.519
    },
    {
      "lang": "en",
      "text": "right which can pick different metrics",
      "offset": 661.76,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "and show how based on the metric",
      "offset": 663.279,
      "duration": 3.521
    },
    {
      "lang": "en",
      "text": "calculations which I'm not showing here",
      "offset": 665.36,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "that these two things are that these um",
      "offset": 666.8,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "the two words from a large category are",
      "offset": 669.12,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "related. Now um the bu story I'm",
      "offset": 671.04,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "building up is that relational alignment",
      "offset": 674.88,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "between puzzles uh can help you",
      "offset": 677.04,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "determine on a computational way whether",
      "offset": 679.44,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "a puzzle is easy or whether it's hard.",
      "offset": 681.6,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "So this is for example from an easy",
      "offset": 683.68,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "puzzle years ago that was uh done versus",
      "offset": 685.519,
      "duration": 5.841
    },
    {
      "lang": "en",
      "text": "a hard puzzle. And this is like um",
      "offset": 689.2,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "people have described this as the solve",
      "offset": 691.36,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "rate is 19% for the hard puzzle but like",
      "offset": 693.12,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "70 something for the easier puzzle. And",
      "offset": 695.6,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "you can see that there's a a rough",
      "offset": 697.6,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "overarching coherence or relational",
      "offset": 699.2,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "alignment score differential between",
      "offset": 701.2,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "easy and hard. So that differential lets",
      "offset": 703.279,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "you understand there's a computational",
      "offset": 705.6,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "process which you can apply. So you can",
      "offset": 707.36,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "see that time variant relational",
      "offset": 710.32,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "alignment scores can go across",
      "offset": 712,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "categories and time. So puzzles are",
      "offset": 714,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "easy, puzzles are hard and you see some",
      "offset": 716.399,
      "duration": 3.521
    },
    {
      "lang": "en",
      "text": "sort of time variant metric which you",
      "offset": 718.079,
      "duration": 3.521
    },
    {
      "lang": "en",
      "text": "know you can you can com you can compute",
      "offset": 719.92,
      "duration": 3.599
    },
    {
      "lang": "en",
      "text": "this and you can draw a graph over time.",
      "offset": 721.6,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "I'm not sure what happened here on 1212.",
      "offset": 723.519,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "I think oh we had a broken puzzle that",
      "offset": 725.76,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "day so it was zero. Um but the idea is",
      "offset": 727.279,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "that you can see that there could be",
      "offset": 730.16,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "patterns established from this um",
      "offset": 731.839,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "alignment score that you compute. Now if",
      "offset": 733.76,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "it was that easy that would be great but",
      "offset": 736.079,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "it's not actually that easy because as",
      "offset": 737.6,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "we have multiple different semantic",
      "offset": 739.279,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "relationships we have multiple",
      "offset": 740.88,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "relational alignment scores. So",
      "offset": 742.88,
      "duration": 4.639
    },
    {
      "lang": "en",
      "text": "basically uh two words can be related in",
      "offset": 745.12,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "multiple ways and they can have",
      "offset": 747.519,
      "duration": 2.721
    },
    {
      "lang": "en",
      "text": "different scores across different",
      "offset": 748.8,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "categories. So some can be semantically",
      "offset": 750.24,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "or morphologically more strongly related",
      "offset": 752.24,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "than they are um for example um",
      "offset": 754.079,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "categorically or encyclopedically",
      "offset": 756.88,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "related. But uh the idea is that you can",
      "offset": 758.639,
      "duration": 4.561
    },
    {
      "lang": "en",
      "text": "create sort of this radar chart which",
      "offset": 761.44,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "lets you kind of map out some sort of",
      "offset": 763.2,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "diagram or surface which you can analyze",
      "offset": 765.44,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "to see how the uh semantic space of the",
      "offset": 767.44,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "word across different categories looks.",
      "offset": 770.32,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "That means you have yet another",
      "offset": 772.24,
      "duration": 3.599
    },
    {
      "lang": "en",
      "text": "dimension to analyze how your AI can",
      "offset": 773.36,
      "duration": 6.159
    },
    {
      "lang": "en",
      "text": "analyze how um to solve a puzzle or your",
      "offset": 775.839,
      "duration": 5.761
    },
    {
      "lang": "en",
      "text": "AI or solver or you yourself if you want",
      "offset": 779.519,
      "duration": 4.241
    },
    {
      "lang": "en",
      "text": "to think about like this stuff deep more",
      "offset": 781.6,
      "duration": 5.039
    },
    {
      "lang": "en",
      "text": "deeply using your um reasoning. So",
      "offset": 783.76,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "multi-dimensional uh relational",
      "offset": 786.639,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "alignment distribution was part of the",
      "offset": 788.88,
      "duration": 3.519
    },
    {
      "lang": "en",
      "text": "things that I was kind of looking at. So",
      "offset": 790.48,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "I basically another component of the",
      "offset": 792.399,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "system I built was the semantic",
      "offset": 794.24,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "distribution evaluation framework where",
      "offset": 796.079,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "I taking a bunch of our puzzles and then",
      "offset": 798.16,
      "duration": 4.479
    },
    {
      "lang": "en",
      "text": "I'm building this category categorical",
      "offset": 800,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "distribution over time where you can see",
      "offset": 802.639,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "on the lower right it's hard maybe to",
      "offset": 804.48,
      "duration": 2.72
    },
    {
      "lang": "en",
      "text": "see a little bit but there's the",
      "offset": 806.079,
      "duration": 3.121
    },
    {
      "lang": "en",
      "text": "different categories like hypernomy",
      "offset": 807.2,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "morphology orthography things I talked",
      "offset": 809.2,
      "duration": 4.639
    },
    {
      "lang": "en",
      "text": "about and the distribution of categories",
      "offset": 811.6,
      "duration": 5.359
    },
    {
      "lang": "en",
      "text": "for um the connections puzzles over time",
      "offset": 813.839,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "and so you can see I'm counting like",
      "offset": 816.959,
      "duration": 3.521
    },
    {
      "lang": "en",
      "text": "which categories over the days fall into",
      "offset": 818.399,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "which um of these buckets with these",
      "offset": 820.48,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "dots on this right and I can build a",
      "offset": 822.399,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "sort of like histogram or count of this",
      "offset": 824.16,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "association and so you can look at",
      "offset": 826.079,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "trends and then you can use that data uh",
      "offset": 828,
      "duration": 4.639
    },
    {
      "lang": "en",
      "text": "that trend data. So now here what it",
      "offset": 830.399,
      "duration": 4.481
    },
    {
      "lang": "en",
      "text": "gets a little bit more involved um the",
      "offset": 832.639,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "graph uh coloring approximation is a",
      "offset": 834.88,
      "duration": 4.639
    },
    {
      "lang": "en",
      "text": "search space reduction uh process but",
      "offset": 837.279,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "then you get to the more complicated",
      "offset": 839.519,
      "duration": 3.521
    },
    {
      "lang": "en",
      "text": "idea of graph clustering. Once you add",
      "offset": 841.12,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "the semantic relationships into the",
      "offset": 843.04,
      "duration": 4.479
    },
    {
      "lang": "en",
      "text": "actual uh formulation um you actually",
      "offset": 844.959,
      "duration": 4.481
    },
    {
      "lang": "en",
      "text": "start to build multi-dimensional or",
      "offset": 847.519,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "hyperraphs. And this is just a",
      "offset": 849.44,
      "duration": 3.519
    },
    {
      "lang": "en",
      "text": "three-dimensional hyperraph. But if you",
      "offset": 851.36,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "have multiple semantic relationships,",
      "offset": 852.959,
      "duration": 2.88
    },
    {
      "lang": "en",
      "text": "you actually have multi-dimensional",
      "offset": 854.48,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "hyperraphs. And this is kind of just a",
      "offset": 855.839,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "demonstration of how the hyperraph",
      "offset": 857.92,
      "duration": 3.359
    },
    {
      "lang": "en",
      "text": "converges in three dimensions. Meaning",
      "offset": 859.44,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "that if you have all these semantic",
      "offset": 861.279,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "relationships, you're going to have",
      "offset": 863.279,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "these uh intercluster strengths between",
      "offset": 865.12,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "uh different nodes and different",
      "offset": 868.079,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "categories. But you also have the",
      "offset": 869.68,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "intracluster strength which shows you",
      "offset": 871.279,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "how strong the relationships are within",
      "offset": 873.44,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "the clusters that form due to the",
      "offset": 875.199,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "algorithm you're using. That's important",
      "offset": 876.56,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "because the graph this graph gives you",
      "offset": 878.399,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "more dimensionality and again will is a",
      "offset": 880.48,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "more computational way of using AI to",
      "offset": 882.639,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "solve this uh problem or any again",
      "offset": 885.12,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "solver to solve the problem.",
      "offset": 887.279,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "Um so how do you build these semantic",
      "offset": 889.76,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "graphs? You can use different types of",
      "offset": 891.6,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "lexical databases or lexical um",
      "offset": 894.16,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "constructors. For example, word net,",
      "offset": 896.24,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "concept net, and other word embeddings",
      "offset": 898.24,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "can be used to construct these",
      "offset": 900.16,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "relationships. And so this is a a flat",
      "offset": 901.44,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "example of a 2D graph of one puzzle",
      "offset": 903.76,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "where you see relationships between like",
      "offset": 905.68,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "different words like for example, two",
      "offset": 908,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "words co- occur together, a mouse hunts",
      "offset": 909.6,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "a cat, a dog is related to a cat, a cat",
      "offset": 911.839,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "is capable of play, a cat is used for",
      "offset": 914.88,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "pet. And you can see the complex",
      "offset": 917.519,
      "duration": 3.201
    },
    {
      "lang": "en",
      "text": "dimensionality of these conceptual",
      "offset": 918.88,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "semantic graphs as derived from word",
      "offset": 920.72,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "net, concept net, and word embeddings",
      "offset": 922.959,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "allows you even more space. So we're",
      "offset": 924.56,
      "duration": 3.519
    },
    {
      "lang": "en",
      "text": "increasing the intelligence here. You",
      "offset": 926.56,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "see, I'm not just doing a reasoning",
      "offset": 928.079,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "model or dumbly putting into an LLM. I'm",
      "offset": 929.6,
      "duration": 4.479
    },
    {
      "lang": "en",
      "text": "actually trying to increase this",
      "offset": 932.079,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "intelligence space like procedurally so",
      "offset": 934.079,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "that you can have a trackable and",
      "offset": 936.48,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "explainable way. You know, explainable",
      "offset": 938,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "AI, that's what I'm all about. This is",
      "offset": 939.92,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "part of that. So um to get to the actual",
      "offset": 941.839,
      "duration": 5.841
    },
    {
      "lang": "en",
      "text": "model which does that anyone familiar",
      "offset": 945.6,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "with graph neural networks? Okay. So if",
      "offset": 947.68,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "you've used GNN's uh before that that",
      "offset": 949.92,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "that's the primary since it's a",
      "offset": 952.16,
      "duration": 4.239
    },
    {
      "lang": "en",
      "text": "geometric problem in multi-pace you well",
      "offset": 953.44,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "I the primary pro solver that I'm using",
      "offset": 956.399,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "is a is a graph convolutional neural",
      "offset": 958.88,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "network which allows you to kind of",
      "offset": 961.519,
      "duration": 5.041
    },
    {
      "lang": "en",
      "text": "create take in a graph as an input and",
      "offset": 964.24,
      "duration": 4.719
    },
    {
      "lang": "en",
      "text": "then put like candidate subgraphs that",
      "offset": 966.56,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "could be solutions as outputs. This is",
      "offset": 968.959,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "one part of the problem. It's part of a",
      "offset": 971.68,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "two-part problem where I'm using the",
      "offset": 973.36,
      "duration": 4.479
    },
    {
      "lang": "en",
      "text": "graph the reinforcement learning system.",
      "offset": 974.72,
      "duration": 5.039
    },
    {
      "lang": "en",
      "text": "So once we have the graph neural network",
      "offset": 977.839,
      "duration": 3.521
    },
    {
      "lang": "en",
      "text": "that's actually outputting candidate",
      "offset": 979.759,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "graphs, you have edge weights and node",
      "offset": 981.36,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "weights that are being optimized and",
      "offset": 983.279,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "then you find out which graph like fits",
      "offset": 984.72,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "into the candidate solutions. Then you",
      "offset": 986.959,
      "duration": 4.641
    },
    {
      "lang": "en",
      "text": "can track the actual structure of the",
      "offset": 990,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "graph which is just cluster morphology",
      "offset": 991.6,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "or like how the graph looks. The next",
      "offset": 993.68,
      "duration": 3.279
    },
    {
      "lang": "en",
      "text": "visualization, this is the system",
      "offset": 995.519,
      "duration": 2.88
    },
    {
      "lang": "en",
      "text": "diagram. Not going to go into it. It's a",
      "offset": 996.959,
      "duration": 3.201
    },
    {
      "lang": "en",
      "text": "lot. But um I'll just say it's the",
      "offset": 998.399,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "combination of aman learning agents with",
      "offset": 1000.16,
      "duration": 6.56
    },
    {
      "lang": "en",
      "text": "uh a graph a graph based system for um",
      "offset": 1003.199,
      "duration": 5.841
    },
    {
      "lang": "en",
      "text": "actually with the graph neural network",
      "offset": 1006.72,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "for kind of isolating how what candidate",
      "offset": 1009.04,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "graphs you have. And so this is I'm",
      "offset": 1011.92,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "almost out of time, but I'll just say",
      "offset": 1014.24,
      "duration": 2.959
    },
    {
      "lang": "en",
      "text": "that this is kind of like how the",
      "offset": 1015.68,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "visualization looks in threespace. Once",
      "offset": 1017.199,
      "duration": 6.161
    },
    {
      "lang": "en",
      "text": "your um semantic graphs are uh once your",
      "offset": 1019.519,
      "duration": 5.361
    },
    {
      "lang": "en",
      "text": "semantic graphs are constructed, your",
      "offset": 1023.36,
      "duration": 2.959
    },
    {
      "lang": "en",
      "text": "graph candidates and the reinforcement",
      "offset": 1024.88,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "learning system is kind of the",
      "offset": 1026.319,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "appropriate way to kind of navigate",
      "offset": 1028.64,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "these subclusters. And you can't",
      "offset": 1030.72,
      "duration": 3.199
    },
    {
      "lang": "en",
      "text": "actually see the cluster points here",
      "offset": 1032.48,
      "duration": 2.88
    },
    {
      "lang": "en",
      "text": "because the visualization wasn't super",
      "offset": 1033.919,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "great, but the actual output is kind of",
      "offset": 1035.36,
      "duration": 4.559
    },
    {
      "lang": "en",
      "text": "like, okay, now this this traversal is",
      "offset": 1037.52,
      "duration": 5.519
    },
    {
      "lang": "en",
      "text": "allowed to exist. So again um after all",
      "offset": 1039.919,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "this stuff the solvability rate from",
      "offset": 1043.039,
      "duration": 4.561
    },
    {
      "lang": "en",
      "text": "before to after for a short a small",
      "offset": 1045.439,
      "duration": 4.561
    },
    {
      "lang": "en",
      "text": "subset of hard puzzle puzzles increases",
      "offset": 1047.6,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "somewhat reasonably but now again this",
      "offset": 1050,
      "duration": 3.679
    },
    {
      "lang": "en",
      "text": "is a work in progress and I tried this",
      "offset": 1052,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "against a few puzzles before and after",
      "offset": 1053.679,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "and now the idea is to extend this and",
      "offset": 1055.919,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "like make it more involved for even more",
      "offset": 1057.52,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "puzzles and then get to game",
      "offset": 1059.6,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "development. So why do all this or well",
      "offset": 1061.28,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "our LLMs are great at a bunch of stuff",
      "offset": 1063.44,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "but you know they can often make you",
      "offset": 1065.6,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "know their own mistakes. LLMs often are",
      "offset": 1067.84,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "trained on internet data and the puzzle",
      "offset": 1070.4,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "solutions are available on the internet.",
      "offset": 1072,
      "duration": 2.64
    },
    {
      "lang": "en",
      "text": "So, who knows if they're just pulling",
      "offset": 1073.44,
      "duration": 2.8
    },
    {
      "lang": "en",
      "text": "the solutions from the internet. That's",
      "offset": 1074.64,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "one thing that bothered me about uh LLM",
      "offset": 1076.24,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "solving these problems. And so, and",
      "offset": 1078.559,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "that's LLM solutions are still a black",
      "offset": 1080.88,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "box. And so, um the idea is to connect",
      "offset": 1082.96,
      "duration": 5.92
    },
    {
      "lang": "en",
      "text": "this to the ArcGI benchmark um and that",
      "offset": 1086,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "kind of thing. So, you know, that",
      "offset": 1088.88,
      "duration": 5.679
    },
    {
      "lang": "en",
      "text": "benchmark has a partition like a yeah uh",
      "offset": 1090.72,
      "duration": 7.36
    },
    {
      "lang": "en",
      "text": "a solvability uh association. So, we",
      "offset": 1094.559,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "have some next steps and this is pretty",
      "offset": 1098.08,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "much the end of my presentation. I ran a",
      "offset": 1099.679,
      "duration": 3.441
    },
    {
      "lang": "en",
      "text": "few seconds over, but yeah, if you're",
      "offset": 1101.2,
      "duration": 5.18
    },
    {
      "lang": "en",
      "text": "interested, talk to me later.",
      "offset": 1103.12,
      "duration": 8.919
    },
    {
      "lang": "en",
      "text": "[Music]",
      "offset": 1106.38,
      "duration": 5.659
    }
  ],
  "cleanText": "[Music]\nUh, yes, AI and a case study on the New York Times Connections, which is um the team that I work on is our games team and I work on our popular games. Um, if anyone's uh heard of Connections before or played Connections um or not, since some people might have. So, um, again, a little bit about me, a game developer at the Times. I worked previously in media for most of my career. Um and uh I have a background in machine learning, mobile development, and data science. So, the majority of this talk is going to probably involve a little bit of all of those. So caveats about what you're about to see and I'll get through as much of it as I can because it's some of it's a little bit dense but this is my own independent research and experimentation. Um, it's not based on our internal research. We do have internal research and just need to clarify that separation. Um, the results of this work are preliminary and subject to refinement uh with additional experimentation.\n\nAnd the purpose of this work is investigating investigatory not authoritative. So it's mostly me trying to kind of look into the realm of uh AI problem solving in the game space through our games and it's mostly like a fun exercise. Um, there does exist third-party research in AI as it resolves as it relates to solving Connections and other games but and that's an inspiration here for this project but the processes and everything that I'm describing here I did on my own with my own research. So, um, for those of you who are not familiar with the game, Connections was launched by the New York Times in, uh, June of 2023 into beta and officially released in August of 2023 to the greater world. Uh, the game is edited by Waloo, who's a awesome editor at the Times that I work with um on games and she creates the puzzles for uh, Connections. Um, it quickly became one of the New York Times most played games, second only to Wordle with hundreds of millions of plays within its first year. And um just to mention all the Connections puzzles and game itself, game the game mechanics and the programming etc are human-made now and forever. So um all of our properties fall into that category. So the game is on the right in case um you have your mobile apps want to download it. So how Connections works uh each so you have a daily puzzle and each puzzle provides 16 words to be grouped. The visualization on the right is kind of demonstrating play. The goal is to form four groups of words of four groups of four related words. Uh, each word belongs only to one group. No overlaps and players can make up to four incorrect guesses before losing. So um you can see that uh as the game finishes this particular situation, the person has won the game. So this is where the AI and data science and etc start to come into play. There's a difficulty structure to Connections. So people who play the game probably know that the easiest category is yellow where yellow is like the most obvious when you actually solve the game the most obvious connections are within the yellow category. Green is the slightly less obvious connections where you have to kind of stretch a little to think but once you get those it's kind of like oh okay this is kind of obvious um why how these things are related. Uh, the blue category is trickier themes where you have things like sayings, um idiomatic, lexical or trivia based themes. And then purple is the infamous purple for those of who you think of the game as a difficult game. Uh, is the category that usually trips up most people from a perfect win. And that's because there's a a concept of decoy overlap misleads that are associated with the purple category.\n\nUm, so why is it an interesting game uh via via AI analysis and standards? So it uh can actually challenge AI's ability to abstractly reason. And now at some point in time we all believe that LLMs can do absolutely everything. Um, and some people think that's true. But uh, one thing that Connections has done throughout the course of its time period is actually challenged LLMs to um actually have a 100% solve rate. Um, the game's intentional decoys tests whether AI can over avoid overfitting or superficial similarities. Um, each solution requires clean and explainable well aligned with AI transparency. So like for example if you want to figure out how AI reasoned through a game. This is an actual good like process because you do need some sort of reasoning and perhaps abstract reasoning to solve like the difficult or purple category and you get to see how AI thinks about that. Um, there's fixed input solutions make it a reproducible and scalable test bed. So one of the interesting things that I like about this game particularly is because it is a could be a potential benchmarking tool and people have uses as such to test the capabilities of AI and since the puzzles are the same and playable you can repeat this process and this is just me entering the puzzle in Chat GPT and Chat GPT giving the wrong solution. This is sort of like um unfair comparison because this is the 40 model. The higher models do give better reasoning, but that's not exactly uh I'll go into that a little later if I get the time. Um, and so how do humans solve Connections? Uh, there's the concept of system one versus system two thinking. Uh, I'm guessing many people might be familiar with this concept. It uh came out in uh the n the '90s. And um, it's so system one thinking is when you're trying to intuitit relationships very fast. When you see two things that are obviously part of the same category, you don't have to think so much. Your your brain sort of makes that automatic judgment. Um, system two, which is slow and deliberate thinking, is where you have like the sort of deep kind of reasoning which you need to perform. And that's where you're like, \"Oh, I'm struggling. I don't know if this belongs to one or two. Let me use my knowledge base.\" Um, and then in order to solve the games uh uh most effectively most people use a high strategy where they've used both the fast intuitive thinking and then the slow deep thinking. And that's what takes a lot of time in the actual playing of the game. And then you can suffer from canonical failures like system one failures. You you thought it looked obvious but you messed up because it wasn't actually obvious. Stuff belonged to a different category or system two thinking where you're like I thought too deeply about this but it was actually the obvious one. And so, you know, you overthought that one. So, that's one of the fun parts of the game if you think that's fun. Um, so Connections studies and benchmarks do exist. There's several benchmarks uh for solving Connections with the later models that are come out that have come out. They're not by us. They're third-party benchmarks, but they do demonstrate progressive capability of LLMs to uh solve the game, but it's still not perfect. And as I mentioned before, there are caveats to that solvability.\n\nSo there's now I'm going into the like deeper part and I'm going to see how far I get through the rest of this because this is where my AI analysis goes into play. So um if this mathematics this is your chances of winning the game if you're guessing randomly right if you use no intuition whatsoever. So um if you're totally randomly guessing you have uh if you have the complete initial board you have about a 0% chance of winning. Then the mathematics or combinatorics of the Connections board uh indicate that after maybe if you get one category right and you still need to randomly guess through the next three you have about a one in 5,000 one in 6,000 chance of winning which is tiny but it's you know you could maybe do it I don't know and then um most people get stuck on the third and fourth category where it's like oh I don't know like I got two and now all these words how do they relate to each other? So, if you're like screw it, I'm going to guess randomly. Uh, then you have a one in 35% chance. One in 35 chance of winning or about% chance. And that means that okay, well, you're doing pretty good, I think. Um, now the graph coloring problem. We're going to go into a little bit of CS. Uh, who's familiar with the graph coloring problem? Okay, great. We have CS people here. Yes. So, graph coloring involves assigning colors to vertices of a graph. The graph is the structure on the right, which is basically a bunch of nodes and edges. um, there's some number associated with the graph. Not going to get too deep into that, but that I'm doing that chromatic number is important. Um, and when you want to solve a graph coloring problem, you use algorithms that are popularly known, backtracking, greedy coloring. And the graph coloring problem just for interest has um applications in all kinds of areas outside of um you know just science, scheduling, frequency assignment, wireless networks and in Connections, that you can model Connections as a graph coloring an augmented graph coloring problem. So this is a Connections solver that I built on the right that a bunch of puzzles and attempts to organize them into graph coloring um groups. So each of the words 16 words and Connections can be a vertex in this graph. There hidden categories that we already went over. They're colorcoded. And the goal is to color each word node with one of the four categories such that all four words belong to a specific category receive the same color. And then the edge is the strength of the connection that it's thought of to exist between words. So that is basically how related they are is the edge. So the reason why that's important is because that creates the search space for an algorithm or an AI to actually you know play the game effectively um or solve the game effectively. Without that it's falling into the random range of gra of sorting words and it becomes much more difficult. So we have this idea of semantic similarity. It's not enough. I I wish I I've renamed it semantic similarity is not all you need if you get the transformer joke. Um, so this is like it's hard to see here but there's a tree of word relationships between different words. For example, anagrams are related uh could be a a type of category called orthography of words. So um, you know that could be an entire category. Morphology meaning things like that have the same uh suffix like something like kingdom fifom or connectedness um things like that. Then you have other semantic relationships that are not so obvious which are could be things like encyclopedic relationships like for example globe mirror post and sun are all part of the newspaper category and then you have things like associative relationships things that are red or things that are green right strawberry rose Mars etc. And so again um the most I just going back to this policy things that can like for example what a mole can be an animal birthark spy or unit uh that is where the Connections actually just for interest sake is the most complicated for most AIs and people because that's the the poly multiple meaning section is where on a base level people get tripped up any intelligence can get tripped up. So you have this concept of relational alignment. So relational alignment is if you can create a metric that associates two words together, you can have a relational alignment score. So there's different metrics that are associated with a relational alignment. And so I created this heat map simulation on the right which can pick different metrics and show how based on the metric calculations which I'm not showing here that these two things are that these um the two words from a large category are related. Now um the bu story I'm building up is that relational alignment between puzzles uh can help you determine on a computational way whether a puzzle is easy or whether it's hard. So this is for example from an easy puzzle years ago that was uh done versus a hard puzzle. And this is like um people have described this as the solve rate is 19% for the hard puzzle but like 70 something for the easier puzzle. And you can see that there's a a rough overarching coherence or relational alignment score differential between easy and hard. So that differential lets you understand there's a computational process which you can apply. So you can see that time variant relational alignment scores can go across categories and time. So puzzles are easy, puzzles are hard and you see some sort of time variant metric which you know you can you can com you can compute this and you can draw a graph over time. I'm not sure what happened here on 1212. I think oh we had a broken puzzle that day so it was zero. Um, but the idea is that you can see that there could be patterns established from this um alignment score that you compute. Now if it was that easy that would be great but it's not actually that easy because as we have multiple different semantic relationships, we have multiple relational alignment scores. So basically uh two words can be related in multiple ways and they can have different scores across different categories. So some can be semantically or morphologically more strongly related than they are um for example um categorically or encyclopedically related. But uh the idea is that you can create sort of this radar chart which lets you kind of map out some sort of diagram or surface which you can analyze to see how the uh semantic space of the word across different categories looks. That means you have yet another dimension to analyze how your AI can analyze how um to solve a puzzle or your AI or solver or you yourself if you want to think about like this stuff deep more deeply using your um reasoning. So multi-dimensional uh relational alignment distribution was part of the things that I was kind of looking at. So I basically another component of the system I built was the semantic distribution evaluation framework where I taking a bunch of our puzzles and then I'm building this category categorical distribution over time where you can see on the lower right it's hard maybe to see a little bit but there's the different categories like hypernomy morphology orthography things I talked about and the distribution of categories for um the Connections puzzles over time and so you can see I'm counting like which categories over the days fall into which um of these buckets with these dots on this right and I can build a sort of like histogram or count of this association and so you can look at trends and then you can use that data uh that trend data. So now here what it gets a little bit more involved um the graph uh coloring approximation is a search space reduction uh process but then you get to the more complicated idea of graph clustering. Once you add the semantic relationships into the actual uh formulation um you actually start to build multi-dimensional or hyperraphs. And this is just a three-dimensional hyperraph. But if you have multiple semantic relationships, you actually have multi-dimensional hyperraphs. And this is kind of just a demonstration of how the hyperraph converges in three dimensions. Meaning that if you have all these semantic relationships, you're going to have these uh intercluster strengths between uh different nodes and different categories. But you also have the intracluster strength which shows you how strong the relationships are within the clusters.\n\nthat form due to the algorithm you're using. That's important because the graph, this graph gives you more dimensionality and, again, will is a more computational way of using AI to solve this, uh, problem or any, again, solver to solve the problem. Um, so how do you build these semantic graphs? You can use different types of lexical databases or lexical, um, constructors. For example, WordNet, ConceptNet, and other word embeddings can be used to construct these relationships. And so this is a, a flat example of a 2D graph of one puzzle where you see relationships between like different words, like, for example, two words co-occur together, a mouse hunts a cat, a dog is related to a cat, a cat is capable of play, a cat is used for pet. And you can see the complex dimensionality of these conceptual semantic graphs as derived from WordNet, ConceptNet, and word embeddings allows you even more space. So we're increasing the intelligence here. You see, I'm not just doing a reasoning model or dumbly putting into an LLM. I'm actually trying to increase this intelligence space like procedurally so that you can have a trackable and explainable way. You know, explainable AI, that's what I'm all about. This is part of that. So, um, to get to the actual model which does that, anyone familiar with Graph Neural Networks? Okay. So if you've used GNNs, uh, before, that that that's the primary since it's a geometric problem in multi-space, you well, I the primary pro solver that I'm using is a is a graph convolutional neural network which allows you to kind of create, take in a graph as an input and then put like candidate subgraphs that could be solutions as outputs. This is one part of the problem. It's part of a two-part problem where I'm using the graph, the reinforcement learning system. So once we have the graph neural network that's actually outputting candidate graphs, you have edge weights and node weights that are being optimized and then you find out which graph like fits into the candidate solutions. Then you can track the actual structure of the graph, which is just cluster morphology or like how the graph looks. The next visualization, this is the system diagram. Not going to go into it. It's a lot. But, um, I'll just say it's the combination of a machine learning agents with, uh, a graph, a graph-based system for, um, actually with the graph neural network for kind of isolating how what candidate graphs you have. And so this is, I'm almost out of time, but I'll just say that this is kind of like how the visualization looks in 3D space. Once your, um, semantic graphs are, uh, once your semantic graphs are constructed, your graph candidates and the reinforcement learning system is kind of the appropriate way to kind of navigate these subclusters. And you can't actually see the cluster points here because the visualization wasn't super great, but the actual output is kind of like, okay, now this this traversal is allowed to exist. So again, um, after all this stuff, the solvability rate from before to after for a short, a small subset of hard puzzle puzzles increases somewhat reasonably, but now again, this is a work in progress and I tried this against a few puzzles before and after and now the idea is to extend this and like make it more involved for even more puzzles and then get to game development. So why do all this? Or well, our LLMs are great at a bunch of stuff, but you know, they can often make, you know, their own mistakes. LLMs often are trained on internet data and the puzzle solutions are available on the internet. So, who knows if they're just pulling the solutions from the internet? That's one thing that bothered me about, uh, LLM solving these problems. And so, and that's LLM solutions are still a black box. And so, um, the idea is to connect this to the ArcGI benchmark, um, and that kind of thing. So, you know, that benchmark has a partition like a, yeah, uh, a solvability, uh, association. So, we have some next steps and this is pretty much the end of my presentation. I ran a few seconds over, but yeah, if you're interested, talk to me later.\n[Music]",
  "dumpedAt": "2025-07-21T18:43:26.264Z"
}