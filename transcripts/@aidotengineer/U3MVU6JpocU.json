{
  "episodeId": "U3MVU6JpocU",
  "channelSlug": "@aidotengineer",
  "title": "AI Agents, Meet Test Driven Development",
  "publishedAt": "2025-02-22T22:05:15.000Z",
  "rawLines": [
    {
      "lang": "en",
      "text": "hi everybody my name is Anita and I'm",
      "offset": 0.28,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "currently leading gen growth and",
      "offset": 2.48,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "education here at vum and over the last",
      "offset": 4.04,
      "duration": 4.28
    },
    {
      "lang": "en",
      "text": "few years we worked with hundreds of",
      "offset": 6.399,
      "duration": 4.12
    },
    {
      "lang": "en",
      "text": "companies who have successfully deployed",
      "offset": 8.32,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "reliable AI Solutions in production from",
      "offset": 10.519,
      "duration": 4.481
    },
    {
      "lang": "en",
      "text": "simple to more advanced agentic",
      "offset": 13.2,
      "duration": 4.919
    },
    {
      "lang": "en",
      "text": "workflows one thing became very clear",
      "offset": 15,
      "duration": 5.48
    },
    {
      "lang": "en",
      "text": "those companies who have adopted a test",
      "offset": 18.119,
      "duration": 4.721
    },
    {
      "lang": "en",
      "text": "driven development approach were able to",
      "offset": 20.48,
      "duration": 5.4
    },
    {
      "lang": "en",
      "text": "build reliable and stronger systems for",
      "offset": 22.84,
      "duration": 5.32
    },
    {
      "lang": "en",
      "text": "production today I'm excited to share",
      "offset": 25.88,
      "duration": 4.559
    },
    {
      "lang": "en",
      "text": "how you can apply that same approach to",
      "offset": 28.16,
      "duration": 3.959
    },
    {
      "lang": "en",
      "text": "build your own effective agentic",
      "offset": 30.439,
      "duration": 4.601
    },
    {
      "lang": "en",
      "text": "workflow that actually works but before",
      "offset": 32.119,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "we jump in let's take a step back and",
      "offset": 35.04,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "truly understand how we got here in the",
      "offset": 37.719,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "first place I'm so excited to get",
      "offset": 39.76,
      "duration": 4.799
    },
    {
      "lang": "en",
      "text": "started let's do it so let's go back to",
      "offset": 41.64,
      "duration": 6.079
    },
    {
      "lang": "en",
      "text": "2023 everyone was building AI rappers",
      "offset": 44.559,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "and most people argued that there is no",
      "offset": 47.719,
      "duration": 4.921
    },
    {
      "lang": "en",
      "text": "defensibility strategy around them and",
      "offset": 50.079,
      "duration": 5.48
    },
    {
      "lang": "en",
      "text": "fast forward to today we have cursor AI",
      "offset": 52.64,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "which is the most popular and wildly",
      "offset": 55.559,
      "duration": 6.041
    },
    {
      "lang": "en",
      "text": "used AI powered IDE that just hit 100",
      "offset": 57.52,
      "duration": 7.719
    },
    {
      "lang": "en",
      "text": "million AR in just 12 months this is the",
      "offset": 61.6,
      "duration": 6.28
    },
    {
      "lang": "en",
      "text": "fastest growing SAS in the history of",
      "offset": 65.239,
      "duration": 6.361
    },
    {
      "lang": "en",
      "text": "SAS so why and how did this happen",
      "offset": 67.88,
      "duration": 6.64
    },
    {
      "lang": "en",
      "text": "because models got better at coding sure",
      "offset": 71.6,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "because AI adoption skyrocketed that's",
      "offset": 74.52,
      "duration": 5.16
    },
    {
      "lang": "en",
      "text": "absolutely correct because coding was an",
      "offset": 77.28,
      "duration": 4.68
    },
    {
      "lang": "en",
      "text": "obvious first Target that was supposed",
      "offset": 79.68,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "to be disrupted by these AI models there",
      "offset": 81.96,
      "duration": 4.6
    },
    {
      "lang": "en",
      "text": "is no doubt about that but more",
      "offset": 84.24,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "importantly we built new techniques and",
      "offset": 86.56,
      "duration": 4.599
    },
    {
      "lang": "en",
      "text": "patterns on how how we can orchestrate",
      "offset": 89.2,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "these models to work better sync better",
      "offset": 91.159,
      "duration": 4.801
    },
    {
      "lang": "en",
      "text": "with our data and then work effectively",
      "offset": 93.92,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "in production we rely on these",
      "offset": 95.96,
      "duration": 3.479
    },
    {
      "lang": "en",
      "text": "techniques because there are clear",
      "offset": 98.079,
      "duration": 3.08
    },
    {
      "lang": "en",
      "text": "limits to model performance",
      "offset": 99.439,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "hallucinations is still a thing",
      "offset": 101.159,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "overfitting is still a problem and",
      "offset": 103.119,
      "duration": 3.64
    },
    {
      "lang": "en",
      "text": "developers needed more structured",
      "offset": 105.079,
      "duration": 3.72
    },
    {
      "lang": "en",
      "text": "outputs and while model providers",
      "offset": 106.759,
      "duration": 4.601
    },
    {
      "lang": "en",
      "text": "started to ship better tooling to Sol",
      "offset": 108.799,
      "duration": 5.081
    },
    {
      "lang": "en",
      "text": "for all of this we didn't see another",
      "offset": 111.36,
      "duration": 6.119
    },
    {
      "lang": "en",
      "text": "lip similar to the lip between GPD 3.5",
      "offset": 113.88,
      "duration": 7.239
    },
    {
      "lang": "en",
      "text": "and gp4 these big jumps started to slow",
      "offset": 117.479,
      "duration": 6.801
    },
    {
      "lang": "en",
      "text": "down and for years making models bigger",
      "offset": 121.119,
      "duration": 5.801
    },
    {
      "lang": "en",
      "text": "and fitting them more data kept making",
      "offset": 124.28,
      "duration": 5.88
    },
    {
      "lang": "en",
      "text": "them smarter but then we hit a wall no",
      "offset": 126.92,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "matter how much more data we added these",
      "offset": 130.16,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "improvements started to slow down and",
      "offset": 132.36,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "models started to reach their limits on",
      "offset": 134.72,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "existing test but is this true did we",
      "offset": 137.4,
      "duration": 6.72
    },
    {
      "lang": "en",
      "text": "really hit that wall seems like there",
      "offset": 140.72,
      "duration": 6.32
    },
    {
      "lang": "en",
      "text": "were some other avenues and new trining",
      "offset": 144.12,
      "duration": 5.8
    },
    {
      "lang": "en",
      "text": "methods that we still haven't explored",
      "offset": 147.04,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "and so let's see what happened next so I",
      "offset": 149.92,
      "duration": 3.599
    },
    {
      "lang": "en",
      "text": "don't really think that there is an",
      "offset": 152.4,
      "duration": 3.479
    },
    {
      "lang": "en",
      "text": "issue here because since then and this",
      "offset": 153.519,
      "duration": 4.481
    },
    {
      "lang": "en",
      "text": "happened in the last two to 3 months",
      "offset": 155.879,
      "duration": 3.881
    },
    {
      "lang": "en",
      "text": "we've seen some new training methods",
      "offset": 158,
      "duration": 4.599
    },
    {
      "lang": "en",
      "text": "that push the field forward for example",
      "offset": 159.76,
      "duration": 5.479
    },
    {
      "lang": "en",
      "text": "we got the Deep seek R1 model which is",
      "offset": 162.599,
      "duration": 5.201
    },
    {
      "lang": "en",
      "text": "the first model that was trained without",
      "offset": 165.239,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "using any labeled data we call this",
      "offset": 167.8,
      "duration": 5.359
    },
    {
      "lang": "en",
      "text": "method real reinforcement learning and",
      "offset": 170.599,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "this means that this model was able to",
      "offset": 173.159,
      "duration": 5.241
    },
    {
      "lang": "en",
      "text": "learn on its own reportedly this is what",
      "offset": 175.239,
      "duration": 5.761
    },
    {
      "lang": "en",
      "text": "open used to train their reasoning",
      "offset": 178.4,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "models like 01 and 03 and all these",
      "offset": 181,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "reasoning models today they use Chain of",
      "offset": 183.76,
      "duration": 5.64
    },
    {
      "lang": "en",
      "text": "Thought thinking at inference time or at",
      "offset": 186.44,
      "duration": 5.92
    },
    {
      "lang": "en",
      "text": "response time to generate their answers",
      "offset": 189.4,
      "duration": 5.919
    },
    {
      "lang": "en",
      "text": "in turn allowing these models to think",
      "offset": 192.36,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "before they give an answer to our",
      "offset": 195.319,
      "duration": 5
    },
    {
      "lang": "en",
      "text": "questions it enables them to really",
      "offset": 197.48,
      "duration": 5.759
    },
    {
      "lang": "en",
      "text": "solve more complex reasoning problems on",
      "offset": 200.319,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "top of this we're seeing all of these",
      "offset": 203.239,
      "duration": 4.28
    },
    {
      "lang": "en",
      "text": "model providers to provide more",
      "offset": 204.879,
      "duration": 5.241
    },
    {
      "lang": "en",
      "text": "capabilities to their models like use of",
      "offset": 207.519,
      "duration": 5.64
    },
    {
      "lang": "en",
      "text": "tools more capabilities for research um",
      "offset": 210.12,
      "duration": 5.64
    },
    {
      "lang": "en",
      "text": "near perfect OCR accuracy when it comes",
      "offset": 213.159,
      "duration": 5.241
    },
    {
      "lang": "en",
      "text": "to the Gemini 2.0 Flash and really",
      "offset": 215.76,
      "duration": 5.8
    },
    {
      "lang": "en",
      "text": "expand the field forward however",
      "offset": 218.4,
      "duration": 5.96
    },
    {
      "lang": "en",
      "text": "traditional benchmarks are so saturated",
      "offset": 221.56,
      "duration": 5.039
    },
    {
      "lang": "en",
      "text": "so people are starting to introduce new",
      "offset": 224.36,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "ones that will really capture the",
      "offset": 226.599,
      "duration": 3.521
    },
    {
      "lang": "en",
      "text": "performance of these new reasoning",
      "offset": 228.519,
      "duration": 4.041
    },
    {
      "lang": "en",
      "text": "models for example The Benchmark that",
      "offset": 230.12,
      "duration": 3.8
    },
    {
      "lang": "en",
      "text": "you're currently seeing on the slide",
      "offset": 232.56,
      "duration": 4.039
    },
    {
      "lang": "en",
      "text": "here the humanities last last exam it",
      "offset": 233.92,
      "duration": 5
    },
    {
      "lang": "en",
      "text": "measures performance on truly difficult",
      "offset": 236.599,
      "duration": 4.441
    },
    {
      "lang": "en",
      "text": "tasks so if you check the table on the",
      "offset": 238.92,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "slide you can clearly see that even the",
      "offset": 241.04,
      "duration": 5.199
    },
    {
      "lang": "en",
      "text": "latest very smart models struggle with",
      "offset": 243.319,
      "duration": 5.321
    },
    {
      "lang": "en",
      "text": "these challenges so yeah models are",
      "offset": 246.239,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "getting better the field is moving",
      "offset": 248.64,
      "duration": 4.599
    },
    {
      "lang": "en",
      "text": "forward but for an AI product that",
      "offset": 250.56,
      "duration": 4.84
    },
    {
      "lang": "en",
      "text": "actually works in production success",
      "offset": 253.239,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "isn't just about the models anymore it's",
      "offset": 255.4,
      "duration": 4.799
    },
    {
      "lang": "en",
      "text": "about how you build around it and that's",
      "offset": 257.639,
      "duration": 5.401
    },
    {
      "lang": "en",
      "text": "exactly what's been evolving in parallel",
      "offset": 260.199,
      "duration": 5.201
    },
    {
      "lang": "en",
      "text": "to model training so we were learning",
      "offset": 263.04,
      "duration": 4.599
    },
    {
      "lang": "en",
      "text": "how to prompt all of these models better",
      "offset": 265.4,
      "duration": 3.72
    },
    {
      "lang": "en",
      "text": "and we developed more Advanced",
      "offset": 267.639,
      "duration": 3.881
    },
    {
      "lang": "en",
      "text": "Techniques like Chain of Thought then we",
      "offset": 269.12,
      "duration": 4.639
    },
    {
      "lang": "en",
      "text": "thought that we should be able to ground",
      "offset": 271.52,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "all of this models responses using our",
      "offset": 273.759,
      "duration": 6.16
    },
    {
      "lang": "en",
      "text": "own data so rag became an important part",
      "offset": 276.56,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "of our workflows then we learned that",
      "offset": 279.919,
      "duration": 5.401
    },
    {
      "lang": "en",
      "text": "for multi-threaded conversations memory",
      "offset": 282.24,
      "duration": 4.84
    },
    {
      "lang": "en",
      "text": "is going to be the most important thing",
      "offset": 285.32,
      "duration": 4.76
    },
    {
      "lang": "en",
      "text": "that we've had long context from the",
      "offset": 287.08,
      "duration": 5.839
    },
    {
      "lang": "en",
      "text": "latest models enabled new use cases then",
      "offset": 290.08,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "we started to think about hierarchy of",
      "offset": 292.919,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "our responses so we started to",
      "offset": 294.96,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "experiment with graph rack and then just",
      "offset": 296.84,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "lately we're thinking about using all",
      "offset": 299.039,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "this reasoning models that in fact will",
      "offset": 301.24,
      "duration": 4.959
    },
    {
      "lang": "en",
      "text": "take a lot more time to think in real",
      "offset": 303.759,
      "duration": 6.121
    },
    {
      "lang": "en",
      "text": "time however it also develops new areas",
      "offset": 306.199,
      "duration": 5.801
    },
    {
      "lang": "en",
      "text": "and use cases that we can develop and",
      "offset": 309.88,
      "duration": 4.52
    },
    {
      "lang": "en",
      "text": "lately we're thinking about a gentic rag",
      "offset": 312,
      "duration": 5.039
    },
    {
      "lang": "en",
      "text": "making our workflows even more powerful",
      "offset": 314.4,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "so that all this can work on its own and",
      "offset": 317.039,
      "duration": 5.401
    },
    {
      "lang": "en",
      "text": "the field is still evolving but even",
      "offset": 320.4,
      "duration": 4.44
    },
    {
      "lang": "en",
      "text": "using these techniques isn't enough you",
      "offset": 322.44,
      "duration": 5
    },
    {
      "lang": "en",
      "text": "need to understand your problem deeply",
      "offset": 324.84,
      "duration": 4.52
    },
    {
      "lang": "en",
      "text": "and take a test driven development",
      "offset": 327.44,
      "duration": 4.28
    },
    {
      "lang": "en",
      "text": "approach to find the right mix of",
      "offset": 329.36,
      "duration": 5.119
    },
    {
      "lang": "en",
      "text": "techniques models and logic that will",
      "offset": 331.72,
      "duration": 5.4
    },
    {
      "lang": "en",
      "text": "actually work for your use case and this",
      "offset": 334.479,
      "duration": 6.081
    },
    {
      "lang": "en",
      "text": "actually brings me to the main first",
      "offset": 337.12,
      "duration": 6.6
    },
    {
      "lang": "en",
      "text": "topic of this presentation test driven",
      "offset": 340.56,
      "duration": 5.639
    },
    {
      "lang": "en",
      "text": "development for building reliable AI",
      "offset": 343.72,
      "duration": 5.72
    },
    {
      "lang": "en",
      "text": "products because the best AI teams that",
      "offset": 346.199,
      "duration": 5.881
    },
    {
      "lang": "en",
      "text": "I've seen follow this structured",
      "offset": 349.44,
      "duration": 5.199
    },
    {
      "lang": "en",
      "text": "approach they start to experiment then",
      "offset": 352.08,
      "duration": 5
    },
    {
      "lang": "en",
      "text": "they evaluate it scale then finally when",
      "offset": 354.639,
      "duration": 4.641
    },
    {
      "lang": "en",
      "text": "they deploy in production they never",
      "offset": 357.08,
      "duration": 4.44
    },
    {
      "lang": "en",
      "text": "stop stop working on their workflow they",
      "offset": 359.28,
      "duration": 4.44
    },
    {
      "lang": "en",
      "text": "capture all of those responses to then",
      "offset": 361.52,
      "duration": 5.119
    },
    {
      "lang": "en",
      "text": "continuously monitor observe and improve",
      "offset": 363.72,
      "duration": 5.919
    },
    {
      "lang": "en",
      "text": "their product for their customers let's",
      "offset": 366.639,
      "duration": 5.641
    },
    {
      "lang": "en",
      "text": "look at what you can do at every stage",
      "offset": 369.639,
      "duration": 4.881
    },
    {
      "lang": "en",
      "text": "of this process before you build",
      "offset": 372.28,
      "duration": 4.359
    },
    {
      "lang": "en",
      "text": "anything production grade you need to",
      "offset": 374.52,
      "duration": 4.44
    },
    {
      "lang": "en",
      "text": "experiment a lot you need to prove",
      "offset": 376.639,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "whether these AI models can actually",
      "offset": 378.96,
      "duration": 4.28
    },
    {
      "lang": "en",
      "text": "solve for your use case so you should",
      "offset": 380.8,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "try different prompting techniques for",
      "offset": 383.24,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "example fuse shot or Chain of Thought",
      "offset": 384.88,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "some of these will work great for simple",
      "offset": 387,
      "duration": 4.039
    },
    {
      "lang": "en",
      "text": "tasks and other will help with a bit",
      "offset": 388.96,
      "duration": 4.239
    },
    {
      "lang": "en",
      "text": "more complex reasoning you should test",
      "offset": 391.039,
      "duration": 4.201
    },
    {
      "lang": "en",
      "text": "various techniques prom chaining is",
      "offset": 393.199,
      "duration": 4.801
    },
    {
      "lang": "en",
      "text": "usually very uh well received because",
      "offset": 395.24,
      "duration": 4.44
    },
    {
      "lang": "en",
      "text": "it's going to work better if you split",
      "offset": 398,
      "duration": 3.96
    },
    {
      "lang": "en",
      "text": "your instructions in multiple prompts or",
      "offset": 399.68,
      "duration": 4.799
    },
    {
      "lang": "en",
      "text": "you can adopt a more agentic workflows",
      "offset": 401.96,
      "duration": 4.84
    },
    {
      "lang": "en",
      "text": "like react that will have a stage to",
      "offset": 404.479,
      "duration": 4.521
    },
    {
      "lang": "en",
      "text": "plan and then reason and refine before",
      "offset": 406.8,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "it actually gives you an answer what is",
      "offset": 409,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "really an important part in this stage",
      "offset": 411.199,
      "duration": 4.041
    },
    {
      "lang": "en",
      "text": "is that you need to involve your domain",
      "offset": 413.08,
      "duration": 4.44
    },
    {
      "lang": "en",
      "text": "experts um because Engineers shouldn't",
      "offset": 415.24,
      "duration": 4.76
    },
    {
      "lang": "en",
      "text": "be the ones who are tweaking prompts uh",
      "offset": 417.52,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "and bringing all these experts will",
      "offset": 420,
      "duration": 3.479
    },
    {
      "lang": "en",
      "text": "actually save a lot of your engineering",
      "offset": 421.68,
      "duration": 4.639
    },
    {
      "lang": "en",
      "text": "time because once you do this phase",
      "offset": 423.479,
      "duration": 5.241
    },
    {
      "lang": "en",
      "text": "right then you will actually have a",
      "offset": 426.319,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "proof that this works and that",
      "offset": 428.72,
      "duration": 5.08
    },
    {
      "lang": "en",
      "text": "engineering time needs to be involved at",
      "offset": 430.479,
      "duration": 4.961
    },
    {
      "lang": "en",
      "text": "this stage you should also stay model",
      "offset": 433.8,
      "duration": 3.88
    },
    {
      "lang": "en",
      "text": "agnostic uh you should incorporate and",
      "offset": 435.44,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "has different models and especially when",
      "offset": 437.68,
      "duration": 3.16
    },
    {
      "lang": "en",
      "text": "it comes to your use case you need to",
      "offset": 439.28,
      "duration": 3.88
    },
    {
      "lang": "en",
      "text": "think about Which models can do the job",
      "offset": 440.84,
      "duration": 5
    },
    {
      "lang": "en",
      "text": "better so in such case you can um maybe",
      "offset": 443.16,
      "duration": 5.24
    },
    {
      "lang": "en",
      "text": "use some uh different uh models like",
      "offset": 445.84,
      "duration": 4.919
    },
    {
      "lang": "en",
      "text": "Gemini 2.0 flash which is actually",
      "offset": 448.4,
      "duration": 4.68
    },
    {
      "lang": "en",
      "text": "really well at OCR uh and something that",
      "offset": 450.759,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "we've seen work really well lately so",
      "offset": 453.08,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "let's say that at this stage you know",
      "offset": 455.639,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "that U these AI models can actually work",
      "offset": 457.479,
      "duration": 4.44
    },
    {
      "lang": "en",
      "text": "you have a few examples that these",
      "offset": 460.199,
      "duration": 3.96
    },
    {
      "lang": "en",
      "text": "models have like really good performance",
      "offset": 461.919,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "on but how can you test whether this",
      "offset": 464.159,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "will actually work in production when",
      "offset": 466.319,
      "duration": 4.84
    },
    {
      "lang": "en",
      "text": "you will potentially have hundreds if",
      "offset": 469.039,
      "duration": 4.481
    },
    {
      "lang": "en",
      "text": "not thousands or millions of requests",
      "offset": 471.159,
      "duration": 3.88
    },
    {
      "lang": "en",
      "text": "per minute and so this is where",
      "offset": 473.52,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "Evolution comes in in this stage you",
      "offset": 475.039,
      "duration": 5.041
    },
    {
      "lang": "en",
      "text": "actually create a data set of hundreds",
      "offset": 477.44,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "of examples that you're going to test",
      "offset": 480.08,
      "duration": 3.88
    },
    {
      "lang": "en",
      "text": "your models and workflows against and so",
      "offset": 481.599,
      "duration": 4.6
    },
    {
      "lang": "en",
      "text": "at this stage you need to uh try to",
      "offset": 483.96,
      "duration": 4.76
    },
    {
      "lang": "en",
      "text": "balance quality and cost and latency and",
      "offset": 486.199,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "privacy and you're definitely going to",
      "offset": 488.72,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "make a lot of tradeoffs because no AI",
      "offset": 490.52,
      "duration": 4.2
    },
    {
      "lang": "en",
      "text": "system is going to get all of this",
      "offset": 492.96,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "perfectly but for example if you need",
      "offset": 494.72,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "high quality maybe you can sacrifice",
      "offset": 496.96,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "speed if cost is critical you might need",
      "offset": 499.039,
      "duration": 5.16
    },
    {
      "lang": "en",
      "text": "some lighter and cheaper model and this",
      "offset": 501.52,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "is the stage where where you need to",
      "offset": 504.199,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "Define your priorities because it's",
      "offset": 505.919,
      "duration": 3.761
    },
    {
      "lang": "en",
      "text": "always better if you define your",
      "offset": 507.639,
      "duration": 5.001
    },
    {
      "lang": "en",
      "text": "priorities earlier in the process you",
      "offset": 509.68,
      "duration": 5
    },
    {
      "lang": "en",
      "text": "should use ground through data where",
      "offset": 512.64,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "possible if you want to evaluate all",
      "offset": 514.68,
      "duration": 3.799
    },
    {
      "lang": "en",
      "text": "these workflows having your subject",
      "offset": 516.56,
      "duration": 4.479
    },
    {
      "lang": "en",
      "text": "matter experts design these databases",
      "offset": 518.479,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "and test these models and workflows",
      "offset": 521.039,
      "duration": 4.961
    },
    {
      "lang": "en",
      "text": "against is going to be very very useful",
      "offset": 522.8,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "synthetic benchmarks help however they",
      "offset": 526,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "will not really evaluate these models",
      "offset": 528.48,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "for your own use case so it's usually",
      "offset": 531.2,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "very very powerful if you can use your",
      "offset": 533.68,
      "duration": 5.159
    },
    {
      "lang": "en",
      "text": "ground through data but don't worry even",
      "offset": 536.24,
      "duration": 4.599
    },
    {
      "lang": "en",
      "text": "if you do not have ground through data",
      "offset": 538.839,
      "duration": 5.721
    },
    {
      "lang": "en",
      "text": "you can use an llm to evaluate another",
      "offset": 540.839,
      "duration": 6.801
    },
    {
      "lang": "en",
      "text": "model's response this is actually a very",
      "offset": 544.56,
      "duration": 5.56
    },
    {
      "lang": "en",
      "text": "standard and reliable way when it comes",
      "offset": 547.64,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "to evaluating your",
      "offset": 550.12,
      "duration": 4.44
    },
    {
      "lang": "en",
      "text": "models very importantly at this stage",
      "offset": 551.72,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "you should make sure that you're using a",
      "offset": 554.56,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "flexible testing framework no matter if",
      "offset": 556.68,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "you're building this in house or if",
      "offset": 559.12,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "you're using any external service your",
      "offset": 561,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "AI isn't static so your workflow should",
      "offset": 563.519,
      "duration": 4.801
    },
    {
      "lang": "en",
      "text": "also be dynamic it should be able to",
      "offset": 566.2,
      "duration": 3.879
    },
    {
      "lang": "en",
      "text": "capture all of this different",
      "offset": 568.32,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "non-deterministic responses you need to",
      "offset": 570.079,
      "duration": 4.76
    },
    {
      "lang": "en",
      "text": "be able to Define custom metrics you",
      "offset": 572.399,
      "duration": 4.961
    },
    {
      "lang": "en",
      "text": "need to be able to write those metcs",
      "offset": 574.839,
      "duration": 5.161
    },
    {
      "lang": "en",
      "text": "metrics using python or typescript so",
      "offset": 577.36,
      "duration": 4.76
    },
    {
      "lang": "en",
      "text": "you shouldn't be looking at a very",
      "offset": 580,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "strict framework customizability is a",
      "offset": 582.12,
      "duration": 6.399
    },
    {
      "lang": "en",
      "text": "very big thing here and then finally you",
      "offset": 584.72,
      "duration": 6.08
    },
    {
      "lang": "en",
      "text": "should run evaluations at every stage",
      "offset": 588.519,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "you should have guard rails that will",
      "offset": 590.8,
      "duration": 3.88
    },
    {
      "lang": "en",
      "text": "check internal nodes and whether these",
      "offset": 592.519,
      "duration": 4.281
    },
    {
      "lang": "en",
      "text": "models are actually producing responses",
      "offset": 594.68,
      "duration": 4.719
    },
    {
      "lang": "en",
      "text": "at every step in your uh workflow",
      "offset": 596.8,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "actually producing responses that are",
      "offset": 599.399,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "correct at every step in your workflow",
      "offset": 601.12,
      "duration": 4.6
    },
    {
      "lang": "en",
      "text": "and then you should also test while your",
      "offset": 603.32,
      "duration": 4.44
    },
    {
      "lang": "en",
      "text": "prototyping but then you should also",
      "offset": 605.72,
      "duration": 4.6
    },
    {
      "lang": "en",
      "text": "utilize this evaluation phase to come",
      "offset": 607.76,
      "duration": 5.8
    },
    {
      "lang": "en",
      "text": "back once you have some real data but",
      "offset": 610.32,
      "duration": 4.84
    },
    {
      "lang": "en",
      "text": "how are you going to get some real data",
      "offset": 613.56,
      "duration": 3.88
    },
    {
      "lang": "en",
      "text": "so let's say that you evaluate your",
      "offset": 615.16,
      "duration": 4.679
    },
    {
      "lang": "en",
      "text": "workflows extensively with your subject",
      "offset": 617.44,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "matter experts with your data that",
      "offset": 619.839,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "they've created and let's say that",
      "offset": 621.68,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "you're now satisfied with the product",
      "offset": 623.68,
      "duration": 3.719
    },
    {
      "lang": "en",
      "text": "that you have so you're ready to deploy",
      "offset": 625.36,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "it in production so once that that",
      "offset": 627.399,
      "duration": 5.401
    },
    {
      "lang": "en",
      "text": "happens what do you need to do is your",
      "offset": 629.76,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "job done here when it comes to AI",
      "offset": 632.8,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "development you need to monitor more",
      "offset": 635.36,
      "duration": 4.479
    },
    {
      "lang": "en",
      "text": "things than deterministic outputs you",
      "offset": 637.12,
      "duration": 5.32
    },
    {
      "lang": "en",
      "text": "need to log all llm calls you need to",
      "offset": 639.839,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "track all of those inputs and outputs",
      "offset": 642.44,
      "duration": 4.68
    },
    {
      "lang": "en",
      "text": "and the latency because AI models they",
      "offset": 644.639,
      "duration": 4.44
    },
    {
      "lang": "en",
      "text": "really they're really really",
      "offset": 647.12,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "unpredictable so you need to be able to",
      "offset": 649.079,
      "duration": 4.681
    },
    {
      "lang": "en",
      "text": "debug issues and understand how your AI",
      "offset": 651.279,
      "duration": 5.281
    },
    {
      "lang": "en",
      "text": "behaves at every step of the way and",
      "offset": 653.76,
      "duration": 4.639
    },
    {
      "lang": "en",
      "text": "this is becoming extremely more",
      "offset": 656.56,
      "duration": 3.88
    },
    {
      "lang": "en",
      "text": "important with a gentic workflows",
      "offset": 658.399,
      "duration": 3.761
    },
    {
      "lang": "en",
      "text": "because gentic workflows are more",
      "offset": 660.44,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "complex workflows that can take",
      "offset": 662.16,
      "duration": 4.76
    },
    {
      "lang": "en",
      "text": "different paths in your workflow and",
      "offset": 664.2,
      "duration": 5.16
    },
    {
      "lang": "en",
      "text": "make decisions on their own you should",
      "offset": 666.92,
      "duration": 5.359
    },
    {
      "lang": "en",
      "text": "also handle API reliability you need to",
      "offset": 669.36,
      "duration": 5.599
    },
    {
      "lang": "en",
      "text": "maintain uh stability in your API calls",
      "offset": 672.279,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "you need to have retries you need to",
      "offset": 674.959,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "have fallback logic to prevent outages",
      "offset": 676.68,
      "duration": 5.32
    },
    {
      "lang": "en",
      "text": "for example two months ago open AI had",
      "offset": 679.839,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "four hours of downtime so if you had a",
      "offset": 682,
      "duration": 5.639
    },
    {
      "lang": "en",
      "text": "fallback logic in your productionize",
      "offset": 684.639,
      "duration": 6.64
    },
    {
      "lang": "en",
      "text": "solution then your um AI will know to go",
      "offset": 687.639,
      "duration": 5.561
    },
    {
      "lang": "en",
      "text": "back to another model and use another",
      "offset": 691.279,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "model instead you should definitely have",
      "offset": 693.2,
      "duration": 4.52
    },
    {
      "lang": "en",
      "text": "Version Control and staging and you",
      "offset": 695.68,
      "duration": 3.719
    },
    {
      "lang": "en",
      "text": "should always deploy in control",
      "offset": 697.72,
      "duration": 4.239
    },
    {
      "lang": "en",
      "text": "environments before you roll out to The",
      "offset": 699.399,
      "duration": 5.56
    },
    {
      "lang": "en",
      "text": "Wider uh public because with it when it",
      "offset": 701.959,
      "duration": 5.641
    },
    {
      "lang": "en",
      "text": "comes to AI you need to be care careful",
      "offset": 704.959,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "that once you update a prompt you're not",
      "offset": 707.6,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "introducing a regression to another",
      "offset": 709.839,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "prompt or part of your workflow so you",
      "offset": 712,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "need to ensure that all these new",
      "offset": 714.639,
      "duration": 3.64
    },
    {
      "lang": "en",
      "text": "updates they won't break whatever you",
      "offset": 716.48,
      "duration": 3.72
    },
    {
      "lang": "en",
      "text": "have in production and the most",
      "offset": 718.279,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "important part here is that make sure to",
      "offset": 720.2,
      "duration": 5.16
    },
    {
      "lang": "en",
      "text": "decouple your deployments from your",
      "offset": 722.839,
      "duration": 5.601
    },
    {
      "lang": "en",
      "text": "scheduled app deployment schedule",
      "offset": 725.36,
      "duration": 6.32
    },
    {
      "lang": "en",
      "text": "because the chances are that um you will",
      "offset": 728.44,
      "duration": 5.839
    },
    {
      "lang": "en",
      "text": "need to update your AI features more",
      "offset": 731.68,
      "duration": 5
    },
    {
      "lang": "en",
      "text": "frequently that you will need to update",
      "offset": 734.279,
      "duration": 4.881
    },
    {
      "lang": "en",
      "text": "your app as a whole so make sure to do",
      "offset": 736.68,
      "duration": 4.839
    },
    {
      "lang": "en",
      "text": "that and so let's say that now you have",
      "offset": 739.16,
      "duration": 5.16
    },
    {
      "lang": "en",
      "text": "deployed you're starting to capture all",
      "offset": 741.519,
      "duration": 5.161
    },
    {
      "lang": "en",
      "text": "of your responses from your users and",
      "offset": 744.32,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "create a feedback loop to identify edge",
      "offset": 746.68,
      "duration": 5.519
    },
    {
      "lang": "en",
      "text": "cases that you capture in production to",
      "offset": 749.76,
      "duration": 5.759
    },
    {
      "lang": "en",
      "text": "then continuously improve and make your",
      "offset": 752.199,
      "duration": 6.281
    },
    {
      "lang": "en",
      "text": "workflow better you can capture all of",
      "offset": 755.519,
      "duration": 5.481
    },
    {
      "lang": "en",
      "text": "these then run evaluations again and",
      "offset": 758.48,
      "duration": 4.76
    },
    {
      "lang": "en",
      "text": "test whether um new prompts that you",
      "offset": 761,
      "duration": 5.24
    },
    {
      "lang": "en",
      "text": "develop will solve for this new cases",
      "offset": 763.24,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "you should also think about building a",
      "offset": 766.24,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "caching layer because if your system is",
      "offset": 767.88,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "handling some repeat queries caching can",
      "offset": 770.24,
      "duration": 4.68
    },
    {
      "lang": "en",
      "text": "drastically reduce costs and improve",
      "offset": 772.92,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "latency so for example instead of",
      "offset": 774.92,
      "duration": 4.279
    },
    {
      "lang": "en",
      "text": "calling an expensive llm for the same",
      "offset": 776.839,
      "duration": 4.521
    },
    {
      "lang": "en",
      "text": "request multiple times you can store and",
      "offset": 779.199,
      "duration": 4.561
    },
    {
      "lang": "en",
      "text": "serve frequent responses instantly and",
      "offset": 781.36,
      "duration": 4.279
    },
    {
      "lang": "en",
      "text": "this is something that is a standard",
      "offset": 783.76,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "these days when it comes to building",
      "offset": 785.639,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "with AI and finally let's say that your",
      "offset": 787.36,
      "duration": 4.36
    },
    {
      "lang": "en",
      "text": "product has been running reliably in",
      "offset": 789.72,
      "duration": 4.44
    },
    {
      "lang": "en",
      "text": "production for uh a longer period of",
      "offset": 791.72,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "time time that you feel comfortable to",
      "offset": 794.16,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "then go back to that data and use it to",
      "offset": 796.6,
      "duration": 5.679
    },
    {
      "lang": "en",
      "text": "fine-tune a custom model that will um",
      "offset": 799.04,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "basically uh create better responses for",
      "offset": 802.279,
      "duration": 4.841
    },
    {
      "lang": "en",
      "text": "your specific use case uh can reduce",
      "offset": 804.72,
      "duration": 4.919
    },
    {
      "lang": "en",
      "text": "Reliance on API calls and in fact can",
      "offset": 807.12,
      "duration": 7.04
    },
    {
      "lang": "en",
      "text": "work with lower costs and so this",
      "offset": 809.639,
      "duration": 7.081
    },
    {
      "lang": "en",
      "text": "process is becoming even more important",
      "offset": 814.16,
      "duration": 5
    },
    {
      "lang": "en",
      "text": "than ever when it comes with agentic",
      "offset": 816.72,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "workflows because these workflows are",
      "offset": 819.16,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "going to use a wide range of tools they",
      "offset": 821.12,
      "duration": 6.88
    },
    {
      "lang": "en",
      "text": "will um call different apis they will",
      "offset": 823.88,
      "duration": 7.12
    },
    {
      "lang": "en",
      "text": "have multi-agent structures that will",
      "offset": 828,
      "duration": 5.519
    },
    {
      "lang": "en",
      "text": "execute a lot of things in parallel so",
      "offset": 831,
      "duration": 4.44
    },
    {
      "lang": "en",
      "text": "when it comes to evaluation with a",
      "offset": 833.519,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "gentic workflows and with this test",
      "offset": 835.44,
      "duration": 4.12
    },
    {
      "lang": "en",
      "text": "driven approach it's not just just about",
      "offset": 837.279,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "measuring performance at every step in",
      "offset": 839.56,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "your workflow because you also need to",
      "offset": 841.6,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "assess the behavior of these agents to",
      "offset": 843.8,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "so that you can make sure that they're",
      "offset": 846.72,
      "duration": 4.2
    },
    {
      "lang": "en",
      "text": "making the right decisions and following",
      "offset": 848.68,
      "duration": 4.839
    },
    {
      "lang": "en",
      "text": "the intended logic and this year more",
      "offset": 850.92,
      "duration": 4.359
    },
    {
      "lang": "en",
      "text": "than ever everyone is talking about",
      "offset": 853.519,
      "duration": 4.12
    },
    {
      "lang": "en",
      "text": "agentic workflows but what does that",
      "offset": 855.279,
      "duration": 4.68
    },
    {
      "lang": "en",
      "text": "actually mean uh I would love to talk",
      "offset": 857.639,
      "duration": 4.241
    },
    {
      "lang": "en",
      "text": "more about how you can build all this",
      "offset": 859.959,
      "duration": 4.481
    },
    {
      "lang": "en",
      "text": "agentic workflows but I'm not here to",
      "offset": 861.88,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "give you the perfect definition of what",
      "offset": 864.44,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "an AI agent is and instead I'm going to",
      "offset": 866.12,
      "duration": 4.68
    },
    {
      "lang": "en",
      "text": "try to Define different agentic",
      "offset": 869.16,
      "duration": 4.119
    },
    {
      "lang": "en",
      "text": "behaviors and some different levels on",
      "offset": 870.8,
      "duration": 6.12
    },
    {
      "lang": "en",
      "text": "how um they can be built so if you think",
      "offset": 873.279,
      "duration": 6.841
    },
    {
      "lang": "en",
      "text": "about it every AI workflow has some",
      "offset": 876.92,
      "duration": 6.2
    },
    {
      "lang": "en",
      "text": "level of ener gentic behavior in it it's",
      "offset": 880.12,
      "duration": 5.48
    },
    {
      "lang": "en",
      "text": "just a question of how much control",
      "offset": 883.12,
      "duration": 5.56
    },
    {
      "lang": "en",
      "text": "reasoning and autonomy it has so we've",
      "offset": 885.6,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "looked at the past the present and where",
      "offset": 888.68,
      "duration": 4.519
    },
    {
      "lang": "en",
      "text": "we're headed and from that we put",
      "offset": 890.48,
      "duration": 5.359
    },
    {
      "lang": "en",
      "text": "together this framework where we Define",
      "offset": 893.199,
      "duration": 5.601
    },
    {
      "lang": "en",
      "text": "four or five different levels of gentic",
      "offset": 895.839,
      "duration": 5.641
    },
    {
      "lang": "en",
      "text": "behav Behavior I'll go into more details",
      "offset": 898.8,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "on each level but keep in mind that this",
      "offset": 901.48,
      "duration": 4.84
    },
    {
      "lang": "en",
      "text": "is not a final framework it's not set in",
      "offset": 903.36,
      "duration": 5.96
    },
    {
      "lang": "en",
      "text": "stone as models evolve this can expand",
      "offset": 906.32,
      "duration": 5.48
    },
    {
      "lang": "en",
      "text": "the things can blur and um a lot of",
      "offset": 909.32,
      "duration": 4.879
    },
    {
      "lang": "en",
      "text": "things can shift but for now this will",
      "offset": 911.8,
      "duration": 4.599
    },
    {
      "lang": "en",
      "text": "give us a way to define where we are",
      "offset": 914.199,
      "duration": 5.481
    },
    {
      "lang": "en",
      "text": "today and what we expect to see next at",
      "offset": 916.399,
      "duration": 5.481
    },
    {
      "lang": "en",
      "text": "this stage you have an llm call you",
      "offset": 919.68,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "retrieve some data from your vectory",
      "offset": 921.88,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "database and then you might have some",
      "offset": 923.92,
      "duration": 4.279
    },
    {
      "lang": "en",
      "text": "inline evals and finally you're going to",
      "offset": 925.56,
      "duration": 4.839
    },
    {
      "lang": "en",
      "text": "uh get some response from this workflow",
      "offset": 928.199,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "so you can notice that in this workflow",
      "offset": 930.399,
      "duration": 3.521
    },
    {
      "lang": "en",
      "text": "there's no reasoning planning or",
      "offset": 932.279,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "decision making Beyond what's baked into",
      "offset": 933.92,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "the prompt and the Model Behavior so the",
      "offset": 936.44,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "model is doing all the reasoning here",
      "offset": 938.88,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "within the prompt itself and so there is",
      "offset": 940.839,
      "duration": 5.161
    },
    {
      "lang": "en",
      "text": "no external agenda organizing uh the",
      "offset": 943.04,
      "duration": 5
    },
    {
      "lang": "en",
      "text": "decisions or planning some actions",
      "offset": 946,
      "duration": 3.639
    },
    {
      "lang": "en",
      "text": "however there is some reasoning and some",
      "offset": 948.04,
      "duration": 4.599
    },
    {
      "lang": "en",
      "text": "agentic Behavior at the models level and",
      "offset": 949.639,
      "duration": 7.041
    },
    {
      "lang": "en",
      "text": "so if we move from l0 to L1 we can see",
      "offset": 952.639,
      "duration": 6.921
    },
    {
      "lang": "en",
      "text": "that in this stage our workplace can now",
      "offset": 956.68,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "use a lot of tools and so this EA System",
      "offset": 959.56,
      "duration": 6.24
    },
    {
      "lang": "en",
      "text": "is no longer just calling apis it no now",
      "offset": 962.36,
      "duration": 5.88
    },
    {
      "lang": "en",
      "text": "knows when to call them and when to make",
      "offset": 965.8,
      "duration": 5.039
    },
    {
      "lang": "en",
      "text": "those actions and so this is where we",
      "offset": 968.24,
      "duration": 4.839
    },
    {
      "lang": "en",
      "text": "start to see more gentic Behavior",
      "offset": 970.839,
      "duration": 4.601
    },
    {
      "lang": "en",
      "text": "because the model can decide whether uh",
      "offset": 973.079,
      "duration": 4.961
    },
    {
      "lang": "en",
      "text": "it will call a specific tool or whether",
      "offset": 975.44,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "it will call our Vector database to",
      "offset": 978.04,
      "duration": 5.08
    },
    {
      "lang": "en",
      "text": "retrieve more data before it actually uh",
      "offset": 980.48,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "generates an output memory here starts",
      "offset": 983.12,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "to play a key role because we're going",
      "offset": 985.44,
      "duration": 3.48
    },
    {
      "lang": "en",
      "text": "to have multi-threaded uh conver",
      "offset": 987.04,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "conversations and then uh all of this",
      "offset": 988.92,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "will potentially happen in parallel so",
      "offset": 991.199,
      "duration": 4.361
    },
    {
      "lang": "en",
      "text": "we need to capture all context",
      "offset": 993.319,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "throughout the whole workflow evaluation",
      "offset": 995.56,
      "duration": 5.279
    },
    {
      "lang": "en",
      "text": "is also needed at every state uh step of",
      "offset": 997.959,
      "duration": 4.721
    },
    {
      "lang": "en",
      "text": "the way here because we need to ensure",
      "offset": 1000.839,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "that this models are making the right",
      "offset": 1002.68,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "decisions using the right tools and",
      "offset": 1004.92,
      "duration": 5.56
    },
    {
      "lang": "en",
      "text": "returning uh accurate responses but this",
      "offset": 1007.16,
      "duration": 5.72
    },
    {
      "lang": "en",
      "text": "workflows can be as simple as on the",
      "offset": 1010.48,
      "duration": 4.359
    },
    {
      "lang": "en",
      "text": "slide right here or even more",
      "offset": 1012.88,
      "duration": 3.399
    },
    {
      "lang": "en",
      "text": "complicated where you're going to have",
      "offset": 1014.839,
      "duration": 4.12
    },
    {
      "lang": "en",
      "text": "more different branching happen uh",
      "offset": 1016.279,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "happens at every stage in this workflow",
      "offset": 1018.959,
      "duration": 3.8
    },
    {
      "lang": "en",
      "text": "where you can have 10 different tools",
      "offset": 1020.68,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "and the agent needs to reason whether",
      "offset": 1022.759,
      "duration": 3.8
    },
    {
      "lang": "en",
      "text": "it's going to call the first five or the",
      "offset": 1024.52,
      "duration": 5.24
    },
    {
      "lang": "en",
      "text": "or the last two and so this is uh where",
      "offset": 1026.559,
      "duration": 5.48
    },
    {
      "lang": "en",
      "text": "again we see a lot more agentic Behavior",
      "offset": 1029.76,
      "duration": 5.84
    },
    {
      "lang": "en",
      "text": "but L2 is where we actually see that um",
      "offset": 1032.039,
      "duration": 6.201
    },
    {
      "lang": "en",
      "text": "these workflows now move from simple",
      "offset": 1035.6,
      "duration": 5.359
    },
    {
      "lang": "en",
      "text": "tool use which is not in many cases it's",
      "offset": 1038.24,
      "duration": 5.64
    },
    {
      "lang": "en",
      "text": "not a simple tool use like the previous",
      "offset": 1040.959,
      "duration": 5.48
    },
    {
      "lang": "en",
      "text": "workflows can be very complex but now we",
      "offset": 1043.88,
      "duration": 5.039
    },
    {
      "lang": "en",
      "text": "see some structured reasoning this work",
      "offset": 1046.439,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "workflow will notice triggers it can",
      "offset": 1048.919,
      "duration": 6.201
    },
    {
      "lang": "en",
      "text": "plan actions and it can execute tasks in",
      "offset": 1051.799,
      "duration": 5.721
    },
    {
      "lang": "en",
      "text": "a structured sequence so this means that",
      "offset": 1055.12,
      "duration": 4.36
    },
    {
      "lang": "en",
      "text": "it can break down a task into multiple",
      "offset": 1057.52,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "steps it can retrieve some information",
      "offset": 1059.48,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "it can decide to call another tool it",
      "offset": 1061.6,
      "duration": 4.28
    },
    {
      "lang": "en",
      "text": "can evaluate its usefulness if it thinks",
      "offset": 1063.72,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "that it needs to be refined at that",
      "offset": 1065.88,
      "duration": 4.039
    },
    {
      "lang": "en",
      "text": "stage and once it does this in a",
      "offset": 1067.64,
      "duration": 4.76
    },
    {
      "lang": "en",
      "text": "continuous loop it can generate the",
      "offset": 1069.919,
      "duration": 5.161
    },
    {
      "lang": "en",
      "text": "final output but um you can notice that",
      "offset": 1072.4,
      "duration": 5.159
    },
    {
      "lang": "en",
      "text": "atic behavior here starts to look more",
      "offset": 1075.08,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "intentional because the system isn't",
      "offset": 1077.559,
      "duration": 5.321
    },
    {
      "lang": "en",
      "text": "just calling the tools that are listed",
      "offset": 1079.72,
      "duration": 5.439
    },
    {
      "lang": "en",
      "text": "uh for their use it's also actively",
      "offset": 1082.88,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "deciding what needs to be done and",
      "offset": 1085.159,
      "duration": 4.121
    },
    {
      "lang": "en",
      "text": "spending more time to think what needs",
      "offset": 1087.2,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "to be done instead of just deciding",
      "offset": 1089.28,
      "duration": 4.36
    },
    {
      "lang": "en",
      "text": "whether a tool should be called and so",
      "offset": 1091.36,
      "duration": 5.319
    },
    {
      "lang": "en",
      "text": "at this stage um one part is that the",
      "offset": 1093.64,
      "duration": 5.399
    },
    {
      "lang": "en",
      "text": "process is still finite so once this",
      "offset": 1096.679,
      "duration": 5.721
    },
    {
      "lang": "en",
      "text": "workflow completes the steps um as it",
      "offset": 1099.039,
      "duration": 5.921
    },
    {
      "lang": "en",
      "text": "plans to complete them it will terminate",
      "offset": 1102.4,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "rather than it will run continuously but",
      "offset": 1104.96,
      "duration": 4.36
    },
    {
      "lang": "en",
      "text": "it's a Leap Forward",
      "offset": 1107.6,
      "duration": 5.84
    },
    {
      "lang": "en",
      "text": "um from just calling uh tools and so uh",
      "offset": 1109.32,
      "duration": 7.52
    },
    {
      "lang": "en",
      "text": "L3 however is where we see more autonomy",
      "offset": 1113.44,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "where we see more uh decision making",
      "offset": 1116.84,
      "duration": 6.36
    },
    {
      "lang": "en",
      "text": "that are not um defined by us as the",
      "offset": 1119.12,
      "duration": 6.6
    },
    {
      "lang": "en",
      "text": "creators of this workload so the L for",
      "offset": 1123.2,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "system can proactively take actions",
      "offset": 1125.72,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "without waiting for direct input so",
      "offset": 1128.08,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "instead of responding responding to a",
      "offset": 1130.36,
      "duration": 4.52
    },
    {
      "lang": "en",
      "text": "single request and then terminating this",
      "offset": 1132.24,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "one will stay alive and will",
      "offset": 1134.88,
      "duration": 4.679
    },
    {
      "lang": "en",
      "text": "continuously monitor its environment and",
      "offset": 1136.96,
      "duration": 5.64
    },
    {
      "lang": "en",
      "text": "it will react as needed so for example",
      "offset": 1139.559,
      "duration": 5.081
    },
    {
      "lang": "en",
      "text": "um this means that it can uh look at",
      "offset": 1142.6,
      "duration": 4.04
    },
    {
      "lang": "en",
      "text": "your email slack Google drive or any",
      "offset": 1144.64,
      "duration": 4.68
    },
    {
      "lang": "en",
      "text": "other Tool uh external Services actually",
      "offset": 1146.64,
      "duration": 5.159
    },
    {
      "lang": "en",
      "text": "that you can give access to and it can",
      "offset": 1149.32,
      "duration": 4.44
    },
    {
      "lang": "en",
      "text": "plan its next moves whether it will",
      "offset": 1151.799,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "execute actions in real time or asks uh",
      "offset": 1153.76,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "the human for more input and so this is",
      "offset": 1156.919,
      "duration": 5.481
    },
    {
      "lang": "en",
      "text": "where uh our AI workflows become less of",
      "offset": 1159.76,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "a tool and more of an independent system",
      "offset": 1162.4,
      "duration": 5.88
    },
    {
      "lang": "en",
      "text": "that we can use to truly make our work",
      "offset": 1165.2,
      "duration": 5.359
    },
    {
      "lang": "en",
      "text": "easier so for example this one can be",
      "offset": 1168.28,
      "duration": 4.759
    },
    {
      "lang": "en",
      "text": "like a marketer that will prepare this",
      "offset": 1170.559,
      "duration": 4.201
    },
    {
      "lang": "en",
      "text": "video or a presentation that you can",
      "offset": 1173.039,
      "duration": 5.161
    },
    {
      "lang": "en",
      "text": "just take and use whenever you want",
      "offset": 1174.76,
      "duration": 4.799
    },
    {
      "lang": "en",
      "text": "however the final stage is where we're",
      "offset": 1178.2,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "going to have a fully creative workflow",
      "offset": 1179.559,
      "duration": 6.161
    },
    {
      "lang": "en",
      "text": "and so at L4 the AI moves between uh",
      "offset": 1181.88,
      "duration": 6.08
    },
    {
      "lang": "en",
      "text": "Beyond Automation and reasoning and it",
      "offset": 1185.72,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "becomes an inventor so instead of just",
      "offset": 1187.96,
      "duration": 5.32
    },
    {
      "lang": "en",
      "text": "executing predefined tasks or just like",
      "offset": 1190.36,
      "duration": 6.199
    },
    {
      "lang": "en",
      "text": "reasoning within some bounds um it can",
      "offset": 1193.28,
      "duration": 5.56
    },
    {
      "lang": "en",
      "text": "create its own new workflows so it can",
      "offset": 1196.559,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "create its own utilities whether it's",
      "offset": 1198.84,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "agents prompts function calls tools that",
      "offset": 1200.96,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "uh it needs to be designed uh it will",
      "offset": 1203.96,
      "duration": 4.959
    },
    {
      "lang": "en",
      "text": "Pro it will solve problems in novel way",
      "offset": 1206.32,
      "duration": 6.2
    },
    {
      "lang": "en",
      "text": "so well true L4 right now is definitely",
      "offset": 1208.919,
      "duration": 5.361
    },
    {
      "lang": "en",
      "text": "Out Of Reach because there's some",
      "offset": 1212.52,
      "duration": 4.2
    },
    {
      "lang": "en",
      "text": "constraints with models like overfitting",
      "offset": 1214.28,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "because models they really love their",
      "offset": 1216.72,
      "duration": 3.72
    },
    {
      "lang": "en",
      "text": "training data and there is some issues",
      "offset": 1218.36,
      "duration": 4.84
    },
    {
      "lang": "en",
      "text": "with uh inductive bias where models will",
      "offset": 1220.44,
      "duration": 4.76
    },
    {
      "lang": "en",
      "text": "make assumptions again based on their",
      "offset": 1223.2,
      "duration": 4.839
    },
    {
      "lang": "en",
      "text": "training data this makes to be like a",
      "offset": 1225.2,
      "duration": 5.599
    },
    {
      "lang": "en",
      "text": "very hard task ask uh today but that's",
      "offset": 1228.039,
      "duration": 4.841
    },
    {
      "lang": "en",
      "text": "the goal AI that doesn't just follow",
      "offset": 1230.799,
      "duration": 4.76
    },
    {
      "lang": "en",
      "text": "instructions but will invent it will",
      "offset": 1232.88,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "improve and it will solve problems in",
      "offset": 1235.559,
      "duration": 5.321
    },
    {
      "lang": "en",
      "text": "ways we didn't even think of before so I",
      "offset": 1237.84,
      "duration": 4.719
    },
    {
      "lang": "en",
      "text": "would say that L1 is where we're seeing",
      "offset": 1240.88,
      "duration": 3.96
    },
    {
      "lang": "en",
      "text": "a lot of production grade Solutions so",
      "offset": 1242.559,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "at Bellum we've worked with companies",
      "offset": 1244.84,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "like redin dra and headspace all of",
      "offset": 1246.4,
      "duration": 4.2
    },
    {
      "lang": "en",
      "text": "which have deployed production grade AI",
      "offset": 1248.84,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "solutions that fall within the L1",
      "offset": 1250.6,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "segment and again like just using tools",
      "offset": 1253.72,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "it can be very simple or it can be very",
      "offset": 1256.2,
      "duration": 5.64
    },
    {
      "lang": "en",
      "text": "complex workflow uh the focus is though",
      "offset": 1258.76,
      "duration": 5.64
    },
    {
      "lang": "en",
      "text": "on orchestrations how do we turn our",
      "offset": 1261.84,
      "duration": 5.4
    },
    {
      "lang": "en",
      "text": "models to interact with our system",
      "offset": 1264.4,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "better how do we make our models to work",
      "offset": 1267.24,
      "duration": 4.679
    },
    {
      "lang": "en",
      "text": "with our data better how do we make sure",
      "offset": 1269.28,
      "duration": 4.36
    },
    {
      "lang": "en",
      "text": "that whatever we retrieve from our",
      "offset": 1271.919,
      "duration": 4.041
    },
    {
      "lang": "en",
      "text": "Vector databases is the right and",
      "offset": 1273.64,
      "duration": 5.08
    },
    {
      "lang": "en",
      "text": "correct context for the uh question that",
      "offset": 1275.96,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "the user is asking and so like we're",
      "offset": 1278.72,
      "duration": 3.88
    },
    {
      "lang": "en",
      "text": "experimented with different modalities",
      "offset": 1281.24,
      "duration": 2.559
    },
    {
      "lang": "en",
      "text": "and all of those techniques that we",
      "offset": 1282.6,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "mentioned before and test driven",
      "offset": 1283.799,
      "duration": 4.841
    },
    {
      "lang": "en",
      "text": "development truly makes its case here",
      "offset": 1285.72,
      "duration": 4.36
    },
    {
      "lang": "en",
      "text": "because like you need to hack different",
      "offset": 1288.64,
      "duration": 3.56
    },
    {
      "lang": "en",
      "text": "tools and models and you need to be able",
      "offset": 1290.08,
      "duration": 4.719
    },
    {
      "lang": "en",
      "text": "to continuously improve on them to build",
      "offset": 1292.2,
      "duration": 4.44
    },
    {
      "lang": "en",
      "text": "not only a more efficient system But A",
      "offset": 1294.799,
      "duration": 3.561
    },
    {
      "lang": "en",
      "text": "system that will work continuously",
      "offset": 1296.64,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "better and better um however L2 is where",
      "offset": 1298.36,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "I think we're going to see most",
      "offset": 1301.6,
      "duration": 3.8
    },
    {
      "lang": "en",
      "text": "Innovation uh happen this year and this",
      "offset": 1302.84,
      "duration": 4.6
    },
    {
      "lang": "en",
      "text": "is where we're going to have a lot of AI",
      "offset": 1305.4,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "agents that are being developed to plan",
      "offset": 1307.44,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "and reason using models like 01 or O3 or",
      "offset": 1309.88,
      "duration": 6.399
    },
    {
      "lang": "en",
      "text": "deep sick uh we might see a bunch of",
      "offset": 1313.2,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "different use cases we might see a lot",
      "offset": 1316.279,
      "duration": 5.081
    },
    {
      "lang": "en",
      "text": "of Innovations when it comes to the UI",
      "offset": 1318.72,
      "duration": 5.439
    },
    {
      "lang": "en",
      "text": "and the ux part of the system where we",
      "offset": 1321.36,
      "duration": 4.199
    },
    {
      "lang": "en",
      "text": "will definitely create some new",
      "offset": 1324.159,
      "duration": 5.241
    },
    {
      "lang": "en",
      "text": "experiments experiences for users and um",
      "offset": 1325.559,
      "duration": 6.6
    },
    {
      "lang": "en",
      "text": "essentially this will be uh a way for us",
      "offset": 1329.4,
      "duration": 5.84
    },
    {
      "lang": "en",
      "text": "to make true reasoners that will handle",
      "offset": 1332.159,
      "duration": 5.081
    },
    {
      "lang": "en",
      "text": "complex tasks so you're going to have",
      "offset": 1335.24,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "bunch of these agents just working for",
      "offset": 1337.24,
      "duration": 5.439
    },
    {
      "lang": "en",
      "text": "you doing uh different things however L3",
      "offset": 1339.159,
      "duration": 6.481
    },
    {
      "lang": "en",
      "text": "and L4 they're still both limited by the",
      "offset": 1342.679,
      "duration": 5.161
    },
    {
      "lang": "en",
      "text": "models today as well as the surrounding",
      "offset": 1345.64,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "logic however however that doesn't mean",
      "offset": 1347.84,
      "duration": 4.199
    },
    {
      "lang": "en",
      "text": "that uh there's a lot of innovation",
      "offset": 1350.039,
      "duration": 4.201
    },
    {
      "lang": "en",
      "text": "happening within those two as well so if",
      "offset": 1352.039,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "you want to learn more about how to",
      "offset": 1354.24,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "build your own uh AI agent I've included",
      "offset": 1355.64,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "everything that I've shared in this",
      "offset": 1358.72,
      "duration": 3.88
    },
    {
      "lang": "en",
      "text": "presentation and more for example uh",
      "offset": 1359.96,
      "duration": 4.36
    },
    {
      "lang": "en",
      "text": "architectures that you can build what",
      "offset": 1362.6,
      "duration": 3.88
    },
    {
      "lang": "en",
      "text": "are the stages that you can test and",
      "offset": 1364.32,
      "duration": 4.359
    },
    {
      "lang": "en",
      "text": "similar things like that we also feature",
      "offset": 1366.48,
      "duration": 4.36
    },
    {
      "lang": "en",
      "text": "top researchers and professionals who",
      "offset": 1368.679,
      "duration": 4.12
    },
    {
      "lang": "en",
      "text": "have shared all of their learnings on",
      "offset": 1370.84,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "how to build these for production so",
      "offset": 1372.799,
      "duration": 4.681
    },
    {
      "lang": "en",
      "text": "feel free to scan this QR code on the",
      "offset": 1374.919,
      "duration": 5.64
    },
    {
      "lang": "en",
      "text": "screen to download this resource so now",
      "offset": 1377.48,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "I think it's time to get more practical",
      "offset": 1380.559,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "I want to show you how I built my own",
      "offset": 1382.76,
      "duration": 4.76
    },
    {
      "lang": "en",
      "text": "SEO agent this specific agent automates",
      "offset": 1384.559,
      "duration": 5.24
    },
    {
      "lang": "en",
      "text": "my whole SEO process from keyword",
      "offset": 1387.52,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "research to content analysis and finally",
      "offset": 1389.799,
      "duration": 4.521
    },
    {
      "lang": "en",
      "text": "for Content creation it decides whether",
      "offset": 1392,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "to use tools and has an embedded",
      "offset": 1394.32,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "evaluator that works on an Editor to",
      "offset": 1396.32,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "tell the agent if it's doing a good job",
      "offset": 1398.4,
      "duration": 4.36
    },
    {
      "lang": "en",
      "text": "let's see a quick sketch of how this",
      "offset": 1400.72,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "agent works so in a minute I'm going to",
      "offset": 1402.76,
      "duration": 4.519
    },
    {
      "lang": "en",
      "text": "show you a real demo on how this agent",
      "offset": 1405.039,
      "duration": 4.561
    },
    {
      "lang": "en",
      "text": "actually works however I wanted to give",
      "offset": 1407.279,
      "duration": 4.561
    },
    {
      "lang": "en",
      "text": "you a high level overview on what are",
      "offset": 1409.6,
      "duration": 4.52
    },
    {
      "lang": "en",
      "text": "the steps that this workflow will take",
      "offset": 1411.84,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "and so when you look at the sketch on",
      "offset": 1414.12,
      "duration": 3.039
    },
    {
      "lang": "en",
      "text": "the screen right now you're going to",
      "offset": 1415.76,
      "duration": 3.56
    },
    {
      "lang": "en",
      "text": "notice that this workflow lies between",
      "offset": 1417.159,
      "duration": 5.841
    },
    {
      "lang": "en",
      "text": "L1 and L2 type of agentic workflow you",
      "offset": 1419.32,
      "duration": 6.08
    },
    {
      "lang": "en",
      "text": "have the SEO analyst and the researcher",
      "offset": 1423,
      "duration": 4.76
    },
    {
      "lang": "en",
      "text": "who will take a keyword and it will call",
      "offset": 1425.4,
      "duration": 4.639
    },
    {
      "lang": "en",
      "text": "Google search and it will analyze the",
      "offset": 1427.76,
      "duration": 4.919
    },
    {
      "lang": "en",
      "text": "top performing articles for that keyword",
      "offset": 1430.039,
      "duration": 4.841
    },
    {
      "lang": "en",
      "text": "one it will identify some of the good",
      "offset": 1432.679,
      "duration": 4.961
    },
    {
      "lang": "en",
      "text": "parts uh Within These articles that we",
      "offset": 1434.88,
      "duration": 5.56
    },
    {
      "lang": "en",
      "text": "also need to amplify in our own article",
      "offset": 1437.64,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "but it will also Identify some missing",
      "offset": 1440.44,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "segments or areas of improvement that we",
      "offset": 1442.84,
      "duration": 4.959
    },
    {
      "lang": "en",
      "text": "should definitely write about to make",
      "offset": 1445.48,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "sure that our article is actually",
      "offset": 1447.799,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "performing better than the ones that",
      "offset": 1449.64,
      "duration": 4.039
    },
    {
      "lang": "en",
      "text": "we're competing against and then after",
      "offset": 1451.159,
      "duration": 4.441
    },
    {
      "lang": "en",
      "text": "the research and planning is done the",
      "offset": 1453.679,
      "duration": 4.041
    },
    {
      "lang": "en",
      "text": "writer has everything it needs to start",
      "offset": 1455.6,
      "duration": 4.36
    },
    {
      "lang": "en",
      "text": "writing the first draft what then the",
      "offset": 1457.72,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "first draft is passed to the editor",
      "offset": 1459.96,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "which is an llm based judge that will",
      "offset": 1461.96,
      "duration": 4.719
    },
    {
      "lang": "en",
      "text": "evaluate whether the first draft is good",
      "offset": 1464.279,
      "duration": 4.76
    },
    {
      "lang": "en",
      "text": "enough based on predefined rules that",
      "offset": 1466.679,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "we've set in its prompt then that",
      "offset": 1469.039,
      "duration": 4.801
    },
    {
      "lang": "en",
      "text": "feedback is passed back to the rouer and",
      "offset": 1471.559,
      "duration": 5.72
    },
    {
      "lang": "en",
      "text": "this will Loop uh continuously until",
      "offset": 1473.84,
      "duration": 6.92
    },
    {
      "lang": "en",
      "text": "some uh criteria is met uh within this",
      "offset": 1477.279,
      "duration": 5.361
    },
    {
      "lang": "en",
      "text": "Loop we also have a memory component",
      "offset": 1480.76,
      "duration": 3.48
    },
    {
      "lang": "en",
      "text": "that will capture all previous",
      "offset": 1482.64,
      "duration": 3.96
    },
    {
      "lang": "en",
      "text": "conversations between the writer and the",
      "offset": 1484.24,
      "duration": 5
    },
    {
      "lang": "en",
      "text": "editor and finally we're going to get a",
      "offset": 1486.6,
      "duration": 4.84
    },
    {
      "lang": "en",
      "text": "final article that's actually a very",
      "offset": 1489.24,
      "duration": 5.159
    },
    {
      "lang": "en",
      "text": "useful um piece of content that it's not",
      "offset": 1491.44,
      "duration": 5.599
    },
    {
      "lang": "en",
      "text": "a generated and not useful but truly",
      "offset": 1494.399,
      "duration": 6.28
    },
    {
      "lang": "en",
      "text": "using all of this context in a Smart Way",
      "offset": 1497.039,
      "duration": 5.88
    },
    {
      "lang": "en",
      "text": "enabling me to have a pretty impressive",
      "offset": 1500.679,
      "duration": 4.521
    },
    {
      "lang": "en",
      "text": "first draft to work with so now let's",
      "offset": 1502.919,
      "duration": 4.521
    },
    {
      "lang": "en",
      "text": "see the demo for the sake of time I'm",
      "offset": 1505.2,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "going to start running this workflow as",
      "offset": 1507.44,
      "duration": 4.839
    },
    {
      "lang": "en",
      "text": "I explain what this agent does at every",
      "offset": 1509.12,
      "duration": 5.72
    },
    {
      "lang": "en",
      "text": "step in the workflow so we ran this",
      "offset": 1512.279,
      "duration": 4.601
    },
    {
      "lang": "en",
      "text": "workflow with the keyword Chain of",
      "offset": 1514.84,
      "duration": 4.6
    },
    {
      "lang": "en",
      "text": "Thought prompting and so the SEO analyst",
      "offset": 1516.88,
      "duration": 4.36
    },
    {
      "lang": "en",
      "text": "currently is taking that keyword is",
      "offset": 1519.44,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "taking some other parameters like my",
      "offset": 1521.24,
      "duration": 3.679
    },
    {
      "lang": "en",
      "text": "writing style like the audience that",
      "offset": 1522.96,
      "duration": 4.36
    },
    {
      "lang": "en",
      "text": "we're trying to cater to and it analyzes",
      "offset": 1524.919,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "the top articles that Google is ranking",
      "offset": 1527.32,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "for that specific keywords it tries to",
      "offset": 1529.399,
      "duration": 4.961
    },
    {
      "lang": "en",
      "text": "identify some good components from those",
      "offset": 1531.88,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "articles that we need to reinforce in",
      "offset": 1534.36,
      "duration": 4.36
    },
    {
      "lang": "en",
      "text": "our article but it also identifies some",
      "offset": 1536.36,
      "duration": 4.36
    },
    {
      "lang": "en",
      "text": "missing opportunities where the",
      "offset": 1538.72,
      "duration": 4.76
    },
    {
      "lang": "en",
      "text": "researcher is going to utilize those to",
      "offset": 1540.72,
      "duration": 5.199
    },
    {
      "lang": "en",
      "text": "then make another search and capture",
      "offset": 1543.48,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "more data to make our article be better",
      "offset": 1545.919,
      "duration": 5.041
    },
    {
      "lang": "en",
      "text": "than the articles that we just analyzed",
      "offset": 1548.76,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "so now that the SEO analyst uh is done",
      "offset": 1550.96,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "with its job the researcher tries to",
      "offset": 1553.64,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "capture more information about the",
      "offset": 1556,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "things that um were previously",
      "offset": 1558.44,
      "duration": 4.359
    },
    {
      "lang": "en",
      "text": "identified as missing pieces to the",
      "offset": 1560.88,
      "duration": 4.519
    },
    {
      "lang": "en",
      "text": "puzzle and then the writer will take a",
      "offset": 1562.799,
      "duration": 4.921
    },
    {
      "lang": "en",
      "text": "lot of this information in its input and",
      "offset": 1565.399,
      "duration": 4.241
    },
    {
      "lang": "en",
      "text": "it will try to create a great first",
      "offset": 1567.72,
      "duration": 5.439
    },
    {
      "lang": "en",
      "text": "draft using that data as context so the",
      "offset": 1569.64,
      "duration": 5.48
    },
    {
      "lang": "en",
      "text": "content here that will be generated by",
      "offset": 1573.159,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "the writer it's not going to be like a",
      "offset": 1575.12,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "slop type of article it's not going to",
      "offset": 1576.76,
      "duration": 4.799
    },
    {
      "lang": "en",
      "text": "be something that it's really not useful",
      "offset": 1579.2,
      "duration": 4.199
    },
    {
      "lang": "en",
      "text": "it's going to actually use all the",
      "offset": 1581.559,
      "duration": 3.561
    },
    {
      "lang": "en",
      "text": "context that we're sending from",
      "offset": 1583.399,
      "duration": 3.801
    },
    {
      "lang": "en",
      "text": "different articles that we just analyzed",
      "offset": 1585.12,
      "duration": 4.12
    },
    {
      "lang": "en",
      "text": "you can also connect your rack here that",
      "offset": 1587.2,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "it will look into your database of",
      "offset": 1589.24,
      "duration": 4.12
    },
    {
      "lang": "en",
      "text": "Articles and learnings and it can really",
      "offset": 1591.2,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "create something that's extremely useful",
      "offset": 1593.36,
      "duration": 4.76
    },
    {
      "lang": "en",
      "text": "now the editor says okay this is a good",
      "offset": 1596.32,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "enough article but here's some feedback",
      "offset": 1598.12,
      "duration": 4.12
    },
    {
      "lang": "en",
      "text": "and so it passes the feedback through",
      "offset": 1600.32,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "the memory component here which is a",
      "offset": 1602.24,
      "duration": 4.559
    },
    {
      "lang": "en",
      "text": "chat history between these two and then",
      "offset": 1604.159,
      "duration": 4.76
    },
    {
      "lang": "en",
      "text": "um this node that uh basically",
      "offset": 1606.799,
      "duration": 4.681
    },
    {
      "lang": "en",
      "text": "structures that input for the sake of",
      "offset": 1608.919,
      "duration": 5.841
    },
    {
      "lang": "en",
      "text": "this demo the conditional here for the",
      "offset": 1611.48,
      "duration": 5.919
    },
    {
      "lang": "en",
      "text": "loop is that this Loop will break if the",
      "offset": 1614.76,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "evaluator actually tells us that this is",
      "offset": 1617.399,
      "duration": 4.481
    },
    {
      "lang": "en",
      "text": "an excellent post which actually rarely",
      "offset": 1619.32,
      "duration": 6.239
    },
    {
      "lang": "en",
      "text": "happens so um we also said that if the",
      "offset": 1621.88,
      "duration": 6.44
    },
    {
      "lang": "en",
      "text": "loop runs for at least one time this",
      "offset": 1625.559,
      "duration": 5.161
    },
    {
      "lang": "en",
      "text": "Loop will break and so it already ran",
      "offset": 1628.32,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "for one time we got still more feedback",
      "offset": 1630.72,
      "duration": 4.199
    },
    {
      "lang": "en",
      "text": "from the editor but in this case for",
      "offset": 1632.96,
      "duration": 4.959
    },
    {
      "lang": "en",
      "text": "this demo let's look at the output that",
      "offset": 1634.919,
      "duration": 4.801
    },
    {
      "lang": "en",
      "text": "we got so mastering Chain of Thought",
      "offset": 1637.919,
      "duration": 3.961
    },
    {
      "lang": "en",
      "text": "prompting in AI a comprehensive guide",
      "offset": 1639.72,
      "duration": 4.839
    },
    {
      "lang": "en",
      "text": "for developers I think it's pretty okay",
      "offset": 1641.88,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "pretty nice I might change the title but",
      "offset": 1644.559,
      "duration": 5.161
    },
    {
      "lang": "en",
      "text": "I know that the components this article",
      "offset": 1646.76,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "are the actual components that other",
      "offset": 1649.72,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "articles are writing about and so uh",
      "offset": 1651.72,
      "duration": 4.439
    },
    {
      "lang": "en",
      "text": "this was great the latency was around",
      "offset": 1654.44,
      "duration": 4.28
    },
    {
      "lang": "en",
      "text": "118 this usually takes around 300",
      "offset": 1656.159,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "seconds to run when we have more",
      "offset": 1658.72,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "evaluation Loops but it's pretty great",
      "offset": 1660.24,
      "duration": 5.08
    },
    {
      "lang": "en",
      "text": "it gives me some foundations on how I",
      "offset": 1662.48,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "can continue to build on this content",
      "offset": 1665.32,
      "duration": 4.479
    },
    {
      "lang": "en",
      "text": "and it saves me a lot of my time so the",
      "offset": 1667.36,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "product that I just used is called",
      "offset": 1669.799,
      "duration": 3.48
    },
    {
      "lang": "en",
      "text": "Bellum workflows and it was designed to",
      "offset": 1671.36,
      "duration": 3.559
    },
    {
      "lang": "en",
      "text": "bridge the gap between the product and",
      "offset": 1673.279,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "Engineering teams so they can speed up",
      "offset": 1674.919,
      "duration": 4.721
    },
    {
      "lang": "en",
      "text": "AI development well still following this",
      "offset": 1676.96,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "test driven approach that we talked so",
      "offset": 1679.64,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "much about in this presentation however",
      "offset": 1682,
      "duration": 5
    },
    {
      "lang": "en",
      "text": "one thing became clear developers want",
      "offset": 1684.6,
      "duration": 4.799
    },
    {
      "lang": "en",
      "text": "more code developers want more control",
      "offset": 1687,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "and flexibility and they want to own",
      "offset": 1689.399,
      "duration": 3.961
    },
    {
      "lang": "en",
      "text": "their definitions in their codebase so",
      "offset": 1691.24,
      "duration": 3.64
    },
    {
      "lang": "en",
      "text": "today I'm excited to introduce our",
      "offset": 1693.36,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "workflow SDK it provides all the",
      "offset": 1694.88,
      "duration": 4.799
    },
    {
      "lang": "en",
      "text": "building blocks you need it's infinitely",
      "offset": 1697.12,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "customizable and it has a",
      "offset": 1699.679,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "self-documenting syntax where you can",
      "offset": 1701.76,
      "duration": 4.639
    },
    {
      "lang": "en",
      "text": "actually spot how this agent is working",
      "offset": 1704.08,
      "duration": 4.28
    },
    {
      "lang": "en",
      "text": "right in your code it's also also",
      "offset": 1706.399,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "expressive enough so that you can",
      "offset": 1708.36,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "understand what's happening at every",
      "offset": 1710.159,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "stage in your code the best part is that",
      "offset": 1711.72,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "the UI and the code stay in sync so",
      "offset": 1714.159,
      "duration": 4.76
    },
    {
      "lang": "en",
      "text": "whether you're defining debugging or",
      "offset": 1716.84,
      "duration": 3.959
    },
    {
      "lang": "en",
      "text": "improving your workflows everyone on",
      "offset": 1718.919,
      "duration": 4.36
    },
    {
      "lang": "en",
      "text": "your team can stay aligned I hope that",
      "offset": 1720.799,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "you like it it's open source and free",
      "offset": 1723.279,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "and you can check it out on GitHub feel",
      "offset": 1725.2,
      "duration": 5.079
    },
    {
      "lang": "en",
      "text": "free to run uh to scan this QR code uh",
      "offset": 1727.039,
      "duration": 6.12
    },
    {
      "lang": "en",
      "text": "to check out the repo and that's a wrap",
      "offset": 1730.279,
      "duration": 4.441
    },
    {
      "lang": "en",
      "text": "thank you so much for listening and I",
      "offset": 1733.159,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "hope that today you learned something",
      "offset": 1734.72,
      "duration": 3.72
    },
    {
      "lang": "en",
      "text": "new if you want to talk more about AI I",
      "offset": 1736.279,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "feel free to scan this QR code on the",
      "offset": 1738.44,
      "duration": 3.959
    },
    {
      "lang": "en",
      "text": "screen to connect on LinkedIn or if you",
      "offset": 1740.36,
      "duration": 4.679
    },
    {
      "lang": "en",
      "text": "have any questions feel free to um send",
      "offset": 1742.399,
      "duration": 4.961
    },
    {
      "lang": "en",
      "text": "me a text message on my email or on",
      "offset": 1745.039,
      "duration": 6.441
    },
    {
      "lang": "en",
      "text": "Twitter I'm GNA follow up for sure",
      "offset": 1747.36,
      "duration": 4.12
    }
  ],
  "cleanText": null,
  "dumpedAt": "2025-07-21T18:43:24.992Z"
}