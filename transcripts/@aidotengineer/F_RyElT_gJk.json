{
  "episodeId": "F_RyElT_gJk",
  "channelSlug": "@aidotengineer",
  "title": "The emerging skillset of wielding coding agents — Beyang Liu, Sourcegraph / Amp",
  "publishedAt": "2025-06-30T22:54:36.000Z",
  "rawLines": [
    {
      "lang": "en",
      "text": "[Music]",
      "offset": 0.38,
      "duration": 7.429
    },
    {
      "lang": "en",
      "text": "My name is Bang. I'm the CTO and",
      "offset": 14.96,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "co-founder of a company called Source",
      "offset": 16.88,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "Graph. Uh we build developer tools and",
      "offset": 18.16,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "today I want to share with you some of",
      "offset": 20.72,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "the observations and insights that we've",
      "offset": 22.8,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "had on this sort of like emerging skill",
      "offset": 24.56,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "set of how to wield coding agents.",
      "offset": 26.56,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "That sound good to everyone? All right,",
      "offset": 30.08,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "cool. Um, okay. So, let's check in on",
      "offset": 31.84,
      "duration": 6.879
    },
    {
      "lang": "en",
      "text": "the uh the the agent discourse. Uh, I",
      "offset": 35.36,
      "duration": 5.039
    },
    {
      "lang": "en",
      "text": "don't know if you all saw this, but a",
      "offset": 38.719,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "couple days ago there were some spicy",
      "offset": 40.399,
      "duration": 5.441
    },
    {
      "lang": "en",
      "text": "tweets about the the efficacy of AI",
      "offset": 42.32,
      "duration": 5.919
    },
    {
      "lang": "en",
      "text": "coding agents or, you know, inefficacy",
      "offset": 45.84,
      "duration": 5.039
    },
    {
      "lang": "en",
      "text": "depending on your perspective. So, um,",
      "offset": 48.239,
      "duration": 5.201
    },
    {
      "lang": "en",
      "text": "Jonathan Blow, who's a really talented",
      "offset": 50.879,
      "duration": 4.801
    },
    {
      "lang": "en",
      "text": "developer, he basically single-handedly",
      "offset": 53.44,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "coded up the indie game Braid, if you're",
      "offset": 55.68,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "familiar with that. So like he's he's",
      "offset": 57.6,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "kind of like god tier status in terms of",
      "offset": 59.6,
      "duration": 5.199
    },
    {
      "lang": "en",
      "text": "coding ability. um retweeted Alex Albert",
      "offset": 61.92,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "who's also someone I respect and admire",
      "offset": 64.799,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "a lot uh works at Enthropic and",
      "offset": 66.64,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "basically claiming that you know all the",
      "offset": 68.479,
      "duration": 3.441
    },
    {
      "lang": "en",
      "text": "hype around coding agents and code in",
      "offset": 69.84,
      "duration": 4.959
    },
    {
      "lang": "en",
      "text": "general uh was just it is just hype",
      "offset": 71.92,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "right there's no substance there um and",
      "offset": 74.799,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "then there were some responses and there",
      "offset": 77.36,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "was kind of a spectrum of responses too",
      "offset": 78.88,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "you know we had some other uh big names",
      "offset": 80.72,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "in the developer world like Jesse",
      "offset": 83.2,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "Friselle she was one of the early uh",
      "offset": 84.56,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "contributors maintainers of Docker she's",
      "offset": 87.04,
      "duration": 4.719
    },
    {
      "lang": "en",
      "text": "also really legit uh she said basically",
      "offset": 89.04,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "something to the effect of like um I",
      "offset": 91.759,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "think you're right. Uh but you're in",
      "offset": 93.84,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "like the top 01% of programmers,",
      "offset": 95.759,
      "duration": 4.561
    },
    {
      "lang": "en",
      "text": "Jonathan. For the rest of us, you know,",
      "offset": 97.92,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "down here in this room that aren't on",
      "offset": 100.32,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "Mount Olympus, it actually helps a lot.",
      "offset": 101.92,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "Um but not super helpful if you're if",
      "offset": 104.479,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "you're really really good. Um but then",
      "offset": 106.64,
      "duration": 4.479
    },
    {
      "lang": "en",
      "text": "we also had folks like Eric uh S.",
      "offset": 108.64,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "Raymond, who is like the one of the",
      "offset": 111.119,
      "duration": 4.241
    },
    {
      "lang": "en",
      "text": "fathers of open source, uh who had a",
      "offset": 113.04,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "very spicy reply. is basically like look",
      "offset": 115.36,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "I you know consider myself to be pretty",
      "offset": 117.2,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "decent at programming and uh these",
      "offset": 119.68,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "things help a lot. Uh and then uh the",
      "offset": 121.92,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "the kind of my favorite one of this was",
      "offset": 125.2,
      "duration": 4.559
    },
    {
      "lang": "en",
      "text": "actually the the top a hacker news post",
      "offset": 127.2,
      "duration": 6.8
    },
    {
      "lang": "en",
      "text": "that was written by um uh Thomas uh uh",
      "offset": 129.759,
      "duration": 6.56
    },
    {
      "lang": "en",
      "text": "Tachek uh who is a a really legit",
      "offset": 134,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "security engineer. Um some of you may",
      "offset": 136.319,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "have seen this uh trending. He was he",
      "offset": 138.4,
      "duration": 3.199
    },
    {
      "lang": "en",
      "text": "was basically taking the opposite view",
      "offset": 140.48,
      "duration": 2.399
    },
    {
      "lang": "en",
      "text": "of like, you know, there's some really",
      "offset": 141.599,
      "duration": 2.64
    },
    {
      "lang": "en",
      "text": "smart people there who are very AI",
      "offset": 142.879,
      "duration": 2.881
    },
    {
      "lang": "en",
      "text": "skeptical, but they're nuts. Like, uh,",
      "offset": 144.239,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "these things are really useful. Um, so I",
      "offset": 145.76,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "I'm guessing if you're at this",
      "offset": 148.4,
      "duration": 3.199
    },
    {
      "lang": "en",
      "text": "conference, you probably lean toward",
      "offset": 149.599,
      "duration": 5.121
    },
    {
      "lang": "en",
      "text": "coding agents uh are substantively uh",
      "offset": 151.599,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "useful and there's something there. I",
      "offset": 154.72,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "don't know. Uh, just a just a guess. But",
      "offset": 156.879,
      "duration": 4.961
    },
    {
      "lang": "en",
      "text": "I think even within this room, there's",
      "offset": 159.76,
      "duration": 6.64
    },
    {
      "lang": "en",
      "text": "probably a spectrum of uh best practices",
      "offset": 161.84,
      "duration": 8
    },
    {
      "lang": "en",
      "text": "and opinions about like where agents are",
      "offset": 166.4,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "good. Uh you know, whether they're",
      "offset": 169.84,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "restricted to like small edits or like",
      "offset": 172.08,
      "duration": 4.799
    },
    {
      "lang": "en",
      "text": "front-end applications or weekend vi",
      "offset": 174.56,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "coding, whether they actually work on",
      "offset": 176.879,
      "duration": 4.801
    },
    {
      "lang": "en",
      "text": "your production codebase. And um I think",
      "offset": 178.48,
      "duration": 5.679
    },
    {
      "lang": "en",
      "text": "this is just uh indicative of of the",
      "offset": 181.68,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "dynamic technical landscape that that",
      "offset": 184.159,
      "duration": 3.041
    },
    {
      "lang": "en",
      "text": "we're in right now. And a couple months",
      "offset": 185.92,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "back, I I wrote this blog post from this",
      "offset": 187.2,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "guy Jeff Huntley. So Jeff was a senior",
      "offset": 189.44,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "engineer at Canva at the time. And uh",
      "offset": 192.08,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "his role at Canva is really interesting.",
      "offset": 194.8,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "He basically went around interviewing",
      "offset": 196.48,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "all the uh developers inside of Canva",
      "offset": 199.12,
      "duration": 5.039
    },
    {
      "lang": "en",
      "text": "using AI tools like cursor and and other",
      "offset": 201.84,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "things and seeing how they're using it.",
      "offset": 204.159,
      "duration": 3.521
    },
    {
      "lang": "en",
      "text": "And he basically came to the conclusion",
      "offset": 206.239,
      "duration": 3.041
    },
    {
      "lang": "en",
      "text": "that like most people were holding it",
      "offset": 207.68,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "wrong. Uh which is which is really",
      "offset": 209.28,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "interesting. and he he came up with a",
      "offset": 211.12,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "blog post about like all the different",
      "offset": 212.56,
      "duration": 4.239
    },
    {
      "lang": "en",
      "text": "antiatterns that he was seeing. Um, but",
      "offset": 214.4,
      "duration": 5.199
    },
    {
      "lang": "en",
      "text": "my summation of of of that blog post is",
      "offset": 216.799,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "like the the number one mistake that",
      "offset": 219.599,
      "duration": 3.121
    },
    {
      "lang": "en",
      "text": "people are using with coding agents",
      "offset": 221.12,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "right now is they're trying to use",
      "offset": 222.72,
      "duration": 4.799
    },
    {
      "lang": "en",
      "text": "coding agents the same way they're using",
      "offset": 225.76,
      "duration": 5.839
    },
    {
      "lang": "en",
      "text": "AI coding tools uh six months ago. um",
      "offset": 227.519,
      "duration": 5.601
    },
    {
      "lang": "en",
      "text": "and and therefore they're wrong, which",
      "offset": 231.599,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "is kind of crazy because normally if",
      "offset": 233.12,
      "duration": 6.399
    },
    {
      "lang": "en",
      "text": "you're you know using a tool uh the the",
      "offset": 235.76,
      "duration": 5.92
    },
    {
      "lang": "en",
      "text": "best practices don't change in in six",
      "offset": 239.519,
      "duration": 3.521
    },
    {
      "lang": "en",
      "text": "months typically the things that you",
      "offset": 241.68,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "learn that are good uh will still be",
      "offset": 243.04,
      "duration": 5.279
    },
    {
      "lang": "en",
      "text": "like present uh and and uh you know",
      "offset": 245.12,
      "duration": 5.679
    },
    {
      "lang": "en",
      "text": "topical and relevant 6 months uh down",
      "offset": 248.319,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "the line but I think we're in a really",
      "offset": 250.799,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "interesting moment in time right now and",
      "offset": 252.959,
      "duration": 4.641
    },
    {
      "lang": "en",
      "text": "you know why the sudden change I think",
      "offset": 255.2,
      "duration": 6.159
    },
    {
      "lang": "en",
      "text": "it's because uh of this step function",
      "offset": 257.6,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "transition uh that we've experienced in",
      "offset": 261.359,
      "duration": 4.481
    },
    {
      "lang": "en",
      "text": "model capabilities in the past 6 months.",
      "offset": 263.6,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "So, you know, we've we've all been",
      "offset": 265.84,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "around since the dawn of generative AI,",
      "offset": 267.84,
      "duration": 6.96
    },
    {
      "lang": "en",
      "text": "the ancient year of uh 2020",
      "offset": 270.8,
      "duration": 7.04
    },
    {
      "lang": "en",
      "text": "two, right? November 2022 was when Chat",
      "offset": 274.8,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "GBT launched, right? And every year uh",
      "offset": 277.84,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "now, you know, this is now the year",
      "offset": 280.16,
      "duration": 4.479
    },
    {
      "lang": "en",
      "text": "three, you know, three after chatbt,",
      "offset": 282.08,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "right? We're now living in the AI",
      "offset": 284.639,
      "duration": 3.201
    },
    {
      "lang": "en",
      "text": "future. Um, but I think there's already",
      "offset": 285.919,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "been kind of like three distinct waves",
      "offset": 287.84,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "or or eras largely driven by the",
      "offset": 289.919,
      "duration": 3.761
    },
    {
      "lang": "en",
      "text": "evolution of frontier model",
      "offset": 292.16,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "capabilities.",
      "offset": 293.68,
      "duration": 4.239
    },
    {
      "lang": "en",
      "text": "Um, and the model capabilities really",
      "offset": 295.36,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "dictate the uh ideal architecture uh",
      "offset": 297.919,
      "duration": 4.881
    },
    {
      "lang": "en",
      "text": "that that becomes dominant at the",
      "offset": 300.88,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "application layer. So in the GPD3 era,",
      "offset": 302.8,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "all the models were text completion",
      "offset": 305.52,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "models uh which meant all the",
      "offset": 307.36,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "applications that people were building",
      "offset": 309.52,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "uh were these like co-pilots or",
      "offset": 311.28,
      "duration": 3.359
    },
    {
      "lang": "en",
      "text": "autocomplete tools. So the dominant UX",
      "offset": 312.56,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "paradigm was like you type some stuff,",
      "offset": 314.639,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "it types some stuff, you type some more",
      "offset": 316.639,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "and that's how you would interact. Uh",
      "offset": 318.479,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "and then chat GBD came along uh with",
      "offset": 320.56,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "GBD3.5 which was instruct tuned to",
      "offset": 322.88,
      "duration": 6.08
    },
    {
      "lang": "en",
      "text": "interact like a uh a chatbot. Uh and",
      "offset": 325.6,
      "duration": 4.879
    },
    {
      "lang": "en",
      "text": "suddenly people realized like oh it's",
      "offset": 328.96,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "not just completing the next thing I'm",
      "offset": 330.479,
      "duration": 3.121
    },
    {
      "lang": "en",
      "text": "talking about. I can actually ask it",
      "offset": 332.24,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "questions like I can a human now. Uh and",
      "offset": 333.6,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "then some other people came along. Uh we",
      "offset": 336.16,
      "duration": 3.599
    },
    {
      "lang": "en",
      "text": "were part of this crowd. We realized",
      "offset": 338.24,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "like hey um you know what's even better",
      "offset": 339.759,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "than just like asking it questions. You",
      "offset": 342,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "can actually copy paste stuff into the",
      "offset": 343.44,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "chat and say like here's some code from",
      "offset": 345.68,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "my codebase use that as an example and",
      "offset": 347.84,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "pattern match against that and you that",
      "offset": 350.4,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "helps it generate you know a little bit",
      "offset": 352.24,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "better code or less uh less fake code or",
      "offset": 353.68,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "less hallucinated code than uh it did",
      "offset": 356.32,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "before. And uh that basically meant that",
      "offset": 358.24,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "everyone at the application layer was",
      "offset": 361.36,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "building a ragbot uh in in 2023. So like",
      "offset": 362.72,
      "duration": 5.919
    },
    {
      "lang": "en",
      "text": "a chatbot plus a a rag retrieval engine.",
      "offset": 365.36,
      "duration": 7.2
    },
    {
      "lang": "en",
      "text": "But now uh I think we've entered a new",
      "offset": 368.639,
      "duration": 5.601
    },
    {
      "lang": "en",
      "text": "era and I don't I'm not sure if everyone",
      "offset": 372.56,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "realizes it or maybe this is I don't",
      "offset": 374.24,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "know like who agrees with this statement",
      "offset": 376.4,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "like who thinks it's a real paradigm",
      "offset": 378,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "shift. Okay. And then who's who here is",
      "offset": 379.52,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "like ah that's a bunch of",
      "offset": 382.16,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "Anyone\n feel free to I like Okay. Okay.",
      "offset": 383.68,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "So maybe I'm maybe I could just skip",
      "offset": 386.56,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "this slide. Um",
      "offset": 388.56,
      "duration": 4.479
    },
    {
      "lang": "en",
      "text": "so we're now living in the era of agents",
      "offset": 391.12,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "and the new model capabilities uh really",
      "offset": 393.039,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "dictate a new application architecture.",
      "offset": 395.039,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "And so one of the things that we asked",
      "offset": 397.44,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "ourselves at source graph is you know a",
      "offset": 398.96,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "lot of the existing tools in the market",
      "offset": 400.88,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "they were designed for the era of GPD4",
      "offset": 402.4,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "and uh claude 3. So there a lot of the",
      "offset": 405.44,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "application stuff uh features and UX and",
      "offset": 408.08,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "UI was really built around the",
      "offset": 410.96,
      "duration": 3.359
    },
    {
      "lang": "en",
      "text": "capabilities or in some cases the",
      "offset": 412.88,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "limitations of the chatbased LMS. Um,",
      "offset": 414.319,
      "duration": 6.081
    },
    {
      "lang": "en",
      "text": "and so if we were going to design a",
      "offset": 418.24,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "coding agent from the ground up to",
      "offset": 420.4,
      "duration": 4.239
    },
    {
      "lang": "en",
      "text": "unleash the capabilities of tool using",
      "offset": 422.319,
      "duration": 4.961
    },
    {
      "lang": "en",
      "text": "LMS, agentic LMS, uh, what would that",
      "offset": 424.639,
      "duration": 4.801
    },
    {
      "lang": "en",
      "text": "look like?",
      "offset": 427.28,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "Okay, so here are my spicy takes. Uh,",
      "offset": 429.44,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "these are controversial design decisions",
      "offset": 432.8,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "that I think are are better to make in",
      "offset": 434.8,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "the age of agents. Uh, and many of these",
      "offset": 436.4,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "go against the best practices that kind",
      "offset": 439.52,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "of emerged in the chatbot era. Okay, so",
      "offset": 441.68,
      "duration": 6.16
    },
    {
      "lang": "en",
      "text": "number one is uh the agent should just",
      "offset": 444.4,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "make edits to your files. It shouldn't",
      "offset": 447.84,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "ask you at every turn like, &quot;Hey, you",
      "offset": 449.84,
      "duration": 2.4
    },
    {
      "lang": "en",
      "text": "know, I want to make this change. Should",
      "offset": 451.28,
      "duration": 2.96
    },
    {
      "lang": "en",
      "text": "I apply it?&quot; Uh if it's asking you and",
      "offset": 452.24,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "it's wrong, uh it's already done the",
      "offset": 454.24,
      "duration": 4.239
    },
    {
      "lang": "en",
      "text": "wrong thing and it's wasted your time.",
      "offset": 456.96,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "Uh humans need to get uh more out of the",
      "offset": 458.479,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "inner loop and more kind of like on top",
      "offset": 460.96,
      "duration": 3.519
    },
    {
      "lang": "en",
      "text": "of the loop like still steering it and",
      "offset": 462.8,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "guiding it, but less you know",
      "offset": 464.479,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "micromanaging and and managing every",
      "offset": 466.16,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "change. Second thing is do we still need",
      "offset": 467.919,
      "duration": 7.84
    },
    {
      "lang": "en",
      "text": "a thick client uh to uh to manipulate",
      "offset": 471.84,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "the LLMs? Like do we still need a fork",
      "offset": 475.759,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "VS code? That's like the salty way of",
      "offset": 477.52,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "saying this, right? Um the VS code fork",
      "offset": 479.039,
      "duration": 4.801
    },
    {
      "lang": "en",
      "text": "became the the culmination of the AI",
      "offset": 481.36,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "coding application I think for for the",
      "offset": 483.84,
      "duration": 3.759
    },
    {
      "lang": "en",
      "text": "the chatbot era. But there's this",
      "offset": 485.44,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "question of like, you know, if the",
      "offset": 487.599,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "contract of an agent is you ask it to do",
      "offset": 489.68,
      "duration": 3.359
    },
    {
      "lang": "en",
      "text": "stuff and then it does stuff, do you",
      "offset": 491.599,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "really still need all that UI built",
      "offset": 493.039,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "around like context management and",
      "offset": 494.879,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "applying the proposed change in the",
      "offset": 497.199,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "codebase or can you just ask it to do",
      "offset": 498.8,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "stuff and expect it to to do the right",
      "offset": 501.199,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "thing?",
      "offset": 502.96,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "Third, I think we're going to move",
      "offset": 504.479,
      "duration": 3.761
    },
    {
      "lang": "en",
      "text": "beyond the choose your own model uh",
      "offset": 506.08,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "phase. So I think in the chatbot era, it",
      "offset": 508.24,
      "duration": 4.719
    },
    {
      "lang": "en",
      "text": "was very easy to swap models in and out",
      "offset": 510.96,
      "duration": 3.199
    },
    {
      "lang": "en",
      "text": "and you'd like, oh, you know, a new",
      "offset": 512.959,
      "duration": 2.96
    },
    {
      "lang": "en",
      "text": "model came along. let me swap it out and",
      "offset": 514.159,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "see how well it attends to the context",
      "offset": 515.919,
      "duration": 4.881
    },
    {
      "lang": "en",
      "text": "that my retrieval engine fetches. Um, in",
      "offset": 518,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "the agentic world, there's a much deeper",
      "offset": 520.8,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "coupling uh because the LLM that you're",
      "offset": 522.399,
      "duration": 4.801
    },
    {
      "lang": "en",
      "text": "using essentially becomes the the brains",
      "offset": 525.12,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "of these agentic chains and so it's much",
      "offset": 527.2,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "harder to rip and replace. And I think a",
      "offset": 529.2,
      "duration": 2.8
    },
    {
      "lang": "en",
      "text": "lot of people in this room who have",
      "offset": 530.8,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "tried mixing and matching uh you know",
      "offset": 532,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "different models uh in the context of",
      "offset": 534.08,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "agents have found that it you know",
      "offset": 536.08,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "swapping out a different model and",
      "offset": 538.32,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "expecting similar results is is very",
      "offset": 539.68,
      "duration": 3.599
    },
    {
      "lang": "en",
      "text": "different. a lot of the like a lot of",
      "offset": 541.68,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "the LMS out there aren't even good at",
      "offset": 543.279,
      "duration": 3.761
    },
    {
      "lang": "en",
      "text": "the basics of tool use yet. So it's it's",
      "offset": 545.04,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "very difficult to just replace the",
      "offset": 547.04,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "brains. Um four is I think we're going",
      "offset": 548.72,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "to move past the era of fixed pricing.",
      "offset": 552.08,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "Uh agents eat up a lot of tokens and so",
      "offset": 554.32,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "they look expensive relative to chat",
      "offset": 556.88,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "bots. Uh but the comparison that more",
      "offset": 559.44,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "and more people are making is how much",
      "offset": 562.56,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "human time is it saving? So they're",
      "offset": 564.08,
      "duration": 3.759
    },
    {
      "lang": "en",
      "text": "still cheap relative to to human time",
      "offset": 565.76,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "saved. And the fixed pricing model",
      "offset": 567.839,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "actually introduces a perverse incentive",
      "offset": 569.76,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "now where uh it's like selling gym",
      "offset": 571.519,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "memberships, right? Like if if I sold",
      "offset": 573.6,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "you a membership to my chatbot and",
      "offset": 575.36,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "you're now paying me, you know, 20 bucks",
      "offset": 577.2,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "a month, uh my incentive now is to push",
      "offset": 578.72,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "the inference cost as low as possible.",
      "offset": 581.2,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "And the easiest way to do that is to use",
      "offset": 582.88,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "dumber models. Um but dumber models just",
      "offset": 584.56,
      "duration": 6.399
    },
    {
      "lang": "en",
      "text": "waste more more of your time. Um sorry,",
      "offset": 587.04,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "this is a long list. Um uh hopefully",
      "offset": 590.959,
      "duration": 4.801
    },
    {
      "lang": "en",
      "text": "it's not too tedious, but um I think",
      "offset": 593.04,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "these are important points. Uh the the",
      "offset": 595.76,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "second to last point I'll make is I",
      "offset": 597.68,
      "duration": 2.719
    },
    {
      "lang": "en",
      "text": "think the Unix philosophy is going to be",
      "offset": 599.04,
      "duration": 2.64
    },
    {
      "lang": "en",
      "text": "more powerful here than vertical",
      "offset": 600.399,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "integration. So in developer tools, the",
      "offset": 601.68,
      "duration": 5.279
    },
    {
      "lang": "en",
      "text": "ability uh to use simple tools in ways",
      "offset": 604.08,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "that compose well with other interesting",
      "offset": 606.959,
      "duration": 5.121
    },
    {
      "lang": "en",
      "text": "tools is really powerful. And so I think",
      "offset": 609.04,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "especially with agents where there's",
      "offset": 612.08,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "less of a need to create like a lot of",
      "offset": 613.6,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "UI around it, you're going to start to",
      "offset": 616,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "see more command driven tools, command",
      "offset": 617.92,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "line tools and things like that. Um and",
      "offset": 619.68,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "then last but not least is uh you know",
      "offset": 622.48,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "we had an existing uh rag chat coding",
      "offset": 624.88,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "assistant. Maybe some of you have used",
      "offset": 627.44,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "it. It was called Kodi. Um it still",
      "offset": 628.8,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "exists. We're still supporting it. Uh",
      "offset": 630.8,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "it's still in heavy use across you know",
      "offset": 632.72,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "many fortune 500 companies. uh but we",
      "offset": 634.24,
      "duration": 5.92
    },
    {
      "lang": "en",
      "text": "decided to build a a new application",
      "offset": 636.64,
      "duration": 5.84
    },
    {
      "lang": "en",
      "text": "from from the ground up for the agentic",
      "offset": 640.16,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "world because we didn't want to be",
      "offset": 642.48,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "constrained by all the assumptions and",
      "offset": 644.16,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "constraints that uh we we built into the",
      "offset": 645.92,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "application layer uh for the previous",
      "offset": 648.8,
      "duration": 4.479
    },
    {
      "lang": "en",
      "text": "generation of LMS.",
      "offset": 650.88,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "And one analogy I like to draw here is",
      "offset": 653.279,
      "duration": 6.321
    },
    {
      "lang": "en",
      "text": "you know what uh the the the early days",
      "offset": 656,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "of the internet right like in the early",
      "offset": 659.6,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "days of the internet the the way people",
      "offset": 661.2,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "you know jumped into the the web was",
      "offset": 663.2,
      "duration": 5.199
    },
    {
      "lang": "en",
      "text": "using an interface on the left. This is",
      "offset": 666.48,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "before like most people knew what the",
      "offset": 668.399,
      "duration": 2.801
    },
    {
      "lang": "en",
      "text": "internet was about what it was capable",
      "offset": 669.76,
      "duration": 2.88
    },
    {
      "lang": "en",
      "text": "of and that was the right interface for",
      "offset": 671.2,
      "duration": 2.56
    },
    {
      "lang": "en",
      "text": "the first generation of the internet",
      "offset": 672.64,
      "duration": 2.8
    },
    {
      "lang": "en",
      "text": "because like what can you do with the",
      "offset": 673.76,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "internet? Well like there's a bunch of",
      "offset": 675.44,
      "duration": 2.88
    },
    {
      "lang": "en",
      "text": "different things you can look at like",
      "offset": 677.04,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "trending celebrities you can you know",
      "offset": 678.32,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "buy automobiles. You can look at movie",
      "offset": 680.24,
      "duration": 3.599
    },
    {
      "lang": "en",
      "text": "reviews, all these things you might not",
      "offset": 682.24,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "have thought of. And so it's it's useful",
      "offset": 683.839,
      "duration": 3.281
    },
    {
      "lang": "en",
      "text": "to have in front of you, but at some",
      "offset": 685.44,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "point it gets a little tedious, like",
      "offset": 687.12,
      "duration": 2.64
    },
    {
      "lang": "en",
      "text": "clicking through all the different",
      "offset": 688.56,
      "duration": 2.88
    },
    {
      "lang": "en",
      "text": "hyperlinks and navigating your way",
      "offset": 689.76,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "through. And then the the real power of",
      "offset": 691.44,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "the web was sort of unleashed by just",
      "offset": 694.16,
      "duration": 4.799
    },
    {
      "lang": "en",
      "text": "like the one simple text box where you",
      "offset": 695.92,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "just like type what you're looking for",
      "offset": 698.959,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "and and you get to it. And I think, you",
      "offset": 700,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "know, with with aentic UIs, that's what",
      "offset": 702.079,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "we should be striving for both in",
      "offset": 705.36,
      "duration": 3.599
    },
    {
      "lang": "en",
      "text": "developer tools and in a lot of",
      "offset": 707.279,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "different application paradigms. Okay,",
      "offset": 708.959,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "so what does that look like in practice?",
      "offset": 711.36,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "So when we went to design this thing, um",
      "offset": 713.12,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "our coding agent is called AMP. Uh and",
      "offset": 715.6,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "AMP has two clients and this is what",
      "offset": 718.24,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "they look like. So both are like very",
      "offset": 720.48,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "very bare bones. A lot of people, you",
      "offset": 722.64,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "know, look at this and like what is",
      "offset": 724.48,
      "duration": 3.039
    },
    {
      "lang": "en",
      "text": "this? It's just a text box. What what",
      "offset": 726,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "can I do with it? Um and and that was by",
      "offset": 727.519,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "design, you know, that for all the",
      "offset": 730.32,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "reasons I just mentioned. Um, one client",
      "offset": 731.92,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "is just a simple VS Code extension um,",
      "offset": 734.88,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "that allows us to take advantage of some",
      "offset": 737.04,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "nice things that you get in in VS Code",
      "offset": 739.12,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "like being able to view diffs. That's",
      "offset": 741.2,
      "duration": 3.759
    },
    {
      "lang": "en",
      "text": "really important in the agent decoding",
      "offset": 742.72,
      "duration": 4.239
    },
    {
      "lang": "en",
      "text": "world. I often joke that like that's now",
      "offset": 744.959,
      "duration": 3.761
    },
    {
      "lang": "en",
      "text": "I use that view more than the editor",
      "offset": 746.959,
      "duration": 4.721
    },
    {
      "lang": "en",
      "text": "view now. Um, and and the second was a",
      "offset": 748.72,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "CLI. So, uh, just stripping things down",
      "offset": 751.68,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "to bare bones. It has access to all the",
      "offset": 754,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "same tools as the the VS Code extension",
      "offset": 755.68,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "does, but it's just something that you",
      "offset": 758.16,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "can invoke in your command line. You can",
      "offset": 759.6,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "also script it, compose it with other",
      "offset": 761.2,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "tools.",
      "offset": 763.12,
      "duration": 4.959
    },
    {
      "lang": "en",
      "text": "Okay. So, what what what does this",
      "offset": 765.279,
      "duration": 5.761
    },
    {
      "lang": "en",
      "text": "actually look like in practice? Um I I",
      "offset": 768.079,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "wanted to do something a little bit",
      "offset": 771.04,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "risky here, which is um in the past I've",
      "offset": 772.16,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "done a lot of like, you know, hey,",
      "offset": 775.6,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "here's me building a simple app, like",
      "offset": 777.04,
      "duration": 3.599
    },
    {
      "lang": "en",
      "text": "those sorts of demos, but I actually",
      "offset": 778.8,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "wanted to show off like where we think",
      "offset": 780.639,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "this is most useful, which is like, hey,",
      "offset": 782.16,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "I'm working on an application that has",
      "offset": 783.839,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "real users. is let me actually make a",
      "offset": 786,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "contribution to that codebase given all",
      "offset": 788,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "w with all the like existing",
      "offset": 790.32,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "constraints. And so I actually want to",
      "offset": 791.76,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "I'm just going to code a little bit. I",
      "offset": 794.399,
      "duration": 2.401
    },
    {
      "lang": "en",
      "text": "don't even know how far we're going to",
      "offset": 795.68,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "get. Um but this is this is AMP. Uh this",
      "offset": 796.8,
      "duration": 6.24
    },
    {
      "lang": "en",
      "text": "is VS Code running AMP in the sidebar",
      "offset": 800.8,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "and it's open to the AMP codebase. Um",
      "offset": 803.04,
      "duration": 5.039
    },
    {
      "lang": "en",
      "text": "and what I want to do is implement like",
      "offset": 806,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "a simple uh change uh to this",
      "offset": 808.079,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "application. So the change that I'm",
      "offset": 811.36,
      "duration": 4.719
    },
    {
      "lang": "en",
      "text": "going to make is AMP has a server",
      "offset": 813.279,
      "duration": 6.401
    },
    {
      "lang": "en",
      "text": "component and the server exists uh as a",
      "offset": 816.079,
      "duration": 5.841
    },
    {
      "lang": "en",
      "text": "way to provide the LM inference point.",
      "offset": 819.68,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "It also provides like team",
      "offset": 821.92,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "functionality. We have a way to share",
      "offset": 823.12,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "like what different teams are doing or",
      "offset": 825.36,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "what different users are doing with AI",
      "offset": 827.44,
      "duration": 2.399
    },
    {
      "lang": "en",
      "text": "so you can kind of learn from other",
      "offset": 828.8,
      "duration": 3.279
    },
    {
      "lang": "en",
      "text": "users. There's leaderboard. It's fun. Um",
      "offset": 829.839,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "but there's also these things called",
      "offset": 832.079,
      "duration": 3.361
    },
    {
      "lang": "en",
      "text": "connectors which allow AMP to talk to",
      "offset": 833.279,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "external services. So our issue tracker",
      "offset": 835.44,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "is Linear. Um, and so I've integrated",
      "offset": 837.199,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "Linear uh into AMP here, but I'm kind of",
      "offset": 839.279,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "annoyed because it's using this generic",
      "offset": 841.519,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "like network icon, and I would really",
      "offset": 843.44,
      "duration": 3.519
    },
    {
      "lang": "en",
      "text": "like to customize this icon such that",
      "offset": 845.12,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "when you plug in the linear MCP",
      "offset": 846.959,
      "duration": 3.761
    },
    {
      "lang": "en",
      "text": "endpoint, it it uses a more appropriate",
      "offset": 848.48,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "icon like a checkbox or something",
      "offset": 850.72,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "issuey.",
      "offset": 852.399,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "Um, so I've already filed this as a",
      "offset": 853.92,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "linear issue and I'm just going to ask",
      "offset": 856,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "uh can you find the linear issue about",
      "offset": 858.079,
      "duration": 8.241
    },
    {
      "lang": "en",
      "text": "customizing the linear connector icon uh",
      "offset": 861.12,
      "duration": 9
    },
    {
      "lang": "en",
      "text": "then implement it.",
      "offset": 866.32,
      "duration": 3.8
    },
    {
      "lang": "en",
      "text": "So what this will do is um it has access",
      "offset": 870.56,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "to a set of tools. Um I can go over here",
      "offset": 874.16,
      "duration": 5.039
    },
    {
      "lang": "en",
      "text": "to the tool panel and see what tools it",
      "offset": 876.56,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "has access to. Some are local, some are",
      "offset": 879.199,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "built in. Um it's got the standard tools",
      "offset": 881.12,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "like read and edit file or run bash",
      "offset": 882.959,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "command. Uh you can also plug in things",
      "offset": 884.8,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "like playrite and postgress via MCP. Uh",
      "offset": 886.8,
      "duration": 5.039
    },
    {
      "lang": "en",
      "text": "and then linear is also plugged in uh",
      "offset": 889.92,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "through this. So we're basically talking",
      "offset": 891.839,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "to the linear API uh through the MCP",
      "offset": 893.6,
      "duration": 6.56
    },
    {
      "lang": "en",
      "text": "server and uh what this will do is it",
      "offset": 896.16,
      "duration": 8
    },
    {
      "lang": "en",
      "text": "will use the linear uh issues API",
      "offset": 900.16,
      "duration": 6.32
    },
    {
      "lang": "en",
      "text": "um and it will search issues. It found",
      "offset": 904.16,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "50 issues and the one that I was",
      "offset": 906.48,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "referring to is at the top here. So add",
      "offset": 908.48,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "a special icon for the linear connector.",
      "offset": 910.16,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "Uh and now it's going to go and",
      "offset": 912.8,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "implement uh the thing for me. Um and",
      "offset": 915.44,
      "duration": 5.759
    },
    {
      "lang": "en",
      "text": "one thing to note here is it's just",
      "offset": 918.8,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "making these tool calls on its own. I'm",
      "offset": 921.199,
      "duration": 4.721
    },
    {
      "lang": "en",
      "text": "not asking it uh to use specific tools.",
      "offset": 923.12,
      "duration": 5.92
    },
    {
      "lang": "en",
      "text": "Um we've also tried to make the uh",
      "offset": 925.92,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "information that you see uh minimal. So",
      "offset": 929.04,
      "duration": 5.039
    },
    {
      "lang": "en",
      "text": "like you don't need to see all the API",
      "offset": 931.68,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "tool calls that it's making underneath",
      "offset": 934.079,
      "duration": 2.801
    },
    {
      "lang": "en",
      "text": "the hood or like crowd out the",
      "offset": 935.519,
      "duration": 2.721
    },
    {
      "lang": "en",
      "text": "transcript with a bunch of things. Most",
      "offset": 936.88,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "of the time uh we we just want to keep",
      "offset": 938.24,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "it simple because the contract we want",
      "offset": 941.04,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "to provide to users is like the the the",
      "offset": 942.56,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "feedback loops here are more robust and",
      "offset": 945.199,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "you don't have to um micromanage this as",
      "offset": 946.72,
      "duration": 4.559
    },
    {
      "lang": "en",
      "text": "much. Another thing I want to point out",
      "offset": 949.04,
      "duration": 4.479
    },
    {
      "lang": "en",
      "text": "here is the search tool that this is",
      "offset": 951.279,
      "duration": 5.041
    },
    {
      "lang": "en",
      "text": "using is is actually a sub agent. So",
      "offset": 953.519,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "it's actually spinning off a sub aent",
      "offset": 956.32,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "loop that uses a form of agentic search.",
      "offset": 958.079,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "It has access to a bunch of different",
      "offset": 960.639,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "search tools. Uh keyword search, uh uh",
      "offset": 962.24,
      "duration": 6.32
    },
    {
      "lang": "en",
      "text": "just regular GP, uh looking up file",
      "offset": 966.079,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "names. Uh if you want to inspect what",
      "offset": 968.56,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "it's doing, it you can click the expand",
      "offset": 970.48,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "thing and see like what different paths",
      "offset": 972.48,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "it's taking, what files it's reading,",
      "offset": 974.24,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "what things it uncovered. Uh but again,",
      "offset": 976,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "by default, we think this is like an",
      "offset": 978.16,
      "duration": 2.799
    },
    {
      "lang": "en",
      "text": "implementation detail and hopefully it",
      "offset": 979.44,
      "duration": 3.759
    },
    {
      "lang": "en",
      "text": "should just surface the the right thing.",
      "offset": 980.959,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "Um so it's it's working. It's gathering",
      "offset": 983.199,
      "duration": 4.241
    },
    {
      "lang": "en",
      "text": "context. Um, another thing I want to",
      "offset": 985.519,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "call out in this interface is um, as",
      "offset": 987.44,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "we've gotten more feedback, we've we've",
      "offset": 990.079,
      "duration": 3.361
    },
    {
      "lang": "en",
      "text": "kind of designed this thing to be more",
      "offset": 991.92,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "multi-threaded. So, there's a quick",
      "offset": 993.44,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "keyboard shortcut that allows you to",
      "offset": 995.36,
      "duration": 2.56
    },
    {
      "lang": "en",
      "text": "like quickly tab through the different",
      "offset": 996.72,
      "duration": 2.479
    },
    {
      "lang": "en",
      "text": "threads that you're running. And it's a",
      "offset": 997.92,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "common paradigm in in our user community",
      "offset": 999.199,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "to be running more than one of these",
      "offset": 1001.04,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "things at a time. Um, and it takes a",
      "offset": 1003.04,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "little bit used to get get used to the",
      "offset": 1005.6,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "the context switching. Like developers",
      "offset": 1007.36,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "hate context switching, right? Like we",
      "offset": 1009.12,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "like to be uh in in flow in in focus.",
      "offset": 1010.48,
      "duration": 7.52
    },
    {
      "lang": "en",
      "text": "Um, Typically what we see here is um the",
      "offset": 1014.8,
      "duration": 5.039
    },
    {
      "lang": "en",
      "text": "the secondary thread will either be",
      "offset": 1018,
      "duration": 3.519
    },
    {
      "lang": "en",
      "text": "something that's like a lot shallower so",
      "offset": 1019.839,
      "duration": 2.961
    },
    {
      "lang": "en",
      "text": "that you can quickly page back to the",
      "offset": 1021.519,
      "duration": 3.361
    },
    {
      "lang": "en",
      "text": "main thread or what I like to do is",
      "offset": 1022.8,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "while the agent is working I actually",
      "offset": 1024.88,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "like to understand the code uh at a",
      "offset": 1026.72,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "deeper level myself so I can better",
      "offset": 1028.72,
      "duration": 3.119
    },
    {
      "lang": "en",
      "text": "understand what what it's going to do.",
      "offset": 1030.4,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "So uh I could ask something like can you",
      "offset": 1031.839,
      "duration": 6.321
    },
    {
      "lang": "en",
      "text": "show me how connectors and connections",
      "offset": 1034.88,
      "duration": 6.319
    },
    {
      "lang": "en",
      "text": "work in AMP? I can ask it to draw a",
      "offset": 1038.16,
      "duration": 6.72
    },
    {
      "lang": "en",
      "text": "picture of that.",
      "offset": 1041.199,
      "duration": 5.201
    },
    {
      "lang": "en",
      "text": "So, we'll kick that kick that thread off",
      "offset": 1044.88,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "in parallel. We'll check back in on what",
      "offset": 1046.4,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "this guy is doing. So, it's found uh",
      "offset": 1048,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "it's read a bunch of files. It's read",
      "offset": 1051.28,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "some frontend files. Our front end is",
      "offset": 1053.12,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "written in spelt. Um and as you can see,",
      "offset": 1054.88,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "it's it's being fairly thoughtful about",
      "offset": 1057.84,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "reading the appropriate files before it",
      "offset": 1059.52,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "actually goes and and does the work. And",
      "offset": 1061.2,
      "duration": 4.719
    },
    {
      "lang": "en",
      "text": "we find that this is really important uh",
      "offset": 1063.28,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "to make the feedback cycles uh more",
      "offset": 1065.919,
      "duration": 4.561
    },
    {
      "lang": "en",
      "text": "robust. Um, otherwise the the anti",
      "offset": 1068.08,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "pattern is you just like get into the",
      "offset": 1070.48,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "weeds of like steering it manually.",
      "offset": 1071.76,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "Um, it's also got this to-do list thing",
      "offset": 1074.559,
      "duration": 4.721
    },
    {
      "lang": "en",
      "text": "at the bottom uh that helps it structure",
      "offset": 1077.12,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "and plan out the the longer term tasks",
      "offset": 1079.28,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "so that it doesn't go like immediately",
      "offset": 1081.44,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "dive into the code. This is a classic",
      "offset": 1083.36,
      "duration": 2.64
    },
    {
      "lang": "en",
      "text": "mistake that like human developers make",
      "offset": 1084.72,
      "duration": 2.4
    },
    {
      "lang": "en",
      "text": "too where you like dive into the code",
      "offset": 1086,
      "duration": 2.4
    },
    {
      "lang": "en",
      "text": "too early and then you get lost in the",
      "offset": 1087.12,
      "duration": 2.96
    },
    {
      "lang": "en",
      "text": "weeds and then it takes a while to dig",
      "offset": 1088.4,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "yourself out.",
      "offset": 1090.08,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "Um, okay. So, it's making some changes.",
      "offset": 1092,
      "duration": 5.84
    },
    {
      "lang": "en",
      "text": "Um, one other thing that I like to point",
      "offset": 1094.96,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "out here is, you know, I mentioned that",
      "offset": 1097.84,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "I use the diff view in VS Code now,",
      "offset": 1100.24,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "probably more than the editor view. Uh,",
      "offset": 1102.24,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "VS Code actually has a really nice diff",
      "offset": 1104.16,
      "duration": 3.759
    },
    {
      "lang": "en",
      "text": "view. I have it hotkeyed um, so I can",
      "offset": 1105.6,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "open it up quickly. And most of the my",
      "offset": 1107.919,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "time in VS Code now is spent just like",
      "offset": 1110.48,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "reviewing the changes it uh, it makes.",
      "offset": 1112.799,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "And I actually like this a lot better",
      "offset": 1115.2,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "than uh, like GitHub PRs or uh, git diff",
      "offset": 1116.64,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "on the command line just because it's in",
      "offset": 1119.76,
      "duration": 2.72
    },
    {
      "lang": "en",
      "text": "the editor. you can see the whole file",
      "offset": 1121.039,
      "duration": 5.361
    },
    {
      "lang": "en",
      "text": "and uh jump to definition uh even works.",
      "offset": 1122.48,
      "duration": 6.559
    },
    {
      "lang": "en",
      "text": "Um so yeah, we'll we'll just wait a",
      "offset": 1126.4,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "little bit for it to to do its thing. I",
      "offset": 1129.039,
      "duration": 6.321
    },
    {
      "lang": "en",
      "text": "actually think it's it's probably made",
      "offset": 1131.84,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "looks like it's getting it's getting",
      "offset": 1135.36,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "there. Um let's it's probably just",
      "offset": 1137.44,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "running like tests. Let's see if we go",
      "offset": 1140.24,
      "duration": 5.439
    },
    {
      "lang": "en",
      "text": "back here if it's updated the icon at",
      "offset": 1142.72,
      "duration": 5.959
    },
    {
      "lang": "en",
      "text": "all.",
      "offset": 1145.679,
      "duration": 3
    },
    {
      "lang": "en",
      "text": "Okay, so it hasn't gotten there yet, but",
      "offset": 1150.72,
      "duration": 5.64
    },
    {
      "lang": "en",
      "text": "I think it's on the right track.",
      "offset": 1152.48,
      "duration": 3.88
    },
    {
      "lang": "en",
      "text": "Does it write its own test?\n Uh, the",
      "offset": 1157.28,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "question was, does it write its own",
      "offset": 1159.76,
      "duration": 2.48
    },
    {
      "lang": "en",
      "text": "tests? Yes, it typically writes its own",
      "offset": 1160.88,
      "duration": 2.96
    },
    {
      "lang": "en",
      "text": "tests. And if if it doesn't, you can",
      "offset": 1162.24,
      "duration": 5.439
    },
    {
      "lang": "en",
      "text": "prompt it to to do so. So, uh, it's",
      "offset": 1163.84,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "doing a lot of things. It's reading a",
      "offset": 1167.679,
      "duration": 2.721
    },
    {
      "lang": "en",
      "text": "lot of files. It's making these edits",
      "offset": 1168.96,
      "duration": 2.719
    },
    {
      "lang": "en",
      "text": "incrementally and then checking the",
      "offset": 1170.4,
      "duration": 2.88
    },
    {
      "lang": "en",
      "text": "diagnostics.",
      "offset": 1171.679,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "Um, and then now let's see if it works.",
      "offset": 1173.28,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "Okay, cool. So you see here the icon has",
      "offset": 1175.28,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "been updated and this is without me",
      "offset": 1177.36,
      "duration": 7.12
    },
    {
      "lang": "en",
      "text": "really steering it in in any fashion. Um",
      "offset": 1179.28,
      "duration": 6.88
    },
    {
      "lang": "en",
      "text": "notice here on this page that this icon",
      "offset": 1184.48,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "didn't update though. Um and so this is",
      "offset": 1186.16,
      "duration": 3.759
    },
    {
      "lang": "en",
      "text": "actually not surprising to me because",
      "offset": 1188.08,
      "duration": 3.599
    },
    {
      "lang": "en",
      "text": "this change as many changes in",
      "offset": 1189.919,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "production code bases are often more",
      "offset": 1191.679,
      "duration": 4.721
    },
    {
      "lang": "en",
      "text": "nuanced than it seems at the surface. So",
      "offset": 1193.84,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "in this case, the reason it's not",
      "offset": 1196.4,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "getting it here is because",
      "offset": 1197.84,
      "duration": 6.719
    },
    {
      "lang": "en",
      "text": "uh this is the admin page and the piece",
      "offset": 1200.08,
      "duration": 6.719
    },
    {
      "lang": "en",
      "text": "of data we need to know uh we need to",
      "offset": 1204.559,
      "duration": 4.561
    },
    {
      "lang": "en",
      "text": "read in order to tell that this is a",
      "offset": 1206.799,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "linear MCP uh rather than a generic MCP",
      "offset": 1209.12,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "is actually part of the config. We have",
      "offset": 1212.559,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "to look at the endpoint of the MCP URL.",
      "offset": 1213.76,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "In order to do that, you have to read",
      "offset": 1216.24,
      "duration": 2.96
    },
    {
      "lang": "en",
      "text": "the config, but the config might also",
      "offset": 1217.6,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "contain secrets. Doesn't contain secrets",
      "offset": 1219.2,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "in this case, but might contain secrets",
      "offset": 1220.96,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "in other cases. So, we actually prohibit",
      "offset": 1222.24,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "those secrets from being sent to",
      "offset": 1224.08,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "non-admin pages. Um, so it's not",
      "offset": 1225.84,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "surprising to me that like the first",
      "offset": 1228.24,
      "duration": 2.319
    },
    {
      "lang": "en",
      "text": "pass it didn't get that right, but let's",
      "offset": 1229.28,
      "duration": 3.519
    },
    {
      "lang": "en",
      "text": "see if it can get like I'll just nudge",
      "offset": 1230.559,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "it a little bit. So, like uh I noticed",
      "offset": 1232.799,
      "duration": 5.921
    },
    {
      "lang": "en",
      "text": "that the icon changed",
      "offset": 1234.559,
      "duration": 6.961
    },
    {
      "lang": "en",
      "text": "on admin connections but not on",
      "offset": 1238.72,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "settings.",
      "offset": 1241.52,
      "duration": 3.519
    },
    {
      "lang": "en",
      "text": "Um,",
      "offset": 1243.12,
      "duration": 6.36
    },
    {
      "lang": "en",
      "text": "can you investigate why?",
      "offset": 1245.039,
      "duration": 4.441
    },
    {
      "lang": "en",
      "text": "And uh in the interest of time, we'll",
      "offset": 1250.24,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "check back on this later. How about",
      "offset": 1252.88,
      "duration": 3.279
    },
    {
      "lang": "en",
      "text": "that? Uh we we'll let it run and we'll",
      "offset": 1254.08,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "we'll see if if it can find its way to",
      "offset": 1256.159,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "the right solution there. Um",
      "offset": 1258.4,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "is it okay if I go a little bit over",
      "offset": 1262.159,
      "duration": 2.88
    },
    {
      "lang": "en",
      "text": "since we started a little bit? Okay,",
      "offset": 1263.6,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "cool. Is it okay with you all if I go a",
      "offset": 1265.039,
      "duration": 3.281
    },
    {
      "lang": "en",
      "text": "little bit over? Okay. Are we still",
      "offset": 1266.88,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "having fun?\n Okay, cool. So, that was",
      "offset": 1268.32,
      "duration": 4.719
    },
    {
      "lang": "en",
      "text": "like a brief demo of just like the",
      "offset": 1271.12,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "interaction patterns and and the UI. We",
      "offset": 1273.039,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "try to keep it really minimal. Um, we've",
      "offset": 1274.96,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "released this to like a small group so",
      "offset": 1277.919,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "far. Uh, the the signup is now publicly",
      "offset": 1279.84,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "open. It's been open for about two",
      "offset": 1281.919,
      "duration": 3.441
    },
    {
      "lang": "en",
      "text": "weeks, but we haven't done a lot of like",
      "offset": 1283.2,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "marketing around it and and that's kind",
      "offset": 1285.36,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "of been intentional because we're really",
      "offset": 1287.12,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "trying to design this for where we think",
      "offset": 1289.679,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "the the puck is going. And so, we've",
      "offset": 1291.2,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "we've done a lot to curate this",
      "offset": 1293.28,
      "duration": 3.759
    },
    {
      "lang": "en",
      "text": "community of people who are trying to",
      "offset": 1294.72,
      "duration": 5.199
    },
    {
      "lang": "en",
      "text": "experiment with LMS and figure out like",
      "offset": 1297.039,
      "duration": 4.721
    },
    {
      "lang": "en",
      "text": "how the interaction paradigms are going",
      "offset": 1299.919,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "to change over the next 6 to 12 months.",
      "offset": 1301.76,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "And so our user community is really",
      "offset": 1303.52,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "people who are like spending nights and",
      "offset": 1305.76,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "weekends uh a lot of time with this",
      "offset": 1307.2,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "thing to see what they can get it to do.",
      "offset": 1309.76,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "And so actually one of the the most",
      "offset": 1312.32,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "insightful things and actually the main",
      "offset": 1314.48,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "topic of of this talk is lessons that",
      "offset": 1316.159,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "we've learned from just like looking at",
      "offset": 1318.4,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "what our power users are doing and",
      "offset": 1320.32,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "seeing what interesting behavior",
      "offset": 1322.88,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "patterns uh they're kind of like",
      "offset": 1324.32,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "implementing. Um and so like the average",
      "offset": 1326.48,
      "duration": 6.559
    },
    {
      "lang": "en",
      "text": "spend uh for agents is is growing. It's",
      "offset": 1329.36,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "a lot more than the average spend was",
      "offset": 1333.039,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "for chat bots or or autocomplete. But",
      "offset": 1334.4,
      "duration": 3.279
    },
    {
      "lang": "en",
      "text": "one other interesting thing that we've",
      "offset": 1336.159,
      "duration": 4.561
    },
    {
      "lang": "en",
      "text": "noticed among the user base is that uh",
      "offset": 1337.679,
      "duration": 5.521
    },
    {
      "lang": "en",
      "text": "there's a huge variance in terms of how",
      "offset": 1340.72,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "much people use this thing. Um to the",
      "offset": 1343.2,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "point where like there there's like an",
      "offset": 1346.4,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "upper echelon of users that are spending",
      "offset": 1348.32,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "like thousands of dollars per month uh",
      "offset": 1350.559,
      "duration": 5.281
    },
    {
      "lang": "en",
      "text": "just in inference costs. And at first",
      "offset": 1353.84,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "we're like this has got to be abuse,",
      "offset": 1355.84,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "right? like someone out there is, you",
      "offset": 1357.6,
      "duration": 3.439
    },
    {
      "lang": "en",
      "text": "know, poked uh, you know, found some way",
      "offset": 1359.28,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "to exploit the inference endpoint is is",
      "offset": 1361.039,
      "duration": 5.441
    },
    {
      "lang": "en",
      "text": "using it to power some like Chinese uh,",
      "offset": 1363.36,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "you know, AI girlfriend or whatever. But",
      "offset": 1366.48,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "actually, no, when we when we spoke to",
      "offset": 1368.72,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "uh, the people using it, we actually",
      "offset": 1370.799,
      "duration": 2.721
    },
    {
      "lang": "en",
      "text": "found that they were doing real things",
      "offset": 1372.4,
      "duration": 2.639
    },
    {
      "lang": "en",
      "text": "and we're like, hm, that's interesting.",
      "offset": 1373.52,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "What the hell are you doing? Um and from",
      "offset": 1375.039,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "those insights and the conversations we",
      "offset": 1377.52,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "basically uh have encapsulated a series",
      "offset": 1379.12,
      "duration": 4.559
    },
    {
      "lang": "en",
      "text": "of like best practices or emergent um",
      "offset": 1381.2,
      "duration": 6.08
    },
    {
      "lang": "en",
      "text": "like power user patterns uh for how the",
      "offset": 1383.679,
      "duration": 7.281
    },
    {
      "lang": "en",
      "text": "the very you know uh dominant users the",
      "offset": 1387.28,
      "duration": 6.48
    },
    {
      "lang": "en",
      "text": "the most active users are are using this",
      "offset": 1390.96,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "thing and this has informed our our",
      "offset": 1393.76,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "product design process as well. So one",
      "offset": 1395.52,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "of the the first changes that we made um",
      "offset": 1397.2,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "was we noticed that a lot of the power",
      "offset": 1399.679,
      "duration": 4.801
    },
    {
      "lang": "en",
      "text": "users were very writing very long",
      "offset": 1402.24,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "prompts. It was not like the simple kind",
      "offset": 1404.48,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "of like Google style like three keywords",
      "offset": 1406.4,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "and just like uh read my mind and expect",
      "offset": 1408.08,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "something good to happen. Uh they",
      "offset": 1410.48,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "actually wanted to write a lot of detail",
      "offset": 1412.24,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "because they realized that LMS are",
      "offset": 1414,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "actually quite programmable. If you give",
      "offset": 1416.32,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "them a lot of context, they will follow",
      "offset": 1418,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "those instructions and get further than",
      "offset": 1419.84,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "if you just give them like a oneline",
      "offset": 1421.6,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "sentence. And so we made the default",
      "offset": 1423.28,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "behavior of the enter key in the AMP",
      "offset": 1425.28,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "input just new line. So you have to hit",
      "offset": 1427.76,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "command enter to submit. And this throws",
      "offset": 1429.76,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "a lot of the new users off because",
      "offset": 1431.6,
      "duration": 2.4
    },
    {
      "lang": "en",
      "text": "they're like, &quot;Wait a minute, why isn't",
      "offset": 1432.88,
      "duration": 2.72
    },
    {
      "lang": "en",
      "text": "it just enter?&quot; like you know if I'm in",
      "offset": 1434,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "like cursor or whatever I just enter",
      "offset": 1435.6,
      "duration": 3.439
    },
    {
      "lang": "en",
      "text": "that's easy that's intuitive but",
      "offset": 1437.36,
      "duration": 3.439
    },
    {
      "lang": "en",
      "text": "actually what we want to push users to",
      "offset": 1439.039,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "do is to write those longer prompts",
      "offset": 1440.799,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "because that actually yields better",
      "offset": 1442.72,
      "duration": 2.4
    },
    {
      "lang": "en",
      "text": "results and I think that's one of the",
      "offset": 1443.919,
      "duration": 3.361
    },
    {
      "lang": "en",
      "text": "things that prevents people uh who are",
      "offset": 1445.12,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "still in the kind of like chat LLM uh",
      "offset": 1447.28,
      "duration": 6.48
    },
    {
      "lang": "en",
      "text": "mode from from unlocking some of the you",
      "offset": 1450,
      "duration": 7.6
    },
    {
      "lang": "en",
      "text": "know cool stuff that that agents can do.",
      "offset": 1453.76,
      "duration": 5.84
    },
    {
      "lang": "en",
      "text": "Um, another thing that people do very",
      "offset": 1457.6,
      "duration": 4.959
    },
    {
      "lang": "en",
      "text": "intentionally is direct the agent to",
      "offset": 1459.6,
      "duration": 5.679
    },
    {
      "lang": "en",
      "text": "look at relevant context and feedback",
      "offset": 1462.559,
      "duration": 4.801
    },
    {
      "lang": "en",
      "text": "mechanisms. So, you know, context was",
      "offset": 1465.279,
      "duration": 4.241
    },
    {
      "lang": "en",
      "text": "very important in the chatbot uh era.",
      "offset": 1467.36,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "It's still important in the agentic era.",
      "offset": 1469.52,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "Now, agents do have a good good amount",
      "offset": 1471.52,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "of like built-in knowledge for how to",
      "offset": 1473.76,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "use tools to acquire context. Like you",
      "offset": 1475.36,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "saw that before when it was using the",
      "offset": 1477.12,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "search tool to find different things um",
      "offset": 1478.48,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "and and it was executing the test to and",
      "offset": 1481.12,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "and uh llinters to see if uh the code",
      "offset": 1483.52,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "was valid.",
      "offset": 1486.08,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "Um, but there's still some cases,",
      "offset": 1487.52,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "especially in production code bases",
      "offset": 1489.6,
      "duration": 2.72
    },
    {
      "lang": "en",
      "text": "where it's like, oh, we do things in a",
      "offset": 1490.88,
      "duration": 2.799
    },
    {
      "lang": "en",
      "text": "very specific way that are kind of like",
      "offset": 1492.32,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "out of distribution and and so like some",
      "offset": 1493.679,
      "duration": 7.36
    },
    {
      "lang": "en",
      "text": "like less uh less agentically inclined",
      "offset": 1497.2,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "users at that point will just give up.",
      "offset": 1501.039,
      "duration": 2.481
    },
    {
      "lang": "en",
      "text": "They're like ah, you know, agents aren't",
      "offset": 1502.32,
      "duration": 2.8
    },
    {
      "lang": "en",
      "text": "capable of working with like backend",
      "offset": 1503.52,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "code yet. But what we've noticed is the",
      "offset": 1505.12,
      "duration": 3.439
    },
    {
      "lang": "en",
      "text": "power user like actually let me try to",
      "offset": 1506.88,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "just tell it how to run, you know, the",
      "offset": 1508.559,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "build in this particular subdirectory or",
      "offset": 1510.799,
      "duration": 3.521
    },
    {
      "lang": "en",
      "text": "run the tests. and that helps it",
      "offset": 1512.559,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "complete the feedback loop so that it",
      "offset": 1514.32,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "can get the validation to get further.",
      "offset": 1516.159,
      "duration": 5.441
    },
    {
      "lang": "en",
      "text": "Um, feedback loops are going to be a big",
      "offset": 1519.76,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "theme of of this talk. So, another like",
      "offset": 1521.6,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "dominant uh paradigm here is",
      "offset": 1524.88,
      "duration": 3.279
    },
    {
      "lang": "en",
      "text": "constructing these like front-end",
      "offset": 1526.88,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "feedback loops. So, like a really common",
      "offset": 1528.159,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "formula is you have the playright MCP",
      "offset": 1530,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "server and then there's a thing called",
      "offset": 1532.24,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "storybook which is basically a way to",
      "offset": 1533.919,
      "duration": 4.721
    },
    {
      "lang": "en",
      "text": "encapsulate or componentize a lot of",
      "offset": 1536,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "your front end components. It makes it",
      "offset": 1538.64,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "very easy to test individual components",
      "offset": 1539.919,
      "duration": 4.721
    },
    {
      "lang": "en",
      "text": "without loading your entire app. And you",
      "offset": 1542,
      "duration": 3.679
    },
    {
      "lang": "en",
      "text": "know, you probably should have been",
      "offset": 1544.64,
      "duration": 2.88
    },
    {
      "lang": "en",
      "text": "doing this anyways as a human developer",
      "offset": 1545.679,
      "duration": 3.201
    },
    {
      "lang": "en",
      "text": "because you get a fast feedback loop.",
      "offset": 1547.52,
      "duration": 2.8
    },
    {
      "lang": "en",
      "text": "You make a change, see it reflected",
      "offset": 1548.88,
      "duration": 2.799
    },
    {
      "lang": "en",
      "text": "instantly. You get the auto reload and",
      "offset": 1550.32,
      "duration": 2.959
    },
    {
      "lang": "en",
      "text": "then go back to your editor. But with",
      "offset": 1551.679,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "agents, you you kind of notice it more",
      "offset": 1553.279,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "because you're no longer like in the",
      "offset": 1555.36,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "weeds doing the thing. You're like, oh,",
      "offset": 1556.559,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "you're you're almost like the developer",
      "offset": 1558.48,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "experience engineer for your agent. It's",
      "offset": 1559.919,
      "duration": 3.201
    },
    {
      "lang": "en",
      "text": "like, how can I make it loop back",
      "offset": 1561.52,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "faster? And so what the agent will do is",
      "offset": 1563.12,
      "duration": 3.439
    },
    {
      "lang": "en",
      "text": "like, you know, make the code change,",
      "offset": 1564.64,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "use playrite to open up the page in the",
      "offset": 1566.559,
      "duration": 4.641
    },
    {
      "lang": "en",
      "text": "browser, snapshot it, uh, uh, and then",
      "offset": 1568.559,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "loop back on itself. And it does that",
      "offset": 1571.2,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "via storybook because it's much faster",
      "offset": 1572.72,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "than reloading the the entire app.",
      "offset": 1574.24,
      "duration": 5.919
    },
    {
      "lang": "en",
      "text": "You you put right as a tool for you.",
      "offset": 1577.52,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "Yes. So it's um, one of the default",
      "offset": 1580.159,
      "duration": 5.681
    },
    {
      "lang": "en",
      "text": "recommended tools.\n So it's right here.",
      "offset": 1582.88,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "Um, and actually it looks like looks",
      "offset": 1585.84,
      "duration": 7.68
    },
    {
      "lang": "en",
      "text": "like that run completed. I wonder if uh",
      "offset": 1588.88,
      "duration": 6.399
    },
    {
      "lang": "en",
      "text": "it looks like it did approximately the",
      "offset": 1593.52,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "right thing. Um sorry, just to jump out",
      "offset": 1595.279,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "of the sides of her a little bit. So now",
      "offset": 1597.919,
      "duration": 2.64
    },
    {
      "lang": "en",
      "text": "you can see like the icon is is",
      "offset": 1599.279,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "customized on the settings page, not",
      "offset": 1600.559,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "just the admin page. And if you look at",
      "offset": 1602.559,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "how it did that, I think it did the",
      "offset": 1604.72,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "right thing. So if you look at the diff,",
      "offset": 1606.799,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "um it actually looked at the surrounding",
      "offset": 1609.2,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "code and was like, &quot;Oh, there is an",
      "offset": 1610.72,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "existing mechanism for plumbing",
      "offset": 1613.279,
      "duration": 3.441
    },
    {
      "lang": "en",
      "text": "non-secret parts of the config through",
      "offset": 1614.96,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "to the UI. let me kind of like use that",
      "offset": 1616.72,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "as a reference point. And it actually",
      "offset": 1619.12,
      "duration": 5.679
    },
    {
      "lang": "en",
      "text": "plumbed exactly that like uh field",
      "offset": 1621.6,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "through to the front end. So now if I",
      "offset": 1624.799,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "add like additional fields to the MCP",
      "offset": 1627.12,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "config that do contain secrets, uh it",
      "offset": 1628.72,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "this is like whitelisted. So it'll still",
      "offset": 1631.2,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "only send the endpoint URL over to the",
      "offset": 1632.96,
      "duration": 3.199
    },
    {
      "lang": "en",
      "text": "client. You know, basically what it",
      "offset": 1634.88,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "needs to make that icon customization.",
      "offset": 1636.159,
      "duration": 5.921
    },
    {
      "lang": "en",
      "text": "Um, so yeah, I know like you know it's",
      "offset": 1638.88,
      "duration": 5.039
    },
    {
      "lang": "en",
      "text": "not a super impressively visual change",
      "offset": 1642.08,
      "duration": 3.599
    },
    {
      "lang": "en",
      "text": "but like a lot of such changes in in",
      "offset": 1643.919,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "messy production code bases are like",
      "offset": 1645.679,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "that and it's cool to see the agent uh",
      "offset": 1647.039,
      "duration": 7.041
    },
    {
      "lang": "en",
      "text": "be able to tease tease out that nuance.",
      "offset": 1650.799,
      "duration": 5.041
    },
    {
      "lang": "en",
      "text": "Um,",
      "offset": 1654.08,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "okay. I know we're we're a little bit",
      "offset": 1655.84,
      "duration": 3.439
    },
    {
      "lang": "en",
      "text": "over time. Can I people mind if I keep",
      "offset": 1657.44,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "going or uh Okay, cool.",
      "offset": 1659.279,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "[Laughter]",
      "offset": 1662.4,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "Um, there's uh some additional uh tips",
      "offset": 1664.559,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "and tricks. Most of this talk is just",
      "offset": 1667.52,
      "duration": 2.48
    },
    {
      "lang": "en",
      "text": "like sharing what we've learned from our",
      "offset": 1668.799,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "power users. So another thing that we've",
      "offset": 1670,
      "duration": 3.279
    },
    {
      "lang": "en",
      "text": "noticed is like there's this kind of",
      "offset": 1672.159,
      "duration": 2.64
    },
    {
      "lang": "en",
      "text": "this prevailing narrative that like you",
      "offset": 1673.279,
      "duration": 2.64
    },
    {
      "lang": "en",
      "text": "know agents are going to make",
      "offset": 1674.799,
      "duration": 2.641
    },
    {
      "lang": "en",
      "text": "programmers lazy. It's going to make it",
      "offset": 1675.919,
      "duration": 3.281
    },
    {
      "lang": "en",
      "text": "so we don't really understand what what",
      "offset": 1677.44,
      "duration": 3.359
    },
    {
      "lang": "en",
      "text": "what's going on in the code. So we're",
      "offset": 1679.2,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "going to ship more slop. But we've",
      "offset": 1680.799,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "actually found the inverse happen uh",
      "offset": 1682.48,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "with with the power users. They're",
      "offset": 1684.48,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "actually using agents to better",
      "offset": 1685.76,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "understand uh the code. And so this is a",
      "offset": 1687.6,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "really good onboarding tool. Like we",
      "offset": 1689.919,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "just hired this guy Tyler Bruno. He's a",
      "offset": 1691.44,
      "duration": 4.479
    },
    {
      "lang": "en",
      "text": "very precocious young developer. He's",
      "offset": 1693.679,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "actually still in college, but he's",
      "offset": 1695.919,
      "duration": 3.521
    },
    {
      "lang": "en",
      "text": "working full-time in addition to taking",
      "offset": 1697.679,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "classes. Uh, so really bright, but also,",
      "offset": 1699.44,
      "duration": 4.479
    },
    {
      "lang": "en",
      "text": "you know, a bit green. Um, he's been",
      "offset": 1701.84,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "using AMP to just like quickly ramp up",
      "offset": 1703.919,
      "duration": 3.521
    },
    {
      "lang": "en",
      "text": "on how the different pieces connect",
      "offset": 1705.6,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "together. Uh, and it could draw diagrams",
      "offset": 1707.44,
      "duration": 3.599
    },
    {
      "lang": "en",
      "text": "and and point you to specific pieces of",
      "offset": 1709.44,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "the code. And, uh, it's really good at",
      "offset": 1711.039,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "accelerating that. And then a correlary",
      "offset": 1712.64,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "to this is like, you know, we all do a",
      "offset": 1715.039,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "form of onboarding to new code whenever",
      "offset": 1716.88,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "we do a code review. Like, by",
      "offset": 1718.559,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "definition, code review is is new code.",
      "offset": 1720,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "And often times it's new code that",
      "offset": 1722.24,
      "duration": 4.559
    },
    {
      "lang": "en",
      "text": "contains bugs or is hard to understand",
      "offset": 1724.72,
      "duration": 4.959
    },
    {
      "lang": "en",
      "text": "or is a bit of a slog. Um and so rather",
      "offset": 1726.799,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "than just you know ignore the code that",
      "offset": 1729.679,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "the AI generates and just commit it",
      "offset": 1732.399,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "blindly uh we find that our user base is",
      "offset": 1733.919,
      "duration": 4.561
    },
    {
      "lang": "en",
      "text": "actually using this tool to do more",
      "offset": 1736.559,
      "duration": 3.521
    },
    {
      "lang": "en",
      "text": "thorough code reviews. So like I've",
      "offset": 1738.48,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "adopted this practice myself where if I",
      "offset": 1740.08,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "have to review a very large diff the",
      "offset": 1742.48,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "first thing I do is ask the agent to",
      "offset": 1744.48,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "consume the diff and generate a high",
      "offset": 1746.72,
      "duration": 2.959
    },
    {
      "lang": "en",
      "text": "level summary so I can have like a high",
      "offset": 1748.08,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "level awareness and then I ask it like",
      "offset": 1749.679,
      "duration": 4.561
    },
    {
      "lang": "en",
      "text": "hey if you were a smart senior dev",
      "offset": 1751.52,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "what's the entry point into this PR",
      "offset": 1754.24,
      "duration": 3.439
    },
    {
      "lang": "en",
      "text": "because like often half the time half",
      "offset": 1756.08,
      "duration": 2.8
    },
    {
      "lang": "en",
      "text": "the battle is just like finding the",
      "offset": 1757.679,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "right entry point and uh psychologically",
      "offset": 1758.88,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "I I often put off code reviews because",
      "offset": 1761.76,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "I'm like oh it's going to be a pain and",
      "offset": 1763.76,
      "duration": 3.519
    },
    {
      "lang": "en",
      "text": "it's going to take forever just to like",
      "offset": 1765.84,
      "duration": 2.4
    },
    {
      "lang": "en",
      "text": "figure out where I should start",
      "offset": 1767.279,
      "duration": 2.801
    },
    {
      "lang": "en",
      "text": "reviewing it so I'll just it tomorrow.",
      "offset": 1768.24,
      "duration": 3.679
    },
    {
      "lang": "en",
      "text": "But this thing just like it helps lower",
      "offset": 1770.08,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "that activation energy and and make code",
      "offset": 1771.919,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "reviews more thorough and and actually",
      "offset": 1773.6,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "uh dare I say like a little bit fun and",
      "offset": 1776.159,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "enjoyable now.",
      "offset": 1778.08,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "Um sub aents are also things. So uh we",
      "offset": 1780.399,
      "duration": 5.441
    },
    {
      "lang": "en",
      "text": "implemented uh the search tool as a sub",
      "offset": 1783.84,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "aent uh in the very beginning but we're",
      "offset": 1785.84,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "seeing more and more uh use cases emerge",
      "offset": 1787.76,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "for sub aents and the general best",
      "offset": 1789.76,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "practice with sub aents uh is that they",
      "offset": 1791.2,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "often are useful for longer uh more",
      "offset": 1793.76,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "complex tasks because the sub aent",
      "offset": 1796.08,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "allows you to essentially preserve the",
      "offset": 1798,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "context window. So like the the the",
      "offset": 1799.44,
      "duration": 6.479
    },
    {
      "lang": "en",
      "text": "quality of the LLM will degrade uh over",
      "offset": 1802.72,
      "duration": 5.199
    },
    {
      "lang": "en",
      "text": "time. You know, Sonnet 4 has a context",
      "offset": 1805.919,
      "duration": 4.561
    },
    {
      "lang": "en",
      "text": "window of 200K, but we see degradation",
      "offset": 1807.919,
      "duration": 5.041
    },
    {
      "lang": "en",
      "text": "typically around like 120 or 130K, and",
      "offset": 1810.48,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "by the time you get hit 170 tokens, uh",
      "offset": 1812.96,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "it you start to see more kind of like",
      "offset": 1815.6,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "off the rails and crazy behavior. Uh but",
      "offset": 1817.36,
      "duration": 4.559
    },
    {
      "lang": "en",
      "text": "sub aents allow you to encapsulate uh",
      "offset": 1819.52,
      "duration": 4.639
    },
    {
      "lang": "en",
      "text": "the context used up by a specific",
      "offset": 1821.919,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "subtask like implementing a small",
      "offset": 1824.159,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "feature uh such that it doesn't pollute",
      "offset": 1825.84,
      "duration": 4.959
    },
    {
      "lang": "en",
      "text": "the the main agent.",
      "offset": 1828.08,
      "duration": 4.959
    },
    {
      "lang": "en",
      "text": "Okay, so that was a quick tour of of uh",
      "offset": 1830.799,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "a lot of best practices. Just to recap",
      "offset": 1833.039,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "like the anti practices, uh the common",
      "offset": 1834.72,
      "duration": 3.199
    },
    {
      "lang": "en",
      "text": "anti patterns are just like",
      "offset": 1836.559,
      "duration": 3.761
    },
    {
      "lang": "en",
      "text": "micromanaging the agent, like using it",
      "offset": 1837.919,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "like you would a chatbot where you have",
      "offset": 1840.32,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "to kind of like steer at every",
      "offset": 1841.679,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "interaction or review every edit it's",
      "offset": 1843.36,
      "duration": 5.039
    },
    {
      "lang": "en",
      "text": "making. Um another common uh antiattern",
      "offset": 1845.6,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "is just like underprompting. So not",
      "offset": 1848.399,
      "duration": 4.561
    },
    {
      "lang": "en",
      "text": "giving it enough detail. Like LMS their",
      "offset": 1850.24,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "knowledge comes from two places. It",
      "offset": 1852.96,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "either comes from their training data or",
      "offset": 1854.72,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "from the context that you give it. And",
      "offset": 1857.039,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "so, uh, you know, it's fine if you do a",
      "offset": 1859.6,
      "duration": 5.199
    },
    {
      "lang": "en",
      "text": "fiveword prompt if you're coding up like",
      "offset": 1862.159,
      "duration": 4.961
    },
    {
      "lang": "en",
      "text": "a 3D Flappy Bird game from scratch",
      "offset": 1864.799,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "because that's well represented in the",
      "offset": 1867.12,
      "duration": 2.32
    },
    {
      "lang": "en",
      "text": "training set. They're really good at",
      "offset": 1868.48,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "that. They're trained to do that. Um,",
      "offset": 1869.44,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "but if you're trying to make a subtle",
      "offset": 1871.52,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "nuance change to your large existing",
      "offset": 1873.6,
      "duration": 3.679
    },
    {
      "lang": "en",
      "text": "codebase, you should be giving it all",
      "offset": 1875.44,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "the details that you would give a",
      "offset": 1877.279,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "colleague on the team uh uh to point",
      "offset": 1878.88,
      "duration": 4.799
    },
    {
      "lang": "en",
      "text": "them in the right direction. And then",
      "offset": 1881.6,
      "duration": 3.679
    },
    {
      "lang": "en",
      "text": "last but not least, like agents are are",
      "offset": 1883.679,
      "duration": 4.561
    },
    {
      "lang": "en",
      "text": "not a vehicle to like TLDDR the code. If",
      "offset": 1885.279,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "anything, they're the opposite. You",
      "offset": 1888.24,
      "duration": 2.559
    },
    {
      "lang": "en",
      "text": "should be using them to do much more",
      "offset": 1889.44,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "thorough code reviews more quickly. Uh",
      "offset": 1890.799,
      "duration": 4.961
    },
    {
      "lang": "en",
      "text": "the human is still you're ultimately",
      "offset": 1893.76,
      "duration": 3.519
    },
    {
      "lang": "en",
      "text": "responsible for the code that you ship",
      "offset": 1895.76,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "and you shouldn't view this as a human",
      "offset": 1897.279,
      "duration": 3.361
    },
    {
      "lang": "en",
      "text": "replacement. It's really a tool that you",
      "offset": 1899.12,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "can wield to make yourself uh 10 100x",
      "offset": 1900.64,
      "duration": 4.639
    },
    {
      "lang": "en",
      "text": "more effective.",
      "offset": 1903.44,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "Uh last tidbit. So one of the things",
      "offset": 1905.279,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "that we've noticed among the very very",
      "offset": 1907.6,
      "duration": 7.12
    },
    {
      "lang": "en",
      "text": "very top 1% of the 1% is uh this this uh",
      "offset": 1908.88,
      "duration": 8.08
    },
    {
      "lang": "en",
      "text": "inclination to run multiple of these",
      "offset": 1914.72,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "things in parallel. So uh Jeff Huntley",
      "offset": 1916.96,
      "duration": 5.439
    },
    {
      "lang": "en",
      "text": "who wrote that blog post uh that I I",
      "offset": 1920.24,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "showed earlier um he started putting out",
      "offset": 1922.399,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "these uh Twitter uh streams. They're",
      "offset": 1925.2,
      "duration": 4.719
    },
    {
      "lang": "en",
      "text": "about like four hours long each and it's",
      "offset": 1927.919,
      "duration": 4.801
    },
    {
      "lang": "en",
      "text": "basically just uh what he's he's working",
      "offset": 1929.919,
      "duration": 5.041
    },
    {
      "lang": "en",
      "text": "on like a compiler on the side. And what",
      "offset": 1932.72,
      "duration": 5.839
    },
    {
      "lang": "en",
      "text": "he does is he he uh constructs prompts",
      "offset": 1934.96,
      "duration": 5.439
    },
    {
      "lang": "en",
      "text": "for like three or four different agents",
      "offset": 1938.559,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "to to work on different parts of of the",
      "offset": 1940.399,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "compiler. Uh and he's gotten to the",
      "offset": 1942.88,
      "duration": 3.279
    },
    {
      "lang": "en",
      "text": "point where he's prompting it such that",
      "offset": 1944.799,
      "duration": 2.48
    },
    {
      "lang": "en",
      "text": "he feels confident enough in the",
      "offset": 1946.159,
      "duration": 3.041
    },
    {
      "lang": "en",
      "text": "feedback loops where he just like hits",
      "offset": 1947.279,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "enter, lets him run, and then goes to",
      "offset": 1949.2,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "sleep. And then like this thing just",
      "offset": 1950.559,
      "duration": 3.441
    },
    {
      "lang": "en",
      "text": "runs on Twitter for a while. And I think",
      "offset": 1952.24,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "he's doing this to kind of like spread",
      "offset": 1954,
      "duration": 3.519
    },
    {
      "lang": "en",
      "text": "the word. It's like hey you can use this",
      "offset": 1955.36,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "for serious engineering engineering like",
      "offset": 1957.519,
      "duration": 4.561
    },
    {
      "lang": "en",
      "text": "compilers are not some like vibe coding",
      "offset": 1959.519,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "uh vibecoded weekend project they're",
      "offset": 1962.08,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "they're real tech they're they're",
      "offset": 1964.159,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "difficult to build um and it is possible",
      "offset": 1966.399,
      "duration": 5.681
    },
    {
      "lang": "en",
      "text": "to use agents for for code like this but",
      "offset": 1969.519,
      "duration": 4.481
    },
    {
      "lang": "en",
      "text": "it has to be a very intentional skill",
      "offset": 1972.08,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "that that you you practice and so I",
      "offset": 1974,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "think it's cool I think like there's a",
      "offset": 1977.12,
      "duration": 2.32
    },
    {
      "lang": "en",
      "text": "lot of people thinking in terms of like",
      "offset": 1978.24,
      "duration": 2.64
    },
    {
      "lang": "en",
      "text": "agent fleets and where the the world is",
      "offset": 1979.44,
      "duration": 3.599
    },
    {
      "lang": "en",
      "text": "going but I I do think that the way that",
      "offset": 1980.88,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "we'll actually get there is by like",
      "offset": 1983.039,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "building these like composable building",
      "offset": 1985.2,
      "duration": 3.199
    },
    {
      "lang": "en",
      "text": "blocks that allow people like Jeff to go",
      "offset": 1986.559,
      "duration": 4.561
    },
    {
      "lang": "en",
      "text": "and like combine them and and uh come up",
      "offset": 1988.399,
      "duration": 4.561
    },
    {
      "lang": "en",
      "text": "with interesting UIs. I think this is",
      "offset": 1991.12,
      "duration": 3.279
    },
    {
      "lang": "en",
      "text": "just running in like T-Mox or some",
      "offset": 1992.96,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "window manager.",
      "offset": 1994.399,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "Okay, so like the takeaways I just want",
      "offset": 1996.48,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "to leave you with is one, you know,",
      "offset": 1998.24,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "contrary to what some might say and you",
      "offset": 2001.12,
      "duration": 2.96
    },
    {
      "lang": "en",
      "text": "know, look, there's a lot of smart",
      "offset": 2002.96,
      "duration": 2.88
    },
    {
      "lang": "en",
      "text": "senior developers out there who think AI",
      "offset": 2004.08,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "is overhyped and maybe parts of it are,",
      "offset": 2005.84,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "but like I think coding agents are very",
      "offset": 2007.36,
      "duration": 5.84
    },
    {
      "lang": "en",
      "text": "real and it is uh I think a high ceiling",
      "offset": 2009.679,
      "duration": 6.48
    },
    {
      "lang": "en",
      "text": "skill. It's like I think we will",
      "offset": 2013.2,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "probably invest in learning how to use",
      "offset": 2016.159,
      "duration": 3.281
    },
    {
      "lang": "en",
      "text": "these things in the same way that we",
      "offset": 2018,
      "duration": 3.279
    },
    {
      "lang": "en",
      "text": "invest in learning how best to use our",
      "offset": 2019.44,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "editor or our programming language of",
      "offset": 2021.279,
      "duration": 4.801
    },
    {
      "lang": "en",
      "text": "choice. And I think the only way you can",
      "offset": 2023.36,
      "duration": 4.559
    },
    {
      "lang": "en",
      "text": "learn this stuff is is by doing it and",
      "offset": 2026.08,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "then sharing it out with others. Uh and",
      "offset": 2027.919,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "one of the reasons we built the kind of",
      "offset": 2030,
      "duration": 3.279
    },
    {
      "lang": "en",
      "text": "like thread sharing mechanism into AMP",
      "offset": 2031.519,
      "duration": 3.441
    },
    {
      "lang": "en",
      "text": "is to help encourage knowledge",
      "offset": 2033.279,
      "duration": 3.201
    },
    {
      "lang": "en",
      "text": "dissemination so that like if you",
      "offset": 2034.96,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "discover an interesting way of of using",
      "offset": 2036.48,
      "duration": 3.199
    },
    {
      "lang": "en",
      "text": "it, you can share that out with your",
      "offset": 2038.24,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "team. Um but yeah, that's it. If you",
      "offset": 2039.679,
      "duration": 5.921
    },
    {
      "lang": "en",
      "text": "want to kind of like see a recap of the",
      "offset": 2043.36,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "best practices in this talk, we've",
      "offset": 2045.6,
      "duration": 3.039
    },
    {
      "lang": "en",
      "text": "actually put out like a an AMP owners",
      "offset": 2046.96,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "manual that guides new users how to to",
      "offset": 2048.639,
      "duration": 4.801
    },
    {
      "lang": "en",
      "text": "best use it. Um, I'll also be around",
      "offset": 2050.8,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "afterwards. We have a booth in the main",
      "offset": 2053.44,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "expo hall. Uh, I'm supposed to say too,",
      "offset": 2055.28,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "if you stop by the booth, we'll give you",
      "offset": 2057.52,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "like $10 in in free credits. So, if",
      "offset": 2059.119,
      "duration": 4.641
    },
    {
      "lang": "en",
      "text": "anything you saw here was of interest of",
      "offset": 2061.919,
      "duration": 3.521
    },
    {
      "lang": "en",
      "text": "you and you want to try this out, um,",
      "offset": 2063.76,
      "duration": 5.72
    },
    {
      "lang": "en",
      "text": "stop by and and say hi.",
      "offset": 2065.44,
      "duration": 4.04
    },
    {
      "lang": "en",
      "text": "I noticed you still type can you and",
      "offset": 2072.56,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "then you correct your uh typos which I",
      "offset": 2075.2,
      "duration": 4.879
    },
    {
      "lang": "en",
      "text": "guess you said you shouldn't do.\n Yeah, I",
      "offset": 2077.76,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "habit.\n I it's it's part habit and it's",
      "offset": 2080.079,
      "duration": 4.481
    },
    {
      "lang": "en",
      "text": "part paranoia that in like a live demo",
      "offset": 2082.32,
      "duration": 5.279
    },
    {
      "lang": "en",
      "text": "setting there will be some uh typo token",
      "offset": 2084.56,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "that will trigger off the rails",
      "offset": 2087.599,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "behavior. But it like I think that was",
      "offset": 2089.04,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "more of a concern that I learned in like",
      "offset": 2091.119,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "2023 when it actually mattered cuz like",
      "offset": 2092.96,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "these days LM are are more and more like",
      "offset": 2095.359,
      "duration": 6.841
    },
    {
      "lang": "en",
      "text": "typo robust I would say.",
      "offset": 2098,
      "duration": 4.2
    },
    {
      "lang": "en",
      "text": "[Music]",
      "offset": 2103.92,
      "duration": 3
    }
  ],
  "cleanText": "[Music]\nMy name is Beyang Liu. I'm the CTO and co-founder of a company called Sourcegraph. Uh, we build developer tools, and today I want to share with you some of the observations and insights that we've had on this sort of like emerging skill set of how to wield coding agents.\n\nThat sound good to everyone? All right, cool. Um, okay. So, let's check in on the uh, the the agent discourse. Uh, I don't know if you all saw this, but a couple days ago there were some spicy tweets about the the efficacy of AI coding agents or, you know, inefficacy depending on your perspective. So, um, Jonathan Blow, who's a really talented developer, he basically single-handedly coded up the indie game Braid, if you're familiar with that. So, like, he's he's kind of like god tier status in terms of coding ability. Um, retweeted Alex Albert, who's also someone I respect and admire a lot, uh, works at Enthropic and basically claiming that, you know, all the hype around coding agents and code in general, uh, was just, it is just hype, right? There's no substance there. Um, and then there were some responses, and there was kind of a spectrum of responses too. You know, we had some other uh, big names in the developer world like Jesse Friselle. She was one of the early uh, contributors, maintainers of Docker. She's also really legit. Uh, she said basically something to the effect of like, um, I think you're right. Uh, but you're in like the top 0.1% of programmers, Jonathan. For the rest of us, you know, down here in this room that aren't on Mount Olympus, it actually helps a lot. Um, but not super helpful if you're if you're really, really good. Um, but then we also had folks like Eric S. Raymond, who is like the one of the fathers of open source, uh, who had a very spicy reply. is basically like, look, I, you know, consider myself to be pretty decent at programming, and uh, these things help a lot. Uh, and then uh, the the kind of my favorite one of this was actually the the top a Hacker News post that was written by um, uh, Thomas uh, uh, Tachek, uh, who is a a really legit security engineer. Um, some of you may have seen this uh, trending. He was he was basically taking the opposite view of like, you know, there's some really smart people there who are very AI skeptical, but they're nuts. Like, uh, these things are really useful. Um, so I I'm guessing if you're at this conference, you probably lean toward coding agents uh, are substantively uh, useful and there's something there. I don't know. Uh, just a just a guess. But I think even within this room, there's probably a spectrum of uh, best practices and opinions about like where agents are good. Uh, you know, whether they're restricted to like small edits or like front-end applications or weekend vi coding, whether they actually work on your production codebase. And um, I think this is just uh, indicative of of the dynamic technical landscape that that we're in right now. And a couple months back, I I wrote this blog post from this guy Jeff Huntley. So, Jeff was a senior engineer at Canva at the time. And uh, his role at Canva is really interesting. He basically went around interviewing all the uh, developers inside of Canva using AI tools like cursor and and other things and seeing how they're using it. And he basically came to the conclusion that like most people were holding it wrong. Uh, which is which is really interesting. And he he came up with a blog post about like all the different anti-patterns that he was seeing. Um, but my summation of of of that blog post is like the the number one mistake that people are using with coding agents right now is they're trying to use coding agents the same way they're using AI coding tools uh, six months ago. Um, and and therefore they're wrong, which is kind of crazy because normally if you're you know using a tool, uh, the the best practices don't change in in six months. Typically the things that you learn that are good uh, will still be like present uh, and and uh, you know, topical and relevant 6 months uh, down the line. But I think we're in a really interesting moment in time right now, and you know, why the sudden change? I think it's because uh, of this step function transition uh, that we've experienced in model capabilities in the past 6 months.\n\nSo, you know, we've we've all been around since the dawn of generative AI, the ancient year of uh, 2022, right? November 2022 was when ChatGPT launched, right? And every year uh, now, you know, this is now the year three, you know, three after ChatGPT, right? We're now living in the AI future. Um, but I think there's already been kind of like three distinct waves or or eras largely driven by the evolution of frontier model capabilities.\n\nUm, and the model capabilities really dictate the uh, ideal architecture uh, that that becomes dominant at the application layer. So in the GPT-3 era, all the models were text completion models, uh, which meant all the applications that people were building uh, were these like co-pilots or autocomplete tools. So the dominant UX paradigm was like you type some stuff, it types some stuff, you type some more, and that's how you would interact. Uh, and then ChatGPT came along uh, with GPT-3.5, which was instruct tuned to interact like a uh, a chatbot. Uh, and suddenly people realized like, oh, it's not just completing the next thing I'm talking about. I can actually ask it questions like I can a human now. Uh, and then some other people came along. Uh, we were part of this crowd. We realized like, hey, um, you know, what's even better than just like asking it questions? You can actually copy paste stuff into the chat and say like, here's some code from my codebase, use that as an example and pattern match against that, and you that helps it generate, you know, a little bit better code or less uh, less fake code or less hallucinated code than uh, it did before. And uh, that basically meant that everyone at the application layer was building a RAGbot uh, in in 2023. So like a chatbot plus a a RAG retrieval engine. But now uh, I think we've entered a new era, and I don't I'm not sure if everyone realizes it, or maybe this is I don't know, like who agrees with this statement, like who thinks it's a real paradigm shift? Okay. And then who's who here is like, ah, that's a bunch of...\n\nAnyone feel free to... I like... Okay. Okay.\nSo maybe I'm, maybe I could just skip this slide.\n\nUm, so we're now living in the era of agents, and the new model capabilities uh, really dictate a new application architecture. And so one of the things that we asked ourselves at Sourcegraph is, you know, a lot of the existing tools in the market, they were designed for the era of GPT-4 and uh, Claude 3. So there a lot of the application stuff, uh, features and UX and UI was really built around the capabilities or in some cases the limitations of the chat-based LLMs. Um, and so if we were going to design a coding agent from the ground up to unleash the capabilities of tool using LLMs, agentic LLMs, uh, what would that look like?\n\nOkay, so here are my spicy takes. Uh, these are controversial design decisions that I think are are better to make in the age of agents. Uh, and many of these go against the best practices that kind of emerged in the chatbot era. Okay, so number one is uh, the agent should just make edits to your files. It shouldn't ask you at every turn like, \"Hey, you know, I want to make this change. Should I apply it?\" Uh, if it's asking you and it's wrong, uh, it's already done the wrong thing and it's wasted your time. Uh, humans need to get uh, more out of the inner loop and more kind of like on top of the loop, like still steering it and guiding it, but less, you know, micromanaging and and managing every change. Second thing is, do we still need a thick client uh, to uh, to manipulate the LLMs? Like, do we still need a fork VS Code? That's like the salty way of saying this, right? Um, the VS Code fork became the the culmination of the AI coding application, I think, for for the the chatbot era. But there's this question of like, you know, if the contract of an agent is you ask it to do stuff and then it does stuff, do you really still need all that UI built around like context management and applying the proposed change in the codebase, or can you just ask it to do stuff and expect it to to do the right thing?\n\nThird, I think we're going to move beyond the choose your own model uh, phase. So I think in the chatbot era, it was very easy to swap models in and out, and you'd like, oh, you know, a new model came along. Let me swap it out and see how well it attends to the context that my retrieval engine fetches. Um, in the agentic world, there's a much deeper coupling uh, because the LLM that you're using essentially becomes the the brains of these agentic chains, and so it's much harder to rip and replace. And I think a lot of people in this room who have tried mixing and matching uh, you know, different models uh, in the context of agents have found that it, you know, swapping out a different model and expecting similar results is is very different. A lot of the like a lot of the LLMs out there aren't even good at the basics of tool use yet. So it's it's very difficult to just replace the brains. Um, four is, I think we're going to move past the era of fixed pricing. Uh, agents eat up a lot of tokens, and so they look expensive relative to chatbots. Uh, but the comparison that more and more people are making is how much human time is it saving? So they're still cheap relative to to human time saved. And the fixed pricing model actually introduces a perverse incentive now where uh, it's like selling gym memberships, right? Like if if I sold you a membership to my chatbot and you're now paying me, you know, 20 bucks a month, uh, my incentive now is to push the inference cost as low as possible. And the easiest way to do that is to use dumber models. Um, but dumber models just waste more more of your time. Um, sorry, this is a long list. Um, uh, hopefully it's not too tedious, but um, I think these are important points. Uh, the the second to last point I'll make is, I think the Unix philosophy is going to be more powerful here than vertical integration. So in developer tools, the ability uh, to use simple tools in ways that compose well with other interesting tools is really powerful. And so I think especially with agents where there's less of a need to create like a lot of UI around it, you're going to start to see more command driven tools, command line tools and things like that. Um, and then last but not least is uh, you know, we had an existing uh, RAG chat coding assistant. Maybe some of you have used it. It was called Kodi. Um, it still exists. We're still supporting it. Uh, it's still in heavy use across, you know, many Fortune 500 companies. Uh, but we decided to build a a new application from from the ground up for the agentic world because we didn't want to be constrained by all the assumptions and constraints that uh, we we built into the application layer uh, for the previous generation of LLMs.\n\nAnd one analogy I like to draw here is, you know, what uh, the the the early days of the internet, right? Like in the early days of the internet, the the way people, you know, jumped into the the web was using an interface on the left. This is before like most people knew what the internet was about, what it was capable of, and that was the right interface for the first generation of the internet because like, what can you do with the internet? Well, like there's a bunch of different things you can look at, like trending celebrities, you can, you know, buy automobiles. You can look at movie reviews, all these things you might not have thought of. And so it's it's useful to have in front of you, but at some point it gets a little tedious, like clicking through all the different hyperlinks and navigating your way through. And then the the real power of the web was sort of unleashed by just like the one simple text box where you just like type what you're looking for and and you get to it. And I think, you know, with agentic UIs, that's what we should be striving for both in developer tools and in a lot of different application paradigms. Okay, so what does that look like in practice? So when we went to design this thing, um, our coding agent is called Amp. Uh, and Amp has two clients, and this is what they look like. So both are like very, very bare bones. A lot of people, you know, look at this and like, what is this? It's just a text box. What what can I do with it? Um, and and that was by design, you know, that for all the reasons I just mentioned. Um, one client is just a simple VS Code extension, um, that allows us to take advantage of some nice things that you get in in VS Code, like being able to view diffs. That's really important in the agent decoding world. I often joke that like that's now I use that view more than the editor view now. Um, and and the second was a CLI. So, uh, just stripping things down to bare bones. It has access to all the same tools as the the VS Code extension does, but it's just something that you can invoke in your command line. You can also script it, compose it with other tools.\n\nOkay. So, what what what does this actually look like in practice? Um, I I wanted to do something a little bit risky here, which is, um, in the past I've done a lot of like, you know, hey, here's me building a simple app, like those sorts of demos, but I actually wanted to show off like where we think this is most useful, which is like, hey, I'm working on an application that has real users. is let me actually make a contribution to that codebase given all with all the like existing constraints. And so I actually want to I'm just going to code a little bit. I don't even know how far we're going to get. Um, but this is this is Amp. Uh, this is VS Code running Amp in the sidebar, and it's open to the Amp codebase. Um, and what I want to do is implement like a simple uh, change uh, to this application. So the change that I'm going to make is Amp has a server component, and the server exists uh, as a way to provide the LM inference point. It also provides like team functionality. We have a way to share like what different teams are doing or what different users are doing with AI, so you can kind of learn from other users. There's leaderboard. It's fun. Um, but there's also these things called connectors which allow Amp to talk to external services. So our issue tracker is Linear. Um, and so I've integrated Linear uh, into\n\n\nAMP here, but I'm kind of annoyed because it's using this generic network icon, and I would really like to customize this icon such that when you plug in the linear MCP endpoint, it uses a more appropriate icon like a checkbox or something issuey.\n\nUm, so I've already filed this as a linear issue, and I'm just going to ask, uh, can you find the linear issue about customizing the linear connector icon, uh, then implement it.\n\nSo what this will do is, um, it has access to a set of tools.\nUm, I can go over here to the tool panel and see what tools it has access to.\nSome are local, some are built in.\nUm, it's got the standard tools like read and edit file or run bash command.\nUh, you can also plug in things like Playwright and Postgres via MCP.\nUh, and then linear is also plugged in, uh, through this.\nSo we're basically talking to the linear API, uh, through the MCP server, and, uh, what this will do is it will use the linear, uh, issues API, um, and it will search issues.\nIt found 50 issues, and the one that I was referring to is at the top here.\nSo add a special icon for the linear connector.\nUh, and now it's going to go and implement, uh, the thing for me.\nUm, and one thing to note here is it's just making these tool calls on its own.\nI'm not asking it, uh, to use specific tools.\nUm, we've also tried to make the, uh, information that you see, uh, minimal.\nSo like you don't need to see all the API tool calls that it's making underneath the hood or like crowd out the transcript with a bunch of things.\nMost of the time, uh, we, we just want to keep it simple because the contract we want to provide to users is like the the feedback loops here are more robust, and you don't have to, um, micromanage this as much.\nAnother thing I want to point out here is the search tool that this is using is, is actually a sub agent.\nSo it's actually spinning off a sub agent loop that uses a form of agentic search.\nIt has access to a bunch of different search tools.\nUh, keyword search, uh, uh, just regular GPT, uh, looking up file names.\nUh, if you want to inspect what it's doing, it, you can click the expand thing and see like what different paths it's taking, what files it's reading, what things it uncovered.\nUh, but again, by default, we think this is like an implementation detail, and hopefully it should just surface the the right thing.\nUm, so it's, it's working.\nIt's gathering context.\nUm, another thing I want to call out in this interface is, um, as we've gotten more feedback, we've, we've kind of designed this thing to be more multi-threaded.\nSo, there's a quick keyboard shortcut that allows you to like quickly tab through the different threads that you're running.\nAnd it's a common paradigm in, in our user community to be running more than one of these things at a time.\nUm, and it takes a little bit used to get, get used to the context switching.\nLike developers hate context switching, right?\nLike we like to be, uh, in, in flow, in, in focus.\nUm, Typically what we see here is, um, the, the secondary thread will either be something that's like a lot shallower so that you can quickly page back to the main thread, or what I like to do is while the agent is working, I actually like to understand the code, uh, at a deeper level myself so I can better understand what, what it's going to do.\nSo, uh, I could ask something like, can you show me how connectors and connections work in AMP?\nI can ask it to draw a picture of that.\n\nSo, we'll kick that kick that thread off in parallel.\nWe'll check back in on what this guy is doing.\nSo, it's found, uh, it's read a bunch of files.\nIt's read some frontend files.\nOur front end is written in spelt.\nUm, and as you can see, it's, it's being fairly thoughtful about reading the appropriate files before it actually goes and and does the work.\nAnd we find that this is really important, uh, to make the feedback cycles, uh, more robust.\nUm, otherwise the the anti pattern is you just like get into the weeds of like steering it manually.\nUm, it's also got this to-do list thing at the bottom, uh, that helps it structure and plan out the the longer term tasks so that it doesn't go like immediately dive into the code.\nThis is a classic mistake that like human developers make too, where you like dive into the code too early and then you get lost in the weeds and then it takes a while to dig yourself out.\nUm, okay.\nSo, it's making some changes.\nUm, one other thing that I like to point out here is, you know, I mentioned that I use the diff view in VS Code now, probably more than the editor view.\nUh, VS Code actually has a really nice diff view.\nI have it hotkeyed, um, so I can open it up quickly.\nAnd most of the my time in VS Code now is spent just like reviewing the changes it, uh, it makes.\nAnd I actually like this a lot better than, uh, like GitHub PRs or, uh, git diff on the command line just because it's in the editor.\nYou can see the whole file and, uh, jump to definition, uh, even works.\nUm, so yeah, we'll, we'll just wait a little bit for it to do its thing.\nI actually think it's, it's probably made, looks like it's getting, it's getting there.\nUm, let's, it's probably just running like tests.\nLet's see if we go back here if it's updated the icon at all.\n\nOkay, so it hasn't gotten there yet, but I think it's on the right track.\nDoes it write its own test?\nUh, the question was, does it write its own tests?\nYes, it typically writes its own tests.\nAnd if, if it doesn't, you can prompt it to to do so.\nSo, uh, it's doing a lot of things.\nIt's reading a lot of files.\nIt's making these edits incrementally and then checking the diagnostics.\nUm, and then now let's see if it works.\nOkay, cool.\nSo you see here the icon has been updated, and this is without me really steering it in in any fashion.\nUm, notice here on this page that this icon didn't update though.\nUm, and so this is actually not surprising to me because this change, as many changes in production code bases, are often more nuanced than it seems at the surface.\nSo in this case, the reason it's not getting it here is because, uh, this is the admin page, and the piece of data we need to know, uh, we need to read in order to tell that this is a linear MCP, uh, rather than a generic MCP, is actually part of the config.\nWe have to look at the endpoint of the MCP URL.\nIn order to do that, you have to read the config, but the config might also contain secrets.\nDoesn't contain secrets in this case, but might contain secrets in other cases.\nSo, we actually prohibit those secrets from being sent to non-admin pages.\nUm, so it's not surprising to me that like the first pass it didn't get that right, but let's see if it can get, like, I'll just nudge it a little bit.\nSo, like, uh, I noticed that the icon changed on admin connections but not on settings.\nUm, can you investigate why?\nAnd, uh, in the interest of time, we'll check back on this later.\nHow about that?\nUh, we, we'll let it run and we'll, we'll see if if it can find its way to the right solution there.\nUm, is it okay if I go a little bit over since we started a little bit?\nOkay, cool.\nIs it okay with you all if I go a little bit over?\nOkay.\nAre we still having fun?\nOkay, cool.\nSo, that was like a brief demo of just like the interaction patterns and and the UI.\nWe try to keep it really minimal.\nUm, we've released this to like a small group so far.\nUh, the the signup is now publicly open.\nIt's been open for about two weeks, but we haven't done a lot of like marketing around it, and and that's kind of been intentional because we're really trying to design this for where we think the the puck is going.\nAnd so, we've, we've done a lot to curate this community of people who are trying to experiment with LLMs and figure out like how the interaction paradigms are going to change over the next 6 to 12 months.\nAnd so our user community is really people who are like spending nights and weekends, uh, a lot of time with this thing to see what they can get it to do.\nAnd so actually one of the the most insightful things and actually the main topic of of this talk is lessons that we've learned from just like looking at what our power users are doing and seeing what interesting behavior patterns, uh, they're kind of like implementing.\nUm, and so like the average spend, uh, for agents is, is growing.\nIt's a lot more than the average spend was for chat bots or or autocomplete.\nBut one other interesting thing that we've noticed among the user base is that, uh, there's a huge variance in terms of how much people use this thing.\nUm, to the point where like there, there's like an upper echelon of users that are spending like thousands of dollars per month, uh, just in inference costs.\nAnd at first we're like, this has got to be abuse, right?\nLike someone out there is, you know, poked, uh, you know, found some way to exploit the inference endpoint is is using it to power some like Chinese, uh, you know, AI girlfriend or whatever.\nBut actually, no, when we, when we spoke to, uh, the people using it, we actually found that they were doing real things and we're like, hm, that's interesting.\nWhat the hell are you doing?\nUm, and from those insights and the conversations, we basically, uh, have encapsulated a series of like best practices or emergent, um, like power user patterns, uh, for how the the very, you know, uh, dominant users, the the most active users are are using this thing, and this has informed our our product design process as well.\nSo one of the the first changes that we made, um, was we noticed that a lot of the power users were very writing very long prompts.\nIt was not like the simple kind of like Google style like three keywords and just like, uh, read my mind and expect something good to happen.\nUh, they actually wanted to write a lot of detail because they realized that LLMs are actually quite programmable.\nIf you give them a lot of context, they will follow those instructions and get further than if you just give them like a oneline sentence.\nAnd so we made the default behavior of the enter key in the AMP input just new line.\nSo you have to hit command enter to submit.\nAnd this throws a lot of the new users off because they're like, \"Wait a minute, why isn't it just enter?\" like, you know, if I'm in like cursor or whatever, I just enter, that's easy, that's intuitive, but actually what we want to push users to do is to write those longer prompts because that actually yields better results, and I think that's one of the things that prevents people, uh, who are still in the kind of like chat LLM, uh, mode from from unlocking some of the, you know, cool stuff that that agents can do.\nUm, another thing that people do very intentionally is direct the agent to look at relevant context and feedback mechanisms.\nSo, you know, context was very important in the chatbot, uh, era.\nIt's still important in the agentic era.\nNow, agents do have a good, good amount of like built-in knowledge for how to use tools to acquire context.\nLike you saw that before when it was using the search tool to find different things, um, and and it was executing the test to and and, uh, linters to see if, uh, the code was valid.\nUm, but there's still some cases, especially in production code bases, where it's like, oh, we do things in a very specific way that are kind of like out of distribution, and and so like some like less, uh, less agentically inclined users at that point will just give up.\nThey're like, ah, you know, agents aren't capable of working with like backend code yet.\nBut what we've noticed is the power user, like, actually let me try to just tell it how to run, you know, the build in this particular subdirectory or run the tests, and that helps it complete the feedback loop so that it can get the validation to get further.\nUm, feedback loops are going to be a big theme of of this talk.\nSo, another like dominant, uh, paradigm here is constructing these like front-end feedback loops.\nSo, like a really common formula is you have the Playwright MCP server, and then there's a thing called Storybook, which is basically a way to encapsulate or componentize a lot of your front end components.\nIt makes it very easy to test individual components without loading your entire app.\nAnd you know, you probably should have been doing this anyways as a human developer because you get a fast feedback loop.\nYou make a change, see it reflected instantly.\nYou get the auto reload and then go back to your editor.\nBut with agents, you, you kind of notice it more because you're no longer like in the weeds doing the thing.\nYou're like, oh, you're, you're almost like the developer experience engineer for your agent.\nIt's like, how can I make it loop back faster?\nAnd so what the agent will do is like, you know, make the code change, use Playwright to open up the page in the browser, snapshot it, uh, uh, and then loop back on itself.\nAnd it does that via Storybook because it's much faster than reloading the the entire app.\nYou you put right as a tool for you.\nYes.\nSo it's, um, one of the default recommended tools.\nSo it's right here.\nUm, and actually it looks like, looks like that run completed.\nI wonder if, uh, it looks like it did approximately the right thing.\nUm, sorry, just to jump out of the sides of her a little bit.\nSo now you can see like the icon is is customized on the settings page, not just the admin page.\nAnd if you look at how it did that, I think it did the right thing.\nSo if you look at the diff, um, it actually looked at the surrounding code and was like, \"Oh, there is an existing mechanism for plumbing non-secret parts of the config through to the UI.\nLet me kind of like use that as a reference point.\nAnd it actually plumbed exactly that like, uh, field through to the front end.\nSo now if I add like additional fields to the MCP config that do contain secrets, uh, it, this is like whitelisted.\nSo it'll still only send the endpoint URL over to the client.\nYou know, basically what it needs to make that icon customization.\nUm, so yeah, I know like, you know, it's not a super impressively visual change, but like a lot of such changes in in messy production code bases are like that, and it's cool to see the agent, uh, be able to tease, tease out that nuance.\nUm, okay.\nI know we're, we're a little bit over time.\nCan I, people mind if I keep going or, uh?\nOkay, cool.\n[Laughter]\nUm, there's, uh, some additional, uh, tips\n\n\nAnd tricks.\nMost of this talk is just like sharing what we've learned from our power users.\nSo another thing that we've noticed is like there's this kind of this prevailing narrative that like, you know, agents are going to make programmers lazy.\nIt's going to make it so we don't really understand what what what's going on in the code.\nSo we're going to ship more slop.\nBut we've actually found the inverse happen uh with with the power users.\nThey're actually using agents to better understand uh the code.\nAnd so this is a really good onboarding tool.\nLike we just hired this guy Tyler Bruno.\nHe's a very precocious young developer.\nHe's actually still in college, but he's working full-time in addition to taking classes.\nUh, so really bright, but also, you know, a bit green.\nUm, he's been using Amp to just like quickly ramp up on how the different pieces connect together.\nUh, and it could draw diagrams and and point you to specific pieces of the code.\nAnd, uh, it's really good at accelerating that.\nAnd then a corollary to this is like, you know, we all do a form of onboarding to new code whenever we do a code review.\nLike, by definition, code review is is new code.\nAnd often times it's new code that contains bugs or is hard to understand or is a bit of a slog.\nUm and so rather than just you know ignore the code that the AI generates and just commit it blindly uh we find that our user base is actually using this tool to do more thorough code reviews.\nSo like I've adopted this practice myself where if I have to review a very large diff the first thing I do is ask the agent to consume the diff and generate a high level summary so I can have like a high level awareness and then I ask it like hey if you were a smart senior dev what's the entry point into this PR because like often half the time half the battle is just like finding the right entry point and uh psychologically I I often put off code reviews because I'm like oh it's going to be a pain and it's going to take forever just to like figure out where I should start reviewing it so I'll just it tomorrow.\nBut this thing just like it helps lower that activation energy and and make code reviews more thorough and and actually uh dare I say like a little bit fun and enjoyable now.\n\nUm sub agents are also things.\nSo uh we implemented uh the search tool as a sub agent uh in the very beginning but we're seeing more and more uh use cases emerge for sub agents and the general best practice with sub agents uh is that they often are useful for longer uh more complex tasks because the sub agent allows you to essentially preserve the context window.\nSo like the the the quality of the LLM will degrade uh over time.\nYou know, Sonnet 4 has a context window of 200K, but we see degradation typically around like 120 or 130K, and by the time you get hit 170 tokens, uh it you start to see more kind of like off the rails and crazy behavior.\nUh but sub agents allow you to encapsulate uh the context used up by a specific subtask like implementing a small feature uh such that it doesn't pollute the the main agent.\n\nOkay, so that was a quick tour of of uh a lot of best practices.\nJust to recap like the anti practices, uh the common anti patterns are just like micromanaging the agent, like using it like you would a chatbot where you have to kind of like steer at every interaction or review every edit it's making.\nUm another common uh antiattern is just like underprompting.\nSo not giving it enough detail.\nLike LLMs their knowledge comes from two places.\nIt either comes from their training data or from the context that you give it.\nAnd so, uh, you know, it's fine if you do a five-word prompt if you're coding up like a 3D Flappy Bird game from scratch because that's well represented in the training set.\nThey're really good at that.\nThey're trained to do that.\nUm, but if you're trying to make a subtle nuance change to your large existing codebase, you should be giving it all the details that you would give a colleague on the team uh uh to point them in the right direction.\nAnd then last but not least, like agents are are not a vehicle to like TLDDR the code.\nIf anything, they're the opposite.\nYou should be using them to do much more thorough code reviews more quickly.\nUh the human is still you're ultimately responsible for the code that you ship and you shouldn't view this as a human replacement.\nIt's really a tool that you can wield to make yourself uh 10 100x more effective.\n\nUh last tidbit.\nSo one of the things that we've noticed among the very very very top 1% of the 1% is uh this this uh inclination to run multiple of these things in parallel.\nSo uh Jeff Huntley who wrote that blog post uh that I I showed earlier um he started putting out these uh Twitter uh streams.\nThey're about like four hours long each and it's basically just uh what he's he's working on like a compiler on the side.\nAnd what he does is he he uh constructs prompts for like three or four different agents to to work on different parts of of the compiler.\nUh and he's gotten to the point where he's prompting it such that he feels confident enough in the feedback loops where he just like hits enter, lets him run, and then goes to sleep.\nAnd then like this thing just runs on Twitter for a while.\nAnd I think he's doing this to kind of like spread the word.\nIt's like hey you can use this for serious engineering engineering like compilers are not some like vibe coding uh vibecoded weekend project they're they're real tech they're they're difficult to build um and it is possible to use agents for for code like this but it has to be a very intentional skill that that you you practice and so I think it's cool I think like there's a lot of people thinking in terms of like agent fleets and where the the world is going but I I do think that the way that we'll actually get there is by like building these like composable building blocks that allow people like Jeff to go and like combine them and and uh come up with interesting UIs.\nI think this is just running in like T-Mox or some window manager.\n\nOkay, so like the takeaways I just want to leave you with is one, you know, contrary to what some might say and you know, look, there's a lot of smart senior developers out there who think AI is overhyped and maybe parts of it are, but like I think coding agents are very real and it is uh I think a high ceiling skill.\nIt's like I think we will probably invest in learning how to use these things in the same way that we invest in learning how best to use our editor or our programming language of choice.\nAnd I think the only way you can learn this stuff is is by doing it and then sharing it out with others.\nUh and one of the reasons we built the kind of like thread sharing mechanism into Amp is to help encourage knowledge dissemination so that like if you discover an interesting way of of using it, you can share that out with your team.\nUm but yeah, that's it.\nIf you want to kind of like see a recap of the best practices in this talk, we've actually put out like a an Amp owners manual that guides new users how to to best use it.\nUm, I'll also be around afterwards.\nWe have a booth in the main expo hall.\nUh, I'm supposed to say too, if you stop by the booth, we'll give you like $10 in in free credits.\nSo, if anything you saw here was of interest of you and you want to try this out, um, stop by and and say hi.\nI noticed you still type can you and then you correct your uh typos which I guess you said you shouldn't do.\nYeah, I habit.\nI it's it's part habit and it's part paranoia that in like a live demo setting there will be some uh typo token that will trigger off the rails behavior.\nBut it like I think that was more of a concern that I learned in like 2023 when it actually mattered cuz like these days LMs are are more and more like typo robust I would say.\n\n[Music]\n",
  "dumpedAt": "2025-07-21T18:43:25.453Z"
}