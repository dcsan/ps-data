{
  "episodeId": "fcPUqxfrE6Y",
  "channelSlug": "@aidotengineer",
  "title": "Why the Best AI Agents Are Built Without Frameworks (Primitives over Frameworks) — Ahmad Awais, CHAI",
  "publishedAt": "2025-06-03T22:23:31.000Z",
  "rawLines": [
    {
      "lang": "en",
      "text": "Well, hello there. I am Ahmed and I'm",
      "offset": 0.32,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "going to vibe code an AI agent built",
      "offset": 2.879,
      "duration": 5.121
    },
    {
      "lang": "en",
      "text": "with AI primitives while I deliver this",
      "offset": 5.2,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "talk, right? So, let's start here. One",
      "offset": 8,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "of the most common AI agents that we've",
      "offset": 9.84,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "seen in production is there's some data",
      "offset": 12.4,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "and there's a chatbot as an agent and",
      "offset": 14.88,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "you're trying to chat with that data",
      "offset": 17.76,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "because well, all of these LLMs are self",
      "offset": 19.6,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "attention algorithms anyway, right? So",
      "offset": 21.84,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "you go to chai new and you say something",
      "offset": 24.08,
      "duration": 4.199
    },
    {
      "lang": "en",
      "text": "like chat with",
      "offset": 26.32,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "PDF and let's see what happens. Chai is",
      "offset": 28.279,
      "duration": 6.041
    },
    {
      "lang": "en",
      "text": "now going to vibe code an AI agent for",
      "offset": 31.76,
      "duration": 5.799
    },
    {
      "lang": "en",
      "text": "you. It's going to build it on top of AI",
      "offset": 34.32,
      "duration": 6.239
    },
    {
      "lang": "en",
      "text": "primitives instead of an AI framework.",
      "offset": 37.559,
      "duration": 4.761
    },
    {
      "lang": "en",
      "text": "And as that is happening it just takes",
      "offset": 40.559,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "like a minute. How about I tell you a",
      "offset": 42.32,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "little bit of more about who I am and",
      "offset": 44.879,
      "duration": 6.441
    },
    {
      "lang": "en",
      "text": "what are we talking about today. Right.",
      "offset": 46.64,
      "duration": 4.68
    },
    {
      "lang": "en",
      "text": "So uh look at perplexity cursor v 0ero",
      "offset": 51.48,
      "duration": 6.919
    },
    {
      "lang": "en",
      "text": "uh lovable bold and even now chai you",
      "offset": 55.68,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "will see one common uh theme across all",
      "offset": 58.399,
      "duration": 5.441
    },
    {
      "lang": "en",
      "text": "these production ready agents that are",
      "offset": 61.44,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "you know building millions of agents",
      "offset": 63.84,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "millions of gener you know millions of",
      "offset": 65.84,
      "duration": 4.959
    },
    {
      "lang": "en",
      "text": "people are using them and there's this",
      "offset": 67.84,
      "duration": 5.279
    },
    {
      "lang": "en",
      "text": "one this one really good trend that you",
      "offset": 70.799,
      "duration": 5.201
    },
    {
      "lang": "en",
      "text": "can pick up that all these AI agents in",
      "offset": 73.119,
      "duration": 5.201
    },
    {
      "lang": "en",
      "text": "production are actually not built on top",
      "offset": 76,
      "duration": 5.439
    },
    {
      "lang": "en",
      "text": "of any AI frameworks because Well,",
      "offset": 78.32,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "frameworks do not really add that much",
      "offset": 81.439,
      "duration": 4.561
    },
    {
      "lang": "en",
      "text": "value. They're bloated. They move super",
      "offset": 83.36,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "slowly and they they're filled with",
      "offset": 86,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "these abstraction that nobody really",
      "offset": 87.759,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "needs. Instead, you should be building",
      "offset": 89.68,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "on top of AI primitives. This is what my",
      "offset": 91.68,
      "duration": 5.759
    },
    {
      "lang": "en",
      "text": "entire talk uh is about today. I am",
      "offset": 94.4,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "Ahmed. I've been around the blog for",
      "offset": 97.439,
      "duration": 4.561
    },
    {
      "lang": "en",
      "text": "quite a while. If you use WordPress,",
      "offset": 99.6,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "NexJS, NodeJS, React, you have probably",
      "offset": 102,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "using my code because I've contributed",
      "offset": 105.2,
      "duration": 4.239
    },
    {
      "lang": "en",
      "text": "to all of these software. I have also",
      "offset": 106.96,
      "duration": 4.6
    },
    {
      "lang": "en",
      "text": "built uh hundreds of open source",
      "offset": 109.439,
      "duration": 4.761
    },
    {
      "lang": "en",
      "text": "packages mostly automation CLIs with",
      "offset": 111.56,
      "duration": 5.96
    },
    {
      "lang": "en",
      "text": "NodeJS and created a shades of purple",
      "offset": 114.2,
      "duration": 6.12
    },
    {
      "lang": "en",
      "text": "code theme all of which are downloaded",
      "offset": 117.52,
      "duration": 5.199
    },
    {
      "lang": "en",
      "text": "like 40 50 million times uh you know a",
      "offset": 120.32,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "year and I've gone up to you know as uh",
      "offset": 122.719,
      "duration": 4.881
    },
    {
      "lang": "en",
      "text": "as technical as you can imagine I've",
      "offset": 125.92,
      "duration": 4.559
    },
    {
      "lang": "en",
      "text": "contributed to NASA helicopter mission",
      "offset": 127.6,
      "duration": 4.719
    },
    {
      "lang": "en",
      "text": "and in the past I have been a VP of",
      "offset": 130.479,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "developer tools VP of engineering Google",
      "offset": 132.319,
      "duration": 4.481
    },
    {
      "lang": "en",
      "text": "developers advisory board member all I'm",
      "offset": 134.56,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "trying to say is I am deeply technical",
      "offset": 136.8,
      "duration": 4.799
    },
    {
      "lang": "en",
      "text": "I've gone through this phase of working",
      "offset": 138.959,
      "duration": 6.321
    },
    {
      "lang": "en",
      "text": "with in building frameworks and now why",
      "offset": 141.599,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "do you think I am talking about",
      "offset": 145.28,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "primitives I think primitives have this",
      "offset": 146.879,
      "duration": 4.641
    },
    {
      "lang": "en",
      "text": "native ability of working really really",
      "offset": 149.04,
      "duration": 5.839
    },
    {
      "lang": "en",
      "text": "well in production like Amazon S3 is a a",
      "offset": 151.52,
      "duration": 5.92
    },
    {
      "lang": "en",
      "text": "really good uh example here Amazon S3 is",
      "offset": 154.879,
      "duration": 4.561
    },
    {
      "lang": "en",
      "text": "a primitive where you can upload data",
      "offset": 157.44,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "and download data and they scale it uh",
      "offset": 159.44,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "massively they're not building a",
      "offset": 162.8,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "framework for object storage it's a very",
      "offset": 164.56,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "simple thing it's a lowle level",
      "offset": 166.48,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "primitive you can use to build lots of",
      "offset": 167.84,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "things right and that is what we are uh",
      "offset": 170.48,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "talking about here today my journey in",
      "offset": 172.72,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "LLM actually started with in 2020 when",
      "offset": 174.64,
      "duration": 5
    },
    {
      "lang": "en",
      "text": "Greg Brockman himself gave me access to",
      "offset": 177.44,
      "duration": 5.84
    },
    {
      "lang": "en",
      "text": "GP3 GP3 was just like what uh maybe a",
      "offset": 179.64,
      "duration": 6.04
    },
    {
      "lang": "en",
      "text": "month old model and I I had already",
      "offset": 183.28,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "started building uh you know something",
      "offset": 185.68,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "like GitHub copilot which uh launched in",
      "offset": 187.92,
      "duration": 4.679
    },
    {
      "lang": "en",
      "text": "2021 a year later",
      "offset": 190.72,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "right even now you know we've been",
      "offset": 192.599,
      "duration": 4.521
    },
    {
      "lang": "en",
      "text": "building it uh things and agents for",
      "offset": 195.12,
      "duration": 5.039
    },
    {
      "lang": "en",
      "text": "like I don't know 5 years building and",
      "offset": 197.12,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "deploying and scaling AI agent remains",
      "offset": 200.159,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "to be the biggest pain there is and I",
      "offset": 202.8,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "think everybody has a different",
      "offset": 205.519,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "definition of AI agents but this is my",
      "offset": 206.64,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "take at it I think AI agents are just a",
      "offset": 209.12,
      "duration": 6.08
    },
    {
      "lang": "en",
      "text": "new way of writing code everything we",
      "offset": 212.08,
      "duration": 6.239
    },
    {
      "lang": "en",
      "text": "know of how we used to build code how",
      "offset": 215.2,
      "duration": 5.679
    },
    {
      "lang": "en",
      "text": "you used to build coding projects uh or",
      "offset": 218.319,
      "duration": 5.121
    },
    {
      "lang": "en",
      "text": "SAS all of that is changing because of",
      "offset": 220.879,
      "duration": 5.121
    },
    {
      "lang": "en",
      "text": "AI and because of agents and it's it's",
      "offset": 223.44,
      "duration": 4.879
    },
    {
      "lang": "en",
      "text": "just big enough. It's not it's it's just",
      "offset": 226,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "a new way to write code. It's big",
      "offset": 228.319,
      "duration": 3.121
    },
    {
      "lang": "en",
      "text": "enough. You know, if you try to put it",
      "offset": 229.84,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "inside of a framework, that abstraction",
      "offset": 231.44,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "might not be enough. Instead, how about",
      "offset": 233.92,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "we build small building blocks that are",
      "offset": 236.48,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "useful across a stack like something",
      "offset": 239.2,
      "duration": 3.679
    },
    {
      "lang": "en",
      "text": "like threads? You know, every agent",
      "offset": 241.04,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "needs to store some sort of context or",
      "offset": 242.879,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "history of conversation. So, threads",
      "offset": 246,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "would be an awesome primitive and we",
      "offset": 248.159,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "build that, right? So, why not build",
      "offset": 250.4,
      "duration": 4.479
    },
    {
      "lang": "en",
      "text": "that? Why I think that is important is",
      "offset": 252.159,
      "duration": 5.441
    },
    {
      "lang": "en",
      "text": "because here's my belief. I think most",
      "offset": 254.879,
      "duration": 4.961
    },
    {
      "lang": "en",
      "text": "of engineers are going to become AI",
      "offset": 257.6,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "engineers. This you can already see with",
      "offset": 259.84,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "fullstack AI engineers, web developers",
      "offset": 262.24,
      "duration": 3.519
    },
    {
      "lang": "en",
      "text": "and front end developers, they're",
      "offset": 264.16,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "quickly transitioning into this AI",
      "offset": 265.759,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "engineering role because they are",
      "offset": 267.68,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "shipping a lot of product with AI and",
      "offset": 269.36,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "they are building stuff with uh",
      "offset": 272.24,
      "duration": 4.239
    },
    {
      "lang": "en",
      "text": "different LLMs or whatnot with vector",
      "offset": 274.32,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "stores and this and that. Even DevOps",
      "offset": 276.479,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "engineers and ML engineers are now",
      "offset": 278.8,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "shipping product. So when everyone is",
      "offset": 280.639,
      "duration": 4.721
    },
    {
      "lang": "en",
      "text": "building as an AI engineer, what we are",
      "offset": 282.8,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "trying to do uh here at Langbase is",
      "offset": 285.36,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "improve their experience. We want to",
      "offset": 288.56,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "become the fastest possible way for you",
      "offset": 290.32,
      "duration": 6.4
    },
    {
      "lang": "en",
      "text": "to build a production ready AI agent.",
      "offset": 292.88,
      "duration": 5.84
    },
    {
      "lang": "en",
      "text": "A lot of people I think start with this",
      "offset": 296.72,
      "duration": 4.479
    },
    {
      "lang": "en",
      "text": "painful way of building AI agents where",
      "offset": 298.72,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "they pick up a framework which is filled",
      "offset": 301.199,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "with uh you know obscure abstractions",
      "offset": 303.12,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "which are really really hard to debug",
      "offset": 305.04,
      "duration": 4.76
    },
    {
      "lang": "en",
      "text": "and then they have to figure out how to",
      "offset": 307.199,
      "duration": 6.321
    },
    {
      "lang": "en",
      "text": "deploy and scale those agents. We think",
      "offset": 309.8,
      "duration": 5.48
    },
    {
      "lang": "en",
      "text": "the other way. I think if you are",
      "offset": 313.52,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "building on top of predefined really",
      "offset": 315.28,
      "duration": 4.479
    },
    {
      "lang": "en",
      "text": "good highly scalable AI primitives",
      "offset": 317.36,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "especially composible primitives that",
      "offset": 319.759,
      "duration": 5.041
    },
    {
      "lang": "en",
      "text": "come with a piece of cloud in it like uh",
      "offset": 322.08,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "you know memory memory is an AI",
      "offset": 324.8,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "primitive which is like you know like",
      "offset": 326.56,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "memory which has a vector store in it",
      "offset": 328.4,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "you can throw in I don't know terabytes",
      "offset": 330.8,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "of data inside of memory and it will",
      "offset": 333.12,
      "duration": 4.799
    },
    {
      "lang": "en",
      "text": "automatically scale so if you build an",
      "offset": 335.36,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "AI agent with that memory or with that",
      "offset": 337.919,
      "duration": 4.241
    },
    {
      "lang": "en",
      "text": "parsing chunking or threads or tools",
      "offset": 340.08,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "infrastructure what you get is a",
      "offset": 342.16,
      "duration": 4.479
    },
    {
      "lang": "en",
      "text": "serverless AI agent that automatically",
      "offset": 344.4,
      "duration": 4.6
    },
    {
      "lang": "en",
      "text": "can do the heavy lifting for",
      "offset": 346.639,
      "duration": 4.801
    },
    {
      "lang": "en",
      "text": "you. But what does that actually look",
      "offset": 349,
      "duration": 5
    },
    {
      "lang": "en",
      "text": "like? Let's take a look at what is",
      "offset": 351.44,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "happening here today in this talk. I'm",
      "offset": 354,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "going to share and by the way like I'm",
      "offset": 356.88,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "going to probably you know already done.",
      "offset": 359.12,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "I'm going to deploy this before you know",
      "offset": 361.039,
      "duration": 5.521
    },
    {
      "lang": "en",
      "text": "we move forward. I am going to go over",
      "offset": 363.36,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "eight different AI agent architectures",
      "offset": 366.56,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "that are built purely with AI primitives",
      "offset": 369.36,
      "duration": 4.959
    },
    {
      "lang": "en",
      "text": "instead of a framework. Look like look",
      "offset": 372.08,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "at this you know I said chat with PDF",
      "offset": 374.319,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "and it figured out that well you need a",
      "offset": 376.8,
      "duration": 5.519
    },
    {
      "lang": "en",
      "text": "memory for storing this PDF which will",
      "offset": 379.199,
      "duration": 5.761
    },
    {
      "lang": "en",
      "text": "have a vector store and you need uh an",
      "offset": 382.319,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "AI agent an LLM uh which will be used to",
      "offset": 384.96,
      "duration": 6.079
    },
    {
      "lang": "en",
      "text": "ask questions from this PDF right so it",
      "offset": 388.319,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "went ahead and did this you know we need",
      "offset": 391.039,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "it created a memory created uh a way for",
      "offset": 393.039,
      "duration": 6.401
    },
    {
      "lang": "en",
      "text": "you to generate answers an agent on top",
      "offset": 396.479,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "of that memory right this uh the flow of",
      "offset": 399.44,
      "duration": 5.039
    },
    {
      "lang": "en",
      "text": "this very simple I want to retrieve a p",
      "offset": 401.759,
      "duration": 5.041
    },
    {
      "lang": "en",
      "text": "some PDF content and then generate the",
      "offset": 404.479,
      "duration": 5.041
    },
    {
      "lang": "en",
      "text": "answer right and you know it's already",
      "offset": 406.8,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "done as you can see these lines the",
      "offset": 409.52,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "first step is to build that memory and",
      "offset": 412.08,
      "duration": 4.839
    },
    {
      "lang": "en",
      "text": "we are using a primitive here",
      "offset": 414.88,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "langbase.mmemories this primitive is",
      "offset": 416.919,
      "duration": 5.641
    },
    {
      "lang": "en",
      "text": "where we will put the user uh input the",
      "offset": 418.96,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "you know the question that user is",
      "offset": 422.56,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "trying to ask is the name of that memory",
      "offset": 424.08,
      "duration": 5.519
    },
    {
      "lang": "en",
      "text": "the PDF uh document memory uh if you go",
      "offset": 426.479,
      "duration": 6.72
    },
    {
      "lang": "en",
      "text": "here you will find that memory in This",
      "offset": 429.599,
      "duration": 6.561
    },
    {
      "lang": "en",
      "text": "all of this can be built uh with API as",
      "offset": 433.199,
      "duration": 5.361
    },
    {
      "lang": "en",
      "text": "well. What I'm going to do here is I'm",
      "offset": 436.16,
      "duration": 5.599
    },
    {
      "lang": "en",
      "text": "going to go to I don't know uh mls.com",
      "offset": 438.56,
      "duration": 4.68
    },
    {
      "lang": "en",
      "text": "about and",
      "offset": 441.759,
      "duration": 6.081
    },
    {
      "lang": "en",
      "text": "ms.com talks. Uh this page has u",
      "offset": 443.24,
      "duration": 6.519
    },
    {
      "lang": "en",
      "text": "information about me. This one has",
      "offset": 447.84,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "information about my talks like the one",
      "offset": 449.759,
      "duration": 4.241
    },
    {
      "lang": "en",
      "text": "I'm giving right now. And I'm going to",
      "offset": 451.44,
      "duration": 4.92
    },
    {
      "lang": "en",
      "text": "throw all of these",
      "offset": 454,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "as PDF files in it. So I have already",
      "offset": 456.36,
      "duration": 4.52
    },
    {
      "lang": "en",
      "text": "saved them on my desktop. So I'm going",
      "offset": 459.44,
      "duration": 4.28
    },
    {
      "lang": "en",
      "text": "to just quickly grab",
      "offset": 460.88,
      "duration": 7.039
    },
    {
      "lang": "en",
      "text": "them and upload here. I've also I'm",
      "offset": 463.72,
      "duration": 8.319
    },
    {
      "lang": "en",
      "text": "going also going to do this API key lang",
      "offset": 467.919,
      "duration": 7.601
    },
    {
      "lang": "en",
      "text": "base. So I'm also going to throw a PDF",
      "offset": 472.039,
      "duration": 6.081
    },
    {
      "lang": "en",
      "text": "version of this particular file into the",
      "offset": 475.52,
      "duration": 5.92
    },
    {
      "lang": "en",
      "text": "memory. As you can see uh this is the",
      "offset": 478.12,
      "duration": 6.359
    },
    {
      "lang": "en",
      "text": "doc about Langbase uh how to get API",
      "offset": 481.44,
      "duration": 6.56
    },
    {
      "lang": "en",
      "text": "keys from Langbase u my talks and my",
      "offset": 484.479,
      "duration": 6.241
    },
    {
      "lang": "en",
      "text": "about page. All of these files are right",
      "offset": 488,
      "duration": 6.16
    },
    {
      "lang": "en",
      "text": "now being processed which means uh a",
      "offset": 490.72,
      "duration": 5.919
    },
    {
      "lang": "en",
      "text": "parser primitive is converting these",
      "offset": 494.16,
      "duration": 6.08
    },
    {
      "lang": "en",
      "text": "files uh from PDF to text and then a",
      "offset": 496.639,
      "duration": 5.601
    },
    {
      "lang": "en",
      "text": "chunker primitive is going to chunk",
      "offset": 500.24,
      "duration": 4.799
    },
    {
      "lang": "en",
      "text": "these into small pieces of context which",
      "offset": 502.24,
      "duration": 4.639
    },
    {
      "lang": "en",
      "text": "are going to be used in a similarity",
      "offset": 505.039,
      "duration": 5.361
    },
    {
      "lang": "en",
      "text": "search. If I refresh these you will see",
      "offset": 506.879,
      "duration": 5.441
    },
    {
      "lang": "en",
      "text": "that all of these files are now ready.",
      "offset": 510.4,
      "duration": 3.24
    },
    {
      "lang": "en",
      "text": "Right",
      "offset": 512.32,
      "duration": 5.199
    },
    {
      "lang": "en",
      "text": "now now let's go to this agent code and",
      "offset": 513.64,
      "duration": 6.04
    },
    {
      "lang": "en",
      "text": "see what is there. All right. So we are",
      "offset": 517.519,
      "duration": 3.96
    },
    {
      "lang": "en",
      "text": "going to ask a question from this",
      "offset": 519.68,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "memory, right? Which will return back",
      "offset": 521.479,
      "duration": 5.641
    },
    {
      "lang": "en",
      "text": "some memories. And these memories are in",
      "offset": 524,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "the second step. As you can see here,",
      "offset": 527.12,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "this is what we are going to use as",
      "offset": 529.36,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "context, right? This is generate answer",
      "offset": 531.36,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "step. And in this step, we are basically",
      "offset": 534.64,
      "duration": 6.08
    },
    {
      "lang": "en",
      "text": "going to create an AI agent that is",
      "offset": 537.36,
      "duration": 6.8
    },
    {
      "lang": "en",
      "text": "going to use that context to answer the",
      "offset": 540.72,
      "duration": 6.64
    },
    {
      "lang": "en",
      "text": "questions you have. Right? Very simple.",
      "offset": 544.16,
      "duration": 5.92
    },
    {
      "lang": "en",
      "text": "Uh it has also uh Chai has also you know",
      "offset": 547.36,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "built an agent app for you which makes",
      "offset": 550.08,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "it really easy to use but you can also",
      "offset": 552.48,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "go ahead and use you know uh an API with",
      "offset": 554.72,
      "duration": 4.239
    },
    {
      "lang": "en",
      "text": "whatever programming language you",
      "offset": 557.76,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "prefer. Let's try the agent app. Let's",
      "offset": 558.959,
      "duration": 6.401
    },
    {
      "lang": "en",
      "text": "ask it something some uh very simple. So",
      "offset": 562.16,
      "duration": 4.52
    },
    {
      "lang": "en",
      "text": "who's the",
      "offset": 565.36,
      "duration": 5.479
    },
    {
      "lang": "en",
      "text": "founder and his last three",
      "offset": 566.68,
      "duration": 7.32
    },
    {
      "lang": "en",
      "text": "talks? There you go. Right now this",
      "offset": 570.839,
      "duration": 5.321
    },
    {
      "lang": "en",
      "text": "information is in two different files in",
      "offset": 574,
      "duration": 6.44
    },
    {
      "lang": "en",
      "text": "our memory which was parsed chunked and",
      "offset": 576.16,
      "duration": 6.72
    },
    {
      "lang": "en",
      "text": "embedded automatically using those",
      "offset": 580.44,
      "duration": 4.6
    },
    {
      "lang": "en",
      "text": "primitives and you can see the answer is",
      "offset": 582.88,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "already here. I'm the founder here are",
      "offset": 585.04,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "you know the last three talks I did uh",
      "offset": 587.44,
      "duration": 6.2
    },
    {
      "lang": "en",
      "text": "and how do I get an API",
      "offset": 590,
      "duration": 6.48
    },
    {
      "lang": "en",
      "text": "key? This should probably also give me",
      "offset": 593.64,
      "duration": 5.08
    },
    {
      "lang": "en",
      "text": "uh an answer on how to get that API key",
      "offset": 596.48,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "from that other file that we had. um",
      "offset": 598.72,
      "duration": 4.76
    },
    {
      "lang": "en",
      "text": "added in",
      "offset": 602.24,
      "duration": 3.599
    },
    {
      "lang": "en",
      "text": "there. There you go. How how you get an",
      "offset": 603.48,
      "duration": 4.6
    },
    {
      "lang": "en",
      "text": "API key. There's a bug. You can actually",
      "offset": 605.839,
      "duration": 6.241
    },
    {
      "lang": "en",
      "text": "go to the app mode and vibe code a fix",
      "offset": 608.08,
      "duration": 6.24
    },
    {
      "lang": "en",
      "text": "for this bug and this app uh will be",
      "offset": 612.08,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "fixed. You can also, you know, make it",
      "offset": 614.32,
      "duration": 4.639
    },
    {
      "lang": "en",
      "text": "public or whatnot. What's happening",
      "offset": 616.16,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "behind the scene here is most",
      "offset": 618.959,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "interesting. You know, uh I think every",
      "offset": 620.48,
      "duration": 5.919
    },
    {
      "lang": "en",
      "text": "agent needs all these primitives that we",
      "offset": 623.839,
      "duration": 4.961
    },
    {
      "lang": "en",
      "text": "are building, right? Primitives are like",
      "offset": 626.399,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "you know memory which is an autonomous",
      "offset": 628.8,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "drag engine a workflow engine that is",
      "offset": 630.8,
      "duration": 4.599
    },
    {
      "lang": "en",
      "text": "built purpose built for multi-steps",
      "offset": 633.44,
      "duration": 4.959
    },
    {
      "lang": "en",
      "text": "agent threads where you store and manage",
      "offset": 635.399,
      "duration": 5.88
    },
    {
      "lang": "en",
      "text": "this context and conversation a parser",
      "offset": 638.399,
      "duration": 5.761
    },
    {
      "lang": "en",
      "text": "to extract the context and a chunker to",
      "offset": 641.279,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "split this right and using all these",
      "offset": 644.16,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "primitives you can build almost any AI",
      "offset": 646.959,
      "duration": 5.921
    },
    {
      "lang": "en",
      "text": "agent we actually did a lot of research",
      "offset": 650.16,
      "duration": 5.679
    },
    {
      "lang": "en",
      "text": "on stateofiag aents.com where you can",
      "offset": 652.88,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "read a lot about how people are building",
      "offset": 655.839,
      "duration": 4.881
    },
    {
      "lang": "en",
      "text": "uh agents what type of primitives they",
      "offset": 658.32,
      "duration": 6.079
    },
    {
      "lang": "en",
      "text": "are using and what type of uh LLM is",
      "offset": 660.72,
      "duration": 6.239
    },
    {
      "lang": "en",
      "text": "required in doing really well in which",
      "offset": 664.399,
      "duration": 6.56
    },
    {
      "lang": "en",
      "text": "type of industry right let's now go over",
      "offset": 666.959,
      "duration": 5.481
    },
    {
      "lang": "en",
      "text": "different AI",
      "offset": 670.959,
      "duration": 3.761
    },
    {
      "lang": "en",
      "text": "primitives and different agent",
      "offset": 672.44,
      "duration": 4.04
    },
    {
      "lang": "en",
      "text": "architectures that use different AI",
      "offset": 674.72,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "primitives so the first most common",
      "offset": 676.48,
      "duration": 4.44
    },
    {
      "lang": "en",
      "text": "architecture that we see is an augmented",
      "offset": 678.8,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "LLM augmented LLM is basically an agent",
      "offset": 680.92,
      "duration": 5.72
    },
    {
      "lang": "en",
      "text": "it's an agent that is going to get an uh",
      "offset": 684.32,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "you some input and it's going to",
      "offset": 686.64,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "generate some output which will have an",
      "offset": 688.48,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "LLM. It will have some way to",
      "offset": 690.88,
      "duration": 4.959
    },
    {
      "lang": "en",
      "text": "automatically call tools so it can",
      "offset": 693.44,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "connect to MCPS or call different APIs.",
      "offset": 695.839,
      "duration": 6.081
    },
    {
      "lang": "en",
      "text": "It will have access to threads. Thread",
      "offset": 699.2,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "is another AI primitive which will which",
      "offset": 701.92,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "is where you can store the conversation",
      "offset": 704.8,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "users are having with this agent or the",
      "offset": 707.44,
      "duration": 5.519
    },
    {
      "lang": "en",
      "text": "context of this agent uh you know which",
      "offset": 710.32,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "might be you know completely completely",
      "offset": 712.959,
      "duration": 5.681
    },
    {
      "lang": "en",
      "text": "asynchronous right uh thread uh of",
      "offset": 715.2,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "context a scratch pad like for example",
      "offset": 718.64,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "when you're booking a flight there's",
      "offset": 720.56,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "certain set of information that you kind",
      "offset": 722.64,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "of keep in your header on a scratch pad",
      "offset": 724.399,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "like I'm going to land here I'm going to",
      "offset": 726.72,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "go do this and that and that is useful",
      "offset": 728.24,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "ful when you are you know booking that",
      "offset": 730.88,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "particular flight. So you can use thread",
      "offset": 733.36,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "to store that uh you know memory like",
      "offset": 735.44,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "context and then there's memory the",
      "offset": 737.6,
      "duration": 4.239
    },
    {
      "lang": "en",
      "text": "long-term memory of you know different",
      "offset": 739.839,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "events or whatnot. This could be",
      "offset": 741.839,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "terabytes of data that you want to",
      "offset": 743.44,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "search when you're using this agent",
      "offset": 746.24,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "right uh which obviously requires more",
      "offset": 748.72,
      "duration": 5.919
    },
    {
      "lang": "en",
      "text": "context and requires you know vector",
      "offset": 752,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "store. So in this example, in this",
      "offset": 754.639,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "augmented LLM, we see tools as",
      "offset": 757.44,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "primitives, threads as a primitive, and",
      "offset": 760.079,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "memory as a primitive. And you can",
      "offset": 762.56,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "basically build almost any type of AI",
      "offset": 764.639,
      "duration": 5.32
    },
    {
      "lang": "en",
      "text": "agent with this augmented LLM",
      "offset": 767.04,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "architecture. As you can see here, lang",
      "offset": 769.959,
      "duration": 4.601
    },
    {
      "lang": "en",
      "text": "pipes or agents provide you with that",
      "offset": 772.48,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "primitive.",
      "offset": 774.56,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "Now let's uh look at what type of agents",
      "offset": 776.16,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "and what type of architectures can you",
      "offset": 779.6,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "actually build uh using that augmented",
      "offset": 781.36,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "LLM that I just showed you. Here's",
      "offset": 784.24,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "another one. So prompt chaining and",
      "offset": 786.32,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "composition where you use multiple",
      "offset": 788.48,
      "duration": 4.2
    },
    {
      "lang": "en",
      "text": "agents as you can see the purple blocks",
      "offset": 790.72,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "here working together. You get an input",
      "offset": 792.68,
      "duration": 6.279
    },
    {
      "lang": "en",
      "text": "and agent creates an output and based on",
      "offset": 796,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "that output you basically decide if you",
      "offset": 798.959,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "want to go forward, right? Maybe you got",
      "offset": 800.72,
      "duration": 4.799
    },
    {
      "lang": "en",
      "text": "an email uh and you figured out if that",
      "offset": 802.8,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "was spam or not. And if it was not spam,",
      "offset": 805.519,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "then you used another agent to write a",
      "offset": 808.56,
      "duration": 5.839
    },
    {
      "lang": "en",
      "text": "draft email in response. And you can uh",
      "offset": 811.279,
      "duration": 4.481
    },
    {
      "lang": "en",
      "text": "take a look at, you know, what's",
      "offset": 814.399,
      "duration": 2.88
    },
    {
      "lang": "en",
      "text": "happening here. There's a summary agent,",
      "offset": 815.76,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "there's a features agent, there's a",
      "offset": 817.279,
      "duration": 4.641
    },
    {
      "lang": "en",
      "text": "marketing copy agent. This code is plain",
      "offset": 819.2,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "JavaScript or TypeScript if you will,",
      "offset": 821.92,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "right? You can see here um a summary",
      "offset": 823.6,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "agent, uh this is a feature agent, and",
      "offset": 826.32,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "this is a marketing copy agent. they're",
      "offset": 829.04,
      "duration": 4.799
    },
    {
      "lang": "en",
      "text": "all going to work together to generate",
      "offset": 831.36,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "an output that you need based on an",
      "offset": 833.839,
      "duration": 6.24
    },
    {
      "lang": "en",
      "text": "input. A more interesting one is uh",
      "offset": 836.88,
      "duration": 5.519
    },
    {
      "lang": "en",
      "text": "something like agent router, right?",
      "offset": 840.079,
      "duration": 5.841
    },
    {
      "lang": "en",
      "text": "Where an agent uh or an LLM router that",
      "offset": 842.399,
      "duration": 6.641
    },
    {
      "lang": "en",
      "text": "you build basically decides which other",
      "offset": 845.92,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "agent is needed to be called next,",
      "offset": 849.04,
      "duration": 5.84
    },
    {
      "lang": "en",
      "text": "right? Let's see what this is what this",
      "offset": 851.92,
      "duration": 6.64
    },
    {
      "lang": "en",
      "text": "architecture looks like in production.",
      "offset": 854.88,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "None of this uh we are going to build",
      "offset": 858.56,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "all of this with AI parameters. None of",
      "offset": 860.48,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "this is built with a framework. We're",
      "offset": 862.8,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "going to basically create three",
      "offset": 864.8,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "specialized agents for different tasks.",
      "offset": 866.32,
      "duration": 4.959
    },
    {
      "lang": "en",
      "text": "One is a summary agent for summarizing",
      "offset": 868.959,
      "duration": 4.961
    },
    {
      "lang": "en",
      "text": "text. The other one is a reasoning agent",
      "offset": 871.279,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "for analyzing and explanations and then",
      "offset": 873.92,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "a coding agent for obvious reasons you",
      "offset": 876.959,
      "duration": 4.481
    },
    {
      "lang": "en",
      "text": "know when you need to write code and all",
      "offset": 878.88,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "these are built with different LLM. So",
      "offset": 881.44,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "summary is from Gemini uh reasoning is",
      "offset": 883.199,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "with deepse uh llama 70B and coding is",
      "offset": 885.68,
      "duration": 5.839
    },
    {
      "lang": "en",
      "text": "with clots on it. Right now let's look",
      "offset": 889.199,
      "duration": 6.801
    },
    {
      "lang": "en",
      "text": "at this code. This code right here is",
      "offset": 891.519,
      "duration": 8.161
    },
    {
      "lang": "en",
      "text": "only going to use AI primitives and you",
      "offset": 896,
      "duration": 6.24
    },
    {
      "lang": "en",
      "text": "will build your own uh AI framework on",
      "offset": 899.68,
      "duration": 4.719
    },
    {
      "lang": "en",
      "text": "top of it instead of using a botted AI",
      "offset": 902.24,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "framework. Right? So as you can see",
      "offset": 904.399,
      "duration": 4.721
    },
    {
      "lang": "en",
      "text": "here's a routing agent. Router is being",
      "offset": 906.639,
      "duration": 5.121
    },
    {
      "lang": "en",
      "text": "told what the job is. It has access to",
      "offset": 909.12,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "all these agents and it is supposed to",
      "offset": 911.76,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "respond back with valid JSON and picking",
      "offset": 914.24,
      "duration": 6.159
    },
    {
      "lang": "en",
      "text": "which of these agents is going to do the",
      "offset": 917.04,
      "duration": 5.599
    },
    {
      "lang": "en",
      "text": "job for us. Right? And here is the",
      "offset": 920.399,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "documentation of a very simple set of",
      "offset": 922.639,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "agents. A summary agent uh uh a summary",
      "offset": 924.32,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "agent, a reasoning agent uh right here",
      "offset": 927.04,
      "duration": 5.919
    },
    {
      "lang": "en",
      "text": "and a coding agent. Right? Now all of",
      "offset": 929.68,
      "duration": 5.519
    },
    {
      "lang": "en",
      "text": "these are going to run together. All of",
      "offset": 932.959,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "this as you can see is just plain old",
      "offset": 935.199,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "code. There's nothing new here. you can",
      "offset": 937.279,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "easily write this. This there's no",
      "offset": 939.36,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "magic. There's nothing to learn. It's",
      "offset": 942.079,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "basically you're just calling these",
      "offset": 944.32,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "agents together and one of these agents",
      "offset": 945.92,
      "duration": 6.08
    },
    {
      "lang": "en",
      "text": "are going to respond back with which",
      "offset": 948.56,
      "duration": 6.079
    },
    {
      "lang": "en",
      "text": "next agent you need to run uh you know",
      "offset": 952,
      "duration": 4.759
    },
    {
      "lang": "en",
      "text": "for the task. So the task is very",
      "offset": 954.639,
      "duration": 6.081
    },
    {
      "lang": "en",
      "text": "simple. Uh y days are shorter in winter.",
      "offset": 956.759,
      "duration": 10
    },
    {
      "lang": "en",
      "text": "Now let's go ahead and run this code.",
      "offset": 960.72,
      "duration": 6.039
    },
    {
      "lang": "en",
      "text": "So the main agent the router the scene",
      "offset": 966.8,
      "duration": 5.92
    },
    {
      "lang": "en",
      "text": "agent has decided that it needs to run",
      "offset": 969.839,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "the reasoning or you need to run the",
      "offset": 972.72,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "reasoning agent uh to for this",
      "offset": 974.959,
      "duration": 4.961
    },
    {
      "lang": "en",
      "text": "particular task. Right? Obviously you're",
      "offset": 978,
      "duration": 3.759
    },
    {
      "lang": "en",
      "text": "not writing code here. You're not uh",
      "offset": 979.92,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "writing summary. You can see how the the",
      "offset": 981.759,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "decision maker made the right choice and",
      "offset": 984.079,
      "duration": 5.361
    },
    {
      "lang": "en",
      "text": "then you pick up the same uh uh",
      "offset": 986.639,
      "duration": 5.521
    },
    {
      "lang": "en",
      "text": "reasoning agent that he had built based",
      "offset": 989.44,
      "duration": 5.92
    },
    {
      "lang": "en",
      "text": "on this answer and then throw that input",
      "offset": 992.16,
      "duration": 5.039
    },
    {
      "lang": "en",
      "text": "in there and here's the you know answer",
      "offset": 995.36,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "of why answer of why days are actually",
      "offset": 997.199,
      "duration": 5.121
    },
    {
      "lang": "en",
      "text": "shorter in winter. Don't get distracted",
      "offset": 999.68,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "by this answer by the way. Right? So",
      "offset": 1002.32,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "another very common architecture for",
      "offset": 1005.12,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "building agents we see is running uh",
      "offset": 1007.68,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "agents in peril. This is absolutely",
      "offset": 1010.56,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "simple to use. Uh there's no abstraction",
      "offset": 1013.12,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "needed for JavaScript. Uh in JavaScript,",
      "offset": 1015.6,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "you can basically build a set of agents",
      "offset": 1018.56,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "as you can see here. Here's a sentiment",
      "offset": 1020.8,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "summary in the scene maker agent and you",
      "offset": 1022.56,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "can promise do all of these agents and",
      "offset": 1025.199,
      "duration": 5.681
    },
    {
      "lang": "en",
      "text": "they will run in parallel.",
      "offset": 1027.6,
      "duration": 5.439
    },
    {
      "lang": "en",
      "text": "My favorite however is this agent",
      "offset": 1030.88,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "orchestrator worker where an agent",
      "offset": 1033.039,
      "duration": 6.241
    },
    {
      "lang": "en",
      "text": "basically decides to orchestrate and",
      "offset": 1036.4,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "build any number of worker agents that",
      "offset": 1039.28,
      "duration": 5.519
    },
    {
      "lang": "en",
      "text": "are going to solve a problem which is",
      "offset": 1042.16,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "then synthesized by another agent.",
      "offset": 1044.799,
      "duration": 5.201
    },
    {
      "lang": "en",
      "text": "Right? This is exactly what uh a deep",
      "offset": 1047.12,
      "duration": 5.919
    },
    {
      "lang": "en",
      "text": "research agent architecture looks like.",
      "offset": 1050,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "So this one is really good. What we are",
      "offset": 1053.039,
      "duration": 3.281
    },
    {
      "lang": "en",
      "text": "going to do in this is we are going to",
      "offset": 1054.88,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "create an orchestrator agent that will",
      "offset": 1056.32,
      "duration": 4.28
    },
    {
      "lang": "en",
      "text": "plan and create",
      "offset": 1058.32,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "subtasks for worker agents and these",
      "offset": 1060.6,
      "duration": 5.199
    },
    {
      "lang": "en",
      "text": "worker agents are going to work on those",
      "offset": 1063.6,
      "duration": 4.959
    },
    {
      "lang": "en",
      "text": "subtasks. Right? Let's see how that look",
      "offset": 1065.799,
      "duration": 4.721
    },
    {
      "lang": "en",
      "text": "what that looks like. So this is the",
      "offset": 1068.559,
      "duration": 4.721
    },
    {
      "lang": "en",
      "text": "orchestrator and the entire thing it is",
      "offset": 1070.52,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "going to do is give us back this type of",
      "offset": 1073.28,
      "duration": 6.56
    },
    {
      "lang": "en",
      "text": "response with subtasks which are going",
      "offset": 1076.12,
      "duration": 6.28
    },
    {
      "lang": "en",
      "text": "to be uh things that you know these",
      "offset": 1079.84,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "worker agents are going to do. It's a",
      "offset": 1082.4,
      "duration": 3.279
    },
    {
      "lang": "en",
      "text": "very simple worker agent. It's going to",
      "offset": 1084.16,
      "duration": 3.519
    },
    {
      "lang": "en",
      "text": "get a subtask and it will complete it",
      "offset": 1085.679,
      "duration": 4.561
    },
    {
      "lang": "en",
      "text": "right. So let's look at the main input",
      "offset": 1087.679,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "here. The input is write a blog post on",
      "offset": 1090.24,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "benefits of remote work. I care about",
      "offset": 1092.559,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "productivity, work life balance and",
      "offset": 1094.72,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "environmental impact. Let's see what",
      "offset": 1096.64,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "happens here. So the orchestrator here",
      "offset": 1098.799,
      "duration": 4.601
    },
    {
      "lang": "en",
      "text": "is going to generate a bunch of",
      "offset": 1101.44,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "subtasks. As you can see that is what it",
      "offset": 1103.4,
      "duration": 5.56
    },
    {
      "lang": "en",
      "text": "has done. So write the introduction uh",
      "offset": 1106,
      "duration": 6.32
    },
    {
      "lang": "en",
      "text": "write a section on productivity on work",
      "offset": 1108.96,
      "duration": 6.719
    },
    {
      "lang": "en",
      "text": "life balance on uh environmental impact",
      "offset": 1112.32,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "and then write a conclusion. So as you",
      "offset": 1115.679,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "can see here there are like one two",
      "offset": 1117.84,
      "duration": 7.04
    },
    {
      "lang": "en",
      "text": "three four and five subtasks. So this is",
      "offset": 1119.919,
      "duration": 9.441
    },
    {
      "lang": "en",
      "text": "going to take five workers worker agents",
      "offset": 1124.88,
      "duration": 7.039
    },
    {
      "lang": "en",
      "text": "to complete. Uh as you can see here,",
      "offset": 1129.36,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "this is the first worker agent. Second,",
      "offset": 1131.919,
      "duration": 5
    },
    {
      "lang": "en",
      "text": "um",
      "offset": 1135.36,
      "duration": 3.08
    },
    {
      "lang": "en",
      "text": "third,",
      "offset": 1136.919,
      "duration": 3.961
    },
    {
      "lang": "en",
      "text": "fourth, and here's the fifth one that is",
      "offset": 1138.44,
      "duration": 4.2
    },
    {
      "lang": "en",
      "text": "writing the conclusion, right? And",
      "offset": 1140.88,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "finally, we are going to synthesize all",
      "offset": 1142.64,
      "duration": 3.08
    },
    {
      "lang": "en",
      "text": "of this into one",
      "offset": 1144.24,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "thing. Uh look how simple this is. This",
      "offset": 1145.72,
      "duration": 5.24
    },
    {
      "lang": "en",
      "text": "is like what like 90 lines of code and",
      "offset": 1148.4,
      "duration": 5.279
    },
    {
      "lang": "en",
      "text": "there's no uh framework here. You're",
      "offset": 1150.96,
      "duration": 7.04
    },
    {
      "lang": "en",
      "text": "basically building very simple uh you",
      "offset": 1153.679,
      "duration": 6.561
    },
    {
      "lang": "en",
      "text": "know agents worker agents in an",
      "offset": 1158,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "orchestrator agent and your promise.all",
      "offset": 1160.24,
      "duration": 5.84
    },
    {
      "lang": "en",
      "text": "all running all of them uh and the data",
      "offset": 1162.88,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "is just flowing through that right",
      "offset": 1166.08,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "there's there's no need to build a",
      "offset": 1167.44,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "complicated abstraction layer on top of",
      "offset": 1169.919,
      "duration": 4.801
    },
    {
      "lang": "en",
      "text": "this because maybe uh you know in a",
      "offset": 1172,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "couple of months you'll see that agent",
      "offset": 1174.72,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "this agentic workflow will get even",
      "offset": 1176.64,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "better with LLMs understanding how to",
      "offset": 1178.559,
      "duration": 5.441
    },
    {
      "lang": "en",
      "text": "run these worker agents if you're using",
      "offset": 1181.36,
      "duration": 5.679
    },
    {
      "lang": "en",
      "text": "any AI framework in abstraction that you",
      "offset": 1184,
      "duration": 5.84
    },
    {
      "lang": "en",
      "text": "are you know kind of stuck with uh when",
      "offset": 1187.039,
      "duration": 4.801
    },
    {
      "lang": "en",
      "text": "these agents in with when these LLMs",
      "offset": 1189.84,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "become much more better at these agendic",
      "offset": 1191.84,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "workflows, you'll have a very hard time",
      "offset": 1194,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "migrating off of it. So, it's much",
      "offset": 1196.16,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "better to build on top of primitives",
      "offset": 1198.4,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "instead of building on top of a",
      "offset": 1200.64,
      "duration": 5.279
    },
    {
      "lang": "en",
      "text": "pre-built abstraction, right?",
      "offset": 1202.96,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "uh we'll probably also going to uh take",
      "offset": 1205.919,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "a look at this evaluator optimizer where",
      "offset": 1208.24,
      "duration": 5.84
    },
    {
      "lang": "en",
      "text": "um an LLM is used an agent is used to",
      "offset": 1211.039,
      "duration": 4.961
    },
    {
      "lang": "en",
      "text": "generate a response uh generate",
      "offset": 1214.08,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "something and this uh something this is",
      "offset": 1216,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "uh probably I don't know let's say a",
      "offset": 1219.2,
      "duration": 3.599
    },
    {
      "lang": "en",
      "text": "marketing copy this is going to be",
      "offset": 1220.96,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "evaluated by an LLM as a judge right",
      "offset": 1222.799,
      "duration": 5.681
    },
    {
      "lang": "en",
      "text": "which will either accept it or reject it",
      "offset": 1225.84,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "with feedback I'm just quickly going to",
      "offset": 1228.48,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "go and run this you know here's a",
      "offset": 1231.36,
      "duration": 5.439
    },
    {
      "lang": "en",
      "text": "generator which is generating ing uh you",
      "offset": 1233.12,
      "duration": 6.64
    },
    {
      "lang": "en",
      "text": "know um some product description. Here's",
      "offset": 1236.799,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "an evaluator which is going to either",
      "offset": 1239.76,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "say accepted or provide with uh feedback",
      "offset": 1241.919,
      "duration": 4.801
    },
    {
      "lang": "en",
      "text": "based on the prompt you write here right",
      "offset": 1244.48,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "and what we are doing is we are writing",
      "offset": 1246.72,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "an eco-friendly uh description for an",
      "offset": 1248.24,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "eco-friendly water bottle for conscious",
      "offset": 1250.4,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "melanin. So um the first agent takes a",
      "offset": 1252.64,
      "duration": 5.84
    },
    {
      "lang": "en",
      "text": "stab at it. Um and the evaluator",
      "offset": 1256.08,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "actually says no uh you are basically",
      "offset": 1258.48,
      "duration": 6.4
    },
    {
      "lang": "en",
      "text": "missing uh you know the point with this",
      "offset": 1261.6,
      "duration": 5.199
    },
    {
      "lang": "en",
      "text": "particular type of audience the",
      "offset": 1264.88,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "eco-conscious millennials right and",
      "offset": 1266.799,
      "duration": 4.721
    },
    {
      "lang": "en",
      "text": "provides very specific feedback uh on",
      "offset": 1268.799,
      "duration": 5.281
    },
    {
      "lang": "en",
      "text": "what to do and how to improve this and",
      "offset": 1271.52,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "this evaluator should be built by",
      "offset": 1274.08,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "probably the best possible uh LLM you",
      "offset": 1276.72,
      "duration": 5.199
    },
    {
      "lang": "en",
      "text": "can think of for your space of what you",
      "offset": 1279.76,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "are trying to evaluate if it is related",
      "offset": 1281.919,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "to health you're probably calling a",
      "offset": 1283.52,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "memory and you you know, you're doing",
      "offset": 1285.52,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "all that you need to do to make sure",
      "offset": 1288.08,
      "duration": 4.719
    },
    {
      "lang": "en",
      "text": "this evaluation is really good, right?",
      "offset": 1290.64,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "And the second iteration, as you can",
      "offset": 1292.799,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "see, uh is very well uh very uh is",
      "offset": 1294.799,
      "duration": 5.041
    },
    {
      "lang": "en",
      "text": "generally well done based on this",
      "offset": 1298.159,
      "duration": 3.721
    },
    {
      "lang": "en",
      "text": "particular",
      "offset": 1299.84,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "feedback. Finally, uh obviously you can",
      "offset": 1301.88,
      "duration": 4.6
    },
    {
      "lang": "en",
      "text": "call tools with this. We can skip that.",
      "offset": 1304.4,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "Uh I think you can probably easily",
      "offset": 1306.48,
      "duration": 3.679
    },
    {
      "lang": "en",
      "text": "understand that. The most interesting",
      "offset": 1308.48,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "one is memory. Memory is when you upload",
      "offset": 1310.159,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "data, you create a memory agent. You",
      "offset": 1312.559,
      "duration": 4.721
    },
    {
      "lang": "en",
      "text": "upload the data and then you retrieve",
      "offset": 1314.559,
      "duration": 4.881
    },
    {
      "lang": "en",
      "text": "that data and ask questions which is",
      "offset": 1317.28,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "exactly what we saw here in this code",
      "offset": 1319.44,
      "duration": 5.92
    },
    {
      "lang": "en",
      "text": "where we created a memory. Let me go to",
      "offset": 1322.4,
      "duration": 6.159
    },
    {
      "lang": "en",
      "text": "the agent code where we created a memory",
      "offset": 1325.36,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "uh uploaded the data manually which you",
      "offset": 1328.559,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "can also do through an API as you can",
      "offset": 1330.48,
      "duration": 3.319
    },
    {
      "lang": "en",
      "text": "see",
      "offset": 1332.64,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "here and then an agent was used to",
      "offset": 1333.799,
      "duration": 5.961
    },
    {
      "lang": "en",
      "text": "answer questions related to that data.",
      "offset": 1337.2,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "This is also a very common pattern for",
      "offset": 1339.76,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "building agents.",
      "offset": 1342,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "Now that you know all of these AI",
      "offset": 1344.4,
      "duration": 4.639
    },
    {
      "lang": "en",
      "text": "primitive patterns, you can build pretty",
      "offset": 1346.24,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "much 80% of the most complicated AI",
      "offset": 1349.039,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "agents out there. And I've done just",
      "offset": 1352.24,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "that like uh I've basically asked Chai",
      "offset": 1354.559,
      "duration": 4.441
    },
    {
      "lang": "en",
      "text": "to build me a deep researcher like",
      "offset": 1357.12,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "perplexity where it actually went ahead",
      "offset": 1359,
      "duration": 5.559
    },
    {
      "lang": "en",
      "text": "to uh build things to analyze the query",
      "offset": 1361.36,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "uh do a web search consolidate the",
      "offset": 1364.559,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "results and then uh create in a",
      "offset": 1366.64,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "response. It is using exa here and all",
      "offset": 1369.039,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "the code is here. I can actually just",
      "offset": 1372.4,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "probably go ahead and ask it something I",
      "offset": 1374.159,
      "duration": 6.88
    },
    {
      "lang": "en",
      "text": "don't know what's the latest with open",
      "offset": 1376.48,
      "duration": 6.559
    },
    {
      "lang": "en",
      "text": "AI something like this and it's probably",
      "offset": 1381.039,
      "duration": 5.201
    },
    {
      "lang": "en",
      "text": "going to go ahead u send this basic uh",
      "offset": 1383.039,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "query and start doing that deep",
      "offset": 1386.24,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "research. I've also built things like",
      "offset": 1388.159,
      "duration": 5.681
    },
    {
      "lang": "en",
      "text": "for example oh let me go back. I've also",
      "offset": 1390.24,
      "duration": 5.84
    },
    {
      "lang": "en",
      "text": "built things like uh I wanted a receipt",
      "offset": 1393.84,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "checker which would do OCR and since",
      "offset": 1396.08,
      "duration": 4.959
    },
    {
      "lang": "en",
      "text": "chai or lang didn't have an OCR",
      "offset": 1398.72,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "primitive I found one from Mistl so I",
      "offset": 1401.039,
      "duration": 4.961
    },
    {
      "lang": "en",
      "text": "asked it to use Mistl OCR and gave it an",
      "offset": 1403.44,
      "duration": 4.719
    },
    {
      "lang": "en",
      "text": "example of how to use it and that is",
      "offset": 1406,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "what it exactly did here so it's",
      "offset": 1408.159,
      "duration": 4.961
    },
    {
      "lang": "en",
      "text": "processing the image with OCR and using",
      "offset": 1410.64,
      "duration": 5.919
    },
    {
      "lang": "en",
      "text": "GPD 4.1 right now extracting uh from the",
      "offset": 1413.12,
      "duration": 6.16
    },
    {
      "lang": "en",
      "text": "user input whatever is needed and also",
      "offset": 1416.559,
      "duration": 5.921
    },
    {
      "lang": "en",
      "text": "using uh MR OCR latest model on top of",
      "offset": 1419.28,
      "duration": 5.84
    },
    {
      "lang": "en",
      "text": "right to do a double fall back and",
      "offset": 1422.48,
      "duration": 6.8
    },
    {
      "lang": "en",
      "text": "really improve the OCR um based on top",
      "offset": 1425.12,
      "duration": 6.64
    },
    {
      "lang": "en",
      "text": "of the image we are going to send it",
      "offset": 1429.28,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "right let's see you know I have an",
      "offset": 1431.76,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "example here I think this is Paulo Alto",
      "offset": 1433.84,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "$15 delivery or something yeah there you",
      "offset": 1436.4,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "go total paid 15 bucks and city of Paulo",
      "offset": 1439.12,
      "duration": 6.559
    },
    {
      "lang": "en",
      "text": "Alto it's a parking ticket I guess it's",
      "offset": 1441.44,
      "duration": 7.52
    },
    {
      "lang": "en",
      "text": "analyzing the result right",
      "offset": 1445.679,
      "duration": 3.281
    },
    {
      "lang": "en",
      "text": "now and there you go city of Polo Alto",
      "offset": 1449.159,
      "duration": 5.441
    },
    {
      "lang": "en",
      "text": "and 15 bucks.",
      "offset": 1452.4,
      "duration": 5.759
    },
    {
      "lang": "en",
      "text": "Right? Similarly, I built an agent where",
      "offset": 1454.6,
      "duration": 7.88
    },
    {
      "lang": "en",
      "text": "I like u let me add an image URL and let",
      "offset": 1458.159,
      "duration": 6.4
    },
    {
      "lang": "en",
      "text": "me chat with that image. Right? So, I",
      "offset": 1462.48,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "just added this uh image URL. Uh what is",
      "offset": 1464.559,
      "duration": 5.961
    },
    {
      "lang": "en",
      "text": "the",
      "offset": 1468.08,
      "duration": 6.76
    },
    {
      "lang": "en",
      "text": "expression of the person in this",
      "offset": 1470.52,
      "duration": 7.159
    },
    {
      "lang": "en",
      "text": "image? Okay, let's give it a go and see,",
      "offset": 1474.84,
      "duration": 4.959
    },
    {
      "lang": "en",
      "text": "you know, what",
      "offset": 1477.679,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "happens. There you go. uh eyebrow is",
      "offset": 1479.799,
      "duration": 6.201
    },
    {
      "lang": "en",
      "text": "raised uh quite skeptical and curious",
      "offset": 1482.799,
      "duration": 5.201
    },
    {
      "lang": "en",
      "text": "which is what I generally look like in",
      "offset": 1486,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "real life right so uh in the code for",
      "offset": 1488,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "this is pretty easy analyze the image",
      "offset": 1490.48,
      "duration": 5.92
    },
    {
      "lang": "en",
      "text": "using GP40 uh a vision capable model uh",
      "offset": 1492.4,
      "duration": 6.48
    },
    {
      "lang": "en",
      "text": "takes the image here uh takes the image",
      "offset": 1496.4,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "URL here from here passes the input and",
      "offset": 1498.88,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "that is pretty much it right it's a",
      "offset": 1502.08,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "pretty simple flow as if you ask me so",
      "offset": 1504.24,
      "duration": 5.039
    },
    {
      "lang": "en",
      "text": "well this this is pretty much it and",
      "offset": 1507.44,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "we've seen like you know it's May 30th",
      "offset": 1509.279,
      "duration": 5.201
    },
    {
      "lang": "en",
      "text": "and you can see almost every other",
      "offset": 1511.84,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "minute there is a new agent being built.",
      "offset": 1514.48,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "I saw somebody building a dental cost",
      "offset": 1517.12,
      "duration": 6.4
    },
    {
      "lang": "en",
      "text": "advisor uh a business swamp pro uh I",
      "offset": 1519.36,
      "duration": 6.88
    },
    {
      "lang": "en",
      "text": "don't know a task refiner all sorts of",
      "offset": 1523.52,
      "duration": 5.279
    },
    {
      "lang": "en",
      "text": "amazing uh agents are being built with",
      "offset": 1526.24,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "chai and chai is building all these on",
      "offset": 1528.799,
      "duration": 6.561
    },
    {
      "lang": "en",
      "text": "top of AI primitives instead of building",
      "offset": 1532.24,
      "duration": 6.08
    },
    {
      "lang": "en",
      "text": "it on top of a framework uh that would",
      "offset": 1535.36,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "have some abstraction that you probably",
      "offset": 1538.32,
      "duration": 4.239
    },
    {
      "lang": "en",
      "text": "don't even need when building agents",
      "offset": 1540.24,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "right so the idea is very simple all the",
      "offset": 1542.559,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "production agents",
      "offset": 1545.6,
      "duration": 3.679
    },
    {
      "lang": "en",
      "text": "that we know of when they are not built",
      "offset": 1547.279,
      "duration": 4.561
    },
    {
      "lang": "en",
      "text": "on top of frameworks. What good a",
      "offset": 1549.279,
      "duration": 5.201
    },
    {
      "lang": "en",
      "text": "framework would do to you in a fastm",
      "offset": 1551.84,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "moving space when every other week there",
      "offset": 1554.48,
      "duration": 6.72
    },
    {
      "lang": "en",
      "text": "is a new paradigm, a new LLM, a new",
      "offset": 1557.52,
      "duration": 6.48
    },
    {
      "lang": "en",
      "text": "problem being solved already that used",
      "offset": 1561.2,
      "duration": 7.04
    },
    {
      "lang": "en",
      "text": "to take a lot. Uh why not build your AI",
      "offset": 1564,
      "duration": 6.4
    },
    {
      "lang": "en",
      "text": "agents on top of really good AI",
      "offset": 1568.24,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "primitives? uh and you can either build",
      "offset": 1570.4,
      "duration": 5.279
    },
    {
      "lang": "en",
      "text": "those AI primitives or you can use the",
      "offset": 1573.2,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "pre-built AI primitives that we built or",
      "offset": 1575.679,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "some of our you know friends uh are",
      "offset": 1577.84,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "building over at different uh companies",
      "offset": 1580.08,
      "duration": 7.52
    },
    {
      "lang": "en",
      "text": "u and also uh if you really enjoy uh you",
      "offset": 1583.44,
      "duration": 7.599
    },
    {
      "lang": "en",
      "text": "know w coding give chia uh you know uh a",
      "offset": 1587.6,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "try. It will try to use the primitives",
      "offset": 1591.039,
      "duration": 5.681
    },
    {
      "lang": "en",
      "text": "it knows and it will also try to you",
      "offset": 1593.6,
      "duration": 5.88
    },
    {
      "lang": "en",
      "text": "make it really really easy for you to",
      "offset": 1596.72,
      "duration": 6.48
    },
    {
      "lang": "en",
      "text": "quickly build an agent deploy it and use",
      "offset": 1599.48,
      "duration": 5.96
    },
    {
      "lang": "en",
      "text": "it right away instead of building a",
      "offset": 1603.2,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "silly demo that may or may not scale",
      "offset": 1605.44,
      "duration": 6.56
    },
    {
      "lang": "en",
      "text": "right. Uh I am MLS and I am always",
      "offset": 1607.84,
      "duration": 6.4
    },
    {
      "lang": "en",
      "text": "hanging out on Twitter. I would love uh",
      "offset": 1612,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "your feedback. I would love to know, you",
      "offset": 1614.24,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "know, what you folks think and what you",
      "offset": 1615.919,
      "duration": 4.481
    },
    {
      "lang": "en",
      "text": "prompt, ship and ship with our AI",
      "offset": 1618,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "primitives or not. Take care. Ciao. Use",
      "offset": 1620.4,
      "duration": 6.96
    },
    {
      "lang": "en",
      "text": "your code for good. Peace.",
      "offset": 1623.52,
      "duration": 3.84
    }
  ],
  "cleanText": "Well, hello there. I am Ahmad, and I'm going to vibe code an AI agent built with AI primitives while I deliver this talk, right? So, let's start here. One of the most common AI agents that we've seen in production is there's some data, and there's a chatbot as an agent, and you're trying to chat with that data because, well, all of these LLMs are self-attention algorithms anyway, right? So you go to chai.new and you say something like chat with PDF, and let's see what happens. Chai is now going to vibe code an AI agent for you. It's going to build it on top of AI primitives instead of an AI framework. And as that is happening, it just takes like a minute. How about I tell you a little bit more about who I am and what are we talking about today, right? So, uh, look at perplexity, Cursor v0, uh, lovable, bolt, and even now, CHAI. You will see one common theme across all these production-ready agents that are, you know, building millions of agents, millions of gener, you know, millions of people are using them, and there's this one, this one really good trend that you can pick up, that all these AI agents in production are actually not built on top of any AI frameworks because, well, frameworks do not really add that much value. They're bloated. They move super slowly, and they're filled with these abstractions that nobody really needs. Instead, you should be building on top of AI primitives. This is what my entire talk, uh, is about today. I am Ahmad. I've been around the blog for quite a while. If you use WordPress, NextJS, NodeJS, React, you have probably been using my code because I've contributed to all of these software. I have also built, uh, hundreds of open-source packages, mostly automation CLIs with NodeJS and created a shades of purple code theme, all of which are downloaded like 40, 50 million times, uh, you know, a year, and I've gone up to, you know, as, uh, as technical as you can imagine. I've contributed to NASA helicopter mission, and in the past, I have been a VP of developer tools, VP of engineering, Google developers advisory board member. All I'm trying to say is I am deeply technical. I've gone through this phase of working with and building frameworks, and now why do you think I am talking about primitives? I think primitives have this native ability of working really, really well in production, like Amazon S3 is a really good, uh, example here. Amazon S3 is a primitive where you can upload data and download data, and they scale it, uh, massively. They're not building a framework for object storage. It's a very simple thing. It's a low-level primitive you can use to build lots of things, right? And that is what we are, uh, talking about here today. My journey in LLM actually started with in 2020 when Greg Brockman himself gave me access to GP3. GP3 was just like what, uh, maybe a month-old model, and I, I had already started building, uh, you know, something like GitHub Copilot, which, uh, launched in 2021, a year later, right? Even now, you know, we've been building it, uh, things and agents for like, I don't know, five years. Building and deploying and scaling AI agent remains to be the biggest pain there is, and I think everybody has a different definition of AI agents, but this is my take at it. I think AI agents are just a new way of writing code. Everything we know of how we used to build code, how you used to build coding projects, uh, or SAS, all of that is changing because of AI and because of agents, and it's, it's just big enough. It's not, it's just a new way to write code. It's big enough. You know, if you try to put it inside of a framework, that abstraction might not be enough. Instead, how about we build small building blocks that are useful across a stack, like something like threads? You know, every agent needs to store some sort of context or history of conversation. So, threads would be an awesome primitive, and we build that, right? So, why not build that? Why I think that is important is because here's my belief. I think most of engineers are going to become AI engineers. This you can already see with full-stack AI engineers, web developers, and front-end developers. They're quickly transitioning into this AI engineering role because they are shipping a lot of product with AI, and they are building stuff with, uh, different LLMs or whatnot, with vector stores and this and that. Even DevOps engineers and ML engineers are now shipping product. So when everyone is building as an AI engineer, what we are trying to do, uh, here at Langbase, is improve their experience. We want to become the fastest possible way for you to build a production-ready AI agent. A lot of people, I think, start with this painful way of building AI agents where they pick up a framework which is filled with, uh, you know, obscure abstractions which are really, really hard to debug, and then they have to figure out how to deploy and scale those agents. We think the other way. I think if you are building on top of predefined, really good, highly scalable AI primitives, especially composable primitives that come with a piece of cloud in it, like, uh, you know, memory. Memory is an AI primitive, which is like, you know, like memory, which has a vector store in it. You can throw in, I don't know, terabytes of data inside of memory, and it will automatically scale. So if you build an AI agent with that memory or with that parsing, chunking, or threads or tools infrastructure, what you get is a serverless AI agent that automatically can do the heavy lifting for you. But what does that actually look like? Let's take a look at what is happening here today in this talk. I'm going to share, and by the way, like I'm going to probably, you know, already done. I'm going to deploy this before you know we move forward. I am going to go over eight different AI agent architectures that are built purely with AI primitives instead of a framework. Look like, look at this, you know, I said chat with PDF, and it figured out that, well, you need a memory for storing this PDF, which will have a vector store, and you need, uh, an AI agent, an LLM, uh, which will be used to ask questions from this PDF, right? So it went ahead and did this, you know, we need it created a memory, created, uh, a way for you to generate answers, an agent on top of that memory, right? This, uh, the flow of this very simple. I want to retrieve some PDF content and then generate the answer, right? And you know, it's already done. As you can see these lines, the first step is to build that memory, and we are using a primitive here, langbase.mmemories. This primitive is where we will put the user, uh, input, the, you know, the question that user is trying to ask, is the name of that memory, the PDF, uh, document memory. Uh, if you go here, you will find that memory. In all of this can be built, uh, with APIs as well. What I'm going to do here is I'm going to go to, I don't know, uh, mls.com about and ms.com talks. Uh, this page has information about me. This one has information about my talks, like the one I'm giving right now. And I'm going to throw all of these as PDF files in it. So I have already saved them on my desktop. So I'm going to just quickly grab them and upload here. I've also, I'm also going to do this API key Langbase. So I'm also going to throw a PDF version of this particular file into the memory. As you can see, uh, this is the doc about Langbase, uh, how to get API keys from Langbase, uh, my talks and my about page. All of these files are right now being processed, which means, uh, a parser primitive is converting these files, uh, from PDF to text, and then a chunker primitive is going to chunk these into small pieces of context, which are going to be used in a similarity search. If I refresh these, you will see that all of these files are now ready, right? Now, now let's go to this agent code and see what is there. All right. So we are going to ask a question from this memory, right? Which will return back some memories. And these memories are in the second step. As you can see here, this is what we are going to use as context, right? This is generate answer step. And in this step, we are basically going to create an AI agent that is going to use that context to answer the questions you have, right? Very simple. Uh, it has also, uh, CHAI has also, you know, built an agent app for you, which makes it really easy to use, but you can also go ahead and use, you know, uh, an API with whatever programming language you prefer. Let's try the agent app. Let's ask it something, some, uh, very simple. So who's the founder and his last three talks? There you go. Right now, this information is in two different files in our memory, which was parsed, chunked, and embedded automatically using those primitives, and you can see the answer is already here. I'm the founder, here are, you know, the last three talks I did, uh, and how do I get an API key? This should probably also give me, uh, an answer on how to get that API key from that other file that we had. Um, added in there. There you go. How you get an API key. There's a bug. You can actually go to the app mode and vibe code a fix for this bug, and this app, uh, will be fixed. You can also, you know, make it public or whatnot. What's happening behind the scene here is most interesting. You know, uh, I think every agent needs all these primitives that we are building, right? Primitives are like, you know, memory, which is an autonomous drag engine, a workflow engine that is built purpose-built for multi-steps agent threads where you store and manage this context and conversation, a parser to extract the context, and a chunker to split this, right? And using all these primitives, you can build almost any AI agent. We actually did a lot of research on stateofiag aents.com, where you can read a lot about how people are building, uh, agents, what type of primitives they are using, and what type of, uh, LLM is required in doing really well in which type of industry, right? Let's now go over different AI primitives and different agent architectures that use different AI primitives. So the first most common architecture that we see is an augmented LLM. Augmented LLM is basically an agent. It's an agent that is going to get an, uh, you, some input, and it's going to generate some output, which will have an LLM. It will have some way to automatically call tools, so it can connect to MCPs or call different APIs. It will have access to threads. Thread is another AI primitive which will, which is where you can store the conversation users are having with this agent or the context of this agent, uh, you know, which might be, you know, completely, completely asynchronous, right? Uh, thread, uh, of context, a scratch pad, like, for example, when you're booking a flight, there's certain set of information that you kind of keep in your header on a scratch pad, like I'm going to land here, I'm going to go do this and that and that is useful when you are, you know, booking that particular flight. So you can use thread to store that, uh, you know, memory, like context, and then there's memory, the long-term memory of, you know, different events or whatnot. This could be terabytes of data that you want to search when you're using this agent, right? Uh, which obviously requires more context and requires, you know, vector store. So in this example, in this augmented LLM, we see tools as primitives, threads as a primitive, and memory as a primitive. And you can basically build almost any type of AI agent with this augmented LLM architecture. As you can see here, Langpipes or agents provide you with that primitive. Now let's, uh, look at what type of agents and what type of architectures can you actually build, uh, using that augmented LLM that I just showed you. Here's another one. So prompt chaining and composition where you use multiple agents, as you can see the purple blocks here, working together. You get an input and agent creates an output, and based on that output, you basically decide if you want to go forward, right? Maybe you got an email, uh, and you figured out if that was spam or not. And if it was not spam, then you used another agent to write a draft email in response. And you can, uh, take a look at, you know, what's happening here. There's a summary agent, there's a features agent, there's a marketing copy agent. This code is plain JavaScript or TypeScript, if you will, right? You can see here, um, a summary agent, uh, this is a feature agent, and this is a marketing copy agent. They're all going to work together to generate an output that you need based on an input. A more interesting one is, uh, something like agent router, right? Where an agent, uh, or an LLM router that you build basically decides which other agent is needed to be called next, right? Let's see what this is, what this architecture looks like in production. None of this, uh, we are going to build all of this with AI parameters. None of this is built with a framework. We're going to basically create three specialized agents for different tasks. One is a summary agent for summarizing text. The other one is a reasoning agent for analyzing and explanations, and then a coding agent for obvious reasons, you know, when you need to write code, and all these are built with different LLM. So summary is from Gemini, uh, reasoning is with deepse, uh, llama 70B, and coding is with clots on it. Right now, let's look at this code. This code right here is only going to use AI primitives, and you will build your own, uh, AI framework on top of it instead of using a botted AI framework, right? So as you can see, here's a routing agent. Router is being told what the job is. It has access to all these agents, and it is supposed to respond back with valid JSON and picking which of these agents is going to do the job for us, right? And here is the documentation of a very simple set of agents. A summary agent, uh, uh, a summary agent, a reasoning agent, uh, right here, and a coding agent, right? Now all of these are going to run together. All of this, as you can see, is just plain old code. There's nothing new here. You can easily write this. This, there's no magic. There's nothing to learn. It's basically you're just calling these agents together, and one of these agents are going to respond back with which next agent you need to run, uh, you know, for the task. So the task is very simple. Uh, y days are shorter in winter. Now let's go ahead and run this code. So the main agent, the router, the scene agent has decided that it needs to run the reasoning, or you need to run the reasoning agent, uh, to for this particular task, right? Obviously, you're not writing code here. You're not, uh, writing summary. You can see how the the decision maker made the right choice, and then you pick up the same, uh, uh, reasoning agent that he had built based on this answer, and then throw that input in there, and here's the, you know, answer of why answer of why days are actually shorter in winter. Don't get distracted by this answer, by the way. Right? So another very common architecture for building agents we see is running, uh, agents in peril. This is absolutely\n\n\nSimple to use.\nUh, there's no abstraction needed for JavaScript.\nUh, in JavaScript, you can basically build a set of agents as you can see here.\nHere's a sentiment summary in the scene maker agent, and you can promise do all of these agents, and they will run in parallel.\nMy favorite, however, is this agent orchestrator worker, where an agent basically decides to orchestrate and build any number of worker agents that are going to solve a problem, which is then synthesized by another agent.\nRight?\nThis is exactly what uh a deep research agent architecture looks like.\nSo this one is really good.\nWhat we are going to do in this is we are going to create an orchestrator agent that will plan and create subtasks for worker agents, and these worker agents are going to work on those subtasks.\nRight?\nLet's see how that look, what that looks like.\nSo this is the orchestrator, and the entire thing it is going to do is give us back this type of response with subtasks, which are going to be uh things that, you know, these worker agents are going to do.\nIt's a very simple worker agent.\nIt's going to get a subtask, and it will complete it, right?\nSo let's look at the main input here.\nThe input is write a blog post on benefits of remote work.\nI care about productivity, work-life balance, and environmental impact.\nLet's see what happens here.\nSo the orchestrator here is going to generate a bunch of subtasks.\nAs you can see, that is what it has done.\nSo write the introduction, uh write a section on productivity, on work-life balance, on uh environmental impact, and then write a conclusion.\nSo as you can see here, there are like one, two, three, four, and five subtasks.\nSo this is going to take five workers, worker agents to complete.\nUh, as you can see here, this is the first worker agent.\nSecond, um, third, fourth, and here's the fifth one that is writing the conclusion, right?\nAnd finally, we are going to synthesize all of this into one thing.\nUh, look how simple this is.\nThis is like what, like 90 lines of code, and there's no uh framework here.\nYou're basically building very simple uh, you know, agents, worker agents in an orchestrator agent, and your promise.all, all running all of them, uh, and the data is just flowing through that, right?\nThere's there's no need to build a complicated abstraction layer on top of this because maybe uh, you know, in a couple of months, you'll see that agent, this agentic workflow will get even better with LLMs understanding how to run these worker agents.\nIf you're using any AI framework in abstraction that you are, you know, kind of stuck with, uh, when these agents in with when these LLMs become much more better at these agentic workflows, you'll have a very hard time migrating off of it.\nSo, it's much better to build on top of primitives instead of building on top of a pre-built abstraction, right?\nUh, we'll probably also going to uh take a look at this evaluator optimizer where um an LLM is used, an agent is used to generate a response, uh generate something, and this uh something, this is uh probably, I don't know, let's say a marketing copy.\nThis is going to be evaluated by an LLM as a judge, right, which will either accept it or reject it with feedback.\nI'm just quickly going to go and run this, you know, here's a generator which is generating ing uh, you know, um, some product description.\nHere's an evaluator which is going to either say accepted or provide with uh feedback based on the prompt you write here, right?\nAnd what we are doing is we are writing an eco-friendly uh description for an eco-friendly water bottle for conscious millennials.\nSo, um, the first agent takes a stab at it.\nUm, and the evaluator actually says no, uh, you are basically missing uh, you know, the point with this particular type of audience, the eco-conscious millennials, right?\nAnd provides very specific feedback uh on what to do and how to improve this, and this evaluator should be built by probably the best possible uh LLM you can think of for your space of what you are trying to evaluate.\nIf it is related to health, you're probably calling a memory, and you, you know, you're doing all that you need to do to make sure this evaluation is really good, right?\nAnd the second iteration, as you can see, uh, is very well, uh, very uh, is generally well done based on this particular feedback.\nFinally, uh, obviously you can call tools with this.\nWe can skip that.\nUh, I think you can probably easily understand that.\nThe most interesting one is memory.\nMemory is when you upload data, you create a memory agent.\nYou upload the data and then you retrieve that data and ask questions, which is exactly what we saw here in this code where we created a memory.\nLet me go to the agent code where we created a memory, uh, uploaded the data manually, which you can also do through an API, as you can see here, and then an agent was used to answer questions related to that data.\nThis is also a very common pattern for building agents.\nNow that you know all of these AI primitive patterns, you can build pretty much 80% of the most complicated AI agents out there.\nAnd I've done just that, like uh, I've basically asked CHAI to build me a deep researcher like perplexity, where it actually went ahead to uh, build things to analyze the query, uh, do a web search, consolidate the results, and then uh, create in a response.\nIt is using exa here, and all the code is here.\nI can actually just probably go ahead and ask it something, I don't know, what's the latest with open AI, something like this, and it's probably going to go ahead, uh, send this basic uh, query and start doing that deep research.\nI've also built things like, for example, oh, let me go back.\nI've also built things like uh, I wanted a receipt checker which would do OCR, and since CHAI or Lang didn't have an OCR primitive, I found one from Mistl, so I asked it to use Mistl OCR and gave it an example of how to use it, and that is what it exactly did here, so it's processing the image with OCR and using GPD 4.1 right now, extracting uh from the user input whatever is needed and also using uh MR OCR latest model on top of right to do a double fall back and really improve the OCR, um, based on top of the image we are going to send it, right?\nLet's see, you know, I have an example here.\nI think this is Paulo Alto $15 delivery or something, yeah, there you go, total paid 15 bucks and city of Paulo Alto, it's a parking ticket, I guess, it's analyzing the result right now, and there you go, city of Polo Alto and 15 bucks.\nRight?\nSimilarly, I built an agent where I like, u let me add an image URL and let me chat with that image.\nRight?\nSo, I just added this uh image URL.\nUh, what is the expression of the person in this image?\nOkay, let's give it a go and see, you know, what happens.\nThere you go.\nUh, eyebrow is raised, uh, quite skeptical and curious, which is what I generally look like in real life, right?\nSo, uh, in the code for this is pretty easy, analyze the image using GP40, uh, a vision capable model, uh, takes the image here, uh, takes the image URL here from here, passes the input, and that is pretty much it, right?\nIt's a pretty simple flow as if you ask me.\nSo, well, this, this is pretty much it, and we've seen like, you know, it's May 30th, and you can see almost every other minute there is a new agent being built.\nI saw somebody building a dental cost advisor, uh, a business swamp pro, uh, I don't know, a task refiner, all sorts of amazing uh, agents are being built with CHAI, and CHAI is building all these on top of AI primitives instead of building it on top of a framework uh, that would have some abstraction that you probably don't even need when building agents, right?\nSo the idea is very simple, all the production agents that we know of when they are not built on top of frameworks.\nWhat good a framework would do to you in a fast-moving space when every other week there is a new paradigm, a new LLM, a new problem being solved already that used to take a lot.\nUh, why not build your AI agents on top of really good AI primitives?\nUh, and you can either build those AI primitives or you can use the pre-built AI primitives that we built or some of our, you know, friends uh, are building over at different uh, companies.\nU, and also uh, if you really enjoy uh, you know, w coding, give CHAI uh, you know, uh, a try.\nIt will try to use the primitives it knows, and it will also try to you make it really, really easy for you to quickly build an agent, deploy it, and use it right away instead of building a silly demo that may or may not scale, right?\nUh, I am MLS, and I am always hanging out on Twitter.\nI would love uh, your feedback.\nI would love to know, you know, what you folks think and what you prompt, ship and ship with our AI primitives or not.\nTake care.\nCiao.\nUse your code for good.\nPeace.\n",
  "dumpedAt": "2025-07-21T18:43:25.772Z"
}