{
  "episodeId": "b0xlsQ_6wUQ",
  "channelSlug": "@aidotengineer",
  "title": "The Future of Qwen: A Generalist Agent Model — Junyang Lin, Alibaba Qwen",
  "publishedAt": "2025-06-03T01:08:22.000Z",
  "rawLines": [
    {
      "lang": "en",
      "text": "Hey everyone, I'm Jinang fromWent team",
      "offset": 3.679,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "Alib to be here in AI engineer world",
      "offset": 6.759,
      "duration": 5.8
    },
    {
      "lang": "en",
      "text": "fair 205 and I'm very excited to share",
      "offset": 9.679,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "some progress about quen to all of you.",
      "offset": 12.559,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "I think you guys know about quen and uh",
      "offset": 14.639,
      "duration": 5.041
    },
    {
      "lang": "en",
      "text": "maybe you are developers I'm very happy",
      "offset": 17.359,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "to share some more things about Gwen to",
      "offset": 19.68,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "all of you. is a large a series of large",
      "offset": 21.68,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "language models and large multimodel",
      "offset": 24.48,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "models and uh we have a dream of",
      "offset": 26.24,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "building a journalist model and",
      "offset": 28.72,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "generalist agent and before I start I",
      "offset": 30.16,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "would like to share some important links",
      "offset": 33.28,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "to all of you uh maybe you know our",
      "offset": 34.8,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "product our chat interface quench chat",
      "offset": 36.8,
      "duration": 5.439
    },
    {
      "lang": "en",
      "text": "uh which is chat.quen.ai AI uh it is",
      "offset": 39.2,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "very easy to use. You can interact with",
      "offset": 42.239,
      "duration": 4.241
    },
    {
      "lang": "en",
      "text": "our latest models. You can use our",
      "offset": 44,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "multimodel models uh by uploading images",
      "offset": 46.48,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "and videos and you can also interact",
      "offset": 49.12,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "with our omni models using voice chat",
      "offset": 50.879,
      "duration": 4.481
    },
    {
      "lang": "en",
      "text": "and video chat. And there are some",
      "offset": 53.36,
      "duration": 5.199
    },
    {
      "lang": "en",
      "text": "important features like webdev and um",
      "offset": 55.36,
      "duration": 6.08
    },
    {
      "lang": "en",
      "text": "deep research. Welcome to enjoy it. And",
      "offset": 58.559,
      "duration": 4.721
    },
    {
      "lang": "en",
      "text": "uh if you like to know more about",
      "offset": 61.44,
      "duration": 3.439
    },
    {
      "lang": "en",
      "text": "technical details, you can check our",
      "offset": 63.28,
      "duration": 3.159
    },
    {
      "lang": "en",
      "text": "blog which is",
      "offset": 64.879,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "quen.github.io. in our blog. Uh once we",
      "offset": 66.439,
      "duration": 5.561
    },
    {
      "lang": "en",
      "text": "release something new, we often uh",
      "offset": 69.2,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "release a blog. So you would can know",
      "offset": 72,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "more about technical details uh through",
      "offset": 74.4,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "our blogs. Uh as we keep open sourcing",
      "offset": 76.08,
      "duration": 6.88
    },
    {
      "lang": "en",
      "text": "so uh we have our codes in GitHub and uh",
      "offset": 78.88,
      "duration": 6.48
    },
    {
      "lang": "en",
      "text": "we have our checkpoints in hugging base.",
      "offset": 82.96,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "So you can download our checkpoints and",
      "offset": 85.36,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "play with our models. Yeah. Um so feel",
      "offset": 86.88,
      "duration": 6.4
    },
    {
      "lang": "en",
      "text": "free to uh check our websites and enjoy",
      "offset": 90.08,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "them. Yep.",
      "offset": 93.28,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "uh in this year just before the spring",
      "offset": 95.36,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "festival we have released uh very good",
      "offset": 97.84,
      "duration": 6.16
    },
    {
      "lang": "en",
      "text": "instruction tune models I think it's a",
      "offset": 101.36,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "very good basis uh for larger language",
      "offset": 104,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "models which is when 2.5 max it is a",
      "offset": 106.96,
      "duration": 6.56
    },
    {
      "lang": "en",
      "text": "very large models and we find that um in",
      "offset": 109.68,
      "duration": 6.16
    },
    {
      "lang": "en",
      "text": "multiple benchmarks uh it achieves very",
      "offset": 113.52,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "very competitive performance to the",
      "offset": 115.84,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "state-of-the-art models at that time",
      "offset": 118,
      "duration": 5.84
    },
    {
      "lang": "en",
      "text": "including colog 3.5 GBD 40 and DCB v3",
      "offset": 119.92,
      "duration": 8.559
    },
    {
      "lang": "en",
      "text": "three uh but we uh we uh we believe that",
      "offset": 123.84,
      "duration": 7.28
    },
    {
      "lang": "en",
      "text": "there are more potential for a large",
      "offset": 128.479,
      "duration": 4.801
    },
    {
      "lang": "en",
      "text": "language model not just becoming an",
      "offset": 131.12,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "instruction tune model but it can uh be",
      "offset": 133.28,
      "duration": 5.92
    },
    {
      "lang": "en",
      "text": "smarter and smarter with reinforcement",
      "offset": 137.12,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "learning. So we have dived into uh doing",
      "offset": 139.2,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "the research in reinforcement learning",
      "offset": 142.16,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "and we finally found that well it is",
      "offset": 143.92,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "really amazing to see that you using RL",
      "offset": 146.4,
      "duration": 5.199
    },
    {
      "lang": "en",
      "text": "can increase its performance especially",
      "offset": 149.52,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "in breathing task like math and coding",
      "offset": 151.599,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "and in increase the performance quite",
      "offset": 154.08,
      "duration": 6.48
    },
    {
      "lang": "en",
      "text": "consistently uh just like for for am 20",
      "offset": 156.879,
      "duration": 6.881
    },
    {
      "lang": "en",
      "text": "uh 24 for a 32 billion parameter model",
      "offset": 160.56,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "you you can find that its performance uh",
      "offset": 163.76,
      "duration": 5.199
    },
    {
      "lang": "en",
      "text": "starting from like 65 and is it",
      "offset": 166.16,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "increasing until it is 80. So it is",
      "offset": 168.959,
      "duration": 5.121
    },
    {
      "lang": "en",
      "text": "really amazing to build a reasoning",
      "offset": 171.92,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "model like Q and also in triple arena",
      "offset": 174.08,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "you can find that its performance uh is",
      "offset": 177.68,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "also very competitive with even larger",
      "offset": 180.08,
      "duration": 6.879
    },
    {
      "lang": "en",
      "text": "models and it is in uh top 15 for for a",
      "offset": 183.2,
      "duration": 6.24
    },
    {
      "lang": "en",
      "text": "long time. So we would like to combine",
      "offset": 186.959,
      "duration": 6.481
    },
    {
      "lang": "en",
      "text": "all our uh efforts uh in our research uh",
      "offset": 189.44,
      "duration": 7.36
    },
    {
      "lang": "en",
      "text": "and development to build a stronger next",
      "offset": 193.44,
      "duration": 5.92
    },
    {
      "lang": "en",
      "text": "generation models. So very very recently",
      "offset": 196.8,
      "duration": 6.4
    },
    {
      "lang": "en",
      "text": "we have released Gwen 3. Gwen 3 is our",
      "offset": 199.36,
      "duration": 6.799
    },
    {
      "lang": "en",
      "text": "latest large language models and we have",
      "offset": 203.2,
      "duration": 5.84
    },
    {
      "lang": "en",
      "text": "released multiple sizes of dense and",
      "offset": 206.159,
      "duration": 5.761
    },
    {
      "lang": "en",
      "text": "models with a large number of models. Uh",
      "offset": 209.04,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "first of all I would like to share the a",
      "offset": 211.92,
      "duration": 6.8
    },
    {
      "lang": "en",
      "text": "flagship model to auto which is a um 20",
      "offset": 213.68,
      "duration": 6.199
    },
    {
      "lang": "en",
      "text": "uh",
      "offset": 218.72,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "235 billion parameter model. It was a",
      "offset": 219.879,
      "duration": 5.64
    },
    {
      "lang": "en",
      "text": "total number but only activates 22",
      "offset": 223.12,
      "duration": 5.92
    },
    {
      "lang": "en",
      "text": "billion parameter models. um uh it is",
      "offset": 225.519,
      "duration": 6.72
    },
    {
      "lang": "en",
      "text": "ane models so it is actually efficient",
      "offset": 229.04,
      "duration": 6.16
    },
    {
      "lang": "en",
      "text": "but it's very effective in comparison",
      "offset": 232.239,
      "duration": 6.161
    },
    {
      "lang": "en",
      "text": "with uh very top tier models like 03",
      "offset": 235.2,
      "duration": 5.599
    },
    {
      "lang": "en",
      "text": "mini and it's just lagging a little bit",
      "offset": 238.4,
      "duration": 5.759
    },
    {
      "lang": "en",
      "text": "behind uh Gemini 2.5 Pro and also for",
      "offset": 240.799,
      "duration": 5.681
    },
    {
      "lang": "en",
      "text": "for our largest dense model it's also",
      "offset": 244.159,
      "duration": 5.841
    },
    {
      "lang": "en",
      "text": "very competitive as uh as well and we",
      "offset": 246.48,
      "duration": 7.44
    },
    {
      "lang": "en",
      "text": "have a very very fast models it is",
      "offset": 250,
      "duration": 6.72
    },
    {
      "lang": "en",
      "text": "relatively small although it has 30",
      "offset": 253.92,
      "duration": 5.24
    },
    {
      "lang": "en",
      "text": "billion total parameter models only",
      "offset": 256.72,
      "duration": 5.199
    },
    {
      "lang": "en",
      "text": "activate three billion parameter models.",
      "offset": 259.16,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "But if you compare the performance with",
      "offset": 261.919,
      "duration": 6.401
    },
    {
      "lang": "en",
      "text": "Q32 billion, the MOE models which only",
      "offset": 264.12,
      "duration": 7.079
    },
    {
      "lang": "en",
      "text": "activate three billion parameter models",
      "offset": 268.32,
      "duration": 6.439
    },
    {
      "lang": "en",
      "text": "even can out compete Q32 billion in some",
      "offset": 271.199,
      "duration": 6.961
    },
    {
      "lang": "en",
      "text": "task. And for a even smaller models very",
      "offset": 274.759,
      "duration": 6.201
    },
    {
      "lang": "en",
      "text": "small it is only 4 billion parameter",
      "offset": 278.16,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "models but this time we have a lot of",
      "offset": 280.96,
      "duration": 5.16
    },
    {
      "lang": "en",
      "text": "techniques uh in distillation distilling",
      "offset": 283.12,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "large the knowledge from large model to",
      "offset": 286.12,
      "duration": 6.04
    },
    {
      "lang": "en",
      "text": "small models. We finally built a very",
      "offset": 288.72,
      "duration": 6.44
    },
    {
      "lang": "en",
      "text": "good small models and with thinking",
      "offset": 292.16,
      "duration": 6.36
    },
    {
      "lang": "en",
      "text": "capabilities it even shows",
      "offset": 295.16,
      "duration": 5.88
    },
    {
      "lang": "en",
      "text": "competitiveness to the flagship model in",
      "offset": 298.52,
      "duration": 8.239
    },
    {
      "lang": "en",
      "text": "our last ver uh iteration like quen",
      "offset": 301.04,
      "duration": 9.04
    },
    {
      "lang": "en",
      "text": "2.572b. Yeah. So it is a really good",
      "offset": 306.759,
      "duration": 5.961
    },
    {
      "lang": "en",
      "text": "model and it is really worth a try for",
      "offset": 310.08,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "you to play with our 4 billion parameter",
      "offset": 312.72,
      "duration": 3.759
    },
    {
      "lang": "en",
      "text": "model and the 4 billion parameter model",
      "offset": 314.88,
      "duration": 3.4
    },
    {
      "lang": "en",
      "text": "and you can even deploy it in mobile",
      "offset": 316.479,
      "duration": 6.481
    },
    {
      "lang": "en",
      "text": "devices. Yeah. So for quen 3 we have",
      "offset": 318.28,
      "duration": 6.759
    },
    {
      "lang": "en",
      "text": "some important features and the most",
      "offset": 322.96,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "important features this time it is",
      "offset": 325.039,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "hybrid thinking mode. So what is hybrid",
      "offset": 327.12,
      "duration": 6.16
    },
    {
      "lang": "en",
      "text": "thinking mode? Hybrid thinking mode",
      "offset": 331.039,
      "duration": 5.241
    },
    {
      "lang": "en",
      "text": "means that you can use thinking and",
      "offset": 333.28,
      "duration": 5.919
    },
    {
      "lang": "en",
      "text": "non-thinking in a single model. We",
      "offset": 336.28,
      "duration": 6.6
    },
    {
      "lang": "en",
      "text": "combine the two behaviors into a model.",
      "offset": 339.199,
      "duration": 6.641
    },
    {
      "lang": "en",
      "text": "What is thinking mode? Uh thinking is",
      "offset": 342.88,
      "duration": 6.64
    },
    {
      "lang": "en",
      "text": "like uh before you answer the question",
      "offset": 345.84,
      "duration": 6.88
    },
    {
      "lang": "en",
      "text": "uh with an an uh detailed answer. You",
      "offset": 349.52,
      "duration": 6.08
    },
    {
      "lang": "en",
      "text": "just start thinking. You just reflect on",
      "offset": 352.72,
      "duration": 6.16
    },
    {
      "lang": "en",
      "text": "yourself, explore possibilities. Finally",
      "offset": 355.6,
      "duration": 4.879
    },
    {
      "lang": "en",
      "text": "you find that well you are ready to",
      "offset": 358.88,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "answer the question so you provide the",
      "offset": 360.479,
      "duration": 6.641
    },
    {
      "lang": "en",
      "text": "answer. So uh like 01 and deep R1 they",
      "offset": 362.8,
      "duration": 6.88
    },
    {
      "lang": "en",
      "text": "have the thinking behavior. Yeah. And",
      "offset": 367.12,
      "duration": 4.639
    },
    {
      "lang": "en",
      "text": "for non-thinking mode it is just a",
      "offset": 369.68,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "traditional uh instruction tune model.",
      "offset": 371.759,
      "duration": 5.041
    },
    {
      "lang": "en",
      "text": "It's just like a chatbot without",
      "offset": 374.72,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "thinking without lagging. It is just",
      "offset": 376.8,
      "duration": 6.6
    },
    {
      "lang": "en",
      "text": "provide the answer. It is near instant.",
      "offset": 379.68,
      "duration": 6.079
    },
    {
      "lang": "en",
      "text": "But this might be the first time in the",
      "offset": 383.4,
      "duration": 4.6
    },
    {
      "lang": "en",
      "text": "open source community that we combine",
      "offset": 385.759,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "the two modes uh into a single model. So",
      "offset": 388,
      "duration": 5.039
    },
    {
      "lang": "en",
      "text": "you can use prompts or hyperparameters",
      "offset": 390.08,
      "duration": 5.92
    },
    {
      "lang": "en",
      "text": "to control its behaviors as you like.",
      "offset": 393.039,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "And once we dive into the hybrid",
      "offset": 396,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "thinking modes, we find that we can",
      "offset": 398.479,
      "duration": 5.201
    },
    {
      "lang": "en",
      "text": "create a feature of dynamic thinking",
      "offset": 401.28,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "budget. So what is dynamic thinking",
      "offset": 403.68,
      "duration": 4.639
    },
    {
      "lang": "en",
      "text": "budgets? For thinking budgets, which",
      "offset": 406.08,
      "duration": 5.559
    },
    {
      "lang": "en",
      "text": "means the maximum thinking tokens. For",
      "offset": 408.319,
      "duration": 7.32
    },
    {
      "lang": "en",
      "text": "example, if you have 32,000 tokens for",
      "offset": 411.639,
      "duration": 9.801
    },
    {
      "lang": "en",
      "text": "your thinking budget. So, uh for a task",
      "offset": 415.639,
      "duration": 8.521
    },
    {
      "lang": "en",
      "text": "which requires thinking, for example, if",
      "offset": 421.44,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "you finish the thinking with like 8,000",
      "offset": 424.16,
      "duration": 8
    },
    {
      "lang": "en",
      "text": "tokens, it is um below 32,000. Okay,",
      "offset": 427.44,
      "duration": 6.64
    },
    {
      "lang": "en",
      "text": "fine. You finish thinking, provide the",
      "offset": 432.16,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "answer. Is it good? But if you only have",
      "offset": 434.08,
      "duration": 6.28
    },
    {
      "lang": "en",
      "text": "a thinking budget of 4,000",
      "offset": 437.44,
      "duration": 7.52
    },
    {
      "lang": "en",
      "text": "tokens, so um uh if if your thinking",
      "offset": 440.36,
      "duration": 7.239
    },
    {
      "lang": "en",
      "text": "requires more than 4,000 tokens, like",
      "offset": 444.96,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "you requires 8,000 tokens to finish your",
      "offset": 447.599,
      "duration": 5.121
    },
    {
      "lang": "en",
      "text": "thinking, but you only have a budget of",
      "offset": 450.08,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "4,000 tokens. So you will stop at 4,000",
      "offset": 452.72,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "tokens, which means that your thinking",
      "offset": 456.08,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "process is truncated. So uh we can check",
      "offset": 457.84,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "the performance with uh larger and",
      "offset": 461.36,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "larger thinking budgets and you'll find",
      "offset": 463.28,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "that well the performance increase quite",
      "offset": 465.12,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "well with the increase of thinking",
      "offset": 468,
      "duration": 4.639
    },
    {
      "lang": "en",
      "text": "budgets and uh with a very small",
      "offset": 470.08,
      "duration": 6.32
    },
    {
      "lang": "en",
      "text": "thinking budget uh for example in AM 24",
      "offset": 472.639,
      "duration": 6.96
    },
    {
      "lang": "en",
      "text": "it only achieves just over 40 but if you",
      "offset": 476.4,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "have a large thinking budget like 32,000",
      "offset": 479.599,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "tokens you can even achieve more than",
      "offset": 482.08,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "80. It is really really amazing with the",
      "offset": 484.319,
      "duration": 6.16
    },
    {
      "lang": "en",
      "text": "thinking capabilities. So uh I hope you",
      "offset": 486.72,
      "duration": 6.64
    },
    {
      "lang": "en",
      "text": "enjoy the hybrid thinking mode. You you",
      "offset": 490.479,
      "duration": 4.961
    },
    {
      "lang": "en",
      "text": "only single model to achieve thinking",
      "offset": 493.36,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "and non non-thinking and you'll find",
      "offset": 495.44,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "something uh good for you. For example",
      "offset": 498.16,
      "duration": 6.719
    },
    {
      "lang": "en",
      "text": "uh in your task you require only like 95",
      "offset": 501.44,
      "duration": 6.879
    },
    {
      "lang": "en",
      "text": "uh uh% accuracy and you will find that",
      "offset": 504.879,
      "duration": 5.16
    },
    {
      "lang": "en",
      "text": "well uh for",
      "offset": 508.319,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "example you use only 8,000 tokens for",
      "offset": 510.039,
      "duration": 5.641
    },
    {
      "lang": "en",
      "text": "your thinking budget you can achieve",
      "offset": 513.279,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "over 95%. So that is quite well. You",
      "offset": 515.68,
      "duration": 4.799
    },
    {
      "lang": "en",
      "text": "don't need to waste more tokens on your",
      "offset": 518.479,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "thinking. So you don't can keep your",
      "offset": 520.479,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "thinking budgets with 8,000 tokens. This",
      "offset": 522.399,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "is only an example. We would like to",
      "offset": 524.56,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "explore the usages. Yeah. The next",
      "offset": 526.8,
      "duration": 5.599
    },
    {
      "lang": "en",
      "text": "important features is that Quen 3",
      "offset": 529.6,
      "duration": 6.12
    },
    {
      "lang": "en",
      "text": "supports over",
      "offset": 532.399,
      "duration": 7.841
    },
    {
      "lang": "en",
      "text": "119 languages and dialects. In Quen 2.5,",
      "offset": 535.72,
      "duration": 7.799
    },
    {
      "lang": "en",
      "text": "it only supports 29 languages, but this",
      "offset": 540.24,
      "duration": 6.12
    },
    {
      "lang": "en",
      "text": "time we support over",
      "offset": 543.519,
      "duration": 6.561
    },
    {
      "lang": "en",
      "text": "119 languages and dialects. We have uh",
      "offset": 546.36,
      "duration": 6.919
    },
    {
      "lang": "en",
      "text": "detail uh names of uh the languages and",
      "offset": 550.08,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "dialects that we support. You can check",
      "offset": 553.279,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "it. I think it will be really good for",
      "offset": 555.44,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "global applications and there are a lot",
      "offset": 557.519,
      "duration": 5.361
    },
    {
      "lang": "en",
      "text": "of people uh previously uh especially if",
      "offset": 559.76,
      "duration": 5.759
    },
    {
      "lang": "en",
      "text": "they are you using open web model. the",
      "offset": 562.88,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "open way models don't support many",
      "offset": 565.519,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "languages quite well. So there will be",
      "offset": 567.36,
      "duration": 6.72
    },
    {
      "lang": "en",
      "text": "more people that are capable of using uh",
      "offset": 569.279,
      "duration": 7.281
    },
    {
      "lang": "en",
      "text": "large language models in in the domains",
      "offset": 574.08,
      "duration": 5.439
    },
    {
      "lang": "en",
      "text": "and in the languages. Yeah.",
      "offset": 576.56,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "And we have spe uh specifically",
      "offset": 579.519,
      "duration": 4.961
    },
    {
      "lang": "en",
      "text": "increased the capabilities uh in uh",
      "offset": 581.76,
      "duration": 5.199
    },
    {
      "lang": "en",
      "text": "agents and codings and especially we",
      "offset": 584.48,
      "duration": 5.359
    },
    {
      "lang": "en",
      "text": "enhanced the support uh for MCP which is",
      "offset": 586.959,
      "duration": 5.681
    },
    {
      "lang": "en",
      "text": "really po popular uh very recently and",
      "offset": 589.839,
      "duration": 6.481
    },
    {
      "lang": "en",
      "text": "and these are two examples to show that",
      "offset": 592.64,
      "duration": 8.12
    },
    {
      "lang": "en",
      "text": "uh our models how to use tools during",
      "offset": 596.32,
      "duration": 7.519
    },
    {
      "lang": "en",
      "text": "thinkings. who will find that uh it can",
      "offset": 600.76,
      "duration": 6.68
    },
    {
      "lang": "en",
      "text": "think while it uh it is using a function",
      "offset": 603.839,
      "duration": 5.761
    },
    {
      "lang": "en",
      "text": "calls to use the tools and it gets the",
      "offset": 607.44,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "feedbacks from the environment and it",
      "offset": 609.6,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "keeps thinking. So that would be a",
      "offset": 611.44,
      "duration": 6.079
    },
    {
      "lang": "en",
      "text": "feature that we really prefer which is",
      "offset": 614.48,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "the model is capable of thinking but it",
      "offset": 617.519,
      "duration": 5.281
    },
    {
      "lang": "en",
      "text": "is also capable of interacting with the",
      "offset": 620.24,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "environment and it keeps thinking. It is",
      "offset": 622.8,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "really good for like uh inference time",
      "offset": 624.8,
      "duration": 4.719
    },
    {
      "lang": "en",
      "text": "scaling. And this is another example for",
      "offset": 627.2,
      "duration": 5.759
    },
    {
      "lang": "en",
      "text": "the model to organize the desktop. So uh",
      "offset": 629.519,
      "duration": 6.241
    },
    {
      "lang": "en",
      "text": "if it has the access to the file system,",
      "offset": 632.959,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "it can do things like that. It thinks uh",
      "offset": 635.76,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "which tools should it use and then it",
      "offset": 638.959,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "use the tools and gets the feedback and",
      "offset": 640.88,
      "duration": 5.519
    },
    {
      "lang": "en",
      "text": "continues thinking while uh it finish",
      "offset": 642.88,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "the you using the tools and it finished",
      "offset": 646.399,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "the task and tell you that well you we",
      "offset": 648.64,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "have organized the de desktop quite",
      "offset": 650.959,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "well. And these are two very simple uh",
      "offset": 653.2,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "examples to show that uh we have",
      "offset": 656.079,
      "duration": 4.961
    },
    {
      "lang": "en",
      "text": "provided better and better support for",
      "offset": 658.48,
      "duration": 5.599
    },
    {
      "lang": "en",
      "text": "uh agent capabilities. And we not only",
      "offset": 661.04,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "would like our models to be a simple",
      "offset": 664.079,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "chatbot, we would like it to be really",
      "offset": 666,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "productive in our working life to become",
      "offset": 668,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "a really really productive agent. Yeah.",
      "offset": 670.32,
      "duration": 7.48
    },
    {
      "lang": "en",
      "text": "And uh these are three features of",
      "offset": 673.44,
      "duration": 8.48
    },
    {
      "lang": "en",
      "text": "um three. Yeah. Uh we have open weighted",
      "offset": 677.8,
      "duration": 7.479
    },
    {
      "lang": "en",
      "text": "uh a lot of sizes um including twoe",
      "offset": 681.92,
      "duration": 6.479
    },
    {
      "lang": "en",
      "text": "models. uh a small model has a total",
      "offset": 685.279,
      "duration": 6.961
    },
    {
      "lang": "en",
      "text": "number of 30 billion and only activates",
      "offset": 688.399,
      "duration": 7.361
    },
    {
      "lang": "en",
      "text": "three billion but uh another one is 235",
      "offset": 692.24,
      "duration": 8.08
    },
    {
      "lang": "en",
      "text": "billion activates um 20 20 uh 22 billion",
      "offset": 695.76,
      "duration": 7.6
    },
    {
      "lang": "en",
      "text": "parameter models. Yeah, we also have six",
      "offset": 700.32,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "dense models and for smaller models you",
      "offset": 703.36,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "can use it for testing and you can",
      "offset": 705.76,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "support draft models but for four",
      "offset": 707.2,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "billion parameter model models you can",
      "offset": 709.12,
      "duration": 4.719
    },
    {
      "lang": "en",
      "text": "deploy it uh on mobile devices and for",
      "offset": 710.88,
      "duration": 5.92
    },
    {
      "lang": "en",
      "text": "32 billion parameter models that these",
      "offset": 713.839,
      "duration": 5.601
    },
    {
      "lang": "en",
      "text": "are models that uh you really prefer and",
      "offset": 716.8,
      "duration": 5.039
    },
    {
      "lang": "en",
      "text": "especially 32 billion parameter model it",
      "offset": 719.44,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "is strong uh this shows competitiveness",
      "offset": 721.839,
      "duration": 5.521
    },
    {
      "lang": "en",
      "text": "and you can use it for doing doing RL",
      "offset": 724.8,
      "duration": 5.839
    },
    {
      "lang": "en",
      "text": "you can deploy it uh uh in in your lo",
      "offset": 727.36,
      "duration": 5.279
    },
    {
      "lang": "en",
      "text": "local environ environment as well. So we",
      "offset": 730.639,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "also open weighted um uh desk models as",
      "offset": 732.639,
      "duration": 6.161
    },
    {
      "lang": "en",
      "text": "well. But we believe that in this year",
      "offset": 736.079,
      "duration": 5.601
    },
    {
      "lang": "en",
      "text": "maybe in the next years the future trend",
      "offset": 738.8,
      "duration": 6.32
    },
    {
      "lang": "en",
      "text": "is belonging to the MOE models. So later",
      "offset": 741.68,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "we will release more models for you to",
      "offset": 745.12,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "use and there will be better support in",
      "offset": 747.68,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "the open source community like thirdarty",
      "offset": 749.92,
      "duration": 5.84
    },
    {
      "lang": "en",
      "text": "frameworks for the models as well. Yeah",
      "offset": 752.16,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "besides building large language models",
      "offset": 755.76,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "we are also building multimodel models.",
      "offset": 757.68,
      "duration": 5.599
    },
    {
      "lang": "en",
      "text": "We have focused quite a lot on vision",
      "offset": 760.56,
      "duration": 6.079
    },
    {
      "lang": "en",
      "text": "language models and uh I think uh many",
      "offset": 763.279,
      "duration": 5.841
    },
    {
      "lang": "en",
      "text": "of you maybe are using quenu and now",
      "offset": 766.639,
      "duration": 6.161
    },
    {
      "lang": "en",
      "text": "using quen 2.5 VL which was released uh",
      "offset": 769.12,
      "duration": 6.48
    },
    {
      "lang": "en",
      "text": "this year in January. Uh it achieves a",
      "offset": 772.8,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "very competitive performance uh in uh",
      "offset": 775.6,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "vision language uh benchmarks uh like",
      "offset": 777.92,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "understanding benchmarks like MMU and",
      "offset": 780.24,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "also math benchmark like math vista and",
      "offset": 782.72,
      "duration": 5.84
    },
    {
      "lang": "en",
      "text": "also general uh a lot of general VQ VQA",
      "offset": 785.12,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "benchmarks. So achieved very good",
      "offset": 788.56,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "performance in the uh benchmarks for uh",
      "offset": 790.48,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "vision language understanding. Um we",
      "offset": 793.04,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "also explore the capabilities of",
      "offset": 796,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "thinking for vision language model. So",
      "offset": 798.16,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "we have uh built QVQ as well and we find",
      "offset": 800.079,
      "duration": 6.32
    },
    {
      "lang": "en",
      "text": "inverse time scaling with larger maximum",
      "offset": 803.04,
      "duration": 6.799
    },
    {
      "lang": "en",
      "text": "thinking length which is equivalent to",
      "offset": 806.399,
      "duration": 5.841
    },
    {
      "lang": "en",
      "text": "the thinking budget that I talked",
      "offset": 809.839,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "before. So if you have a larger thinking",
      "offset": 812.24,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "budget it will achieve better and better",
      "offset": 814.959,
      "duration": 5.041
    },
    {
      "lang": "en",
      "text": "performance uh in reasoning task",
      "offset": 817.44,
      "duration": 6.32
    },
    {
      "lang": "en",
      "text": "especially u uh like mathematics uh even",
      "offset": 820,
      "duration": 6.56
    },
    {
      "lang": "en",
      "text": "for vision language models it shows uh",
      "offset": 823.76,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "similar features as well. Um but for",
      "offset": 826.56,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "multimodel models we what we really",
      "offset": 829.04,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "would like to do is to build an omni",
      "offset": 831.6,
      "duration": 5.359
    },
    {
      "lang": "en",
      "text": "model which accepts multimodalities",
      "offset": 833.92,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "uh for the inputs and also it is capable",
      "offset": 836.959,
      "duration": 5.521
    },
    {
      "lang": "en",
      "text": "of generating multiple modalities uh",
      "offset": 839.68,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "like text vision and audios but this",
      "offset": 842.48,
      "duration": 6.4
    },
    {
      "lang": "en",
      "text": "time um this is not the a perfect state",
      "offset": 845.04,
      "duration": 6.56
    },
    {
      "lang": "en",
      "text": "but I think it's good it's a relatively",
      "offset": 848.88,
      "duration": 4.959
    },
    {
      "lang": "en",
      "text": "a small model but we are really proud of",
      "offset": 851.6,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "this attempt it's a 7 billion large",
      "offset": 853.839,
      "duration": 5.041
    },
    {
      "lang": "en",
      "text": "language model it's based on it. But it",
      "offset": 856.72,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "is capable of accepting three modalities",
      "offset": 858.88,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "including text, vision. Vision includes",
      "offset": 861.36,
      "duration": 6.64
    },
    {
      "lang": "en",
      "text": "uh images and videos and also uh it can",
      "offset": 864.48,
      "duration": 6.96
    },
    {
      "lang": "en",
      "text": "accept uh a audio and this time it can",
      "offset": 868,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "generate text and audio. Maybe in the",
      "offset": 871.44,
      "duration": 4.639
    },
    {
      "lang": "en",
      "text": "future our models might be capable of",
      "offset": 873.12,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "generating images, high quality images",
      "offset": 876.079,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "and videos that will be a truly omni",
      "offset": 878.48,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "models. Now for this omni model it is it",
      "offset": 881.199,
      "duration": 5.361
    },
    {
      "lang": "en",
      "text": "can be used in uh voice chat and video",
      "offset": 884.24,
      "duration": 5.599
    },
    {
      "lang": "en",
      "text": "chat and text chat as well. Um it",
      "offset": 886.56,
      "duration": 5.92
    },
    {
      "lang": "en",
      "text": "achieves state performance uh in audio",
      "offset": 889.839,
      "duration": 4.881
    },
    {
      "lang": "en",
      "text": "tasks uh for for for the same size",
      "offset": 892.48,
      "duration": 5.359
    },
    {
      "lang": "en",
      "text": "models like 7 billion parameter models.",
      "offset": 894.72,
      "duration": 6.559
    },
    {
      "lang": "en",
      "text": "uh but what surprised us a little bit is",
      "offset": 897.839,
      "duration": 6.641
    },
    {
      "lang": "en",
      "text": "that uh it can even achieve better",
      "offset": 901.279,
      "duration": 4.481
    },
    {
      "lang": "en",
      "text": "performance in vision language",
      "offset": 904.48,
      "duration": 2.96
    },
    {
      "lang": "en",
      "text": "understanding house in comparison with",
      "offset": 905.76,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "quen 2.5 VL 7 billion which means that",
      "offset": 907.44,
      "duration": 7.04
    },
    {
      "lang": "en",
      "text": "um we can achieve very good performance",
      "offset": 911.44,
      "duration": 5.519
    },
    {
      "lang": "en",
      "text": "for an omni model in vision language",
      "offset": 914.48,
      "duration": 5.919
    },
    {
      "lang": "en",
      "text": "tasks but uh a little bit that we had",
      "offset": 916.959,
      "duration": 6.801
    },
    {
      "lang": "en",
      "text": "not done well but we believe we can done",
      "offset": 920.399,
      "duration": 6.161
    },
    {
      "lang": "en",
      "text": "we can do well is that uh we should",
      "offset": 923.76,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "recover the performance drop in language",
      "offset": 926.56,
      "duration": 6.16
    },
    {
      "lang": "en",
      "text": "task uh especially for its intelligence",
      "offset": 929.36,
      "duration": 6.159
    },
    {
      "lang": "en",
      "text": "uh especially for its uh agent task. I",
      "offset": 932.72,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "think we can recover it uh uh by",
      "offset": 935.519,
      "duration": 4.721
    },
    {
      "lang": "en",
      "text": "improving our data quality, improving",
      "offset": 938.24,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "our training training methods. But now",
      "offset": 940.24,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "um there are still some room for",
      "offset": 942.8,
      "duration": 4.719
    },
    {
      "lang": "en",
      "text": "improving uh uh the model capabilities",
      "offset": 944.48,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "in different domains and different",
      "offset": 947.519,
      "duration": 4.961
    },
    {
      "lang": "en",
      "text": "tasks. Uh and this is the uh omni models",
      "offset": 949.04,
      "duration": 6.159
    },
    {
      "lang": "en",
      "text": "and no matter what models we keep open",
      "offset": 952.48,
      "duration": 5.039
    },
    {
      "lang": "en",
      "text": "sourcing. We love open sourcing because",
      "offset": 955.199,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "open sourcing really helps us quite a",
      "offset": 957.519,
      "duration": 6.641
    },
    {
      "lang": "en",
      "text": "lot. Um by uh the developers can give us",
      "offset": 959.519,
      "duration": 7.201
    },
    {
      "lang": "en",
      "text": "some feedbacks to help us uh improve our",
      "offset": 964.16,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "models. the interaction with the C uh",
      "offset": 966.72,
      "duration": 5.039
    },
    {
      "lang": "en",
      "text": "open source community uh makes us happy",
      "offset": 969.68,
      "duration": 6.159
    },
    {
      "lang": "en",
      "text": "and makes us um we have more we are more",
      "offset": 971.759,
      "duration": 7.041
    },
    {
      "lang": "en",
      "text": "encouraged to build more good models to",
      "offset": 975.839,
      "duration": 5.281
    },
    {
      "lang": "en",
      "text": "for for all of you. Yeah, we have a lot",
      "offset": 978.8,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "of titled models uh in the open source",
      "offset": 981.12,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "communities including LLMs and also",
      "offset": 983.68,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "coders and quento.5 coders uh is",
      "offset": 985.92,
      "duration": 6.24
    },
    {
      "lang": "en",
      "text": "something that uh many people are using",
      "offset": 988.8,
      "duration": 6.88
    },
    {
      "lang": "en",
      "text": "for local development and something that",
      "offset": 992.16,
      "duration": 6.16
    },
    {
      "lang": "en",
      "text": "I can tell you that we are now building",
      "offset": 995.68,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "quen three coders. I think you guys know",
      "offset": 998.32,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "about it. Yeah. Um we have many model",
      "offset": 1000.24,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "sizes because we we just believe that",
      "offset": 1003.44,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "for each size there might be a lot of",
      "offset": 1006,
      "duration": 4.639
    },
    {
      "lang": "en",
      "text": "users and actually there are there are a",
      "offset": 1008.24,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "lot of users no matter very very small",
      "offset": 1010.639,
      "duration": 4.241
    },
    {
      "lang": "en",
      "text": "models like 0.6 6 billion parameter",
      "offset": 1012.56,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "models and there are a large models",
      "offset": 1014.88,
      "duration": 4.959
    },
    {
      "lang": "en",
      "text": "previously 72 billion dense models and",
      "offset": 1016.88,
      "duration": 6.56
    },
    {
      "lang": "en",
      "text": "now 235 billion models. There are a lot",
      "offset": 1019.839,
      "duration": 5.84
    },
    {
      "lang": "en",
      "text": "of users using it and they need",
      "offset": 1023.44,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "quantized models. So we've just provide",
      "offset": 1025.679,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "quantized models in different formats",
      "offset": 1028,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "including GUM, GBQ, AWQ and MOX for",
      "offset": 1029.6,
      "duration": 7.479
    },
    {
      "lang": "en",
      "text": "Apple as well. We try to use Apache 2.0",
      "offset": 1033.28,
      "duration": 7.279
    },
    {
      "lang": "en",
      "text": "for most models. So you can just use it",
      "offset": 1037.079,
      "duration": 6.681
    },
    {
      "lang": "en",
      "text": "freely. you can change the models freely",
      "offset": 1040.559,
      "duration": 4.801
    },
    {
      "lang": "en",
      "text": "uh in your business. You don't need to",
      "offset": 1043.76,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "worry about too many things. You don't",
      "offset": 1045.36,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "need to access uh for the permission.",
      "offset": 1047.12,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "You just directly use it. We hope that",
      "offset": 1049.52,
      "duration": 3.519
    },
    {
      "lang": "en",
      "text": "large language models and large",
      "offset": 1051.84,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "multimodel models or foundation models",
      "offset": 1053.039,
      "duration": 6.64
    },
    {
      "lang": "en",
      "text": "can help you create good applications",
      "offset": 1056.08,
      "duration": 6.959
    },
    {
      "lang": "en",
      "text": "and this is what we like to do and uh as",
      "offset": 1059.679,
      "duration": 5.441
    },
    {
      "lang": "en",
      "text": "we are becoming popular and popular",
      "offset": 1063.039,
      "duration": 4.721
    },
    {
      "lang": "en",
      "text": "during these two years. So for quen",
      "offset": 1065.12,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "models uh it should be supported by a",
      "offset": 1067.76,
      "duration": 6.48
    },
    {
      "lang": "en",
      "text": "lot of maybe most uh rel uh rel relative",
      "offset": 1070.32,
      "duration": 6.479
    },
    {
      "lang": "en",
      "text": "third party frameworks and API platforms",
      "offset": 1074.24,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "as well. Yeah and we are also building",
      "offset": 1076.799,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "products we are also building products",
      "offset": 1079.84,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "for for you to interact with our models.",
      "offset": 1081.919,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "We are building agents as well and in",
      "offset": 1084.32,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "our quad just as I uh mentioned before",
      "offset": 1086.799,
      "duration": 5.601
    },
    {
      "lang": "en",
      "text": "we have some uh very good features. This",
      "offset": 1089.44,
      "duration": 4.479
    },
    {
      "lang": "en",
      "text": "is something that I really like which is",
      "offset": 1092.4,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "called web deck. Um, by entering webdev,",
      "offset": 1093.919,
      "duration": 7.841
    },
    {
      "lang": "en",
      "text": "you just need to insert or input a very",
      "offset": 1097.6,
      "duration": 7.36
    },
    {
      "lang": "en",
      "text": "simple prompt. Uh, things like create a",
      "offset": 1101.76,
      "duration": 6.159
    },
    {
      "lang": "en",
      "text": "Twitter website and we'll find that it",
      "offset": 1104.96,
      "duration": 7.12
    },
    {
      "lang": "en",
      "text": "just generates a code uh and then uh",
      "offset": 1107.919,
      "duration": 6.321
    },
    {
      "lang": "en",
      "text": "some effects like artifacts. So you you",
      "offset": 1112.08,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "have a website um to to see how how it",
      "offset": 1114.24,
      "duration": 5.84
    },
    {
      "lang": "en",
      "text": "is shown and you can also deploy as",
      "offset": 1117.76,
      "duration": 5.039
    },
    {
      "lang": "en",
      "text": "well. You can deploy it and get the URL,",
      "offset": 1120.08,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "share it to your friends to show that",
      "offset": 1122.799,
      "duration": 3.521
    },
    {
      "lang": "en",
      "text": "how creative you are. You can also",
      "offset": 1124.32,
      "duration": 5.359
    },
    {
      "lang": "en",
      "text": "create a website uh for your product.",
      "offset": 1126.32,
      "duration": 5.92
    },
    {
      "lang": "en",
      "text": "For example, this is a very simple",
      "offset": 1129.679,
      "duration": 5.041
    },
    {
      "lang": "en",
      "text": "prompt. Create a sunscreen product",
      "offset": 1132.24,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "introduction website and you have a very",
      "offset": 1134.72,
      "duration": 4.959
    },
    {
      "lang": "en",
      "text": "good website. You can even click on the",
      "offset": 1137.44,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "buttons as well. And for making a card",
      "offset": 1139.679,
      "duration": 6.321
    },
    {
      "lang": "en",
      "text": "uh not not just making a website just by",
      "offset": 1143.2,
      "duration": 7.2
    },
    {
      "lang": "en",
      "text": "making a card. Well, it it generates a",
      "offset": 1146,
      "duration": 7.36
    },
    {
      "lang": "en",
      "text": "card. I I really like the card. We we",
      "offset": 1150.4,
      "duration": 5.84
    },
    {
      "lang": "en",
      "text": "often use the card in our Twitter. So,",
      "offset": 1153.36,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "uh our promise is also simple. We give",
      "offset": 1156.24,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "it a link. So, based on the link, you",
      "offset": 1158.4,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "just create a nice looking card and we",
      "offset": 1160.559,
      "duration": 5.041
    },
    {
      "lang": "en",
      "text": "provide more information to you. You",
      "offset": 1163.6,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "just based on the information and build",
      "offset": 1165.6,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "a card for for us. Yeah. Um this is",
      "offset": 1167.12,
      "duration": 6.32
    },
    {
      "lang": "en",
      "text": "something I really really like webdev uh",
      "offset": 1170.4,
      "duration": 6.88
    },
    {
      "lang": "en",
      "text": "uh makes me more creative and helps me",
      "offset": 1173.44,
      "duration": 7.52
    },
    {
      "lang": "en",
      "text": "quite a lot to show our things to all to",
      "offset": 1177.28,
      "duration": 6.16
    },
    {
      "lang": "en",
      "text": "to people all over the world. Yeah, we",
      "offset": 1180.96,
      "duration": 4.719
    },
    {
      "lang": "en",
      "text": "also have things like deep research uh",
      "offset": 1183.44,
      "duration": 5.359
    },
    {
      "lang": "en",
      "text": "by doing deep research um you just need",
      "offset": 1185.679,
      "duration": 6.641
    },
    {
      "lang": "en",
      "text": "to ask something to write a report uh in",
      "offset": 1188.799,
      "duration": 6.481
    },
    {
      "lang": "en",
      "text": "what you are interested in. Yeah, maybe",
      "offset": 1192.32,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "like healthcare industry, maybe like",
      "offset": 1195.28,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "artificial intelligence. Just ask it.",
      "offset": 1197.6,
      "duration": 5.72
    },
    {
      "lang": "en",
      "text": "Give it a prompt and it will ask you",
      "offset": 1200.08,
      "duration": 6.24
    },
    {
      "lang": "en",
      "text": "what you are going to focus on. You can",
      "offset": 1203.32,
      "duration": 5.88
    },
    {
      "lang": "en",
      "text": "tell it and you or or you can just say",
      "offset": 1206.32,
      "duration": 5.84
    },
    {
      "lang": "en",
      "text": "as you like and it will start doing",
      "offset": 1209.2,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "research by making a plan first and then",
      "offset": 1212.16,
      "duration": 6.08
    },
    {
      "lang": "en",
      "text": "doing the search step by step, writing",
      "offset": 1215.2,
      "duration": 6.76
    },
    {
      "lang": "en",
      "text": "parts step by step. Yeah.",
      "offset": 1218.24,
      "duration": 5.799
    },
    {
      "lang": "en",
      "text": "and keep",
      "offset": 1221.96,
      "duration": 4.719
    },
    {
      "lang": "en",
      "text": "searching and finally gives a",
      "offset": 1224.039,
      "duration": 5.64
    },
    {
      "lang": "en",
      "text": "comprehensive report to all of you. You",
      "offset": 1226.679,
      "duration": 6.281
    },
    {
      "lang": "en",
      "text": "can download our report by a PDF. We are",
      "offset": 1229.679,
      "duration": 6.641
    },
    {
      "lang": "en",
      "text": "still improving uh its quality by uh",
      "offset": 1232.96,
      "duration": 5.839
    },
    {
      "lang": "en",
      "text": "doing reinforcement learning to build a",
      "offset": 1236.32,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "fine-tune model specifically for deep",
      "offset": 1238.799,
      "duration": 4.641
    },
    {
      "lang": "en",
      "text": "research and we believe that there's",
      "offset": 1241.36,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "still much room uh in this field. It is",
      "offset": 1243.44,
      "duration": 4.239
    },
    {
      "lang": "en",
      "text": "really hard to do reinforcement learning",
      "offset": 1245.52,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "uh for this talk but um once you have",
      "offset": 1247.679,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "built a good model for uh for this",
      "offset": 1250.32,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "product it will be really productive for",
      "offset": 1252.559,
      "duration": 5.441
    },
    {
      "lang": "en",
      "text": "people uh in their working life. Yeah.",
      "offset": 1254.48,
      "duration": 7.36
    },
    {
      "lang": "en",
      "text": "So in the future we will do many things",
      "offset": 1258,
      "duration": 5.679
    },
    {
      "lang": "en",
      "text": "uh there are still a lot of things for",
      "offset": 1261.84,
      "duration": 4.719
    },
    {
      "lang": "en",
      "text": "us to do to achieve AGI to build a",
      "offset": 1263.679,
      "duration": 4.841
    },
    {
      "lang": "en",
      "text": "really good foundation model and",
      "offset": 1266.559,
      "duration": 6.401
    },
    {
      "lang": "en",
      "text": "foundation agent for all of you. And the",
      "offset": 1268.52,
      "duration": 7.08
    },
    {
      "lang": "en",
      "text": "first thing is that uh something really",
      "offset": 1272.96,
      "duration": 4.959
    },
    {
      "lang": "en",
      "text": "different from what other people think.",
      "offset": 1275.6,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "We still believe that there is still",
      "offset": 1277.919,
      "duration": 4.961
    },
    {
      "lang": "en",
      "text": "much room in training. Um I'm happy that",
      "offset": 1279.28,
      "duration": 6.16
    },
    {
      "lang": "en",
      "text": "you uh you have shown your preference uh",
      "offset": 1282.88,
      "duration": 5.679
    },
    {
      "lang": "en",
      "text": "in our uh pre-training models. Uh but we",
      "offset": 1285.44,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "still find that there are still a lot of",
      "offset": 1288.559,
      "duration": 4.561
    },
    {
      "lang": "en",
      "text": "good data we did not put into it. Uh",
      "offset": 1290.48,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "there are still a lot of data we did not",
      "offset": 1293.12,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "clean it quite well. And we find that we",
      "offset": 1294.96,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "can use multimodel data and to make the",
      "offset": 1297.36,
      "duration": 7.679
    },
    {
      "lang": "en",
      "text": "models more uh capable uh in doing",
      "offset": 1300.08,
      "duration": 6.479
    },
    {
      "lang": "en",
      "text": "different tasks in different domains.",
      "offset": 1305.039,
      "duration": 4.281
    },
    {
      "lang": "en",
      "text": "And we also have synthetic datas and",
      "offset": 1306.559,
      "duration": 6.24
    },
    {
      "lang": "en",
      "text": "maybe we'll finally do something really",
      "offset": 1309.32,
      "duration": 5.719
    },
    {
      "lang": "en",
      "text": "really different training methods for",
      "offset": 1312.799,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "pre-training not just like next token",
      "offset": 1315.039,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "prediction. Maybe later we use",
      "offset": 1316.96,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "reinforcement learning in pre-raining as",
      "offset": 1318.88,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "well. And so there is still much room uh",
      "offset": 1320.799,
      "duration": 5.601
    },
    {
      "lang": "en",
      "text": "in pre-training to build a very good",
      "offset": 1324,
      "duration": 6.88
    },
    {
      "lang": "en",
      "text": "basis for the uh chatbot or agents. And",
      "offset": 1326.4,
      "duration": 6.56
    },
    {
      "lang": "en",
      "text": "this is the first thing and the second",
      "offset": 1330.88,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "thing is that uh the scaling laws uh",
      "offset": 1332.96,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "there are some changes in scaling law.",
      "offset": 1336.48,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "Previously we're scaling uh in the model",
      "offset": 1338.48,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "sizes in the pre-training data but now",
      "offset": 1341.28,
      "duration": 4.639
    },
    {
      "lang": "en",
      "text": "we need to scale the compute uh in",
      "offset": 1343.84,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "reinforcement learning and we have a",
      "offset": 1345.919,
      "duration": 5.201
    },
    {
      "lang": "en",
      "text": "focus on long horizon reasoning uh with",
      "offset": 1348,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "the environment feedback. So uh if you",
      "offset": 1351.12,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "train model which is capable of",
      "offset": 1353.6,
      "duration": 4.6
    },
    {
      "lang": "en",
      "text": "interacting with the environment keep",
      "offset": 1356.32,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "thinking this will be something really",
      "offset": 1358.2,
      "duration": 4.92
    },
    {
      "lang": "en",
      "text": "really uh competitive. So it will get",
      "offset": 1360.32,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "the feedback from the environment keeps",
      "offset": 1363.12,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "thinking it will become smarter and",
      "offset": 1365.12,
      "duration": 4.039
    },
    {
      "lang": "en",
      "text": "smarter with inference time scaling.",
      "offset": 1366.96,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "Yeah. So you'll find that it it will",
      "offset": 1369.159,
      "duration": 5.041
    },
    {
      "lang": "en",
      "text": "generate very very long",
      "offset": 1372.48,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "context and you'll have very long",
      "offset": 1374.2,
      "duration": 5.959
    },
    {
      "lang": "en",
      "text": "context for your input uh especially",
      "offset": 1377.6,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "when you have memory. So you need to",
      "offset": 1380.159,
      "duration": 5.201
    },
    {
      "lang": "en",
      "text": "scale your context. Maybe finally we are",
      "offset": 1382.08,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "moving towards infinite context but now",
      "offset": 1385.36,
      "duration": 4.559
    },
    {
      "lang": "en",
      "text": "we need to fix the problems of one",
      "offset": 1387.84,
      "duration": 4.959
    },
    {
      "lang": "en",
      "text": "million tokens uh quite well and then we",
      "offset": 1389.919,
      "duration": 4.801
    },
    {
      "lang": "en",
      "text": "are marching to 10 million tokens and",
      "offset": 1392.799,
      "duration": 4.721
    },
    {
      "lang": "en",
      "text": "then infinite context. So we are scaling",
      "offset": 1394.72,
      "duration": 4.959
    },
    {
      "lang": "en",
      "text": "context uh we're going to scale the",
      "offset": 1397.52,
      "duration": 5.08
    },
    {
      "lang": "en",
      "text": "context at least 1 million tokens this",
      "offset": 1399.679,
      "duration": 6.24
    },
    {
      "lang": "en",
      "text": "year for most of our models. Yeah, we're",
      "offset": 1402.6,
      "duration": 5.8
    },
    {
      "lang": "en",
      "text": "also going to scale modalities. Um may",
      "offset": 1405.919,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "maybe scaling on modalities doesn't",
      "offset": 1408.4,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "increase your intelligence but uh if you",
      "offset": 1410.159,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "scale on modalities you can make your",
      "offset": 1412.559,
      "duration": 5.841
    },
    {
      "lang": "en",
      "text": "models more capable and more productive.",
      "offset": 1414.799,
      "duration": 5.681
    },
    {
      "lang": "en",
      "text": "uh especially with the vision language",
      "offset": 1418.4,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "understanding you you if you have vision",
      "offset": 1420.48,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "language understanding capability you",
      "offset": 1423.2,
      "duration": 4.479
    },
    {
      "lang": "en",
      "text": "can make a like GUI agent but before",
      "offset": 1424.88,
      "duration": 5.679
    },
    {
      "lang": "en",
      "text": "that if you have no vision capability",
      "offset": 1427.679,
      "duration": 5.041
    },
    {
      "lang": "en",
      "text": "you can it is almost impossible for you",
      "offset": 1430.559,
      "duration": 5.201
    },
    {
      "lang": "en",
      "text": "to make a GUI agent and do things like",
      "offset": 1432.72,
      "duration": 7.04
    },
    {
      "lang": "en",
      "text": "uh uh computer use and um maybe there is",
      "offset": 1435.76,
      "duration": 6.84
    },
    {
      "lang": "en",
      "text": "still much room uh in uh scaling the",
      "offset": 1439.76,
      "duration": 6.08
    },
    {
      "lang": "en",
      "text": "modalities in either inputs and outputs",
      "offset": 1442.6,
      "duration": 5.24
    },
    {
      "lang": "en",
      "text": "uh we are going to unifying",
      "offset": 1445.84,
      "duration": 4.719
    },
    {
      "lang": "en",
      "text": "understanding and gener generation. For",
      "offset": 1447.84,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "example, for for the image understanding",
      "offset": 1450.559,
      "duration": 4.961
    },
    {
      "lang": "en",
      "text": "and image generation at the same time",
      "offset": 1452.32,
      "duration": 6.56
    },
    {
      "lang": "en",
      "text": "just like GPT4 they generate u very",
      "offset": 1455.52,
      "duration": 5.759
    },
    {
      "lang": "en",
      "text": "interesting uh and high quality uh",
      "offset": 1458.88,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "images that that is something what we",
      "offset": 1461.279,
      "duration": 4.801
    },
    {
      "lang": "en",
      "text": "are going to do as well. Yeah. Uh so",
      "offset": 1463.36,
      "duration": 4.76
    },
    {
      "lang": "en",
      "text": "based on the four things that I",
      "offset": 1466.08,
      "duration": 5.92
    },
    {
      "lang": "en",
      "text": "mentioned so if you would like me to",
      "offset": 1468.12,
      "duration": 6.2
    },
    {
      "lang": "en",
      "text": "summarize what we are going to do in",
      "offset": 1472,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "this year next year I think we are",
      "offset": 1474.32,
      "duration": 4.239
    },
    {
      "lang": "en",
      "text": "moving from the era of training models",
      "offset": 1476.4,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "to training agents we are actually",
      "offset": 1478.559,
      "duration": 5.441
    },
    {
      "lang": "en",
      "text": "training the agents uh not only with",
      "offset": 1480.96,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "scaling with pre training but also",
      "offset": 1484,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "skating with RL especially with the",
      "offset": 1486,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "environment we are actually training the",
      "offset": 1488.24,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "agents so uh I think we can say that we",
      "offset": 1490.08,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "are now staying in",
      "offset": 1493.2,
      "duration": 3.719
    },
    {
      "lang": "en",
      "text": "uh era of",
      "offset": 1494.96,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "agents. Yeah, that's all. Uh thank you",
      "offset": 1496.919,
      "duration": 5.401
    },
    {
      "lang": "en",
      "text": "very much uh for listening to my talk",
      "offset": 1499.6,
      "duration": 6.959
    },
    {
      "lang": "en",
      "text": "and if you are interested uh in quen uh",
      "offset": 1502.32,
      "duration": 8.52
    },
    {
      "lang": "en",
      "text": "shoot me an email and talk to me in X.",
      "offset": 1506.559,
      "duration": 8.641
    },
    {
      "lang": "en",
      "text": "Um yeah, thanks a lot.",
      "offset": 1510.84,
      "duration": 4.36
    }
  ],
  "cleanText": null,
  "dumpedAt": "2025-07-21T18:43:24.433Z"
}