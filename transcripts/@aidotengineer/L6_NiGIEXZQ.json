{
  "episodeId": "L6_NiGIEXZQ",
  "channelSlug": "@aidotengineer",
  "title": "Production software keeps breaking and it will only get worse â€” Anish Agarwal, Traversal.ai",
  "publishedAt": "2025-07-10T16:29:07.000Z",
  "rawLines": [
    {
      "lang": "en",
      "text": "[Music]",
      "offset": 1.72,
      "duration": 6.91
    },
    {
      "lang": "en",
      "text": "hi everyone. Thank you for uh coming to",
      "offset": 15.599,
      "duration": 4.801
    },
    {
      "lang": "en",
      "text": "our talk. Uh so he was kind enough to",
      "offset": 18.24,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "already introduce us. Um so I'm the CEO.",
      "offset": 20.4,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "Matthew was the first person who joined",
      "offset": 22.72,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "us. Uh if any difficult questions,",
      "offset": 24.24,
      "duration": 4.799
    },
    {
      "lang": "en",
      "text": "please direct it towards Matt. Um now if",
      "offset": 25.92,
      "duration": 5.119
    },
    {
      "lang": "en",
      "text": "you think about the three major",
      "offset": 29.039,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "categories of of software engineering at",
      "offset": 31.039,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "least as we see it there's three things",
      "offset": 32.559,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "that show up to me the system design",
      "offset": 34.239,
      "duration": 3.201
    },
    {
      "lang": "en",
      "text": "where you think about you know how do",
      "offset": 36.16,
      "duration": 2.719
    },
    {
      "lang": "en",
      "text": "you actually architect a system a lot of",
      "offset": 37.44,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "the the talks we saw in this uh track",
      "offset": 38.879,
      "duration": 4.721
    },
    {
      "lang": "en",
      "text": "have been about that in some sense at a",
      "offset": 42,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "high level second is actually developing",
      "offset": 43.6,
      "duration": 3.279
    },
    {
      "lang": "en",
      "text": "software right putting in the business",
      "offset": 45.6,
      "duration": 3.119
    },
    {
      "lang": "en",
      "text": "logic of your particular company and and",
      "offset": 46.879,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "all of the devops that comes with it and",
      "offset": 48.719,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "then when you when your software",
      "offset": 50.8,
      "duration": 3.279
    },
    {
      "lang": "en",
      "text": "actually hits production invariably it's",
      "offset": 52.32,
      "duration": 2.879
    },
    {
      "lang": "en",
      "text": "going to break and then troubleshooting",
      "offset": 54.079,
      "duration": 2.561
    },
    {
      "lang": "en",
      "text": "of these production incidents right at",
      "offset": 55.199,
      "duration": 2.561
    },
    {
      "lang": "en",
      "text": "the heart of it those are the three",
      "offset": 56.64,
      "duration": 2.88
    },
    {
      "lang": "en",
      "text": "things interspersed with each other as",
      "offset": 57.76,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "you think about developing production",
      "offset": 59.52,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "grade software.",
      "offset": 61.12,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "Now what what's been happening with the",
      "offset": 62.96,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "magic of um AI software engineering",
      "offset": 64.72,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "tools like cursor or winds or GitHub",
      "offset": 67.2,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "copilot and there's many more others the",
      "offset": 69.119,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "the part development is getting narrowed",
      "offset": 71.2,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "right that's the part we're relying on",
      "offset": 73.119,
      "duration": 2.961
    },
    {
      "lang": "en",
      "text": "all these different systems to do it for",
      "offset": 74.32,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "us and increasingly so right so over the",
      "offset": 76.08,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "next year I'd say more and more of what",
      "offset": 78.24,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "we see uh is going to make the",
      "offset": 79.92,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "development part of it really seamless",
      "offset": 81.84,
      "duration": 3.599
    },
    {
      "lang": "en",
      "text": "right the question is what happens to",
      "offset": 84,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "the other two parts of this entire",
      "offset": 85.439,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "software engineering workflow the first",
      "offset": 87.84,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "one being system design and the other",
      "offset": 89.439,
      "duration": 3.761
    },
    {
      "lang": "en",
      "text": "one being troubleshooting Right now,",
      "offset": 90.96,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "what is the promise that is u as we",
      "offset": 93.2,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "think about what software engineering",
      "offset": 95.84,
      "duration": 2.959
    },
    {
      "lang": "en",
      "text": "could look like is that we'll get to",
      "offset": 97.04,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "focus on just the most high impact and",
      "offset": 98.799,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "creative work that happens in",
      "offset": 100.64,
      "duration": 2.96
    },
    {
      "lang": "en",
      "text": "engineering which is system design right",
      "offset": 102.079,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "so we're hoping that AI will write our",
      "offset": 103.6,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "code for us and also troubleshoot all",
      "offset": 105.439,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "the production incidents so we just get",
      "offset": 107.28,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "to focus on the fun stuff which is the",
      "offset": 109.04,
      "duration": 2.719
    },
    {
      "lang": "en",
      "text": "creative work of how do we put all these",
      "offset": 110.32,
      "duration": 2.56
    },
    {
      "lang": "en",
      "text": "different pieces together that's the",
      "offset": 111.759,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "hope um I actually think that to make",
      "offset": 112.88,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "that happen there's something missing",
      "offset": 115.759,
      "duration": 2.64
    },
    {
      "lang": "en",
      "text": "right which is the the problem of",
      "offset": 116.96,
      "duration": 3.119
    },
    {
      "lang": "en",
      "text": "troubleshooting how do you automate that",
      "offset": 118.399,
      "duration": 3.281
    },
    {
      "lang": "en",
      "text": "part of it and I think if we just",
      "offset": 120.079,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "continue in the way we're going. It's",
      "offset": 121.68,
      "duration": 2.96
    },
    {
      "lang": "en",
      "text": "actually going to look the opposite is",
      "offset": 123.119,
      "duration": 3.121
    },
    {
      "lang": "en",
      "text": "that most of our time I think is going",
      "offset": 124.64,
      "duration": 3.599
    },
    {
      "lang": "en",
      "text": "to be spent doing on call for the m vast",
      "offset": 126.24,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "majority of us. And why is that? I think",
      "offset": 128.239,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "troubleshooting is going to get more and",
      "offset": 130.399,
      "duration": 4.241
    },
    {
      "lang": "en",
      "text": "more complex as we go along. Uh first is",
      "offset": 131.84,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "that as we write as these software",
      "offset": 134.64,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "engineering AI software engineering",
      "offset": 136.64,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "systems write more and more of our code,",
      "offset": 138,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "humans are going to have less context",
      "offset": 139.92,
      "duration": 2.399
    },
    {
      "lang": "en",
      "text": "about what happened. They don't",
      "offset": 141.36,
      "duration": 2.48
    },
    {
      "lang": "en",
      "text": "understand the inner workings of the",
      "offset": 142.319,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "code. They don't have all the context in",
      "offset": 143.84,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "their minds. Right? Second, we're going",
      "offset": 145.599,
      "duration": 3.041
    },
    {
      "lang": "en",
      "text": "to push these systems to the limit. So",
      "offset": 147.36,
      "duration": 2.16
    },
    {
      "lang": "en",
      "text": "we're going to write more and more",
      "offset": 148.64,
      "duration": 2.4
    },
    {
      "lang": "en",
      "text": "complex systems just like the things we",
      "offset": 149.52,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "saw in the previous talks, right? Right?",
      "offset": 151.04,
      "duration": 2.64
    },
    {
      "lang": "en",
      "text": "So the system's going to get more",
      "offset": 152.64,
      "duration": 2.08
    },
    {
      "lang": "en",
      "text": "complex and we're going to have less",
      "offset": 153.68,
      "duration": 3.279
    },
    {
      "lang": "en",
      "text": "understanding of it. And as a result,",
      "offset": 154.72,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "troubleshooting is going to get really",
      "offset": 156.959,
      "duration": 2.961
    },
    {
      "lang": "en",
      "text": "really painful and complex. And I think",
      "offset": 158.16,
      "duration": 2.64
    },
    {
      "lang": "en",
      "text": "that's where we're going to spend most",
      "offset": 159.92,
      "duration": 2.319
    },
    {
      "lang": "en",
      "text": "of our time in this world which is just",
      "offset": 160.8,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "QA and on call, right? And that would be",
      "offset": 162.239,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "kind of a sad existence for ourselves if",
      "offset": 164.16,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "that's what happens, right? So this I",
      "offset": 165.84,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "think is a grim reality if we don't do",
      "offset": 167.84,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "something about it.",
      "offset": 169.2,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "So now if you think about the workflow",
      "offset": 171.12,
      "duration": 4.479
    },
    {
      "lang": "en",
      "text": "of troubleshooting, what does it look",
      "offset": 174,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "like? In my head, you'll have all of",
      "offset": 175.599,
      "duration": 4.241
    },
    {
      "lang": "en",
      "text": "these different wonderful companies like",
      "offset": 178,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "Graphfana, Data Dog, Splunk, Elastic,",
      "offset": 179.84,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "uh, Sentry, whatever it might be. And",
      "offset": 183.04,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "what they do essentially is they help",
      "offset": 185.28,
      "duration": 3.599
    },
    {
      "lang": "en",
      "text": "process data and help you visualize it,",
      "offset": 186.8,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "right? And so if anyone who's been on a",
      "offset": 188.879,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "data dog dashboard or whatever it might",
      "offset": 190.72,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "be, you have these beautiful dashboards,",
      "offset": 192.56,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "thousands of them to give you some cut",
      "offset": 194.4,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "as to what is the health of your system.",
      "offset": 196.4,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "Now, something will break invariably in",
      "offset": 198.319,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "production. Then what happens next? The",
      "offset": 200,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "next step as I see it is what I call",
      "offset": 201.92,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "dashboard dumpster diving, right? Right?",
      "offset": 203.68,
      "duration": 2.559
    },
    {
      "lang": "en",
      "text": "You'll go through all these different",
      "offset": 205.2,
      "duration": 2.48
    },
    {
      "lang": "en",
      "text": "thousands of dashboards to try to find",
      "offset": 206.239,
      "duration": 3.041
    },
    {
      "lang": "en",
      "text": "the one that explains what happened. And",
      "offset": 207.68,
      "duration": 2.88
    },
    {
      "lang": "en",
      "text": "you'll try to have many different people",
      "offset": 209.28,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "doing it in parallel. At some point, you",
      "offset": 210.56,
      "duration": 2.88
    },
    {
      "lang": "en",
      "text": "might come up with some sort of",
      "offset": 212.4,
      "duration": 2.32
    },
    {
      "lang": "en",
      "text": "promising lead being like, okay, maybe",
      "offset": 213.44,
      "duration": 2.48
    },
    {
      "lang": "en",
      "text": "that was it. That's the dashboard that",
      "offset": 214.72,
      "duration": 2.72
    },
    {
      "lang": "en",
      "text": "kind of explains what happened or that's",
      "offset": 215.92,
      "duration": 2.8
    },
    {
      "lang": "en",
      "text": "the log that kind of explains what",
      "offset": 217.44,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "happened. Then you want to connect it to",
      "offset": 218.72,
      "duration": 2.96
    },
    {
      "lang": "en",
      "text": "some sort of change you made in your",
      "offset": 220.48,
      "duration": 2.479
    },
    {
      "lang": "en",
      "text": "system, right? As we think about root",
      "offset": 221.68,
      "duration": 2.8
    },
    {
      "lang": "en",
      "text": "cause analysis, it's typically you're",
      "offset": 222.959,
      "duration": 2.721
    },
    {
      "lang": "en",
      "text": "trying to connect it to some particular",
      "offset": 224.48,
      "duration": 3.119
    },
    {
      "lang": "en",
      "text": "change in the system, whether it's a",
      "offset": 225.68,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "pull request or a change of your",
      "offset": 227.599,
      "duration": 3.121
    },
    {
      "lang": "en",
      "text": "configuration files, whatever it might",
      "offset": 229.2,
      "duration": 2.8
    },
    {
      "lang": "en",
      "text": "be, right? Right? And that's where you",
      "offset": 230.72,
      "duration": 2.799
    },
    {
      "lang": "en",
      "text": "start say that's the second stage of",
      "offset": 232,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "your troubleshooting which you stare",
      "offset": 233.519,
      "duration": 3.041
    },
    {
      "lang": "en",
      "text": "aggressively at your code base till",
      "offset": 235.12,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "something you know some sort of uh",
      "offset": 236.56,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "inspiration hits you and then most of",
      "offset": 238.72,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "the time it doesn't hit you and then you",
      "offset": 241.04,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "kind of bring more teams into the mix",
      "offset": 242.48,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "because you know it's maybe not be your",
      "offset": 245.12,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "issue and suddenly you have 30 40 50 100",
      "offset": 246.4,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "people in a slack incident channel",
      "offset": 249.04,
      "duration": 3.279
    },
    {
      "lang": "en",
      "text": "trying to figure out what happened and",
      "offset": 251.12,
      "duration": 3.039
    },
    {
      "lang": "en",
      "text": "this loop keeps going on and on and on",
      "offset": 252.319,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "right so the status quo of what incident",
      "offset": 254.159,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "production incident debugging looks like",
      "offset": 256.239,
      "duration": 3.441
    },
    {
      "lang": "en",
      "text": "clearly is is not optimal and I think",
      "offset": 257.759,
      "duration": 3.361
    },
    {
      "lang": "en",
      "text": "it's only going to get worse based for",
      "offset": 259.68,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "all the reasons I talked about earlier.",
      "offset": 261.12,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "Okay. And obviously this problem has",
      "offset": 263.52,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "been around since software has been",
      "offset": 266.8,
      "duration": 2.88
    },
    {
      "lang": "en",
      "text": "written and it's not like we're the",
      "offset": 268.32,
      "duration": 2.72
    },
    {
      "lang": "en",
      "text": "first people to think about thinking of",
      "offset": 269.68,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "this issue. Right? The problem is that",
      "offset": 271.04,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "the existing approaches we've taken to",
      "offset": 272.96,
      "duration": 2.799
    },
    {
      "lang": "en",
      "text": "troubleshooting or using machine",
      "offset": 274.56,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "learning or AI towards it have not",
      "offset": 275.759,
      "duration": 3.521
    },
    {
      "lang": "en",
      "text": "worked and I don't believe will work for",
      "offset": 277.6,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "really fundamental reasons. Right? So",
      "offset": 279.28,
      "duration": 3.359
    },
    {
      "lang": "en",
      "text": "the first one is what we call AI ops",
      "offset": 280.96,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "broadly speaking which is we're using",
      "offset": 282.639,
      "duration": 3.761
    },
    {
      "lang": "en",
      "text": "traditional machine learning and",
      "offset": 284.4,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "statistical anomaly detection type",
      "offset": 286.4,
      "duration": 2.96
    },
    {
      "lang": "en",
      "text": "techniques to help figure out what",
      "offset": 287.84,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "happened. Right? The problem is if any",
      "offset": 289.36,
      "duration": 2.64
    },
    {
      "lang": "en",
      "text": "of you have actually tried these",
      "offset": 291.04,
      "duration": 2.32
    },
    {
      "lang": "en",
      "text": "techniques in production systems, it",
      "offset": 292,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "leads to too many false positives. Your",
      "offset": 293.36,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "system is too complex. It's too dynamic.",
      "offset": 295.12,
      "duration": 3.359
    },
    {
      "lang": "en",
      "text": "And if you just try to come up with some",
      "offset": 297.199,
      "duration": 2.801
    },
    {
      "lang": "en",
      "text": "sort of numerical representation of your",
      "offset": 298.479,
      "duration": 3.121
    },
    {
      "lang": "en",
      "text": "data, it's going to be not",
      "offset": 300,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "representative enough. And what you'll",
      "offset": 301.6,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "see is that you'll have thousands of",
      "offset": 303.28,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "alerts happening. Maybe one of them is",
      "offset": 304.88,
      "duration": 2.96
    },
    {
      "lang": "en",
      "text": "useful, but you just don't know which",
      "offset": 306.8,
      "duration": 2.64
    },
    {
      "lang": "en",
      "text": "one, right? So typically leads to more",
      "offset": 307.84,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "signal, sorry, more noise than signal is",
      "offset": 309.44,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "what AI ops has led to sadly. Okay, now",
      "offset": 311.52,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "we have this new world of LLMs. Okay, so",
      "offset": 314.16,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "one option is okay, let me I'm sure many",
      "offset": 316.56,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "people here have taken a log and put in",
      "offset": 318.32,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "chat GPT and said explain to me what",
      "offset": 320.88,
      "duration": 2.64
    },
    {
      "lang": "en",
      "text": "happened. What what's going on in this",
      "offset": 322.32,
      "duration": 2.64
    },
    {
      "lang": "en",
      "text": "log, right? That's something I think all",
      "offset": 323.52,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "of us have done. Now that's okay if you",
      "offset": 324.96,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "know which log you want to look at. But",
      "offset": 327.12,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "if I'm actually dealing with production",
      "offset": 328.72,
      "duration": 2.64
    },
    {
      "lang": "en",
      "text": "grade systems, you're going to have",
      "offset": 330.16,
      "duration": 2.8
    },
    {
      "lang": "en",
      "text": "terabytes of data. You might have a",
      "offset": 331.36,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "trillion logs. Which one do I look at?",
      "offset": 332.96,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "You can't take all of these different",
      "offset": 335.28,
      "duration": 3.359
    },
    {
      "lang": "en",
      "text": "logs, the trillion logs, and put into",
      "offset": 336.72,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "context. Right? Even if you have",
      "offset": 338.639,
      "duration": 3.521
    },
    {
      "lang": "en",
      "text": "infinite context, it doesn't matter. The",
      "offset": 340.08,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "size of these systems are so large that",
      "offset": 342.16,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "forget about context window. It doesn't",
      "offset": 344.08,
      "duration": 2.72
    },
    {
      "lang": "en",
      "text": "even fit into memory. It doesn't even",
      "offset": 345.44,
      "duration": 2.96
    },
    {
      "lang": "en",
      "text": "fit into a cluster. That's why you have",
      "offset": 346.8,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "such difficult retention policies for",
      "offset": 348.4,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "data, right, for logs and metrics. And",
      "offset": 350,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "second, the problem with these LLMs are",
      "offset": 351.84,
      "duration": 2.639
    },
    {
      "lang": "en",
      "text": "is that they don't have a really good",
      "offset": 353.28,
      "duration": 2.32
    },
    {
      "lang": "en",
      "text": "understanding of the numerical",
      "offset": 354.479,
      "duration": 2.641
    },
    {
      "lang": "en",
      "text": "representation of the data. So they have",
      "offset": 355.6,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "a good semantic understanding. They",
      "offset": 357.12,
      "duration": 2.96
    },
    {
      "lang": "en",
      "text": "don't have a good numerical",
      "offset": 358.88,
      "duration": 2.8
    },
    {
      "lang": "en",
      "text": "representation and also the context",
      "offset": 360.08,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "isn't big enough. Okay. Now, the third",
      "offset": 361.68,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "thing we might think about is let's",
      "offset": 363.52,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "build an agent, right? Like let's build",
      "offset": 364.96,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "a React style agent. The problem with",
      "offset": 366.72,
      "duration": 3.599
    },
    {
      "lang": "en",
      "text": "that is that if you think about these",
      "offset": 368.96,
      "duration": 2.88
    },
    {
      "lang": "en",
      "text": "React style agents, what they're going",
      "offset": 370.319,
      "duration": 2.88
    },
    {
      "lang": "en",
      "text": "to do is they're going to assume you",
      "offset": 371.84,
      "duration": 2.479
    },
    {
      "lang": "en",
      "text": "have some access to some sort of",
      "offset": 373.199,
      "duration": 3.201
    },
    {
      "lang": "en",
      "text": "runbook, some sort of meta workflow that",
      "offset": 374.319,
      "duration": 3.521
    },
    {
      "lang": "en",
      "text": "they can rely on to help you make the",
      "offset": 376.4,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "decision of what next tool to call. The",
      "offset": 377.84,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "problem is any runbook you actually put",
      "offset": 380.319,
      "duration": 3.121
    },
    {
      "lang": "en",
      "text": "into place is deprecated the second you",
      "offset": 381.919,
      "duration": 2.881
    },
    {
      "lang": "en",
      "text": "create it. I don't know how many of you",
      "offset": 383.44,
      "duration": 2.879
    },
    {
      "lang": "en",
      "text": "have used runbooks, but typically what",
      "offset": 384.8,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "we found in my experience and the team's",
      "offset": 386.319,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "experience is that they're typically",
      "offset": 388.56,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "deprecated by the time they're built,",
      "offset": 390.24,
      "duration": 3.679
    },
    {
      "lang": "en",
      "text": "right? And so that workflow that the",
      "offset": 392.08,
      "duration": 3.119
    },
    {
      "lang": "en",
      "text": "agent is going to go through is not",
      "offset": 393.919,
      "duration": 3.361
    },
    {
      "lang": "en",
      "text": "going to be um is is is just not going",
      "offset": 395.199,
      "duration": 3.761
    },
    {
      "lang": "en",
      "text": "to be optimal. And also if you try to",
      "offset": 397.28,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "make it do a much more broad search of",
      "offset": 398.96,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "your system, if you give it these simple",
      "offset": 401.44,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "tools, it's going to be take too long,",
      "offset": 403.52,
      "duration": 3.679
    },
    {
      "lang": "en",
      "text": "right? If you just put it in into like a",
      "offset": 405.84,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "loop tool to tool calling loop, it might",
      "offset": 407.199,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "take days to run if if it doesn't time",
      "offset": 409.28,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "out, right? And typically if you try to",
      "offset": 411.759,
      "duration": 3.041
    },
    {
      "lang": "en",
      "text": "solve an incident, you need to solve it",
      "offset": 413.36,
      "duration": 2.8
    },
    {
      "lang": "en",
      "text": "in two to five minutes for it to be",
      "offset": 414.8,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "really useful, right? So every minute",
      "offset": 416.16,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "counts when things are down. So as a",
      "offset": 418.08,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "result, none of these three things if",
      "offset": 420.08,
      "duration": 3.519
    },
    {
      "lang": "en",
      "text": "you do them just by themselves is enough",
      "offset": 421.44,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "to really d troubleshoot. There's",
      "offset": 423.599,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "fundamental issues in all of them that I",
      "offset": 425.12,
      "duration": 3.199
    },
    {
      "lang": "en",
      "text": "think need to be solved by thinking",
      "offset": 427.039,
      "duration": 2.88
    },
    {
      "lang": "en",
      "text": "about them in a more collective way. And",
      "offset": 428.319,
      "duration": 2.72
    },
    {
      "lang": "en",
      "text": "that's really what we're trying to do at",
      "offset": 429.919,
      "duration": 3.521
    },
    {
      "lang": "en",
      "text": "tra traversal, right? What you need to",
      "offset": 431.039,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "do with traversal is what we're trying",
      "offset": 433.44,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "to do with traversal is really good out",
      "offset": 435.12,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "of sample autonomous troubleshooting,",
      "offset": 436.56,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "which is that you have a new incident,",
      "offset": 438.24,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "we've never seen it before. Can you",
      "offset": 440,
      "duration": 2.88
    },
    {
      "lang": "en",
      "text": "troubleshoot it from first principles",
      "offset": 441.44,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "debugging? And to do so, I think we need",
      "offset": 442.88,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "to combine a few different ideas. The",
      "offset": 444.88,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "first one being statistical, the second",
      "offset": 446.56,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "one being semanticus and then the third",
      "offset": 448.72,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "one being a novel agentic control flow.",
      "offset": 450.56,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "And with statistics, what I mean is is",
      "offset": 452.96,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "causal machine learning. So that's where",
      "offset": 454.639,
      "duration": 3.201
    },
    {
      "lang": "en",
      "text": "a lot of our research came. So the idea",
      "offset": 456,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "of causal machine learning is this idea",
      "offset": 457.84,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "of being correlation isn't causation. So",
      "offset": 459.28,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "how do you get these AI systems to pick",
      "offset": 461.36,
      "duration": 2.72
    },
    {
      "lang": "en",
      "text": "up cause and effect relationships from",
      "offset": 462.72,
      "duration": 2.8
    },
    {
      "lang": "en",
      "text": "data programmatically? That's what we",
      "offset": 464.08,
      "duration": 2.64
    },
    {
      "lang": "en",
      "text": "spend a lot of time thinking about. And",
      "offset": 465.52,
      "duration": 2.64
    },
    {
      "lang": "en",
      "text": "obviously that problem shows up a lot in",
      "offset": 466.72,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "production incidents because typically",
      "offset": 468.16,
      "duration": 3.039
    },
    {
      "lang": "en",
      "text": "when something breaks a lot of things",
      "offset": 469.84,
      "duration": 2.479
    },
    {
      "lang": "en",
      "text": "break around them, right? So there's a",
      "offset": 471.199,
      "duration": 2.641
    },
    {
      "lang": "en",
      "text": "lot of correlated failures which are not",
      "offset": 472.319,
      "duration": 3.121
    },
    {
      "lang": "en",
      "text": "the root cause. And so thinking about it",
      "offset": 473.84,
      "duration": 2.88
    },
    {
      "lang": "en",
      "text": "programmatically is what the study of",
      "offset": 475.44,
      "duration": 3.199
    },
    {
      "lang": "en",
      "text": "causal machine learning is. The second",
      "offset": 476.72,
      "duration": 3.599
    },
    {
      "lang": "en",
      "text": "being semantics, right? Which is",
      "offset": 478.639,
      "duration": 2.881
    },
    {
      "lang": "en",
      "text": "actually trying to push the limits of",
      "offset": 480.319,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "what these reasoning models can give you",
      "offset": 481.52,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "uh to help you understand the semantic",
      "offset": 483.759,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "rich semantic context that exists in in",
      "offset": 485.28,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "log fields in the metadata source of the",
      "offset": 487.199,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "metric and so on so forth, right? Or in",
      "offset": 489.36,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "code itself, right? And so by combining",
      "offset": 491.12,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "causal machine learning, which is the",
      "offset": 494.24,
      "duration": 2.959
    },
    {
      "lang": "en",
      "text": "best of what statistics gives you, and",
      "offset": 495.44,
      "duration": 3.039
    },
    {
      "lang": "en",
      "text": "reasoning models, which is the best of",
      "offset": 497.199,
      "duration": 2.961
    },
    {
      "lang": "en",
      "text": "what semantics gives you, you now have",
      "offset": 498.479,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "at least the tools, the basic tools to",
      "offset": 500.16,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "put into place so that you can actually",
      "offset": 502.319,
      "duration": 3.121
    },
    {
      "lang": "en",
      "text": "deal with this issue. Now you have to",
      "offset": 503.52,
      "duration": 3.359
    },
    {
      "lang": "en",
      "text": "figure out how do you actually make this",
      "offset": 505.44,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "work in an agentic system. And what we",
      "offset": 506.879,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "found is this idea of swarms of agent",
      "offset": 508.96,
      "duration": 2.639
    },
    {
      "lang": "en",
      "text": "where you have these thousands of",
      "offset": 510.56,
      "duration": 2.88
    },
    {
      "lang": "en",
      "text": "parallel agentic tool calls happening",
      "offset": 511.599,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "giving you this kind of exhaustive",
      "offset": 513.44,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "search through all of your telemetry in",
      "offset": 514.719,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "some sort of efficient way. That's what",
      "offset": 516.56,
      "duration": 2.959
    },
    {
      "lang": "en",
      "text": "brings it together and helps you",
      "offset": 518.159,
      "duration": 3.201
    },
    {
      "lang": "en",
      "text": "actually deal with this issue. Right? So",
      "offset": 519.519,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "just to repeat, it's statistics which is",
      "offset": 521.36,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "causal machine learning, semantics which",
      "offset": 523.599,
      "duration": 3.761
    },
    {
      "lang": "en",
      "text": "is these reasoning models and this novel",
      "offset": 525.76,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "agentic control flow which call the",
      "offset": 527.36,
      "duration": 3.599
    },
    {
      "lang": "en",
      "text": "swarms of agent. All of this put",
      "offset": 529.2,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "together in the right elegant way is",
      "offset": 530.959,
      "duration": 3.041
    },
    {
      "lang": "en",
      "text": "what actually helps you autonomously",
      "offset": 532.48,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "troubleshoot. Right? And a lot of the",
      "offset": 534,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "work we we rely on is based on our years",
      "offset": 536.08,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "of research years of experience as",
      "offset": 538.72,
      "duration": 2.96
    },
    {
      "lang": "en",
      "text": "researchers. We've written a number of",
      "offset": 540.48,
      "duration": 2.96
    },
    {
      "lang": "en",
      "text": "papers on these various different fields",
      "offset": 541.68,
      "duration": 2.88
    },
    {
      "lang": "en",
      "text": "and also relying on a lot of the",
      "offset": 543.44,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "research that has happened uh in general",
      "offset": 544.56,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "in the field over the last couple of",
      "offset": 546.88,
      "duration": 2.72
    },
    {
      "lang": "en",
      "text": "years that we're relying on to actually",
      "offset": 548.399,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "make this into a reality. Um and so if",
      "offset": 549.6,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "you think about the the troubleshooting",
      "offset": 552.959,
      "duration": 3.121
    },
    {
      "lang": "en",
      "text": "workflow we talked about earlier and all",
      "offset": 554.72,
      "duration": 2.88
    },
    {
      "lang": "en",
      "text": "the pains of it, each of the different",
      "offset": 556.08,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "things can help remove or alleviate some",
      "offset": 557.6,
      "duration": 3.679
    },
    {
      "lang": "en",
      "text": "of those pains. So the idea of finding",
      "offset": 559.44,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "the promising lead from your sea of",
      "offset": 561.279,
      "duration": 3.761
    },
    {
      "lang": "en",
      "text": "information, that's where this agent",
      "offset": 563.36,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "swarm and causal machine learning put",
      "offset": 565.04,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "together really help. And then from the",
      "offset": 566.56,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "promising lead connecting it to a",
      "offset": 568.48,
      "duration": 2.799
    },
    {
      "lang": "en",
      "text": "specific change in your system whether",
      "offset": 569.92,
      "duration": 3.359
    },
    {
      "lang": "en",
      "text": "it's a pull request or change log that's",
      "offset": 571.279,
      "duration": 3.201
    },
    {
      "lang": "en",
      "text": "a lot of the work that's happening in",
      "offset": 573.279,
      "duration": 2.801
    },
    {
      "lang": "en",
      "text": "code agents and also vector search",
      "offset": 574.48,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "relying on it. Uh as this get better we",
      "offset": 576.08,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "get better right and as a result because",
      "offset": 577.92,
      "duration": 3.599
    },
    {
      "lang": "en",
      "text": "you're building this context in real",
      "offset": 579.92,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "time and agents are doing it they're",
      "offset": 581.519,
      "duration": 2.88
    },
    {
      "lang": "en",
      "text": "pulling in the right team at the with",
      "offset": 583.2,
      "duration": 2.72
    },
    {
      "lang": "en",
      "text": "the right context or the right time and",
      "offset": 584.399,
      "duration": 2.801
    },
    {
      "lang": "en",
      "text": "so don't people want to get pulled into",
      "offset": 585.92,
      "duration": 2.32
    },
    {
      "lang": "en",
      "text": "an incident being like I don't really",
      "offset": 587.2,
      "duration": 2.4
    },
    {
      "lang": "en",
      "text": "know why I'm being pulled in here which",
      "offset": 588.24,
      "duration": 2.4
    },
    {
      "lang": "en",
      "text": "I'm sure many of you have been",
      "offset": 589.6,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "experienced in your time as engineers.",
      "offset": 590.64,
      "duration": 5.199
    },
    {
      "lang": "en",
      "text": "Um, and so now I'm going to hand it over",
      "offset": 593.519,
      "duration": 4.561
    },
    {
      "lang": "en",
      "text": "to Matt to actually talk through a real",
      "offset": 595.839,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "life case study uh that we've done with",
      "offset": 598.08,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "one of our customers. Hi everybody. I'm",
      "offset": 600.24,
      "duration": 5.279
    },
    {
      "lang": "en",
      "text": "Matt as Anish said. Thank you. Uh, and",
      "offset": 603.68,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "no, I I don't own any of their outfits.",
      "offset": 605.519,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "Um,",
      "offset": 608.08,
      "duration": 2.8
    },
    {
      "lang": "en",
      "text": "so I'm going to tell you a little bit",
      "offset": 609.68,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "about how I got involved with Traversal.",
      "offset": 610.88,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "I'm going to show you how we are helping",
      "offset": 612.8,
      "duration": 4.719
    },
    {
      "lang": "en",
      "text": "out some of our customers. So, uh, in my",
      "offset": 614.72,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "career I spent most my time in high",
      "offset": 617.519,
      "duration": 3.361
    },
    {
      "lang": "en",
      "text": "frequency trading. uh what I wanted to",
      "offset": 619.12,
      "duration": 4.719
    },
    {
      "lang": "en",
      "text": "spend my time doing there was uh you",
      "offset": 620.88,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "know focusing and writing beautiful",
      "offset": 623.839,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "code. What I ended up doing much more",
      "offset": 625.68,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "often than not was debugging production",
      "offset": 627.76,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "incidents. So I got sick of this as you",
      "offset": 629.6,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "might understand and uh very happily",
      "offset": 632.56,
      "duration": 5.839
    },
    {
      "lang": "en",
      "text": "quit. Sometime later I I found myself in",
      "offset": 635.36,
      "duration": 7.039
    },
    {
      "lang": "en",
      "text": "a class on causal AI. Uh the guy",
      "offset": 638.399,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "teaching the class seemed pretty smart.",
      "offset": 642.399,
      "duration": 3.761
    },
    {
      "lang": "en",
      "text": "it uh looking back then it may have just",
      "offset": 644.079,
      "duration": 3.121
    },
    {
      "lang": "en",
      "text": "been the fact that he was much better",
      "offset": 646.16,
      "duration": 2.08
    },
    {
      "lang": "en",
      "text": "dressed than your average computer",
      "offset": 647.2,
      "duration": 2.4
    },
    {
      "lang": "en",
      "text": "science professor and he had a you know",
      "offset": 648.24,
      "duration": 5.279
    },
    {
      "lang": "en",
      "text": "a fancy accent. Um but he uh he",
      "offset": 649.6,
      "duration": 5.84
    },
    {
      "lang": "en",
      "text": "mentioned in class one day sort of an",
      "offset": 653.519,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "off-hand comment it seemed that oh you",
      "offset": 655.44,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "might be able to use causal AI to",
      "offset": 657.839,
      "duration": 4.961
    },
    {
      "lang": "en",
      "text": "automate incident remediation workflows",
      "offset": 660.32,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "and I'm sitting in the back back of the",
      "offset": 662.8,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "class and my head explodes like this",
      "offset": 664.8,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "sounds like an amazing idea and so I",
      "offset": 666.24,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "casually come up to him at the end of",
      "offset": 668.48,
      "duration": 2.56
    },
    {
      "lang": "en",
      "text": "class and say you know maybe we might",
      "offset": 669.76,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "want to do a research project on this",
      "offset": 671.04,
      "duration": 4.239
    },
    {
      "lang": "en",
      "text": "and uh little did I know that at the",
      "offset": 672.8,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "time he had actually started a company",
      "offset": 675.279,
      "duration": 3.201
    },
    {
      "lang": "en",
      "text": "to solve this problem so he invited me",
      "offset": 676.8,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "to join him on that journey and very",
      "offset": 678.48,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "grateful for that. And so fast forward a",
      "offset": 681.12,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "year though and we have uh we built",
      "offset": 683.68,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "something that we're quite proud of and",
      "offset": 686.56,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "I'll I'll show you how it works. Uh but",
      "offset": 688.079,
      "duration": 5.681
    },
    {
      "lang": "en",
      "text": "to begin uh I'm going to be talking",
      "offset": 690.959,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "about a client of ours, Digital Ocean.",
      "offset": 693.76,
      "duration": 3.519
    },
    {
      "lang": "en",
      "text": "Digital Ocean is a cloud provider. They",
      "offset": 695.519,
      "duration": 3.121
    },
    {
      "lang": "en",
      "text": "serve hundreds of thousands of customers",
      "offset": 697.279,
      "duration": 3.521
    },
    {
      "lang": "en",
      "text": "every day. And I'm going to tell you",
      "offset": 698.64,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "about what uh the life of an on call",
      "offset": 700.8,
      "duration": 6.039
    },
    {
      "lang": "en",
      "text": "engineer was like prior to traversal.",
      "offset": 702.32,
      "duration": 4.519
    },
    {
      "lang": "en",
      "text": "So, imagine you're in the middle of a",
      "offset": 707.2,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "productive workday. You're focused day",
      "offset": 709.2,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "in. You're writing code. Um, and then",
      "offset": 710.88,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "you get hit with a message uh describing",
      "offset": 714.24,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "something that's broken horribly. It's",
      "offset": 716.56,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "it's causing issues for customers. It",
      "offset": 718.56,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "might say something like powered some",
      "offset": 719.92,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "potential compromise of some host",
      "offset": 722.48,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "assigned to, you know, a bad",
      "offset": 724.8,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "application. And my apologies in advance",
      "offset": 726.72,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "here. This is not a demo per se. This is",
      "offset": 728.56,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "us telling you in the real world how uh",
      "offset": 730.639,
      "duration": 4.721
    },
    {
      "lang": "en",
      "text": "we are we are solving issues for our",
      "offset": 733.76,
      "duration": 3.199
    },
    {
      "lang": "en",
      "text": "customers. So apologies for the",
      "offset": 735.36,
      "duration": 4.719
    },
    {
      "lang": "en",
      "text": "redactions that you're seeing here.",
      "offset": 736.959,
      "duration": 6.161
    },
    {
      "lang": "en",
      "text": "So you get this context and then you get",
      "offset": 740.079,
      "duration": 4.721
    },
    {
      "lang": "en",
      "text": "thrown into an incident Slack channel",
      "offset": 743.12,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "and in this Slack channel you and 40 50",
      "offset": 744.8,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "60 other engineers begin frantically",
      "offset": 747.2,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "searching to find what's the cause of",
      "offset": 749.68,
      "duration": 3.599
    },
    {
      "lang": "en",
      "text": "the customer issue, right? But you're",
      "offset": 751.44,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "not looking through some documents,",
      "offset": 753.279,
      "duration": 3.281
    },
    {
      "lang": "en",
      "text": "you're not looking through a database",
      "offset": 755.2,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "table. You're looking through hundreds",
      "offset": 756.56,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "of millions of metrics which are",
      "offset": 758.72,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "viewable on thousands of dashboards",
      "offset": 761.44,
      "duration": 5.92
    },
    {
      "lang": "en",
      "text": "and beyond this you also have tens of",
      "offset": 764.72,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "billions of logs that you might want to",
      "offset": 767.36,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "find and these are coming from thousands",
      "offset": 769.12,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "of services. And what's the thing you're",
      "offset": 770.88,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "looking for here? You're looking for a",
      "offset": 773.279,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "something that's comparatively",
      "offset": 775.279,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "microscopic. So this might be a single",
      "offset": 776.399,
      "duration": 4.801
    },
    {
      "lang": "en",
      "text": "log that describes the thing that went",
      "offset": 779.12,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "wrong, the root cause of the incident.",
      "offset": 781.2,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "And you know if you're lucky after a few",
      "offset": 783.2,
      "duration": 3.759
    },
    {
      "lang": "en",
      "text": "hours of everybody frantically searching",
      "offset": 784.88,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "the incident gets resolved and you know",
      "offset": 786.959,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "everybody can go back to work that is",
      "offset": 789.12,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "until the next production incident comes",
      "offset": 791.04,
      "duration": 6.4
    },
    {
      "lang": "en",
      "text": "and the cycle repeats itself. So this is",
      "offset": 794,
      "duration": 6.079
    },
    {
      "lang": "en",
      "text": "a very familiar situation to me",
      "offset": 797.44,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "unfortunately it may be a very similar",
      "offset": 800.079,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "situation to all of you but things have",
      "offset": 801.6,
      "duration": 7.32
    },
    {
      "lang": "en",
      "text": "changed for digital ocean. So",
      "offset": 804.079,
      "duration": 4.841
    },
    {
      "lang": "en",
      "text": "what traversal has been able to do for",
      "offset": 810.56,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "digital ocean is make their mission",
      "offset": 811.92,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "critical infrastructure far more",
      "offset": 813.92,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "resilient. So you'll see here that uh",
      "offset": 815.2,
      "duration": 5.84
    },
    {
      "lang": "en",
      "text": "meanantime to resolution uh mtr has",
      "offset": 818.079,
      "duration": 4.481
    },
    {
      "lang": "en",
      "text": "reduced pretty dramatically for digital",
      "offset": 821.04,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "ocean. We've measured that about 40%",
      "offset": 822.56,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "reduction and the amount of time that it",
      "offset": 824.48,
      "duration": 3.599
    },
    {
      "lang": "en",
      "text": "takes to find and resolve production",
      "offset": 826.48,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "incidents. And all of these minutes mean",
      "offset": 828.079,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "a lot of pain for a engineer that's",
      "offset": 830.72,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "that's now been removed and also",
      "offset": 833.279,
      "duration": 5.441
    },
    {
      "lang": "en",
      "text": "thousands of dollars for each minute. So",
      "offset": 835.44,
      "duration": 4.639
    },
    {
      "lang": "en",
      "text": "now I'll be able to show you how this",
      "offset": 838.72,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "works.",
      "offset": 840.079,
      "duration": 4.721
    },
    {
      "lang": "en",
      "text": "So in the world post traversal rather",
      "offset": 841.92,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "than this frantic search going on all",
      "offset": 844.8,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "the time when an instant kicks off the",
      "offset": 847.44,
      "duration": 5.759
    },
    {
      "lang": "en",
      "text": "traversal AI the ambient traversal AI",
      "offset": 850.24,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "begins its investigation. And the thing",
      "offset": 853.199,
      "duration": 4.721
    },
    {
      "lang": "en",
      "text": "that it begins its investigation with is",
      "offset": 855.36,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "the same little bit of context that",
      "offset": 857.92,
      "duration": 4.719
    },
    {
      "lang": "en",
      "text": "engineers get when the incident starts.",
      "offset": 860,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "And given the small amount of context,",
      "offset": 862.639,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "traversal AI orchestrates a swarm of",
      "offset": 864.72,
      "duration": 6.479
    },
    {
      "lang": "en",
      "text": "expert AI sRes to sift through pabytes",
      "offset": 867.279,
      "duration": 6.721
    },
    {
      "lang": "en",
      "text": "of observability data all in parallel.",
      "offset": 871.199,
      "duration": 5.601
    },
    {
      "lang": "en",
      "text": "And so what was done previously manually",
      "offset": 874,
      "duration": 6.56
    },
    {
      "lang": "en",
      "text": "is done exhaustively and automatically.",
      "offset": 876.8,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "And then after about five minutes,",
      "offset": 880.56,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "traversal comes back to the users right",
      "offset": 882.48,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "where they are in the incident slack",
      "offset": 884.48,
      "duration": 4.479
    },
    {
      "lang": "en",
      "text": "channel and tells them what happened. So",
      "offset": 885.92,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "here you can see that uh traversal",
      "offset": 888.959,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "identified an issue. There was a",
      "offset": 891.12,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "deployment that introduced changes a",
      "offset": 892.399,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "cascade of issues throughout the entire",
      "offset": 895.04,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "system. And when engineers see this,",
      "offset": 896.72,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "they can roll it back. They can move on",
      "offset": 898.56,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "and and get back to their good work. And",
      "offset": 900.48,
      "duration": 4.479
    },
    {
      "lang": "en",
      "text": "you'll note here that uh traversal the",
      "offset": 902.32,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "engineers at digital ocean noted that",
      "offset": 904.959,
      "duration": 2.721
    },
    {
      "lang": "en",
      "text": "this was this was the thing that solved",
      "offset": 906.399,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "the issue. This was the correct finding.",
      "offset": 907.68,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "And this is happening all the time.",
      "offset": 909.839,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "Engineers that want to dive in further",
      "offset": 911.6,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "can look in the traversal UI where you",
      "offset": 913.199,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "have a wealth of information that",
      "offset": 914.72,
      "duration": 4.239
    },
    {
      "lang": "en",
      "text": "traversal unears uh describing what",
      "offset": 916.639,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "happened with the incident. It cites",
      "offset": 918.959,
      "duration": 3.281
    },
    {
      "lang": "en",
      "text": "relevant observability data just like",
      "offset": 920.32,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "any good engineer would. It gives you",
      "offset": 922.24,
      "duration": 3.599
    },
    {
      "lang": "en",
      "text": "confidence levels for the potential root",
      "offset": 924.32,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "cause candidates. It explains its",
      "offset": 925.839,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "reasoning. And if you want to dive in",
      "offset": 927.44,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "even further, traversal allows you to",
      "offset": 929.519,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "interact with an uh AI generated impact",
      "offset": 931.279,
      "duration": 4.481
    },
    {
      "lang": "en",
      "text": "map. And you can even ask follow-up",
      "offset": 933.92,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "questions to traversal to describe to",
      "offset": 935.76,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "ask questions like how does this",
      "offset": 938.16,
      "duration": 3.039
    },
    {
      "lang": "en",
      "text": "incident impact the part of the stack",
      "offset": 939.68,
      "duration": 3.599
    },
    {
      "lang": "en",
      "text": "that I care the most about? And this",
      "offset": 941.199,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "entire experience is exactly the kind of",
      "offset": 943.279,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "thing that I was dying for in my",
      "offset": 945.36,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "previous roles and so excited to share",
      "offset": 947.12,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "that it's now a reality.",
      "offset": 949.04,
      "duration": 6.32
    },
    {
      "lang": "en",
      "text": "So thank you. Uh so but this is not just",
      "offset": 952.16,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "happening for digital ocean. We're",
      "offset": 955.36,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "working across a very heterogeneous",
      "offset": 956.56,
      "duration": 6.639
    },
    {
      "lang": "en",
      "text": "group of uh enterprise environments. Uh",
      "offset": 959.36,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "so you'll see here the thing that I want",
      "offset": 963.199,
      "duration": 2.88
    },
    {
      "lang": "en",
      "text": "you to focus on here is that we're",
      "offset": 964.8,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "talking to basically every obser obser",
      "offset": 966.079,
      "duration": 4.241
    },
    {
      "lang": "en",
      "text": "observability tool out there and we're",
      "offset": 968.32,
      "duration": 3.519
    },
    {
      "lang": "en",
      "text": "talking to them on a massive scale.",
      "offset": 970.32,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "We're talking trillions of logs. So yes,",
      "offset": 971.839,
      "duration": 4.721
    },
    {
      "lang": "en",
      "text": "it's an AI agents problem and I I like",
      "offset": 974.56,
      "duration": 3.279
    },
    {
      "lang": "en",
      "text": "thinking about the AI agents problem,",
      "offset": 976.56,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "but in reality this is just as much an",
      "offset": 977.839,
      "duration": 6.281
    },
    {
      "lang": "en",
      "text": "AI infrastructure problem.",
      "offset": 980,
      "duration": 4.12
    },
    {
      "lang": "en",
      "text": "Furthermore, the problem that we're",
      "offset": 984.48,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "solving here is one where we have a",
      "offset": 986.24,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "massive set of data and we're looking",
      "offset": 988.32,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "for this small piece of information",
      "offset": 990.24,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "that's telling you everything that you",
      "offset": 993.04,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "need to know. This is sort of a needle",
      "offset": 994.399,
      "duration": 3.761
    },
    {
      "lang": "en",
      "text": "in the haststack problem. And we're",
      "offset": 996.24,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "focused right now on observability. But",
      "offset": 998.16,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "there are plenty of other domains where",
      "offset": 1000.24,
      "duration": 3.039
    },
    {
      "lang": "en",
      "text": "there are s similar principles that can",
      "offset": 1001.6,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "be applied in my experience that when",
      "offset": 1003.279,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "you're doing network observability,",
      "offset": 1005.36,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "you're working on cyber security, you",
      "offset": 1007.44,
      "duration": 3.759
    },
    {
      "lang": "en",
      "text": "find similar patterns here that I hope",
      "offset": 1009.36,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "that you all in your respective domains",
      "offset": 1011.199,
      "duration": 4.961
    },
    {
      "lang": "en",
      "text": "can take from this that these strategies",
      "offset": 1013.6,
      "duration": 4.479
    },
    {
      "lang": "en",
      "text": "of exhaustive search and swarms of",
      "offset": 1016.16,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "agents can be applied in this in these",
      "offset": 1018.079,
      "duration": 5.041
    },
    {
      "lang": "en",
      "text": "domains as well.",
      "offset": 1019.92,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "Uh not only is this an amazing problem",
      "offset": 1023.12,
      "duration": 2.959
    },
    {
      "lang": "en",
      "text": "to work on, frankly, we've assembled an",
      "offset": 1024.64,
      "duration": 3.039
    },
    {
      "lang": "en",
      "text": "amazing group of people to do it. Uh",
      "offset": 1026.079,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "we've got AI researchers from the top AI",
      "offset": 1027.679,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "labs in the world that that are pushing",
      "offset": 1029.919,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "the limits of what AI what AI can do. We",
      "offset": 1031.28,
      "duration": 4.799
    },
    {
      "lang": "en",
      "text": "have people from top dev tools companies",
      "offset": 1034,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "who know what it takes to build a tool",
      "offset": 1036.079,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "that developers love to use. We have",
      "offset": 1038,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "fantastic AI product engineers who know",
      "offset": 1040.319,
      "duration": 3.441
    },
    {
      "lang": "en",
      "text": "who know how to make delightful AI",
      "offset": 1042.319,
      "duration": 3.441
    },
    {
      "lang": "en",
      "text": "products. And of course, we've got high",
      "offset": 1043.76,
      "duration": 3.439
    },
    {
      "lang": "en",
      "text": "frequency quant finance traders who can",
      "offset": 1045.76,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "deal with pain and know what the pain of",
      "offset": 1047.199,
      "duration": 5.041
    },
    {
      "lang": "en",
      "text": "production downtime actually means.",
      "offset": 1048.96,
      "duration": 4.959
    },
    {
      "lang": "en",
      "text": "But I think what's uh most special about",
      "offset": 1052.24,
      "duration": 3.439
    },
    {
      "lang": "en",
      "text": "the traversal team is not necessarily",
      "offset": 1053.919,
      "duration": 3.361
    },
    {
      "lang": "en",
      "text": "the skills that that that we bring to",
      "offset": 1055.679,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "the table, but you know, it's it's",
      "offset": 1057.28,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "really unusual. It's really rare to be",
      "offset": 1059.52,
      "duration": 3.279
    },
    {
      "lang": "en",
      "text": "able to find a group of people that",
      "offset": 1061.28,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "aren't really all out there for",
      "offset": 1062.799,
      "duration": 2.801
    },
    {
      "lang": "en",
      "text": "themselves. And everybody's working for",
      "offset": 1064.4,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "the betterment of each other. And we",
      "offset": 1065.6,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "have a lot of fun coming into work and",
      "offset": 1067.76,
      "duration": 2.72
    },
    {
      "lang": "en",
      "text": "everybody loves showing up to the",
      "offset": 1069.12,
      "duration": 3.439
    },
    {
      "lang": "en",
      "text": "office. And this is what makes Reversal,",
      "offset": 1070.48,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "in my opinion, an amazing place to work.",
      "offset": 1072.559,
      "duration": 4.801
    },
    {
      "lang": "en",
      "text": "And so if the team or the problem sounds",
      "offset": 1074.96,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "interesting to you, please uh scan the",
      "offset": 1077.36,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "QR code, look at one of these websites",
      "offset": 1079.12,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "and uh help us try to create this",
      "offset": 1080.72,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "picture of me that we have right here",
      "offset": 1082.72,
      "duration": 2.959
    },
    {
      "lang": "en",
      "text": "for all all the engineers in the world.",
      "offset": 1084.16,
      "duration": 5.16
    },
    {
      "lang": "en",
      "text": "Thank you very much.",
      "offset": 1085.679,
      "duration": 3.641
    }
  ],
  "cleanText": "[Music]\nHi everyone.\nThank you for coming to our talk.\nUh, so he was kind enough to already introduce us.\nUm, so I'm the CEO.\nMatthew was the first person who joined us.\nUh, if any difficult questions, please direct it towards Matt.\nUm, now if you think about the three major categories of software engineering, at least as we see it, there's three things that show up to me: the system design, where you think about, you know, how do you actually architect a system?\nA lot of the talks we saw in this track have been about that in some sense at a high level.\nSecond is actually developing software, right, putting in the business logic of your particular company and all of the DevOps that comes with it.\nAnd then when you when your software actually hits production, invariably it's going to break and then troubleshooting of these production incidents, right, at the heart of it.\nThose are the three things interspersed with each other as you think about developing production grade software.\nNow what what's been happening with the magic of um AI software engineering tools like cursor or winds or GitHub copilot and there's many more others, the part development is getting narrowed, right?\nThat's the part we're relying on all these different systems to do it for us and increasingly so, right?\nSo over the next year, I'd say more and more of what we see is going to make the development part of it really seamless, right?\nThe question is what happens to the other two parts of this entire software engineering workflow, the first one being system design and the other one being troubleshooting.\nRight now, what is the promise that is as we think about what software engineering could look like is that we'll get to focus on just the most high impact and creative work that happens in engineering, which is system design, right?\nSo we're hoping that AI will write our code for us and also troubleshoot all the production incidents so we just get to focus on the fun stuff, which is the creative work of how do we put all these different pieces together.\nThat's the hope.\nUm, I actually think that to make that happen, there's something missing, right?\nWhich is the the problem of troubleshooting, how do you automate that part of it?\nAnd I think if we just continue in the way we're going, it's actually going to look the opposite is that most of our time I think is going to be spent doing on call for the vast majority of us.\nAnd why is that?\nI think troubleshooting is going to get more and more complex as we go along.\nUh, first is that as we write as these software engineering AI software engineering systems write more and more of our code, humans are going to have less context about what happened.\nThey don't understand the inner workings of the code.\nThey don't have all the context in their minds, right?\nSecond, we're going to push these systems to the limit.\nSo we're going to write more and more complex systems just like the things we saw in the previous talks, right?\nRight?\nSo the system's going to get more complex and we're going to have less understanding of it.\nAnd as a result, troubleshooting is going to get really, really painful and complex.\nAnd I think that's where we're going to spend most of our time in this world, which is just QA and on call, right?\nAnd that would be kind of a sad existence for ourselves if that's what happens, right?\nSo this I think is a grim reality if we don't do something about it.\nSo now if you think about the workflow of troubleshooting, what does it look like?\nIn my head, you'll have all of these different wonderful companies like Graphfana, Data Dog, Splunk, Elastic, uh, Sentry, whatever it might be.\nAnd what they do essentially is they help process data and help you visualize it, right?\nAnd so if anyone who's been on a data dog dashboard or whatever it might be, you have these beautiful dashboards, thousands of them to give you some cut as to what is the health of your system.\nNow, something will break invariably in production.\nThen what happens next?\nThe next step as I see it is what I call dashboard dumpster diving, right?\nRight?\nYou'll go through all these different thousands of dashboards to try to find the one that explains what happened.\nAnd you'll try to have many different people doing it in parallel.\nAt some point, you might come up with some sort of promising lead being like, okay, maybe that was it.\nThat's the dashboard that kind of explains what happened or that's the log that kind of explains what happened.\nThen you want to connect it to some sort of change you made in your system, right?\nAs we think about root cause analysis, it's typically you're trying to connect it to some particular change in the system, whether it's a pull request or a change of your configuration files, whatever it might be, right?\nRight?\nAnd that's where you start say that's the second stage of your troubleshooting which you stare aggressively at your code base till something you know some sort of uh inspiration hits you and then most of the time it doesn't hit you and then you kind of bring more teams into the mix because you know it's maybe not be your issue and suddenly you have 30 40 50 100 people in a slack incident channel trying to figure out what happened and this loop keeps going on and on and on, right?\nSo the status quo of what incident production incident debugging looks like clearly is is not optimal and I think it's only going to get worse based for all the reasons I talked about earlier.\nOkay.\nAnd obviously this problem has been around since software has been written and it's not like we're the first people to think about thinking of this issue, right?\nThe problem is that the existing approaches we've taken to troubleshooting or using machine learning or AI towards it have not worked and I don't believe will work for really fundamental reasons, right?\nSo the first one is what we call AI ops broadly speaking, which is we're using traditional machine learning and statistical anomaly detection type techniques to help figure out what happened, right?\nThe problem is if any of you have actually tried these techniques in production systems, it leads to too many false positives.\nYour system is too complex.\nIt's too dynamic.\nAnd if you just try to come up with some sort of numerical representation of your data, it's going to be not representative enough.\nAnd what you'll see is that you'll have thousands of alerts happening.\nMaybe one of them is useful, but you just don't know which one, right?\nSo typically leads to more signal, sorry, more noise than signal is what AI ops has led to sadly.\nOkay, now we have this new world of LLMs.\nOkay, so one option is okay, let me I'm sure many people here have taken a log and put in chat GPT and said explain to me what happened.\nWhat what's going on in this log, right?\nThat's something I think all of us have done.\nNow that's okay if you know which log you want to look at.\nBut if I'm actually dealing with production grade systems, you're going to have terabytes of data.\nYou might have a trillion logs.\nWhich one do I look at?\nYou can't take all of these different logs, the trillion logs, and put into context, right?\nEven if you have infinite context, it doesn't matter.\nThe size of these systems are so large that forget about context window.\nIt doesn't even fit into memory.\nIt doesn't even fit into a cluster.\nThat's why you have such difficult retention policies for data, right, for logs and metrics.\nAnd second, the problem with these LLMs are is that they don't have a really good understanding of the numerical representation of the data.\nSo they have a good semantic understanding.\nThey don't have a good numerical representation and also the context isn't big enough.\nOkay.\nNow, the third thing we might think about is let's build an agent, right?\nLike let's build a React style agent.\nThe problem with that is that if you think about these React style agents, what they're going to do is they're going to assume you have some access to some sort of runbook, some sort of meta workflow that they can rely on to help you make the decision of what next tool to call.\nThe problem is any runbook you actually put into place is deprecated the second you create it.\nI don't know how many of you have used runbooks, but typically what we found in my experience and the team's experience is that they're typically deprecated by the time they're built, right?\nAnd so that workflow that the agent is going to go through is not going to be um is is is just not going to be optimal.\nAnd also if you try to make it do a much more broad search of your system, if you give it these simple tools, it's going to be take too long, right?\nIf you just put it in into like a loop tool to tool calling loop, it might take days to run if if it doesn't time out, right?\nAnd typically if you try to solve an incident, you need to solve it in two to five minutes for it to be really useful, right?\nSo every minute counts when things are down.\nSo as a result, none of these three things if you do them just by themselves is enough to really troubleshoot.\nThere's fundamental issues in all of them that I think need to be solved by thinking about them in a more collective way.\nAnd that's really what we're trying to do at Traversal, right?\nWhat you need to do with Traversal is what we're trying to do with Traversal is really good out of sample autonomous troubleshooting, which is that you have a new incident, we've never seen it before.\nCan you troubleshoot it from first principles debugging?\nAnd to do so, I think we need to combine a few different ideas.\nThe first one being statistical, the second one being semantics, and then the third one being a novel agentic control flow.\nAnd with statistics, what I mean is is causal machine learning.\nSo that's where a lot of our research came.\nSo the idea of causal machine learning is this idea of being correlation isn't causation.\nSo how do you get these AI systems to pick up cause and effect relationships from data programmatically?\nThat's what we spend a lot of time thinking about.\nAnd obviously that problem shows up a lot in production incidents because typically when something breaks a lot of things break around them, right?\nSo there's a lot of correlated failures which are not the root cause.\nAnd so thinking about it programmatically is what the study of causal machine learning is.\nThe second being semantics, right?\nWhich is actually trying to push the limits of what these reasoning models can give you uh to help you understand the semantic rich semantic context that exists in in log fields in the metadata source of the metric and so on so forth, right?\nOr in code itself, right?\nAnd so by combining causal machine learning, which is the best of what statistics gives you, and reasoning models, which is the best of what semantics gives you, you now have at least the tools, the basic tools to put into place so that you can actually deal with this issue.\nNow you have to figure out how do you actually make this work in an agentic system.\nAnd what we found is this idea of swarms of agent where you have these thousands of parallel agentic tool calls happening giving you this kind of exhaustive search through all of your telemetry in some sort of efficient way.\nThat's what brings it together and helps you actually deal with this issue.\nRight?\nSo just to repeat, it's statistics which is causal machine learning, semantics which is these reasoning models and this novel agentic control flow which call the swarms of agent.\nAll of this put together in the right elegant way is what actually helps you autonomously troubleshoot.\nRight?\nAnd a lot of the work we we rely on is based on our years of research years of experience as researchers.\nWe've written a number of papers on these various different fields and also relying on a lot of the research that has happened uh in general in the field over the last couple of years that we're relying on to actually make this into a reality.\nUm, and so if you think about the the troubleshooting workflow we talked about earlier and all the pains of it, each of the different things can help remove or alleviate some of those pains.\nSo the idea of finding the promising lead from your sea of information, that's where this agent swarm and causal machine learning put together really help.\nAnd then from the promising lead connecting it to a specific change in your system whether it's a pull request or change log that's a lot of the work that's happening in code agents and also vector search relying on it.\nUh as this get better we get better, right?\nAnd as a result because you're building this context in real time and agents are doing it they're pulling in the right team at the with the right context or the right time and so don't people want to get pulled into an incident being like I don't really know why I'm being pulled in here which I'm sure many of you have been experienced in your time as engineers.\nUm, and so now I'm going to hand it over to Matt to actually talk through a real life case study uh that we've done with one of our customers.\nHi everybody.\nI'm Matt as Anish said.\nThank you.\nUh, and no, I I don't own any of their outfits.\nUm,\nso I'm going to tell you a little bit about how I got involved with Traversal.\nI'm going to show you how we are helping out some of our customers.\nSo, uh, in my career I spent most my time in high frequency trading.\nUh what I wanted to spend my time doing there was uh you know focusing and writing beautiful code.\nWhat I ended up doing much more often than not was debugging production incidents.\nSo I got sick of this as you might understand and uh very happily quit.\nSometime later I I found myself in a class on causal AI.\nUh the guy teaching the class seemed pretty smart.\nIt uh looking back then it may have just been the fact that he was much better dressed than your average computer science professor and he had a you know a fancy accent.\nUm but he uh he mentioned in class one day sort of an off-hand comment it seemed that oh you might be able to use causal AI to automate incident remediation workflows and I'm sitting in the back back of the class and my head explodes like this sounds like an amazing idea and so I casually come up to him at the end of class and say you know maybe we might want to do a research project on this and uh little did I know that at the time he had actually started a company to solve this problem so he invited me to join him on that journey and very grateful for that.\nAnd so fast forward a year though and we have uh we built something that we're quite proud of and I'll I'll show you how it works.\nUh but to begin uh I'm going to be talking about a client of ours, Digital Ocean.\nDigital Ocean is a cloud provider.\nThey serve hundreds of thousands of customers every day.\nAnd I'm going to tell you about what uh the life of an on call engineer was like prior to Traversal.\nSo, imagine you're in the middle of a productive workday.\nYou're focused day in.\nYou're writing code.\nUm, and then you get hit with a\n\n\nA message, uh, describing something that's broken horribly.\nIt's, it's causing issues for customers.\nIt might say something like, \"Powered some potential compromise of some host assigned to, you know, a bad application.\"\nAnd my apologies in advance here.\nThis is not a demo per se.\nThis is us telling you in the real world how, uh, we are, we are solving issues for our customers.\nSo apologies for the redactions that you're seeing here.\nSo you get this context, and then you get thrown into an incident Slack channel.\nAnd in this Slack channel, you and 40, 50, 60 other engineers begin frantically searching to find what's the cause of the customer issue, right?\nBut you're not looking through some documents, you're not looking through a database table.\nYou're looking through hundreds of millions of metrics which are viewable on thousands of dashboards.\nAnd beyond this, you also have tens of billions of logs that you might want to find, and these are coming from thousands of services.\nAnd what's the thing you're looking for here?\nYou're looking for a something that's comparatively microscopic.\nSo this might be a single log that describes the thing that went wrong, the root cause of the incident.\nAnd you know, if you're lucky, after a few hours of everybody frantically searching, the incident gets resolved, and you know, everybody can go back to work.\nThat is until the next production incident comes, and the cycle repeats itself.\nSo this is a very familiar situation to me.\nUnfortunately, it may be a very similar situation to all of you, but things have changed for Digital Ocean.\nSo what Traversal has been able to do for Digital Ocean is make their mission-critical infrastructure far more resilient.\nSo you'll see here that, uh, meantime to resolution, uh, MTR, has reduced pretty dramatically for Digital Ocean.\nWe've measured that about a 40% reduction in the amount of time that it takes to find and resolve production incidents.\nAnd all of these minutes mean a lot of pain for an engineer that's, that's now been removed, and also thousands of dollars for each minute.\nSo now I'll be able to show you how this works.\nSo in the world post Traversal, rather than this frantic search going on all the time, when an instant kicks off, the Traversal AI, the ambient Traversal AI, begins its investigation.\nAnd the thing that it begins its investigation with is the same little bit of context that engineers get when the incident starts.\nAnd given the small amount of context, Traversal AI orchestrates a swarm of expert AI SREs to sift through petabytes of observability data, all in parallel.\nAnd so what was done previously manually is done exhaustively and automatically.\nAnd then after about five minutes, Traversal comes back to the users right where they are in the incident Slack channel and tells them what happened.\nSo here you can see that, uh, Traversal identified an issue.\nThere was a deployment that introduced changes, a cascade of issues throughout the entire system.\nAnd when engineers see this, they can roll it back.\nThey can move on and and get back to their good work.\nAnd you'll note here that, uh, the engineers at Digital Ocean noted that this was this was the thing that solved the issue.\nThis was the correct finding.\nAnd this is happening all the time.\nEngineers that want to dive in further can look in the Traversal UI, where you have a wealth of information that Traversal unearths, uh, describing what happened with the incident.\nIt cites relevant observability data, just like any good engineer would.\nIt gives you confidence levels for the potential root cause candidates.\nIt explains its reasoning.\nAnd if you want to dive in even further, Traversal allows you to interact with an, uh, AI-generated impact map.\nAnd you can even ask follow-up questions to Traversal to describe, to ask questions like, \"How does this incident impact the part of the stack that I care the most about?\"\nAnd this entire experience is exactly the kind of thing that I was dying for in my previous roles and so excited to share that it's now a reality.\nSo thank you.\nUh, so but this is not just happening for Digital Ocean.\nWe're working across a very heterogeneous group of, uh, enterprise environments.\nUh, so you'll see here the thing that I want you to focus on here is that we're talking to basically every observability tool out there, and we're talking to them on a massive scale.\nWe're talking trillions of logs.\nSo yes, it's an AI agents problem, and I, I like thinking about the AI agents problem, but in reality, this is just as much an AI infrastructure problem.\nFurthermore, the problem that we're solving here is one where we have a massive set of data, and we're looking for this small piece of information that's telling you everything that you need to know.\nThis is sort of a needle in the haystack problem.\nAnd we're focused right now on observability.\nBut there are plenty of other domains where there are similar principles that can be applied.\nIn my experience, that when you're doing network observability, you're working on cyber security, you find similar patterns here that I hope that you all in your respective domains can take from this that these strategies of exhaustive search and swarms of agents can be applied in this in these domains as well.\nUh, not only is this an amazing problem to work on, frankly, we've assembled an amazing group of people to do it.\nUh, we've got AI researchers from the top AI labs in the world that that are pushing the limits of what AI, what AI can do.\nWe have people from top dev tools companies who know what it takes to build a tool that developers love to use.\nWe have fantastic AI product engineers who know who know how to make delightful AI products.\nAnd of course, we've got high-frequency quant finance traders who can deal with pain and know what the pain of production downtime actually means.\nBut I think what's, uh, most special about the Traversal team is not necessarily the skills that that that we bring to the table, but you know, it's, it's really unusual.\nIt's really rare to be able to find a group of people that aren't really all out there for themselves.\nAnd everybody's working for the betterment of each other.\nAnd we have a lot of fun coming into work, and everybody loves showing up to the office.\nAnd this is what makes Traversal, in my opinion, an amazing place to work.\nAnd so if the team or the problem sounds interesting to you, please, uh, scan the QR code, look at one of these websites, and, uh, help us try to create this picture of me that we have right here for all all the engineers in the world.\nThank you very much.\n",
  "dumpedAt": "2025-07-21T18:43:26.034Z"
}