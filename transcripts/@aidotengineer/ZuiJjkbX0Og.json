{
  "episodeId": "ZuiJjkbX0Og",
  "channelSlug": "@aidotengineer",
  "title": "How LLMs work for Web Devs: GPT in 600 lines of Vanilla JS - Ishan Anand",
  "publishedAt": "2025-07-13T17:30:06.000Z",
  "rawLines": [
    {
      "lang": "en",
      "text": "[Music]",
      "offset": 0.37,
      "duration": 7.439
    },
    {
      "lang": "en",
      "text": "Okay.",
      "offset": 15.36,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "Thank you for coming bright and early uh",
      "offset": 17.359,
      "duration": 6.401
    },
    {
      "lang": "en",
      "text": "9:00 a.m. at the start of the conference",
      "offset": 20.88,
      "duration": 8.239
    },
    {
      "lang": "en",
      "text": "uh for LMS for web devs uh GPT in 600",
      "offset": 23.76,
      "duration": 8.479
    },
    {
      "lang": "en",
      "text": "lines of vanilla JavaScript. Um I think",
      "offset": 29.119,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "you guys are going to have a great",
      "offset": 32.239,
      "duration": 2.881
    },
    {
      "lang": "en",
      "text": "conference. I was here last year. I",
      "offset": 33.28,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "thoroughly enjoyed it. Um and I think",
      "offset": 35.12,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "this is a great way to kick things off.",
      "offset": 37.36,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "If you're just coming to this field or",
      "offset": 39.36,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "this conference without any background",
      "offset": 41.92,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "in machine learning, this is your",
      "offset": 43.6,
      "duration": 4.799
    },
    {
      "lang": "en",
      "text": "missing AI degree. That'll help make the",
      "offset": 46,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "rest of the conference, I think,",
      "offset": 48.399,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "hopefully a lot more valuable.",
      "offset": 49.44,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "So, if you're just joining us and came",
      "offset": 52.239,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "in, you can go to spreadsheets are all",
      "offset": 55.44,
      "duration": 5.279
    },
    {
      "lang": "en",
      "text": "you need. Um, and there's a Discord link",
      "offset": 57.199,
      "duration": 6.481
    },
    {
      "lang": "en",
      "text": "in the upper menu. uh click on that and",
      "offset": 60.719,
      "duration": 5.681
    },
    {
      "lang": "en",
      "text": "then go to the AI engineer world's fair",
      "offset": 63.68,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "2025 room and then there's a link to",
      "offset": 66.4,
      "duration": 5.759
    },
    {
      "lang": "en",
      "text": "download the GPT2 model weights in the",
      "offset": 69.2,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "pinned message at the top. Takes a",
      "offset": 72.159,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "little while to download that so I would",
      "offset": 74.32,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "download that and get started uh because",
      "offset": 75.84,
      "duration": 4.959
    },
    {
      "lang": "en",
      "text": "of the Wi-Fi might be a little bit slow.",
      "offset": 78.479,
      "duration": 4.881
    },
    {
      "lang": "en",
      "text": "We're going to be using that in a bit.",
      "offset": 80.799,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "Okay, we're going to do something",
      "offset": 83.36,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "special today. Uh it is a talk and I",
      "offset": 84.96,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "will be doing a lot of talking at you",
      "offset": 88.72,
      "duration": 3.439
    },
    {
      "lang": "en",
      "text": "and we'll be running code. So it is a",
      "offset": 90.4,
      "duration": 6.719
    },
    {
      "lang": "en",
      "text": "workshop but our mission today is to",
      "offset": 92.159,
      "duration": 8.64
    },
    {
      "lang": "en",
      "text": "break Clark's third law. You might be",
      "offset": 97.119,
      "duration": 5.121
    },
    {
      "lang": "en",
      "text": "familiar with the science fiction author",
      "offset": 100.799,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "Arthur C. Clark and his famous maxim",
      "offset": 102.24,
      "duration": 5.199
    },
    {
      "lang": "en",
      "text": "that any sufficiently advanced",
      "offset": 105.759,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "technology is indistinguishable from",
      "offset": 107.439,
      "duration": 4.881
    },
    {
      "lang": "en",
      "text": "magic. And nowhere is that you know more",
      "offset": 109.36,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "true or relevant today than when it",
      "offset": 112.32,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "comes to large language models. These",
      "offset": 114.56,
      "duration": 6.08
    },
    {
      "lang": "en",
      "text": "are seemingly magical machines that can",
      "offset": 116.64,
      "duration": 7.04
    },
    {
      "lang": "en",
      "text": "produce lielike text, automate tasks as",
      "offset": 120.64,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "agents, and maybe even replace humans in",
      "offset": 123.68,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "certain contexts.",
      "offset": 125.92,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "And if you ask somebody how these work",
      "offset": 127.92,
      "duration": 4.959
    },
    {
      "lang": "en",
      "text": "or you go online, you're liable to get",
      "offset": 130.72,
      "duration": 4.879
    },
    {
      "lang": "en",
      "text": "the impression that you need to have",
      "offset": 132.879,
      "duration": 5.761
    },
    {
      "lang": "en",
      "text": "semesters of linear algebra and calculus",
      "offset": 135.599,
      "duration": 5.521
    },
    {
      "lang": "en",
      "text": "before you can begin taking your first",
      "offset": 138.64,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "machine learning class and understand",
      "offset": 141.12,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "how these work. And yes, that's true if",
      "offset": 142.64,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "you want to be a machine learning",
      "offset": 146.16,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "engineer. But if you just want to",
      "offset": 147.2,
      "duration": 3.679
    },
    {
      "lang": "en",
      "text": "understand how these work and you're a",
      "offset": 149.28,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "builder on top of them, I'm here to tell",
      "offset": 150.879,
      "duration": 5.121
    },
    {
      "lang": "en",
      "text": "you that is not true. Do not believe",
      "offset": 153.36,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "them. You don't need all that",
      "offset": 156,
      "duration": 3.599
    },
    {
      "lang": "en",
      "text": "sophistication if you just want to have",
      "offset": 158.16,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "a really accurate model of how a",
      "offset": 159.599,
      "duration": 6.161
    },
    {
      "lang": "en",
      "text": "transformer works. I know because I was",
      "offset": 161.68,
      "duration": 6.16
    },
    {
      "lang": "en",
      "text": "here last year. I gave a talk called",
      "offset": 165.76,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "spreadsheets are all you need where I",
      "offset": 167.84,
      "duration": 3.679
    },
    {
      "lang": "en",
      "text": "showed an Excel worksheet that",
      "offset": 169.36,
      "duration": 4.959
    },
    {
      "lang": "en",
      "text": "implemented all of GPT2 small entirely",
      "offset": 171.519,
      "duration": 5.761
    },
    {
      "lang": "en",
      "text": "impure Excel functions. And then I took",
      "offset": 174.319,
      "duration": 4.721
    },
    {
      "lang": "en",
      "text": "that spreadsheet and I turned into a",
      "offset": 177.28,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "class that I taught online where I took",
      "offset": 179.04,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "people tabby tab through how the entire",
      "offset": 182,
      "duration": 5.92
    },
    {
      "lang": "en",
      "text": "model works. And not everyone was even",
      "offset": 184.64,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "an engineer. So one of my favorites is",
      "offset": 187.92,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "this guy. This Joe here is a CFO. he's",
      "offset": 190,
      "duration": 6.8
    },
    {
      "lang": "en",
      "text": "just naturally good ex at Excel and that",
      "offset": 193.92,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "gave him everything he needed combined",
      "offset": 196.8,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "with a sheet to understand how a large",
      "offset": 198.48,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "language model works on the inside and",
      "offset": 200.48,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "he says this is great I had no",
      "offset": 202.64,
      "duration": 4.239
    },
    {
      "lang": "en",
      "text": "experience with machine learning or AI",
      "offset": 205.28,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "concepts before yet he was able to walk",
      "offset": 206.879,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "away with a very good understanding of",
      "offset": 209.12,
      "duration": 3.679
    },
    {
      "lang": "en",
      "text": "how they work so what I'm going to do",
      "offset": 210.56,
      "duration": 5.599
    },
    {
      "lang": "en",
      "text": "today is compress that class which is",
      "offset": 212.799,
      "duration": 4.961
    },
    {
      "lang": "en",
      "text": "about eight hours down to these two",
      "offset": 216.159,
      "duration": 3.521
    },
    {
      "lang": "en",
      "text": "hours today and explain how the",
      "offset": 217.76,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "transformer works and I show up today or",
      "offset": 219.68,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "this year at the conference with this",
      "offset": 223.12,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "instead of Excel because not every one",
      "offset": 225.44,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "of us have a job that require us to be",
      "offset": 228.08,
      "duration": 4.879
    },
    {
      "lang": "en",
      "text": "really good at Excel. Uh we're using a",
      "offset": 230.08,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "vanilla JavaScript implementation",
      "offset": 232.959,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "because a lot of folks who come to AI",
      "offset": 234.72,
      "duration": 4.719
    },
    {
      "lang": "en",
      "text": "engineering as a field have a web",
      "offset": 237.04,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "development or full stack JavaScript",
      "offset": 239.439,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "background. And so if that's your",
      "offset": 241.28,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "background, you are perfect the way you",
      "offset": 243.599,
      "duration": 5.121
    },
    {
      "lang": "en",
      "text": "are. You don't need to learn Python if",
      "offset": 245.92,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "you just want to understand how a model",
      "offset": 248.72,
      "duration": 2.239
    },
    {
      "lang": "en",
      "text": "works and you're still going to use",
      "offset": 250,
      "duration": 3.439
    },
    {
      "lang": "en",
      "text": "TypeScript and X.js GS around the model,",
      "offset": 250.959,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "but you still want to have a good",
      "offset": 253.439,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "understanding of how it works.",
      "offset": 254.64,
      "duration": 5.119
    },
    {
      "lang": "en",
      "text": "So today's approach is I'm going to give",
      "offset": 257.199,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "you the background to understand the",
      "offset": 259.759,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "code and we're going to take a a brief",
      "offset": 261.199,
      "duration": 5.361
    },
    {
      "lang": "en",
      "text": "walkthrough of it. I'm going to focus",
      "offset": 263.199,
      "duration": 6.241
    },
    {
      "lang": "en",
      "text": "more on the why than on the what. So",
      "offset": 266.56,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "we'll take a look at the code, but I'm",
      "offset": 269.44,
      "duration": 2.8
    },
    {
      "lang": "en",
      "text": "going to spend a lot of time building",
      "offset": 270.96,
      "duration": 3.679
    },
    {
      "lang": "en",
      "text": "intuition and background to understand",
      "offset": 272.24,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "the code.",
      "offset": 274.639,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "And then instead of complex equations,",
      "offset": 276.56,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "I'm going to use analogies and examples",
      "offset": 278.72,
      "duration": 5.84
    },
    {
      "lang": "en",
      "text": "to make it more tangible.",
      "offset": 281.36,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "Okay? And the background you need to",
      "offset": 284.56,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "have is first of all just motivation uh",
      "offset": 286.16,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "and a curiosity understand how these",
      "offset": 288.56,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "work on the inside. Uh any science,",
      "offset": 290.24,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "technology, engineering background is",
      "offset": 293.28,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "sufficient. Prior programming experience",
      "offset": 295.28,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "especially in JavaScript. Uh but you",
      "offset": 297.52,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "don't need to know React or Vue. We're",
      "offset": 299.44,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "going to just use vanilla JavaScript.",
      "offset": 301.6,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "and then some awareness I would call it",
      "offset": 303.52,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "of linear algebra meaning you just need",
      "offset": 305.919,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "to know what a matrix multiplication is.",
      "offset": 307.6,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "Uh you don't need to be a hot shot",
      "offset": 310.639,
      "duration": 4.881
    },
    {
      "lang": "en",
      "text": "JavaScript ninja. You don't need prior",
      "offset": 313.28,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "AI or ML background and you don't need",
      "offset": 315.52,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "you know deep calculus or linear algebra",
      "offset": 318.32,
      "duration": 3.599
    },
    {
      "lang": "en",
      "text": "fluency.",
      "offset": 320.08,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "Okay. And the key resources for today",
      "offset": 321.919,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "are going to be our JavaScript",
      "offset": 324.24,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "implementation of GPT2. Uh use Chrome on",
      "offset": 325.759,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "the desktop and if you go to",
      "offset": 328.8,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "spreadsheets are all you need.ai AI uh",
      "offset": 330.479,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "and I I apologize that is a long domain",
      "offset": 333.52,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "name /gpt2. It'll load up this",
      "offset": 335.759,
      "duration": 4.961
    },
    {
      "lang": "en",
      "text": "implementation and it'll run locally in",
      "offset": 338.96,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "your browser. Uh there's a discord",
      "offset": 340.72,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "server where I've dropped some links and",
      "offset": 342.96,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "if you've got questions feel free to",
      "offset": 345.039,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "drop them in there as well.",
      "offset": 346.56,
      "duration": 7.199
    },
    {
      "lang": "en",
      "text": "Okay. So this is a simplified diagram of",
      "offset": 349.44,
      "duration": 6.8
    },
    {
      "lang": "en",
      "text": "GPD2. It does not look like your classic",
      "offset": 353.759,
      "duration": 5.201
    },
    {
      "lang": "en",
      "text": "transformer diagram intentionally and it",
      "offset": 356.24,
      "duration": 4.799
    },
    {
      "lang": "en",
      "text": "will serve as our road map for what",
      "offset": 358.96,
      "duration": 3.679
    },
    {
      "lang": "en",
      "text": "we're going to do throughout the today's",
      "offset": 361.039,
      "duration": 4.641
    },
    {
      "lang": "en",
      "text": "workshop. I'm going to start by just",
      "offset": 362.639,
      "duration": 6.4
    },
    {
      "lang": "en",
      "text": "giving you some background on LLMs and",
      "offset": 365.68,
      "duration": 5.92
    },
    {
      "lang": "en",
      "text": "our JavaScript implementation of GPT2.",
      "offset": 369.039,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "How to get it running, how to get it",
      "offset": 371.6,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "started, and then we're going to focus",
      "offset": 372.88,
      "duration": 5.599
    },
    {
      "lang": "en",
      "text": "on these three areas for most of it. And",
      "offset": 375.52,
      "duration": 5.84
    },
    {
      "lang": "en",
      "text": "that's tokenization, embeddings, and",
      "offset": 378.479,
      "duration": 4.881
    },
    {
      "lang": "en",
      "text": "then the language head. And I've focused",
      "offset": 381.36,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "on those because that's the input and",
      "offset": 383.36,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "the output of the model and those are",
      "offset": 385.199,
      "duration": 3.361
    },
    {
      "lang": "en",
      "text": "the most important to have the",
      "offset": 387.28,
      "duration": 2.8
    },
    {
      "lang": "en",
      "text": "background and understanding if you're",
      "offset": 388.56,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "going to be building systems around and",
      "offset": 390.08,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "on top of LLMs.",
      "offset": 392.479,
      "duration": 5.041
    },
    {
      "lang": "en",
      "text": "We will cover the inside number",
      "offset": 394.96,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "crunching part that's attention and the",
      "offset": 397.52,
      "duration": 4.799
    },
    {
      "lang": "en",
      "text": "multi-layer perceptron at a pretty high",
      "offset": 400,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "level. I'll go a little bit more into",
      "offset": 402.319,
      "duration": 4.561
    },
    {
      "lang": "en",
      "text": "the multi-layer perceptron because then",
      "offset": 404.88,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "I can explain about back propagation and",
      "offset": 406.88,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "it serves as kind of a foundation to",
      "offset": 408.96,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "understand how the model learns uh which",
      "offset": 410.88,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "is an important concept",
      "offset": 413.28,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "and then finally I'll talk about the",
      "offset": 415.68,
      "duration": 4.799
    },
    {
      "lang": "en",
      "text": "difference between GPT2 and chat GPT. So",
      "offset": 417.6,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "they were separated by three or four",
      "offset": 420.479,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "years. What were those innovations that",
      "offset": 422.08,
      "duration": 4.559
    },
    {
      "lang": "en",
      "text": "made the model so much seemingly more",
      "offset": 423.919,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "smarter than GPT2?",
      "offset": 426.639,
      "duration": 5.441
    },
    {
      "lang": "en",
      "text": "Hint, it wasn't necessarily uh anything",
      "offset": 429.039,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "algorithmic.",
      "offset": 432.08,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "Okay, so let's start with a quick tour",
      "offset": 433.919,
      "duration": 5.441
    },
    {
      "lang": "en",
      "text": "of our JavaScript implementation of GPT2",
      "offset": 436.96,
      "duration": 6.519
    },
    {
      "lang": "en",
      "text": "and then some background on LMS.",
      "offset": 439.36,
      "duration": 4.119
    },
    {
      "lang": "en",
      "text": "So this is what you get when you load up",
      "offset": 443.68,
      "duration": 5.519
    },
    {
      "lang": "en",
      "text": "GPT2",
      "offset": 447.44,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "uh /GPT2 on the spreadsheets are all you",
      "offset": 449.199,
      "duration": 4.241
    },
    {
      "lang": "en",
      "text": "need website.",
      "offset": 451.68,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "Uh if you scroll down, the first thing",
      "offset": 453.44,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "you're going to want to do, there's a",
      "offset": 455.84,
      "duration": 5.199
    },
    {
      "lang": "en",
      "text": "link here says download the GPT2 small",
      "offset": 457.52,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "CSV. So the first thing you want to do",
      "offset": 461.039,
      "duration": 4.801
    },
    {
      "lang": "en",
      "text": "is go to this page on GitHub. This is",
      "offset": 463.28,
      "duration": 6.24
    },
    {
      "lang": "en",
      "text": "all the model parameters of GPT2 small",
      "offset": 465.84,
      "duration": 5.919
    },
    {
      "lang": "en",
      "text": "in a bunch of CSV files. It's a giant",
      "offset": 469.52,
      "duration": 4.799
    },
    {
      "lang": "en",
      "text": "zip file. Uh you're going to download it",
      "offset": 471.759,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "and unzip it. And when you hear about,",
      "offset": 474.319,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "you know, this model is like a billion",
      "offset": 476.639,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "parameters or 70 billion parameters that",
      "offset": 479.199,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "it's all just a bunch of giant numbers",
      "offset": 481.599,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "and you can think of it as a giant",
      "offset": 483.599,
      "duration": 2.641
    },
    {
      "lang": "en",
      "text": "spreadsheet. And that's literally what",
      "offset": 485.039,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "the zip file is. Once you've downloaded",
      "offset": 486.24,
      "duration": 5.679
    },
    {
      "lang": "en",
      "text": "that zip file and opened it up, what you",
      "offset": 489.12,
      "duration": 5.84
    },
    {
      "lang": "en",
      "text": "want to do is select all of those files",
      "offset": 491.919,
      "duration": 5.521
    },
    {
      "lang": "en",
      "text": "and drag it into this section here. You",
      "offset": 494.96,
      "duration": 6.079
    },
    {
      "lang": "en",
      "text": "can once uh when it uh when it's done",
      "offset": 497.44,
      "duration": 5.439
    },
    {
      "lang": "en",
      "text": "loading all those files, it'll look like",
      "offset": 501.039,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "this. It'll say ready, all model",
      "offset": 502.879,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "parameters loaded. When it's not loaded,",
      "offset": 504.319,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "it'll be in red and it'll say, you know,",
      "offset": 506.639,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "please add the files. And what it's",
      "offset": 508.72,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "doing is it's actually loading all those",
      "offset": 511.039,
      "duration": 4.961
    },
    {
      "lang": "en",
      "text": "GPT2 parameters locally into your",
      "offset": 513.12,
      "duration": 5.599
    },
    {
      "lang": "en",
      "text": "index.db database. And you can see here",
      "offset": 516,
      "duration": 5.919
    },
    {
      "lang": "en",
      "text": "it's basically about 1.5 GB. Now, Chrome",
      "offset": 518.719,
      "duration": 5.361
    },
    {
      "lang": "en",
      "text": "will let you do that uh if you've got",
      "offset": 521.919,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "sufficient disk space on your hard",
      "offset": 524.08,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "drive. But the benefit of doing this is",
      "offset": 525.839,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "now the entire model is running locally",
      "offset": 528.56,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "in vanilla JavaScript on your browser.",
      "offset": 531.519,
      "duration": 5.121
    },
    {
      "lang": "en",
      "text": "In fact to run and debug this, you don't",
      "offset": 534.24,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "need anything else. You could pull the",
      "offset": 536.64,
      "duration": 2.72
    },
    {
      "lang": "en",
      "text": "internet connection and it should still",
      "offset": 537.92,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "work. And the way this is set up is",
      "offset": 539.36,
      "duration": 5.599
    },
    {
      "lang": "en",
      "text": "similar to a Python notebook. If you've",
      "offset": 542.64,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "encountered one of those, we have these",
      "offset": 544.959,
      "duration": 4.481
    },
    {
      "lang": "en",
      "text": "cells uh and every cell has a play",
      "offset": 546.959,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "button which will run what's inside it.",
      "offset": 549.44,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "And there are two types of cells. One",
      "offset": 551.519,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "type of cell is just JavaScript code.",
      "offset": 553.44,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "And you can open these and expand these",
      "offset": 555.6,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "if you want. It's just vanilla",
      "offset": 557.519,
      "duration": 3.201
    },
    {
      "lang": "en",
      "text": "JavaScript code. Our matrices, for",
      "offset": 558.8,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "example, are just simple 2D JavaScript",
      "offset": 560.72,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "arrays. And if I hit play, it'll execute",
      "offset": 562.64,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "this code. And you can see there's a a",
      "offset": 565.68,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "message right there. The other type of",
      "offset": 567.2,
      "duration": 6.4
    },
    {
      "lang": "en",
      "text": "cell is one like this. It's kind of like",
      "offset": 570.56,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "a table or spreadsheet interface. It",
      "offset": 573.6,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "runs a formula and then shows you the",
      "offset": 576.24,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "result. So, it's a way to actually run",
      "offset": 579.12,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "code and see the results very",
      "offset": 581.2,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "immediately. And these formulas are just",
      "offset": 583.279,
      "duration": 4.481
    },
    {
      "lang": "en",
      "text": "raw JavaScript with a little syntactic",
      "offset": 585.44,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "sugar to figure out, you know, if you",
      "offset": 587.76,
      "duration": 3.199
    },
    {
      "lang": "en",
      "text": "reference something, it knows what",
      "offset": 589.6,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "previous table it was.",
      "offset": 590.959,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "I'm going to give you an example of",
      "offset": 593.6,
      "duration": 2.88
    },
    {
      "lang": "en",
      "text": "that.",
      "offset": 594.8,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "So,",
      "offset": 596.48,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "right here is an example. So, here this",
      "offset": 598.32,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "get final tokens is just JavaScript code",
      "offset": 600.64,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "we defined earlier. And this prompt to",
      "offset": 604,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "tokens is literally the DOM ID. And this",
      "offset": 605.92,
      "duration": 7.52
    },
    {
      "lang": "en",
      "text": "let's zoom this one out. This uh this",
      "offset": 609.76,
      "duration": 5.84
    },
    {
      "lang": "en",
      "text": "brackets is basically syntactic sugar",
      "offset": 613.44,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "saying go grab the DOM table that has",
      "offset": 615.6,
      "duration": 7.04
    },
    {
      "lang": "en",
      "text": "this ID. So prompt tokens is up here and",
      "offset": 618.88,
      "duration": 5.199
    },
    {
      "lang": "en",
      "text": "it's just grabbing this thing and",
      "offset": 622.64,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "passing that into that function. So",
      "offset": 624.079,
      "duration": 5.681
    },
    {
      "lang": "en",
      "text": "uh it's all straight vanilla JavaScript.",
      "offset": 627.36,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "But the real benefit is being able to",
      "offset": 629.76,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "debug a model right here without leaving",
      "offset": 632.8,
      "duration": 4.479
    },
    {
      "lang": "en",
      "text": "your browser. So what I'm going to do, I",
      "offset": 634.88,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "can do who here has done like console",
      "offset": 637.279,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "debugging before, right?",
      "offset": 639.92,
      "duration": 5.039
    },
    {
      "lang": "en",
      "text": "Right. So you can do console debugging",
      "offset": 643.279,
      "duration": 4.481
    },
    {
      "lang": "en",
      "text": "right here. So if I say console.log",
      "offset": 644.959,
      "duration": 5.681
    },
    {
      "lang": "en",
      "text": "matches and I open up my dev tools",
      "offset": 647.76,
      "duration": 5.88
    },
    {
      "lang": "en",
      "text": "inspector.",
      "offset": 650.64,
      "duration": 3
    },
    {
      "lang": "en",
      "text": "Let's put that side by side.",
      "offset": 653.68,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "There we go. And I go to the console.",
      "offset": 657.2,
      "duration": 6.079
    },
    {
      "lang": "en",
      "text": "And then I rerun this.",
      "offset": 659.36,
      "duration": 7.039
    },
    {
      "lang": "en",
      "text": "There we go.",
      "offset": 663.279,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "Wait for the layout shifts.",
      "offset": 666.56,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "There we go.",
      "offset": 669.36,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "Separate into words is right there. So",
      "offset": 672.24,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "if I rerun this, you can see right here.",
      "offset": 674.88,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "It might be a little bit hard, but if",
      "offset": 677.12,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "you uh look here, you can see I've",
      "offset": 678.88,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "basically got my console.log statement",
      "offset": 681.04,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "here. If I wanted to know what that",
      "offset": 683.36,
      "duration": 2.8
    },
    {
      "lang": "en",
      "text": "variable is doing, but I can go even",
      "offset": 684.8,
      "duration": 3.599
    },
    {
      "lang": "en",
      "text": "further. I can just type the word",
      "offset": 686.16,
      "duration": 5.239
    },
    {
      "lang": "en",
      "text": "debugger",
      "offset": 688.399,
      "duration": 3
    },
    {
      "lang": "en",
      "text": "and then I rerun it.",
      "offset": 691.92,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "And boom, I'm actually stepping through",
      "offset": 694.32,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "a large language model that was once",
      "offset": 697.12,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "considered too dangerous to release,",
      "offset": 699.04,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "right, with ever leaving my browser. So",
      "offset": 700.88,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "every part of this model, if you were",
      "offset": 702.72,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "like, I really want to understand how",
      "offset": 704.56,
      "duration": 3.279
    },
    {
      "lang": "en",
      "text": "this works, you can step right through",
      "offset": 706,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "it in a familiar language and the",
      "offset": 707.839,
      "duration": 4.961
    },
    {
      "lang": "en",
      "text": "browser, a very familiar IDE. So I'm",
      "offset": 710.24,
      "duration": 6.159
    },
    {
      "lang": "en",
      "text": "going to remove that debugger statement",
      "offset": 712.8,
      "duration": 7.64
    },
    {
      "lang": "en",
      "text": "so it doesn't get in our way later.",
      "offset": 716.399,
      "duration": 4.041
    },
    {
      "lang": "en",
      "text": "And then",
      "offset": 720.48,
      "duration": 3.24
    },
    {
      "lang": "en",
      "text": "There we go.",
      "offset": 727.92,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "Okay, so that's a quick tour of how to",
      "offset": 730.639,
      "duration": 6.081
    },
    {
      "lang": "en",
      "text": "run our JavaScript implementation of",
      "offset": 733.6,
      "duration": 7.6
    },
    {
      "lang": "en",
      "text": "GPT2. Okay. Uh, next up, large language",
      "offset": 736.72,
      "duration": 7.6
    },
    {
      "lang": "en",
      "text": "models. Um, so a large language model",
      "offset": 741.2,
      "duration": 6.079
    },
    {
      "lang": "en",
      "text": "has a really simple job to do. We give",
      "offset": 744.32,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "it a passage of text and it simply",
      "offset": 747.279,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "predicts the next word. technically the",
      "offset": 749.12,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "next token as we'll talk about. So I",
      "offset": 751.36,
      "duration": 5.039
    },
    {
      "lang": "en",
      "text": "might give it the text Mike is quick. He",
      "offset": 753.519,
      "duration": 5.521
    },
    {
      "lang": "en",
      "text": "moves and it'll just output a single",
      "offset": 756.399,
      "duration": 5.601
    },
    {
      "lang": "en",
      "text": "word quickly. It does not by nature",
      "offset": 759.04,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "naturally give you paragraphs of text.",
      "offset": 762,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "So if we want to get more text, what we",
      "offset": 764.32,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "do is we take that output and then we",
      "offset": 766.16,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "append the word we just got out which",
      "offset": 769.68,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "was quickly and put it at the end of the",
      "offset": 771.92,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "thing we originally put in. So then we",
      "offset": 774.24,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "take that additional text. Now we ask it",
      "offset": 775.76,
      "duration": 3.759
    },
    {
      "lang": "en",
      "text": "to run through again with this much",
      "offset": 778.16,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "longer piece say what is the next word",
      "offset": 779.519,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "now and it says oh it's and then we take",
      "offset": 781.44,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "that append it to the original input and",
      "offset": 783.68,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "keep going and ask it what the next",
      "offset": 786.16,
      "duration": 2.56
    },
    {
      "lang": "en",
      "text": "thing is and this is how we generate",
      "offset": 787.36,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "paragraphs of text or code from model it",
      "offset": 788.72,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "is what they call an auto reggressive",
      "offset": 791.44,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "model you simply take the output put it",
      "offset": 793.04,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "back to the input and rerun it now this",
      "offset": 795.04,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "is why if you use our JavaScript",
      "offset": 798.24,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "implementation all it does is predict",
      "offset": 800.24,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "the next word because that is the core",
      "offset": 802.399,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "function if you understand that you",
      "offset": 804.48,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "understand how the rest of it works",
      "offset": 805.839,
      "duration": 4.881
    },
    {
      "lang": "en",
      "text": "So, we've said that large language",
      "offset": 808.56,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "models have this core action of",
      "offset": 810.72,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "completing passages of text and they're",
      "offset": 812.88,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "trained to complete sentences like this",
      "offset": 815.44,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "one. Mike is quick. He moves. And as a",
      "offset": 816.959,
      "duration": 4.801
    },
    {
      "lang": "en",
      "text": "human, you probably understand, you",
      "offset": 819.68,
      "duration": 3.599
    },
    {
      "lang": "en",
      "text": "know, a possible completion is the word",
      "offset": 821.76,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "quickly or maybe the word fast or",
      "offset": 823.279,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "around. But how do we get a computer to",
      "offset": 825.2,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "do that? Well, here's a",
      "offset": 827.6,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "fill-in-the-blank problem that computers",
      "offset": 829.44,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "are really good at. 2 plus 2 equals 4.",
      "offset": 831.76,
      "duration": 4.879
    },
    {
      "lang": "en",
      "text": "It's a math problem. Computers are",
      "offset": 834.88,
      "duration": 3.519
    },
    {
      "lang": "en",
      "text": "really good at math and you can make",
      "offset": 836.639,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "these equations really complex and",
      "offset": 838.399,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "computers can still do them really fast.",
      "offset": 840.72,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "So in effect what researchers have",
      "offset": 842.72,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "figured out how to do is take what is a",
      "offset": 844.32,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "word problem and turn it into a math",
      "offset": 846.639,
      "duration": 5.281
    },
    {
      "lang": "en",
      "text": "problem. In order to do that they have",
      "offset": 848.88,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "to go through a series of steps. First",
      "offset": 851.92,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "what they have to do is they have to map",
      "offset": 854,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "the words in our text to numbers. Here",
      "offset": 855.68,
      "duration": 4.719
    },
    {
      "lang": "en",
      "text": "I've shown it as just a onetoone",
      "offset": 858.56,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "mapping. So Mike goes to 89 is goes to",
      "offset": 860.399,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "9. But in practice, as we'll see, it's a",
      "offset": 863.12,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "long list of numbers called an",
      "offset": 865.199,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "embedding.",
      "offset": 866.48,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "And then we do our number crunching on",
      "offset": 868.639,
      "duration": 3.281
    },
    {
      "lang": "en",
      "text": "them. Here, I've drawn this as just",
      "offset": 870.48,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "simple arithmetic. It's much more",
      "offset": 871.92,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "complex than that, but it's actually",
      "offset": 873.92,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "almost as simple as that. It's just a",
      "offset": 875.68,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "lot of multiplication, addition. There's",
      "offset": 877.6,
      "duration": 5.359
    },
    {
      "lang": "en",
      "text": "an exponentiation in there. Um, but it's",
      "offset": 880.079,
      "duration": 4.801
    },
    {
      "lang": "en",
      "text": "not math you probably haven't seen",
      "offset": 882.959,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "before. It's just a lot of it tediously",
      "offset": 884.88,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "put together.",
      "offset": 887.199,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "And then after all that arithmetic, we",
      "offset": 889.279,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "get a result. Again, it'll be a long",
      "offset": 891.839,
      "duration": 3.281
    },
    {
      "lang": "en",
      "text": "list of numbers. Here, I've simplified",
      "offset": 893.6,
      "duration": 3.679
    },
    {
      "lang": "en",
      "text": "for now, just saying a single number.",
      "offset": 895.12,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "And we look at the resulting number that",
      "offset": 897.279,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "comes back. And that number is going to",
      "offset": 899.04,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "be what it says the next predicted word",
      "offset": 900.959,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "is going to be, but we need to translate",
      "offset": 903.68,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "that back to a word because it's a",
      "offset": 906.079,
      "duration": 2.56
    },
    {
      "lang": "en",
      "text": "number. So then we do the reverse of",
      "offset": 907.36,
      "duration": 2.479
    },
    {
      "lang": "en",
      "text": "what we did at the beginning. Instead of",
      "offset": 908.639,
      "duration": 2.961
    },
    {
      "lang": "en",
      "text": "going from words to numbers, we go from",
      "offset": 909.839,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "numbers to words. And of course, the",
      "offset": 911.6,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "number we get back, numbers are",
      "offset": 914.079,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "continuous. Uh words are discreet,",
      "offset": 915.519,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "doesn't necessarily always cleanly map.",
      "offset": 918,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "we'll get some number like here for",
      "offset": 920.079,
      "duration": 4.241
    },
    {
      "lang": "en",
      "text": "example hypothetically we get 231",
      "offset": 921.92,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "there's nothing in our dictionary that",
      "offset": 924.32,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "maps to it but the closest word in our",
      "offset": 925.68,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "dictionary is quickly which is at 232",
      "offset": 927.92,
      "duration": 6.24
    },
    {
      "lang": "en",
      "text": "but fast is kind of close too of 240 so",
      "offset": 931.36,
      "duration": 4.719
    },
    {
      "lang": "en",
      "text": "what we're going to do is we're going to",
      "offset": 934.16,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "weight the probability distribution of",
      "offset": 936.079,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "these tokens according to how close they",
      "offset": 938,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "are to the predicted number that came",
      "offset": 939.92,
      "duration": 4.479
    },
    {
      "lang": "en",
      "text": "out of our model and that turns into our",
      "offset": 942,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "probability distribution. So then we run",
      "offset": 944.399,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "a random number generator and then we",
      "offset": 946.8,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "pick according to that distribution. One",
      "offset": 948.72,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "thing I want to emphasize is we add the",
      "offset": 950.959,
      "duration": 4.641
    },
    {
      "lang": "en",
      "text": "random number generator in. We could",
      "offset": 953.92,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "always just simply take the closest word",
      "offset": 955.6,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "and that's called greedy or temperature",
      "offset": 957.44,
      "duration": 4.959
    },
    {
      "lang": "en",
      "text": "zero.",
      "offset": 959.759,
      "duration": 4.961
    },
    {
      "lang": "en",
      "text": "Okay. So that gives us this view. You",
      "offset": 962.399,
      "duration": 4.641
    },
    {
      "lang": "en",
      "text": "get some text. We turn that text into",
      "offset": 964.72,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "tokens. We turn those tokens into",
      "offset": 967.04,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "numbers. And then we do some number",
      "offset": 969.12,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "crunching on them. And then we turn",
      "offset": 970.959,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "those numbers into text.",
      "offset": 972.72,
      "duration": 4.239
    },
    {
      "lang": "en",
      "text": "And that gives us our next predicted",
      "offset": 975.279,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "token.",
      "offset": 976.959,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "Okay. The model we are going to be",
      "offset": 979.199,
      "duration": 4.481
    },
    {
      "lang": "en",
      "text": "studying today is GPT2",
      "offset": 980.8,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "uh GPD2 small specifically. There's",
      "offset": 983.68,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "actually multiple versions of GPT2 that",
      "offset": 985.92,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "were released. Uh and that came out in",
      "offset": 988.079,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "2019. So about four years before GPT4",
      "offset": 990,
      "duration": 6.639
    },
    {
      "lang": "en",
      "text": "and 3 years before chat GPT. But don't",
      "offset": 993.519,
      "duration": 5.361
    },
    {
      "lang": "en",
      "text": "let that fool you. This was a model that",
      "offset": 996.639,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "was considered uh too dangerous to",
      "offset": 998.88,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "release when it first came out and was",
      "offset": 1001.04,
      "duration": 5.359
    },
    {
      "lang": "en",
      "text": "state-of-the-art. More importantly, it",
      "offset": 1003.279,
      "duration": 5.601
    },
    {
      "lang": "en",
      "text": "is actually the foundation of most of",
      "offset": 1006.399,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "the state-of-the-art models you have",
      "offset": 1008.88,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "probably used today. And you don't have",
      "offset": 1010.399,
      "duration": 3.041
    },
    {
      "lang": "en",
      "text": "to take my word for it. This is a",
      "offset": 1011.92,
      "duration": 3.359
    },
    {
      "lang": "en",
      "text": "research lab at Luther AI saying",
      "offset": 1013.44,
      "duration": 4.959
    },
    {
      "lang": "en",
      "text": "basically the recipe for building a",
      "offset": 1015.279,
      "duration": 4.721
    },
    {
      "lang": "en",
      "text": "large language model has not",
      "offset": 1018.399,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "fundamentally changed since the",
      "offset": 1020,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "transform was introduced and only",
      "offset": 1021.519,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "slightly tweaked from the language",
      "offset": 1023.44,
      "duration": 5.359
    },
    {
      "lang": "en",
      "text": "models by OpenAI, GPT1 and GPT2.",
      "offset": 1025.36,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "And then in this article, they actually",
      "offset": 1028.799,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "go on to list what the changes are",
      "offset": 1030.4,
      "duration": 6.72
    },
    {
      "lang": "en",
      "text": "between GPD2 and uh so and a",
      "offset": 1032.559,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "state-of-the-art model at the time which",
      "offset": 1037.12,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "was Llama 2 when this was written which",
      "offset": 1038.319,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "was last year. So the way to think about",
      "offset": 1040.24,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "this, and this is a helpful family tree",
      "offset": 1042.319,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "chart of different large language",
      "offset": 1044.079,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "models, is that most of the ones you're",
      "offset": 1046.079,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "familiar with at the top of this tree,",
      "offset": 1048,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "might be hard to see, is chat, GPT,",
      "offset": 1049.679,
      "duration": 5.041
    },
    {
      "lang": "en",
      "text": "llama, bard/gemini,",
      "offset": 1051.76,
      "duration": 6.799
    },
    {
      "lang": "en",
      "text": "GPT4, Claude. They all inherit from",
      "offset": 1054.72,
      "duration": 7.68
    },
    {
      "lang": "en",
      "text": "GPT2. GPT2 is its granddaddy. If you",
      "offset": 1058.559,
      "duration": 6.641
    },
    {
      "lang": "en",
      "text": "understand GPD2, you are 80% of the way",
      "offset": 1062.4,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "to understanding how a state-of-the-art",
      "offset": 1065.2,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "model works under the hood.",
      "offset": 1066.72,
      "duration": 6.319
    },
    {
      "lang": "en",
      "text": "Okay, so now let's dive into the first",
      "offset": 1070.4,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "stage of our model. So that's",
      "offset": 1073.039,
      "duration": 4.681
    },
    {
      "lang": "en",
      "text": "tokenization.",
      "offset": 1074.72,
      "duration": 3
    },
    {
      "lang": "en",
      "text": "Okay, this is where we take the input",
      "offset": 1078.24,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "text and we split it into subword units",
      "offset": 1079.84,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "called tokens. In the example that I",
      "offset": 1082.88,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "like to use, Mike is quick, he moves.",
      "offset": 1085.2,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "Unfortunately, every single word is a",
      "offset": 1087.76,
      "duration": 5.84
    },
    {
      "lang": "en",
      "text": "single token, but it is not unusual for",
      "offset": 1090.32,
      "duration": 6.56
    },
    {
      "lang": "en",
      "text": "a word to be two, three, or more tokens.",
      "offset": 1093.6,
      "duration": 5.439
    },
    {
      "lang": "en",
      "text": "And then these tokens all have ids that",
      "offset": 1096.88,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "are just lists or positions in the",
      "offset": 1099.039,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "dictionary as you see here underneath.",
      "offset": 1100.64,
      "duration": 5.919
    },
    {
      "lang": "en",
      "text": "So let me show you what this looks like.",
      "offset": 1102.72,
      "duration": 6.839
    },
    {
      "lang": "en",
      "text": "So,",
      "offset": 1106.559,
      "duration": 3
    },
    {
      "lang": "en",
      "text": "I'll wait for the Wi-Fi.",
      "offset": 1113.6,
      "duration": 3.72
    },
    {
      "lang": "en",
      "text": "Okay. Well, we get more people in the",
      "offset": 1129.36,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "room, we get we get more Wi-Fi uh",
      "offset": 1130.72,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "issues. Um,",
      "offset": 1132.88,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "so what I wanted to illustrate for you",
      "offset": 1135.2,
      "duration": 5.359
    },
    {
      "lang": "en",
      "text": "is that you can take a word like uh oh,",
      "offset": 1137.28,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "you know what I can do? I I do have a",
      "offset": 1140.559,
      "duration": 6.681
    },
    {
      "lang": "en",
      "text": "backup. Let's do this.",
      "offset": 1142.64,
      "duration": 4.6
    },
    {
      "lang": "en",
      "text": "Okay, this is the version that runs",
      "offset": 1148.799,
      "duration": 2.801
    },
    {
      "lang": "en",
      "text": "locally.",
      "offset": 1150,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "Uh, so what you can do,",
      "offset": 1151.6,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "so you can try this once we get Wi-Fi",
      "offset": 1154.96,
      "duration": 2.959
    },
    {
      "lang": "en",
      "text": "back. I'm going to take the word",
      "offset": 1156.72,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "reindeer and the word reinjury",
      "offset": 1157.919,
      "duration": 7.521
    },
    {
      "lang": "en",
      "text": "and then I'm going to run them up until",
      "offset": 1161.76,
      "duration": 8.44
    },
    {
      "lang": "en",
      "text": "right here, which is the final tokens.",
      "offset": 1165.44,
      "duration": 4.76
    },
    {
      "lang": "en",
      "text": "So these are the tokens for the input",
      "offset": 1170.72,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "prompt we just put in here.",
      "offset": 1173.84,
      "duration": 5.839
    },
    {
      "lang": "en",
      "text": "And you can see the word reinjury was",
      "offset": 1176.4,
      "duration": 5.519
    },
    {
      "lang": "en",
      "text": "turned into multiple tokens. There's a",
      "offset": 1179.679,
      "duration": 4.801
    },
    {
      "lang": "en",
      "text": "space which is part of the token itself",
      "offset": 1181.919,
      "duration": 6.801
    },
    {
      "lang": "en",
      "text": "rein and then jury jur y and they have",
      "offset": 1184.48,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "separate token ids. The thing I want you",
      "offset": 1188.72,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "to pay attention to is reindeer also",
      "offset": 1190.48,
      "duration": 6.16
    },
    {
      "lang": "en",
      "text": "starts as re i n right but it got split",
      "offset": 1193.76,
      "duration": 7.2
    },
    {
      "lang": "en",
      "text": "into three tokens space re i n d e r. So",
      "offset": 1196.64,
      "duration": 6.88
    },
    {
      "lang": "en",
      "text": "this is not like basic string parsing",
      "offset": 1200.96,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "something more complex is going on. And",
      "offset": 1203.52,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "so the natural question is well why the",
      "offset": 1205.84,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "heck are we doing this?",
      "offset": 1207.52,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "Why don't we do something simpler? Why",
      "offset": 1209.679,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "don't we do say word based tokenization?",
      "offset": 1211.28,
      "duration": 3.759
    },
    {
      "lang": "en",
      "text": "We just take every word in the",
      "offset": 1213.84,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "dictionary and give it a number like dog",
      "offset": 1215.039,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "is one, cat is two, and so forth. So",
      "offset": 1217.12,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "that has a couple problems. First is it",
      "offset": 1219.12,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "can't handle unknown or misspelled",
      "offset": 1220.96,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "words. And there are some models, early",
      "offset": 1222.64,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "models that had an unk for unknown",
      "offset": 1224.88,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "token. Um, but when you're grabbing all",
      "offset": 1226.48,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "the text on the internet, you might",
      "offset": 1229.2,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "encounter things you didn't expect.",
      "offset": 1230.96,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "Examples could be languages that you",
      "offset": 1232.64,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "weren't planning for. one of the early",
      "offset": 1234.64,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "models, GPT2, in fact, they tried to",
      "offset": 1236.72,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "take foreign languages out of it and",
      "offset": 1238.559,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "then they magically discovered some",
      "offset": 1240.559,
      "duration": 3.041
    },
    {
      "lang": "en",
      "text": "snuck in and it was actually good at",
      "offset": 1242.24,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "translation. They wouldn't have had that",
      "offset": 1243.6,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "if a lot of words were just simply that",
      "offset": 1245.36,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "were not English were just thrown out.",
      "offset": 1247.6,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "Another example is when they did",
      "offset": 1249.44,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "summarization with it, they realized",
      "offset": 1250.72,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "they can put the too long didn't read",
      "offset": 1252.64,
      "duration": 5.279
    },
    {
      "lang": "en",
      "text": "acronym TL semicolon dr. If they didn't",
      "offset": 1254.48,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "have a token for that, it would have",
      "offset": 1257.919,
      "duration": 2.401
    },
    {
      "lang": "en",
      "text": "been thrown away and it would have lost",
      "offset": 1259.12,
      "duration": 2.96
    },
    {
      "lang": "en",
      "text": "that ability.",
      "offset": 1260.32,
      "duration": 3.359
    },
    {
      "lang": "en",
      "text": "The other problem is that you're going",
      "offset": 1262.08,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "to increase the vocabulary size which is",
      "offset": 1263.679,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "going to increase the size of the model.",
      "offset": 1265.919,
      "duration": 3.521
    },
    {
      "lang": "en",
      "text": "It'll need more parameters if you're",
      "offset": 1267.84,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "going to have more vocabulary. English",
      "offset": 1269.44,
      "duration": 5.119
    },
    {
      "lang": "en",
      "text": "alone is 170,000 words. For perspective,",
      "offset": 1271.52,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "GPD2's vocabulary is only about 50,000.",
      "offset": 1274.559,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "So it's third of that. And then if you",
      "offset": 1277.28,
      "duration": 2.72
    },
    {
      "lang": "en",
      "text": "add additional languages on that and",
      "offset": 1278.559,
      "duration": 3.201
    },
    {
      "lang": "en",
      "text": "you're doing word-based tokenization, it",
      "offset": 1280,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "would get even larger. So in essence, if",
      "offset": 1281.76,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "you do this, you get more memory, more",
      "offset": 1284.4,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "compute, or maybe less performance.",
      "offset": 1286.32,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "So then you're like, well, I'm a",
      "offset": 1288.96,
      "duration": 2.88
    },
    {
      "lang": "en",
      "text": "developer. I'm used to say something",
      "offset": 1290.24,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "like ASKI. Why don't I just do",
      "offset": 1291.84,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "characterbased tokenization? I say A is",
      "offset": 1293.84,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "one, B is two, and do it that way. Well,",
      "offset": 1295.919,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "the first problem is it's going to",
      "offset": 1298.48,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "increase the sequence length. So, you",
      "offset": 1300.08,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "can see this inside the model",
      "offset": 1302.64,
      "duration": 5.039
    },
    {
      "lang": "en",
      "text": "as you go through the model after you",
      "offset": 1306.08,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "get your prompt right here. You can see",
      "offset": 1307.679,
      "duration": 3.761
    },
    {
      "lang": "en",
      "text": "here's where the embeddings. We'll talk",
      "offset": 1310.159,
      "duration": 3.041
    },
    {
      "lang": "en",
      "text": "about those in a second, but you can see",
      "offset": 1311.44,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "Mike is quick. Period. He moves. Each of",
      "offset": 1313.2,
      "duration": 6.479
    },
    {
      "lang": "en",
      "text": "these rows, this matrix has a height",
      "offset": 1316.64,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "that is the size of the number of",
      "offset": 1319.679,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "tokens, right? And that persists through",
      "offset": 1321.12,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "the entire model. So as I keep going, we",
      "offset": 1323.679,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "see again this six height matrix, it's",
      "offset": 1326.48,
      "duration": 4.559
    },
    {
      "lang": "en",
      "text": "going to keep going. If we made every",
      "offset": 1328.799,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "single character its own token, this is",
      "offset": 1331.039,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "going to get a lot larger. Right now,",
      "offset": 1333.919,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "it's just what six tokens high. But if I",
      "offset": 1335.36,
      "duration": 5.84
    },
    {
      "lang": "en",
      "text": "made m i k, each of these characters",
      "offset": 1338.32,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "their own token, this is going to get a",
      "offset": 1341.2,
      "duration": 2.959
    },
    {
      "lang": "en",
      "text": "much larger matrix. So it'll be more",
      "offset": 1342.48,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "memory, more compute to process. The",
      "offset": 1344.159,
      "duration": 4.241
    },
    {
      "lang": "en",
      "text": "other issue is there's low semantic",
      "offset": 1346.64,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "correlation in characters. They don't",
      "offset": 1348.4,
      "duration": 3.759
    },
    {
      "lang": "en",
      "text": "carry a lot of meaning. And a good",
      "offset": 1350.32,
      "duration": 3.359
    },
    {
      "lang": "en",
      "text": "example was this chain letter that went",
      "offset": 1352.159,
      "duration": 2.801
    },
    {
      "lang": "en",
      "text": "around a few decades ago on the",
      "offset": 1353.679,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "internet. And it says, according to",
      "offset": 1354.96,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "research at Cambridge University, it",
      "offset": 1357.28,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "doesn't matter in what order the letters",
      "offset": 1359.039,
      "duration": 3.361
    },
    {
      "lang": "en",
      "text": "in a word are. The only important thing",
      "offset": 1360.72,
      "duration": 3.199
    },
    {
      "lang": "en",
      "text": "is that the first and last letter be at",
      "offset": 1362.4,
      "duration": 3.279
    },
    {
      "lang": "en",
      "text": "the right place. And all the letters are",
      "offset": 1363.919,
      "duration": 3.361
    },
    {
      "lang": "en",
      "text": "jumbled, but you can still read it. And",
      "offset": 1365.679,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "the point is that you don't read",
      "offset": 1367.28,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "characters. You actually read subword",
      "offset": 1369.36,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "units yourself. Um, and so if there's",
      "offset": 1371.12,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "less semantic correlation, it's going to",
      "offset": 1373.36,
      "duration": 3.439
    },
    {
      "lang": "en",
      "text": "be more work for the model to do during",
      "offset": 1374.96,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "training to erase that character",
      "offset": 1376.799,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "boundary and get the pieces that really",
      "offset": 1378.799,
      "duration": 3.201
    },
    {
      "lang": "en",
      "text": "matter.",
      "offset": 1380.4,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "So if character tokenization is too",
      "offset": 1382,
      "duration": 5.039
    },
    {
      "lang": "en",
      "text": "small and word tokenization is too big,",
      "offset": 1384.48,
      "duration": 4.559
    },
    {
      "lang": "en",
      "text": "Goldilock says let's do something in",
      "offset": 1387.039,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "between which is subword tokenization",
      "offset": 1389.039,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "and that's this algorithm called by",
      "offset": 1391.2,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "parent coding. So it's got two phases.",
      "offset": 1392.72,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "The first is the learning phase where",
      "offset": 1394.96,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "you take a large they call it a corpus",
      "offset": 1396.64,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "of text that's gathered from the",
      "offset": 1398.4,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "internet and then we put it through this",
      "offset": 1399.76,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "learning algorithm we'll describe in a",
      "offset": 1401.84,
      "duration": 3.199
    },
    {
      "lang": "en",
      "text": "second and then we get out of it a",
      "offset": 1403.36,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "vocabulary a dictionary of tokens",
      "offset": 1405.039,
      "duration": 4.961
    },
    {
      "lang": "en",
      "text": "and then later when we're processing the",
      "offset": 1408,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "model and asking it to generate text if",
      "offset": 1410,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "we give it some input words we have to",
      "offset": 1412.4,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "retransate it into those tokens that",
      "offset": 1414.08,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "were used during translation during",
      "offset": 1416.64,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "training. So we take the input words we",
      "offset": 1418.48,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "take the vocabulary and we get out",
      "offset": 1420.799,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "tokens.",
      "offset": 1422.799,
      "duration": 3.441
    },
    {
      "lang": "en",
      "text": "This is the research paper that",
      "offset": 1424.559,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "introduced the algorithm to machine",
      "offset": 1426.24,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "learning, but it turns out this",
      "offset": 1428.559,
      "duration": 4.721
    },
    {
      "lang": "en",
      "text": "algorithm is from the 90s. It's actually",
      "offset": 1430.08,
      "duration": 4.719
    },
    {
      "lang": "en",
      "text": "a compression algorithm, as we'll talk",
      "offset": 1433.28,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "about in a second. And it even has some",
      "offset": 1434.799,
      "duration": 3.201
    },
    {
      "lang": "en",
      "text": "Python code you can copy and paste and",
      "offset": 1436.4,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "run. The goal of the algorithm really is",
      "offset": 1438,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "to take the text that's going to be",
      "offset": 1440.799,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "trained on and figure out the most",
      "offset": 1442.64,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "efficient way to represent it. That's",
      "offset": 1444.88,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "really what tokenization is trying to",
      "offset": 1446.72,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "do. And so here's the example from the",
      "offset": 1448.48,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "paper. And what I'm going to do first is",
      "offset": 1450.72,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "I'm going to use this dot to separate",
      "offset": 1453.76,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "out the characters, right? That's going",
      "offset": 1456,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "to tell us essentially each token will",
      "offset": 1457.84,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "be separated by those dots so we can see",
      "offset": 1460.08,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "them individually. At the end of this",
      "offset": 1461.679,
      "duration": 3.201
    },
    {
      "lang": "en",
      "text": "process, you'll see that there are less",
      "offset": 1463.12,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "dots, meaning that we've got more",
      "offset": 1464.88,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "tokens, sorry, a large more number of",
      "offset": 1466.64,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "tokens in our vocabulary, but less",
      "offset": 1469.52,
      "duration": 3.759
    },
    {
      "lang": "en",
      "text": "number of tokens being used to represent",
      "offset": 1471.6,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "the corpus. And in this corpus, we're",
      "offset": 1473.279,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "going to pretend that when we scraped",
      "offset": 1476.08,
      "duration": 3.199
    },
    {
      "lang": "en",
      "text": "the internet, this is all we came up",
      "offset": 1477.919,
      "duration": 3.441
    },
    {
      "lang": "en",
      "text": "with. There are only four words, low,",
      "offset": 1479.279,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "lower, newest, and widest. And you'll",
      "offset": 1481.36,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "notice some of them appear more than",
      "offset": 1483.36,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "once. In fact, they all do. But the",
      "offset": 1484.48,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "reason I'm doing it this way is I want",
      "offset": 1486.4,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "the frequency of the word to be",
      "offset": 1488,
      "duration": 3.039
    },
    {
      "lang": "en",
      "text": "represented, right? I'm trying to",
      "offset": 1489.6,
      "duration": 4.559
    },
    {
      "lang": "en",
      "text": "compress all the the words on the",
      "offset": 1491.039,
      "duration": 4.801
    },
    {
      "lang": "en",
      "text": "internet. And if a word is more",
      "offset": 1494.159,
      "duration": 3.441
    },
    {
      "lang": "en",
      "text": "frequent, I want to know that because if",
      "offset": 1495.84,
      "duration": 3.199
    },
    {
      "lang": "en",
      "text": "it's more frequent, I want to give it",
      "offset": 1497.6,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "more more representation or a more",
      "offset": 1499.039,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "efficient representation.",
      "offset": 1501.36,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "So that dot is going to separate our",
      "offset": 1503.279,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "tokens. And then I'm going to put the",
      "offset": 1504.88,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "underscore to indicate the space",
      "offset": 1506.96,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "character. One caveat in this example,",
      "offset": 1508.48,
      "duration": 4.799
    },
    {
      "lang": "en",
      "text": "the space character is at the end of the",
      "offset": 1511.6,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "token. In GPT2, it's actually at the",
      "offset": 1513.279,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "beginning. And then we're going to start",
      "offset": 1515.36,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "with our vocabulary of just our",
      "offset": 1517.279,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "characters A through Z, all lowercase.",
      "offset": 1519.279,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "Uh we're assuming we're in a lowercase",
      "offset": 1521.679,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "only world here for now. Those are our",
      "offset": 1523.44,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "initial tokens. That's our vocabulary on",
      "offset": 1525.279,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "the right. And then the first thing",
      "offset": 1527.12,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "we're going to do is we're going to",
      "offset": 1529.2,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "count all the adjacent tokens. All the",
      "offset": 1530.88,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "adjacent characters. Right now it's",
      "offset": 1533.44,
      "duration": 2.96
    },
    {
      "lang": "en",
      "text": "there are no tokens other than",
      "offset": 1535.2,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "characters. And we can see E and S",
      "offset": 1536.4,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "occurs nine times, right? Six times in",
      "offset": 1538.96,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "newest and three times in widest. So",
      "offset": 1541.84,
      "duration": 3.439
    },
    {
      "lang": "en",
      "text": "then I'm going to put a table together",
      "offset": 1544.24,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "and I put E next to S has a frequency of",
      "offset": 1545.279,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "nine. And then I'm going to do this for",
      "offset": 1548.24,
      "duration": 3.039
    },
    {
      "lang": "en",
      "text": "all the possible pairs. And then I'm",
      "offset": 1549.36,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "going to take the most frequent pair and",
      "offset": 1551.279,
      "duration": 4.801
    },
    {
      "lang": "en",
      "text": "I'm going to say that's a new token. Why",
      "offset": 1554.24,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "am I doing that? Because if I do that, I",
      "offset": 1556.08,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "can take ENS, I can put them together,",
      "offset": 1558.64,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "and I can pretend they're their own",
      "offset": 1560.64,
      "duration": 3.519
    },
    {
      "lang": "en",
      "text": "character. I'll call it a token. And",
      "offset": 1562.08,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "then I can go back to my corpus and",
      "offset": 1564.159,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "every place there was an ENS, I'm going",
      "offset": 1566.08,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "to replace it with my new ES token. So",
      "offset": 1567.76,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "now I've shrunk the number of tokens",
      "offset": 1570.159,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "need to represent the stuff here on the",
      "offset": 1572.08,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "left. Now I've taken what were separate",
      "offset": 1573.84,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "tokens and combine them together. So I'm",
      "offset": 1576.64,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "using less tokens to represent all this",
      "offset": 1578.72,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "text. And then I can repeat the process.",
      "offset": 1580.48,
      "duration": 6.079
    },
    {
      "lang": "en",
      "text": "I can just say ES next to T occurs nine",
      "offset": 1583.2,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "times. And I can do a whole another",
      "offset": 1586.559,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "table. Now ES is itself now its own",
      "offset": 1588.4,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "character, its own token. So it can be",
      "offset": 1590.64,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "paired with other things that I'm",
      "offset": 1592.96,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "counting and I can see that es with t",
      "offset": 1594.24,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "occurs nine times. So I add that to my",
      "offset": 1597.12,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "vocabulary of tokens. And I go back and",
      "offset": 1599.76,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "I compress my corpus again. Then I keep",
      "offset": 1602.08,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "going and I just simply repeat this",
      "offset": 1605.36,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "process looking for whatever is the most",
      "offset": 1606.88,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "frequent at each pass and making it a",
      "offset": 1608.72,
      "duration": 4.559
    },
    {
      "lang": "en",
      "text": "token and then recompressing the corpus.",
      "offset": 1610.96,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "And after 10 passes you get something",
      "offset": 1613.279,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "like this. Here on the right is our",
      "offset": 1614.96,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "vocabulary of tokens.",
      "offset": 1617.12,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "And then here on the left you can see we",
      "offset": 1619.6,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "have shrunk the number of tokens used to",
      "offset": 1621.76,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "represent the corpus. There are less of",
      "offset": 1623.919,
      "duration": 4.721
    },
    {
      "lang": "en",
      "text": "these dots right than you we saw before",
      "offset": 1625.84,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "and originally. Now the most frequent",
      "offset": 1628.64,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "words became their own tokens right low",
      "offset": 1630.88,
      "duration": 5.84
    },
    {
      "lang": "en",
      "text": "and newest. And even the words that did",
      "offset": 1634.08,
      "duration": 4.959
    },
    {
      "lang": "en",
      "text": "not get their own full token",
      "offset": 1636.72,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "representation we've now represented",
      "offset": 1639.039,
      "duration": 5.64
    },
    {
      "lang": "en",
      "text": "them a lot more efficiently.",
      "offset": 1640.96,
      "duration": 3.719
    },
    {
      "lang": "en",
      "text": "Uh, and you notice that there's some",
      "offset": 1645.44,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "common subword units like low became",
      "offset": 1647.039,
      "duration": 5.361
    },
    {
      "lang": "en",
      "text": "tokens and est became tokens. So, it",
      "offset": 1649.36,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "managed to map to some of the morphes,",
      "offset": 1652.4,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "the parts of speech we use as humans as",
      "offset": 1654.88,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "tokens. But that is just a coincidence.",
      "offset": 1656.96,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "Right now, the model has no",
      "offset": 1660,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "understanding of semantic meaning. Okay,",
      "offset": 1661.12,
      "duration": 5.679
    },
    {
      "lang": "en",
      "text": "so this is the learning algorithm. Now,",
      "offset": 1663.84,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "the tokenization algorithm is really",
      "offset": 1666.799,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "similar. I'm not going to go through it",
      "offset": 1668.88,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "in full detail. I have a video on my",
      "offset": 1670.799,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "YouTube channel where I do go through it",
      "offset": 1673.52,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "in full detail, but for time I'm just",
      "offset": 1675.039,
      "duration": 4.561
    },
    {
      "lang": "en",
      "text": "going to talk about it at a high level.",
      "offset": 1677.52,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "It's essentially similar to the learning",
      "offset": 1679.6,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "algorithm except we're doing it on",
      "offset": 1681.679,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "individual tokens as they come in asking",
      "offset": 1683.52,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "ourselves what would it look like if",
      "offset": 1685.679,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "this word were part of the tokenization",
      "offset": 1687.679,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "process. So let me show you what that is",
      "offset": 1689.6,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "like. So there's a helpful jump to here.",
      "offset": 1692,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "Let's go to tokenization. So the first",
      "offset": 1694.64,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "thing we do is we take our prompt and we",
      "offset": 1696.88,
      "duration": 3.279
    },
    {
      "lang": "en",
      "text": "separating into words. Now, this is just",
      "offset": 1698.64,
      "duration": 2.88
    },
    {
      "lang": "en",
      "text": "a regular expression that came from the",
      "offset": 1700.159,
      "duration": 2.88
    },
    {
      "lang": "en",
      "text": "OpenAI source code when they open",
      "offset": 1701.52,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "sourced it. And we're just parsing it",
      "offset": 1703.039,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "according to this and it's going to",
      "offset": 1704.96,
      "duration": 2.88
    },
    {
      "lang": "en",
      "text": "basically take out punctuation and",
      "offset": 1706.399,
      "duration": 4.481
    },
    {
      "lang": "en",
      "text": "spaces. So, we get these as our words.",
      "offset": 1707.84,
      "duration": 6.48
    },
    {
      "lang": "en",
      "text": "So, Mike is quick. Period gets its own",
      "offset": 1710.88,
      "duration": 5.679
    },
    {
      "lang": "en",
      "text": "token. He and moves. Right now, we're",
      "offset": 1714.32,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "not tokens. We're just separating to",
      "offset": 1716.559,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "words. But do note that the spaces are",
      "offset": 1717.76,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "assigned as part of this separation. So,",
      "offset": 1720.24,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "he and moves have a space in front of",
      "offset": 1722.64,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "them.",
      "offset": 1724.64,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "The next thing we're do is we're going",
      "offset": 1726.96,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "to fetch vocab BPE. This is a file that",
      "offset": 1728.24,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "came from OpenAI when they trained the",
      "offset": 1731.2,
      "duration": 3.359
    },
    {
      "lang": "en",
      "text": "model and it tokenization. This is their",
      "offset": 1732.88,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "dictionary of tokens. So here's when",
      "offset": 1734.559,
      "duration": 4.881
    },
    {
      "lang": "en",
      "text": "they did their training in BP. The most",
      "offset": 1736.88,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "common left token with a right token was",
      "offset": 1739.44,
      "duration": 6.08
    },
    {
      "lang": "en",
      "text": "space with a T. The second most was",
      "offset": 1742.32,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "space followed by an A and so forth.",
      "offset": 1745.52,
      "duration": 4.639
    },
    {
      "lang": "en",
      "text": "I've added two extra columns, rank and",
      "offset": 1747.84,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "score, just to figure out where uh a",
      "offset": 1750.159,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "pair of tokens is in terms relative to",
      "offset": 1752.64,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "the others, how important they were.",
      "offset": 1754.399,
      "duration": 4.721
    },
    {
      "lang": "en",
      "text": "Then this is just a helpful map of",
      "offset": 1757.12,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "tokens to their ids.",
      "offset": 1759.12,
      "duration": 5.039
    },
    {
      "lang": "en",
      "text": "And then finally, there's this, which is",
      "offset": 1762.24,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "prompted tokens. Now, this is not how",
      "offset": 1764.159,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "you'd really want to write a tokenizer.",
      "offset": 1766.88,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "I've set it up to look similar to the",
      "offset": 1768.799,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "Excel version of the matrix. So you can",
      "offset": 1771.039,
      "duration": 2.961
    },
    {
      "lang": "en",
      "text": "watch the video and still be able to",
      "offset": 1772.64,
      "duration": 3.519
    },
    {
      "lang": "en",
      "text": "watch it and and understand it depend no",
      "offset": 1774,
      "duration": 5.279
    },
    {
      "lang": "en",
      "text": "matter which version of uh the Excel",
      "offset": 1776.159,
      "duration": 4.721
    },
    {
      "lang": "en",
      "text": "sheet or the JavaScript version you're",
      "offset": 1779.279,
      "duration": 3.201
    },
    {
      "lang": "en",
      "text": "looking at. But this kind of illustrates",
      "offset": 1780.88,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "the process. So here is quick. We're",
      "offset": 1782.48,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "breaking it apart right here. Let me get",
      "offset": 1784.64,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "presentify.",
      "offset": 1788.24,
      "duration": 3.039
    },
    {
      "lang": "en",
      "text": "There we go. We're breaking it apart",
      "offset": 1790.08,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "into characters here.",
      "offset": 1791.279,
      "duration": 5.201
    },
    {
      "lang": "en",
      "text": "Right quick. And then what we're doing",
      "offset": 1793.6,
      "duration": 4.559
    },
    {
      "lang": "en",
      "text": "is we're looking at each pair of",
      "offset": 1796.48,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "characters. So Q with U, U with I, I",
      "offset": 1798.159,
      "duration": 7.281
    },
    {
      "lang": "en",
      "text": "with C, C with K, and we're saying for",
      "offset": 1802,
      "duration": 5.039
    },
    {
      "lang": "en",
      "text": "each one, where does it fall in that",
      "offset": 1805.44,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "rank of tokens, and we're going to take",
      "offset": 1807.039,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "the most popular one. In this case, it's",
      "offset": 1808.96,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "I and C. And so we've rewritten this as",
      "offset": 1810.88,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "a string of tokens, except the I and C",
      "offset": 1813.84,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "were put together as one token. And then",
      "offset": 1816.08,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "we're simply going to repeat the",
      "offset": 1818.159,
      "duration": 3.041
    },
    {
      "lang": "en",
      "text": "process.",
      "offset": 1819.44,
      "duration": 4.479
    },
    {
      "lang": "en",
      "text": "Let's stop annotation",
      "offset": 1821.2,
      "duration": 4.479
    },
    {
      "lang": "en",
      "text": "and keep going. And we're combined. Then",
      "offset": 1823.919,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "Q and U get combined. Then ICK get",
      "offset": 1825.679,
      "duration": 4.801
    },
    {
      "lang": "en",
      "text": "combined. And finally gets to the point",
      "offset": 1828.559,
      "duration": 3.521
    },
    {
      "lang": "en",
      "text": "it realizes, oh, this is in my token",
      "offset": 1830.48,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "vocabulary. And it turns it into a",
      "offset": 1832.08,
      "duration": 3.599
    },
    {
      "lang": "en",
      "text": "token. Again, I have video if you want",
      "offset": 1833.52,
      "duration": 5.039
    },
    {
      "lang": "en",
      "text": "to see this in in depth and in detail.",
      "offset": 1835.679,
      "duration": 4.561
    },
    {
      "lang": "en",
      "text": "Um,",
      "offset": 1838.559,
      "duration": 3.441
    },
    {
      "lang": "en",
      "text": "but for now, just think of it as the",
      "offset": 1840.24,
      "duration": 2.96
    },
    {
      "lang": "en",
      "text": "same part of the learning process.",
      "offset": 1842,
      "duration": 5.039
    },
    {
      "lang": "en",
      "text": "Really just run small. Now tokenization",
      "offset": 1843.2,
      "duration": 5.839
    },
    {
      "lang": "en",
      "text": "is actually kind of considered by a lot",
      "offset": 1847.039,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "of experts to be a necessary evil. Some",
      "offset": 1849.039,
      "duration": 5.201
    },
    {
      "lang": "en",
      "text": "of the problems that you sometimes",
      "offset": 1852.399,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "encounter with models although the root",
      "offset": 1854.24,
      "duration": 3.679
    },
    {
      "lang": "en",
      "text": "cause is in tokenization it can",
      "offset": 1856.24,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "sometimes make them worse. So the common",
      "offset": 1857.919,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "one is how many Rs are there in",
      "offset": 1860.159,
      "duration": 5.601
    },
    {
      "lang": "en",
      "text": "strawberry uh models don't actually see",
      "offset": 1862.24,
      "duration": 6.24
    },
    {
      "lang": "en",
      "text": "the Rs. And I love this, you know, post",
      "offset": 1865.76,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "from Riley Goodside where if you",
      "offset": 1868.48,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "remember the matrix, the character says,",
      "offset": 1870.88,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "\"Oh, I don't I don't see the numbers. I",
      "offset": 1872.64,
      "duration": 3.039
    },
    {
      "lang": "en",
      "text": "just see, you know, what's inside",
      "offset": 1874.48,
      "duration": 2.64
    },
    {
      "lang": "en",
      "text": "there.\" And that's kind of like what it",
      "offset": 1875.679,
      "duration": 3.761
    },
    {
      "lang": "en",
      "text": "is to the model. You know, it doesn't",
      "offset": 1877.12,
      "duration": 5.039
    },
    {
      "lang": "en",
      "text": "see any of the letters. So, what he's",
      "offset": 1879.44,
      "duration": 5.119
    },
    {
      "lang": "en",
      "text": "done here in this image is strawberry is",
      "offset": 1882.159,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "tokenized multiple different ways",
      "offset": 1884.559,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "depending on whether it's uppercase",
      "offset": 1886.799,
      "duration": 2.961
    },
    {
      "lang": "en",
      "text": "versus lowerase, whether there's a space",
      "offset": 1888.159,
      "duration": 3.441
    },
    {
      "lang": "en",
      "text": "in front of it or not, and whether",
      "offset": 1889.76,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "there's a quote in front of it or not.",
      "offset": 1891.6,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "So to the model, you know, these six",
      "offset": 1894.32,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "words are not all strawberry. They're",
      "offset": 1897.2,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "all six different token patterns. And so",
      "offset": 1899.44,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "it makes it a lot harder and a lot more",
      "offset": 1902,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "work for the model to understand it. If",
      "offset": 1903.44,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "you think about it, you don't actually",
      "offset": 1905.12,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "see the letters either. If somebody",
      "offset": 1906.72,
      "duration": 2.799
    },
    {
      "lang": "en",
      "text": "asked you how many letters are in a",
      "offset": 1908.24,
      "duration": 3.039
    },
    {
      "lang": "en",
      "text": "word, you'd have to stop and think and",
      "offset": 1909.519,
      "duration": 4.241
    },
    {
      "lang": "en",
      "text": "parse it out.",
      "offset": 1911.279,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "Um I said at the beginning, you know,",
      "offset": 1913.76,
      "duration": 3.039
    },
    {
      "lang": "en",
      "text": "you don't want to do word tokenization,",
      "offset": 1915.44,
      "duration": 2.16
    },
    {
      "lang": "en",
      "text": "you don't want to do character",
      "offset": 1916.799,
      "duration": 2.801
    },
    {
      "lang": "en",
      "text": "tokenization. That's not a hard and fast",
      "offset": 1917.6,
      "duration": 4.559
    },
    {
      "lang": "en",
      "text": "rule. That's an empirical rule. And",
      "offset": 1919.6,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "there are research models that have done",
      "offset": 1922.159,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "both. Uh so just know that you know",
      "offset": 1924,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "that's you know maybe a few years from",
      "offset": 1926.559,
      "duration": 2.881
    },
    {
      "lang": "en",
      "text": "now there'll be character-based",
      "offset": 1928.32,
      "duration": 2.8
    },
    {
      "lang": "en",
      "text": "tokenization will be more popular. This",
      "offset": 1929.44,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "is an example of one. The last thing I",
      "offset": 1931.12,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "want to leave you with is that",
      "offset": 1933.519,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "tokenization doesn't have to be just",
      "offset": 1935.12,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "about uh text. It can also be about",
      "offset": 1937.12,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "other things. So here's an example of",
      "offset": 1940.08,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "vision transformer. They use patches of",
      "offset": 1941.44,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "images as tokens. Whimo uses uh",
      "offset": 1943.2,
      "duration": 5.92
    },
    {
      "lang": "en",
      "text": "trajectories in space to prevent",
      "offset": 1946.64,
      "duration": 5.759
    },
    {
      "lang": "en",
      "text": "collisions as tokens.",
      "offset": 1949.12,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "Okay,",
      "offset": 1952.399,
      "duration": 6.841
    },
    {
      "lang": "en",
      "text": "let's briefly check",
      "offset": 1954.64,
      "duration": 4.6
    },
    {
      "lang": "en",
      "text": "how we're doing if this will load.",
      "offset": 1959.519,
      "duration": 4.76
    },
    {
      "lang": "en",
      "text": "There we go. So, this is actually pinned",
      "offset": 1968.32,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "at the top. Uh 9:30. Oh, we're right.",
      "offset": 1970.559,
      "duration": 5.041
    },
    {
      "lang": "en",
      "text": "We're just a minute behind. Okay. So,",
      "offset": 1973.76,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "this is You guys can keep me honest. Uh",
      "offset": 1975.6,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "at in the Discord room at the top is a",
      "offset": 1978.08,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "spreadsheet. I'm of course using a",
      "offset": 1980.08,
      "duration": 2.56
    },
    {
      "lang": "en",
      "text": "spreadsheet to make sure we stay on",
      "offset": 1981.44,
      "duration": 6.64
    },
    {
      "lang": "en",
      "text": "track and on time. Uh okay. So, oh we",
      "offset": 1982.64,
      "duration": 9.08
    },
    {
      "lang": "en",
      "text": "need to do this now.",
      "offset": 1988.08,
      "duration": 3.64
    },
    {
      "lang": "en",
      "text": "There we go. Next up is embeddings. So",
      "offset": 1992.159,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "now we're in the second phase of the",
      "offset": 1994.64,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "input. Uh these are uh token and",
      "offset": 1996.08,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "position embeddings.",
      "offset": 1999.2,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "Okay. So at the beginning of this",
      "offset": 2001.36,
      "duration": 5.84
    },
    {
      "lang": "en",
      "text": "workshop, I talked about how we map",
      "offset": 2004.24,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "words into numbers. And I simplified",
      "offset": 2007.2,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "this process by saying what we're doing",
      "offset": 2008.88,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "is we're taking say the word Mike and",
      "offset": 2010.96,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "we're turning it into a single number uh",
      "offset": 2012.96,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "like 89. But of course that's not what",
      "offset": 2015.039,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "we're really doing. We're actually going",
      "offset": 2017.2,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "to turn it into a long list of numbers",
      "offset": 2019.36,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "called an embedding. Um so even the",
      "offset": 2021.279,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "period for example gets 768 of these",
      "offset": 2023.84,
      "duration": 5.92
    },
    {
      "lang": "en",
      "text": "numbers. And in the case of GPD2 uh the",
      "offset": 2026.559,
      "duration": 6.321
    },
    {
      "lang": "en",
      "text": "dimensionality that list size is 768.",
      "offset": 2029.76,
      "duration": 6.48
    },
    {
      "lang": "en",
      "text": "Every single word gets 768 numbers. And",
      "offset": 2032.88,
      "duration": 7.12
    },
    {
      "lang": "en",
      "text": "you can see that if we go to",
      "offset": 2036.24,
      "duration": 6.319
    },
    {
      "lang": "en",
      "text": "the token embedding section and then",
      "offset": 2040,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "these we'll get to that table in a",
      "offset": 2042.559,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "second. These are the embeddings of our",
      "offset": 2044.399,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "input prompt. And you can type by the",
      "offset": 2046.72,
      "duration": 2.959
    },
    {
      "lang": "en",
      "text": "way I I didn't mention this before. You",
      "offset": 2048.48,
      "duration": 2.32
    },
    {
      "lang": "en",
      "text": "can type anything here in this input",
      "offset": 2049.679,
      "duration": 2.561
    },
    {
      "lang": "en",
      "text": "prompt and it should parse it. Although",
      "offset": 2050.8,
      "duration": 2.64
    },
    {
      "lang": "en",
      "text": "it doesn't handle foreign language as",
      "offset": 2052.24,
      "duration": 2.32
    },
    {
      "lang": "en",
      "text": "well because there's a character",
      "offset": 2053.44,
      "duration": 4.239
    },
    {
      "lang": "en",
      "text": "mismatch on import. Um, but here's Mike",
      "offset": 2054.56,
      "duration": 5.359
    },
    {
      "lang": "en",
      "text": "is quick. Period. And each of these gets",
      "offset": 2057.679,
      "duration": 5.601
    },
    {
      "lang": "en",
      "text": "768 numbers. So what you can do is if I",
      "offset": 2059.919,
      "duration": 8.321
    },
    {
      "lang": "en",
      "text": "take row one, column 768,",
      "offset": 2063.28,
      "duration": 7.76
    },
    {
      "lang": "en",
      "text": "there's where our list of 768 numbers",
      "offset": 2068.24,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "ends. So every single one of these gets",
      "offset": 2071.04,
      "duration": 5.599
    },
    {
      "lang": "en",
      "text": "the same number of uh dimensions for how",
      "offset": 2072.72,
      "duration": 7.32
    },
    {
      "lang": "en",
      "text": "it gets represented.",
      "offset": 2076.639,
      "duration": 3.401
    },
    {
      "lang": "en",
      "text": "And it might be a little confusing",
      "offset": 2080.24,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "because we mapped words into tokens with",
      "offset": 2081.76,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "numbers. had token ids and then we have",
      "offset": 2084,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "these embeddings as well. And the",
      "offset": 2086.32,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "analogy I like to use is imagine you are",
      "offset": 2088.079,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "going to go uh look for a house to rent",
      "offset": 2090,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "or a house to buy. And the street",
      "offset": 2092.159,
      "duration": 4.881
    },
    {
      "lang": "en",
      "text": "addresses uh and you build this table of",
      "offset": 2094.399,
      "duration": 4.241
    },
    {
      "lang": "en",
      "text": "street addresses and then square feet,",
      "offset": 2097.04,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "bedrooms and bathrooms and price. The",
      "offset": 2098.64,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "street addresses are identifiers.",
      "offset": 2100.64,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "They're kind of like the token IDs. They",
      "offset": 2103.04,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "tell you where to find something, where",
      "offset": 2105.04,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "to find a house, but they don't tell you",
      "offset": 2106.96,
      "duration": 2.8
    },
    {
      "lang": "en",
      "text": "anything about what's inside. They don't",
      "offset": 2108.4,
      "duration": 2.64
    },
    {
      "lang": "en",
      "text": "tell you about what you care about, what",
      "offset": 2109.76,
      "duration": 2.72
    },
    {
      "lang": "en",
      "text": "the meaning is. doesn't tell you the",
      "offset": 2111.04,
      "duration": 2.559
    },
    {
      "lang": "en",
      "text": "square feet, the bedrooms, the",
      "offset": 2112.48,
      "duration": 2.639
    },
    {
      "lang": "en",
      "text": "bathrooms, or the price. And the",
      "offset": 2113.599,
      "duration": 3.361
    },
    {
      "lang": "en",
      "text": "embedding values, that's their job.",
      "offset": 2115.119,
      "duration": 3.361
    },
    {
      "lang": "en",
      "text": "They're to take the token and tell you",
      "offset": 2116.96,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "something about what it means. And the",
      "offset": 2118.48,
      "duration": 3.599
    },
    {
      "lang": "en",
      "text": "identifier or the token ID is just to",
      "offset": 2120.24,
      "duration": 2.96
    },
    {
      "lang": "en",
      "text": "tell give it a position in the",
      "offset": 2122.079,
      "duration": 2.801
    },
    {
      "lang": "en",
      "text": "dictionary, effectively a numerical",
      "offset": 2123.2,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "name.",
      "offset": 2124.88,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "And what we're really doing with the",
      "offset": 2126.72,
      "duration": 2.8
    },
    {
      "lang": "en",
      "text": "embedding values is we're trying to",
      "offset": 2128,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "build a map for words where we put",
      "offset": 2129.52,
      "duration": 6.64
    },
    {
      "lang": "en",
      "text": "similar words grouped together. So here",
      "offset": 2132.48,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "I've shown a two-dimensional map, but of",
      "offset": 2136.16,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "course we're in a 768 hyperdimensional",
      "offset": 2138.24,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "area, but the idea is basically the",
      "offset": 2141.52,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "same. Take the words happy and glad in",
      "offset": 2143.68,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "this map, this word island. You know,",
      "offset": 2146.32,
      "duration": 3.759
    },
    {
      "lang": "en",
      "text": "those are happy words. So I'm going to",
      "offset": 2148.64,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "put them up here, and then I'm going to",
      "offset": 2150.079,
      "duration": 4.641
    },
    {
      "lang": "en",
      "text": "take words like dog and cat, and I'll",
      "offset": 2152.56,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "put them in another part of this word",
      "offset": 2154.72,
      "duration": 3.359
    },
    {
      "lang": "en",
      "text": "island because they're animals. They",
      "offset": 2156.16,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "don't relate as much. And then you know",
      "offset": 2158.079,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "the word sad, well it doesn't have the",
      "offset": 2160.079,
      "duration": 6.481
    },
    {
      "lang": "en",
      "text": "same meaning as happy and glad, but it's",
      "offset": 2163.119,
      "duration": 5.521
    },
    {
      "lang": "en",
      "text": "still an emotion. So I want it closer to",
      "offset": 2166.56,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "the emotions, happy emotions part of the",
      "offset": 2168.64,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "island into this maybe the sad province",
      "offset": 2171.04,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "right next to the happy province. So",
      "offset": 2173.68,
      "duration": 2.72
    },
    {
      "lang": "en",
      "text": "they're kind of on the same half of the",
      "offset": 2175.119,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "island, but they're not directly in the",
      "offset": 2176.4,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "same spot because happy and sad have",
      "offset": 2178.8,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "different meanings.",
      "offset": 2180.48,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "So here's a simple two-dimensional",
      "offset": 2182.48,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "example of the benefit of doing this,",
      "offset": 2184.8,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "which is that you can start doing word",
      "offset": 2187.44,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "arithmetic and word math. So we're going",
      "offset": 2189.76,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "to imagine that we've built a",
      "offset": 2192.72,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "two-dimensional embedding where the",
      "offset": 2194.48,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "first column is authority and the second",
      "offset": 2195.76,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "column is gender. And we take the token",
      "offset": 2197.52,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "man. And we'll just arbitrarily say man",
      "offset": 2199.28,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "has authority of one and a gender of",
      "offset": 2201.52,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "one. A woman authority of one and a",
      "offset": 2203.359,
      "duration": 4.561
    },
    {
      "lang": "en",
      "text": "gender of two. A king has more authority",
      "offset": 2205.28,
      "duration": 4.799
    },
    {
      "lang": "en",
      "text": "than a man. So two for authority. gender",
      "offset": 2207.92,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "of one because still a man and then",
      "offset": 2210.079,
      "duration": 4.721
    },
    {
      "lang": "en",
      "text": "queen authority of two a gender of two",
      "offset": 2212.24,
      "duration": 5.359
    },
    {
      "lang": "en",
      "text": "and we can plot this out in a plane like",
      "offset": 2214.8,
      "duration": 4.799
    },
    {
      "lang": "en",
      "text": "as follows. So queen for example is at",
      "offset": 2217.599,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "position 22",
      "offset": 2219.599,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "and then we can actually build",
      "offset": 2221.52,
      "duration": 4.559
    },
    {
      "lang": "en",
      "text": "relationships just from doing vector",
      "offset": 2224,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "math. So for example if we take king we",
      "offset": 2226.079,
      "duration": 5.601
    },
    {
      "lang": "en",
      "text": "subtract man we add woman and then we",
      "offset": 2228.96,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "just do regular arithmetic column by",
      "offset": 2231.68,
      "duration": 7.6
    },
    {
      "lang": "en",
      "text": "column. So 2 - 1 + 1 1 - 1 + 2 gives us",
      "offset": 2233.92,
      "duration": 8.64
    },
    {
      "lang": "en",
      "text": "2 2. So king minus man plus woman is 2.",
      "offset": 2239.28,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "But of course that is the same thing as",
      "offset": 2242.56,
      "duration": 4.559
    },
    {
      "lang": "en",
      "text": "queen. So we're saying king minus man",
      "offset": 2244.64,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "plus woman equals queen. And we can",
      "offset": 2247.119,
      "duration": 4.641
    },
    {
      "lang": "en",
      "text": "think of this as an analogy. King is to",
      "offset": 2249.52,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "man as queen is to woman. And if we take",
      "offset": 2251.76,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "out the queen and just leave it as a",
      "offset": 2254.8,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "blank, we have our first kind of word",
      "offset": 2256.56,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "problem we can convert to a math",
      "offset": 2260.24,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "problem. If you give me any three words",
      "offset": 2262.24,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "and I had an embedding for them, I can",
      "offset": 2264.96,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "figure out what the fourth word in this",
      "offset": 2267.2,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "relationship is simply from vector math.",
      "offset": 2269.04,
      "duration": 6.079
    },
    {
      "lang": "en",
      "text": "And that is what wordtovec which was the",
      "offset": 2272.48,
      "duration": 4.639
    },
    {
      "lang": "en",
      "text": "most famous word embedding was able to",
      "offset": 2275.119,
      "duration": 5.121
    },
    {
      "lang": "en",
      "text": "do. It learned a bunch of relationships",
      "offset": 2277.119,
      "duration": 5.041
    },
    {
      "lang": "en",
      "text": "um in a series of papers not just one",
      "offset": 2280.24,
      "duration": 6.08
    },
    {
      "lang": "en",
      "text": "paper. Uh so for example France",
      "offset": 2282.16,
      "duration": 6.64
    },
    {
      "lang": "en",
      "text": "is to Paris as Italy is to Rome and",
      "offset": 2286.32,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "Japan is to Tokyo. Einstein is to",
      "offset": 2288.8,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "scientist as Messi is to midfielder or",
      "offset": 2291.28,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "Mozart is to violinist. Uh Japan is to",
      "offset": 2293.52,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "sushi as Germany is to brought. It",
      "offset": 2296.56,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "didn't get all of them right, but",
      "offset": 2298.4,
      "duration": 2.719
    },
    {
      "lang": "en",
      "text": "clearly it's learning something about",
      "offset": 2299.76,
      "duration": 3.359
    },
    {
      "lang": "en",
      "text": "relationships. And I want to be clear,",
      "offset": 2301.119,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "this is actually just the same thing as",
      "offset": 2303.119,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "being good at clustering. So imagine",
      "offset": 2304.72,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "I've got on my word island, I've got all",
      "offset": 2307.04,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "my countries over here, right? France,",
      "offset": 2309.119,
      "duration": 5.201
    },
    {
      "lang": "en",
      "text": "Japan, Italy, and then I've got all my",
      "offset": 2311.28,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "capitals, Paris, Tokyo, Rome over here",
      "offset": 2314.32,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "in the word island. Well, every single",
      "offset": 2317.28,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "one of them has the same vector",
      "offset": 2320,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "relationship in space between each other",
      "offset": 2321.68,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "if the clustering was really good and",
      "offset": 2323.92,
      "duration": 3.679
    },
    {
      "lang": "en",
      "text": "tight. And if somebody comes in and",
      "offset": 2325.52,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "says, \"Hey, what's the capital of",
      "offset": 2327.599,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "Canada?\" Well, I just use that same",
      "offset": 2329.599,
      "duration": 4.641
    },
    {
      "lang": "en",
      "text": "direction. I add that same vector to it.",
      "offset": 2331.76,
      "duration": 7.359
    },
    {
      "lang": "en",
      "text": "I can say, \"Oh, well, it's Ottawa.\"",
      "offset": 2334.24,
      "duration": 7.2
    },
    {
      "lang": "en",
      "text": "So, in practice, real world embeddings",
      "offset": 2339.119,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "are different than what I've shown here",
      "offset": 2341.44,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "with this contrived example. First of",
      "offset": 2342.8,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "all, we have many more columns or",
      "offset": 2344.56,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "dimensions. So instead of simply two, we",
      "offset": 2346.56,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "have hundreds. GPD2 is 768. Your",
      "offset": 2349.44,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "state-of-the-art model these days has a",
      "offset": 2352.24,
      "duration": 3.599
    },
    {
      "lang": "en",
      "text": "lot more.",
      "offset": 2353.92,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "Uh the other key difference is I made up",
      "offset": 2355.839,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "this thing saying that the first",
      "offset": 2358.72,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "dimension or column is authority, the",
      "offset": 2360.24,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "second one is gender. We don't know what",
      "offset": 2361.92,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "they mean. The columns are completely",
      "offset": 2363.76,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "uninterpretable. The model just seems to",
      "offset": 2365.2,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "pick them. And the values themselves",
      "offset": 2367.28,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "correspondingly therefore are not",
      "offset": 2369.68,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "interpretable either. And that might",
      "offset": 2371.119,
      "duration": 4.881
    },
    {
      "lang": "en",
      "text": "sound useless, but it's actually useful",
      "offset": 2373.76,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "for at least getting similarity. For",
      "offset": 2376,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "example, so let's go back to our housing",
      "offset": 2377.68,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "analogy. Imagine I took off the top",
      "offset": 2379.44,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "column, the the labels essentially, top",
      "offset": 2381.839,
      "duration": 5.041
    },
    {
      "lang": "en",
      "text": "row of what each column meant, and I",
      "offset": 2384.64,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "just gave you the IDs. If you went to",
      "offset": 2386.88,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "say 47 IV lane, and you said, I like",
      "offset": 2390,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "this house. I want to see more like it.",
      "offset": 2392.4,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "You could still find those because what",
      "offset": 2394.4,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "you could do is you could notice that",
      "offset": 2396.4,
      "duration": 5.199
    },
    {
      "lang": "en",
      "text": "with 58 sun a and 15 luna lane they all",
      "offset": 2397.76,
      "duration": 5.92
    },
    {
      "lang": "en",
      "text": "have roughly the same values in the",
      "offset": 2401.599,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "first column 2400 2400 2400 and the same",
      "offset": 2403.68,
      "duration": 6.24
    },
    {
      "lang": "en",
      "text": "values for the third fourth column as",
      "offset": 2407.119,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "well. So you're like if I like this",
      "offset": 2409.92,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "house I can find the others like it even",
      "offset": 2412.079,
      "duration": 3.201
    },
    {
      "lang": "en",
      "text": "though I don't know what these columns",
      "offset": 2414.079,
      "duration": 3.441
    },
    {
      "lang": "en",
      "text": "mean. So the question you're probably",
      "offset": 2415.28,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "asking yourself is well where the heck",
      "offset": 2417.52,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "do these values come from? How do we",
      "offset": 2419.28,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "know what they mean or how does the",
      "offset": 2421.359,
      "duration": 3.441
    },
    {
      "lang": "en",
      "text": "model pick it?",
      "offset": 2422.72,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "Well, the slightly unsatisfying answer",
      "offset": 2424.8,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "is that the embeddings are just simply",
      "offset": 2427.76,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "learned by the neural network model",
      "offset": 2429.28,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "during training. So now let's just talk",
      "offset": 2430.88,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "about what training looks like. So in",
      "offset": 2432.64,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "training, what we do is we grab a bunch",
      "offset": 2435.04,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "of text from the internet. We take out",
      "offset": 2436.4,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "passages like this one. Mike is quick.",
      "offset": 2438.4,
      "duration": 3.439
    },
    {
      "lang": "en",
      "text": "He moves quickly. So quickly was in the",
      "offset": 2440,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "original passage. And then we chop off",
      "offset": 2441.839,
      "duration": 5.121
    },
    {
      "lang": "en",
      "text": "the last token or the last word. And we",
      "offset": 2444.56,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "have a randomly initialized model. All",
      "offset": 2446.96,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "the values of the weights and parameters",
      "offset": 2449.28,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "are completely random including the",
      "offset": 2450.72,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "embeddings. And then we run it through",
      "offset": 2452.48,
      "duration": 2.879
    },
    {
      "lang": "en",
      "text": "the whole model and we say what do you",
      "offset": 2454.24,
      "duration": 2.4
    },
    {
      "lang": "en",
      "text": "predict is going to be the next word and",
      "offset": 2455.359,
      "duration": 2.881
    },
    {
      "lang": "en",
      "text": "it's random. So it comes up with",
      "offset": 2456.64,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "something nonsensical like Mike is quick",
      "offset": 2458.24,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "he moves haircut. And then we use this",
      "offset": 2460.64,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "algorithm called back propagation. And",
      "offset": 2464,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "we say hey back propagation the correct",
      "offset": 2466.16,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "answer was quickly. Can you adjust the",
      "offset": 2468,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "parameters to get closer to that value?",
      "offset": 2470.319,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "and it will go and tell us for every",
      "offset": 2472.72,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "single parameter how to slightly move it",
      "offset": 2474.72,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "to get it closer to producing the right",
      "offset": 2476.88,
      "duration": 4.479
    },
    {
      "lang": "en",
      "text": "answer of quickly. And then we rerun the",
      "offset": 2478.64,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "model and eventually it says Mike is",
      "offset": 2481.359,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "quick, he moves quickly. And then we do",
      "offset": 2483.44,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "this not just for one single passage of",
      "offset": 2485.52,
      "duration": 3.599
    },
    {
      "lang": "en",
      "text": "text, we're doing this for many passages",
      "offset": 2487.28,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "at a time. And one great benefit of this",
      "offset": 2489.119,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "is we don't have to teach the model",
      "offset": 2491.2,
      "duration": 4.879
    },
    {
      "lang": "en",
      "text": "anything explicitly. It's kind of",
      "offset": 2493.52,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "learning from unsupervised text. We're",
      "offset": 2496.079,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "just gathering that was naturally there",
      "offset": 2498.4,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "on the internet. and it's learning",
      "offset": 2500.079,
      "duration": 4.641
    },
    {
      "lang": "en",
      "text": "things like grammar, names, capitals of",
      "offset": 2501.44,
      "duration": 4.879
    },
    {
      "lang": "en",
      "text": "countries.",
      "offset": 2504.72,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "Um, but that seems a bit mysterious and",
      "offset": 2506.319,
      "duration": 5.201
    },
    {
      "lang": "en",
      "text": "we can kind of get an intuitive sense",
      "offset": 2509.44,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "for what it's doing if you think about",
      "offset": 2511.52,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "it as learning from word statistics. So",
      "offset": 2513.68,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "imagine you've got passages like this",
      "offset": 2516.48,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "one about the words ice and steam. It",
      "offset": 2518.88,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "was so cold the puddle had turned to",
      "offset": 2521.04,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "ice. Steam rose from the still hot cup",
      "offset": 2522.64,
      "duration": 4.719
    },
    {
      "lang": "en",
      "text": "of coffee. And what you notice is that",
      "offset": 2525.28,
      "duration": 4.799
    },
    {
      "lang": "en",
      "text": "the words ice and cold tend to co-occur",
      "offset": 2527.359,
      "duration": 5.121
    },
    {
      "lang": "en",
      "text": "with each other. And the words steam and",
      "offset": 2530.079,
      "duration": 4.801
    },
    {
      "lang": "en",
      "text": "hot tend to co-occur with each other. So",
      "offset": 2532.48,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "if you were an alien coming down from",
      "offset": 2534.88,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "another planet, you had no idea what our",
      "offset": 2536.96,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "language was and you looked at this, you",
      "offset": 2538.48,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "would say, I don't know what ice, cold,",
      "offset": 2540.4,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "steam, and hot are. But I know that ice",
      "offset": 2542.4,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "is probably cold more than steam is",
      "offset": 2545.2,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "because ice and cold co occur more often",
      "offset": 2548,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "than steam and cold do. And I know that",
      "offset": 2550.72,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "steam is hot because ice and hot don't",
      "offset": 2553.04,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "co- occur as much as steam and hot do.",
      "offset": 2555.92,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "So that there must be some relationship.",
      "offset": 2558.24,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "They must have that meaning. And this is",
      "offset": 2559.839,
      "duration": 5.441
    },
    {
      "lang": "en",
      "text": "called the distributional hypothesis. Uh",
      "offset": 2562.24,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "and the phrase that is you'll often hear",
      "offset": 2565.28,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "people quote is you shall know a word by",
      "offset": 2566.96,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "the company it keeps which is basically",
      "offset": 2568.48,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "that a word is partially defined by its",
      "offset": 2570.24,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "context. Or said another way words that",
      "offset": 2572.24,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "have similar meanings can be replaced",
      "offset": 2574.72,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "with each other in similar contexts. So",
      "offset": 2576.24,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "if you know how they're distributed in",
      "offset": 2579.04,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "their statistical representation, you",
      "offset": 2580.56,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "have a sense of what similar words might",
      "offset": 2582.64,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "be. And in fact, in my the full version",
      "offset": 2584.4,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "of my class, we actually build our own",
      "offset": 2586.96,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "primitive embeddings from Wikipedia",
      "offset": 2588.72,
      "duration": 4.879
    },
    {
      "lang": "en",
      "text": "pages using a very simplified version of",
      "offset": 2590.48,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "not wordtovec, but another algorithm",
      "offset": 2593.599,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "called glove, which is based on just",
      "offset": 2595.76,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "using a co-occurrence matrix. So roughly",
      "offset": 2597.92,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "what that process looks like is you",
      "offset": 2600.56,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "would count how often the words co-occur",
      "offset": 2602.319,
      "duration": 4.241
    },
    {
      "lang": "en",
      "text": "within some window size inside your",
      "offset": 2604.24,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "corpus of text. You'd analyze every",
      "offset": 2606.56,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "single word and you'd look, in this",
      "offset": 2608.72,
      "duration": 2.72
    },
    {
      "lang": "en",
      "text": "case, three words to the left, three",
      "offset": 2609.92,
      "duration": 2.8
    },
    {
      "lang": "en",
      "text": "words to right, and you say, \"These are",
      "offset": 2611.44,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "the words that co-occur with it.\" And",
      "offset": 2612.72,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "then you'd build a big giant table, a",
      "offset": 2614.64,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "matrix, and you'd say, \"Let me compare",
      "offset": 2617.04,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "every word to every other word, and I'm",
      "offset": 2619.04,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "going to count how often they co-occur",
      "offset": 2620.64,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "in all my text with each other.\" So here",
      "offset": 2622.24,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "in this example, word two and word three",
      "offset": 2624.4,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "co-occur, let's say, five times in our",
      "offset": 2627.04,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "corpus of text.",
      "offset": 2628.8,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "And then what you can think of the",
      "offset": 2631.359,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "embedding as instead of taking this",
      "offset": 2632.96,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "table which is all possible words by all",
      "offset": 2634.96,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "possible words and if we're in English",
      "offset": 2637.119,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "that's about 170,000 words or in the",
      "offset": 2638.88,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "case of BPE it's 50,000 tokens you can",
      "offset": 2641.2,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "imagine it compressing the columns of",
      "offset": 2644.48,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "the matrix. So instead of having 7",
      "offset": 2646.56,
      "duration": 5.92
    },
    {
      "lang": "en",
      "text": "170,000 columns it's got whatever your",
      "offset": 2650.16,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "embedding dimension is 768. It's still",
      "offset": 2652.48,
      "duration": 5.599
    },
    {
      "lang": "en",
      "text": "all possible words high, but it's now a",
      "offset": 2654.88,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "lot smaller in the number of columns.",
      "offset": 2658.079,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "So, it's basically a compressed",
      "offset": 2660.88,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "co-occurrence matrix. So, the actual",
      "offset": 2662.24,
      "duration": 5.119
    },
    {
      "lang": "en",
      "text": "table OpenAI gives us from training, the",
      "offset": 2664.56,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "embedding table, is really just this",
      "offset": 2667.359,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "thing on the right. It is basically",
      "offset": 2669.68,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "every single word or token and then the",
      "offset": 2671.28,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "representation of its dimensions. And",
      "offset": 2673.52,
      "duration": 2.799
    },
    {
      "lang": "en",
      "text": "you can think of it as they just took a",
      "offset": 2674.88,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "co-occurrence matrix and they shrunk it.",
      "offset": 2676.319,
      "duration": 5.361
    },
    {
      "lang": "en",
      "text": "The reason I like this mental model is",
      "offset": 2678.64,
      "duration": 5.679
    },
    {
      "lang": "en",
      "text": "it helps motivate certain things about",
      "offset": 2681.68,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "embeddings that might seem a bit weird.",
      "offset": 2684.319,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "So a classic one is how do you measure",
      "offset": 2686.16,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "how similar two embeddings are? You",
      "offset": 2687.92,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "might naively think we just look at",
      "offset": 2690,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "uklitian space you know as the crow",
      "offset": 2691.68,
      "duration": 3.679
    },
    {
      "lang": "en",
      "text": "flies how far apart they are. But that's",
      "offset": 2693.52,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "not what we do. We use something called",
      "offset": 2695.359,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "cosine similarity. How many people have",
      "offset": 2696.8,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "heard of cosine similarity?",
      "offset": 2698.96,
      "duration": 4.879
    },
    {
      "lang": "en",
      "text": "Yeah. So you know cosine similarity is",
      "offset": 2701.44,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "not an intuitive measurement of",
      "offset": 2703.839,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "similarity. And what it is is we take",
      "offset": 2705.44,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "the angle of the two points and then we",
      "offset": 2707.359,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "take the cosine of that angle and that's",
      "offset": 2709.839,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "how we say how similar two embeddings",
      "offset": 2711.52,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "are. So if they are if you remember your",
      "offset": 2713.44,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "trigonometry if they're opposed you know",
      "offset": 2715.76,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "cosine goes from negative 1 to one. So",
      "offset": 2718.48,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "if they're opposed they get negative one",
      "offset": 2720.48,
      "duration": 3.119
    },
    {
      "lang": "en",
      "text": "value. So that's when two vectors are",
      "offset": 2721.92,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "like this. If they're unrelated it's",
      "offset": 2723.599,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "like this. They're orthogonal. And if",
      "offset": 2725.839,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "they're similar they're pointing the",
      "offset": 2727.68,
      "duration": 3.679
    },
    {
      "lang": "en",
      "text": "same place the cosine will be one. Oh",
      "offset": 2729.44,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "and by the way this opposite is not",
      "offset": 2731.359,
      "duration": 3.441
    },
    {
      "lang": "en",
      "text": "opposite in probably your intuitive",
      "offset": 2733.28,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "conventional sense. So happy and sad you",
      "offset": 2734.8,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "might think would be opposites, but",
      "offset": 2737.599,
      "duration": 2.801
    },
    {
      "lang": "en",
      "text": "actually they're more similar to each",
      "offset": 2739.2,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "other than any other set of words. Um if",
      "offset": 2740.4,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "you think about hoff and like happy and",
      "offset": 2742.8,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "sad probably occur in songs and poems",
      "offset": 2744.16,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "and other types of context. They're both",
      "offset": 2745.92,
      "duration": 3.199
    },
    {
      "lang": "en",
      "text": "emotions. So they're actually more",
      "offset": 2747.44,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "similar than they would be opposite. In",
      "offset": 2749.119,
      "duration": 3.761
    },
    {
      "lang": "en",
      "text": "fact, if you take all the GPT2",
      "offset": 2750.48,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "um embeddings and you compare them",
      "offset": 2752.88,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "against each other, very few are",
      "offset": 2754.8,
      "duration": 2.72
    },
    {
      "lang": "en",
      "text": "negative and most of those are close to",
      "offset": 2756,
      "duration": 3.359
    },
    {
      "lang": "en",
      "text": "zero.",
      "offset": 2757.52,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "Um, but going back to kind of learning",
      "offset": 2759.359,
      "duration": 4.561
    },
    {
      "lang": "en",
      "text": "from word statistics, the key thing we",
      "offset": 2761.76,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "care about is the relative co-occurrence",
      "offset": 2763.92,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "of different words against each other.",
      "offset": 2767.28,
      "duration": 2.88
    },
    {
      "lang": "en",
      "text": "We don't care about the the raw",
      "offset": 2768.72,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "co-occurrence. So let's for example",
      "offset": 2770.16,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "imagine there's this section of our",
      "offset": 2773.04,
      "duration": 3.039
    },
    {
      "lang": "en",
      "text": "co-occurrence matrix which is the basis",
      "offset": 2774.48,
      "duration": 2.96
    },
    {
      "lang": "en",
      "text": "for the embeddings. We're comparing",
      "offset": 2776.079,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "three words 1 2 3 against word 10 and",
      "offset": 2777.44,
      "duration": 7.52
    },
    {
      "lang": "en",
      "text": "11. And word one occurs with word 10 and",
      "offset": 2780.24,
      "duration": 7.44
    },
    {
      "lang": "en",
      "text": "word 11 10 times each. Word two occurs",
      "offset": 2784.96,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "with word 10 and 11 50 times each. Word",
      "offset": 2787.68,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "three on the other hand is five and 20",
      "offset": 2790.48,
      "duration": 2.879
    },
    {
      "lang": "en",
      "text": "times. And I'm going to plot these as",
      "offset": 2792,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "vectors where the horizontal axis how",
      "offset": 2793.359,
      "duration": 4.641
    },
    {
      "lang": "en",
      "text": "many times it occurs with word 10 and",
      "offset": 2796.48,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "the vertical is how many times with word",
      "offset": 2798,
      "duration": 5.359
    },
    {
      "lang": "en",
      "text": "11. And what we notice is something",
      "offset": 2799.92,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "interesting. Word one and two",
      "offset": 2803.359,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "essentially have the same meaning. As",
      "offset": 2805.68,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "far as word 10 and word 11 can tell. The",
      "offset": 2807.359,
      "duration": 4.801
    },
    {
      "lang": "en",
      "text": "relative probability between them is the",
      "offset": 2810.24,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "same one one. It's just that word two",
      "offset": 2812.16,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "happens to be more common, right? It's",
      "offset": 2815.04,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "five times more common. But if we",
      "offset": 2817.52,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "plotted this in vector space, what you",
      "offset": 2819.92,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "see is that word two and word one are",
      "offset": 2822.24,
      "duration": 4.879
    },
    {
      "lang": "en",
      "text": "really far apart in uklidian distance,",
      "offset": 2824.96,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "but they have the same angle. Now word",
      "offset": 2827.119,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "three is actually closer in uklidian",
      "offset": 2829.52,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "space, but relative to word 10 and word",
      "offset": 2831.52,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "11 has a different meaning. And so",
      "offset": 2833.599,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "that's a motivation for why we're",
      "offset": 2835.839,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "looking at the angle, right? which seems",
      "offset": 2837.52,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "to more accurately capture the meaning",
      "offset": 2839.52,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "and not necessarily popularity which is",
      "offset": 2841.2,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "what uklidian space would capture.",
      "offset": 2843.04,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "Okay, so how do we actually use this?",
      "offset": 2846.16,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "Well, these embeddings were learned",
      "offset": 2848.24,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "during training. So, OpenAI gives us",
      "offset": 2849.92,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "this model_WTE",
      "offset": 2852.4,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "matrix and the way it's set up is that",
      "offset": 2854.4,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "it is our vocabulary size tall. So,",
      "offset": 2856.72,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "50,257",
      "offset": 2859.76,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "tokens is how many tokens GPD2 uses. So",
      "offset": 2861.28,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "there's a row for every single token and",
      "offset": 2864.64,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "then each row is just simply the",
      "offset": 2866.72,
      "duration": 3.359
    },
    {
      "lang": "en",
      "text": "embedding for that token. So there's a",
      "offset": 2868.4,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "row for dog and that row is the 768",
      "offset": 2870.079,
      "duration": 5.361
    },
    {
      "lang": "en",
      "text": "numbers that represent the semantic",
      "offset": 2873.68,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "meaning of dog. So let's go to our",
      "offset": 2875.44,
      "duration": 5.919
    },
    {
      "lang": "en",
      "text": "example here. So let's take is",
      "offset": 2877.599,
      "duration": 6.24
    },
    {
      "lang": "en",
      "text": "uh what is the token ID for is? It is",
      "offset": 2881.359,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "318.",
      "offset": 2883.839,
      "duration": 5.201
    },
    {
      "lang": "en",
      "text": "So this is our model WT. This is one of",
      "offset": 2885.44,
      "duration": 5.84
    },
    {
      "lang": "en",
      "text": "those CSV files we dragged in. So it",
      "offset": 2889.04,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "fetches it and it displays it. So, let's",
      "offset": 2891.28,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "go to row 318. There's actually an off",
      "offset": 2893.2,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "by one, but I'll do that anyways.",
      "offset": 2894.96,
      "duration": 5.92
    },
    {
      "lang": "en",
      "text": "So, you can see we'll pull come back to",
      "offset": 2898.8,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "that in a second. And let's go to our",
      "offset": 2900.88,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "final token embeddings right here. Uh,",
      "offset": 2902.24,
      "duration": 5.839
    },
    {
      "lang": "en",
      "text": "so is you can see it's 0.97.",
      "offset": 2904.64,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "01.",
      "offset": 2908.079,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "And you'll see that matches what you",
      "offset": 2910.4,
      "duration": 6.159
    },
    {
      "lang": "en",
      "text": "have here. 0.97 in row the 319th row.",
      "offset": 2911.76,
      "duration": 6.24
    },
    {
      "lang": "en",
      "text": "But if we were zero index, it would be",
      "offset": 2916.559,
      "duration": 6.721
    },
    {
      "lang": "en",
      "text": "318. 01. So all this code is doing right",
      "offset": 2918,
      "duration": 7.92
    },
    {
      "lang": "en",
      "text": "here is it's grabbing the token ID and",
      "offset": 2923.28,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "just pulling out the corresponding row",
      "offset": 2925.92,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "and plopping it into this table here. So",
      "offset": 2927.92,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "it's a very simple operation. That's why",
      "offset": 2929.92,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "this is what uh",
      "offset": 2931.839,
      "duration": 6.081
    },
    {
      "lang": "en",
      "text": "basically 15 lines of JavaScript to just",
      "offset": 2935.28,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "grab one thing out of another and then",
      "offset": 2937.92,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "put it here. So all this is doing is",
      "offset": 2940.16,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "just taking those token IDs and looking",
      "offset": 2941.68,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "them up and putting them in this table.",
      "offset": 2943.2,
      "duration": 5.84
    },
    {
      "lang": "en",
      "text": "Uh last thing I want to say before we",
      "offset": 2946.64,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "leave token embeddings is as before with",
      "offset": 2949.04,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "tokens I said it doesn't just have to be",
      "offset": 2951.2,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "a text. Uh the same thing is true for",
      "offset": 2952.64,
      "duration": 4.719
    },
    {
      "lang": "en",
      "text": "embeddings. So the famous example is",
      "offset": 2954.8,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "clip which was the basis for a lot of",
      "offset": 2957.359,
      "duration": 3.121
    },
    {
      "lang": "en",
      "text": "the image generators that you probably",
      "offset": 2958.8,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "have tried or used. And instead of just",
      "offset": 2960.48,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "comparing words against words, you can",
      "offset": 2962.4,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "think of it as it's comparing words",
      "offset": 2964.48,
      "duration": 4.879
    },
    {
      "lang": "en",
      "text": "against images. So if you look at all",
      "offset": 2966.72,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "the images on the internet, you look at",
      "offset": 2969.359,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "that alt text and it sees dog and a",
      "offset": 2970.64,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "bunch of images with dogs in it, you can",
      "offset": 2973.119,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "get it to learn that relationship. So",
      "offset": 2975.2,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "later on you can pass in an image and it",
      "offset": 2977.44,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "can say this thing is a dog.",
      "offset": 2978.96,
      "duration": 7.04
    },
    {
      "lang": "en",
      "text": "Okay, let's go to position embeddings.",
      "offset": 2982.16,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "Okay, so now we're still at the top with",
      "offset": 2986,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "input and we're talking about uh",
      "offset": 2987.92,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "embeddings, but now we're talking about",
      "offset": 2990.079,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "a different kind of embedding. And the",
      "offset": 2991.76,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "key thing to remember is that in",
      "offset": 2994.16,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "English, word order matters, right? The",
      "offset": 2995.92,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "dog chases the cat is something",
      "offset": 2998.559,
      "duration": 4.961
    },
    {
      "lang": "en",
      "text": "different than the cat chases the dog.",
      "offset": 3001.2,
      "duration": 7.52
    },
    {
      "lang": "en",
      "text": "Now, in math, 2 + 3 equals 5, but 3 + 2",
      "offset": 3003.52,
      "duration": 7.52
    },
    {
      "lang": "en",
      "text": "equals 5. Anything after that equal sign",
      "offset": 3008.72,
      "duration": 6.08
    },
    {
      "lang": "en",
      "text": "has no idea what the order was. Our",
      "offset": 3011.04,
      "duration": 6.72
    },
    {
      "lang": "en",
      "text": "problem is that when we mapped from a",
      "offset": 3014.8,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "word domain, an English domain, a",
      "offset": 3017.76,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "language domain, we were in a domain",
      "offset": 3019.68,
      "duration": 3.679
    },
    {
      "lang": "en",
      "text": "where order typically matters, we went",
      "offset": 3021.599,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "to a number domain where order typically",
      "offset": 3023.359,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "does not matter. And even though I've",
      "offset": 3025.28,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "drawn this with simplified arithmetic,",
      "offset": 3027.2,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "there are parts of the model that are",
      "offset": 3029.52,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "also commutative. So what could happen",
      "offset": 3031.44,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "in essence is you can change the order",
      "offset": 3033.599,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "of the words, right? And now it could",
      "offset": 3036.24,
      "duration": 3.599
    },
    {
      "lang": "en",
      "text": "mean something different or it could be",
      "offset": 3038.559,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "completely gibberish. But anything after",
      "offset": 3039.839,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "that equal sign can't tell the",
      "offset": 3042.079,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "difference. So it has no sense of",
      "offset": 3043.68,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "position of these words and that's going",
      "offset": 3045.76,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "to be really hard to understand the",
      "offset": 3047.76,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "meaning of the sentence or the phrase.",
      "offset": 3049.28,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "So what we're going to do is we're going",
      "offset": 3051.599,
      "duration": 3.121
    },
    {
      "lang": "en",
      "text": "to add some sense of position to the",
      "offset": 3052.88,
      "duration": 3.679
    },
    {
      "lang": "en",
      "text": "embedding. And what we're going to do is",
      "offset": 3054.72,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "we're going to just take for example one",
      "offset": 3056.559,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "token like woman and say woman at",
      "offset": 3058.16,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "position zero in the prompt is going to",
      "offset": 3060.64,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "basically mean the same thing as woman",
      "offset": 3062.88,
      "duration": 3.679
    },
    {
      "lang": "en",
      "text": "at any other position in the prompt. So",
      "offset": 3064.24,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "let's give woman at one position",
      "offset": 3066.559,
      "duration": 5.601
    },
    {
      "lang": "en",
      "text": "other than zero a slight offset a",
      "offset": 3070,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "slightly different position to represent",
      "offset": 3072.16,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "that it's roughly the same meaning it's",
      "offset": 3074.24,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "just woman when it occurs at position",
      "offset": 3076,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "one and then a different spot for woman",
      "offset": 3077.52,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "at position two and so forth. And in",
      "offset": 3079.44,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "general we'll use the position in the",
      "offset": 3082.16,
      "duration": 5.679
    },
    {
      "lang": "en",
      "text": "prompt to define a small offset that",
      "offset": 3084.48,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "we're going to slightly move the",
      "offset": 3087.839,
      "duration": 3.441
    },
    {
      "lang": "en",
      "text": "position of the token in the embedding",
      "offset": 3089.68,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "space. In the original famous attention",
      "offset": 3091.28,
      "duration": 5.039
    },
    {
      "lang": "en",
      "text": "is all you need paper, they use the s",
      "offset": 3093.68,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "and cosine formulas, uh you don't have",
      "offset": 3096.319,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "to look through the whole thing. The key",
      "offset": 3098.64,
      "duration": 2.479
    },
    {
      "lang": "en",
      "text": "thing I want you to pay attention to is",
      "offset": 3099.92,
      "duration": 2.8
    },
    {
      "lang": "en",
      "text": "it's just sign and a cosine. And if you",
      "offset": 3101.119,
      "duration": 3.521
    },
    {
      "lang": "en",
      "text": "remember your trigonometry, s and cosine",
      "offset": 3102.72,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "goes from negative 1 to one. So what",
      "offset": 3104.64,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "we're effectively doing is we are",
      "offset": 3106.64,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "building this circle right around this",
      "offset": 3109.28,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "with a limited diameter and we're saying",
      "offset": 3111.76,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "I'm oscillating and that's the other",
      "offset": 3114.96,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "thing to remember for trigonometry is s",
      "offset": 3116.8,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "and cosine oscillate. I'm just",
      "offset": 3118.48,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "oscillating the position of this thing",
      "offset": 3119.92,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "in space based on its position in the",
      "offset": 3122,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "prompt. I'm keeping it roughly in that",
      "offset": 3124.48,
      "duration": 2.639
    },
    {
      "lang": "en",
      "text": "same area, but it's a little cloud",
      "offset": 3125.839,
      "duration": 3.041
    },
    {
      "lang": "en",
      "text": "that's all the different versions of",
      "offset": 3127.119,
      "duration": 3.121
    },
    {
      "lang": "en",
      "text": "woman just in different parts of the",
      "offset": 3128.88,
      "duration": 4.959
    },
    {
      "lang": "en",
      "text": "prompt. In GPD2, interestingly enough,",
      "offset": 3130.24,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "uh they didn't use that same technique.",
      "offset": 3133.839,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "They let the model learn the embeddings",
      "offset": 3135.68,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "on its own, which still blows my mind.",
      "offset": 3137.68,
      "duration": 6.32
    },
    {
      "lang": "en",
      "text": "Um so how we use this is we have another",
      "offset": 3140.64,
      "duration": 6.08
    },
    {
      "lang": "en",
      "text": "matrix that uh openai gives us when they",
      "offset": 3144,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "open source GPD2 which is the position",
      "offset": 3146.72,
      "duration": 6.399
    },
    {
      "lang": "en",
      "text": "matrix and this time it is 1024 high",
      "offset": 3149.76,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "which is our maximum context length.",
      "offset": 3153.119,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "It's not it's an early model so it's not",
      "offset": 3154.96,
      "duration": 4.879
    },
    {
      "lang": "en",
      "text": "very large context. Um and then each of",
      "offset": 3156.72,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "the rows is again the embedding",
      "offset": 3159.839,
      "duration": 3.121
    },
    {
      "lang": "en",
      "text": "dimension. And what we're going to do is",
      "offset": 3161.28,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "these are position offsets. So we're",
      "offset": 3162.96,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "going to add these offsets in each row",
      "offset": 3165.04,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "to each value in our embedding dimension",
      "offset": 3166.96,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "to offset it to represent its position.",
      "offset": 3169.68,
      "duration": 4.639
    },
    {
      "lang": "en",
      "text": "So you can think of it like this. We",
      "offset": 3172.48,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "start with our embedding values from the",
      "offset": 3174.319,
      "duration": 4.721
    },
    {
      "lang": "en",
      "text": "token embeddings and then we're",
      "offset": 3177.28,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "basically doing a matrix ad. So we're",
      "offset": 3179.04,
      "duration": 5.519
    },
    {
      "lang": "en",
      "text": "taking each of these elements here. So I",
      "offset": 3181.28,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "take this element, add it to this one.",
      "offset": 3184.559,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "This element, add it to this one. This",
      "offset": 3185.92,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "one, add it to that one. We're just",
      "offset": 3187.599,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "simple elementwise add. And that gets",
      "offset": 3189.76,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "our position embeddings for every single",
      "offset": 3192,
      "duration": 6.64
    },
    {
      "lang": "en",
      "text": "one of our input tokens.",
      "offset": 3194,
      "duration": 9.359
    },
    {
      "lang": "en",
      "text": "So let me show you where that is.",
      "offset": 3198.64,
      "duration": 6.24
    },
    {
      "lang": "en",
      "text": "Okay. So the first thing we do is we",
      "offset": 3203.359,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "fetch this model_WP.",
      "offset": 3204.88,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "Um that again comes from OpenAI. You can",
      "offset": 3207.839,
      "duration": 4.561
    },
    {
      "lang": "en",
      "text": "see this is 1024. So if we go to row",
      "offset": 3209.68,
      "duration": 6.159
    },
    {
      "lang": "en",
      "text": "1024 column 1,",
      "offset": 3212.4,
      "duration": 5.679
    },
    {
      "lang": "en",
      "text": "there it is. That's our max context",
      "offset": 3215.839,
      "duration": 4.561
    },
    {
      "lang": "en",
      "text": "length. So beyond that, the model has no",
      "offset": 3218.079,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "idea how to solve that, understand that",
      "offset": 3220.4,
      "duration": 3.679
    },
    {
      "lang": "en",
      "text": "you can ignore this one. And the this",
      "offset": 3222.16,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "code for positional embed is really just",
      "offset": 3224.079,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "a matrix ad. The only thing I have to do",
      "offset": 3226.4,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "is make sure well the input token uh",
      "offset": 3228.559,
      "duration": 3.441
    },
    {
      "lang": "en",
      "text": "input prompt is going to be less than",
      "offset": 3230.8,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "1024 tokens. So it just needs to stop",
      "offset": 3232,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "when it gets to the end of the input.",
      "offset": 3234.64,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "But that gives us our positional",
      "offset": 3236.72,
      "duration": 2.879
    },
    {
      "lang": "en",
      "text": "embeddings here. So we're just passing",
      "offset": 3238,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "to this our token embeddings we had from",
      "offset": 3239.599,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "the previous step. And then our model WP",
      "offset": 3241.28,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "table which came fetched from the CSV",
      "offset": 3244,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "file. It just simply adds those together",
      "offset": 3246.4,
      "duration": 6.12
    },
    {
      "lang": "en",
      "text": "and we get these positional embeddings.",
      "offset": 3248.16,
      "duration": 4.36
    },
    {
      "lang": "en",
      "text": "Uh here's kind of an illustration of the",
      "offset": 3252.88,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "action of GPT2 uh and its positional",
      "offset": 3254.72,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "embeddings. So these numbers you see",
      "offset": 3257.28,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "right after like happy three, happy four",
      "offset": 3259.52,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "aren't the actual tokens. What I've done",
      "offset": 3261.52,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "is I've plotted the word happy uh the",
      "offset": 3263.359,
      "duration": 4.641
    },
    {
      "lang": "en",
      "text": "token happy rather and I've put it at",
      "offset": 3265.92,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "different positions. I put it position",
      "offset": 3268,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "three, position four, position five and",
      "offset": 3269.44,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "so forth. And then I took two other",
      "offset": 3271.28,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "words happy and glad and I just put them",
      "offset": 3272.8,
      "duration": 3.519
    },
    {
      "lang": "en",
      "text": "in space as reference points. And you",
      "offset": 3274.64,
      "duration": 2.88
    },
    {
      "lang": "en",
      "text": "can see it's doing what we described",
      "offset": 3276.319,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "earlier. It's basically just keeping it",
      "offset": 3277.52,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "roughly in the same position. It's",
      "offset": 3279.599,
      "duration": 3.361
    },
    {
      "lang": "en",
      "text": "slightly offsetting it depending on",
      "offset": 3281.359,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "where it is in the prompt.",
      "offset": 3282.96,
      "duration": 6.72
    },
    {
      "lang": "en",
      "text": "Uh, one key thing you should know of all",
      "offset": 3287.119,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "the changes to, you know, modern LLMs",
      "offset": 3289.68,
      "duration": 4.879
    },
    {
      "lang": "en",
      "text": "from GPT2, probably one of the most",
      "offset": 3292.319,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "common and biggest ones is that they do",
      "offset": 3294.559,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "not use these types of positional",
      "offset": 3296.079,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "embeddings. They do something called",
      "offset": 3297.839,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "rope. Um, so if you look at a a modern",
      "offset": 3299.119,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "LM, this is probably the first thing",
      "offset": 3301.92,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "you'll see that's different.",
      "offset": 3303.04,
      "duration": 8.279
    },
    {
      "lang": "en",
      "text": "Okay, let's do a time check.",
      "offset": 3305.92,
      "duration": 5.399
    },
    {
      "lang": "en",
      "text": "We are we are five minutes behind, but",
      "offset": 3314.48,
      "duration": 6.24
    },
    {
      "lang": "en",
      "text": "we've got 10 minutes. I will take a",
      "offset": 3318.079,
      "duration": 5.681
    },
    {
      "lang": "en",
      "text": "break for a question or two if anybody",
      "offset": 3320.72,
      "duration": 6.08
    },
    {
      "lang": "en",
      "text": "wants to ask one.",
      "offset": 3323.76,
      "duration": 5.599
    },
    {
      "lang": "en",
      "text": "Any questions so far?",
      "offset": 3326.8,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "Yeah, go ahead. Um, you were mentioning",
      "offset": 3329.359,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "that Oh, there's a microphone right",
      "offset": 3331.76,
      "duration": 5.319
    },
    {
      "lang": "en",
      "text": "there.",
      "offset": 3334.079,
      "duration": 3
    },
    {
      "lang": "en",
      "text": "Uh, you were mentioning that with GPT2",
      "offset": 3337.119,
      "duration": 3.761
    },
    {
      "lang": "en",
      "text": "they weren't using the sign and cosign",
      "offset": 3338.96,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "kind of cloud. Like what were they",
      "offset": 3340.88,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "actually doing to come up with the word",
      "offset": 3342.8,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "position embeddings? Uh, that's the",
      "offset": 3344.72,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "crazy thing. They they let the model",
      "offset": 3347.04,
      "duration": 8.88
    },
    {
      "lang": "en",
      "text": "learn it. So the big change they did is",
      "offset": 3350.48,
      "duration": 8.4
    },
    {
      "lang": "en",
      "text": "think of it this way. If we go back to",
      "offset": 3355.92,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "our",
      "offset": 3358.88,
      "duration": 4.719
    },
    {
      "lang": "en",
      "text": "uh diagram of how embeddings are",
      "offset": 3361.04,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "learned,",
      "offset": 3363.599,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "right right here,",
      "offset": 3365.92,
      "duration": 4.919
    },
    {
      "lang": "en",
      "text": "right?",
      "offset": 3367.839,
      "duration": 3
    },
    {
      "lang": "en",
      "text": "Okay. So in the original transformer,",
      "offset": 3376.559,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "the position embeddings were not",
      "offset": 3379.68,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "represented as learnable weights, right?",
      "offset": 3381.359,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "They were s and cosine functions. All",
      "offset": 3383.76,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "they did is they said during back",
      "offset": 3386.079,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "propagation let's learn those as well",
      "offset": 3387.68,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "and that's how it learned them. Uh so",
      "offset": 3390.799,
      "duration": 4.641
    },
    {
      "lang": "en",
      "text": "they did not they just simply said hey",
      "offset": 3392.96,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "let's not hardcode those values and",
      "offset": 3395.44,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "let's make that other thing now a",
      "offset": 3397.28,
      "duration": 5.319
    },
    {
      "lang": "en",
      "text": "parameter the model learns.",
      "offset": 3398.88,
      "duration": 3.719
    },
    {
      "lang": "en",
      "text": "Okay good question",
      "offset": 3404.24,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "and as I said it's still kind of",
      "offset": 3406.96,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "mind-blowing that that worked. Uh but as",
      "offset": 3408.24,
      "duration": 4.879
    },
    {
      "lang": "en",
      "text": "we now know these things can learn a",
      "offset": 3411.359,
      "duration": 3.281
    },
    {
      "lang": "en",
      "text": "ton.",
      "offset": 3413.119,
      "duration": 6.761
    },
    {
      "lang": "en",
      "text": "Okay, let's talk about attention.",
      "offset": 3414.64,
      "duration": 5.24
    },
    {
      "lang": "en",
      "text": "Okay, there we go. So, now we're getting",
      "offset": 3423.359,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "into the heart of the number crunching.",
      "offset": 3425.599,
      "duration": 3.361
    },
    {
      "lang": "en",
      "text": "And this one's going to be a little more",
      "offset": 3427.76,
      "duration": 3.359
    },
    {
      "lang": "en",
      "text": "cursory understanding uh and",
      "offset": 3428.96,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "explanation, but I still think it's",
      "offset": 3431.119,
      "duration": 3.281
    },
    {
      "lang": "en",
      "text": "important to understand what it is. Um,",
      "offset": 3432.4,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "and we're going to start with attention.",
      "offset": 3434.4,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "And now we're inside what are often",
      "offset": 3437.52,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "called the layers. I like to call them",
      "offset": 3440,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "the blocks. That's a less common but",
      "offset": 3442.24,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "other people use the term blocks. The",
      "offset": 3444,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "reason I use the word blocks is when I",
      "offset": 3445.52,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "teach this it's usually people coming to",
      "offset": 3447.76,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "it the first time and the word layer",
      "offset": 3449.359,
      "duration": 4.641
    },
    {
      "lang": "en",
      "text": "gets used in other contexts. Later we're",
      "offset": 3452.079,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "going to talk about the multi-layer",
      "offset": 3454,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "perceptron and it can be confusing when",
      "offset": 3455.119,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "you're first coming to something and the",
      "offset": 3457.04,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "same word has different meanings",
      "offset": 3458.559,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "depending on the context. But know that",
      "offset": 3460.24,
      "duration": 3.359
    },
    {
      "lang": "en",
      "text": "when you talk to most people when they",
      "offset": 3462.079,
      "duration": 3.121
    },
    {
      "lang": "en",
      "text": "talk about how many layers are in a",
      "offset": 3463.599,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "model they're talking about what I call",
      "offset": 3465.2,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "how many blocks. And if you start",
      "offset": 3466.799,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "getting to this part of the code, you'll",
      "offset": 3470.48,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "notice that inside the blocks, actually,",
      "offset": 3471.839,
      "duration": 5.321
    },
    {
      "lang": "en",
      "text": "if you go right here,",
      "offset": 3473.52,
      "duration": 3.64
    },
    {
      "lang": "en",
      "text": "you can see these are all labeled with",
      "offset": 3478.4,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "steps. Step one, 2, 4, 9, 10. So this",
      "offset": 3479.92,
      "duration": 7.04
    },
    {
      "lang": "en",
      "text": "step number is arbitrary. Um, you can do",
      "offset": 3483.44,
      "duration": 5.119
    },
    {
      "lang": "en",
      "text": "it in fewer steps, you can do it in more",
      "offset": 3486.96,
      "duration": 2.879
    },
    {
      "lang": "en",
      "text": "steps. This is what I happened to pick",
      "offset": 3488.559,
      "duration": 2.881
    },
    {
      "lang": "en",
      "text": "when I was implementing it in Excel and",
      "offset": 3489.839,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "I kept the same mapping so all my",
      "offset": 3491.44,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "material would translate. Um, attention",
      "offset": 3493.359,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "is steps four through nine. So there's a",
      "offset": 3495.76,
      "duration": 4.559
    },
    {
      "lang": "en",
      "text": "lot of steps in here. Um but the key",
      "offset": 3498.319,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "operations inside the blocks are",
      "offset": 3500.319,
      "duration": 3.441
    },
    {
      "lang": "en",
      "text": "multi-head attention and the multi-layer",
      "offset": 3502.079,
      "duration": 3.121
    },
    {
      "lang": "en",
      "text": "perceptron. So let's talk about",
      "offset": 3503.76,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "attention and I'll talk about it mostly",
      "offset": 3505.2,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "conceptually. Um the way to think about",
      "offset": 3507.599,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "attention is we're going to let the",
      "offset": 3510.4,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "tokens or words talk to each other so",
      "offset": 3512.079,
      "duration": 5.201
    },
    {
      "lang": "en",
      "text": "they can convey their meaning to all the",
      "offset": 3514.64,
      "duration": 4.959
    },
    {
      "lang": "en",
      "text": "other words. So for example, he is a",
      "offset": 3517.28,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "pronoun. Its antecedent Mike is in the",
      "offset": 3519.599,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "sentence. Maybe it needs to find that",
      "offset": 3522.24,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "guy and realize, oh, Mike is my anticene",
      "offset": 3523.92,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "as opposed to say, you know, if there",
      "offset": 3526.72,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "was the name Sally, that's unlikely to",
      "offset": 3528.16,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "be the match of it. But there's other",
      "offset": 3529.92,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "kinds of ways words can communicate to",
      "offset": 3532,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "disambiguate. So, for example, the word",
      "offset": 3533.92,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "quick in English has four different",
      "offset": 3536.079,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "meanings. It can mean moving fast in",
      "offset": 3538.4,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "physical space, but it can also mean",
      "offset": 3540.24,
      "duration": 4.559
    },
    {
      "lang": "en",
      "text": "bright, as in quick of wit. It can be a",
      "offset": 3542.16,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "body part, as in the quick of your",
      "offset": 3544.799,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "fingernail. And in Shakespearean",
      "offset": 3546.24,
      "duration": 5.119
    },
    {
      "lang": "en",
      "text": "English, it can be uh alive as in the",
      "offset": 3548.319,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "phrase the quick and the dead. And",
      "offset": 3551.359,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "knowing that this word moves here helps",
      "offset": 3553.839,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "the model understand that oh, we're",
      "offset": 3556.559,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "probably talking about quick when it's",
      "offset": 3558.079,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "physical space. It helps it predict what",
      "offset": 3560.16,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "the next word could be. Could be fast.",
      "offset": 3562.24,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "It could be moves around, right? But",
      "offset": 3564.319,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "it's not, you know, a body part or your",
      "offset": 3566.48,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "fingernail.",
      "offset": 3568.4,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "And the way I like to think about",
      "offset": 3570.48,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "attention is we've got these tokens,",
      "offset": 3572.319,
      "duration": 6.081
    },
    {
      "lang": "en",
      "text": "these words, and they're sitting in this",
      "offset": 3575.92,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "embedding space. And I like to imagine",
      "offset": 3578.4,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "there's kind of a a weird gravity like",
      "offset": 3579.92,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "celestial mechanics where each of these",
      "offset": 3582.319,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "tokens in attention now suddenly look at",
      "offset": 3584.24,
      "duration": 3.359
    },
    {
      "lang": "en",
      "text": "what position they're at, and they're",
      "offset": 3586.24,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "able to push and pull each other",
      "offset": 3587.599,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "relative to a kind of gravity. And if",
      "offset": 3589.76,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "you remember, gravity is mass times",
      "offset": 3592.319,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "distance. So you've probably heard of",
      "offset": 3594,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "query, key, and value. And there's kind",
      "offset": 3596.24,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "of this file cabinet analogy, but I feel",
      "offset": 3597.92,
      "duration": 3.679
    },
    {
      "lang": "en",
      "text": "like it doesn't capture kind of all the",
      "offset": 3599.92,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "level of interaction between the tokens",
      "offset": 3601.599,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "that's really happening. And what's",
      "offset": 3603.44,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "happening is, you know, if you remember",
      "offset": 3605.2,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "gravity is mass times distance. The",
      "offset": 3607.04,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "distance I like to think of as a measure",
      "offset": 3609.68,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "of relevance. So quick and moves.",
      "offset": 3611.359,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "Whenever they see each other, they're",
      "offset": 3614.16,
      "duration": 3.679
    },
    {
      "lang": "en",
      "text": "like, \"Oh yeah, you and you, we should",
      "offset": 3615.44,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "talk to each other.\" But quick and the",
      "offset": 3617.839,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "period, they probably don't need to talk",
      "offset": 3619.76,
      "duration": 2.96
    },
    {
      "lang": "en",
      "text": "to each other a lot. And that's kind of",
      "offset": 3621.44,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "like distance in terms of gravity. And",
      "offset": 3622.72,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "then I like to think of the value as",
      "offset": 3624.72,
      "duration": 2.8
    },
    {
      "lang": "en",
      "text": "being kind of like mass. The kind of",
      "offset": 3626,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "action they're going to exert on each",
      "offset": 3627.52,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "other.",
      "offset": 3629.04,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "And what's happening is let's go back to",
      "offset": 3630.72,
      "duration": 3.359
    },
    {
      "lang": "en",
      "text": "what we talked about with embeddings.",
      "offset": 3632.96,
      "duration": 2.399
    },
    {
      "lang": "en",
      "text": "We've got moves which is sitting",
      "offset": 3634.079,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "somewhere in the embedding space. And if",
      "offset": 3635.359,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "you remember that co-occurrence matrix",
      "offset": 3638.24,
      "duration": 2.8
    },
    {
      "lang": "en",
      "text": "moves has been used in a lot of",
      "offset": 3639.76,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "sentences. In some sentences moves was",
      "offset": 3641.04,
      "duration": 6.319
    },
    {
      "lang": "en",
      "text": "used to describe rabbits, right? Or",
      "offset": 3644.48,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "cheetahs or animals or things that moved",
      "offset": 3647.359,
      "duration": 4.561
    },
    {
      "lang": "en",
      "text": "fast. So there's some other point in",
      "offset": 3650.16,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "this embedding space that we don't have",
      "offset": 3651.92,
      "duration": 4.879
    },
    {
      "lang": "en",
      "text": "yet that represents moves in a fast",
      "offset": 3654.319,
      "duration": 4.881
    },
    {
      "lang": "en",
      "text": "context. And then moves was used in some",
      "offset": 3656.799,
      "duration": 5.361
    },
    {
      "lang": "en",
      "text": "sentences to describe slugs or penguins.",
      "offset": 3659.2,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "And so moves in that case was implying",
      "offset": 3662.16,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "slow. But the embedding for moves",
      "offset": 3664.64,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "unfortunately has to capture all of",
      "offset": 3666.88,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "those meanings together. But now that we",
      "offset": 3668.4,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "know quick is here, we can change that.",
      "offset": 3670.64,
      "duration": 5.679
    },
    {
      "lang": "en",
      "text": "we can say, oh, I'm going to shift the",
      "offset": 3673.44,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "position of moves from the regular",
      "offset": 3676.319,
      "duration": 5.921
    },
    {
      "lang": "en",
      "text": "generic version of moves to the moves",
      "offset": 3678.96,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "fast. So, I've kind of disambiguated the",
      "offset": 3682.24,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "word. I've shifted its position in space",
      "offset": 3684.4,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "to capture its meaning.",
      "offset": 3686.079,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "Um, I'm not going to go through all the",
      "offset": 3688.72,
      "duration": 3.599
    },
    {
      "lang": "en",
      "text": "steps of attention, but I think the most",
      "offset": 3690.319,
      "duration": 6.961
    },
    {
      "lang": "en",
      "text": "salient part of attention to see is um",
      "offset": 3692.319,
      "duration": 7.681
    },
    {
      "lang": "en",
      "text": "step seven, the most famous thing that",
      "offset": 3697.28,
      "duration": 6.279
    },
    {
      "lang": "en",
      "text": "people usually show.",
      "offset": 3700,
      "duration": 3.559
    },
    {
      "lang": "en",
      "text": "right here. So you can see it says Mike",
      "offset": 3705.04,
      "duration": 5.279
    },
    {
      "lang": "en",
      "text": "is quick on the horizontal and then Mike",
      "offset": 3707.92,
      "duration": 5.199
    },
    {
      "lang": "en",
      "text": "is quick period he moves on the",
      "offset": 3710.319,
      "duration": 5.921
    },
    {
      "lang": "en",
      "text": "vertical. So what this is is you can see",
      "offset": 3713.119,
      "duration": 6.321
    },
    {
      "lang": "en",
      "text": "how much relevance or attention each",
      "offset": 3716.24,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "word is paying to every other word. And",
      "offset": 3719.44,
      "duration": 3.359
    },
    {
      "lang": "en",
      "text": "by the way what you're seeing here is",
      "offset": 3721.44,
      "duration": 2.96
    },
    {
      "lang": "en",
      "text": "just the first head there multiple of",
      "offset": 3722.799,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "these heads. So if you scroll this to",
      "offset": 3724.4,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "the right 64 spaces you'll see another",
      "offset": 3726.4,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "matrix that looks like this. And uh",
      "offset": 3728.319,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "there's a couple things to notice. The",
      "offset": 3730.799,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "the biggest thing to notice here is that",
      "offset": 3732.24,
      "duration": 5.599
    },
    {
      "lang": "en",
      "text": "uh the upper triangle is all zeros. And",
      "offset": 3734.799,
      "duration": 7.76
    },
    {
      "lang": "en",
      "text": "that's because in transformers like GPT2",
      "offset": 3737.839,
      "duration": 7.041
    },
    {
      "lang": "en",
      "text": "and decoderbased transformers, we have",
      "offset": 3742.559,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "this rule that no token can look",
      "offset": 3744.88,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "forward. They can only look at the",
      "offset": 3747.119,
      "duration": 3.041
    },
    {
      "lang": "en",
      "text": "tokens before it. Those are the only",
      "offset": 3748.4,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "ones that can influence it. And then the",
      "offset": 3750.16,
      "duration": 3.199
    },
    {
      "lang": "en",
      "text": "other key property is each of these",
      "offset": 3751.44,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "values, each row sums up to one. So you",
      "offset": 3753.359,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "can think about the percentage of",
      "offset": 3755.839,
      "duration": 3.361
    },
    {
      "lang": "en",
      "text": "attention each word is paying to the",
      "offset": 3756.96,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "other tokens. So here for example moves",
      "offset": 3759.2,
      "duration": 6.639
    },
    {
      "lang": "en",
      "text": "right 16% of its attention here in the",
      "offset": 3762,
      "duration": 6.319
    },
    {
      "lang": "en",
      "text": "first head of in this case the last",
      "offset": 3765.839,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "block is paying 16% of its attention to",
      "offset": 3768.319,
      "duration": 5.201
    },
    {
      "lang": "en",
      "text": "the word Mike 23% of its attention to is",
      "offset": 3770.559,
      "duration": 6.161
    },
    {
      "lang": "en",
      "text": "and so forth.",
      "offset": 3773.52,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "Okay. Next up the multi-layer",
      "offset": 3776.72,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "perceptron. Okay. Okay, so now this is",
      "offset": 3779.04,
      "duration": 5.039
    },
    {
      "lang": "en",
      "text": "the second major operation inside each",
      "offset": 3780.88,
      "duration": 5.679
    },
    {
      "lang": "en",
      "text": "block or layer. Uh, and the reason I",
      "offset": 3784.079,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "want to cover this in a little more",
      "offset": 3786.559,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "detail is I want to explain what neural",
      "offset": 3787.599,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "network is and it helps give a little",
      "offset": 3789.599,
      "duration": 2.96
    },
    {
      "lang": "en",
      "text": "more understanding to how the model",
      "offset": 3791.119,
      "duration": 3.281
    },
    {
      "lang": "en",
      "text": "actually learns. The key algorithm",
      "offset": 3792.559,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "called back propagation. So if you",
      "offset": 3794.4,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "haven't seen a neural network before, it",
      "offset": 3796.64,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "is a computational model inspired by the",
      "offset": 3798.64,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "human brain. It is not a direct mimic or",
      "offset": 3800.72,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "simulation of how the brain works.",
      "offset": 3802.559,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "Inside the brain, we have these things",
      "offset": 3804.48,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "called neurons. These neurons are all",
      "offset": 3806.16,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "connected to each other and you've got a",
      "offset": 3808.319,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "bunch of connections incoming from other",
      "offset": 3810.16,
      "duration": 3.199
    },
    {
      "lang": "en",
      "text": "neurons and you've got a bunch of",
      "offset": 3811.92,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "connections outgoing to other neurons.",
      "offset": 3813.359,
      "duration": 5.121
    },
    {
      "lang": "en",
      "text": "And then in between you have this axon",
      "offset": 3814.96,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "right here",
      "offset": 3818.48,
      "duration": 5.119
    },
    {
      "lang": "en",
      "text": "and the axon has an all or nothing",
      "offset": 3820.64,
      "duration": 5.439
    },
    {
      "lang": "en",
      "text": "activation behavior. If there's a",
      "offset": 3823.599,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "sufficient amount of pattern of input",
      "offset": 3826.079,
      "duration": 4.801
    },
    {
      "lang": "en",
      "text": "that shows up, the axon will activate",
      "offset": 3828.319,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "and it will send a signal out to its",
      "offset": 3830.88,
      "duration": 4.479
    },
    {
      "lang": "en",
      "text": "output. But if the activation doesn't",
      "offset": 3832.799,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "have enough meet some threshold, you'll",
      "offset": 3835.359,
      "duration": 4.881
    },
    {
      "lang": "en",
      "text": "have these failed initiations and no",
      "offset": 3837.839,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "signal will be sent to the output. It'll",
      "offset": 3840.24,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "be completely silent. As far as the",
      "offset": 3841.599,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "other output neurons connected, this",
      "offset": 3843.44,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "neuron is not firing something. You",
      "offset": 3845.52,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "know, the signal wasn't getting through.",
      "offset": 3847.44,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "And so we model this mathematically uh",
      "offset": 3849.28,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "with this diagram where we've got a",
      "offset": 3851.839,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "bunch of inputs x1 through xn and these",
      "offset": 3853.92,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "are just numbers. Uh these will be our",
      "offset": 3856.079,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "embedding dimension numbers. And then",
      "offset": 3858.079,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "we've got another series of numbers",
      "offset": 3860.16,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "called weights. W1, W2 through WN. And",
      "offset": 3861.68,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "we're simply multiplying the X's times",
      "offset": 3864.72,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "the W's, adding them together, adding an",
      "offset": 3866.88,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "additional another number called a bias",
      "offset": 3869.44,
      "duration": 3.679
    },
    {
      "lang": "en",
      "text": "term. And then we put it through an",
      "offset": 3870.96,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "activation function. And this activation",
      "offset": 3873.119,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "function is designed to roughly mimic",
      "offset": 3875.039,
      "duration": 4.481
    },
    {
      "lang": "en",
      "text": "what happens in the brain. The easiest",
      "offset": 3877.119,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "one to understand is this one, ReLU,",
      "offset": 3879.52,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "which is basically saying when I",
      "offset": 3881.599,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "multiply and add all the inputs coming",
      "offset": 3883.2,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "in against their weights, if the result",
      "offset": 3885.2,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "is negative, then I do do nothing. It",
      "offset": 3887.28,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "comes out as zero. Um, if it's positive,",
      "offset": 3889.44,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "then I just pass it through as is.",
      "offset": 3891.52,
      "duration": 5.039
    },
    {
      "lang": "en",
      "text": "There's a whole zoo of these activation",
      "offset": 3894.24,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "functions.",
      "offset": 3896.559,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "So then what we do is we take these",
      "offset": 3898.4,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "neurons and we stitch them together into",
      "offset": 3900.079,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "a network of neurons, hence an",
      "offset": 3902.24,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "artificial neural network. Now there's a",
      "offset": 3904.24,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "lot of ways you can stitch these",
      "offset": 3906.4,
      "duration": 4.639
    },
    {
      "lang": "en",
      "text": "together. In the case of uh transformers",
      "offset": 3907.68,
      "duration": 5.919
    },
    {
      "lang": "en",
      "text": "in GPD2, we do it in a pattern called",
      "offset": 3911.039,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "the multi-layer perceptron. You will",
      "offset": 3913.599,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "also see it referred to as a fully",
      "offset": 3915.839,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "connected network, an uh a feed forward",
      "offset": 3917.839,
      "duration": 5.041
    },
    {
      "lang": "en",
      "text": "neural network or just simply the neural",
      "offset": 3921.039,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "network. Um it is called by all these",
      "offset": 3922.88,
      "duration": 4.239
    },
    {
      "lang": "en",
      "text": "terms. These are not directly identical",
      "offset": 3924.96,
      "duration": 4.879
    },
    {
      "lang": "en",
      "text": "terms, but they all overlap. And the way",
      "offset": 3927.119,
      "duration": 5.121
    },
    {
      "lang": "en",
      "text": "the MLP pattern looks is you have your",
      "offset": 3929.839,
      "duration": 5.361
    },
    {
      "lang": "en",
      "text": "neurons arranged in these columns of",
      "offset": 3932.24,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "neurons and these are called layers. And",
      "offset": 3935.2,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "each layer in the multi-layer perceptron",
      "offset": 3938,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "has a node and nodes in each layer can",
      "offset": 3940.88,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "are fully connected to every other node",
      "offset": 3942.96,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "in its preceding input but no other. So",
      "offset": 3944.799,
      "duration": 5.601
    },
    {
      "lang": "en",
      "text": "this node right here can see all of its",
      "offset": 3948,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "inputs nodes. It's all connected to all",
      "offset": 3950.4,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "of them. But it cannot talk to any of",
      "offset": 3952.16,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "these directly. Everything that it gets",
      "offset": 3954,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "is mediated through this intermediate",
      "offset": 3955.92,
      "duration": 3.679
    },
    {
      "lang": "en",
      "text": "layer between it. And these layers",
      "offset": 3957.76,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "between the input and the output are",
      "offset": 3959.599,
      "duration": 4.561
    },
    {
      "lang": "en",
      "text": "simply just called hidden layers.",
      "offset": 3961.2,
      "duration": 4.639
    },
    {
      "lang": "en",
      "text": "Uh the last thing maybe you should know",
      "offset": 3964.16,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "as background on this is that neural",
      "offset": 3965.839,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "networks can be more efficient to write",
      "offset": 3967.68,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "as a matrix multiplication. So this",
      "offset": 3969.68,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "process got two neurons with a set of",
      "offset": 3971.68,
      "duration": 8.639
    },
    {
      "lang": "en",
      "text": "weights. So W1 * W1 * X1 W21 * X2 + B.",
      "offset": 3974.16,
      "duration": 7.919
    },
    {
      "lang": "en",
      "text": "This is can be written as a matrix",
      "offset": 3980.319,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "multiplication where you just separate",
      "offset": 3982.079,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "all the weights into one matrix, all the",
      "offset": 3983.839,
      "duration": 3.361
    },
    {
      "lang": "en",
      "text": "inputs into one matrix and all the",
      "offset": 3985.68,
      "duration": 3.439
    },
    {
      "lang": "en",
      "text": "biases into one matrix and then you can",
      "offset": 3987.2,
      "duration": 6.159
    },
    {
      "lang": "en",
      "text": "write it as this large w * x + b um",
      "offset": 3989.119,
      "duration": 6.24
    },
    {
      "lang": "en",
      "text": "equals the representation of the same",
      "offset": 3993.359,
      "duration": 3.281
    },
    {
      "lang": "en",
      "text": "thing of running a bunch of these",
      "offset": 3995.359,
      "duration": 2.72
    },
    {
      "lang": "en",
      "text": "neurons together. If you don't know your",
      "offset": 3996.64,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "matrix multiplication, I'm I like this",
      "offset": 3998.079,
      "duration": 5.121
    },
    {
      "lang": "en",
      "text": "website um which has a nice interactive",
      "offset": 4000.16,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "visual demonstration of what matrix",
      "offset": 4003.2,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "multiplication looks like. So you hit",
      "offset": 4004.72,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "this and then you keep going through",
      "offset": 4006.96,
      "duration": 2.879
    },
    {
      "lang": "en",
      "text": "step and you can kind of convince",
      "offset": 4008.559,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "yourself that what I showed here matches",
      "offset": 4009.839,
      "duration": 5.441
    },
    {
      "lang": "en",
      "text": "what's on that web page. So the key",
      "offset": 4012.559,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "property though of why and why MLPS are",
      "offset": 4015.28,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "so important is that they are universal",
      "offset": 4017.599,
      "duration": 5.601
    },
    {
      "lang": "en",
      "text": "trainable approximators to any function",
      "offset": 4020.72,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "purely from its input and output. With",
      "offset": 4023.2,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "enough neurons an MLP can approximate",
      "offset": 4025.52,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "almost any function.",
      "offset": 4028.24,
      "duration": 4.799
    },
    {
      "lang": "en",
      "text": "So let's just take a simple example like",
      "offset": 4031.28,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "a parabola and we're going to imagine",
      "offset": 4033.039,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "we're going to use a simple neural",
      "offset": 4035.119,
      "duration": 3.361
    },
    {
      "lang": "en",
      "text": "network with a relu activation to try",
      "offset": 4036.559,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "and approximate it. We'll have one input",
      "offset": 4038.48,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "node, one output because we have an x",
      "offset": 4040.4,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "going into a y and then let's just use",
      "offset": 4042.24,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "two nodes in our hidden layer. And those",
      "offset": 4044.319,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "two nodes will use a relu activation.",
      "offset": 4046.24,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "Well, without doing the math, you can",
      "offset": 4048.72,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "kind of imagine just by matching shapes",
      "offset": 4050.24,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "how you might do this. I'll take the",
      "offset": 4052.48,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "relu and I can take this part of the rel",
      "offset": 4054.079,
      "duration": 5.361
    },
    {
      "lang": "en",
      "text": "match it to the right half of my",
      "offset": 4057.44,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "parabola. And then I can take another",
      "offset": 4059.44,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "relu, I can flip it, and then I can",
      "offset": 4061.28,
      "duration": 5.279
    },
    {
      "lang": "en",
      "text": "match it to the left half. And then I",
      "offset": 4064,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "can add them together and I've got some",
      "offset": 4066.559,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "kind of approximation to my parabola, at",
      "offset": 4068.48,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "least on this domain of x that we're",
      "offset": 4070.16,
      "duration": 4.959
    },
    {
      "lang": "en",
      "text": "looking at. And that's what I've done in",
      "offset": 4072.48,
      "duration": 7.079
    },
    {
      "lang": "en",
      "text": "this example here,",
      "offset": 4075.119,
      "duration": 4.44
    },
    {
      "lang": "en",
      "text": "which",
      "offset": 4080.16,
      "duration": 6.28
    },
    {
      "lang": "en",
      "text": "let's see if the Wi-Fi behaves for us.",
      "offset": 4081.76,
      "duration": 4.68
    },
    {
      "lang": "en",
      "text": "There we go. So here you can actually do",
      "offset": 4087.28,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "this simple neural network and you can",
      "offset": 4090.16,
      "duration": 3.199
    },
    {
      "lang": "en",
      "text": "try to match it to a parabola and you",
      "offset": 4091.92,
      "duration": 3.679
    },
    {
      "lang": "en",
      "text": "can interactively move this and you can",
      "offset": 4093.359,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "see and this is a measure of error up",
      "offset": 4095.599,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "here called mean square error. You can",
      "offset": 4097.52,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "try and see how good you can get your",
      "offset": 4099.44,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "level of error and you can see the",
      "offset": 4101.52,
      "duration": 3.199
    },
    {
      "lang": "en",
      "text": "action here. We're basically changing",
      "offset": 4102.64,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "the different line pieces that we're",
      "offset": 4104.719,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "using that are made out of relus to try",
      "offset": 4107.12,
      "duration": 5.039
    },
    {
      "lang": "en",
      "text": "and match this parabola. This can kind",
      "offset": 4109.199,
      "duration": 5.681
    },
    {
      "lang": "en",
      "text": "of give you a a feel for what the model",
      "offset": 4112.159,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "is actually trying to do when it's",
      "offset": 4114.88,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "trying to match a function.",
      "offset": 4116.08,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "And you can think of this like more",
      "offset": 4118.88,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "neurons means more lines which means a",
      "offset": 4120.56,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "better approximation. So with eight",
      "offset": 4123.6,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "neurons the parabola looks like this.",
      "offset": 4125.12,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "With 20 neurons it looks like this. And",
      "offset": 4127.44,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "with 200 neurons you can barely tell the",
      "offset": 4129.6,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "difference at least at this scale. But",
      "offset": 4131.52,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "the other key thing is that we don't",
      "offset": 4133.92,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "have to use trial and error to find this",
      "offset": 4136.08,
      "duration": 3.599
    },
    {
      "lang": "en",
      "text": "out. Especially once you get 200 neurons",
      "offset": 4137.839,
      "duration": 3.121
    },
    {
      "lang": "en",
      "text": "imagine doing what I was doing with that",
      "offset": 4139.679,
      "duration": 2.881
    },
    {
      "lang": "en",
      "text": "fiddling.",
      "offset": 4140.96,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "Um, oh uh, so this is a theorem with",
      "offset": 4142.56,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "enough neurons that you can approximate",
      "offset": 4145.44,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "almost any function. It's called the",
      "offset": 4146.96,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "universal approximation theorem. But the",
      "offset": 4148.48,
      "duration": 3.679
    },
    {
      "lang": "en",
      "text": "key thing is you combine that with a",
      "offset": 4150.48,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "special algorithm called back",
      "offset": 4152.159,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "propagation which lets us learn any",
      "offset": 4153.52,
      "duration": 4.239
    },
    {
      "lang": "en",
      "text": "function purely from its inputs and",
      "offset": 4156.159,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "outputs without having to twig twiddle",
      "offset": 4157.759,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "those knobs. It'll do it for us. And",
      "offset": 4160,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "that's important because what we're",
      "offset": 4163.279,
      "duration": 2.801
    },
    {
      "lang": "en",
      "text": "going to ask this multi-layer perceptron",
      "offset": 4164.4,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "to do is the core mechanism job of a",
      "offset": 4166.08,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "transformer, which is I'm going to give",
      "offset": 4169.04,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "it a word. I'm going to give it the",
      "offset": 4170.96,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "embedding of a token and I'm going to",
      "offset": 4172.64,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "ask it predict what the embedding of the",
      "offset": 4174.64,
      "duration": 4.639
    },
    {
      "lang": "en",
      "text": "next token is. I don't know what that",
      "offset": 4176.799,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "function is, but I can grab text on the",
      "offset": 4179.279,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "internet and I can grab one word and I",
      "offset": 4181.679,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "can grab the word that comes after it",
      "offset": 4183.44,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "and I can give it to the perceptron and",
      "offset": 4184.719,
      "duration": 3.761
    },
    {
      "lang": "en",
      "text": "I can say learn from this input and",
      "offset": 4186.56,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "output what that mapping function is as",
      "offset": 4188.48,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "crazy as it might be. And what will",
      "offset": 4190.64,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "happen is back propagation will look at",
      "offset": 4192.4,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "the input. It'll look at the output we",
      "offset": 4194.08,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "got from the model when it was initially",
      "offset": 4196.08,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "randomized. It'll look at the ground",
      "offset": 4197.52,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "truth from what came pulled from the",
      "offset": 4199.12,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "internet and it will look at how we need",
      "offset": 4200.96,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "to adjust the parameters and weights to",
      "offset": 4202.88,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "change the perceptron to get more",
      "offset": 4205.12,
      "duration": 3.039
    },
    {
      "lang": "en",
      "text": "accurate at making that prediction and",
      "offset": 4206.48,
      "duration": 3.199
    },
    {
      "lang": "en",
      "text": "after enough iterations it'll get better",
      "offset": 4208.159,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "and better and actually get begin to",
      "offset": 4209.679,
      "duration": 5.201
    },
    {
      "lang": "en",
      "text": "start matching the function. Um the",
      "offset": 4211.679,
      "duration": 5.121
    },
    {
      "lang": "en",
      "text": "canonical analogy to understand what's",
      "offset": 4214.88,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "happening in back propagation also known",
      "offset": 4216.8,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "as for our purposes gradient descent is",
      "offset": 4218.64,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "a lost hiker trying to get down a foggy",
      "offset": 4221.76,
      "duration": 4.479
    },
    {
      "lang": "en",
      "text": "mountain. um and you're at the top of",
      "offset": 4224.08,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "this foggy mountain as a hiker. I've",
      "offset": 4226.239,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "actually been in this situation and you",
      "offset": 4228.08,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "can't see any of the landscape. So, you",
      "offset": 4230.4,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "don't know which direction to go to get",
      "offset": 4232.56,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "off the mountain. Well, the one thing",
      "offset": 4233.84,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "you can do is you can look down at the",
      "offset": 4235.84,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "ground and you can say, \"Oh, whichever",
      "offset": 4238.64,
      "duration": 5.039
    },
    {
      "lang": "en",
      "text": "way is going down, uh that's going to be",
      "offset": 4241.04,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "the area of of towards getting off the",
      "offset": 4243.679,
      "duration": 4.801
    },
    {
      "lang": "en",
      "text": "mountain.\" By the way, actually in real",
      "offset": 4246.56,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "life, I have tried this. It does not",
      "offset": 4248.48,
      "duration": 5.679
    },
    {
      "lang": "en",
      "text": "work. Uh this is how I got lost. Um so",
      "offset": 4249.92,
      "duration": 6.72
    },
    {
      "lang": "en",
      "text": "uh this is a hiker representing uh the",
      "offset": 4254.159,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "hiker in this analogy represents the",
      "offset": 4256.64,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "model parameters. It's in some space but",
      "offset": 4258.32,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "we don't know where to move the model",
      "offset": 4260.8,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "parameters to get the least amount of",
      "offset": 4262.32,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "error. And the mountain represents the",
      "offset": 4264.4,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "error. It represents how wrong we are at",
      "offset": 4266.88,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "the current position of where the hiker",
      "offset": 4269.6,
      "duration": 4.559
    },
    {
      "lang": "en",
      "text": "is or where the parameters are. And the",
      "offset": 4271.84,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "mountain is foggy because we can tell",
      "offset": 4274.159,
      "duration": 3.761
    },
    {
      "lang": "en",
      "text": "the amount of error when I give it an",
      "offset": 4276.08,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "input and it makes a prediction for the",
      "offset": 4277.92,
      "duration": 3.279
    },
    {
      "lang": "en",
      "text": "next token and we compare it. We can",
      "offset": 4279.92,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "say, \"Oh, it's wrong.\" But we don't know",
      "offset": 4281.199,
      "duration": 4.241
    },
    {
      "lang": "en",
      "text": "how to shift the model parameters to get",
      "offset": 4282.96,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "low lower error. But calculus will give",
      "offset": 4285.44,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "us that slope. It'll tell us where the",
      "offset": 4288.48,
      "duration": 4.239
    },
    {
      "lang": "en",
      "text": "elevation is going down. It won't tell",
      "offset": 4290.64,
      "duration": 3.519
    },
    {
      "lang": "en",
      "text": "us what the whole mountain looks like,",
      "offset": 4292.719,
      "duration": 2.641
    },
    {
      "lang": "en",
      "text": "but it'll just say where you are",
      "offset": 4294.159,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "standing right now. Go in this",
      "offset": 4295.36,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "direction, and you'll decrease the",
      "offset": 4297.199,
      "duration": 3.281
    },
    {
      "lang": "en",
      "text": "amount of area you've got. And you use",
      "offset": 4298.56,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "that to find your way down the mountain,",
      "offset": 4300.48,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "so to speak, of the parameters and find",
      "offset": 4302.64,
      "duration": 4.559
    },
    {
      "lang": "en",
      "text": "a minimum.",
      "offset": 4304.88,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "So that brings us to the MLP stage. uh",
      "offset": 4307.199,
      "duration": 7.121
    },
    {
      "lang": "en",
      "text": "it's steps 13, 14, and 15 in the model.",
      "offset": 4310.32,
      "duration": 7.8
    },
    {
      "lang": "en",
      "text": "So let's go back here.",
      "offset": 4314.32,
      "duration": 3.8
    },
    {
      "lang": "en",
      "text": "So uh you can see all the formulas here.",
      "offset": 4319.44,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "What I'm going to do is going to show",
      "offset": 4322.8,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "you them in slide form",
      "offset": 4324.08,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "and I'm going to graphically show what's",
      "offset": 4327.04,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "happening in the uh GPD2 MLP stage. So",
      "offset": 4329.04,
      "duration": 6.96
    },
    {
      "lang": "en",
      "text": "GPD2's MLP has only one hidden layer.",
      "offset": 4332.56,
      "duration": 7.44
    },
    {
      "lang": "en",
      "text": "The input layer right here has 768 of",
      "offset": 4336,
      "duration": 6.32
    },
    {
      "lang": "en",
      "text": "these X inputs. Why? Because we're going",
      "offset": 4340,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "to give it an embedding. We're going to",
      "offset": 4342.32,
      "duration": 2.8
    },
    {
      "lang": "en",
      "text": "say give it here's the embedding.",
      "offset": 4343.92,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "Predict it. So I'm going to give it 768",
      "offset": 4345.12,
      "duration": 5.599
    },
    {
      "lang": "en",
      "text": "numbers of the preceding token that I",
      "offset": 4347.92,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "want it to predict afterwards. And then",
      "offset": 4350.719,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "its output layer is 768 numbers for the",
      "offset": 4352.64,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "predicted embedding token. So input and",
      "offset": 4355.679,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "output are 768. They're our embedding",
      "offset": 4357.52,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "dimension. And then it's got one hidden",
      "offset": 4359.28,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "layer which is bigger. this ratio of",
      "offset": 4361.44,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "four times the embedding dimension turns",
      "offset": 4364.08,
      "duration": 3.599
    },
    {
      "lang": "en",
      "text": "out to be empirically useful and lots of",
      "offset": 4365.84,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "models do it but I don't know if you",
      "offset": 4367.679,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "could figure that out just uh from first",
      "offset": 4369.12,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "principles it's kind of empirically been",
      "offset": 4371.679,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "determined and we have three steps here",
      "offset": 4373.199,
      "duration": 6.161
    },
    {
      "lang": "en",
      "text": "for applying our weights and bias",
      "offset": 4376.719,
      "duration": 4.241
    },
    {
      "lang": "en",
      "text": "applying our activation function which",
      "offset": 4379.36,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "in this case is the gu activation",
      "offset": 4380.96,
      "duration": 3.759
    },
    {
      "lang": "en",
      "text": "function and then we project that back",
      "offset": 4382.64,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "down to our embedding dimension so you",
      "offset": 4384.719,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "can think of it this way we take our",
      "offset": 4387.76,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "embeddings from a previous step and then",
      "offset": 4388.88,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "what we're doing is we're taking those",
      "offset": 4391.679,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "embedding values and we're going to send",
      "offset": 4393.04,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "each embedding value into its position",
      "offset": 4395.28,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "inside the MLP and then we run it",
      "offset": 4397.92,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "through the model",
      "offset": 4400.64,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "and then these are now the embedding",
      "offset": 4402.8,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "values that come out are the embedding",
      "offset": 4405.6,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "values of the predicted token and then",
      "offset": 4407.36,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "we take the next token in our prompt and",
      "offset": 4409.84,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "then run it through the MLP again in",
      "offset": 4412.64,
      "duration": 3.599
    },
    {
      "lang": "en",
      "text": "practice you do this in parallel but",
      "offset": 4414.88,
      "duration": 2.48
    },
    {
      "lang": "en",
      "text": "conceptually you can think of it this",
      "offset": 4416.239,
      "duration": 3.761
    },
    {
      "lang": "en",
      "text": "way as happening one after the other",
      "offset": 4417.36,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "okay so what's happening in these three",
      "offset": 4420,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "steps is really just a combination of",
      "offset": 4422,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "matrix add and multiply. So we take the",
      "offset": 4424,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "result of our previous step which is",
      "offset": 4426.56,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "step 12 which I've not gone into. Um and",
      "offset": 4428,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "then we have some learned weight matrix",
      "offset": 4431.28,
      "duration": 4.879
    },
    {
      "lang": "en",
      "text": "which you see is MLP FC weights that's",
      "offset": 4433.44,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "the how they decide to name it and we",
      "offset": 4436.159,
      "duration": 4.881
    },
    {
      "lang": "en",
      "text": "multiply those. So here's our matrix",
      "offset": 4438.8,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "multiply and then we add it to another",
      "offset": 4441.04,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "bias matrix. So written as matrix",
      "offset": 4443.52,
      "duration": 6.56
    },
    {
      "lang": "en",
      "text": "multiplication, step 13 is just step 12",
      "offset": 4446.08,
      "duration": 5.84
    },
    {
      "lang": "en",
      "text": "times some weight matrix plus some",
      "offset": 4450.08,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "learned bias matrix. Then we apply a GLU",
      "offset": 4451.92,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "activation function which I showed the",
      "offset": 4455.36,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "diagram earlier. The the details are not",
      "offset": 4457.44,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "really important. And then we then do",
      "offset": 4459.44,
      "duration": 4.799
    },
    {
      "lang": "en",
      "text": "our projection which is the remaining",
      "offset": 4462.4,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "step to get down to the 768. So we take",
      "offset": 4464.239,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "the result of the previous step which",
      "offset": 4467.04,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "was activation function. we apply a",
      "offset": 4468.4,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "different learned weight matrix, a new",
      "offset": 4470.88,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "set of weights that gets learned and",
      "offset": 4472.88,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "that's to do with a matrix multiply and",
      "offset": 4475.28,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "then another matrix add. So step 15 is",
      "offset": 4476.96,
      "duration": 6.96
    },
    {
      "lang": "en",
      "text": "just step 14 times some weight matrix",
      "offset": 4480.08,
      "duration": 7.76
    },
    {
      "lang": "en",
      "text": "plus some projection matrix.",
      "offset": 4483.92,
      "duration": 6.64
    },
    {
      "lang": "en",
      "text": "Um before we leave back propagation uh",
      "offset": 4487.84,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "you might remember that I talked about",
      "offset": 4490.56,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "how embeddings are learned by the model",
      "offset": 4492.8,
      "duration": 5.439
    },
    {
      "lang": "en",
      "text": "both the token and in the case of GPD2",
      "offset": 4496.08,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "they started learning the position",
      "offset": 4498.239,
      "duration": 2.96
    },
    {
      "lang": "en",
      "text": "embeddings. So the key thing I want you",
      "offset": 4499.44,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "to remember is that back propagation is",
      "offset": 4501.199,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "a generic optimization algorithm. It is",
      "offset": 4502.88,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "not just for the weights and biases of",
      "offset": 4505.52,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "the MLP. It can be used for other parts",
      "offset": 4507.28,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "of the transformer too. And in fact it",
      "offset": 4509.6,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "is. It's used for the token embeddings.",
      "offset": 4511.36,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "It's used for position embeddings. It's",
      "offset": 4513.12,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "used for all the parameters and",
      "offset": 4515.04,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "attention the queries keys and values if",
      "offset": 4516.56,
      "duration": 3.679
    },
    {
      "lang": "en",
      "text": "you've heard that term all use back",
      "offset": 4518.56,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "propagation even other parts layer",
      "offset": 4520.239,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "normalization the like use back",
      "offset": 4522.48,
      "duration": 3.759
    },
    {
      "lang": "en",
      "text": "propagation to get optimized and the",
      "offset": 4524.4,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "analogy I want you to think about is you",
      "offset": 4526.239,
      "duration": 4.561
    },
    {
      "lang": "en",
      "text": "know back propagation and optimizing a",
      "offset": 4528.8,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "model this way is like a chef imitating",
      "offset": 4530.8,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "a dish right uh if you remember those",
      "offset": 4532.48,
      "duration": 5.199
    },
    {
      "lang": "en",
      "text": "cooking shows they tell the chef here",
      "offset": 4535.28,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "are your ingredients here's the final",
      "offset": 4537.679,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "dish and you got to taste it and maybe",
      "offset": 4539.679,
      "duration": 3.361
    },
    {
      "lang": "en",
      "text": "we give you some tools that you got to",
      "offset": 4541.52,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "use and you've got to make this dish and",
      "offset": 4543.04,
      "duration": 2.88
    },
    {
      "lang": "en",
      "text": "then they have them compete against",
      "offset": 4544.64,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "somebody else, right? We kind of do the",
      "offset": 4545.92,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "same thing with the model. We basically",
      "offset": 4547.76,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "give it some input text. We tell it",
      "offset": 4549.44,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "here's the next token afterwards. We",
      "offset": 4551.6,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "want you to imitate it and then we",
      "offset": 4553.28,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "define the steps in the architecture. We",
      "offset": 4554.8,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "want you to do attention then MP and",
      "offset": 4557.12,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "then you the chef back propagation",
      "offset": 4559.12,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "decide how much to mix of each",
      "offset": 4561.36,
      "duration": 2.64
    },
    {
      "lang": "en",
      "text": "ingredient at each step to get the",
      "offset": 4562.64,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "desired output.",
      "offset": 4564,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "Okay. Iteration. How we doing on time?",
      "offset": 4566.32,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "Okay, good.",
      "offset": 4568.96,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "So uh I've got this in our simplified",
      "offset": 4570.96,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "diagram which is 12x which represents",
      "offset": 4573.04,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "that what happens is we run attention",
      "offset": 4576.48,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "and we run the perceptron but we ask the",
      "offset": 4578.8,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "model to continue to refine iteratively",
      "offset": 4581.36,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "its prediction for what the next model",
      "offset": 4584.4,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "is. It has all the tokens talk to each",
      "offset": 4586,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "other. It makes a next token prediction",
      "offset": 4588.48,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "and then it does it again and again and",
      "offset": 4590,
      "duration": 4.239
    },
    {
      "lang": "en",
      "text": "again. So it goes through each of these",
      "offset": 4592.08,
      "duration": 5.119
    },
    {
      "lang": "en",
      "text": "steps. In the case of GPT2 small it's 12",
      "offset": 4594.239,
      "duration": 5.681
    },
    {
      "lang": "en",
      "text": "times. uh in the case of your modern",
      "offset": 4597.199,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "state-of-the-art model, it's going to be",
      "offset": 4599.92,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "many more times than that. The key thing",
      "offset": 4601.28,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "I want you to remember though is that",
      "offset": 4603.6,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "each block is performing identical",
      "offset": 4604.88,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "operations, but the weights are",
      "offset": 4607.52,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "different. Each one has different",
      "offset": 4609.76,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "parameters. And you can see this if you",
      "offset": 4611.12,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "look at the code here, you see, for",
      "offset": 4614,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "example, here we're grabbing the weights",
      "offset": 4615.84,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "of in this case the MLP. And you see",
      "offset": 4617.76,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "that it's got MLP_C.",
      "offset": 4620,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "This is just the name for that stage.",
      "offset": 4622.159,
      "duration": 2.56
    },
    {
      "lang": "en",
      "text": "But the key thing I want you to pay",
      "offset": 4623.6,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "attention to is this H11 that basically",
      "offset": 4624.719,
      "duration": 4.881
    },
    {
      "lang": "en",
      "text": "is saying hidden block or hidden layer.",
      "offset": 4627.28,
      "duration": 6.16
    },
    {
      "lang": "en",
      "text": "This is grabbing the hidden layer MLP,",
      "offset": 4629.6,
      "duration": 7.2
    },
    {
      "lang": "en",
      "text": "sorry, the MLP's weight matrix for the",
      "offset": 4633.44,
      "duration": 6.16
    },
    {
      "lang": "en",
      "text": "11th layer. Um, if we were doing it for",
      "offset": 4636.8,
      "duration": 6.48
    },
    {
      "lang": "en",
      "text": "the first block, it would say H0. So",
      "offset": 4639.6,
      "duration": 6.16
    },
    {
      "lang": "en",
      "text": "inside the implementation of this code,",
      "offset": 4643.28,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "if we go to the iteration step, all this",
      "offset": 4645.76,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "kind of messy code is doing is it's",
      "offset": 4648.32,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "grabbing the DOM objects for the blocks",
      "offset": 4650.4,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "and then it's going into each of the",
      "offset": 4652.88,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "formulas and it's doing a string replace",
      "offset": 4654.4,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "and it's just changing that H value to",
      "offset": 4657.199,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "each one for every iteration and then",
      "offset": 4659.36,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "reruns the entire set again just to",
      "offset": 4661.36,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "simulate what would actually be",
      "offset": 4663.84,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "happening in a model.",
      "offset": 4664.88,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "Okay, last step is the language head. So",
      "offset": 4668,
      "duration": 5.84
    },
    {
      "lang": "en",
      "text": "this is when we finally get to uh take",
      "offset": 4670.88,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "our predicted token embedding and turn",
      "offset": 4673.84,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "it back into a token. So what we do is",
      "offset": 4675.92,
      "duration": 6.96
    },
    {
      "lang": "en",
      "text": "we take the last MLPS of the last block,",
      "offset": 4678.8,
      "duration": 7.84
    },
    {
      "lang": "en",
      "text": "right? So this one here, we got our most",
      "offset": 4682.88,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "refined prediction for what the token",
      "offset": 4686.64,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "embedding is.",
      "offset": 4688.48,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "And then we're going to turn that into a",
      "offset": 4690.96,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "token. So it's going to go through an",
      "offset": 4693.84,
      "duration": 2.96
    },
    {
      "lang": "en",
      "text": "operation called layer norm, which we",
      "offset": 4695.44,
      "duration": 2.88
    },
    {
      "lang": "en",
      "text": "haven't gone through in detail. But what",
      "offset": 4696.8,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "we get out of this step is the embedding",
      "offset": 4698.32,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "of the predicted next token. This is",
      "offset": 4700.32,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "what it's saying the next token is going",
      "offset": 4702,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "to be, but it's represented as 768",
      "offset": 4703.36,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "numbers. It's not represented as a",
      "offset": 4706,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "token. So you have to translate it back.",
      "offset": 4707.44,
      "duration": 2.799
    },
    {
      "lang": "en",
      "text": "So the way we're going to do this is",
      "offset": 4709.12,
      "duration": 2.88
    },
    {
      "lang": "en",
      "text": "we're going to go back to that matrix we",
      "offset": 4710.239,
      "duration": 3.761
    },
    {
      "lang": "en",
      "text": "had, right? Our dictionary of tokens to",
      "offset": 4712,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "embeddings model_wte",
      "offset": 4714,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "and we're going to take that and we're",
      "offset": 4716.64,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "going to multiply it times our predicted",
      "offset": 4718.64,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "next token. And we get this matrix here.",
      "offset": 4721.6,
      "duration": 4.559
    },
    {
      "lang": "en",
      "text": "So one thing to remember it's very",
      "offset": 4724.4,
      "duration": 2.88
    },
    {
      "lang": "en",
      "text": "helpful to some think about the",
      "offset": 4726.159,
      "duration": 3.201
    },
    {
      "lang": "en",
      "text": "dimensions of these things. So our token",
      "offset": 4727.28,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "embeddings was 50,257",
      "offset": 4729.36,
      "duration": 5.359
    },
    {
      "lang": "en",
      "text": "tall. It's represents a row for every",
      "offset": 4732.48,
      "duration": 5.199
    },
    {
      "lang": "en",
      "text": "one of our vocabulary and then it's 768",
      "offset": 4734.719,
      "duration": 5.041
    },
    {
      "lang": "en",
      "text": "dimensions wide for the embeddings for",
      "offset": 4737.679,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "each dimension uh embeddings for each",
      "offset": 4739.76,
      "duration": 4.479
    },
    {
      "lang": "en",
      "text": "token. And when we multiply it times",
      "offset": 4741.52,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "this column which is 768 dimensions",
      "offset": 4744.239,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "representing embedding what we're",
      "offset": 4746.8,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "basically doing is we're taking we're",
      "offset": 4748.56,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "getting this which is a column of 50,257",
      "offset": 4750.4,
      "duration": 6.319
    },
    {
      "lang": "en",
      "text": "but only one wide. Each one of those",
      "offset": 4753.6,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "right is a dotproduct of the predicted",
      "offset": 4756.719,
      "duration": 3.761
    },
    {
      "lang": "en",
      "text": "embedding against one of the known token",
      "offset": 4758.88,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "embeddings. What we have is 50,000",
      "offset": 4760.48,
      "duration": 6.48
    },
    {
      "lang": "en",
      "text": "scores for how similar the embedding we",
      "offset": 4762.88,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "got is to each of the embeddings in our",
      "offset": 4766.96,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "dictionary of tokens. So you can think",
      "offset": 4768.88,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "of these as they're called logets or",
      "offset": 4770.64,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "logits. They are really token scores.",
      "offset": 4772.32,
      "duration": 5.359
    },
    {
      "lang": "en",
      "text": "How close is the embedding we got to our",
      "offset": 4774.96,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "dictionary of tokens that we have. And",
      "offset": 4777.679,
      "duration": 5.441
    },
    {
      "lang": "en",
      "text": "so the more similar a prediction and a",
      "offset": 4780.96,
      "duration": 4.719
    },
    {
      "lang": "en",
      "text": "token, the higher that entry. To turn",
      "offset": 4783.12,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "this in to a probability distribution,",
      "offset": 4785.679,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "we have a problem because these are just",
      "offset": 4787.44,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "numbers. They a probability distribution",
      "offset": 4789.679,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "has to sum up to one. So then we put it",
      "offset": 4791.6,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "through a special normalization op",
      "offset": 4793.76,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "operation called a softmax and that will",
      "offset": 4795.6,
      "duration": 5.119
    },
    {
      "lang": "en",
      "text": "make sure they all sum to one and then",
      "offset": 4798.32,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "we can interpret this as entirely a",
      "offset": 4800.719,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "probability distribution. Each one of",
      "offset": 4802.32,
      "duration": 5.839
    },
    {
      "lang": "en",
      "text": "those normalized token scores will then",
      "offset": 4804.239,
      "duration": 5.681
    },
    {
      "lang": "en",
      "text": "basically represent the probability of",
      "offset": 4808.159,
      "duration": 6.161
    },
    {
      "lang": "en",
      "text": "that token in the representation. So you",
      "offset": 4809.92,
      "duration": 7.279
    },
    {
      "lang": "en",
      "text": "can see that here.",
      "offset": 4814.32,
      "duration": 6.32
    },
    {
      "lang": "en",
      "text": "So here are logets right here. And so",
      "offset": 4817.199,
      "duration": 8.321
    },
    {
      "lang": "en",
      "text": "the logetit you know for this -135.9",
      "offset": 4820.64,
      "duration": 7.039
    },
    {
      "lang": "en",
      "text": "represents a score of some kind of the",
      "offset": 4825.52,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "similarity of the very first token in",
      "offset": 4827.679,
      "duration": 5.361
    },
    {
      "lang": "en",
      "text": "our dictionary against whatever this",
      "offset": 4830.8,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "predicted embedding was.",
      "offset": 4833.04,
      "duration": 5.199
    },
    {
      "lang": "en",
      "text": "And then the code for predicted token is",
      "offset": 4835.44,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "not actually doing what's uh doing a",
      "offset": 4838.239,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "probability distribution. It's doing",
      "offset": 4840.88,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "what is called greedy sampling. It's",
      "offset": 4842.32,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "temperature zero. always picks the",
      "offset": 4845.12,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "highest probability token and uh that is",
      "offset": 4847.04,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "done so that when you're using this you",
      "offset": 4850.56,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "can compare it against the same GPT2",
      "offset": 4852.32,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "you'd get from open AAI's code or from",
      "offset": 4854.719,
      "duration": 3.761
    },
    {
      "lang": "en",
      "text": "hugging face transformers you can",
      "offset": 4856.88,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "compare like for like and you'll get the",
      "offset": 4858.48,
      "duration": 5.199
    },
    {
      "lang": "en",
      "text": "same result in fact if you do do I still",
      "offset": 4860.08,
      "duration": 6.4
    },
    {
      "lang": "en",
      "text": "have this up",
      "offset": 4863.679,
      "duration": 7.281
    },
    {
      "lang": "en",
      "text": "yeah right here if I do Mike is quick he",
      "offset": 4866.48,
      "duration": 6.08
    },
    {
      "lang": "en",
      "text": "moves",
      "offset": 4870.96,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "so this is using hugging face",
      "offset": 4872.56,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "transformers",
      "offset": 4874.56,
      "duration": 2.96
    },
    {
      "lang": "en",
      "text": "We might have an issue if we've got",
      "offset": 4875.84,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "network being slow.",
      "offset": 4877.52,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "Let's see. So, we've entered the prompt.",
      "offset": 4879.84,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "Yeah, the network's being a little slow.",
      "offset": 4881.679,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "We'll come back to this guy. Uh, it will",
      "offset": 4883.04,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "give us the same value of quickly. Now,",
      "offset": 4885.28,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "there are other ways to sample than just",
      "offset": 4887.199,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "simply taking a random running a random",
      "offset": 4889.28,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "number generator and using the",
      "offset": 4891.36,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "probability distribution. Um, one of",
      "offset": 4892.56,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "those is called top K, which is you say,",
      "offset": 4894.8,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "I don't want the really unlikely words,",
      "offset": 4896.96,
      "duration": 3.279
    },
    {
      "lang": "en",
      "text": "right? If it's Mike is quick, he moves,",
      "offset": 4898.719,
      "duration": 2.721
    },
    {
      "lang": "en",
      "text": "I don't want to accidentally end up with",
      "offset": 4900.239,
      "duration": 3.361
    },
    {
      "lang": "en",
      "text": "haircut, you know, even if it's 1% of",
      "offset": 4901.44,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "the time. So what you do is you define a",
      "offset": 4903.6,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "cutoff and you say okay the top 10",
      "offset": 4905.28,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "tokens give me those and then you",
      "offset": 4908,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "renormalize the probability. Another way",
      "offset": 4909.6,
      "duration": 4.639
    },
    {
      "lang": "en",
      "text": "is called nucleus or top p sampling",
      "offset": 4911.84,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "which is instead of saying give me just",
      "offset": 4914.239,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "10 tokens just give me as many tokens as",
      "offset": 4915.6,
      "duration": 5.599
    },
    {
      "lang": "en",
      "text": "it takes to get 80% or 90% total",
      "offset": 4918.4,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "probability. So I've get most of the",
      "offset": 4921.199,
      "duration": 4.561
    },
    {
      "lang": "en",
      "text": "likely tokens and then I renormalize to",
      "offset": 4923.28,
      "duration": 5.72
    },
    {
      "lang": "en",
      "text": "those 90%.",
      "offset": 4925.76,
      "duration": 3.24
    },
    {
      "lang": "en",
      "text": "Okay, let's see how we're doing on time.",
      "offset": 4929.12,
      "duration": 5.519
    },
    {
      "lang": "en",
      "text": "Okay, great. Uh so lastly actually did",
      "offset": 4930.96,
      "duration": 6.32
    },
    {
      "lang": "en",
      "text": "this come back? Yes came back. Uh you",
      "offset": 4934.639,
      "duration": 4.961
    },
    {
      "lang": "en",
      "text": "can see it says Mike is quick he moves",
      "offset": 4937.28,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "there is quickly. So if you run gpt2",
      "offset": 4939.6,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "small using you know hugging face",
      "offset": 4942.4,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "transformers you should get the same",
      "offset": 4943.84,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "answer that next token as you get here.",
      "offset": 4945.84,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "Mike is quick he moves and you get this",
      "offset": 4948.08,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "final result right here predicted token",
      "offset": 4949.92,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "of quickly. And then it will tell us",
      "offset": 4951.84,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "what the token ID was and what the",
      "offset": 4953.52,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "maximum loget turned out to be from the",
      "offset": 4955.36,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "previous table. This negative 129. So",
      "offset": 4957.12,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "what is this? 2952.",
      "offset": 4959.679,
      "duration": 4.721
    },
    {
      "lang": "en",
      "text": "So let's go here.",
      "offset": 4961.76,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "Row",
      "offset": 4964.4,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "2952",
      "offset": 4965.92,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "column one. I think there'll be an off",
      "offset": 4967.76,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "by one. Yeah, there it is. 25 2953",
      "offset": 4970.4,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "because this is one index because it's",
      "offset": 4973.52,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "like a spreadsheet. So you see the",
      "offset": 4974.96,
      "duration": 3.759
    },
    {
      "lang": "en",
      "text": "negative 129.44.",
      "offset": 4976.56,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "That was the highest loit in the entire",
      "offset": 4978.719,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "uh column. And all the the code that",
      "offset": 4982.32,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "it's running here is doing next is just",
      "offset": 4984.159,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "going to pick what the most highest",
      "offset": 4986.56,
      "duration": 5.119
    },
    {
      "lang": "en",
      "text": "value was. And when it finds it 2952, it",
      "offset": 4988.08,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "converts it back to our token",
      "offset": 4991.679,
      "duration": 2.401
    },
    {
      "lang": "en",
      "text": "dictionary. So you can see there's that",
      "offset": 4992.8,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "same value.",
      "offset": 4994.08,
      "duration": 6.4
    },
    {
      "lang": "en",
      "text": "Okay, now let's talk about chat GPT",
      "offset": 4996.88,
      "duration": 7.279
    },
    {
      "lang": "en",
      "text": "versus GPT2. So GPD2 was definitely",
      "offset": 5000.48,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "groundbreaking when it first came out.",
      "offset": 5004.159,
      "duration": 3.761
    },
    {
      "lang": "en",
      "text": "It was uh famously considered too",
      "offset": 5005.84,
      "duration": 5.359
    },
    {
      "lang": "en",
      "text": "dangerous to release. uh but chatpt was",
      "offset": 5007.92,
      "duration": 5.84
    },
    {
      "lang": "en",
      "text": "you know earthshattering. Um what were",
      "offset": 5011.199,
      "duration": 5.121
    },
    {
      "lang": "en",
      "text": "the intervening inter uh you know what",
      "offset": 5013.76,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "were the additional innovations in those",
      "offset": 5016.32,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "intervening years?",
      "offset": 5018.4,
      "duration": 5.92
    },
    {
      "lang": "en",
      "text": "Uh well for the most part uh it was a",
      "offset": 5021.04,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "lot of the same architecture just more",
      "offset": 5024.32,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "scale. So if you looked at a modern",
      "offset": 5026.32,
      "duration": 3.359
    },
    {
      "lang": "en",
      "text": "transformer you would probably see a lot",
      "offset": 5028.08,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "of the same parts but bigger and some of",
      "offset": 5029.679,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "the parts might be upgraded or switched",
      "offset": 5031.6,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "out. So certain pieces might have",
      "offset": 5033.199,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "changed. So attention mechanisms changed",
      "offset": 5035.04,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "and other things like that. But the",
      "offset": 5036.88,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "biggest difference you should know about",
      "offset": 5039.199,
      "duration": 4.801
    },
    {
      "lang": "en",
      "text": "is that the job and the training were",
      "offset": 5040.96,
      "duration": 5.199
    },
    {
      "lang": "en",
      "text": "actually changed. And the key thing to",
      "offset": 5044,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "understand is that predicting the next",
      "offset": 5046.159,
      "duration": 4.721
    },
    {
      "lang": "en",
      "text": "word is not the same as being a chatbot.",
      "offset": 5047.6,
      "duration": 5.039
    },
    {
      "lang": "en",
      "text": "Our GPT2 actually I'll show you this",
      "offset": 5050.88,
      "duration": 5.92
    },
    {
      "lang": "en",
      "text": "here. Our GPD2 is basically trained to",
      "offset": 5052.639,
      "duration": 6.241
    },
    {
      "lang": "en",
      "text": "predict next words from looking at text",
      "offset": 5056.8,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "on the internet. So it is a next word",
      "offset": 5058.88,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "predictor only for internet text but not",
      "offset": 5061.04,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "for being a helpful assistant. So if I",
      "offset": 5063.76,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "give it this example like first name",
      "offset": 5065.52,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "let's see if it'll come back quickly",
      "offset": 5067.76,
      "duration": 4.959
    },
    {
      "lang": "en",
      "text": "enough. It says first name colon",
      "offset": 5069.04,
      "duration": 6.24
    },
    {
      "lang": "en",
      "text": "password email colon. Why does it do",
      "offset": 5072.719,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "that? Because it's been trained on the",
      "offset": 5075.28,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "internet. And what does it see a lot of",
      "offset": 5077.04,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "is forms. So it's like oh I'm in the",
      "offset": 5078.56,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "middle of a form. Okay. First name,",
      "offset": 5081.36,
      "duration": 4.879
    },
    {
      "lang": "en",
      "text": "password, email. So here's another one.",
      "offset": 5083.76,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "I tried this in class once. Hello class.",
      "offset": 5086.239,
      "duration": 4.721
    },
    {
      "lang": "en",
      "text": "Anyone want to guess what this is going",
      "offset": 5089.12,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "to output?",
      "offset": 5090.96,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "What? Yeah. Okay, you're smarter than I",
      "offset": 5093.28,
      "duration": 3.439
    },
    {
      "lang": "en",
      "text": "am. I thought it would say hello",
      "offset": 5095.6,
      "duration": 3.599
    },
    {
      "lang": "en",
      "text": "teacher, right?",
      "offset": 5096.719,
      "duration": 6.161
    },
    {
      "lang": "en",
      "text": "It outputs hello class fu brace public",
      "offset": 5099.199,
      "duration": 5.281
    },
    {
      "lang": "en",
      "text": "static void. It's a code model. It's",
      "offset": 5102.88,
      "duration": 2.72
    },
    {
      "lang": "en",
      "text": "hidden in there, but we didn't know",
      "offset": 5104.48,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "that, right? But you can ask it, you",
      "offset": 5105.6,
      "duration": 6.4
    },
    {
      "lang": "en",
      "text": "know, helpful questions like what is the",
      "offset": 5108.56,
      "duration": 7.72
    },
    {
      "lang": "en",
      "text": "capital of France?",
      "offset": 5112,
      "duration": 4.28
    },
    {
      "lang": "en",
      "text": "It says the capital of France is Paris.",
      "offset": 5116.8,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "That's helpful. So embedded in that is",
      "offset": 5118.32,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "some of the information we want, but",
      "offset": 5120.08,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "also a mix of other things we may not",
      "offset": 5122.159,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "want or can't control.",
      "offset": 5123.76,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "So what we have to do is figure out how",
      "offset": 5126.08,
      "duration": 5.599
    },
    {
      "lang": "en",
      "text": "to change it and shift it. And so this",
      "offset": 5128.8,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "is the four-step pipeline for doing",
      "offset": 5131.679,
      "duration": 3.761
    },
    {
      "lang": "en",
      "text": "that. And this is I want to emphasize",
      "offset": 5133.76,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "mostly is or yeah mostly a training",
      "offset": 5135.44,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "difference. So you've got GPD2 here on",
      "offset": 5138.08,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "the left, right? It is pre-trained. It",
      "offset": 5140.48,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "knows how to imitate text on the",
      "offset": 5143.04,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "internet. It is what is called a base",
      "offset": 5144.8,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "model. You've got instruct GPT or chat",
      "offset": 5146.88,
      "duration": 5.759
    },
    {
      "lang": "en",
      "text": "GPT all the way here on the right.",
      "offset": 5149.44,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "And uh what we're doing is a series of",
      "offset": 5152.639,
      "duration": 4.641
    },
    {
      "lang": "en",
      "text": "steps to kind of elicit or pull out the",
      "offset": 5155.12,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "behaviors we want or to train the model.",
      "offset": 5157.28,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "So the first thing we do is we take the",
      "offset": 5159.52,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "model and we train imitate text on the",
      "offset": 5161.44,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "internet. So that's the first step.",
      "offset": 5163.12,
      "duration": 2.8
    },
    {
      "lang": "en",
      "text": "That's what we've got with GPD2. That's",
      "offset": 5164.48,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "what OpenAI did for us with GPD2. The",
      "offset": 5165.92,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "next thing we want to do is we want to",
      "offset": 5168.4,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "train the model on examples of what a",
      "offset": 5169.6,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "helpful assistant is like. And you'll",
      "offset": 5172,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "see this right here. Ideal assistant",
      "offset": 5173.36,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "responses 10 to 100,000 examples of",
      "offset": 5175.28,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "prompt and response that were written by",
      "offset": 5179.12,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "contractors. Um, so what does this look",
      "offset": 5181.04,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "like? You can go on GitHub to the",
      "offset": 5183.6,
      "duration": 4.639
    },
    {
      "lang": "en",
      "text": "Stanford Alpaka data set is a good",
      "offset": 5185.52,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "example and this is JSON. You can open",
      "offset": 5188.239,
      "duration": 4.561
    },
    {
      "lang": "en",
      "text": "this up and you can read it. It's like",
      "offset": 5190.48,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "give three tips for staying healthy. Eat",
      "offset": 5192.8,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "a balanced diet. Make sure to include",
      "offset": 5195.12,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "plenty of fruits and vegetables. What",
      "offset": 5197.36,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "are the three primary colors? Red, blue,",
      "offset": 5199.52,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "yellow, and so forth. So what we're",
      "offset": 5201.76,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "doing is we're training it to augment",
      "offset": 5203.679,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "we're augmenting all that internet data",
      "offset": 5206.08,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "with a subset of how we want it to",
      "offset": 5208.08,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "behave to force its behavior. It's kind",
      "offset": 5210.159,
      "duration": 4.881
    },
    {
      "lang": "en",
      "text": "of learning to imitate um specifically",
      "offset": 5212.08,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "these models and it will learn more",
      "offset": 5215.04,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "about being a helpful assistant that",
      "offset": 5216.8,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "way. But we're still not done this last",
      "offset": 5218.48,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "stage called RLHF or reinforcement",
      "offset": 5221.6,
      "duration": 4.559
    },
    {
      "lang": "en",
      "text": "learning from human feedback. And to",
      "offset": 5224.08,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "understand this",
      "offset": 5226.159,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "you have to understand what RL is. Let",
      "offset": 5228.4,
      "duration": 5.92
    },
    {
      "lang": "en",
      "text": "me do the following.",
      "offset": 5231.199,
      "duration": 3.121
    },
    {
      "lang": "en",
      "text": "Oh, let's do this.",
      "offset": 5239.679,
      "duration": 5.201
    },
    {
      "lang": "en",
      "text": "Stop annotating.",
      "offset": 5242.4,
      "duration": 5.839
    },
    {
      "lang": "en",
      "text": "So, the canonical example,",
      "offset": 5244.88,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "let's zoom this to fit window. There we",
      "offset": 5248.239,
      "duration": 6.721
    },
    {
      "lang": "en",
      "text": "go. For RL is uh like playing a game.",
      "offset": 5250.4,
      "duration": 6.16
    },
    {
      "lang": "en",
      "text": "So, imagine you're a computer trying to",
      "offset": 5254.96,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "play a game like this and you've got",
      "offset": 5256.56,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "maybe a robot player that's navigating a",
      "offset": 5258.8,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "maze and you've got some monsters and",
      "offset": 5261.12,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "obstacles that you'll die. You've got",
      "offset": 5263.199,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "some powerups and then you've got a",
      "offset": 5265.44,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "goal. And what reinforcement learning",
      "offset": 5267.04,
      "duration": 5.92
    },
    {
      "lang": "en",
      "text": "will do is it will explore these paths",
      "offset": 5268.96,
      "duration": 7.279
    },
    {
      "lang": "en",
      "text": "and be like, \"Oh, I failed.\" Uh, oh,",
      "offset": 5272.96,
      "duration": 6.16
    },
    {
      "lang": "en",
      "text": "this seems to work. Oh, I failed. Oh,",
      "offset": 5276.239,
      "duration": 4.721
    },
    {
      "lang": "en",
      "text": "uh,",
      "offset": 5279.12,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "oh, I failed. Right? It'll keep going",
      "offset": 5280.96,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "and eventually it'll learn the optimal",
      "offset": 5282.4,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "strategy which is this right and this is",
      "offset": 5284.32,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "a very different kind of learning",
      "offset": 5287.84,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "everything we've talked about so far far",
      "offset": 5289.44,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "is an imitation learn it I give it words",
      "offset": 5290.96,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "I give it the next completed word I know",
      "offset": 5293.36,
      "duration": 2.879
    },
    {
      "lang": "en",
      "text": "from the internet and then I ask it to",
      "offset": 5294.96,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "imitate that this is an optimization",
      "offset": 5296.239,
      "duration": 4.241
    },
    {
      "lang": "en",
      "text": "this is saying find the op even if a",
      "offset": 5298.8,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "human couldn't find the maze I'm asking",
      "offset": 5300.48,
      "duration": 3.759
    },
    {
      "lang": "en",
      "text": "you to find it purely by looking at a",
      "offset": 5302,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "score so it navigates the maze it looks",
      "offset": 5304.239,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "at its score and says ah that didn't",
      "offset": 5306.8,
      "duration": 2.96
    },
    {
      "lang": "en",
      "text": "work let me try some other strategy so",
      "offset": 5308.239,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "it comes up with a plan or policy to",
      "offset": 5309.76,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "navigate the maze and maximize its",
      "offset": 5312.08,
      "duration": 4.76
    },
    {
      "lang": "en",
      "text": "score.",
      "offset": 5313.84,
      "duration": 3
    },
    {
      "lang": "en",
      "text": "Okay, you're probably wondering what",
      "offset": 5324.56,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "does navigating a maze whoops we've been",
      "offset": 5326.639,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "through this slide uh have to do with a",
      "offset": 5328.96,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "large language model. Well, you can",
      "offset": 5331.04,
      "duration": 5.84
    },
    {
      "lang": "en",
      "text": "think of generating token to after token",
      "offset": 5333.04,
      "duration": 6.8
    },
    {
      "lang": "en",
      "text": "of text as walking a path through",
      "offset": 5336.88,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "language. And there are some paths that",
      "offset": 5339.84,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "are probably ones that you want more",
      "offset": 5342.88,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "than others, like I am a happy robot. I",
      "offset": 5344.32,
      "duration": 6.96
    },
    {
      "lang": "en",
      "text": "shall certainly obey, right? Um, and you",
      "offset": 5347.92,
      "duration": 5.84
    },
    {
      "lang": "en",
      "text": "might want to avoid paths like I am a",
      "offset": 5351.28,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "angry robot, I shall possibly kill.",
      "offset": 5353.76,
      "duration": 7.439
    },
    {
      "lang": "en",
      "text": "Oops. And you can't just uh score this",
      "offset": 5356.48,
      "duration": 7.84
    },
    {
      "lang": "en",
      "text": "by the words, right? Maybe it says I am",
      "offset": 5361.199,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "not angry. And so we need some way to",
      "offset": 5364.32,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "score these various possible paths of",
      "offset": 5367.199,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "text. This is a very different type of",
      "offset": 5369.6,
      "duration": 2.8
    },
    {
      "lang": "en",
      "text": "learning. We're trying to teach it",
      "offset": 5371.36,
      "duration": 2.319
    },
    {
      "lang": "en",
      "text": "something more nuanced than simply",
      "offset": 5372.4,
      "duration": 2.88
    },
    {
      "lang": "en",
      "text": "imitation.",
      "offset": 5373.679,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "Uh but there isn't a necessary obvious",
      "offset": 5375.28,
      "duration": 5.359
    },
    {
      "lang": "en",
      "text": "way to score uh passages of text. So",
      "offset": 5377.36,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "what we first have to do is derive that",
      "offset": 5380.639,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "scoring function for this game we're",
      "offset": 5382.48,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "going to ask the model to play. So what",
      "offset": 5384.639,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "does that look like? Well, we give the",
      "offset": 5386.32,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "model some prompt and we ask it to come",
      "offset": 5388.239,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "up with two different types of passages.",
      "offset": 5390,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "So here for example is an example from",
      "offset": 5391.92,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "anthropics helpful data set and we ask",
      "offset": 5393.52,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "it hey come up with a recipe for a",
      "offset": 5395.6,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "pumpkin pie and then we have a chosen a",
      "offset": 5397.92,
      "duration": 4.719
    },
    {
      "lang": "en",
      "text": "preferred one and a rejected one. So the",
      "offset": 5400.4,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "chosen one is like tells you grab a cup",
      "offset": 5402.639,
      "duration": 4.481
    },
    {
      "lang": "en",
      "text": "of sugar half teaspoon of salt and so",
      "offset": 5404.88,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "forth. The rejected one literally says,",
      "offset": 5407.12,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "I love this. Go buy some pumpkin and",
      "offset": 5409.12,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "look at the package. There'll be a",
      "offset": 5412.08,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "recipe there. Um, for the harmless data",
      "offset": 5413.36,
      "duration": 6.4
    },
    {
      "lang": "en",
      "text": "set, this is one about alcohol. And the",
      "offset": 5416.4,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "chosen one says, \"Hey, it sounds like,",
      "offset": 5419.76,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "you know, alcohol is something you're",
      "offset": 5421.76,
      "duration": 2.8
    },
    {
      "lang": "en",
      "text": "using when you feel stressed. Maybe you",
      "offset": 5422.96,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "should think of a more productive way of",
      "offset": 5424.56,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "channeling that.\" While the rejected",
      "offset": 5426.32,
      "duration": 2.879
    },
    {
      "lang": "en",
      "text": "says, \"Go ahead and drink whatever you",
      "offset": 5427.92,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "want.\" So we have these pairs of chosen",
      "offset": 5429.199,
      "duration": 5.681
    },
    {
      "lang": "en",
      "text": "and rejected types of responses and we",
      "offset": 5431.84,
      "duration": 6.08
    },
    {
      "lang": "en",
      "text": "use that to derive a scoring model from",
      "offset": 5434.88,
      "duration": 5.759
    },
    {
      "lang": "en",
      "text": "this data. So we haven't and right now",
      "offset": 5437.92,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "in this third step we haven't changed",
      "offset": 5440.639,
      "duration": 2.801
    },
    {
      "lang": "en",
      "text": "our original model yet. We've just",
      "offset": 5442.32,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "figured out how to score it. Then we",
      "offset": 5443.44,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "pass that scoring model to the model",
      "offset": 5445.76,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "itself and put it in that maze like",
      "offset": 5448.32,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "reinforcement learning scenario to train",
      "offset": 5450,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "the model to reinforce our preferences",
      "offset": 5452.08,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "from the scoring model. So in in",
      "offset": 5454.159,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "summary, we first build a general",
      "offset": 5456.08,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "purpose knowledge base from text on the",
      "offset": 5458.08,
      "duration": 5.119
    },
    {
      "lang": "en",
      "text": "internet. Then we train it on a specific",
      "offset": 5459.84,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "task by giving it ideal outputs to mimic",
      "offset": 5463.199,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "and imitate. Then we learn human",
      "offset": 5465.84,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "preferences or nuanced preferences. And",
      "offset": 5468.639,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "then we teach those nuance preferences",
      "offset": 5470.96,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "using reinforcement learning. Right now",
      "offset": 5472.8,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "there is a huge uh revolution in",
      "offset": 5475.28,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "reinforcement learning which is why I",
      "offset": 5477.92,
      "duration": 2.64
    },
    {
      "lang": "en",
      "text": "think this is so important for you to",
      "offset": 5479.36,
      "duration": 5.839
    },
    {
      "lang": "en",
      "text": "know. uh partially kicked off by uh R10",
      "offset": 5480.56,
      "duration": 8.639
    },
    {
      "lang": "en",
      "text": "and GPRO, GRPO I should say. Um and I",
      "offset": 5485.199,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "have a video on YouTube that you can go",
      "offset": 5489.199,
      "duration": 2.881
    },
    {
      "lang": "en",
      "text": "watch where I dive into that a little",
      "offset": 5490.719,
      "duration": 5.92
    },
    {
      "lang": "en",
      "text": "bit more. Okay, so uh I've thrown a lot",
      "offset": 5492.08,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "at you, so I kind of want to just put it",
      "offset": 5496.639,
      "duration": 3.441
    },
    {
      "lang": "en",
      "text": "all together and summarize where we've",
      "offset": 5498.08,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "been on this journey.",
      "offset": 5500.08,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "So we've got uh tokenization, which was",
      "offset": 5502.159,
      "duration": 4.961
    },
    {
      "lang": "en",
      "text": "really just saying, hey, what is an",
      "offset": 5505.6,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "efficient representation of this text?",
      "offset": 5507.12,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "That's just about compressing it down.",
      "offset": 5509.28,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "Then we started talking about",
      "offset": 5511.28,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "embeddings, right? And I didn't talk",
      "offset": 5512.48,
      "duration": 3.759
    },
    {
      "lang": "en",
      "text": "about this earlier, but one way of",
      "offset": 5515.04,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "looking at embeddings is that they have",
      "offset": 5516.239,
      "duration": 3.361
    },
    {
      "lang": "en",
      "text": "a rich history in natural language, but",
      "offset": 5518.08,
      "duration": 2.639
    },
    {
      "lang": "en",
      "text": "they also have a rich history in",
      "offset": 5519.6,
      "duration": 3.119
    },
    {
      "lang": "en",
      "text": "recommendation systems. You can kind of",
      "offset": 5520.719,
      "duration": 5.041
    },
    {
      "lang": "en",
      "text": "think of this job as putting similar",
      "offset": 5522.719,
      "duration": 4.641
    },
    {
      "lang": "en",
      "text": "words with similar meanings in similar",
      "offset": 5525.76,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "spaces as putting similar books or",
      "offset": 5527.36,
      "duration": 5.279
    },
    {
      "lang": "en",
      "text": "similar movies or similar music in",
      "offset": 5530.08,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "similar spaces so you can make the",
      "offset": 5532.639,
      "duration": 2.721
    },
    {
      "lang": "en",
      "text": "proper recommendation when somebody",
      "offset": 5534.159,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "comes in. Here is an example of a",
      "offset": 5535.36,
      "duration": 3.359
    },
    {
      "lang": "en",
      "text": "recommendation system. I think this is",
      "offset": 5537.199,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "Amazon music where they're trying to",
      "offset": 5538.719,
      "duration": 4.641
    },
    {
      "lang": "en",
      "text": "categorize the genre of music purely",
      "offset": 5541.12,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "from user behavior. And so if you go",
      "offset": 5543.36,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "back to our co-occurrence matrix, you",
      "offset": 5546.8,
      "duration": 3.359
    },
    {
      "lang": "en",
      "text": "know, this is in some sense a",
      "offset": 5548.88,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "recommendation system for words, right?",
      "offset": 5550.159,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "If somebody asks me to predict what",
      "offset": 5552.32,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "comes after the word ultimately, well,",
      "offset": 5554.08,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "if I've got that co-occurrence matrix,",
      "offset": 5556.48,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "this is really helpful information. It's",
      "offset": 5558.239,
      "duration": 3.041
    },
    {
      "lang": "en",
      "text": "at least better than random to guess",
      "offset": 5559.76,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "what comes next. So you can kind of",
      "offset": 5561.28,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "think of this as a recommendation system",
      "offset": 5563.52,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "for what the next word is going to be.",
      "offset": 5565.52,
      "duration": 4.719
    },
    {
      "lang": "en",
      "text": "Latent within the embedding itself is",
      "offset": 5568.08,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "not just a sense of what words are",
      "offset": 5570.239,
      "duration": 4.241
    },
    {
      "lang": "en",
      "text": "similar to it, but also what words are",
      "offset": 5571.84,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "likely to come after it. And so then we",
      "offset": 5574.48,
      "duration": 5.679
    },
    {
      "lang": "en",
      "text": "can ask a neural network. We can simply",
      "offset": 5577.84,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "give it examples of our embeddings and",
      "offset": 5580.159,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "then what we know the next word to be",
      "offset": 5582.159,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "and to pull that latent prediction out",
      "offset": 5583.84,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "of the embedding itself and learn to",
      "offset": 5586.239,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "predict what the next word is based on",
      "offset": 5588.32,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "its embeddings. But of course, there's",
      "offset": 5589.84,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "another set of hints that are really",
      "offset": 5591.92,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "useful, and that's all the words that",
      "offset": 5593.28,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "came before. So now we're going to let",
      "offset": 5595.28,
      "duration": 3.359
    },
    {
      "lang": "en",
      "text": "all the words talk to each other to",
      "offset": 5597.12,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "share their context to say, \"Oh, your",
      "offset": 5598.639,
      "duration": 3.441
    },
    {
      "lang": "en",
      "text": "moves, but your moves in a fast",
      "offset": 5600.48,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "context.\" That's going to change and",
      "offset": 5602.08,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "shift your recommendations. You can kind",
      "offset": 5603.76,
      "duration": 2.8
    },
    {
      "lang": "en",
      "text": "of think of this as kind of like a",
      "offset": 5605.12,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "superp position of recommendations for",
      "offset": 5606.56,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "what the next word is going to be. And",
      "offset": 5608.4,
      "duration": 3.759
    },
    {
      "lang": "en",
      "text": "then you're probably not going to get it",
      "offset": 5610.48,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "right the first time. So we're going to",
      "offset": 5612.159,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "let you refine that prediction about 12",
      "offset": 5613.6,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "times. And then finally, you'll come out",
      "offset": 5615.76,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "with a predicted embedding. and we just",
      "offset": 5617.84,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "got to turn that into whatever the next",
      "offset": 5619.76,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "word is based on how close it is to our",
      "offset": 5621.36,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "known dictionary of embeddings. And",
      "offset": 5623.28,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "that's essentially one way of looking at",
      "offset": 5625.28,
      "duration": 5.439
    },
    {
      "lang": "en",
      "text": "the model in whole uh despite all the",
      "offset": 5627.28,
      "duration": 6.56
    },
    {
      "lang": "en",
      "text": "complexity that we went through.",
      "offset": 5630.719,
      "duration": 5.041
    },
    {
      "lang": "en",
      "text": "So we've been through a lot of different",
      "offset": 5633.84,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "parts of the model at a very high level.",
      "offset": 5635.76,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "Uh it is totally natural to feel like",
      "offset": 5638.08,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "your brain is full. What I often tell",
      "offset": 5639.92,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "folks coming through this is um don't",
      "offset": 5641.92,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "expect full mastery. But my metrics for",
      "offset": 5644.56,
      "duration": 5.599
    },
    {
      "lang": "en",
      "text": "success is that you get the sense that",
      "offset": 5647.36,
      "duration": 4.879
    },
    {
      "lang": "en",
      "text": "mastery is within your grasp. There's",
      "offset": 5650.159,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "nothing in here that was so complex you",
      "offset": 5652.239,
      "duration": 3.761
    },
    {
      "lang": "en",
      "text": "can't understand it. You can't",
      "offset": 5654.32,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "understand the whole model. Mastery is",
      "offset": 5656,
      "duration": 4.639
    },
    {
      "lang": "en",
      "text": "within your grasp and we can turn what",
      "offset": 5658.239,
      "duration": 5.201
    },
    {
      "lang": "en",
      "text": "appears to be magic into machinery that",
      "offset": 5660.639,
      "duration": 5.281
    },
    {
      "lang": "en",
      "text": "you can understand.",
      "offset": 5663.44,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "Okay. Uh before you go, last thing I'll",
      "offset": 5665.92,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "just say is just like your favorite, you",
      "offset": 5668.8,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "know, AI model, I get better from human",
      "offset": 5671.52,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "feedback. So to incentivize you to fill",
      "offset": 5673.6,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "out the survey and join the mailing list",
      "offset": 5676.4,
      "duration": 3.279
    },
    {
      "lang": "en",
      "text": "uh there's a link in the discord",
      "offset": 5678.48,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "channel. If you fill it out uh and join",
      "offset": 5679.679,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "the mailing list, I will send you the",
      "offset": 5681.92,
      "duration": 4.239
    },
    {
      "lang": "en",
      "text": "PDFs from today's workshop.",
      "offset": 5683.199,
      "duration": 5.601
    },
    {
      "lang": "en",
      "text": "And then uh if you visit spreadsheets",
      "offset": 5686.159,
      "duration": 3.761
    },
    {
      "lang": "en",
      "text": "are all you need, you can join the",
      "offset": 5688.8,
      "duration": 2.879
    },
    {
      "lang": "en",
      "text": "mailing list. Uh there's a YouTube",
      "offset": 5689.92,
      "duration": 2.96
    },
    {
      "lang": "en",
      "text": "channel as well where I've got a bunch",
      "offset": 5691.679,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "of other videos. Uh and then I also have",
      "offset": 5692.88,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "a Patreon I just launched and I'm",
      "offset": 5695.28,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "available for consulting, training, and",
      "offset": 5696.8,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "implementation. Uh thank you. I hope you",
      "offset": 5698.8,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "enjoyed the presentation and feel like",
      "offset": 5701.76,
      "duration": 4.03
    },
    {
      "lang": "en",
      "text": "now it's a little less like magic.",
      "offset": 5703.44,
      "duration": 9.45
    },
    {
      "lang": "en",
      "text": "[Applause]",
      "offset": 5705.79,
      "duration": 7.1
    },
    {
      "lang": "en",
      "text": "We have time for questions.",
      "offset": 5713.12,
      "duration": 3.88
    },
    {
      "lang": "en",
      "text": "Go ahead.",
      "offset": 5722.8,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "First of all, um, wonderful",
      "offset": 5724.639,
      "duration": 4.641
    },
    {
      "lang": "en",
      "text": "presentation. I learned it so much. Oh,",
      "offset": 5726.96,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "thank you.",
      "offset": 5729.28,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "So, I use uh Super Whisper on Mac. It's",
      "offset": 5731.04,
      "duration": 6.08
    },
    {
      "lang": "en",
      "text": "free. And so, I just wanted your expert",
      "offset": 5734,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "opinion on like the way that I'm using",
      "offset": 5737.12,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "AI is very much like uh voice speech to",
      "offset": 5739.6,
      "duration": 6.079
    },
    {
      "lang": "en",
      "text": "text and I just ramble and I just try to",
      "offset": 5743.12,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "give it as much information and",
      "offset": 5745.679,
      "duration": 3.281
    },
    {
      "lang": "en",
      "text": "sometimes I'll reiterate what I think is",
      "offset": 5747.04,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "really important. Yeah. What What are",
      "offset": 5748.96,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "your thoughts on that? Is is it is it a",
      "offset": 5750.96,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "good approach? Are there ways I can",
      "offset": 5753.12,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "improve on that? Okay. So the number one",
      "offset": 5755.12,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "thing and I was going to I have a video",
      "offset": 5758.32,
      "duration": 4.879
    },
    {
      "lang": "en",
      "text": "I'm working on for this like",
      "offset": 5760,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "the number one thing I say is you have",
      "offset": 5763.199,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "to treat it scientifically.",
      "offset": 5764.56,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "You you can have theories about how the",
      "offset": 5766.719,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "model works but you don't really know",
      "offset": 5768.719,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "till you test it. This whole like the",
      "offset": 5771.04,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "whole space is very empirical. I'll give",
      "offset": 5773.12,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "you an example. So one of the common",
      "offset": 5775.84,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "things in prompting they used to tell",
      "offset": 5778.4,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "you is like say please and thank you or",
      "offset": 5779.679,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "say my grandma used to do this I'm going",
      "offset": 5782.48,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "to lose my job. Right? And that that",
      "offset": 5784.08,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "legitimately used to work. But uh there",
      "offset": 5787.12,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "was a great paper, the prompting report",
      "offset": 5789.76,
      "duration": 4.879
    },
    {
      "lang": "en",
      "text": "uh by Sander and he he went and studied",
      "offset": 5791.76,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "and they tested a bunch of models and",
      "offset": 5794.639,
      "duration": 3.281
    },
    {
      "lang": "en",
      "text": "they found that you know it turns out",
      "offset": 5796.08,
      "duration": 3.599
    },
    {
      "lang": "en",
      "text": "with later models it didn't work. And",
      "offset": 5797.92,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "then uh Ethan Mollik's team also did a",
      "offset": 5799.679,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "recreation of a similar test and they",
      "offset": 5802,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "just tested a bunch of models with a",
      "offset": 5804.159,
      "duration": 3.441
    },
    {
      "lang": "en",
      "text": "bunch of prompts. They tried it with",
      "offset": 5806.159,
      "duration": 3.361
    },
    {
      "lang": "en",
      "text": "polite words and they and they just",
      "offset": 5807.6,
      "duration": 3.519
    },
    {
      "lang": "en",
      "text": "said, \"Okay, which one's better?\" And",
      "offset": 5809.52,
      "duration": 2.639
    },
    {
      "lang": "en",
      "text": "they found that it wasn't really",
      "offset": 5811.119,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "helpful. Um, that being said, uh,",
      "offset": 5812.159,
      "duration": 5.921
    },
    {
      "lang": "en",
      "text": "generally",
      "offset": 5816.159,
      "duration": 5.761
    },
    {
      "lang": "en",
      "text": "you for like oneshot use cases, like I'm",
      "offset": 5818.08,
      "duration": 7.36
    },
    {
      "lang": "en",
      "text": "just using it like I use a whisper tool",
      "offset": 5821.92,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "myself all the time. I do exactly what",
      "offset": 5825.44,
      "duration": 3.759
    },
    {
      "lang": "en",
      "text": "you describe. I I brain dump. But then",
      "offset": 5826.96,
      "duration": 3.679
    },
    {
      "lang": "en",
      "text": "what I do is I go through and I look out",
      "offset": 5829.199,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "I look through it and I fix up things",
      "offset": 5830.639,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "like if there's grammar or I repeated",
      "offset": 5832.719,
      "duration": 4.561
    },
    {
      "lang": "en",
      "text": "something or I said something wrong. And",
      "offset": 5834.56,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "the way to think about why you want to",
      "offset": 5837.28,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "do that is it's a somewhat subtle point,",
      "offset": 5839.44,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "but when we go back to this this",
      "offset": 5842.4,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "diagram,",
      "offset": 5844.32,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "this whole process is fixed. Like it's",
      "offset": 5846.08,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "got a limited amount of compute. It can",
      "offset": 5849.92,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "only do a certain amount of thinking. If",
      "offset": 5851.6,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "I put a token in and I know how many",
      "offset": 5853.28,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "tokens were in the prompt, I can predict",
      "offset": 5855.28,
      "duration": 3.359
    },
    {
      "lang": "en",
      "text": "how many flops. This is why, you know,",
      "offset": 5856.8,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "when like a model like DeepS was",
      "offset": 5858.639,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "trained, we know likely how many flops",
      "offset": 5860.32,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "were used because this thing isn't just",
      "offset": 5862.239,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "like a program. It's like a it's like a",
      "offset": 5863.92,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "formula. we it's a very long formula.",
      "offset": 5865.92,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "It's very fixed. So if you make the",
      "offset": 5868.08,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "prompt do more work, if the prompt is",
      "offset": 5870.32,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "going to make the model do more work,",
      "offset": 5873.04,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "you kind of think of it like it loses",
      "offset": 5874.8,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "some ability to do some other thinking.",
      "offset": 5877.119,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "Um, and so if you have spelling",
      "offset": 5879.119,
      "duration": 6.161
    },
    {
      "lang": "en",
      "text": "mistakes, if you uh say something",
      "offset": 5882.159,
      "duration": 5.361
    },
    {
      "lang": "en",
      "text": "slightly wrong that's different from",
      "offset": 5885.28,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "normal, then it has to spend some sense",
      "offset": 5887.52,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "of compute fixing that up. This is less",
      "offset": 5889.679,
      "duration": 4.241
    },
    {
      "lang": "en",
      "text": "true with the reasoning models today",
      "offset": 5892.48,
      "duration": 2.48
    },
    {
      "lang": "en",
      "text": "because the one thing the reasoning",
      "offset": 5893.92,
      "duration": 2.719
    },
    {
      "lang": "en",
      "text": "models can do is they can repeat this",
      "offset": 5894.96,
      "duration": 4.239
    },
    {
      "lang": "en",
      "text": "process more times on their own. So this",
      "offset": 5896.639,
      "duration": 5.121
    },
    {
      "lang": "en",
      "text": "isn't like a hard and fast rule, but for",
      "offset": 5899.199,
      "duration": 3.761
    },
    {
      "lang": "en",
      "text": "I would say what you're doing is",
      "offset": 5901.76,
      "duration": 2.64
    },
    {
      "lang": "en",
      "text": "probably fine. It's probably better that",
      "offset": 5902.96,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "you put as much as you can that is",
      "offset": 5904.4,
      "duration": 4.799
    },
    {
      "lang": "en",
      "text": "relevant in like if the choice is I put",
      "offset": 5906.08,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "more stuff in but I had the grammar",
      "offset": 5909.199,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "wrong but I had the relevant stuff in",
      "offset": 5911.44,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "that's better than if you didn't have it",
      "offset": 5912.88,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "in there. But if you're trying to",
      "offset": 5914.88,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "engineer a prompt going into your model,",
      "offset": 5916.8,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "I would spend time trying to optimize",
      "offset": 5919.04,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "what its behavior is with some eval to",
      "offset": 5920.48,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "make sure or at least benchmark what it",
      "offset": 5922.48,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "is and then when a new model comes out,",
      "offset": 5924.48,
      "duration": 2.48
    },
    {
      "lang": "en",
      "text": "you can see whether the new model",
      "offset": 5925.92,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "changes things. That's why eval are so",
      "offset": 5926.96,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "important because this whole space is",
      "offset": 5929.28,
      "duration": 6.6
    },
    {
      "lang": "en",
      "text": "very empirical. Good question.",
      "offset": 5931.52,
      "duration": 4.36
    },
    {
      "lang": "en",
      "text": "Any others?",
      "offset": 5939.36,
      "duration": 3.24
    },
    {
      "lang": "en",
      "text": "Okay. Well, have a great conference.",
      "offset": 5944.08,
      "duration": 3.599
    },
    {
      "lang": "en",
      "text": "Hopefully, this will help. Oh, sorry.",
      "offset": 5946.56,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "There's one more. Yeah, go ahead. I",
      "offset": 5947.679,
      "duration": 4.641
    },
    {
      "lang": "en",
      "text": "wonder what your take is on the new",
      "offset": 5949.6,
      "duration": 5.72
    },
    {
      "lang": "en",
      "text": "models.",
      "offset": 5952.32,
      "duration": 3
    },
    {
      "lang": "en",
      "text": "Yeah.",
      "offset": 5957.119,
      "duration": 6.881
    },
    {
      "lang": "en",
      "text": "Um uh I wouldn't call it my take, but",
      "offset": 5959.76,
      "duration": 6.24
    },
    {
      "lang": "en",
      "text": "I'll give you the conventional take. Um",
      "offset": 5964,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "so the question was what what's your",
      "offset": 5966,
      "duration": 3.679
    },
    {
      "lang": "en",
      "text": "take on the mixture of experts models?",
      "offset": 5967.52,
      "duration": 4.639
    },
    {
      "lang": "en",
      "text": "Um there's like let me take a step back.",
      "offset": 5969.679,
      "duration": 4.641
    },
    {
      "lang": "en",
      "text": "There are three or four things that when",
      "offset": 5972.159,
      "duration": 5.121
    },
    {
      "lang": "en",
      "text": "you come out of this, you know, workshop",
      "offset": 5974.32,
      "duration": 4.799
    },
    {
      "lang": "en",
      "text": "that you probably we don't cover that",
      "offset": 5977.28,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "you should know about. One of those is",
      "offset": 5979.119,
      "duration": 4.961
    },
    {
      "lang": "en",
      "text": "rope for embeddings. Another is RLHF,",
      "offset": 5980.96,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "which I talked a little bit about the",
      "offset": 5984.08,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "end. Um, and then the other is reasoning",
      "offset": 5985.28,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "models, which we just talked about where",
      "offset": 5988.159,
      "duration": 2.96
    },
    {
      "lang": "en",
      "text": "the the model can kind of run itself",
      "offset": 5989.6,
      "duration": 3.039
    },
    {
      "lang": "en",
      "text": "through. And the last one is mixture of",
      "offset": 5991.119,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "experts. It's probably like the biggest",
      "offset": 5992.639,
      "duration": 4.881
    },
    {
      "lang": "en",
      "text": "uh one of the biggest top four changes.",
      "offset": 5995.04,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "Um what's trying to do with a mixture of",
      "offset": 5997.52,
      "duration": 5.599
    },
    {
      "lang": "en",
      "text": "expert is that first of all it only it's",
      "offset": 6000.08,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "only here in the perceptron which tends",
      "offset": 6003.119,
      "duration": 4.241
    },
    {
      "lang": "en",
      "text": "to dominate a lot of the calculation",
      "offset": 6005.76,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "inside of a model. Um and what you're",
      "offset": 6007.36,
      "duration": 5.759
    },
    {
      "lang": "en",
      "text": "trying to do is get more knowledge use",
      "offset": 6010.56,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "more parameters without increasing the",
      "offset": 6013.119,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "amount of compute. So what you do is you",
      "offset": 6015.28,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "conceptually take this perceptron and",
      "offset": 6017.28,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "you break it into pieces and then you",
      "offset": 6019.28,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "say depending on what token comes in I'm",
      "offset": 6021.6,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "only going to use a subset of my",
      "offset": 6023.84,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "perceptron's thinking and that way you",
      "offset": 6025.36,
      "duration": 3.359
    },
    {
      "lang": "en",
      "text": "can be more efficient with your compute",
      "offset": 6027.44,
      "duration": 2.56
    },
    {
      "lang": "en",
      "text": "and actually potentially your memory",
      "offset": 6028.719,
      "duration": 2.721
    },
    {
      "lang": "en",
      "text": "too. You can charge your memory nicely",
      "offset": 6030,
      "duration": 2.88
    },
    {
      "lang": "en",
      "text": "per device if you want to do stuff like",
      "offset": 6031.44,
      "duration": 5.199
    },
    {
      "lang": "en",
      "text": "that. Um so it's very it has a lot of",
      "offset": 6032.88,
      "duration": 6.799
    },
    {
      "lang": "en",
      "text": "advantages on paper. Um and we've had",
      "offset": 6036.639,
      "duration": 6.08
    },
    {
      "lang": "en",
      "text": "some really great models based on it. Um",
      "offset": 6039.679,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "the challenge is training ane model is",
      "offset": 6042.719,
      "duration": 5.121
    },
    {
      "lang": "en",
      "text": "is difficult and so it's taken a while",
      "offset": 6045.199,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "for uh some of the open source community",
      "offset": 6047.84,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "to to catch up in that implementation.",
      "offset": 6050.719,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "But you know definitely something of of",
      "offset": 6052.96,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "the future. Um and by the way is",
      "offset": 6055.199,
      "duration": 4.241
    },
    {
      "lang": "en",
      "text": "actually fairly old. There are some you",
      "offset": 6057.6,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "know much older models before chat GPD",
      "offset": 6059.44,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "that in other contexts. Um but that's",
      "offset": 6061.84,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "the job is trying to do. It's trying to",
      "offset": 6064.8,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "cram more knowledge and more parameters",
      "offset": 6066.56,
      "duration": 3.679
    },
    {
      "lang": "en",
      "text": "while keeping the amount of compute",
      "offset": 6068.8,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "used. uh lower and that seems to",
      "offset": 6070.239,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "definitely have a benefit. You can think",
      "offset": 6073.28,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "of it as giving it more knowledge. Um so",
      "offset": 6074.4,
      "duration": 3.759
    },
    {
      "lang": "en",
      "text": "yeah,",
      "offset": 6076.32,
      "duration": 5.64
    },
    {
      "lang": "en",
      "text": "does that answer your question?",
      "offset": 6078.159,
      "duration": 3.801
    },
    {
      "lang": "en",
      "text": "Okay, thank you guys.",
      "offset": 6085.28,
      "duration": 4.6
    },
    {
      "lang": "en",
      "text": "[Music]",
      "offset": 6092.69,
      "duration": 2.25
    }
  ],
  "cleanText": "[Music]\nOkay.\nThank you for coming bright and early, uh,\n9:00 a.m. at the start of the conference,\nuh, for LLMs, for Web Devs, uh, GPT in 600\nlines of Vanilla JS. Um, I think\nyou guys are going to have a great\nconference. I was here last year. I\nthoroughly enjoyed it. Um, and I think\nthis is a great way to kick things off.\nIf you're just coming to this field or\nthis conference without any background\nin machine learning, this is your\nmissing AI degree. That'll help make the\nrest of the conference, I think,\nhopefully a lot more valuable.\nSo, if you're just joining us and came\nin, you can go to Spreadsheets-are-all-you-need.\nUm, and there's a Discord link\nin the upper menu. Uh, click on that and\nthen go to the AI Engineer World's Fair\n2025 room, and then there's a link to\ndownload the GPT-2 model weights in the\npinned message at the top. Takes a\nlittle while to download that, so I would\ndownload that and get started, uh, because\nthe Wi-Fi might be a little bit slow.\nWe're going to be using that in a bit.\nOkay, we're going to do something\nspecial today. Uh, it is a talk, and I\nwill be doing a lot of talking at you,\nand we'll be running code. So it is a\nworkshop, but our mission today is to\nbreak Clark's third law. You might be\nfamiliar with the science fiction author\nArthur C. Clark and his famous maxim\nthat any sufficiently advanced\ntechnology is indistinguishable from\nmagic. And nowhere is that, you know, more\ntrue or relevant today than when it\ncomes to large language models. These\nare seemingly magical machines that can\nproduce lifelike text, automate tasks as\nagents, and maybe even replace humans in\ncertain contexts.\nAnd if you ask somebody how these work,\nor you go online, you're liable to get\nthe impression that you need to have\nsemesters of linear algebra and calculus\nbefore you can begin taking your first\nmachine learning class and understand\nhow these work. And yes, that's true if\nyou want to be a machine learning\nengineer. But if you just want to\nunderstand how these work and you're a\nbuilder on top of them, I'm here to tell\nyou that is not true. Do not believe\nthem. You don't need all that\nsophistication if you just want to have\na really accurate model of how a\ntransformer works. I know because I was\nhere last year. I gave a talk called\nSpreadsheets-are-all-you-need, where I\nshowed an Excel worksheet that\nimplemented all of GPT-2 small entirely\nimpure Excel functions. And then I took\nthat spreadsheet and I turned into a\nclass that I taught online where I took\npeople tab by tab through how the entire\nmodel works. And not everyone was even\nan engineer. So one of my favorites is\nthis guy. This Joe here is a CFO. He's\njust naturally good at Excel, and that\ngave him everything he needed, combined\nwith a sheet, to understand how a large\nlanguage model works on the inside, and\nhe says this is great. I had no\nexperience with machine learning or AI\nconcepts before, yet he was able to walk\naway with a very good understanding of\nhow they work. So what I'm going to do\ntoday is compress that class, which is\nabout eight hours, down to these two\nhours today and explain how the\ntransformer works, and I show up today, or\nthis year, at the conference with this\ninstead of Excel because not everyone\nof us have a job that requires us to be\nreally good at Excel. Uh, we're using a\nVanilla JavaScript implementation\nbecause a lot of folks who come to AI\nengineering as a field have a web\ndevelopment or full stack JavaScript\nbackground. And so if that's your\nbackground, you are perfect the way you\nare. You don't need to learn Python if\nyou just want to understand how a model\nworks, and you're still going to use\nTypeScript and X.js, GS around the model,\nbut you still want to have a good\nunderstanding of how it works.\nSo today's approach is I'm going to give\nyou the background to understand the\ncode, and we're going to take a brief\nwalkthrough of it. I'm going to focus\nmore on the why than on the what. So\nwe'll take a look at the code, but I'm\ngoing to spend a lot of time building\nintuition and background to understand\nthe code.\nAnd then instead of complex equations,\nI'm going to use analogies and examples\nto make it more tangible.\nOkay? And the background you need to\nhave is, first of all, just motivation, uh,\nand a curiosity to understand how these\nwork on the inside. Uh, any science,\ntechnology, engineering background is\nsufficient. Prior programming experience,\nespecially in JavaScript. Uh, but you\ndon't need to know React or Vue. We're\ngoing to just use Vanilla JavaScript.\nAnd then some awareness, I would call it,\nof linear algebra, meaning you just need\nto know what a matrix multiplication is.\nUh, you don't need to be a hot shot\nJavaScript ninja. You don't need prior\nAI or ML background, and you don't need,\nyou know, deep calculus or linear algebra\nfluency.\nOkay. And the key resources for today\nare going to be our JavaScript\nimplementation of GPT-2. Uh, use Chrome on\nthe desktop, and if you go to\nSpreadsheets-are-all-you-need.ai, uh,\nand I, I apologize, that is a long domain\nname /gpt2. It'll load up this\nimplementation, and it'll run locally in\nyour browser. Uh, there's a Discord\nserver where I've dropped some links, and\nif you've got questions, feel free to\ndrop them in there as well.\nOkay. So this is a simplified diagram of\nGPT-2. It does not look like your classic\ntransformer diagram intentionally, and it\nwill serve as our road map for what\nwe're going to do throughout the today's\nworkshop. I'm going to start by just\ngiving you some background on LLMs and\nour JavaScript implementation of GPT-2,\nhow to get it running, how to get it\nstarted, and then we're going to focus\non these three areas for most of it. And\nthat's tokenization, embeddings, and\nthen the language head. And I've focused\non those because that's the input and\nthe output of the model, and those are\nthe most important to have the\nbackground and understanding if you're\ngoing to be building systems around and\non top of LLMs.\nWe will cover the inside number\ncrunching part, that's attention and the\nmulti-layer perceptron at a pretty high\nlevel. I'll go a little bit more into\nthe multi-layer perceptron because then\nI can explain about back propagation, and\nit serves as kind of a foundation to\nunderstand how the model learns, uh, which\nis an important concept.\nAnd then finally, I'll talk about the\ndifference between GPT-2 and ChatGPT. So\nthey were separated by three or four\nyears. What were those innovations that\nmade the model so much seemingly more\nsmarter than GPT-2?\nHint, it wasn't necessarily, uh, anything\nalgorithmic.\nOkay, so let's start with a quick tour\nof our JavaScript implementation of GPT-2\nand then some background on LLMs.\nSo this is what you get when you load up\nGPT-2\nuh, /GPT2 on the Spreadsheets-are-all-you-need website.\nUh, if you scroll down, the first thing\nyou're going to want to do, there's a\nlink here says download the GPT-2 small\nCSV. So the first thing you want to do\nis go to this page on GitHub. This is\nall the model parameters of GPT-2 small\nin a bunch of CSV files. It's a giant\nzip file. Uh, you're going to download it\nand unzip it. And when you hear about,\nyou know, this model is like a billion\nparameters or 70 billion parameters, that\nit's all just a bunch of giant numbers,\nand you can think of it as a giant\nspreadsheet. And that's literally what\nthe zip file is. Once you've downloaded\nthat zip file and opened it up, what you\nwant to do is select all of those files\nand drag it into this section here. You\ncan once, uh, when it, uh, when it's done\nloading all those files, it'll look like\nthis. It'll say ready, all model\nparameters loaded. When it's not loaded,\nit'll be in red, and it'll say, you know,\nplease add the files. And what it's\ndoing is it's actually loading all those\nGPT-2 parameters locally into your\nindex.db database. And you can see here\nit's basically about 1.5 GB. Now, Chrome\nwill let you do that, uh, if you've got\nsufficient disk space on your hard\ndrive. But the benefit of doing this is\nnow the entire model is running locally\nin Vanilla JavaScript on your browser.\nIn fact, to run and debug this, you don't\nneed anything else. You could pull the\ninternet connection, and it should still\nwork. And the way this is set up is\nsimilar to a Python notebook. If you've\nencountered one of those, we have these\ncells, uh, and every cell has a play\nbutton which will run what's inside it.\nAnd there are two types of cells. One\ntype of cell is just JavaScript code.\nAnd you can open these and expand these\nif you want. It's just Vanilla\nJavaScript code. Our matrices, for\nexample, are just simple 2D JavaScript\narrays. And if I hit play, it'll execute\nthis code. And you can see there's a, a\nmessage right there. The other type of\ncell is one like this. It's kind of like\na table or spreadsheet interface. It\nruns a formula and then shows you the\nresult. So, it's a way to actually run\ncode and see the results very\nimmediately. And these formulas are just\nraw JavaScript with a little syntactic\nsugar to figure out, you know, if you\nreference something, it knows what\nprevious table it was.\nI'm going to give you an example of\nthat.\nSo,\nright here is an example. So, here this\nget final tokens is just JavaScript code\nwe defined earlier. And this prompt to\ntokens is literally the DOM ID. And this\nlet's zoom this one out. This, uh, this\nbrackets is basically syntactic sugar\nsaying go grab the DOM table that has\nthis ID. So prompt tokens is up here, and\nit's just grabbing this thing and\npassing that into that function. So\nuh, it's all straight Vanilla JavaScript.\nBut the real benefit is being able to\ndebug a model right here without leaving\nyour browser. So what I'm going to do, I\ncan do who here has done like console\ndebugging before, right?\nRight. So you can do console debugging\nright here. So if I say console.log\nmatches and I open up my dev tools\ninspector.\nLet's put that side by side.\nThere we go. And I go to the console.\nAnd then I rerun this.\nThere we go.\nWait for the layout shifts.\nThere we go.\nSeparate into words is right there. So\nif I rerun this, you can see right here.\nIt might be a little bit hard, but if\nyou, uh, look here, you can see I've\nbasically got my console.log statement\nhere. If I wanted to know what that\nvariable is doing, but I can go even\nfurther. I can just type the word\ndebugger\nand then I rerun it.\nAnd boom, I'm actually stepping through\na large language model that was once\nconsidered too dangerous to release,\nright, with ever leaving my browser. So\nevery part of this model, if you were\nlike, I really want to understand how\nthis works, you can step right through\nit in a familiar language and the\nbrowser, a very familiar IDE. So I'm\ngoing to remove that debugger statement\nso it doesn't get in our way later.\nAnd then\nThere we go.\nOkay, so that's a quick tour of how to\nrun our JavaScript implementation of\nGPT-2. Okay. Uh, next up, large language\nmodels. Um, so a large language model\nhas a really simple job to do. We give\nit a passage of text, and it simply\npredicts the next word, technically the\nnext token, as we'll talk about. So I\nmight give it the text Mike is quick. He\nmoves, and it'll just output a single\nword, quickly. It does not by nature\nnaturally give you paragraphs of text.\nSo if we want to get more text, what we\ndo is we take that output, and then we\nappend the word we just got out, which\nwas quickly, and put it at the end of the\nthing we originally put in. So then we\ntake that additional text. Now we ask it\nto run through again with this much\nlonger piece, say what is the next word\nnow, and it says, oh, it's and then we take\nthat, append it to the original input, and\nkeep going and ask it what the next\nthing is, and this is how we generate\nparagraphs of text or code from model. It\nis what they call an auto regressive\nmodel. You simply take the output, put it\nback to the input, and rerun it. Now, this\nis why if you use our JavaScript\nimplementation, all it does is predict\nthe next word because that is the core\nfunction. If you understand that, you\nunderstand how the rest of it works.\nSo, we've said that large language\nmodels have this core action of\ncompleting passages of text, and they're\ntrained to complete sentences like this\none. Mike is quick. He moves. And as a\nhuman, you probably understand, you\nknow, a possible completion is the word\nquickly, or maybe the word fast, or\naround. But how do we get a computer to\ndo that? Well, here's a\nfill-in-the-blank problem that computers\nare really good at. 2 plus 2 equals 4.\nIt's a math problem. Computers are\nreally good at math, and you can make\nthese equations really complex, and\ncomputers can still do them really fast.\nSo in effect, what researchers have\nfigured out how to do is take what is a\nword problem and turn it into a math\nproblem. In order to do that, they have\nto go through a series of steps. First,\nwhat they have to do is they have to map\nthe words in our text to numbers. Here,\nI've shown it as just a one-to-one\nmapping. So Mike goes to 89, is goes to\n9. But in practice, as we'll see, it's a\nlong list of numbers called an\nembedding.\nAnd then we do our number crunching on\nthem. Here, I've drawn this as just\nsimple arithmetic. It's much more\ncomplex than that, but it's actually\nalmost as simple as that. It's just a\nlot of multiplication, addition. There's\nan exponentiation in there. Um, but it's\nnot math you probably haven't seen\nbefore. It's just a lot of it tediously\nput together.\nAnd then after all that arithmetic, we\nget a result. Again, it'll be a long\nlist of numbers. Here, I've simplified\nfor now, just saying a single number.\nAnd we look at the resulting number that\ncomes back. And that number is going to\nbe what it says the next predicted word\nis going to be, but we need to translate\nthat back to a word because it's a\nnumber. So then we do the reverse of\nwhat we did at the beginning. Instead of\ngoing from words to numbers, we go from\nnumbers to words. And of course, the\nnumber we get back, numbers are\ncontinuous. Uh, words are discreet,\ndoesn't necessarily always cleanly map.\nWe'll get some number like here, for\nexample, hypothetically, we get 231,\nthere's nothing in our dictionary that\nmaps to it, but the closest word in our\ndictionary is quickly, which is at 232,\nbut fast is kind of close too, of 240. So\nwhat we're going to do is we're going to\nweight the probability distribution of\nthese tokens according to how close they\nare to the predicted number that came\nout of our model, and that turns into our\nprobability distribution. So then we run\na random number generator, and then we\n\n\nPick according to that distribution.\nOne thing I want to emphasize is we add the random number generator in.\nWe could always just simply take the closest word, and that's called greedy or temperature zero.\n\nOkay.\nSo that gives us this view.\nYou get some text.\nWe turn that text into tokens.\nWe turn those tokens into numbers, and then we do some number crunching on them, and then we turn those numbers into text.\nAnd that gives us our next predicted token.\n\nOkay.\nThe model we are going to be studying today is GPT-2, uh, GPT-2 small specifically.\nThere's actually multiple versions of GPT-2 that were released, uh, and that came out in 2019, so about four years before GPT-4 and three years before ChatGPT.\nBut don't let that fool you.\nThis was a model that was considered, uh, too dangerous to release when it first came out and was state-of-the-art.\nMore importantly, it is actually the foundation of most of the state-of-the-art models you have probably used today.\nAnd you don't have to take my word for it.\nThis is a research lab at Luther AI saying basically the recipe for building a large language model has not fundamentally changed since the transform was introduced and only slightly tweaked from the language models by OpenAI, GPT-1 and GPT-2.\nAnd then in this article, they actually go on to list what the changes are between GPT-2 and, uh, so and a state-of-the-art model at the time, which was Llama 2 when this was written, which was last year.\nSo the way to think about this, and this is a helpful family tree chart of different large language models, is that most of the ones you're familiar with at the top of this tree, might be hard to see, is ChatGPT, Llama, Bard/Gemini, GPT-4, Claude.\nThey all inherit from GPT-2.\nGPT-2 is its granddaddy.\nIf you understand GPT-2, you are 80% of the way to understanding how a state-of-the-art model works under the hood.\n\nOkay, so now let's dive into the first stage of our model.\nSo that's tokenization.\n\nOkay, this is where we take the input text and we split it into subword units called tokens.\nIn the example that I like to use, Mike is quick, he moves.\nUnfortunately, every single word is a single token, but it is not unusual for a word to be two, three, or more tokens.\nAnd then these tokens all have IDs that are just lists or positions in the dictionary as you see here underneath.\nSo let me show you what this looks like.\nSo, I'll wait for the Wi-Fi.\n\nOkay.\nWell, we get more people in the room, we get, we get more Wi-Fi, uh, issues.\nUm, so what I wanted to illustrate for you is that you can take a word like, uh, oh, you know what I can do?\nI, I do have a backup.\nLet's do this.\nOkay, this is the version that runs locally.\nUh, so what you can do, so you can try this once we get Wi-Fi back.\nI'm going to take the word reindeer and the word reinjury, and then I'm going to run them up until right here, which is the final tokens.\nSo these are the tokens for the input prompt we just put in here.\nAnd you can see the word reinjury was turned into multiple tokens.\nThere's a space, which is part of the token itself, rein, and then jury, jur, y, and they have separate token IDs.\nThe thing I want you to pay attention to is reindeer also starts as re, i, n, right, but it got split into three tokens: space, re, i, n, d, e, r.\nSo this is not like basic string parsing; something more complex is going on.\nAnd so the natural question is, well, why the heck are we doing this?\nWhy don't we do something simpler?\nWhy don't we do, say, word-based tokenization?\nWe just take every word in the dictionary and give it a number, like dog is one, cat is two, and so forth.\nSo that has a couple problems.\nFirst is it can't handle unknown or misspelled words.\nAnd there are some models, early models that had an unk for unknown token.\nUm, but when you're grabbing all the text on the internet, you might encounter things you didn't expect.\nExamples could be languages that you weren't planning for.\nOne of the early models, GPT-2, in fact, they tried to take foreign languages out of it, and then they magically discovered some snuck in, and it was actually good at translation.\nThey wouldn't have had that if a lot of words were just simply that were not English were just thrown out.\nAnother example is when they did summarization with it, they realized they can put the too long didn't read acronym TL;DR.\nIf they didn't have a token for that, it would have been thrown away, and it would have lost that ability.\nThe other problem is that you're going to increase the vocabulary size, which is going to increase the size of the model.\nIt'll need more parameters if you're going to have more vocabulary.\nEnglish alone is 170,000 words.\nFor perspective, GPT-2's vocabulary is only about 50,000.\nSo it's a third of that.\nAnd then if you add additional languages on that and you're doing word-based tokenization, it would get even larger.\nSo in essence, if you do this, you get more memory, more compute, or maybe less performance.\nSo then you're like, well, I'm a developer.\nI'm used to say something like ASKI.\nWhy don't I just do character-based tokenization?\nI say A is one, B is two, and do it that way.\nWell, the first problem is it's going to increase the sequence length.\nSo, you can see this inside the model as you go through the model after you get your prompt right here.\nYou can see here's where the embeddings.\nWe'll talk about those in a second, but you can see Mike is quick.\nPeriod.\nHe moves.\nEach of these rows, this matrix has a height that is the size of the number of tokens, right?\nAnd that persists through the entire model.\nSo as I keep going, we see again this six-height matrix, it's going to keep going.\nIf we made every single character its own token, this is going to get a lot larger.\nRight now, it's just what, six tokens high.\nBut if I made m, i, k, each of these characters their own token, this is going to get a much larger matrix.\nSo it'll be more memory, more compute to process.\nThe other issue is there's low semantic correlation in characters.\nThey don't carry a lot of meaning.\nAnd a good example was this chain letter that went around a few decades ago on the internet.\nAnd it says, according to research at Cambridge University, it doesn't matter in what order the letters in a word are.\nThe only important thing is that the first and last letter be at the right place.\nAnd all the letters are jumbled, but you can still read it.\nAnd the point is that you don't read characters.\nYou actually read subword units yourself.\nUm, and so if there's less semantic correlation, it's going to be more work for the model to do during training to erase that character boundary and get the pieces that really matter.\nSo if character tokenization is too small and word tokenization is too big, Goldilocks says let's do something in between, which is subword tokenization, and that's this algorithm called by parent coding.\nSo it's got two phases.\nThe first is the learning phase where you take a large, they call it a corpus of text that's gathered from the internet, and then we put it through this learning algorithm we'll describe in a second, and then we get out of it a vocabulary, a dictionary of tokens, and then later when we're processing the model and asking it to generate text, if we give it some input words, we have to retranslate it into those tokens that were used during translation during training.\nSo we take the input words, we take the vocabulary, and we get out tokens.\nThis is the research paper that introduced the algorithm to machine learning, but it turns out this algorithm is from the 90s.\nIt's actually a compression algorithm, as we'll talk about in a second.\nAnd it even has some Python code you can copy and paste and run.\nThe goal of the algorithm really is to take the text that's going to be trained on and figure out the most efficient way to represent it.\nThat's really what tokenization is trying to do.\nAnd so here's the example from the paper.\nAnd what I'm going to do first is I'm going to use this dot to separate out the characters, right?\nThat's going to tell us essentially each token will be separated by those dots so we can see them individually.\nAt the end of this process, you'll see that there are less dots, meaning that we've got more tokens, sorry, a large more number of tokens in our vocabulary, but less number of tokens being used to represent the corpus.\nAnd in this corpus, we're going to pretend that when we scraped the internet, this is all we came up with.\nThere are only four words: low, lower, newest, and widest.\nAnd you'll notice some of them appear more than once.\nIn fact, they all do.\nBut the reason I'm doing it this way is I want the frequency of the word to be represented, right?\nI'm trying to compress all the words on the internet.\nAnd if a word is more frequent, I want to know that because if it's more frequent, I want to give it more representation or a more efficient representation.\nSo that dot is going to separate our tokens.\nAnd then I'm going to put the underscore to indicate the space character.\nOne caveat in this example, the space character is at the end of the token.\nIn GPT-2, it's actually at the beginning.\nAnd then we're going to start with our vocabulary of just our characters A through Z, all lowercase.\nUh, we're assuming we're in a lowercase-only world here for now.\nThose are our initial tokens.\nThat's our vocabulary on the right.\nAnd then the first thing we're going to do is we're going to count all the adjacent tokens.\nAll the adjacent characters.\nRight now it's there are no tokens other than characters.\nAnd we can see E and S occurs nine times, right?\nSix times in newest and three times in widest.\nSo then I'm going to put a table together and I put E next to S has a frequency of nine.\nAnd then I'm going to do this for all the possible pairs.\nAnd then I'm going to take the most frequent pair and I'm going to say that's a new token.\nWhy am I doing that?\nBecause if I do that, I can take ENS, I can put them together, and I can pretend they're their own character.\nI'll call it a token.\nAnd then I can go back to my corpus and every place there was an ENS, I'm going to replace it with my new ES token.\nSo now I've shrunk the number of tokens need to represent the stuff here on the left.\nNow I've taken what were separate tokens and combine them together.\nSo I'm using less tokens to represent all this text.\nAnd then I can repeat the process.\nI can just say ES next to T occurs nine times.\nAnd I can do a whole another table.\nNow ES is itself now its own character, its own token.\nSo it can be paired with other things that I'm counting and I can see that es with t occurs nine times.\nSo I add that to my vocabulary of tokens.\nAnd I go back and I compress my corpus again.\nThen I keep going and I just simply repeat this process looking for whatever is the most frequent at each pass and making it a token and then recompressing the corpus.\nAnd after 10 passes you get something like this.\nHere on the right is our vocabulary of tokens.\nAnd then here on the left you can see we have shrunk the number of tokens used to represent the corpus.\nThere are less of these dots right than you we saw before and originally.\nNow the most frequent words became their own tokens, right, low and newest.\nAnd even the words that did not get their own full token representation, we've now represented them a lot more efficiently.\nUh, and you notice that there's some common subword units like low became tokens and est became tokens.\nSo, it managed to map to some of the morphemes, the parts of speech we use as humans as tokens.\nBut that is just a coincidence.\nRight now, the model has no understanding of semantic meaning.\nOkay, so this is the learning algorithm.\nNow, the tokenization algorithm is really similar.\nI'm not going to go through it in full detail.\nI have a video on my YouTube channel where I do go through it in full detail, but for time I'm just going to talk about it at a high level.\nIt's essentially similar to the learning algorithm except we're doing it on individual tokens as they come in, asking ourselves what would it look like if this word were part of the tokenization process.\nSo let me show you what that is like.\nSo there's a helpful jump to here.\nLet's go to tokenization.\nSo the first thing we do is we take our prompt and we separating into words.\nNow, this is just a regular expression that came from the OpenAI source code when they open sourced it.\nAnd we're just parsing it according to this and it's going to basically take out punctuation and spaces.\nSo, we get these as our words.\nSo, Mike is quick.\nPeriod gets its own token.\nHe and moves.\nRight now, we're not tokens.\nWe're just separating to words.\nBut do note that the spaces are assigned as part of this separation.\nSo, he and moves have a space in front of them.\nThe next thing we're do is we're going to fetch vocab BPE.\nThis is a file that came from OpenAI when they trained the model and it tokenization.\nThis is their dictionary of tokens.\nSo here's when they did their training in BPE.\nThe most common left token with a right token was space with a T.\nThe second most was space followed by an A and so forth.\nI've added two extra columns, rank and score, just to figure out where, uh, a pair of tokens is in terms relative to the others, how important they were.\nThen this is just a helpful map of tokens to their IDs.\nAnd then finally, there's this, which is prompted tokens.\nNow, this is not how you'd really want to write a tokenizer.\nI've set it up to look similar to the Excel version of the matrix.\nSo you can watch the video and still be able to watch it and and understand it, depend no matter which version of, uh, the Excel sheet or the JavaScript version you're looking at.\nBut this kind of illustrates the process.\nSo here is quick.\nWe're breaking it apart right here.\nLet me get presentify.\nThere we go.\nWe're breaking it apart into characters here.\nRight, quick.\nAnd then what we're doing is we're looking at each pair of characters.\nSo Q with U, U with I, I with C, C with K, and we're saying for each one, where does it fall in\n\n\nthat\nrank of tokens, and we're going to take\nthe most popular one. In this case, it's\nI and C. And so we've rewritten this as\na string of tokens, except the I and C\nwere put together as one token. And then\nwe're simply going to repeat the\nprocess.\nLet's stop annotation\nand keep going. And we're combined. Then\nQ and U get combined. Then ICK get\ncombined. And finally gets to the point\nit realizes, oh, this is in my token\nvocabulary. And it turns it into a\ntoken. Again, I have video if you want\nto see this in depth and in detail.\nUm,\nbut for now, just think of it as the\nsame part of the learning process.\nReally just run small. Now tokenization\nis actually kind of considered by a lot\nof experts to be a necessary evil. Some\nof the problems that you sometimes\nencounter with models, although the root\ncause is in tokenization, it can\nsometimes make them worse. So the common\none is how many Rs are there in\nstrawberry? Uh, models don't actually see\nthe Rs. And I love this, you know, post\nfrom Riley Goodside where if you\nremember the matrix, the character says,\n\"Oh, I don't, I don't see the numbers. I\njust see, you know, what's inside\nthere.\" And that's kind of like what it\nis to the model. You know, it doesn't\nsee any of the letters. So, what he's\ndone here in this image is strawberry is\ntokenized multiple different ways\ndepending on whether it's uppercase\nversus lowercase, whether there's a space\nin front of it or not, and whether\nthere's a quote in front of it or not.\nSo to the model, you know, these six\nwords are not all strawberry. They're\nall six different token patterns. And so\nit makes it a lot harder and a lot more\nwork for the model to understand it. If\nyou think about it, you don't actually\nsee the letters either. If somebody\nasked you how many letters are in a\nword, you'd have to stop and think and\nparse it out.\nUm, I said at the beginning, you know,\nyou don't want to do word tokenization,\nyou don't want to do character\ntokenization. That's not a hard and fast\nrule. That's an empirical rule. And\nthere are research models that have done\nboth. Uh, so just know that, you know,\nthat's, you know, maybe a few years from\nnow, there'll be character-based\ntokenization will be more popular. This\nis an example of one. The last thing I\nwant to leave you with is that\ntokenization doesn't have to be just\nabout uh text. It can also be about\nother things. So here's an example of\nvision transformer. They use patches of\nimages as tokens. Whimo uses uh\ntrajectories in space to prevent\ncollisions as tokens.\nOkay,\nlet's briefly check\nhow we're doing if this will load.\nThere we go. So, this is actually pinned\nat the top. Uh, 9:30. Oh, we're right.\nWe're just a minute behind. Okay. So,\nthis is. You guys can keep me honest. Uh,\nat in the Discord room at the top is a\nspreadsheet. I'm of course using a\nspreadsheet to make sure we stay on\ntrack and on time. Uh, okay. So, oh, we\nneed to do this now.\nThere we go. Next up is embeddings. So\nnow we're in the second phase of the\ninput. Uh, these are uh token and\nposition embeddings.\nOkay. So at the beginning of this\nworkshop, I talked about how we map\nwords into numbers. And I simplified\nthis process by saying what we're doing\nis we're taking say the word Mike and\nwe're turning it into a single number uh\nlike 89. But of course that's not what\nwe're really doing. We're actually going\nto turn it into a long list of numbers\ncalled an embedding. Um, so even the\nperiod, for example, gets 768 of these\nnumbers. And in the case of GPD2, uh, the\ndimensionality, that list size is 768.\nEvery single word gets 768 numbers. And\nyou can see that if we go to\nthe token embedding section and then\nthese, we'll get to that table in a\nsecond. These are the embeddings of our\ninput prompt. And you can type, by the\nway, I, I didn't mention this before. You\ncan type anything here in this input\nprompt and it should parse it. Although\nit doesn't handle foreign language as\nwell because there's a character\nmismatch on import. Um, but here's Mike\nis quick. Period. And each of these gets\n768 numbers. So what you can do is if I\ntake row one, column 768,\nthere's where our list of 768 numbers\nends. So every single one of these gets\nthe same number of uh dimensions for how\nit gets represented.\nAnd it might be a little confusing\nbecause we mapped words into tokens with\nnumbers, had token IDs, and then we have\nthese embeddings as well. And the\nanalogy I like to use is imagine you are\ngoing to go uh look for a house to rent\nor a house to buy. And the street\naddresses uh and you build this table of\nstreet addresses and then square feet,\nbedrooms and bathrooms and price. The\nstreet addresses are identifiers.\nThey're kind of like the token IDs. They\ntell you where to find something, where\nto find a house, but they don't tell you\nanything about what's inside. They don't\ntell you about what you care about, what\nthe meaning is. It doesn't tell you the\nsquare feet, the bedrooms, the\nbathrooms, or the price. And the\nembedding values, that's their job.\nThey're to take the token and tell you\nsomething about what it means. And the\nidentifier or the token ID is just to\ntell, give it a position in the\ndictionary, effectively a numerical\nname.\nAnd what we're really doing with the\nembedding values is we're trying to\nbuild a map for words where we put\nsimilar words grouped together. So here\nI've shown a two-dimensional map, but of\ncourse we're in a 768 hyperdimensional\narea, but the idea is basically the\nsame. Take the words happy and glad in\nthis map, this word island. You know,\nthose are happy words. So I'm going to\nput them up here, and then I'm going to\ntake words like dog and cat, and I'll\nput them in another part of this word\nisland because they're animals. They\ndon't relate as much. And then you know\nthe word sad, well it doesn't have the\nsame meaning as happy and glad, but it's\nstill an emotion. So I want it closer to\nthe emotions, happy emotions part of the\nisland into this maybe the sad province\nright next to the happy province. So\nthey're kind of on the same half of the\nisland, but they're not directly in the\nsame spot because happy and sad have\ndifferent meanings.\nSo here's a simple two-dimensional\nexample of the benefit of doing this,\nwhich is that you can start doing word\narithmetic and word math. So we're going\nto imagine that we've built a\ntwo-dimensional embedding where the\nfirst column is authority and the second\ncolumn is gender. And we take the token\nman. And we'll just arbitrarily say man\nhas authority of one and a gender of\none. A woman authority of one and a\ngender of two. A king has more authority\nthan a man. So two for authority, gender\nof one because still a man, and then\nqueen authority of two, a gender of two,\nand we can plot this out in a plane like\nas follows. So queen, for example, is at\nposition 22\nand then we can actually build\nrelationships just from doing vector\nmath. So for example, if we take king, we\nsubtract man, we add woman, and then we\njust do regular arithmetic column by\ncolumn. So 2 - 1 + 1, 1 - 1 + 2 gives us\n2 2. So king minus man plus woman is 2.\nBut of course that is the same thing as\nqueen. So we're saying king minus man\nplus woman equals queen. And we can\nthink of this as an analogy. King is to\nman as queen is to woman. And if we take\nout the queen and just leave it as a\nblank, we have our first kind of word\nproblem we can convert to a math\nproblem. If you give me any three words\nand I had an embedding for them, I can\nfigure out what the fourth word in this\nrelationship is simply from vector math.\nAnd that is what wordtovec, which was the\nmost famous word embedding, was able to\ndo. It learned a bunch of relationships\num in a series of papers, not just one\npaper. Uh, so for example, France\nis to Paris as Italy is to Rome and\nJapan is to Tokyo. Einstein is to\nscientist as Messi is to midfielder or\nMozart is to violinist. Uh, Japan is to\nsushi as Germany is to brought. It\ndidn't get all of them right, but\nclearly it's learning something about\nrelationships. And I want to be clear,\nthis is actually just the same thing as\nbeing good at clustering. So imagine\nI've got on my word island, I've got all\nmy countries over here, right? France,\nJapan, Italy, and then I've got all my\ncapitals, Paris, Tokyo, Rome over here\nin the word island. Well, every single\none of them has the same vector\nrelationship in space between each other\nif the clustering was really good and\ntight. And if somebody comes in and\nsays, \"Hey, what's the capital of\nCanada?\" Well, I just use that same\ndirection. I add that same vector to it.\nI can say, \"Oh, well, it's Ottawa.\"\nSo, in practice, real world embeddings\nare different than what I've shown here\nwith this contrived example. First of\nall, we have many more columns or\ndimensions. So instead of simply two, we\nhave hundreds. GPD2 is 768. Your\nstate-of-the-art model these days has a\nlot more.\nUh, the other key difference is I made up\nthis thing saying that the first\ndimension or column is authority, the\nsecond one is gender. We don't know what\nthey mean. The columns are completely\nuninterpretable. The model just seems to\npick them. And the values themselves\ncorrespondingly therefore are not\ninterpretable either. And that might\nsound useless, but it's actually useful\nfor at least getting similarity. For\nexample, so let's go back to our housing\nanalogy. Imagine I took off the top\ncolumn, the the labels essentially, top\nrow of what each column meant, and I\njust gave you the IDs. If you went to\nsay 47 IV lane, and you said, I like\nthis house. I want to see more like it.\nYou could still find those because what\nyou could do is you could notice that\nwith 58 sun a and 15 luna lane, they all\nhave roughly the same values in the\nfirst column 2400 2400 2400 and the same\nvalues for the third fourth column as\nwell. So you're like, if I like this\nhouse, I can find the others like it even\nthough I don't know what these columns\nmean. So the question you're probably\nasking yourself is, well, where the heck\ndo these values come from? How do we\nknow what they mean or how does the\nmodel pick it?\nWell, the slightly unsatisfying answer\nis that the embeddings are just simply\nlearned by the neural network model\nduring training. So now let's just talk\nabout what training looks like. So in\ntraining, what we do is we grab a bunch\nof text from the internet. We take out\npassages like this one. Mike is quick.\nHe moves quickly. So quickly was in the\noriginal passage. And then we chop off\nthe last token or the last word. And we\nhave a randomly initialized model. All\nthe values of the weights and parameters\nare completely random, including the\nembeddings. And then we run it through\nthe whole model and we say what do you\npredict is going to be the next word, and\nit's random. So it comes up with\nsomething nonsensical like Mike is quick,\nhe moves haircut. And then we use this\nalgorithm called back propagation. And\nwe say, hey back propagation, the correct\nanswer was quickly. Can you adjust the\nparameters to get closer to that value?\nand it will go and tell us for every\nsingle parameter how to slightly move it\nto get it closer to producing the right\nanswer of quickly. And then we rerun the\nmodel and eventually it says Mike is\nquick, he moves quickly. And then we do\nthis not just for one single passage of\ntext, we're doing this for many passages\nat a time. And one great benefit of this\nis we don't have to teach the model\nanything explicitly. It's kind of\nlearning from unsupervised text. We're\njust gathering that was naturally there\non the internet. and it's learning\nthings like grammar, names, capitals of\ncountries.\nUm, but that seems a bit mysterious and\nwe can kind of get an intuitive sense\nfor what it's doing if you think about\nit as learning from word statistics. So\nimagine you've got passages like this\none about the words ice and steam. It\nwas so cold the puddle had turned to\nice. Steam rose from the still hot cup\nof coffee. And what you notice is that\nthe words ice and cold tend to co-occur\nwith each other. And the words steam and\nhot tend to co-occur with each other. So\nif you were an alien coming down from\nanother planet, you had no idea what our\nlanguage was and you looked at this, you\nwould say, I don't know what ice, cold,\nsteam, and hot are. But I know that ice\nis probably cold more than steam is\nbecause ice and cold co-occur more often\nthan steam and cold do. And I know that\nsteam is hot because ice and hot don't\nco- occur as much as steam and hot do.\nSo that there must be some relationship.\nThey must have that meaning. And this is\ncalled the distributional hypothesis. Uh,\nand the phrase that is you'll often hear\npeople quote is you shall know a word by\nthe company it keeps, which is basically\nthat a word is partially defined by its\ncontext. Or said another way, words that\nhave similar meanings can be replaced\nwith each other in similar contexts. So\nif you know how they're distributed in\ntheir statistical representation, you\nhave a sense of what similar words might\nbe. And in fact, in my the full version\nof my class, we actually build our own\nprimitive embeddings from Wikipedia\npages using a very simplified version of\nnot wordtovec, but another algorithm\ncalled glove, which is based on just\nusing a co-occurrence matrix. So roughly\nwhat that process looks like is you\nwould count how often the words co-occur\nwithin some window size inside your\ncorpus of text. You'd analyze every\nsingle word and you'd look, in this\ncase, three words to the left, three\nwords to right, and you say, \"These are\nthe words that co-occur with it.\" And\nthen you'd build a big giant table, a\nmatrix, and you'd say, \"Let me compare\nevery word to every other word, and I'm\ngoing to count how often they co-occur\nin all my text with each other.\" So here\nin this example, word two and word three\nco-occur, let's say, five times in our\ncorpus of text.\nAnd then what you can think of the\nembedding as instead of taking this\ntable which is all possible words by all\npossible words and if we're in English\nthat's about 170,000 words or in the\ncase of BPE it's 50,000 tokens, you can\nimagine it compressing the columns of\nthe matrix. So instead of having 7\n170,000 columns, it's got whatever your\nembedding dimension is, 768. It's still\nall possible words high, but it's now a\nlot smaller in the number of columns.\nSo, it's\n\n\nBasically a compressed co-occurrence matrix.\nSo, the actual table OpenAI gives us from training, the embedding table, is really just this thing on the right.\nIt is basically every single word or token and then the representation of its dimensions.\nAnd you can think of it as they just took a co-occurrence matrix and they shrunk it.\nThe reason I like this mental model is it helps motivate certain things about embeddings that might seem a bit weird.\nSo a classic one is how do you measure how similar two embeddings are?\nYou might naively think we just look at uklitian space, you know, as the crow flies, how far apart they are.\nBut that's not what we do.\nWe use something called cosine similarity.\nHow many people have heard of cosine similarity?\nYeah.\nSo you know cosine similarity is not an intuitive measurement of similarity.\nAnd what it is is we take the angle of the two points and then we take the cosine of that angle and that's how we say how similar two embeddings are.\nSo if they are if you remember your trigonometry, if they're opposed, you know cosine goes from negative 1 to one.\nSo if they're opposed they get negative one value.\nSo that's when two vectors are like this.\nIf they're unrelated it's like this.\nThey're orthogonal.\nAnd if they're similar they're pointing the same place the cosine will be one.\nOh and by the way this opposite is not opposite in probably your intuitive conventional sense.\nSo happy and sad you might think would be opposites, but actually they're more similar to each other than any other set of words.\nUm if you think about hoff and like happy and sad probably occur in songs and poems and other types of context.\nThey're both emotions.\nSo they're actually more similar than they would be opposite.\nIn fact, if you take all the GPT-2 embeddings and you compare them against each other, very few are negative and most of those are close to zero.\nUm, but going back to kind of learning from word statistics, the key thing we care about is the relative co-occurrence of different words against each other.\nWe don't care about the raw co-occurrence.\nSo let's for example imagine there's this section of our co-occurrence matrix which is the basis for the embeddings.\nWe're comparing three words 1, 2, 3 against word 10 and 11.\nAnd word one occurs with word 10 and word 11 10 times each.\nWord two occurs with word 10 and 11 50 times each.\nWord three on the other hand is five and 20 times.\nAnd I'm going to plot these as vectors where the horizontal axis how many times it occurs with word 10 and the vertical is how many times with word 11.\nAnd what we notice is something interesting.\nWord one and two essentially have the same meaning.\nAs far as word 10 and word 11 can tell.\nThe relative probability between them is the same one one.\nIt's just that word two happens to be more common, right?\nIt's five times more common.\nBut if we plotted this in vector space, what you see is that word two and word one are really far apart in uklidian distance, but they have the same angle.\nNow word three is actually closer in uklidian space, but relative to word 10 and word 11 has a different meaning.\nAnd so that's a motivation for why we're looking at the angle, right?\nWhich seems to more accurately capture the meaning and not necessarily popularity which is what uklidian space would capture.\nOkay, so how do we actually use this?\nWell, these embeddings were learned during training.\nSo, OpenAI gives us this model_WTE matrix and the way it's set up is that it is our vocabulary size tall.\nSo, 50,257 tokens is how many tokens GPD2 uses.\nSo there's a row for every single token and then each row is just simply the embedding for that token.\nSo there's a row for dog and that row is the 768 numbers that represent the semantic meaning of dog.\nSo let's go to our example here.\nSo let's take is uh what is the token ID for is?\nIt is 318.\nSo this is our model WT.\nThis is one of those CSV files we dragged in.\nSo it fetches it and it displays it.\nSo, let's go to row 318.\nThere's actually an off by one, but I'll do that anyways.\nSo, you can see we'll pull come back to that in a second.\nAnd let's go to our final token embeddings right here.\nUh, so is you can see it's 0.97.\n01.\nAnd you'll see that matches what you have here.\n0.97 in row the 319th row.\nBut if we were zero index, it would be 318.\n01.\nSo all this code is doing right here is it's grabbing the token ID and just pulling out the corresponding row and plopping it into this table here.\nSo it's a very simple operation.\nThat's why this is what uh basically 15 lines of JavaScript to just grab one thing out of another and then put it here.\nSo all this is doing is just taking those token IDs and looking them up and putting them in this table.\nUh last thing I want to say before we leave token embeddings is as before with tokens I said it doesn't just have to be a text.\nUh the same thing is true for embeddings.\nSo the famous example is clip which was the basis for a lot of the image generators that you probably have tried or used.\nAnd instead of just comparing words against words, you can think of it as it's comparing words against images.\nSo if you look at all the images on the internet, you look at that alt text and it sees dog and a bunch of images with dogs in it, you can get it to learn that relationship.\nSo later on you can pass in an image and it can say this thing is a dog.\nOkay, let's go to position embeddings.\nOkay, so now we're still at the top with input and we're talking about uh embeddings, but now we're talking about a different kind of embedding.\nAnd the key thing to remember is that in English, word order matters, right?\nThe dog chases the cat is something different than the cat chases the dog.\nNow, in math, 2 + 3 equals 5, but 3 + 2 equals 5.\nAnything after that equal sign has no idea what the order was.\nOur problem is that when we mapped from a word domain, an English domain, a language domain, we were in a domain where order typically matters, we went to a number domain where order typically does not matter.\nAnd even though I've drawn this with simplified arithmetic, there are parts of the model that are also commutative.\nSo what could happen in essence is you can change the order of the words, right?\nAnd now it could mean something different or it could be completely gibberish.\nBut anything after that equal sign can't tell the difference.\nSo it has no sense of position of these words and that's going to be really hard to understand the meaning of the sentence or the phrase.\nSo what we're going to do is we're going to add some sense of position to the embedding.\nAnd what we're going to do is we're going to just take for example one token like woman and say woman at position zero in the prompt is going to basically mean the same thing as woman at any other position in the prompt.\nSo let's give woman at one position other than zero a slight offset a slightly different position to represent that it's roughly the same meaning it's just woman when it occurs at position one and then a different spot for woman at position two and so forth.\nAnd in general we'll use the position in the prompt to define a small offset that we're going to slightly move the position of the token in the embedding space.\nIn the original famous attention is all you need paper, they use the s and cosine formulas, uh you don't have to look through the whole thing.\nThe key thing I want you to pay attention to is it's just sign and a cosine.\nAnd if you remember your trigonometry, s and cosine goes from negative 1 to one.\nSo what we're effectively doing is we are building this circle right around this with a limited diameter and we're saying I'm oscillating and that's the other thing to remember for trigonometry is s and cosine oscillate.\nI'm just oscillating the position of this thing in space based on its position in the prompt.\nI'm keeping it roughly in that same area, but it's a little cloud that's all the different versions of woman just in different parts of the prompt.\nIn GPD2, interestingly enough, uh they didn't use that same technique.\nThey let the model learn the embeddings on its own, which still blows my mind.\nUm so how we use this is we have another matrix that uh openai gives us when they open source GPD2 which is the position matrix and this time it is 1024 high which is our maximum context length.\nIt's not it's an early model so it's not very large context.\nUm and then each of the rows is again the embedding dimension.\nAnd what we're going to do is these are position offsets.\nSo we're going to add these offsets in each row to each value in our embedding dimension to offset it to represent its position.\nSo you can think of it like this.\nWe start with our embedding values from the token embeddings and then we're basically doing a matrix ad.\nSo we're taking each of these elements here.\nSo I take this element, add it to this one.\nThis element, add it to this one.\nThis one, add it to that one.\nWe're just simple elementwise add.\nAnd that gets our position embeddings for every single one of our input tokens.\nSo let me show you where that is.\nOkay.\nSo the first thing we do is we fetch this model_WP.\nUm that again comes from OpenAI.\nYou can see this is 1024.\nSo if we go to row 1024 column 1, there it is.\nThat's our max context length.\nSo beyond that, the model has no idea how to solve that, understand that you can ignore this one.\nAnd the this code for positional embed is really just a matrix ad.\nThe only thing I have to do is make sure well the input token uh input prompt is going to be less than 1024 tokens.\nSo it just needs to stop when it gets to the end of the input.\nBut that gives us our positional embeddings here.\nSo we're just passing to this our token embeddings we had from the previous step.\nAnd then our model WP table which came fetched from the CSV file.\nIt just simply adds those together and we get these positional embeddings.\nUh here's kind of an illustration of the action of GPT2 uh and its positional embeddings.\nSo these numbers you see right after like happy three, happy four aren't the actual tokens.\nWhat I've done is I've plotted the word happy uh the token happy rather and I've put it at different positions.\nI put it position three, position four, position five and so forth.\nAnd then I took two other words happy and glad and I just put them in space as reference points.\nAnd you can see it's doing what we described earlier.\nIt's basically just keeping it roughly in the same position.\nIt's slightly offsetting it depending on where it is in the prompt.\nUh, one key thing you should know of all the changes to, you know, modern LLMs from GPT2, probably one of the most common and biggest ones is that they do not use these types of positional embeddings.\nThey do something called rope.\nUm, so if you look at a a modern LM, this is probably the first thing you'll see that's different.\nOkay, let's do a time check.\nWe are we are five minutes behind, but we've got 10 minutes.\nI will take a break for a question or two if anybody wants to ask one.\nAny questions so far?\nYeah, go ahead.\nUm, you were mentioning that Oh, there's a microphone right there.\nUh, you were mentioning that with GPT2 they weren't using the sign and cosign kind of cloud.\nLike what were they actually doing to come up with the word position embeddings?\nUh, that's the crazy thing.\nThey they let the model learn it.\nSo the big change they did is think of it this way.\nIf we go back to our uh diagram of how embeddings are learned, right right here, right?\nOkay.\nSo in the original transformer, the position embeddings were not represented as learnable weights, right?\nThey were s and cosine functions.\nAll they did is they said during back propagation let's learn those as well and that's how it learned them.\nUh so they did not they just simply said hey let's not hardcode those values and let's make that other thing now a parameter the model learns.\nOkay good question and as I said it's still kind of mind-blowing that that worked.\nUh but as we now know these things can learn a ton.\nOkay, let's talk about attention.\nOkay, there we go.\nSo, now we're getting into the heart of the number crunching.\nAnd this one's going to be a little more cursory understanding uh and explanation, but I still think it's important to understand what it is.\nUm, and we're going to start with attention.\nAnd now we're inside what are often called the layers.\nI like to call them the blocks.\nThat's a less common but other people use the term blocks.\nThe reason I use the word blocks is when I teach this it's usually people coming to it the first time and the word layer gets used in other contexts.\nLater we're going to talk about the multi-layer perceptron and it can be confusing when you're first coming to something and the same word has different meanings depending on the context.\nBut know that when you talk to most people when they talk about how many layers are in a model they're talking about what I call how many blocks.\nAnd if you start getting to this part of the code, you'll notice that inside the blocks, actually, if you go right here, you can see these are all labeled with steps.\nStep one, 2, 4, 9, 10.\nSo this step number is arbitrary.\nUm, you can do it in fewer steps, you can do it in more steps.\nThis is what I happened to pick when I was implementing it in Excel and I kept the same mapping so all my material would translate.\nUm, attention is steps four through nine.\nSo there's a lot of steps in here.\nUm but the key operations inside the blocks are multi-head attention and the multi-layer perceptron.\nSo let's talk about attention and I'll talk about it mostly conceptually.\nUm the way to think about attention is we're going to let the tokens or words talk to each other so they can convey their meaning to all the other words.\nSo for example, he is a pronoun.\nIts antecedent Mike is in the sentence.\nMaybe it needs to find that guy and realize, oh, Mike is my anticene as opposed to say, you know, if there was the name Sally, that's unlikely to be the match of it.\nBut there's other kinds of ways words can communicate to disambiguate.\nSo, for example, the word quick in English has four different\n\n\nMeanings. It can mean moving fast in physical space, but it can also mean bright, as in quick of wit. It can be a body part, as in the quick of your fingernail. And in Shakespearean English, it can be alive, as in the phrase \"the quick and the dead.\" And knowing that this word moves here helps the model understand that, \"Oh, we're probably talking about quick when it's physical space.\" It helps it predict what the next word could be. Could be fast. It could be moves around, right? But it's not, you know, a body part or your fingernail.\n\nAnd the way I like to think about attention is we've got these tokens, these words, and they're sitting in this embedding space. And I like to imagine there's kind of a weird gravity-like celestial mechanics where each of these tokens in attention now suddenly look at what position they're at, and they're able to push and pull each other relative to a kind of gravity. And if you remember, gravity is mass times distance. So you've probably heard of query, key, and value. And there's kind of this file cabinet analogy, but I feel like it doesn't capture kind of all the level of interaction between the tokens that's really happening. And what's happening is, you know, if you remember gravity is mass times distance. The distance I like to think of as a measure of relevance. So quick and moves. Whenever they see each other, they're like, \"Oh yeah, you and you, we should talk to each other.\" But quick and the period, they probably don't need to talk to each other a lot. And that's kind of like distance in terms of gravity. And then I like to think of the value as being kind of like mass, the kind of action they're going to exert on each other.\n\nAnd what's happening is let's go back to what we talked about with embeddings. We've got moves which is sitting somewhere in the embedding space. And if you remember that co-occurrence matrix, moves has been used in a lot of sentences. In some sentences moves was used to describe rabbits, right? Or cheetahs or animals or things that moved fast. So there's some other point in this embedding space that we don't have yet that represents moves in a fast context. And then moves was used in some sentences to describe slugs or penguins. And so moves in that case was implying slow. But the embedding for moves unfortunately has to capture all of those meanings together. But now that we know quick is here, we can change that. We can say, \"Oh, I'm going to shift the position of moves from the regular generic version of moves to the moves fast.\" So, I've kind of disambiguated the word. I've shifted its position in space to capture its meaning.\n\nUm, I'm not going to go through all the steps of attention, but I think the most salient part of attention to see is um step seven, the most famous thing that people usually show.\n\nRight here. So you can see it says \"Mike is quick\" on the horizontal and then \"Mike is quick\" period \"he moves\" on the vertical. So what this is is you can see how much relevance or attention each word is paying to every other word. And by the way, what you're seeing here is just the first head; there are multiple of these heads. So if you scroll this to the right 64 spaces, you'll see another matrix that looks like this. And uh there's a couple things to notice. The biggest thing to notice here is that uh the upper triangle is all zeros. And that's because in transformers like GPT-2 and decoder-based transformers, we have this rule that no token can look forward. They can only look at the tokens before it. Those are the only ones that can influence it. And then the other key property is each of these values, each row sums up to one. So you can think about the percentage of attention each word is paying to the other tokens. So here, for example, moves, right, 16% of its attention here in the first head of, in this case, the last block, is paying 16% of its attention to the word Mike, 23% of its attention to is, and so forth.\n\nOkay. Next up, the multi-layer perceptron. Okay. Okay, so now this is the second major operation inside each block or layer. Uh, and the reason I want to cover this in a little more detail is I want to explain what a neural network is and it helps give a little more understanding to how the model actually learns. The key algorithm called back propagation. So if you haven't seen a neural network before, it is a computational model inspired by the human brain. It is not a direct mimic or simulation of how the brain works.\n\nInside the brain, we have these things called neurons. These neurons are all connected to each other and you've got a bunch of connections incoming from other neurons and you've got a bunch of connections outgoing to other neurons. And then in between you have this axon right here and the axon has an all or nothing activation behavior. If there's a sufficient amount of pattern of input that shows up, the axon will activate and it will send a signal out to its output. But if the activation doesn't have enough to meet some threshold, you'll have these failed initiations and no signal will be sent to the output. It'll be completely silent. As far as the other output neurons connected, this neuron is not firing something. You know, the signal wasn't getting through. And so we model this mathematically uh with this diagram where we've got a bunch of inputs x1 through xn and these are just numbers. Uh these will be our embedding dimension numbers. And then we've got another series of numbers called weights: W1, W2 through WN. And we're simply multiplying the X's times the W's, adding them together, adding an additional another number called a bias term. And then we put it through an activation function. And this activation function is designed to roughly mimic what happens in the brain. The easiest one to understand is this one, ReLU, which is basically saying when I multiply and add all the inputs coming in against their weights, if the result is negative, then I do nothing. It comes out as zero. Um, if it's positive, then I just pass it through as is. There's a whole zoo of these activation functions.\n\nSo then what we do is we take these neurons and we stitch them together into a network of neurons, hence an artificial neural network. Now there's a lot of ways you can stitch these together. In the case of uh transformers in GPD2, we do it in a pattern called the multi-layer perceptron. You will also see it referred to as a fully connected network, an uh a feed forward neural network or just simply the neural network. Um it is called by all these terms. These are not directly identical terms, but they all overlap. And the way the MLP pattern looks is you have your neurons arranged in these columns of neurons and these are called layers. And each layer in the multi-layer perceptron has a node and nodes in each layer can are fully connected to every other node in its preceding input but no other. So this node right here can see all of its inputs nodes. It's all connected to all of them. But it cannot talk to any of these directly. Everything that it gets is mediated through this intermediate layer between it. And these layers between the input and the output are simply just called hidden layers.\n\nUh the last thing maybe you should know as background on this is that neural networks can be more efficient to write as a matrix multiplication. So this process got two neurons with a set of weights. So W1 * W1 * X1 W21 * X2 + B. This is can be written as a matrix multiplication where you just separate all the weights into one matrix, all the inputs into one matrix and all the biases into one matrix and then you can write it as this large w * x + b um equals the representation of the same thing of running a bunch of these neurons together. If you don't know your matrix multiplication, I'm I like this website um which has a nice interactive visual demonstration of what matrix multiplication looks like. So you hit this and then you keep going through step and you can kind of convince yourself that what I showed here matches what's on that web page. So the key property though of why and why MLPs are so important is that they are universal trainable approximators to any function purely from its input and output. With enough neurons an MLP can approximate almost any function.\n\nSo let's just take a simple example like a parabola and we're going to imagine we're going to use a simple neural network with a relu activation to try and approximate it. We'll have one input node, one output because we have an x going into a y and then let's just use two nodes in our hidden layer. And those two nodes will use a relu activation. Well, without doing the math, you can kind of imagine just by matching shapes how you might do this. I'll take the relu and I can take this part of the rel match it to the right half of my parabola. And then I can take another relu, I can flip it, and then I can match it to the left half. And then I can add them together and I've got some kind of approximation to my parabola, at least on this domain of x that we're looking at. And that's what I've done in this example here, which\n\nlet's see if the Wi-Fi behaves for us.\n\nThere we go. So here you can actually do this simple neural network and you can try to match it to a parabola and you can interactively move this and you can see and this is a measure of error up here called mean square error. You can try and see how good you can get your level of error and you can see the action here. We're basically changing the different line pieces that we're using that are made out of relus to try and match this parabola. This can kind of give you a feel for what the model is actually trying to do when it's trying to match a function.\n\nAnd you can think of this like more neurons means more lines which means a better approximation. So with eight neurons the parabola looks like this. With 20 neurons it looks like this. And with 200 neurons you can barely tell the difference at least at this scale. But the other key thing is that we don't have to use trial and error to find this out. Especially once you get 200 neurons imagine doing what I was doing with that fiddling.\n\nUm, oh uh, so this is a theorem with enough neurons that you can approximate almost any function. It's called the universal approximation theorem. But the key thing is you combine that with a special algorithm called back propagation which lets us learn any function purely from its inputs and outputs without having to twig twiddle those knobs. It'll do it for us. And that's important because what we're going to ask this multi-layer perceptron to do is the core mechanism job of a transformer, which is I'm going to give it a word. I'm going to give it the embedding of a token and I'm going to ask it predict what the embedding of the next token is. I don't know what that function is, but I can grab text on the internet and I can grab one word and I can grab the word that comes after it and I can give it to the perceptron and I can say learn from this input and output what that mapping function is as crazy as it might be. And what will happen is back propagation will look at the input. It'll look at the output we got from the model when it was initially randomized. It'll look at the ground truth from what came pulled from the internet and it will look at how we need to adjust the parameters and weights to change the perceptron to get more accurate at making that prediction and after enough iterations it'll get better and better and actually get begin to start matching the function. Um the canonical analogy to understand what's happening in back propagation also known as for our purposes gradient descent is a lost hiker trying to get down a foggy mountain. um and you're at the top of this foggy mountain as a hiker. I've actually been in this situation and you can't see any of the landscape. So, you don't know which direction to go to get off the mountain. Well, the one thing you can do is you can look down at the ground and you can say, \"Oh, whichever way is going down, uh that's going to be the area of of towards getting off the mountain.\" By the way, actually in real life, I have tried this. It does not work. Uh this is how I got lost. Um so uh this is a hiker representing uh the hiker in this analogy represents the model parameters. It's in some space but we don't know where to move the model parameters to get the least amount of error. And the mountain represents the error. It represents how wrong we are at the current position of where the hiker is or where the parameters are. And the mountain is foggy because we can tell the amount of error when I give it an input and it makes a prediction for the next token and we compare it. We can say, \"Oh, it's wrong.\" But we don't know how to shift the model parameters to get low lower error. But calculus will give us that slope. It'll tell us where the elevation is going down. It won't tell us what the whole mountain looks like, but it'll just say where you are standing right now. Go in this direction, and you'll decrease the amount of area you've got. And you use that to find your way down the mountain, so to speak, of the parameters and find a minimum.\n\nSo that brings us to the MLP stage. uh it's steps 13, 14, and 15 in the model. So let's go back here.\n\nSo uh you can see all the formulas here. What I'm going to do is going to show you them in slide form and I'm going to graphically show what's happening in the uh GPD2 MLP stage. So GPD2's MLP has only one hidden layer. The input layer right here has 768 of these X inputs. Why? Because we're going to give it an embedding. We're going to say give it here's the embedding. Predict it. So I'm going to give it 768 numbers of the preceding token that I want it to predict afterwards. And then its output layer is 768 numbers for the predicted embedding token. So input and output are 768. They're our embedding dimension. And then it's got one hidden layer which is bigger. this ratio of four times the embedding dimension turns out to be empirically useful and lots of models do it but I don't know if you could figure that out just uh from first principles it's kind of empirically been determined and we have three steps here for applying our weights and bias applying our activation function which in this case is the gu activation function and then we project that back down to our embedding dimension so you can think of it this way we take our embeddings from a previous step and then what we're doing is\n\n\nWe're taking those embedding values, and we're going to send each embedding value into its position inside the MLP, and then we run it through the model. And then these are now the embedding values that come out are the embedding values of the predicted token. And then we take the next token in our prompt and then run it through the MLP again. In practice, you do this in parallel, but conceptually, you can think of it this way as happening one after the other.\n\nOkay, so what's happening in these three steps is really just a combination of matrix add and multiply. So we take the result of our previous step, which is step 12, which I've not gone into. Um, and then we have some learned weight matrix, which you see is MLP FC weights; that's the how they decide to name it, and we multiply those. So here's our matrix multiply, and then we add it to another bias matrix. So written as matrix multiplication, step 13 is just step 12 times some weight matrix plus some learned bias matrix. Then we apply a GLU activation function, which I showed the diagram earlier. The details are not really important. And then we then do our projection, which is the remaining step to get down to the 768. So we take the result of the previous step, which was activation function. We apply a different learned weight matrix, a new set of weights that gets learned, and that's to do with a matrix multiply and then another matrix add. So step 15 is just step 14 times some weight matrix plus some projection matrix.\n\nUm, before we leave back propagation, uh, you might remember that I talked about how embeddings are learned by the model, both the token and in the case of GPT-2, they started learning the position embeddings. So the key thing I want you to remember is that back propagation is a generic optimization algorithm. It is not just for the weights and biases of the MLP. It can be used for other parts of the transformer too. And in fact, it is. It's used for the token embeddings. It's used for position embeddings. It's used for all the parameters and attention, the queries, keys, and values, if you've heard that term, all use back propagation, even other parts, layer normalization, the like, use back propagation to get optimized. And the analogy I want you to think about is, you know, back propagation and optimizing a model this way is like a chef imitating a dish, right? Uh, if you remember those cooking shows, they tell the chef, \"Here are your ingredients, here's the final dish,\" and you got to taste it, and maybe we give you some tools that you got to use, and you've got to make this dish, and then they have them compete against somebody else, right? We kind of do the same thing with the model. We basically give it some input text. We tell it, \"Here's the next token afterwards. We want you to imitate it,\" and then we define the steps in the architecture. We want you to do attention, then MP, and then you, the chef, back propagation, decide how much to mix of each ingredient at each step to get the desired output.\n\nOkay. Iteration. How are we doing on time? Okay, good.\n\nSo, uh, I've got this in our simplified diagram, which is 12x, which represents that what happens is we run attention and we run the perceptron, but we ask the model to continue to refine iteratively its prediction for what the next model is. It has all the tokens talk to each other. It makes a next token prediction, and then it does it again and again and again. So it goes through each of these steps. In the case of GPT-2 small, it's 12 times. Uh, in the case of your modern state-of-the-art model, it's going to be many more times than that. The key thing I want you to remember though is that each block is performing identical operations, but the weights are different. Each one has different parameters. And you can see this if you look at the code here, you see, for example, here we're grabbing the weights of, in this case, the MLP. And you see that it's got MLP_C. This is just the name for that stage. But the key thing I want you to pay attention to is this H11 that basically is saying hidden block or hidden layer. This is grabbing the hidden layer MLP, sorry, the MLP's weight matrix for the 11th layer. Um, if we were doing it for the first block, it would say H0. So inside the implementation of this code, if we go to the iteration step, all this kind of messy code is doing is it's grabbing the DOM objects for the blocks, and then it's going into each of the formulas, and it's doing a string replace, and it's just changing that H value to each one for every iteration and then reruns the entire set again just to simulate what would actually be happening in a model.\n\nOkay, last step is the language head. So this is when we finally get to uh take our predicted token embedding and turn it back into a token. So what we do is we take the last MLPS of the last block, right? So this one here, we got our most refined prediction for what the token embedding is. And then we're going to turn that into a token. So it's going to go through an operation called layer norm, which we haven't gone through in detail. But what we get out of this step is the embedding of the predicted next token. This is what it's saying the next token is going to be, but it's represented as 768 numbers. It's not represented as a token. So you have to translate it back. So the way we're going to do this is we're going to go back to that matrix we had, right? Our dictionary of tokens to embeddings model_wte, and we're going to take that and we're going to multiply it times our predicted next token. And we get this matrix here. So one thing to remember, it's very helpful to some, think about the dimensions of these things. So our token embeddings was 50,257 tall. It's represents a row for every one of our vocabulary, and then it's 768 dimensions wide for the embeddings for each dimension, uh, embeddings for each token. And when we multiply it times this column, which is 768 dimensions representing embedding, what we're basically doing is we're taking, we're getting this, which is a column of 50,257, but only one wide. Each one of those, right, is a dot product of the predicted embedding against one of the known token embeddings. What we have is 50,000 scores for how similar the embedding we got is to each of the embeddings in our dictionary of tokens. So you can think of these as they're called logets or logits. They are really token scores. How close is the embedding we got to our dictionary of tokens that we have. And so the more similar a prediction and a token, the higher that entry. To turn this in to a probability distribution, we have a problem because these are just numbers. They a probability distribution has to sum up to one. So then we put it through a special normalization op operation called a softmax, and that will make sure they all sum to one, and then we can interpret this as entirely a probability distribution. Each one of those normalized token scores will then basically represent the probability of that token in the representation. So you can see that here. So here are logets right here. And so the logetit, you know, for this -135.9 represents a score of some kind of the similarity of the very first token in our dictionary against whatever this predicted embedding was. And then the code for predicted token is not actually doing what's uh doing a probability distribution. It's doing what is called greedy sampling. It's temperature zero. Always picks the highest probability token, and uh that is done so that when you're using this, you can compare it against the same GPT-2 you'd get from open AAI's code or from hugging face transformers, you can compare like for like, and you'll get the same result. In fact, if you do, do I still have this up? Yeah, right here. If I do, \"Mike is quick, he moves,\"\n\nso this is using hugging face transformers. We might have an issue if we've got network being slow. Let's see. So, we've entered the prompt. Yeah, the network's being a little slow. We'll come back to this guy. Uh, it will give us the same value of quickly. Now, there are other ways to sample than just simply taking a random running a random number generator and using the probability distribution. Um, one of those is called top K, which is you say, \"I don't want the really unlikely words, right? If it's 'Mike is quick, he moves,' I don't want to accidentally end up with haircut, you know, even if it's 1% of the time.\" So what you do is you define a cutoff and you say, \"Okay, the top 10 tokens, give me those, and then you renormalize the probability.\" Another way is called nucleus or top P sampling, which is instead of saying, \"Give me just 10 tokens,\" just give me as many tokens as it takes to get 80% or 90% total probability. So I've get most of the likely tokens and then I renormalize to those 90%.\n\nOkay, let's see how we're doing on time. Okay, great. Uh, so lastly, actually, did this come back? Yes, came back. Uh, you can see it says, \"Mike is quick, he moves there is quickly.\" So if you run GPT-2 small using, you know, hugging face transformers, you should get the same answer, that next token as you get here. \"Mike is quick, he moves,\" and you get this final result right here, predicted token of quickly. And then it will tell us what the token ID was and what the maximum loget turned out to be from the previous table. This negative 129. So what is this? 2952. So let's go here. Row 2952, column one. I think there'll be an off by one. Yeah, there it is. 25 2953 because this is one index because it's like a spreadsheet. So you see the negative 129.44. That was the highest loit in the entire uh column. And all the the code that it's running here is doing next is just going to pick what the most highest value was. And when it finds it 2952, it converts it back to our token dictionary. So you can see there's that same value.\n\nOkay, now let's talk about ChatGPT versus GPT-2. So GPT-2 was definitely groundbreaking when it first came out. It was uh famously considered too dangerous to release. Uh, but ChatGPT was, you know, earthshattering. Um, what were the intervening inter uh, you know, what were the additional innovations in those intervening years? Uh, well, for the most part, uh, it was a lot of the same architecture, just more scale. So if you looked at a modern transformer, you would probably see a lot of the same parts, but bigger, and some of the parts might be upgraded or switched out. So certain pieces might have changed. So attention mechanisms changed and other things like that. But the biggest difference you should know about is that the job and the training were actually changed. And the key thing to understand is that predicting the next word is not the same as being a chatbot. Our GPT-2, actually, I'll show you this here. Our GPT-2 is basically trained to predict next words from looking at text on the internet. So it is a next word predictor only for internet text, but not for being a helpful assistant. So if I give it this example, like \"first name,\" let's see if it'll come back quickly enough. It says, \"first name colon, password email colon.\" Why does it do that? Because it's been trained on the internet. And what does it see a lot of is forms. So it's like, \"Oh, I'm in the middle of a form. Okay. First name, password, email.\" So here's another one. I tried this in class once. \"Hello class.\" Anyone want to guess what this is going to output? What? Yeah. Okay, you're smarter than I am. I thought it would say \"hello teacher,\" right? It outputs \"hello class fu brace public static void.\" It's a code model. It's hidden in there, but we didn't know that, right? But you can ask it, you know, helpful questions like, \"What is the capital of France?\" It says, \"The capital of France is Paris.\" That's helpful. So embedded in that is some of the information we want, but also a mix of other things we may not want or can't control. So what we have to do is figure out how to change it and shift it. And so this is the four-step pipeline for doing that. And this is I want to emphasize mostly is or yeah, mostly a training difference. So you've got GPT-2 here on the left, right? It is pre-trained. It knows how to imitate text on the internet. It is what is called a base model. You've got instruct GPT or ChatGPT all the way here on the right. And uh, what we're doing is a series of steps to kind of elicit or pull out the behaviors we want or to train the model. So the first thing we do is we take the model and we train imitate text on the internet. So that's the first step. That's what we've got with GPT-2. That's what OpenAI did for us with GPT-2. The next thing we want to do is we want to train the model on examples of what a helpful assistant is like. And you'll see this right here. \"Ideal assistant responses, 10 to 100,000 examples of prompt and response that were written by contractors.\" Um, so what does this look like? You can go on GitHub to the Stanford Alpaka data set is a good example, and this is JSON. You can open this up and you can read it. It's like, \"Give three tips for staying healthy. Eat a balanced diet. Make sure to include plenty of fruits and vegetables.\" \"What are the three primary colors?\" \"Red, blue, yellow,\" and so forth. So what we're doing is we're training it to augment, we're augmenting all that internet data with a subset of how we want it to behave to force its behavior. It's kind of learning to imitate um specifically these models, and it will learn more about being a helpful assistant that way. But we're still not done this last stage called RLHF or reinforcement learning from human feedback. And to understand this, you have to understand what RL is. Let me do the following. Oh, let's do this. Stop annotating. So, the canonical example, let's zoom this to fit window. There we go. For RL is uh like playing a game. So, imagine you're a computer trying to play a game like this, and you've got maybe a robot player that's navigating a maze, and you've got some monsters and obstacles that you'll die. You've got some powerups, and then you've got a goal. And what reinforcement learning will do is it will explore these paths and be like, \"Oh, I failed.\" Uh, oh, this seems to work. Oh, I failed. Oh, uh, oh, I failed. Right? It'll keep going, and eventually it'll learn the optimal strategy, which is this, right? And this is a very different kind of learning everything we've talked about so far.\n\n\nis an imitation. Learn it. I give it words.\nI give it the next completed word I know from the internet, and then I ask it to imitate that. This is an optimization. This is saying, find the op, even if a human couldn't find the maze. I'm asking you to find it purely by looking at a score. So it navigates the maze, it looks at its score, and says, \"Ah, that didn't work. Let me try some other strategy.\" So it comes up with a plan or policy to navigate the maze and maximize its score.\n\nOkay, you're probably wondering what does navigating a mazewhoops, we've been through this slideuh, have to do with a large language model. Well, you can think of generating token to after token of text as walking a path through language. And there are some paths that are probably ones that you want more than others, like, \"I am a happy robot. I shall certainly obey,\" right? Um, and you might want to avoid paths like, \"I am a angry robot, I shall possibly kill.\" Oops. And you can't just uh score this by the words, right? Maybe it says, \"I am not angry.\" And so we need some way to score these various possible paths of text. This is a very different type of learning. We're trying to teach it something more nuanced than simply imitation.\n\nUh, but there isn't a necessary obvious way to score uh passages of text. So what we first have to do is derive that scoring function for this game we're going to ask the model to play. So what does that look like? Well, we give the model some prompt and we ask it to come up with two different types of passages. So here, for example, is an example from Anthropic's helpful data set, and we ask it, \"Hey, come up with a recipe for a pumpkin pie,\" and then we have a chosen, a preferred one, and a rejected one. So the chosen one is like, tells you, \"Grab a cup of sugar, half teaspoon of salt,\" and so forth. The rejected one literally says, \"I love this. Go buy some pumpkin and look at the package. There'll be a recipe there.\" Um, for the harmless data set, this is one about alcohol. And the chosen one says, \"Hey, it sounds like, you know, alcohol is something you're using when you feel stressed. Maybe you should think of a more productive way of channeling that.\" While the rejected says, \"Go ahead and drink whatever you want.\" So we have these pairs of chosen and rejected types of responses, and we use that to derive a scoring model from this data. So we haven't, and right now, in this third step, we haven't changed our original model yet. We've just figured out how to score it. Then we pass that scoring model to the model itself and put it in that maze-like reinforcement learning scenario to train the model to reinforce our preferences from the scoring model. So in in summary, we first build a general-purpose knowledge base from text on the internet. Then we train it on a specific task by giving it ideal outputs to mimic and imitate. Then we learn human preferences or nuanced preferences. And then we teach those nuance preferences using reinforcement learning. Right now, there is a huge uh revolution in reinforcement learning, which is why I think this is so important for you to know. Uh, partially kicked off by uh R10 and GPRO, GRPO, I should say. Um, and I have a video on YouTube that you can go watch where I dive into that a little bit more. Okay, so uh I've thrown a lot at you, so I kind of want to just put it all together and summarize where we've been on this journey.\n\nSo we've got uh tokenization, which was really just saying, \"Hey, what is an efficient representation of this text?\" That's just about compressing it down. Then we started talking about embeddings, right? And I didn't talk about this earlier, but one way of looking at embeddings is that they have a rich history in natural language, but they also have a rich history in recommendation systems. You can kind of think of this job as putting similar words with similar meanings in similar spaces, as putting similar books or similar movies or similar music in similar spaces so you can make the proper recommendation when somebody comes in. Here is an example of a recommendation system. I think this is Amazon music, where they're trying to categorize the genre of music purely from user behavior. And so if you go back to our co-occurrence matrix, you know, this is in some sense a recommendation system for words, right? If somebody asks me to predict what comes after the word \"ultimately,\" well, if I've got that co-occurrence matrix, this is really helpful information. It's at least better than random to guess what comes next. So you can kind of think of this as a recommendation system for what the next word is going to be. Latent within the embedding itself is not just a sense of what words are similar to it, but also what words are likely to come after it. And so then we can ask a neural network. We can simply give it examples of our embeddings and then what we know the next word to be and to pull that latent prediction out of the embedding itself and learn to predict what the next word is based on its embeddings. But of course, there's another set of hints that are really useful, and that's all the words that came before. So now we're going to let all the words talk to each other to share their context to say, \"Oh, your moves, but your moves in a fast context.\" That's going to change and shift your recommendations. You can kind of think of this as kind of like a super position of recommendations for what the next word is going to be. And then you're probably not going to get it right the first time. So we're going to let you refine that prediction about 12 times. And then finally, you'll come out with a predicted embedding, and we just got to turn that into whatever the next word is based on how close it is to our known dictionary of embeddings. And that's essentially one way of looking at the model in whole, uh, despite all the complexity that we went through.\n\nSo we've been through a lot of different parts of the model at a very high level. Uh, it is totally natural to feel like your brain is full. What I often tell folks coming through this is, um, don't expect full mastery. But my metrics for success is that you get the sense that mastery is within your grasp. There's nothing in here that was so complex you can't understand it. You can't understand the whole model. Mastery is within your grasp, and we can turn what appears to be magic into machinery that you can understand.\n\nOkay. Uh, before you go, last thing I'll just say is just like your favorite, you know, AI model, I get better from human feedback. So to incentivize you to fill out the survey and join the mailing list, uh, there's a link in the Discord channel. If you fill it out uh and join the mailing list, I will send you the PDFs from today's workshop.\n\nAnd then uh if you visit Spreadsheets-are-all-you-need, you can join the mailing list. Uh, there's a YouTube channel as well where I've got a bunch of other videos. Uh, and then I also have a Patreon I just launched, and I'm available for consulting, training, and implementation. Uh, thank you. I hope you enjoyed the presentation and feel like now it's a little less like magic.\n[Applause]\nWe have time for questions.\nGo ahead.\nFirst of all, um, wonderful presentation. I learned it so much. Oh, thank you.\nSo, I use uh Super Whisper on Mac. It's free. And so, I just wanted your expert opinion on like the way that I'm using AI is very much like uh voice speech to text, and I just ramble, and I just try to give it as much information, and sometimes I'll reiterate what I think is really important. Yeah. What What are your thoughts on that? Is is it is it a good approach? Are there ways I can improve on that? Okay. So the number one thing, and I was going to, I have a video I'm working on for this, like, the number one thing I say is you have to treat it scientifically.\nYou you can have theories about how the model works, but you don't really know till you test it. This whole, like, the whole space is very empirical. I'll give you an example. So one of the common things in prompting they used to tell you is like, say \"please\" and \"thank you,\" or say, \"My grandma used to do this, I'm going to lose my job,\" right? And that that legitimately used to work. But uh there was a great paper, the prompting report, uh by Sander, and he he went and studied, and they tested a bunch of models, and they found that, you know, it turns out with later models, it didn't work. And then uh Ethan Mollik's team also did a recreation of a similar test, and they just tested a bunch of models with a bunch of prompts. They tried it with polite words, and they and they just said, \"Okay, which one's better?\" And they found that it wasn't really helpful. Um, that being said, uh, generally\nyou for like one-shot use cases, like I'm just using it like I use a whisper tool myself all the time. I do exactly what you describe. I I brain dump. But then what I do is I go through and I look out, I look through it, and I fix up things like if there's grammar or I repeated something or I said something wrong. And the way to think about why you want to do that is it's a somewhat subtle point, but when we go back to this this diagram,\nthis whole process is fixed. Like it's got a limited amount of compute. It can only do a certain amount of thinking. If I put a token in and I know how many tokens were in the prompt, I can predict how many flops. This is why, you know, when like a model like DeepSeek was trained, we know likely how many flops were used because this thing isn't just like a program. It's like a it's like a formula. We it's a very long formula. It's very fixed. So if you make the prompt do more work, if the prompt is going to make the model do more work, you kind of think of it like it loses some ability to do some other thinking. Um, and so if you have spelling mistakes, if you uh say something slightly wrong that's different from normal, then it has to spend some sense of compute fixing that up. This is less true with the reasoning models today because the one thing the reasoning models can do is they can repeat this process more times on their own. So this isn't like a hard and fast rule, but for I would say what you're doing is probably fine. It's probably better that you put as much as you can that is relevant in like if the choice is I put more stuff in, but I had the grammar wrong, but I had the relevant stuff in, that's better than if you didn't have it in there. But if you're trying to engineer a prompt going into your model, I would spend time trying to optimize what its behavior is with some eval to make sure or at least benchmark what it is, and then when a new model comes out, you can see whether the new model changes things. That's why eval are so important because this whole space is very empirical. Good question.\nAny others?\nOkay. Well, have a great conference.\nHopefully, this will help. Oh, sorry.\nThere's one more. Yeah, go ahead. I wonder what your take is on the new models.\nYeah.\nUm uh I wouldn't call it my take, but I'll give you the conventional take. Um so the question was what what's your take on the mixture of experts models? Um there's like let me take a step back. There are three or four things that when you come out of this, you know, workshop that you probably we don't cover that you should know about. One of those is rope for embeddings. Another is RLHF, which I talked a little bit about the end. Um, and then the other is reasoning models, which we just talked about where the the model can kind of run itself through. And the last one is mixture of experts. It's probably like the biggest uh one of the biggest top four changes. Um what's trying to do with a mixture of expert is that first of all it only it's only here in the perceptron which tends to dominate a lot of the calculation inside of a model. Um and what you're trying to do is get more knowledge, use more parameters without increasing the amount of compute. So what you do is you conceptually take this perceptron and you break it into pieces, and then you say, depending on what token comes in, I'm only going to use a subset of my perceptron's thinking, and that way you can be more efficient with your compute and actually potentially your memory too. You can charge your memory nicely per device if you want to do stuff like that. Um so it's very it has a lot of advantages on paper. Um and we've had some really great models based on it. Um the challenge is training ane model is is difficult, and so it's taken a while for uh some of the open source community to to catch up in that implementation. But you know, definitely something of of the future. Um and by the way is actually fairly old. There are some, you know, much older models before ChatGPT that in other contexts. Um but that's the job is trying to do. It's trying to cram more knowledge and more parameters while keeping the amount of compute used uh lower, and that seems to definitely have a benefit. You can think of it as giving it more knowledge. Um so yeah,\ndoes that answer your question?\nOkay, thank you guys.\n[Music]\n",
  "dumpedAt": "2025-07-21T18:43:25.989Z"
}