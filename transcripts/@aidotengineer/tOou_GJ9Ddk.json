{
  "episodeId": "tOou_GJ9Ddk",
  "channelSlug": "@aidotengineer",
  "title": "Are MCPs Overhyped? A Rant about MCPs — Henry Mao, Smithery",
  "publishedAt": "2025-06-03T22:23:31.000Z",
  "rawLines": [
    {
      "lang": "en",
      "text": "Hi, I'm Henry. Because MCP is such a new",
      "offset": 2.639,
      "duration": 5.361
    },
    {
      "lang": "en",
      "text": "space, uh instead of going into",
      "offset": 5.92,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "technical details like most AI engineer",
      "offset": 8,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "videos that you're probably seeing, uh",
      "offset": 10.08,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "today I'll be doing a highle overview",
      "offset": 12.24,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "and a rant about all the problems within",
      "offset": 14.48,
      "duration": 4.639
    },
    {
      "lang": "en",
      "text": "the MCP space and ecosystem. A quick",
      "offset": 16.64,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "introduction about myself. Um so I'm",
      "offset": 19.119,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "Henry. I'm the founder and CEO of",
      "offset": 21.6,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "Smithery. Uh I'm also a member of the",
      "offset": 23.199,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "MCP sir committee. Before Smidy, um I",
      "offset": 25.439,
      "duration": 6.08
    },
    {
      "lang": "en",
      "text": "co-founder Jenny AI. Um let me tell you",
      "offset": 29.199,
      "duration": 3.801
    },
    {
      "lang": "en",
      "text": "a little bit about the origin story for",
      "offset": 31.519,
      "duration": 5.361
    },
    {
      "lang": "en",
      "text": "Smidy. Um this is around November last",
      "offset": 33,
      "duration": 6.68
    },
    {
      "lang": "en",
      "text": "year 2024. Uh I went down this rabbit",
      "offset": 36.88,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "hole trying to figure out uh trying to",
      "offset": 39.68,
      "duration": 4.879
    },
    {
      "lang": "en",
      "text": "tackle the ARC AGI challenge. And if you",
      "offset": 41.92,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "haven't heard of the ARC AGI challenge,",
      "offset": 44.559,
      "duration": 5.281
    },
    {
      "lang": "en",
      "text": "it's an IQ test made for LLMs. And in",
      "offset": 46.239,
      "duration": 5.921
    },
    {
      "lang": "en",
      "text": "this challenge, um you're given two or",
      "offset": 49.84,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "three different examples of a pattern.",
      "offset": 52.16,
      "duration": 4.559
    },
    {
      "lang": "en",
      "text": "And you want your LM to predict the",
      "offset": 54.64,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "missing last pattern here. And turns out",
      "offset": 56.719,
      "duration": 4.801
    },
    {
      "lang": "en",
      "text": "that this challenge is very easy for",
      "offset": 59.6,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "humans to do. Humans get about uh 80%",
      "offset": 61.52,
      "duration": 5.279
    },
    {
      "lang": "en",
      "text": "accuracy on this challenge, but it's",
      "offset": 64.32,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "pretty hard for LM to do. And LMS could",
      "offset": 66.799,
      "duration": 5.761
    },
    {
      "lang": "en",
      "text": "not crack it for many many years. So I I",
      "offset": 69.76,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "kind of focused on tackling the",
      "offset": 72.56,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "challenge. Uh but very quickly, uh",
      "offset": 73.68,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "OpenAI decided to release 03. and Ozu",
      "offset": 75.92,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "completely dominated the ARC AGI1",
      "offset": 78.88,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "challenge and basically got human level",
      "offset": 81.28,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "performance. It scored very well on math",
      "offset": 83.68,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "benchmarks as well. So, we're basically",
      "offset": 85.84,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "done, right? AGI achieved. Um,",
      "offset": 88,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "autonomous agents are going to be",
      "offset": 90.56,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "solving all our problems now. But fast",
      "offset": 92.24,
      "duration": 3.96
    },
    {
      "lang": "en",
      "text": "forward to",
      "offset": 94.96,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "2025 and I'm wondering where are all the",
      "offset": 96.2,
      "duration": 4.84
    },
    {
      "lang": "en",
      "text": "autonomous agents? Why are they not",
      "offset": 99.36,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "solving all the tasks that we don't want",
      "offset": 101.04,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "to be doing? So, what we're seeing here",
      "offset": 103.04,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "is sort of Claude's paradox. uh we have",
      "offset": 105.04,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "all these frontier labs creating uh all",
      "offset": 107.6,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "this intelligence but all this",
      "offset": 110.32,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "intelligence is stuck in a box and in",
      "offset": 112.64,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "order to make AI agents practically",
      "offset": 115.04,
      "duration": 4.719
    },
    {
      "lang": "en",
      "text": "useful we have to start thinking about",
      "offset": 116.96,
      "duration": 4.479
    },
    {
      "lang": "en",
      "text": "context and capability what are the",
      "offset": 119.759,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "inputs and outputs uh to our models",
      "offset": 121.439,
      "duration": 5.121
    },
    {
      "lang": "en",
      "text": "everyone from startups to major labs",
      "offset": 124.719,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "recognize this problem and so in",
      "offset": 126.56,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "November 2024 anthropic released the",
      "offset": 128.479,
      "duration": 5.041
    },
    {
      "lang": "en",
      "text": "model context protocol uh it's an open",
      "offset": 131.2,
      "duration": 3.759
    },
    {
      "lang": "en",
      "text": "standard to help LMS connect to",
      "offset": 133.52,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "different services uh with a promise of",
      "offset": 134.959,
      "duration": 4.241
    },
    {
      "lang": "en",
      "text": "standardizing uh this end times end",
      "offset": 137.12,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "problem. So when I saw MCPS uh in around",
      "offset": 139.2,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "this time last year, I was pretty",
      "offset": 142,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "excited about it. Um there was a small",
      "offset": 143.36,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "but vibrant developer community. So",
      "offset": 145.12,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "models are getting smarter and MCPs are",
      "offset": 147.2,
      "duration": 4.36
    },
    {
      "lang": "en",
      "text": "standardizing the way models talk to",
      "offset": 149.52,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "services. So are we finally done? Well,",
      "offset": 151.56,
      "duration": 6.759
    },
    {
      "lang": "en",
      "text": "not quite. With MCP and a new ecosystem",
      "offset": 154.72,
      "duration": 7.12
    },
    {
      "lang": "en",
      "text": "of services trying to target AI agents,",
      "offset": 158.319,
      "duration": 5.521
    },
    {
      "lang": "en",
      "text": "we have a bunch of new problems showing",
      "offset": 161.84,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "up. So first I want to go through the",
      "offset": 163.84,
      "duration": 5.039
    },
    {
      "lang": "en",
      "text": "list of user problems that we have. So",
      "offset": 166.08,
      "duration": 4.879
    },
    {
      "lang": "en",
      "text": "the first one is fragmentation. There",
      "offset": 168.879,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "are more and more MCP servers being",
      "offset": 170.959,
      "duration": 3.041
    },
    {
      "lang": "en",
      "text": "deployed every single day and it's",
      "offset": 172.319,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "becoming hard to find high quality ones.",
      "offset": 174,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "The MCP committee is currently working",
      "offset": 176.239,
      "duration": 3.041
    },
    {
      "lang": "en",
      "text": "on a better solution for this by",
      "offset": 177.68,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "creating an official registry thanks to",
      "offset": 179.28,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "test and the pulse MCP team. Simply",
      "offset": 181.92,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "having a registry doesn't solve the",
      "offset": 184.8,
      "duration": 2.719
    },
    {
      "lang": "en",
      "text": "problem. For example, how do we assign",
      "offset": 186.08,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "reputation to highquality MCPS is still",
      "offset": 187.519,
      "duration": 4.561
    },
    {
      "lang": "en",
      "text": "an open question.",
      "offset": 190.239,
      "duration": 4.241
    },
    {
      "lang": "en",
      "text": "Another problem that MCP users face is",
      "offset": 192.08,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "high friction install. If you go to any",
      "offset": 194.48,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "MCP's GitHub repository, you you'll",
      "offset": 196.48,
      "duration": 3.759
    },
    {
      "lang": "en",
      "text": "probably see this five-step installation",
      "offset": 198.56,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "process, which makes it very difficult",
      "offset": 200.239,
      "duration": 3.761
    },
    {
      "lang": "en",
      "text": "to install. And in addition to that,",
      "offset": 201.76,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "once you have your MCP installed, you",
      "offset": 204,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "might just have installed an insecure",
      "offset": 205.92,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "unsecure MCP. Finally, it's unclear how",
      "offset": 207.76,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "we're going to create this new economy",
      "offset": 210.319,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "of AI native services. We don't have a",
      "offset": 211.92,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "plan on how to handle agentic payments.",
      "offset": 214.4,
      "duration": 4.559
    },
    {
      "lang": "en",
      "text": "Open questions in this area include, how",
      "offset": 217.12,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "do I get agents to pay on my behalf? And",
      "offset": 218.959,
      "duration": 4.881
    },
    {
      "lang": "en",
      "text": "how do I avoid subscribing to 100",
      "offset": 222.08,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "different services uh each charging $10",
      "offset": 223.84,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "a month? Next, let's look at the",
      "offset": 226,
      "duration": 4.239
    },
    {
      "lang": "en",
      "text": "developer side problems. So, if you're",
      "offset": 228.239,
      "duration": 5.121
    },
    {
      "lang": "en",
      "text": "building an MCP, you probably face",
      "offset": 230.239,
      "duration": 4.961
    },
    {
      "lang": "en",
      "text": "hosting problems. Thanks to the Streambo",
      "offset": 233.36,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "HTTP transport is now much easier for",
      "offset": 235.2,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "developers to find platforms to host on.",
      "offset": 237.439,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "But hosting is still a challenge. Uh",
      "offset": 239.68,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "developers will have to deal with staple",
      "offset": 241.599,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "sessions, resumability, and other",
      "offset": 243.04,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "issues.",
      "offset": 245.2,
      "duration": 3.599
    },
    {
      "lang": "en",
      "text": "The developer tooling is also uh quite",
      "offset": 246.64,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "lacking in the MCP space. We have a",
      "offset": 248.799,
      "duration": 5.201
    },
    {
      "lang": "en",
      "text": "basic MCP inspector provided by the",
      "offset": 250.959,
      "duration": 5.361
    },
    {
      "lang": "en",
      "text": "official MCP repository which allows you",
      "offset": 254,
      "duration": 4.239
    },
    {
      "lang": "en",
      "text": "to test out different tools uh check out",
      "offset": 256.32,
      "duration": 3.439
    },
    {
      "lang": "en",
      "text": "your prompts but there are still open",
      "offset": 258.239,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "questions that developers are asking us.",
      "offset": 259.759,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "For example, how do I design the best",
      "offset": 261.519,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "MCPS? How do I know if my tool is going",
      "offset": 263.68,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "to be called? How do I create the best",
      "offset": 265.68,
      "duration": 3.48
    },
    {
      "lang": "en",
      "text": "agent",
      "offset": 267.84,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "experience? Next, we also have",
      "offset": 269.16,
      "duration": 3.24
    },
    {
      "lang": "en",
      "text": "distribution as a problem. If you're a",
      "offset": 270.88,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "developer, you create an MCP. How does",
      "offset": 272.4,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "your MCP get discovered? Observability",
      "offset": 274.32,
      "duration": 4.879
    },
    {
      "lang": "en",
      "text": "is also an issue. If you deploy your MCP",
      "offset": 276.479,
      "duration": 4.241
    },
    {
      "lang": "en",
      "text": "and people are using it, how do you",
      "offset": 279.199,
      "duration": 3.801
    },
    {
      "lang": "en",
      "text": "improve this MCP once it's",
      "offset": 280.72,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "launched? And lastly, how do you make",
      "offset": 283,
      "duration": 4.759
    },
    {
      "lang": "en",
      "text": "money out of your MCPs? So, in summary,",
      "offset": 285.36,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "the MCP ecosystem is very exciting, but",
      "offset": 287.759,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "it has a bunch of different problems. On",
      "offset": 289.84,
      "duration": 3.359
    },
    {
      "lang": "en",
      "text": "the left side, we have all the problems",
      "offset": 291.6,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "faced by MCB users. On the right side,",
      "offset": 293.199,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "we have problems faced by all the MCB",
      "offset": 295.12,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "developers. That's why we're building",
      "offset": 297.199,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "Smidy. I started Smidy in around",
      "offset": 298.72,
      "duration": 5.08
    },
    {
      "lang": "en",
      "text": "December 2024 to tackle these",
      "offset": 301.199,
      "duration": 5.041
    },
    {
      "lang": "en",
      "text": "challenges. Smittery is aiming to become",
      "offset": 303.8,
      "duration": 4.6
    },
    {
      "lang": "en",
      "text": "the AI gateway to grow and orchestrate",
      "offset": 306.24,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "this new era of AI native services for",
      "offset": 308.4,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "AI agents. So far, we've only scratched",
      "offset": 310.4,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "the surface of the problems I've",
      "offset": 312.88,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "described uh previously. But we built",
      "offset": 314.16,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "this little demo to showcase what you",
      "offset": 316.88,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "can build when some of these problems",
      "offset": 318.56,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "are solved. So here what you're seeing",
      "offset": 320.32,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "is uh the spittery playground. The main",
      "offset": 322.4,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "goal of the playgrounds for us is to",
      "offset": 325.12,
      "duration": 3.519
    },
    {
      "lang": "en",
      "text": "demonstrate what an AI agent can do when",
      "offset": 326.24,
      "duration": 4.92
    },
    {
      "lang": "en",
      "text": "it has access to thousands of curated",
      "offset": 328.639,
      "duration": 5.361
    },
    {
      "lang": "en",
      "text": "MCPs. So let's start with a prompt. Find",
      "offset": 331.16,
      "duration": 4.44
    },
    {
      "lang": "en",
      "text": "the most pressing issue on my GitHub",
      "offset": 334,
      "duration": 3.639
    },
    {
      "lang": "en",
      "text": "repository called",
      "offset": 335.6,
      "duration": 7.52
    },
    {
      "lang": "en",
      "text": "smidy- CLI and create a new ticket on",
      "offset": 337.639,
      "duration": 5.481
    },
    {
      "lang": "en",
      "text": "linear. Okay. So let's submit this",
      "offset": 343.4,
      "duration": 4.92
    },
    {
      "lang": "en",
      "text": "prompt. You'll see the agent first start",
      "offset": 345.6,
      "duration": 5.84
    },
    {
      "lang": "en",
      "text": "thinking about the issue. It does. It",
      "offset": 348.32,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "then calls this search servers function",
      "offset": 351.44,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "which uh looks up for all the servers",
      "offset": 353.28,
      "duration": 6.68
    },
    {
      "lang": "en",
      "text": "within SPI3. It connects to the best",
      "offset": 355.6,
      "duration": 7.319
    },
    {
      "lang": "en",
      "text": "server. It also connects to",
      "offset": 359.96,
      "duration": 6.12
    },
    {
      "lang": "en",
      "text": "linear. It's able to go on uh GitHub",
      "offset": 362.919,
      "duration": 5.481
    },
    {
      "lang": "en",
      "text": "using the GitHub MCP to find uh",
      "offset": 366.08,
      "duration": 3.64
    },
    {
      "lang": "en",
      "text": "different",
      "offset": 368.4,
      "duration": 3.519
    },
    {
      "lang": "en",
      "text": "bugs. It's trying to find the most high",
      "offset": 369.72,
      "duration": 5.599
    },
    {
      "lang": "en",
      "text": "priority item.",
      "offset": 371.919,
      "duration": 3.4
    },
    {
      "lang": "en",
      "text": "So I found a team and now it's creating",
      "offset": 375.6,
      "duration": 5
    },
    {
      "lang": "en",
      "text": "uh a ticket on",
      "offset": 377.52,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "linear. Great. So it looks like our",
      "offset": 380.6,
      "duration": 5.8
    },
    {
      "lang": "en",
      "text": "agent has successfully uh went on GitHub",
      "offset": 383.28,
      "duration": 5.84
    },
    {
      "lang": "en",
      "text": "looked for the most pressing issue uh on",
      "offset": 386.4,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "my GitHub issues and created a linear",
      "offset": 389.12,
      "duration": 3.32
    },
    {
      "lang": "en",
      "text": "ticket. So let's take a look at this",
      "offset": 391.28,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "ticket. Nice. Okay. So it has a lot of",
      "offset": 392.44,
      "duration": 3.879
    },
    {
      "lang": "en",
      "text": "details. It has even a link to the",
      "offset": 394.96,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "original issue. Um yeah, so we have sort",
      "offset": 396.319,
      "duration": 7.44
    },
    {
      "lang": "en",
      "text": "of an endto-end uh task uh being solved",
      "offset": 400.08,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "by an AI agent connected to two",
      "offset": 403.759,
      "duration": 3.761
    },
    {
      "lang": "en",
      "text": "different MCPs. So obviously, you know,",
      "offset": 405.44,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "this demo only scratched the surface,",
      "offset": 407.52,
      "duration": 3.679
    },
    {
      "lang": "en",
      "text": "but you can imagine what we can do when",
      "offset": 408.96,
      "duration": 4.239
    },
    {
      "lang": "en",
      "text": "more and more servers get deployed on",
      "offset": 411.199,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "Spitter. So this graph kind of shows you",
      "offset": 413.199,
      "duration": 4.241
    },
    {
      "lang": "en",
      "text": "the number of servers being deployed uh",
      "offset": 415.6,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "over the last couple months and the",
      "offset": 417.44,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "number of tool calls we've been getting.",
      "offset": 419.12,
      "duration": 4.639
    },
    {
      "lang": "en",
      "text": "With all this developer enthusiasm, I'm",
      "offset": 421.28,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "confident that we can solve all the",
      "offset": 423.759,
      "duration": 3.72
    },
    {
      "lang": "en",
      "text": "problems that I mentioned in this talk",
      "offset": 425.199,
      "duration": 4.641
    },
    {
      "lang": "en",
      "text": "today. It's clear to me that the future",
      "offset": 427.479,
      "duration": 3.801
    },
    {
      "lang": "en",
      "text": "of the internet will be dominated by",
      "offset": 429.84,
      "duration": 3.56
    },
    {
      "lang": "en",
      "text": "tool calls rather than",
      "offset": 431.28,
      "duration": 4.639
    },
    {
      "lang": "en",
      "text": "clicks. And in this new world, it's",
      "offset": 433.4,
      "duration": 4.28
    },
    {
      "lang": "en",
      "text": "going to be the agent experience that",
      "offset": 435.919,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "matters more than the user experience.",
      "offset": 437.68,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "And this agent experience is not going",
      "offset": 439.759,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "to be built by just me or a few",
      "offset": 441.599,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "companies. It's going to be built by all",
      "offset": 443.759,
      "duration": 6.081
    },
    {
      "lang": "en",
      "text": "of you. Thank you.",
      "offset": 445.759,
      "duration": 4.081
    }
  ],
  "cleanText": "Hi, I'm Henry. Because Model Context Protocol (MCP) is such a new space, uh instead of going into technical details like most AI engineer videos that you're probably seeing, uh today I'll be doing a high-level overview and a rant about all the problems within the MCP space and ecosystem. A quick introduction about myself. Um so I'm Henry Mao. I'm the founder and CEO of Smithery. Uh I'm also a member of the MCP sir committee. Before Smithery, um I co-founder Jenny AI. Um let me tell you a little bit about the origin story for Smithery. Um this is around November last year 2024. Uh I went down this rabbit hole trying to figure out uh trying to tackle the ARC AGI challenge. And if you haven't heard of the ARC AGI challenge, it's an IQ test made for LLMs. And in this challenge, um you're given two or three different examples of a pattern. And you want your LM to predict the missing last pattern here. And turns out that this challenge is very easy for humans to do. Humans get about uh 80% accuracy on this challenge, but it's pretty hard for LM to do. And LMS could not crack it for many many years. So I I kind of focused on tackling the challenge. Uh but very quickly, uh OpenAI decided to release 03. and Ozu completely dominated the ARC AGI1 challenge and basically got human level performance. It scored very well on math benchmarks as well. So, we're basically done, right? AGI achieved. Um, autonomous agents are going to be solving all our problems now. But fast forward to 2025 and I'm wondering where are all the autonomous agents? Why are they not solving all the tasks that we don't want to be doing? So, what we're seeing here is sort of Claude's paradox. uh we have all these frontier labs creating uh all this intelligence but all this intelligence is stuck in a box and in order to make AI agents practically useful we have to start thinking about context and capability what are the inputs and outputs uh to our models everyone from startups to major labs recognize this problem and so in November 2024 anthropic released the Model Context Protocol uh it's an open standard to help LMS connect to different services uh with a promise of standardizing uh this end times end problem. So when I saw MCPs uh in around this time last year, I was pretty excited about it. Um there was a small but vibrant developer community. So models are getting smarter and MCPs are standardizing the way models talk to services. So are we finally done? Well, not quite. With MCP and a new ecosystem of services trying to target AI agents, we have a bunch of new problems showing up. So first I want to go through the list of user problems that we have. So the first one is fragmentation. There are more and more MCP servers being deployed every single day and it's becoming hard to find high quality ones. The MCP committee is currently working on a better solution for this by creating an official registry thanks to test and the pulse MCP team. Simply having a registry doesn't solve the problem. For example, how do we assign reputation to high-quality MCPs is still an open question.\nAnother problem that MCP users face is high friction install. If you go to any MCP's GitHub repository, you you'll probably see this five-step installation process, which makes it very difficult to install. And in addition to that, once you have your MCP installed, you might just have installed an insecure unsecure MCP. Finally, it's unclear how we're going to create this new economy of AI native services. We don't have a plan on how to handle agentic payments. Open questions in this area include, how do I get agents to pay on my behalf? And how do I avoid subscribing to 100 different services uh each charging $10 a month? Next, let's look at the developer side problems. So, if you're building an MCP, you probably face hosting problems. Thanks to the Streambo HTTP transport is now much easier for developers to find platforms to host on. But hosting is still a challenge. Uh developers will have to deal with staple sessions, resumability, and other issues.\nThe developer tooling is also uh quite lacking in the MCP space. We have a basic MCP inspector provided by the official MCP repository which allows you to test out different tools uh check out your prompts but there are still open questions that developers are asking us. For example, how do I design the best MCPs? How do I know if my tool is going to be called? How do I create the best agent experience? Next, we also have distribution as a problem. If you're a developer, you create an MCP. How does your MCP get discovered? Observability is also an issue. If you deploy your MCP and people are using it, how do you improve this MCP once it's launched? And lastly, how do you make money out of your MCPs? So, in summary, the MCP ecosystem is very exciting, but it has a bunch of different problems. On the left side, we have all the problems faced by MCB users. On the right side, we have problems faced by all the MCB developers. That's why we're building Smithery. I started Smithery in around December 2024 to tackle these challenges. Smithery is aiming to become the AI gateway to grow and orchestrate this new era of AI native services for AI agents. So far, we've only scratched the surface of the problems I've described uh previously. But we built this little demo to showcase what you can build when some of these problems are solved. So here what you're seeing is uh the spittery playground. The main goal of the playgrounds for us is to demonstrate what an AI agent can do when it has access to thousands of curated MCPs. So let's start with a prompt. Find the most pressing issue on my GitHub repository called smidy- CLI and create a new ticket on linear. Okay. So let's submit this prompt. You'll see the agent first start thinking about the issue. It does. It then calls this search servers function which uh looks up for all the servers within SPI3. It connects to the best server. It also connects to linear. It's able to go on uh GitHub using the GitHub MCP to find uh different bugs. It's trying to find the most high priority item.\nSo I found a team and now it's creating uh a ticket on linear. Great. So it looks like our agent has successfully uh went on GitHub looked for the most pressing issue uh on my GitHub issues and created a linear ticket. So let's take a look at this ticket. Nice. Okay. So it has a lot of details. It has even a link to the original issue. Um yeah, so we have sort of an end-to-end uh task uh being solved by an AI agent connected to two different MCPs. So obviously, you know, this demo only scratched the surface, but you can imagine what we can do when more and more servers get deployed on Spitter. So this graph kind of shows you the number of servers being deployed uh over the last couple months and the number of tool calls we've been getting. With all this developer enthusiasm, I'm confident that we can solve all the problems that I mentioned in this talk today. It's clear to me that the future of the internet will be dominated by tool calls rather than clicks. And in this new world, it's going to be the agent experience that matters more than the user experience. And this agent experience is not going to be built by just me or a few companies. It's going to be built by all of you. Thank you.\n",
  "dumpedAt": "2025-07-21T18:43:25.768Z"
}