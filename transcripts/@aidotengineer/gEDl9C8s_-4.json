{
  "episodeId": "gEDl9C8s_-4",
  "channelSlug": "@aidotengineer",
  "title": "How to Train Your Agent: Building Reliable Agents with RL â€” Kyle Corbitt, OpenPipe",
  "publishedAt": "2025-07-19T21:12:06.000Z",
  "rawLines": [
    {
      "lang": "en",
      "text": "[Music]",
      "offset": 0.37,
      "duration": 7.49
    },
    {
      "lang": "en",
      "text": "Um, hey everyone. Glad you're all here.",
      "offset": 14.4,
      "duration": 5.039
    },
    {
      "lang": "en",
      "text": "This is the reasoning and reinforcement",
      "offset": 17.279,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "learning track uh on the afternoon of",
      "offset": 19.439,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "the last day of the AI engineer world's",
      "offset": 21.439,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "fair. Glad you're all here. Glad you're",
      "offset": 23.039,
      "duration": 3.761
    },
    {
      "lang": "en",
      "text": "sharing it with us. Today, what I'm",
      "offset": 25.039,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "going to talk about is uh a very",
      "offset": 26.8,
      "duration": 4.479
    },
    {
      "lang": "en",
      "text": "specific case study um that we did. Uh",
      "offset": 29.039,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "this case study, I'm going to talk about",
      "offset": 31.279,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "lessons learned very concretely. Um what",
      "offset": 32.64,
      "duration": 3.439
    },
    {
      "lang": "en",
      "text": "did and didn't work, how we able to",
      "offset": 34.88,
      "duration": 2.16
    },
    {
      "lang": "en",
      "text": "build an agent that worked well with",
      "offset": 36.079,
      "duration": 3.121
    },
    {
      "lang": "en",
      "text": "reinforcement learning. Uh all of this",
      "offset": 37.04,
      "duration": 3.359
    },
    {
      "lang": "en",
      "text": "uh everything that I'm talking about in",
      "offset": 39.2,
      "duration": 2.72
    },
    {
      "lang": "en",
      "text": "this presentation, this is an open-",
      "offset": 40.399,
      "duration": 4.241
    },
    {
      "lang": "en",
      "text": "source codebase that we built. Um we",
      "offset": 41.92,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "wanted to share these learnings and I'll",
      "offset": 44.64,
      "duration": 2.8
    },
    {
      "lang": "en",
      "text": "I'll I'll share that link with you at",
      "offset": 46.239,
      "duration": 2.721
    },
    {
      "lang": "en",
      "text": "the end as well. Um for those of you who",
      "offset": 47.44,
      "duration": 4.639
    },
    {
      "lang": "en",
      "text": "want to replicate what we did um so what",
      "offset": 48.96,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "is the project we're going to be talking",
      "offset": 52.079,
      "duration": 3.521
    },
    {
      "lang": "en",
      "text": "about? It's a project called ART E. It",
      "offset": 53.28,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "is a natural language uh assistant that",
      "offset": 55.6,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "helps you answer questions from your",
      "offset": 58.8,
      "duration": 3.759
    },
    {
      "lang": "en",
      "text": "email inbox. So I'll give you an example",
      "offset": 60.64,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "of what we're talking about here. Um",
      "offset": 62.559,
      "duration": 4.641
    },
    {
      "lang": "en",
      "text": "let's say you want to ask, you know, in",
      "offset": 65.36,
      "duration": 3.119
    },
    {
      "lang": "en",
      "text": "this case our example question is when",
      "offset": 67.2,
      "duration": 2.88
    },
    {
      "lang": "en",
      "text": "is Sherry's move to Portland targeted",
      "offset": 68.479,
      "duration": 3.121
    },
    {
      "lang": "en",
      "text": "for? So you would ask this question to",
      "offset": 70.08,
      "duration": 3.039
    },
    {
      "lang": "en",
      "text": "the assistant. It then goes and it",
      "offset": 71.6,
      "duration": 2.8
    },
    {
      "lang": "en",
      "text": "searches your inbox. It's got several",
      "offset": 73.119,
      "duration": 2.721
    },
    {
      "lang": "en",
      "text": "tools. So it has like a search tool, it",
      "offset": 74.4,
      "duration": 3.359
    },
    {
      "lang": "en",
      "text": "has a read email tool, and then it can",
      "offset": 75.84,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "actually answer the final question. You",
      "offset": 77.759,
      "duration": 3.281
    },
    {
      "lang": "en",
      "text": "can kind of see if you if you look here",
      "offset": 79.28,
      "duration": 3.199
    },
    {
      "lang": "en",
      "text": "what's going on behind the scenes. This",
      "offset": 81.04,
      "duration": 2.719
    },
    {
      "lang": "en",
      "text": "is important so you get a sense of kind",
      "offset": 82.479,
      "duration": 2.881
    },
    {
      "lang": "en",
      "text": "of how this agent works and as we're",
      "offset": 83.759,
      "duration": 2.961
    },
    {
      "lang": "en",
      "text": "talking through how we built it, how we",
      "offset": 85.36,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "made it work. Um hopefully that that",
      "offset": 86.72,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "helps uh make the conversation very",
      "offset": 88.56,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "grounded in a specific task. So anyway,",
      "offset": 90.32,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "you see the agent, it's it's you know",
      "offset": 92.479,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "searching for certain keywords. It get",
      "offset": 94.64,
      "duration": 3.439
    },
    {
      "lang": "en",
      "text": "those messages back. It's in reading one",
      "offset": 96.479,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "of them and and answering the question.",
      "offset": 98.079,
      "duration": 5.841
    },
    {
      "lang": "en",
      "text": "That's that's what it does. Okay. So um",
      "offset": 99.759,
      "duration": 5.521
    },
    {
      "lang": "en",
      "text": "question, you know, once once we've",
      "offset": 103.92,
      "duration": 2.64
    },
    {
      "lang": "en",
      "text": "decided this is kind of the the task",
      "offset": 105.28,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "we're trying to solve, why would you re",
      "offset": 106.56,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "use reinforcement learning for this",
      "offset": 108.32,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "specifically? Um and uh and the answer",
      "offset": 110.24,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "is like to start with you shouldn't. In",
      "offset": 113.28,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "fact to start off with we did not. Um so",
      "offset": 114.72,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "the first version of this agent once we",
      "offset": 117.119,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "decided we wanted to build this we did",
      "offset": 118.96,
      "duration": 2.96
    },
    {
      "lang": "en",
      "text": "we didn't use any reinforcement learning",
      "offset": 120.399,
      "duration": 3.521
    },
    {
      "lang": "en",
      "text": "at all. We purely built this on prompted",
      "offset": 121.92,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "models and this is the first lesson from",
      "offset": 123.92,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "this talk uh that I want to share is I",
      "offset": 125.68,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "would generally always recommend",
      "offset": 127.759,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "starting with getting the best",
      "offset": 129.44,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "performance you can with a prompted",
      "offset": 131.039,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "model before going to any training",
      "offset": 132.56,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "including reinforcement learning.",
      "offset": 134.239,
      "duration": 2.801
    },
    {
      "lang": "en",
      "text": "There's a few different reasons to do",
      "offset": 135.84,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "that uh 3 in specifically. Um the first",
      "offset": 137.04,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "one is just like working out the bugs in",
      "offset": 140.239,
      "duration": 3.041
    },
    {
      "lang": "en",
      "text": "your environment, right? Um you know,",
      "offset": 141.68,
      "duration": 2.88
    },
    {
      "lang": "en",
      "text": "maybe your tools aren't implemented",
      "offset": 143.28,
      "duration": 2.64
    },
    {
      "lang": "en",
      "text": "properly, maybe they don't have access",
      "offset": 144.56,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "to the data you think they do. Um we",
      "offset": 145.92,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "find this happens a lot and it's a lot",
      "offset": 148.64,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "less frustrating to debug that uh you",
      "offset": 150.16,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "know, separately from debugging your",
      "offset": 152.4,
      "duration": 2.8
    },
    {
      "lang": "en",
      "text": "your training loop. So you want to make",
      "offset": 153.92,
      "duration": 2.48
    },
    {
      "lang": "en",
      "text": "sure that like you can get at least some",
      "offset": 155.2,
      "duration": 3.039
    },
    {
      "lang": "en",
      "text": "kind of performance um before you start",
      "offset": 156.4,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "training. Um and then second of all, you",
      "offset": 158.239,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "may find as you're trying to improve the",
      "offset": 160.4,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "performance on uh on using these",
      "offset": 162.4,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "prompted models that uh you can get it",
      "offset": 165.04,
      "duration": 2.72
    },
    {
      "lang": "en",
      "text": "working really well and that's great. So",
      "offset": 166.56,
      "duration": 2.08
    },
    {
      "lang": "en",
      "text": "that means you don't need to train",
      "offset": 167.76,
      "duration": 3.119
    },
    {
      "lang": "en",
      "text": "anything. Um and that saves you a lot of",
      "offset": 168.64,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "time. Um there's a third reason as well",
      "offset": 170.879,
      "duration": 4.801
    },
    {
      "lang": "en",
      "text": "uh that I'll share which is uh basically",
      "offset": 173.44,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "once you've gone to that effort, you've",
      "offset": 175.68,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "done your best to get the best quality",
      "offset": 177.04,
      "duration": 5.119
    },
    {
      "lang": "en",
      "text": "prompted baselines you possibly can. Um",
      "offset": 179.04,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "then uh if you find that those baselines",
      "offset": 182.159,
      "duration": 2.8
    },
    {
      "lang": "en",
      "text": "are not able to get you where you need",
      "offset": 184,
      "duration": 2.239
    },
    {
      "lang": "en",
      "text": "to go and you're able to surpass them",
      "offset": 184.959,
      "duration": 3.041
    },
    {
      "lang": "en",
      "text": "with re reinforcement learning, it feels",
      "offset": 186.239,
      "duration": 2.961
    },
    {
      "lang": "en",
      "text": "great. You get to glow and be like,",
      "offset": 188,
      "duration": 2.48
    },
    {
      "lang": "en",
      "text": "\"Yes, I was able to beat the the",
      "offset": 189.2,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "frontier models on my task.\" Um this",
      "offset": 190.48,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "this I I highly recommend it. Feels",
      "offset": 192.72,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "good. You can you can like post on X",
      "offset": 194.64,
      "duration": 2.48
    },
    {
      "lang": "en",
      "text": "about it. there's there's nice, you",
      "offset": 196.08,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "know, graphs and stuff. So, this is this",
      "offset": 197.12,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "is what it looks like when everything",
      "offset": 199.68,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "goes right. Um, so this is an example of",
      "offset": 201.12,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "a training run for this art e model that",
      "offset": 203.599,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "I'm going to be talking about. Uh, you",
      "offset": 205.84,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "can see that there's these these lines",
      "offset": 207.76,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "for each of the prompted model baselines",
      "offset": 209.28,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "that we've got. Um, so we've got 03, 04",
      "offset": 211.04,
      "duration": 5.279
    },
    {
      "lang": "en",
      "text": "mini, and then Gemini and and 4.1. And",
      "offset": 213.28,
      "duration": 4.959
    },
    {
      "lang": "en",
      "text": "you can see uh those ones, you know,",
      "offset": 216.319,
      "duration": 3.361
    },
    {
      "lang": "en",
      "text": "they have certain level performance. And",
      "offset": 218.239,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "then you can see this this uh sort of",
      "offset": 219.68,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "moving line um that's going on. This is",
      "offset": 221.599,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "the model that we trained. And you can",
      "offset": 223.68,
      "duration": 3.279
    },
    {
      "lang": "en",
      "text": "see it actually starts out significantly",
      "offset": 225.44,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "worse than these other models uh from",
      "offset": 226.959,
      "duration": 2.801
    },
    {
      "lang": "en",
      "text": "from the start. That's because we",
      "offset": 228.56,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "started from a Quen 2.5 the 14 billion",
      "offset": 229.76,
      "duration": 4.559
    },
    {
      "lang": "en",
      "text": "parameter one. It's a relatively small",
      "offset": 232.64,
      "duration": 3.679
    },
    {
      "lang": "en",
      "text": "model, relatively weak model. Um and so",
      "offset": 234.319,
      "duration": 3.441
    },
    {
      "lang": "en",
      "text": "it was doing much worse than these",
      "offset": 236.319,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "initially, but you can see as training",
      "offset": 237.76,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "progresses um you know initially at the",
      "offset": 239.519,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "beginning it it's sort of maybe maybe",
      "offset": 241.84,
      "duration": 3.039
    },
    {
      "lang": "en",
      "text": "there's it's learning the right way to",
      "offset": 243.519,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "do tool calls. There's a very sharp bump",
      "offset": 244.879,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "as it figures out the basic stuff and",
      "offset": 246.879,
      "duration": 2.961
    },
    {
      "lang": "en",
      "text": "then a more gradual climb until",
      "offset": 248.48,
      "duration": 2.959
    },
    {
      "lang": "en",
      "text": "eventually it's able to significantly",
      "offset": 249.84,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "outperform uh any of the prompted models",
      "offset": 251.439,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "on this task. And this is sort of what",
      "offset": 253.92,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "you're you know in the ideal case when",
      "offset": 255.519,
      "duration": 2.72
    },
    {
      "lang": "en",
      "text": "everything works this this is what",
      "offset": 257.12,
      "duration": 2.32
    },
    {
      "lang": "en",
      "text": "you're looking for. This is what what",
      "offset": 258.239,
      "duration": 4.481
    },
    {
      "lang": "en",
      "text": "you're hoping to achieve. Um this is",
      "offset": 259.44,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "another view actually of that same data",
      "offset": 262.72,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "we were just looking at. Um I I like I",
      "offset": 264.4,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "wanted to highlight it in this way",
      "offset": 266.56,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "because it's important to realize. So on",
      "offset": 268.24,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "the last graph it looked like the the",
      "offset": 270.4,
      "duration": 2.96
    },
    {
      "lang": "en",
      "text": "lines sort of asmtote out pretty close",
      "offset": 271.68,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "together. That's because they're getting",
      "offset": 273.36,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "near 100%. But the last um you can see",
      "offset": 274.8,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "for example with our best prompted model",
      "offset": 277.6,
      "duration": 5.92
    },
    {
      "lang": "en",
      "text": "here 03 uh it's 90% accuracy and with",
      "offset": 279.12,
      "duration": 6.24
    },
    {
      "lang": "en",
      "text": "our RL model we're able to get up to",
      "offset": 283.52,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "96%. And so one way to think about that",
      "offset": 285.36,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "is like 60% of the errors that 03 was",
      "offset": 287.84,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "making um are are actually solved with",
      "offset": 291.36,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "our model. Um which is which is quite a",
      "offset": 293.52,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "large uh you know we find that that's",
      "offset": 295.36,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "actually can be very very important for",
      "offset": 296.88,
      "duration": 3.759
    },
    {
      "lang": "en",
      "text": "the user experience of someone using one",
      "offset": 298.88,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "of these um if you're getting you know",
      "offset": 300.639,
      "duration": 3.521
    },
    {
      "lang": "en",
      "text": "just half as many errors uh that that",
      "offset": 302.24,
      "duration": 4.959
    },
    {
      "lang": "en",
      "text": "can make the product much stronger. Um",
      "offset": 304.16,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "so this is this is where we got to on",
      "offset": 307.199,
      "duration": 3.361
    },
    {
      "lang": "en",
      "text": "accuracy. There's a couple other metrics",
      "offset": 308.72,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "that we find are often very very",
      "offset": 310.56,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "important. Um and you know the trade-off",
      "offset": 313.6,
      "duration": 3.599
    },
    {
      "lang": "en",
      "text": "between these does does is very task",
      "offset": 315.52,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "dependent but but they matter in many",
      "offset": 317.199,
      "duration": 4.801
    },
    {
      "lang": "en",
      "text": "cases. Um cost obviously is a big one.",
      "offset": 318.8,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "So for for this email agentic harness",
      "offset": 322,
      "duration": 5.039
    },
    {
      "lang": "en",
      "text": "that we had we benchmarked the cost on",
      "offset": 324.56,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "034 mini and our model. So if you wanted",
      "offset": 327.039,
      "duration": 4.801
    },
    {
      "lang": "en",
      "text": "to do like a thousand searches using 03",
      "offset": 329.84,
      "duration": 5.359
    },
    {
      "lang": "en",
      "text": "that's going to cost $55. Um which is a",
      "offset": 331.84,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "lot. I think for most use cases that",
      "offset": 335.199,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "probably would be cost prohibitive just",
      "offset": 337.12,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "from a unit economics point of view. Um",
      "offset": 338.479,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "on 04 mini we're down to $8 but that's",
      "offset": 340.32,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "still quite expensive. And then we drop",
      "offset": 342.479,
      "duration": 3.521
    },
    {
      "lang": "en",
      "text": "another order of magnitude by moving to",
      "offset": 344.08,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "this smaller Quen 2.514B. Again, this is",
      "offset": 346,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "just driven it by being it being a much",
      "offset": 348.56,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "smaller model. So it's it's much cheaper",
      "offset": 350.08,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "to run. Um but we're still able to get",
      "offset": 351.68,
      "duration": 2.799
    },
    {
      "lang": "en",
      "text": "very good performance because we've",
      "offset": 353.28,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "specialized it on our task. Um beyond",
      "offset": 354.479,
      "duration": 5.361
    },
    {
      "lang": "en",
      "text": "cost and the accuracy, um the third",
      "offset": 357.199,
      "duration": 5.041
    },
    {
      "lang": "en",
      "text": "metric that often comes up is latency.",
      "offset": 359.84,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "Uh particularly if you're doing I mean",
      "offset": 362.24,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "certainly anything with voice, but if",
      "offset": 363.84,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "there's any real-time human interaction",
      "offset": 365.6,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "with the task, latency is going to",
      "offset": 367.36,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "matter a lot. Um, and we were able to",
      "offset": 369.44,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "find on on this task we were able to get",
      "offset": 371.44,
      "duration": 3.759
    },
    {
      "lang": "en",
      "text": "significantly better latency. There's a",
      "offset": 373.36,
      "duration": 2.959
    },
    {
      "lang": "en",
      "text": "number of different ways which I'll go",
      "offset": 375.199,
      "duration": 2.641
    },
    {
      "lang": "en",
      "text": "into in more detail later that we were",
      "offset": 376.319,
      "duration": 3.361
    },
    {
      "lang": "en",
      "text": "able to achieve this. Um, you know, one",
      "offset": 377.84,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "was just again moving to a smaller model",
      "offset": 379.68,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "helps. There's just less less loading",
      "offset": 381.28,
      "duration": 3.359
    },
    {
      "lang": "en",
      "text": "from memory, less matrix multiplies.",
      "offset": 382.96,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "It's just you're able to get tokens out",
      "offset": 384.639,
      "duration": 3.441
    },
    {
      "lang": "en",
      "text": "faster. Um, we were also able to train",
      "offset": 386,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "this model to have fewer turns going",
      "offset": 388.08,
      "duration": 4.239
    },
    {
      "lang": "en",
      "text": "back and forth with the database with",
      "offset": 390.319,
      "duration": 4.241
    },
    {
      "lang": "en",
      "text": "the actual email um the list of emails.",
      "offset": 392.319,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "Uh, we we were able to train it to be",
      "offset": 394.56,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "more efficient with its queries. Um, and",
      "offset": 396.4,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "I'll go to that in a moment. And so that",
      "offset": 398.4,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "that leads to lower latency. Um there's",
      "offset": 399.84,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "actually a third thing which we didn't",
      "offset": 401.68,
      "duration": 2.799
    },
    {
      "lang": "en",
      "text": "apply here but can help a lot with these",
      "offset": 402.88,
      "duration": 2.56
    },
    {
      "lang": "en",
      "text": "smaller things which is called",
      "offset": 404.479,
      "duration": 2.56
    },
    {
      "lang": "en",
      "text": "speculative decoding. That's something",
      "offset": 405.44,
      "duration": 3.199
    },
    {
      "lang": "en",
      "text": "you can do on large or small models. It",
      "offset": 407.039,
      "duration": 3.361
    },
    {
      "lang": "en",
      "text": "generally works better on smaller task",
      "offset": 408.639,
      "duration": 3.761
    },
    {
      "lang": "en",
      "text": "specific models because you get higher",
      "offset": 410.4,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "um acceptance rates on on your",
      "offset": 412.4,
      "duration": 2.72
    },
    {
      "lang": "en",
      "text": "speculator. But basically um there's",
      "offset": 413.6,
      "duration": 2.64
    },
    {
      "lang": "en",
      "text": "there's lots of reasons why smaller",
      "offset": 415.12,
      "duration": 4.479
    },
    {
      "lang": "en",
      "text": "models work better. Um okay. So then the",
      "offset": 416.24,
      "duration": 4.799
    },
    {
      "lang": "en",
      "text": "next question uh for those of you who",
      "offset": 419.599,
      "duration": 3.361
    },
    {
      "lang": "en",
      "text": "haven't done this yet is like okay what",
      "offset": 421.039,
      "duration": 3.521
    },
    {
      "lang": "en",
      "text": "is the effort required to do this to",
      "offset": 422.96,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "actually achieve these results? Um, if",
      "offset": 424.56,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "you'd asked me this question a year ago,",
      "offset": 427.28,
      "duration": 2.88
    },
    {
      "lang": "en",
      "text": "I would say, \"Hey, you should really",
      "offset": 428.88,
      "duration": 2.8
    },
    {
      "lang": "en",
      "text": "only be doing this if you know you're",
      "offset": 430.16,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "this big company and willing to put, you",
      "offset": 431.68,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "know, months of of work into a project.\"",
      "offset": 433.44,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "I think that's changing. I honestly do.",
      "offset": 435.84,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "Um, in this case, uh, so this this",
      "offset": 437.599,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "training run, it cost us about $80 in",
      "offset": 440.08,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "GPU time. It did take about a week of",
      "offset": 441.919,
      "duration": 3.761
    },
    {
      "lang": "en",
      "text": "engineering time to build this. And and",
      "offset": 444.24,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "caveat that was with an engineer who is",
      "offset": 445.68,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "familiar with this domain and and had",
      "offset": 447.44,
      "duration": 2.879
    },
    {
      "lang": "en",
      "text": "quite a lot of experience uh, you know,",
      "offset": 448.88,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "with machine learning and RL. Um but I",
      "offset": 450.319,
      "duration": 4.561
    },
    {
      "lang": "en",
      "text": "actually expect as as we figure out the",
      "offset": 452.8,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "right patterns here collectively as an",
      "offset": 454.88,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "industry this will keep dropping. Um and",
      "offset": 456.4,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "I expect that uh you know the sort of",
      "offset": 458.56,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "payback period to get a return on",
      "offset": 460.319,
      "duration": 3.521
    },
    {
      "lang": "en",
      "text": "investment from these specialized models",
      "offset": 462.479,
      "duration": 3.041
    },
    {
      "lang": "en",
      "text": "is actually going to continue falling as",
      "offset": 463.84,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "well. Um and uh you know part of part of",
      "offset": 465.52,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "the reason I wanted to give this talk is",
      "offset": 469.52,
      "duration": 2.64
    },
    {
      "lang": "en",
      "text": "to sort of distribute that know the",
      "offset": 470.72,
      "duration": 3.039
    },
    {
      "lang": "en",
      "text": "knowledge we learned and hopefully move",
      "offset": 472.16,
      "duration": 3.039
    },
    {
      "lang": "en",
      "text": "faster towards that that world where",
      "offset": 473.759,
      "duration": 2.481
    },
    {
      "lang": "en",
      "text": "this is just sort of like a thing",
      "offset": 475.199,
      "duration": 2.641
    },
    {
      "lang": "en",
      "text": "everyone knows how to do and it's very",
      "offset": 476.24,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "easy and very fast. Um, so that's that's",
      "offset": 477.84,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "what we'll be talking about for the rest",
      "offset": 480.24,
      "duration": 2.399
    },
    {
      "lang": "en",
      "text": "of time is is some more of the lessons",
      "offset": 481.12,
      "duration": 6.72
    },
    {
      "lang": "en",
      "text": "we learned. Um, okay. So, uh, when you",
      "offset": 482.639,
      "duration": 7.68
    },
    {
      "lang": "en",
      "text": "are using RL to train an agent or really",
      "offset": 487.84,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "using RL for anything else, um, I find",
      "offset": 490.319,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "that consistently with different",
      "offset": 492.8,
      "duration": 2.799
    },
    {
      "lang": "en",
      "text": "problems we look at, there are there are",
      "offset": 494.24,
      "duration": 2.799
    },
    {
      "lang": "en",
      "text": "sort of two hard problems that come up",
      "offset": 495.599,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "every single time. All right? Um, and",
      "offset": 497.039,
      "duration": 3.761
    },
    {
      "lang": "en",
      "text": "the two hard problems are first of all",
      "offset": 499.039,
      "duration": 3.521
    },
    {
      "lang": "en",
      "text": "figuring out a realistic environment,",
      "offset": 500.8,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "right? So if you're training an agent,",
      "offset": 502.56,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "you need to be training it with",
      "offset": 504.639,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "realistic data, with realistic inputs",
      "offset": 506.16,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "and outputs, tools available, everything",
      "offset": 508.479,
      "duration": 3.361
    },
    {
      "lang": "en",
      "text": "like that to how it's going to be used",
      "offset": 510,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "in production. Um because if you don't,",
      "offset": 511.84,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "then it's going to be optimizing for the",
      "offset": 513.919,
      "duration": 2.48
    },
    {
      "lang": "en",
      "text": "wrong thing and and you won't get the",
      "offset": 515.2,
      "duration": 2.8
    },
    {
      "lang": "en",
      "text": "results you want when you deploy it. And",
      "offset": 516.399,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "then the second thing which sometimes is",
      "offset": 518,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "hard um sometimes isn't this one is a",
      "offset": 520.08,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "little bit test dependent is getting the",
      "offset": 522.159,
      "duration": 2.961
    },
    {
      "lang": "en",
      "text": "right reward function. So reward",
      "offset": 523.44,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "function that just means you have to be",
      "offset": 525.12,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "able to know when your agent's gone",
      "offset": 527.12,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "through and say in this case give it an",
      "offset": 528.72,
      "duration": 2.96
    },
    {
      "lang": "en",
      "text": "answer to my email. You have to have",
      "offset": 530.24,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "some way of knowing did it do a good job",
      "offset": 531.68,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "or a bad job. All right, that's the",
      "offset": 533.44,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "reward function. It decides it it it's",
      "offset": 534.8,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "it's how you decide if it's good or it's",
      "offset": 536.56,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "bad. Um some depending on the domain",
      "offset": 538.24,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "sometimes that's really easy. We have I",
      "offset": 540.8,
      "duration": 2.8
    },
    {
      "lang": "en",
      "text": "don't know if Nathan's here, he's going",
      "offset": 542.64,
      "duration": 2.24
    },
    {
      "lang": "en",
      "text": "to be talking next, but um you know he",
      "offset": 543.6,
      "duration": 2.4
    },
    {
      "lang": "en",
      "text": "and his team put together this thing",
      "offset": 544.88,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "called RLVR which in some verifiable",
      "offset": 546,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "domains it's actually very easy to do a",
      "offset": 548.32,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "reward. Often times uh not all domains",
      "offset": 550.399,
      "duration": 4.721
    },
    {
      "lang": "en",
      "text": "are like that. oftentimes it is kind of",
      "offset": 553.36,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "hard. Um, and so it's it's somewhat task",
      "offset": 555.12,
      "duration": 3.279
    },
    {
      "lang": "en",
      "text": "dependent. I'm going to go through how",
      "offset": 557.36,
      "duration": 2.96
    },
    {
      "lang": "en",
      "text": "we solve these problems specifically",
      "offset": 558.399,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "with RE. Okay, first one, realistic",
      "offset": 560.32,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "environment. So for our RE task, what is",
      "offset": 562.32,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "the environment we need? What is the",
      "offset": 565.36,
      "duration": 2.4
    },
    {
      "lang": "en",
      "text": "environment this agent's going to be",
      "offset": 566.64,
      "duration": 2.96
    },
    {
      "lang": "en",
      "text": "operating in? Well, it needs these tools",
      "offset": 567.76,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "available. It needs to be able to go and",
      "offset": 569.6,
      "duration": 2.56
    },
    {
      "lang": "en",
      "text": "query an email inbox. It needs to be",
      "offset": 570.8,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "able to like get emails back um and and",
      "offset": 572.16,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "that look realistic. These emails, you",
      "offset": 574.8,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "know, the inbox should be large because",
      "offset": 576.56,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "that's what most email inboxes are like.",
      "offset": 578.24,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "Um the emails in it should be diverse",
      "offset": 580.24,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "and they have to look kind of like real",
      "offset": 581.6,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "emails. Um so this could be kind of hard",
      "offset": 583.36,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "because you can't just go ask like a",
      "offset": 586.24,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "thousand people to you know give you uh",
      "offset": 587.6,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "their their their personal emails to",
      "offset": 589.36,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "train on. Um luckily in this case we",
      "offset": 590.88,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "were able to solve this with the help of",
      "offset": 593.2,
      "duration": 3.199
    },
    {
      "lang": "en",
      "text": "a company that has contributed a lot um",
      "offset": 594.56,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "to just the open data ecosystem uh",
      "offset": 596.399,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "generally. It's it's like a quite an",
      "offset": 598.8,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "iconic company perhaps I would call it a",
      "offset": 600.48,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "historic company. Um I'm of course",
      "offset": 602.32,
      "duration": 5.199
    },
    {
      "lang": "en",
      "text": "talking about Enron. Um",
      "offset": 604,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "I'm hearing some laughter. So anyway,",
      "offset": 607.519,
      "duration": 4.801
    },
    {
      "lang": "en",
      "text": "Enron was a uh they were a financialized",
      "offset": 609.04,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "energy company in the '9s and 2000s,",
      "offset": 612.32,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "committed massive fraud, ended up",
      "offset": 614.8,
      "duration": 2.56
    },
    {
      "lang": "en",
      "text": "getting shut down by the Department of",
      "offset": 616.24,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "Justice. As part of this uh um you know,",
      "offset": 617.36,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "process, the the the court cases they",
      "offset": 620.16,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "were going through. Um a dump of like",
      "offset": 622.48,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "500,000 of their emails was released to",
      "offset": 624.32,
      "duration": 2.8
    },
    {
      "lang": "en",
      "text": "the public as part of the discovery",
      "offset": 626,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "process. Um so that's that's that's",
      "offset": 627.12,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "great for things like this and that's",
      "offset": 629.44,
      "duration": 2.8
    },
    {
      "lang": "en",
      "text": "what we used as our environment for the",
      "offset": 630.64,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "email inboxes. All right. So now we've",
      "offset": 632.24,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "got realistic email inboxes um with tens",
      "offset": 634.8,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "of thousands of emails that are real",
      "offset": 637.12,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "emails back and forth. Now we have to",
      "offset": 638.32,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "design our reward function. So as our",
      "offset": 640.16,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "agent is going and as our agent is um",
      "offset": 641.92,
      "duration": 5.039
    },
    {
      "lang": "en",
      "text": "you know we're asking it questions and",
      "offset": 645.12,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "then it's giving us answers, we have to",
      "offset": 646.959,
      "duration": 2.88
    },
    {
      "lang": "en",
      "text": "know is the answer correct or not so we",
      "offset": 648.16,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "can reward it when it gets the answer",
      "offset": 649.839,
      "duration": 2.961
    },
    {
      "lang": "en",
      "text": "right and it can learn to do that",
      "offset": 651.36,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "better. There's different ways and this",
      "offset": 652.8,
      "duration": 5.279
    },
    {
      "lang": "en",
      "text": "part is very task dependent. Um the way",
      "offset": 655.519,
      "duration": 5.201
    },
    {
      "lang": "en",
      "text": "that we went about it in this case um",
      "offset": 658.079,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "was we basically turned it into a more",
      "offset": 660.72,
      "duration": 4.559
    },
    {
      "lang": "en",
      "text": "of a verifiable problem. And the way we",
      "offset": 663.519,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "did that was we actually took our email",
      "offset": 665.279,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "inbox. We sort of inverted the problem.",
      "offset": 667.36,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "We um we grabbed batches of 20 emails at",
      "offset": 668.88,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "a time uh from the inbox and gave them",
      "offset": 671.6,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "to Gemini 2.5 Pro and said, \"Hey, given",
      "offset": 674.32,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "this set of emails, give us a few",
      "offset": 677.12,
      "duration": 2.64
    },
    {
      "lang": "en",
      "text": "questions that a user might",
      "offset": 678.64,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "realistically ask that the answers are",
      "offset": 679.76,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "found in this email.\" Right? And so",
      "offset": 681.92,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "Gemini generated the questions, it",
      "offset": 683.68,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "generated the answers, and then of",
      "offset": 685.6,
      "duration": 2.88
    },
    {
      "lang": "en",
      "text": "course the the source emails that came",
      "offset": 686.8,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "from. Um, and there were some extra",
      "offset": 688.48,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "steps on top of that. A lot of the",
      "offset": 690.48,
      "duration": 2.4
    },
    {
      "lang": "en",
      "text": "questions it came up with looked a",
      "offset": 691.6,
      "duration": 2.4
    },
    {
      "lang": "en",
      "text": "little bit unrealistic. We had a",
      "offset": 692.88,
      "duration": 2.24
    },
    {
      "lang": "en",
      "text": "separate filtering step where we're",
      "offset": 694,
      "duration": 2.56
    },
    {
      "lang": "en",
      "text": "like, okay, let's find the subset of",
      "offset": 695.12,
      "duration": 2.88
    },
    {
      "lang": "en",
      "text": "these that that actually look like",
      "offset": 696.56,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "questions that, you know, I would maybe",
      "offset": 698,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "ask. And we ended up with a list of a",
      "offset": 699.6,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "few thousand questions um along with",
      "offset": 701.44,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "their verified answers. Um, and so at",
      "offset": 704.16,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "this point, it becomes much more of a a",
      "offset": 706.56,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "sort of verified thing. the the reward",
      "offset": 708.24,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "function becomes much easier because we",
      "offset": 709.92,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "know what the correct answer should be.",
      "offset": 711.6,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "And so the way we can tell if our agent",
      "offset": 713.36,
      "duration": 3.599
    },
    {
      "lang": "en",
      "text": "did a good job is we give our agent the",
      "offset": 715.04,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "question, we let it go and search the",
      "offset": 716.959,
      "duration": 2.481
    },
    {
      "lang": "en",
      "text": "email inbox and try and find the right",
      "offset": 718.16,
      "duration": 2.64
    },
    {
      "lang": "en",
      "text": "emails and everything. And eventually it",
      "offset": 719.44,
      "duration": 2.959
    },
    {
      "lang": "en",
      "text": "comes back with an answer. And then we",
      "offset": 720.8,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "can just use an LLM as judge, a very",
      "offset": 722.399,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "simple one, and say like, hey, you know,",
      "offset": 724.24,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "here's the question. Here's the the",
      "offset": 726.079,
      "duration": 3.041
    },
    {
      "lang": "en",
      "text": "golden answer that that we believe is",
      "offset": 727.6,
      "duration": 2.96
    },
    {
      "lang": "en",
      "text": "right. Here's the answer we got from our",
      "offset": 729.12,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "from our model. Is it right or not? Um",
      "offset": 730.56,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "we did have to do a little bit of uh",
      "offset": 732.8,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "iteration there making sure that the",
      "offset": 734.48,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "judge was well calibrated on like what",
      "offset": 735.92,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "you know what what counts as as correct",
      "offset": 737.68,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "or not but by and large this worked",
      "offset": 739.44,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "pretty well um and was able to make this",
      "offset": 741.519,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "more of a verified task. Um so so that's",
      "offset": 743.76,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "how that's how we solved the the reward",
      "offset": 746.959,
      "duration": 2.88
    },
    {
      "lang": "en",
      "text": "function problem was by having that you",
      "offset": 748.48,
      "duration": 2.479
    },
    {
      "lang": "en",
      "text": "know turning this into something where",
      "offset": 749.839,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "we had more of a golden data set. Um,",
      "offset": 750.959,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "okay. So, once you've solved that",
      "offset": 754,
      "duration": 2.48
    },
    {
      "lang": "en",
      "text": "problem, those problems, once you have",
      "offset": 755.12,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "your environment, once you have um your",
      "offset": 756.48,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "your reward function defined, then",
      "offset": 758.72,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "basically you just kind of have to run a",
      "offset": 760.56,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "loop over and over and over again where",
      "offset": 762.24,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "you have your agent go through and it",
      "offset": 764.399,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "tries to um solve the problem and then",
      "offset": 766.48,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "you figure out if it's good or it's bad.",
      "offset": 768.639,
      "duration": 4.241
    },
    {
      "lang": "en",
      "text": "Um, and then you just uh you know,",
      "offset": 770.639,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "reward if it's if it's good and punish",
      "offset": 772.88,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "if it's bad and that's it. Um, and uh,",
      "offset": 774.72,
      "duration": 4.239
    },
    {
      "lang": "en",
      "text": "you do this over and over and over",
      "offset": 777.76,
      "duration": 2.96
    },
    {
      "lang": "en",
      "text": "again. And then hopefully if you've got",
      "offset": 778.959,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "everything set up right, um, it learns",
      "offset": 780.72,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "what good looks like, it learns what bad",
      "offset": 783.36,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "looks like, um, and it starts doing it",
      "offset": 784.88,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "right. Um, and then again, this is this",
      "offset": 786.72,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "is the curve we saw earlier where where",
      "offset": 789.04,
      "duration": 3.039
    },
    {
      "lang": "en",
      "text": "you can see it it it starts getting",
      "offset": 790.48,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "better over time. Um, okay, a few other",
      "offset": 792.079,
      "duration": 5.521
    },
    {
      "lang": "en",
      "text": "like interesting learnings from this",
      "offset": 795.76,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "project. Um, one thing is we found that",
      "offset": 797.6,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "there's actually you can throw a lot of",
      "offset": 799.839,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "stuff into your reward function uh",
      "offset": 801.92,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "beyond just the primary thing you're",
      "offset": 804.399,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "trying to solve for. And so we actually",
      "offset": 806.16,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "ended up we there were like sort of",
      "offset": 808.32,
      "duration": 2.4
    },
    {
      "lang": "en",
      "text": "eight different little things that we",
      "offset": 809.6,
      "duration": 2.88
    },
    {
      "lang": "en",
      "text": "gave extra credit for. Um, and I'm going",
      "offset": 810.72,
      "duration": 4.239
    },
    {
      "lang": "en",
      "text": "to share two of them here. So the first",
      "offset": 812.48,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "one here is um is we were trying to have",
      "offset": 814.959,
      "duration": 4.641
    },
    {
      "lang": "en",
      "text": "it optimized for the number of turns,",
      "offset": 817.76,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "how many times back and forth, how many",
      "offset": 819.6,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "times it had to query the email inbox",
      "offset": 820.88,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "before it came up with the right answer.",
      "offset": 822.8,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "Right? So, because the most important",
      "offset": 824.32,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "thing, of course, is is getting the",
      "offset": 826.24,
      "duration": 2.8
    },
    {
      "lang": "en",
      "text": "answer right, but between two answers",
      "offset": 827.36,
      "duration": 3.279
    },
    {
      "lang": "en",
      "text": "that both get it right, we would rather",
      "offset": 829.04,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "it took fewer turns back and forth",
      "offset": 830.639,
      "duration": 2.961
    },
    {
      "lang": "en",
      "text": "because that's fewer tokens, that's",
      "offset": 832.24,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "lower latency, lower costs. Um, it's",
      "offset": 833.6,
      "duration": 4.799
    },
    {
      "lang": "en",
      "text": "just like a more efficient agent. So,",
      "offset": 835.68,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "um, so you can see here on this first",
      "offset": 838.399,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "graph that early on, while was getting",
      "offset": 839.76,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "its feet wet and figuring out what",
      "offset": 842.32,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "worked, it it ended up spiking up to",
      "offset": 843.68,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "over six turns on average. So, it would",
      "offset": 845.36,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "go back and forth a bunch of times with",
      "offset": 847.6,
      "duration": 2.799
    },
    {
      "lang": "en",
      "text": "the email inbox and and try and find the",
      "offset": 848.72,
      "duration": 3.359
    },
    {
      "lang": "en",
      "text": "right thing. But then once it was able",
      "offset": 850.399,
      "duration": 3.761
    },
    {
      "lang": "en",
      "text": "to like figure out how to use the tools",
      "offset": 852.079,
      "duration": 3.521
    },
    {
      "lang": "en",
      "text": "efficiently, figure out like you know",
      "offset": 854.16,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "the the right way to construct keywords",
      "offset": 855.6,
      "duration": 3.359
    },
    {
      "lang": "en",
      "text": "and find the right email, it was able to",
      "offset": 857.44,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "get very efficient and actually fast uh",
      "offset": 858.959,
      "duration": 3.761
    },
    {
      "lang": "en",
      "text": "better than any of our prompted models",
      "offset": 861.12,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "uh on this metric of um using fewer",
      "offset": 862.72,
      "duration": 3.359
    },
    {
      "lang": "en",
      "text": "turns. And again, this was just because",
      "offset": 865.04,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "we gave it a little bit of extra. It was",
      "offset": 866.079,
      "duration": 3.521
    },
    {
      "lang": "en",
      "text": "it was a very small amount relative to",
      "offset": 868.16,
      "duration": 3.039
    },
    {
      "lang": "en",
      "text": "the reward for getting it right, but a",
      "offset": 869.6,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "little bit of extra credit on on using",
      "offset": 871.199,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "for fewer turns and it was able to to",
      "offset": 873.04,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "use that um to to optimize against that.",
      "offset": 874.88,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "Um, another extra reward function we",
      "offset": 877.92,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "gave it is um to try and discourage it",
      "offset": 879.68,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "from hallucinating answers. So, um,",
      "offset": 882.16,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "obviously the best thing is to get the",
      "offset": 884.8,
      "duration": 3.279
    },
    {
      "lang": "en",
      "text": "right answer. If you can't find the",
      "offset": 886.56,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "right answer, it's much better to say,",
      "offset": 888.079,
      "duration": 2.961
    },
    {
      "lang": "en",
      "text": "hey, I don't know, than to make up an",
      "offset": 889.6,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "answer in in a situation like this. So,",
      "offset": 891.04,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "we basically penalized it if um if the",
      "offset": 893.36,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "reward model said, \"Hey, you got the",
      "offset": 896.48,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "answer wrong.\" And but it had tried to",
      "offset": 897.92,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "get an answer give an answer, that was",
      "offset": 900.16,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "like a much lower reward than if it just",
      "offset": 901.839,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "said, \"Hey, I don't know. I can't solve",
      "offset": 904.079,
      "duration": 2.961
    },
    {
      "lang": "en",
      "text": "this problem.\" And as you can see, that",
      "offset": 905.519,
      "duration": 2.801
    },
    {
      "lang": "en",
      "text": "worked quite well. Um, compared to any",
      "offset": 907.04,
      "duration": 2.88
    },
    {
      "lang": "en",
      "text": "of the prompted models, including 03, we",
      "offset": 908.32,
      "duration": 3.199
    },
    {
      "lang": "en",
      "text": "ended up with a significantly lower",
      "offset": 909.92,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "hallucination rate because that was part",
      "offset": 911.519,
      "duration": 4.481
    },
    {
      "lang": "en",
      "text": "of our reward function. Um, again, these",
      "offset": 914,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "are these are things that are just sort",
      "offset": 916,
      "duration": 2.8
    },
    {
      "lang": "en",
      "text": "of like extra credit, but um, we found",
      "offset": 917.12,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "that like you can throw in a bunch of",
      "offset": 918.8,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "these and and it can jointly optimize",
      "offset": 920.16,
      "duration": 3.679
    },
    {
      "lang": "en",
      "text": "all of them at the same time, which is",
      "offset": 922.32,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "super powerful.",
      "offset": 923.839,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "Okay, I want to talk a little bit about",
      "offset": 925.76,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "reward hacking. Um, it's it's something",
      "offset": 927.279,
      "duration": 3.441
    },
    {
      "lang": "en",
      "text": "that comes up a lot when you're trying",
      "offset": 929.36,
      "duration": 2.64
    },
    {
      "lang": "en",
      "text": "to do this, and it's kind of a fun thing",
      "offset": 930.72,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "to talk about. Um this is an iconic",
      "offset": 932,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "video some of you might have seen. Uh",
      "offset": 934.16,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "this was released by OpenAI almost a",
      "offset": 935.839,
      "duration": 3.521
    },
    {
      "lang": "en",
      "text": "decade ago at this point of um they were",
      "offset": 937.6,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "they were trying to uh they had this",
      "offset": 939.36,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "environment where you were trying to uh",
      "offset": 941.36,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "get this boat to complete a race and",
      "offset": 943.04,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "instead of learning to complete uh",
      "offset": 945.12,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "complete the race it learned that oh if",
      "offset": 946.88,
      "duration": 2.48
    },
    {
      "lang": "en",
      "text": "I just go in this like little circle",
      "offset": 948.32,
      "duration": 2.48
    },
    {
      "lang": "en",
      "text": "that's not even part of the racetrack I",
      "offset": 949.36,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "can like just get a bunch of points. Um",
      "offset": 950.8,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "and so it just started doing that over",
      "offset": 953.12,
      "duration": 2.639
    },
    {
      "lang": "en",
      "text": "and over and over again instead of like",
      "offset": 954.48,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "actually following. Um, this is",
      "offset": 955.759,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "something that comes up a lot if you're",
      "offset": 957.92,
      "duration": 2.88
    },
    {
      "lang": "en",
      "text": "doing reinforcement learning. And it's",
      "offset": 959.36,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "basically just the difference between",
      "offset": 960.8,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "um, uh, the difference between what you",
      "offset": 962.8,
      "duration": 4.959
    },
    {
      "lang": "en",
      "text": "actually want the model to do and what",
      "offset": 966.24,
      "duration": 3.279
    },
    {
      "lang": "en",
      "text": "you can measure. Um, like what you're",
      "offset": 967.759,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "actually rewarding it for. And, and if",
      "offset": 969.519,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "you almost always, if you let one of",
      "offset": 971.44,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "these run long enough, it will figure",
      "offset": 972.959,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "out some way to exploit your measure.",
      "offset": 974.72,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "Um, and it will figure out some way to",
      "offset": 976.88,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "to get a really high reward um, without",
      "offset": 978.639,
      "duration": 3.281
    },
    {
      "lang": "en",
      "text": "actually solving the problem. And you",
      "offset": 980.8,
      "duration": 2.159
    },
    {
      "lang": "en",
      "text": "need to just watch for that. So, I'm",
      "offset": 981.92,
      "duration": 3.279
    },
    {
      "lang": "en",
      "text": "going to give a couple examples here. Um",
      "offset": 982.959,
      "duration": 4.481
    },
    {
      "lang": "en",
      "text": "this is a this is a graph um from",
      "offset": 985.199,
      "duration": 4.241
    },
    {
      "lang": "en",
      "text": "another project actually not this one.",
      "offset": 987.44,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "Uh so an engineer on our team was uh was",
      "offset": 989.44,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "working on this game called NYT",
      "offset": 991.759,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "connections. Some of you might know you",
      "offset": 993.279,
      "duration": 3.441
    },
    {
      "lang": "en",
      "text": "get 16 words and you have to put them in",
      "offset": 995.199,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "like four groups of four. It's quite a",
      "offset": 996.72,
      "duration": 3.679
    },
    {
      "lang": "en",
      "text": "challenging game especially for these",
      "offset": 998.639,
      "duration": 3.041
    },
    {
      "lang": "en",
      "text": "language models because it requires a",
      "offset": 1000.399,
      "duration": 2.88
    },
    {
      "lang": "en",
      "text": "lot of world knowledge and like you know",
      "offset": 1001.68,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "lateral thinking. Anyway, um so so they",
      "offset": 1003.279,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "were trying to train this model to do it",
      "offset": 1006,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "and uh it wasn't figuring out wasn't",
      "offset": 1007.519,
      "duration": 2.801
    },
    {
      "lang": "en",
      "text": "figuring out. what if it wasn't figured",
      "offset": 1009.44,
      "duration": 2.24
    },
    {
      "lang": "en",
      "text": "out? And then boom, you you can see here",
      "offset": 1010.32,
      "duration": 2.56
    },
    {
      "lang": "en",
      "text": "around step 40, it just like takes off",
      "offset": 1011.68,
      "duration": 2.64
    },
    {
      "lang": "en",
      "text": "and it's like, okay, we figured out how",
      "offset": 1012.88,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "to how to solve this and and this",
      "offset": 1014.32,
      "duration": 2.959
    },
    {
      "lang": "en",
      "text": "engineer I'm I'm going to I'm going to",
      "offset": 1015.92,
      "duration": 2.96
    },
    {
      "lang": "en",
      "text": "call out where's where's where's An on",
      "offset": 1017.279,
      "duration": 2.641
    },
    {
      "lang": "en",
      "text": "our team? He's here at the conference.",
      "offset": 1018.88,
      "duration": 2.399
    },
    {
      "lang": "en",
      "text": "Yeah, he's great. You should talk to him",
      "offset": 1019.92,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "after. But um he was like, hey, we we we",
      "offset": 1021.279,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "solved it. Like we got NYT connections",
      "offset": 1023.04,
      "duration": 3.519
    },
    {
      "lang": "en",
      "text": "and like and it's like, okay, the graph",
      "offset": 1024.88,
      "duration": 2.88
    },
    {
      "lang": "en",
      "text": "looks good. Let's look at what it's",
      "offset": 1026.559,
      "duration": 3.041
    },
    {
      "lang": "en",
      "text": "actually doing. What it was actually",
      "offset": 1027.76,
      "duration": 3.199
    },
    {
      "lang": "en",
      "text": "doing is it had figured out there was a",
      "offset": 1029.6,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "bug in how we wrote the verification.",
      "offset": 1030.959,
      "duration": 4.641
    },
    {
      "lang": "en",
      "text": "And if it just put every single word in",
      "offset": 1033.76,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "every single category, it was able to",
      "offset": 1035.6,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "get a perfect score. um because we",
      "offset": 1036.88,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "weren't verifying that they were in fact",
      "offset": 1039.36,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "only four words uh in each category. Um",
      "offset": 1040.799,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "so this is another example. This is a",
      "offset": 1044,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "fun one. So I was I was training a model",
      "offset": 1045.919,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "um to produce really good titles for",
      "offset": 1047.839,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "hacker news um titles that would get a",
      "offset": 1049.6,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "thing upvoted. So I had this reward",
      "offset": 1051.44,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "model I'd trained on like existing",
      "offset": 1053.2,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "hacker news um articles and how many up",
      "offset": 1054.88,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "votes they got. And I was I was trying",
      "offset": 1057.039,
      "duration": 2.721
    },
    {
      "lang": "en",
      "text": "to train this model to produce new",
      "offset": 1058.32,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "titles and it was working really well",
      "offset": 1059.76,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "for a while. You can see and and sort of",
      "offset": 1061.6,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "subjectively as well. I I looked at a",
      "offset": 1063.36,
      "duration": 2.96
    },
    {
      "lang": "en",
      "text": "bunch of these these titles generated",
      "offset": 1064.88,
      "duration": 2.88
    },
    {
      "lang": "en",
      "text": "and and for these first like thousand",
      "offset": 1066.32,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "steps or so, it was actually learning",
      "offset": 1067.76,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "things that I was like, \"Okay, as",
      "offset": 1069.84,
      "duration": 2.8
    },
    {
      "lang": "en",
      "text": "someone who spends way too much time on",
      "offset": 1071.12,
      "duration": 2.88
    },
    {
      "lang": "en",
      "text": "Hacker News, yeah, that that does look",
      "offset": 1072.64,
      "duration": 2.56
    },
    {
      "lang": "en",
      "text": "like a good title. You're you're doing a",
      "offset": 1074,
      "duration": 2.88
    },
    {
      "lang": "en",
      "text": "good job.\" And then you can see around",
      "offset": 1075.2,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "step um 1200 here, it just like jumps a",
      "offset": 1076.88,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "bunch, right? It's like, \"Okay.\" Um it",
      "offset": 1079.44,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "clearly figured something out. I don't",
      "offset": 1081.28,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "know what it figured out. Um but we",
      "offset": 1082.48,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "should look at that. Um, and so, uh,",
      "offset": 1084.4,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "what it turns out what the model had",
      "offset": 1087.36,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "figured out was that it could just",
      "offset": 1089.36,
      "duration": 3.679
    },
    {
      "lang": "en",
      "text": "completely ignore the content of the",
      "offset": 1090.96,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "post and generate the same title for",
      "offset": 1093.039,
      "duration": 3.201
    },
    {
      "lang": "en",
      "text": "every single one of them and that would",
      "offset": 1095.12,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "like maximize its score. So, it",
      "offset": 1096.24,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "generated this title, Google lays off",
      "offset": 1098.4,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "80% of workforce, literally every single",
      "offset": 1100,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "article, this was this was what it",
      "offset": 1102.559,
      "duration": 3.441
    },
    {
      "lang": "en",
      "text": "labeled it as. And was like, yes, that",
      "offset": 1103.84,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "is going to get up on HackerNews for",
      "offset": 1106,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "sure, which which it probably would to",
      "offset": 1107.6,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "be fair. Um",
      "offset": 1109.6,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "so so anyway the way the way we solved",
      "offset": 1112.08,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "this um what we found is that it's it's",
      "offset": 1114.24,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "really important to watch out for this",
      "offset": 1116.16,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "solving it typically involves modifying",
      "offset": 1118,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "in some way your reward function to",
      "offset": 1120.64,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "penalize things like that. So in the",
      "offset": 1122.96,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "second example I talked about it was",
      "offset": 1125.039,
      "duration": 2.801
    },
    {
      "lang": "en",
      "text": "actually quite an easy fix once we",
      "offset": 1126.24,
      "duration": 3.439
    },
    {
      "lang": "en",
      "text": "identified it um which was just add an",
      "offset": 1127.84,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "extra LMS judge that looked at the title",
      "offset": 1129.679,
      "duration": 3.521
    },
    {
      "lang": "en",
      "text": "looked at the content and said hey is",
      "offset": 1131.6,
      "duration": 2.88
    },
    {
      "lang": "en",
      "text": "there anything in the title that's not",
      "offset": 1133.2,
      "duration": 2.64
    },
    {
      "lang": "en",
      "text": "supported by the content and we added",
      "offset": 1134.48,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "that on and and it it actually worked",
      "offset": 1135.84,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "great. Um, the important thing here is",
      "offset": 1137.52,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "you want to be looking at your your",
      "offset": 1139.28,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "rollouts, not just blindly trusting the",
      "offset": 1140.96,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "reward function, figuring out what's",
      "offset": 1142.64,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "actually happening. Um, anyway, so, uh,",
      "offset": 1144.32,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "that's it. Um, I'm I'm almost out of",
      "offset": 1147.52,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "time, so I'm going to stop. Couple of QR",
      "offset": 1149.12,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "codes for you. Um, everything in this",
      "offset": 1150.88,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "presentation, and there's a much longer",
      "offset": 1153.52,
      "duration": 3.519
    },
    {
      "lang": "en",
      "text": "write up I have of this whole project.",
      "offset": 1155.28,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "It includes the code. It includes the",
      "offset": 1157.039,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "artifacts, data sets along the way. Um,",
      "offset": 1158.64,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "you can you can check that out there.",
      "offset": 1161.12,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "Um, one more thing is, uh, we have a",
      "offset": 1162.88,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "Discord that's open. We have an open",
      "offset": 1165.44,
      "duration": 2.64
    },
    {
      "lang": "en",
      "text": "source project for training",
      "offset": 1166.96,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "reinforcement learning models. Um we",
      "offset": 1168.08,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "have a discord you can go to if you're",
      "offset": 1170.16,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "interested in this kind of thing. Um we",
      "offset": 1172.16,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "we're all in there. We answer questions.",
      "offset": 1174,
      "duration": 2.48
    },
    {
      "lang": "en",
      "text": "There's lots of people from the",
      "offset": 1175.6,
      "duration": 2.8
    },
    {
      "lang": "en",
      "text": "community trying to do these things. So",
      "offset": 1176.48,
      "duration": 3.439
    },
    {
      "lang": "en",
      "text": "if uh if you're interested in building",
      "offset": 1178.4,
      "duration": 2.96
    },
    {
      "lang": "en",
      "text": "things with this um feel free to join",
      "offset": 1179.919,
      "duration": 3.521
    },
    {
      "lang": "en",
      "text": "it. And yeah, happy happy to chat there.",
      "offset": 1181.36,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "And um yes, thank you everyone. Uh",
      "offset": 1183.44,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "appreciate your time.",
      "offset": 1185.6,
      "duration": 3.36
    }
  ],
  "cleanText": "[Music]\n\nUm, hey everyone.\nGlad you're all here.\nThis is the reasoning and reinforcement learning track on the afternoon of the last day of the AI Engineer World's Fair.\nGlad you're sharing it with us.\nToday, what I'm going to talk about is a very specific case study that we did.\nUh, this case study, I'm going to talk about lessons learned very concretely.\nUm, what did and didn't work, how we able to build an agent that worked well with reinforcement learning.\nUh, all of this, everything that I'm talking about in this presentation, this is an open-source codebase that we built.\nUm, we wanted to share these learnings and I'll I'll share that link with you at the end as well for those of you who want to replicate what we did.\nUm, so what is the project we're going to be talking about?\nIt's a project called ART-E.\nIt is a natural language assistant that helps you answer questions from your email inbox.\nSo I'll give you an example of what we're talking about here.\nUm, let's say you want to ask, you know, in this case our example question is when is Sherry's move to Portland targeted for?\nSo you would ask this question to the assistant.\nIt then goes and it searches your inbox.\nIt's got several tools.\nSo it has like a search tool, it has a read email tool, and then it can actually answer the final question.\nYou can kind of see if you if you look here what's going on behind the scenes.\nThis is important so you get a sense of kind of how this agent works and as we're talking through how we built it, how we made it work.\nUm, hopefully that that helps make the conversation very grounded in a specific task.\nSo anyway, you see the agent, it's it's you know searching for certain keywords.\nIt get those messages back.\nIt's in reading one of them and and answering the question.\nThat's that's what it does.\nOkay.\nSo um question, you know, once once we've decided this is kind of the the task we're trying to solve, why would you re use reinforcement learning for this specifically?\nUm and uh and the answer is like to start with you shouldn't.\nIn fact to start off with we did not.\nUm so the first version of this agent once we decided we wanted to build this we did we didn't use any reinforcement learning at all.\nWe purely built this on prompted models and this is the first lesson from this talk uh that I want to share is I would generally always recommend starting with getting the best performance you can with a prompted model before going to any training including reinforcement learning.\nThere's a few different reasons to do that, three in specifically.\nUm, the first one is just like working out the bugs in your environment, right?\nUm, you know, maybe your tools aren't implemented properly, maybe they don't have access to the data you think they do.\nUm, we find this happens a lot and it's a lot less frustrating to debug that uh you know, separately from debugging your your training loop.\nSo you want to make sure that like you can get at least some kind of performance um before you start training.\nUm and then second of all, you may find as you're trying to improve the performance on uh on using these prompted models that uh you can get it working really well and that's great.\nSo that means you don't need to train anything.\nUm and that saves you a lot of time.\nUm there's a third reason as well uh that I'll share which is uh basically once you've gone to that effort, you've done your best to get the best quality prompted baselines you possibly can.\nUm then uh if you find that those baselines are not able to get you where you need to go and you're able to surpass them with re reinforcement learning, it feels great.\nYou get to glow and be like, \"Yes, I was able to beat the the frontier models on my task.\"\nUm this this I I highly recommend it.\nFeels good.\nYou can you can like post on X about it.\nThere's there's nice, you know, graphs and stuff.\nSo, this is this is what it looks like when everything goes right.\nUm, so this is an example of a training run for this ART-E model that I'm going to be talking about.\nUh, you can see that there's these these lines for each of the prompted model baselines that we've got.\nUm, so we've got o3, o4-mini, and then Gemini and and 4.1.\nAnd you can see uh those ones, you know, they have certain level performance.\nAnd then you can see this this uh sort of moving line um that's going on.\nThis is the model that we trained.\nAnd you can see it actually starts out significantly worse than these other models uh from from the start.\nThat's because we started from a Quen 2.5 the 14 billion parameter one.\nIt's a relatively small model, relatively weak model.\nUm and so it was doing much worse than these initially, but you can see as training progresses um you know initially at the beginning it it's sort of maybe maybe there's it's learning the right way to do tool calls.\nThere's a very sharp bump as it figures out the basic stuff and then a more gradual climb until eventually it's able to significantly outperform uh any of the prompted models on this task.\nAnd this is sort of what you're you know in the ideal case when everything works this this is what you're looking for.\nThis is what what you're hoping to achieve.\nUm this is another view actually of that same data we were just looking at.\nUm I I like I wanted to highlight it in this way because it's important to realize.\nSo on the last graph it looked like the the lines sort of asmtote out pretty close together.\nThat's because they're getting near 100%.\nBut the last um you can see for example with our best prompted model here o3 uh it's 90% accuracy and with our RL model we're able to get up to 96%.\nAnd so one way to think about that is like 60% of the errors that o3 was making um are are actually solved with our model.\nUm which is which is quite a large uh you know we find that that's actually can be very very important for the user experience of someone using one of these um if you're getting you know just half as many errors uh that that can make the product much stronger.\nUm so this is this is where we got to on accuracy.\nThere's a couple other metrics that we find are often very very important.\nUm and you know the trade-off between these does does is very task dependent but but they matter in many cases.\nUm cost obviously is a big one.\nSo for for this email agentic harness that we had we benchmarked the cost on o3, o4-mini and our model.\nSo if you wanted to do like a thousand searches using o3 that's going to cost $55.\nUm which is a lot.\nI think for most use cases that probably would be cost prohibitive just from a unit economics point of view.\nUm on o4-mini we're down to $8 but that's still quite expensive.\nAnd then we drop another order of magnitude by moving to this smaller Quen 2.514B.\nAgain, this is just driven it by being it being a much smaller model.\nSo it's it's much cheaper to run.\nUm but we're still able to get very good performance because we've specialized it on our task.\nUm beyond cost and the accuracy, um the third metric that often comes up is latency.\nUh particularly if you're doing I mean certainly anything with voice, but if there's any real-time human interaction with the task, latency is going to matter a lot.\nUm, and we were able to find on on this task we were able to get significantly better latency.\nThere's a number of different ways which I'll go into in more detail later that we were able to achieve this.\nUm, you know, one was just again moving to a smaller model helps.\nThere's just less less loading from memory, less matrix multiplies.\nIt's just you're able to get tokens out faster.\nUm, we were also able to train this model to have fewer turns going back and forth with the database with the actual email um the list of emails.\nUh, we we were able to train it to be more efficient with its queries.\nUm, and I'll go to that in a moment.\nAnd so that that leads to lower latency.\nUm there's actually a third thing which we didn't apply here but can help a lot with these smaller things which is called speculative decoding.\nThat's something you can do on large or small models.\nIt generally works better on smaller task specific models because you get higher um acceptance rates on on your speculator.\nBut basically um there's there's lots of reasons why smaller models work better.\nUm okay.\nSo then the next question uh for those of you who haven't done this yet is like okay what is the effort required to do this to actually achieve these results?\nUm, if you'd asked me this question a year ago, I would say, \"Hey, you should really only be doing this if you know you're this big company and willing to put, you know, months of of work into a project.\"\nI think that's changing.\nI honestly do.\nUm, in this case, uh, so this this training run, it cost us about $80 in GPU time.\nIt did take about a week of engineering time to build this.\nAnd and caveat that was with an engineer who is familiar with this domain and and had quite a lot of experience uh, you know, with machine learning and RL.\nUm but I actually expect as as we figure out the right patterns here collectively as an industry this will keep dropping.\nUm and I expect that uh you know the sort of payback period to get a return on investment from these specialized models is actually going to continue falling as well.\nUm and uh you know part of part of the reason I wanted to give this talk is to sort of distribute that know the knowledge we learned and hopefully move faster towards that that world where this is just sort of like a thing everyone knows how to do and it's very easy and very fast.\nUm, so that's that's what we'll be talking about for the rest of time is is some more of the lessons we learned.\nUm, okay.\nSo, uh, when you are using RL to train an agent or really using RL for anything else, um, I find that consistently with different problems we look at, there are there are sort of two hard problems that come up every single time.\nAll right?\nUm, and the two hard problems are first of all figuring out a realistic environment, right?\nSo if you're training an agent, you need to be training it with realistic data, with realistic inputs and outputs, tools available, everything like that to how it's going to be used in production.\nUm because if you don't, then it's going to be optimizing for the wrong thing and and you won't get the results you want when you deploy it.\nAnd then the second thing which sometimes is hard um sometimes isn't this one is a little bit test dependent is getting the right reward function.\nSo reward function that just means you have to be able to know when your agent's gone through and say in this case give it an answer to my email.\nYou have to have some way of knowing did it do a good job or a bad job.\nAll right, that's the reward function.\nIt decides it it it's it's how you decide if it's good or it's bad.\nUm some depending on the domain sometimes that's really easy.\nWe have I don't know if Nathan's here, he's going to be talking next, but um you know he and his team put together this thing called RLVR which in some verifiable domains it's actually very easy to do a reward.\nOften times uh not all domains are like that.\nOftentimes it is kind of hard.\nUm, and so it's it's somewhat task dependent.\nI'm going to go through how we solve these problems specifically with RE.\nOkay, first one, realistic environment.\nSo for our RE task, what is the environment we need?\nWhat is the environment this agent's going to be operating in?\nWell, it needs these tools available.\nIt needs to be able to go and query an email inbox.\nIt needs to be able to like get emails back um and and that look realistic.\nThese emails, you know, the inbox should be large because that's what most email inboxes are like.\nUm the emails in it should be diverse and they have to look kind of like real emails.\nUm so this could be kind of hard because you can't just go ask like a thousand people to you know give you uh their their their personal emails to train on.\nUm luckily in this case we were able to solve this with the help of a company that has contributed a lot um to just the open data ecosystem uh generally.\nIt's it's like a quite an iconic company perhaps I would call it a historic company.\nUm I'm of course talking about Enron.\nUm\nI'm hearing some laughter.\nSo anyway, Enron was a uh they were a financialized energy company in the '9s and 2000s, committed massive fraud, ended up getting shut down by the Department of Justice.\nAs part of this uh um you know, process, the the the court cases they were going through.\nUm a dump of like 500,000 of their emails was released to the public as part of the discovery process.\nUm so that's that's that's great for things like this and that's what we used as our environment for the email inboxes.\nAll right.\nSo now we've got realistic email inboxes um with tens of thousands of emails that are real emails back and forth.\nNow we have to design our reward function.\nSo as our agent is going and as our agent is um you know we're asking it questions and then it's giving us answers, we have to know is the answer correct or not so we can reward it when it gets the answer right and it can learn to do that better.\nThere's different ways and this part is very task dependent.\nUm the way that we went about it in this case um was we basically turned it into a more of a verifiable problem.\nAnd the way we did that was we actually took our email inbox.\nWe sort of inverted the problem.\nWe um we grabbed batches of 20 emails at a time uh from the inbox and gave them to Gemini 2.5 Pro and said, \"Hey, given this set of emails, give us a few questions that a user might realistically ask that the answers are found in this email.\"\nRight?\nAnd so Gemini generated the questions, it generated the answers, and then of course the the source emails that came from.\nUm, and there were some extra steps on top of that.\nA lot of the questions it came up with looked a little bit unrealistic.\nWe had a separate filtering step where we're like, okay, let's find the subset of these that that actually look like questions that, you know, I would maybe ask.\nAnd we ended up with a list of a few thousand questions um along with their verified answers.\nUm, and so at this point, it becomes much more of a a sort of verified thing.\nThe reward function becomes much easier because we know what the correct answer should be.\nAnd so the way we can tell if our agent did a good job is we give our agent the question, we let it go and search the email inbox and try and\n\n\nFind the right emails and everything.\nAnd eventually it comes back with an answer.\nAnd then we can just use an LLM as judge, a very simple one, and say like, hey, you know, here's the question.\nHere's the the golden answer that that we believe is right.\nHere's the answer we got from our from our model.\nIs it right or not?\nUm, we did have to do a little bit of uh iteration there making sure that the judge was well calibrated on like what you know what what counts as as correct or not, but by and large this worked pretty well, um, and was able to make this more of a verified task.\nUm, so that's how that's how we solved the the reward function problem was by having that you know turning this into something where we had more of a golden data set.\nUm, okay.\nSo, once you've solved that problem, those problems, once you have your environment, once you have um your your reward function defined, then basically you just kind of have to run a loop over and over and over again where you have your agent go through and it tries to um solve the problem and then you figure out if it's good or it's bad.\nUm, and then you just uh you know, reward if it's if it's good and punish if it's bad, and that's it.\nUm, and uh, you do this over and over and over again.\nAnd then hopefully if you've got everything set up right, um, it learns what good looks like, it learns what bad looks like, um, and it starts doing it right.\nUm, and then again, this is this is the curve we saw earlier where where you can see it it it starts getting better over time.\nUm, okay, a few other like interesting learnings from this project.\nUm, one thing is we found that there's actually you can throw a lot of stuff into your reward function uh beyond just the primary thing you're trying to solve for.\nAnd so we actually ended up we there were like sort of eight different little things that we gave extra credit for.\nUm, and I'm going to share two of them here.\nSo the first one here is um is we were trying to have it optimized for the number of turns, how many times back and forth, how many times it had to query the email inbox before it came up with the right answer.\nRight?\nSo, because the most important thing, of course, is is getting the answer right, but between two answers that both get it right, we would rather it took fewer turns back and forth because that's fewer tokens, that's lower latency, lower costs.\nUm, it's just like a more efficient agent.\nSo, um, so you can see here on this first graph that early on, while was getting its feet wet and figuring out what worked, it it ended up spiking up to over six turns on average.\nSo, it would go back and forth a bunch of times with the email inbox and and try and find the right thing.\nBut then once it was able to like figure out how to use the tools efficiently, figure out like you know the the right way to construct keywords and find the right email, it was able to get very efficient and actually fast uh better than any of our prompted models uh on this metric of um using fewer turns.\nAnd again, this was just because we gave it a little bit of extra.\nIt was it was a very small amount relative to the reward for getting it right, but a little bit of extra credit on on using for fewer turns and it was able to to use that um to to optimize against that.\nUm, another extra reward function we gave it is um to try and discourage it from hallucinating answers.\nSo, um, obviously the best thing is to get the right answer.\nIf you can't find the right answer, it's much better to say, hey, I don't know, than to make up an answer in in a situation like this.\nSo, we basically penalized it if um if the reward model said, \"Hey, you got the answer wrong.\"\nAnd but it had tried to get an answer give an answer, that was like a much lower reward than if it just said, \"Hey, I don't know.\nI can't solve this problem.\"\nAnd as you can see, that worked quite well.\nUm, compared to any of the prompted models, including 03, we ended up with a significantly lower hallucination rate because that was part of our reward function.\nUm, again, these are these are things that are just sort of like extra credit, but um, we found that like you can throw in a bunch of these and and it can jointly optimize all of them at the same time, which is super powerful.\nOkay, I want to talk a little bit about reward hacking.\nUm, it's it's something that comes up a lot when you're trying to do this, and it's kind of a fun thing to talk about.\nUm this is an iconic video some of you might have seen.\nUh this was released by OpenAI almost a decade ago at this point of um they were they were trying to uh they had this environment where you were trying to uh get this boat to complete a race and instead of learning to complete uh complete the race it learned that oh if I just go in this like little circle that's not even part of the racetrack I can like just get a bunch of points.\nUm and so it just started doing that over and over and over again instead of like actually following.\nUm, this is something that comes up a lot if you're doing reinforcement learning.\nAnd it's basically just the difference between um, uh, the difference between what you actually want the model to do and what you can measure.\nUm, like what you're actually rewarding it for.\nAnd, and if you almost always, if you let one of these run long enough, it will figure out some way to exploit your measure.\nUm, and it will figure out some way to to get a really high reward um, without actually solving the problem.\nAnd you need to just watch for that.\nSo, I'm going to give a couple examples here.\nUm this is a this is a graph um from another project actually not this one.\nUh so an engineer on our team was uh was working on this game called NYT connections.\nSome of you might know you get 16 words and you have to put them in like four groups of four.\nIt's quite a challenging game especially for these language models because it requires a lot of world knowledge and like you know lateral thinking.\nAnyway, um so so they were trying to train this model to do it and uh it wasn't figuring out wasn't figuring out.\nwhat if it wasn't figured out?\nAnd then boom, you you can see here around step 40, it just like takes off and it's like, okay, we figured out how to how to solve this and and this engineer I'm I'm going to I'm going to call out where's where's where's An on our team?\nHe's here at the conference.\nYeah, he's great.\nYou should talk to him after.\nBut um he was like, hey, we we we solved it.\nLike we got NYT connections and like and it's like, okay, the graph looks good.\nLet's look at what it's actually doing.\nWhat it was actually doing is it had figured out there was a bug in how we wrote the verification.\nAnd if it just put every single word in every single category, it was able to get a perfect score.\nUm because we weren't verifying that they were in fact only four words uh in each category.\nUm so this is another example.\nThis is a fun one.\nSo I was I was training a model um to produce really good titles for hacker news um titles that would get a thing upvoted.\nSo I had this reward model I'd trained on like existing hacker news um articles and how many up votes they got.\nAnd I was I was trying to train this model to produce new titles and it was working really well for a while.\nYou can see and and sort of subjectively as well.\nI I looked at a bunch of these these titles generated and and for these first like thousand steps or so, it was actually learning things that I was like, \"Okay, as someone who spends way too much time on Hacker News, yeah, that that does look like a good title.\nYou're you're doing a good job.\"\nAnd then you can see around step um 1200 here, it just like jumps a bunch, right?\nIt's like, \"Okay.\"\nUm it clearly figured something out.\nI don't know what it figured out.\nUm but we should look at that.\nUm, and so, uh, what it turns out what the model had figured out was that it could just completely ignore the content of the post and generate the same title for every single one of them and that would like maximize its score.\nSo, it generated this title, Google lays off 80% of workforce, literally every single article, this was this was what it labeled it as.\nAnd was like, yes, that is going to get up on HackerNews for sure, which which it probably would to be fair.\nUm so so anyway the way the way we solved this um what we found is that it's it's really important to watch out for this solving it typically involves modifying in some way your reward function to penalize things like that.\nSo in the second example I talked about it was actually quite an easy fix once we identified it um which was just add an extra LMS judge that looked at the title looked at the content and said hey is there anything in the title that's not supported by the content and we added that on and and it it actually worked great.\nUm, the important thing here is you want to be looking at your your rollouts, not just blindly trusting the reward function, figuring out what's actually happening.\nUm, anyway, so, uh, that's it.\nUm, I'm I'm almost out of time, so I'm going to stop.\nCouple of QR codes for you.\nUm, everything in this presentation, and there's a much longer write up I have of this whole project.\nIt includes the code.\nIt includes the artifacts, data sets along the way.\nUm, you can you can check that out there.\nUm, one more thing is, uh, we have a Discord that's open.\nWe have an open source project for training reinforcement learning models.\nUm we have a discord you can go to if you're interested in this kind of thing.\nUm we we're all in there.\nWe answer questions.\nThere's lots of people from the community trying to do these things.\nSo if uh if you're interested in building things with this um feel free to join it.\nAnd yeah, happy happy to chat there.\nAnd um yes, thank you everyone.\nUh appreciate your time.\n",
  "dumpedAt": "2025-07-21T18:43:25.327Z"
}