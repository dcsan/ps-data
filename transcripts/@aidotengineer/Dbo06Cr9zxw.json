{
  "episodeId": "Dbo06Cr9zxw",
  "channelSlug": "@aidotengineer",
  "title": "Building AI Products That Actually Work - Ben Hylak, Sid Bendre",
  "publishedAt": "2025-06-21T17:00:06.000Z",
  "rawLines": [
    {
      "lang": "en",
      "text": "[Music]",
      "offset": 4.16,
      "duration": 3.099
    },
    {
      "lang": "en",
      "text": "Uh my name is Ben Hilac and uh also just",
      "offset": 15.36,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "feeling really grateful to be with all",
      "offset": 18.24,
      "duration": 3.119
    },
    {
      "lang": "en",
      "text": "of you guys today. Uh it's pretty",
      "offset": 19.6,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "exciting and we're here to talk about",
      "offset": 21.359,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "building AI products that actually work.",
      "offset": 24.72,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "Um I'll introduce this guy in a second.",
      "offset": 27.359,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "Sorry, it wasn't the right word. Uh, so",
      "offset": 29.039,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "I tweeted last night. I was kind of",
      "offset": 31.119,
      "duration": 2.801
    },
    {
      "lang": "en",
      "text": "like, what should we uh what should we",
      "offset": 32.559,
      "duration": 3.361
    },
    {
      "lang": "en",
      "text": "talk about today? Uh, and the",
      "offset": 33.92,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "overwhelming response I got was like,",
      "offset": 35.92,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "please no more evalu. Uh, apparently",
      "offset": 37.68,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "there's a lot of eval tracks. We'll",
      "offset": 39.68,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "touch on eval still just a little bit,",
      "offset": 41.44,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "but mainly we're going to be focusing on",
      "offset": 43.28,
      "duration": 5.92
    },
    {
      "lang": "en",
      "text": "how to iterate on AI products. And so I",
      "offset": 46.32,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "think iteration is actually one of the",
      "offset": 49.2,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "most important parts of building AI",
      "offset": 51.36,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "products that actually work. So again,",
      "offset": 53.76,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "just a little bit about us. So, I'm the",
      "offset": 56.32,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "CTO of a company called Raindrop. And",
      "offset": 58.16,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "Raindrop helps companies find and fix",
      "offset": 60.16,
      "duration": 5.84
    },
    {
      "lang": "en",
      "text": "issues in their AI products. Uh, before",
      "offset": 63.44,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "that, I was actually kind of a weird",
      "offset": 66,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "background, but I used to be really into",
      "offset": 67.6,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "robotics. I did avionics at SpaceX for a",
      "offset": 69.04,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "little bit. Um, and then most recently,",
      "offset": 71.68,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "I was an engineer and then on the design",
      "offset": 73.68,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "team at Apple for almost four years.",
      "offset": 75.68,
      "duration": 5.759
    },
    {
      "lang": "en",
      "text": "And, uh, we also have Sid. So, uh, in",
      "offset": 78.4,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "the spirit of",
      "offset": 81.439,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "sharing how to build things that",
      "offset": 83.92,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "actually work, uh, I brought Sid, who",
      "offset": 85.36,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "actually knows how to build products",
      "offset": 88.24,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "that actually work. So, I think Sid is",
      "offset": 89.52,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "like, uh, the co-founder of a company",
      "offset": 91.36,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "called Alie. Um, with just four people,",
      "offset": 93.28,
      "duration": 6.479
    },
    {
      "lang": "en",
      "text": "they grew a suite of viral apps to over",
      "offset": 97.36,
      "duration": 4.799
    },
    {
      "lang": "en",
      "text": "six million AR. So, Sid is going to",
      "offset": 99.759,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "share again how to build products that",
      "offset": 102.159,
      "duration": 5.32
    },
    {
      "lang": "en",
      "text": "actually work.",
      "offset": 104.079,
      "duration": 3.4
    },
    {
      "lang": "en",
      "text": "I think it's actually a really exciting",
      "offset": 108,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "time for AI products. And I say it's an",
      "offset": 109.52,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "exciting time because in the last year,",
      "offset": 111.28,
      "duration": 5.92
    },
    {
      "lang": "en",
      "text": "we've seen that it's possible to really",
      "offset": 114.96,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "focus on a use case, really focus on",
      "offset": 117.2,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "something and make that thing",
      "offset": 119.36,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "exceptional, like really really crack",
      "offset": 121.2,
      "duration": 4.879
    },
    {
      "lang": "en",
      "text": "it. Um, we've seen that it's possible to",
      "offset": 123.28,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "train like small models, really really",
      "offset": 126.079,
      "duration": 5.201
    },
    {
      "lang": "en",
      "text": "tiny models to just be exceptional at",
      "offset": 128.64,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "specific tasks if you focus on a",
      "offset": 131.28,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "specific use case. And we're also seeing",
      "offset": 133.68,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "that increasingly providers right are",
      "offset": 135.599,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "actually focusing on on launching those",
      "offset": 138.16,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "sort of products which is you know that",
      "offset": 140,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "might be the scary part. Um but deep",
      "offset": 141.68,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "research is a great example right where",
      "offset": 144.4,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "chat GPT just focused on how do we you",
      "offset": 146.4,
      "duration": 5.199
    },
    {
      "lang": "en",
      "text": "know how do we collect a data set how do",
      "offset": 149.76,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "we train something to just be",
      "offset": 151.599,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "exceptionally good at searching the web",
      "offset": 153.2,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "and they were I think it's one of the",
      "offset": 155.28,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "best products that they've released",
      "offset": 156.48,
      "duration": 6.08
    },
    {
      "lang": "en",
      "text": "but even open AAI is not immune to",
      "offset": 159.12,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "shipping like not so great products",
      "offset": 162.56,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "right I think like to me I I don't know",
      "offset": 164.56,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "uh what your guys' experience is but I",
      "offset": 167.04,
      "duration": 2.8
    },
    {
      "lang": "en",
      "text": "think that like I've actually had a lot",
      "offset": 168.64,
      "duration": 2.72
    },
    {
      "lang": "en",
      "text": "of trouble with codeex and I don't know",
      "offset": 169.84,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "that it's like exceptionally better than",
      "offset": 171.36,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "uh other things that exist. Like this is",
      "offset": 174.16,
      "duration": 2.799
    },
    {
      "lang": "en",
      "text": "kind of a funny one. I was like write",
      "offset": 175.76,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "some tests and it it actually correctly",
      "offset": 176.959,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "generated this hash for the word hello,",
      "offset": 180,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "you know, but it's like I'm not sure",
      "offset": 182.239,
      "duration": 2.321
    },
    {
      "lang": "en",
      "text": "this is like, you know, when I think",
      "offset": 183.44,
      "duration": 2.4
    },
    {
      "lang": "en",
      "text": "about writing tests for my back end, I'm",
      "offset": 184.56,
      "duration": 2.48
    },
    {
      "lang": "en",
      "text": "not sure that this is what I wanted,",
      "offset": 185.84,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "right? Um",
      "offset": 187.04,
      "duration": 5.119
    },
    {
      "lang": "en",
      "text": "and it's not just open AI, right? Like I",
      "offset": 189.68,
      "duration": 5.199
    },
    {
      "lang": "en",
      "text": "think that increasingly in the last",
      "offset": 192.159,
      "duration": 4.961
    },
    {
      "lang": "en",
      "text": "year, AI products still even in the last",
      "offset": 194.879,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "couple months, couple weeks, like",
      "offset": 197.12,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "there's all these weird issues like",
      "offset": 198.959,
      "duration": 3.521
    },
    {
      "lang": "en",
      "text": "Yeah, this is a funny one, right? So,",
      "offset": 200.72,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "Virgin Money, their chatbot was",
      "offset": 202.48,
      "duration": 3.759
    },
    {
      "lang": "en",
      "text": "threatening to cut off their customers",
      "offset": 204.8,
      "duration": 6.24
    },
    {
      "lang": "en",
      "text": "for using the word virgin, right? So, uh",
      "offset": 206.239,
      "duration": 6.801
    },
    {
      "lang": "en",
      "text": "just the other day I was using uh uh",
      "offset": 211.04,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "Google Cloud and I asked it where my",
      "offset": 213.04,
      "duration": 2.88
    },
    {
      "lang": "en",
      "text": "credits are and it was like, &quot;Are you",
      "offset": 214.72,
      "duration": 2.799
    },
    {
      "lang": "en",
      "text": "talking about Azure credits or Roblox",
      "offset": 215.92,
      "duration": 2.64
    },
    {
      "lang": "en",
      "text": "credits?&quot; You know, and I was like,",
      "offset": 217.519,
      "duration": 3.201
    },
    {
      "lang": "en",
      "text": "&quot;What? How is this possible?&quot; It's funny",
      "offset": 218.56,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "because I tweeted this and it's like,",
      "offset": 220.72,
      "duration": 2.56
    },
    {
      "lang": "en",
      "text": "&quot;This isn't just a one-off thing, right?",
      "offset": 221.68,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "Like someone's like, &quot;Oh, yeah. This",
      "offset": 223.28,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "exact same thing happened to me, right?&quot;",
      "offset": 225.12,
      "duration": 4.479
    },
    {
      "lang": "en",
      "text": "Um",
      "offset": 228.08,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "just a few weeks ago Grock had this",
      "offset": 229.599,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "crazy thing right where people were",
      "offset": 231.44,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "asking in this case about enterprise",
      "offset": 232.879,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "software and it's like oh by the way you",
      "offset": 234.72,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "know let's talk about uh the you know",
      "offset": 237.04,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "claims of white genocide in South Africa",
      "offset": 238.72,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "you know just completely off off the",
      "offset": 241.04,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "rails here and we only see we only",
      "offset": 242.879,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "caught something like this only kind of",
      "offset": 245.92,
      "duration": 3.599
    },
    {
      "lang": "en",
      "text": "entered the public you know awareness",
      "offset": 247.2,
      "duration": 4.239
    },
    {
      "lang": "en",
      "text": "because Grock is public and because you",
      "offset": 249.519,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "can kind of see everything. Funny",
      "offset": 251.439,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "enough, um I I actually tweet a lot",
      "offset": 253.599,
      "duration": 2.961
    },
    {
      "lang": "en",
      "text": "about, if you follow me, you know I",
      "offset": 255.28,
      "duration": 2.959
    },
    {
      "lang": "en",
      "text": "tweet a lot about AI products and where",
      "offset": 256.56,
      "duration": 4.239
    },
    {
      "lang": "en",
      "text": "they fail. And so last night when I was",
      "offset": 258.239,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "like rushing to get this presentation,",
      "offset": 260.799,
      "duration": 4.641
    },
    {
      "lang": "en",
      "text": "my part of Hit done, uh I asked it to",
      "offset": 262.639,
      "duration": 4.241
    },
    {
      "lang": "en",
      "text": "find tweets of mine about AI failures",
      "offset": 265.44,
      "duration": 2.88
    },
    {
      "lang": "en",
      "text": "and it says, I don't have access to your",
      "offset": 266.88,
      "duration": 2.96
    },
    {
      "lang": "en",
      "text": "personal Twitter. I can't search tweets.",
      "offset": 268.32,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "I was like, I think I can. So I I double",
      "offset": 269.84,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "down. I'm like, you are literally Grock,",
      "offset": 272.4,
      "duration": 2.64
    },
    {
      "lang": "en",
      "text": "you know, like this is what you're made",
      "offset": 273.84,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "for. And it's like, oh, you're right. I",
      "offset": 275.04,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "can I just don't have your username, you",
      "offset": 276.96,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "know? So it's absurd. And I actually",
      "offset": 279.28,
      "duration": 3.359
    },
    {
      "lang": "en",
      "text": "like like this is this is yesterday,",
      "offset": 281.12,
      "duration": 2.799
    },
    {
      "lang": "en",
      "text": "right? this is still a bug that they",
      "offset": 282.639,
      "duration": 3.441
    },
    {
      "lang": "en",
      "text": "have.",
      "offset": 283.919,
      "duration": 4.961
    },
    {
      "lang": "en",
      "text": "So, I feel really lucky to be, you know,",
      "offset": 286.08,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "like like I mentioned, I I I'm a CTO,",
      "offset": 288.88,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "co-founder of a company called Raindrop",
      "offset": 291.12,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "and we're in this really cool position",
      "offset": 293.12,
      "duration": 3.519
    },
    {
      "lang": "en",
      "text": "where we get to work with some of the",
      "offset": 295.36,
      "duration": 3.279
    },
    {
      "lang": "en",
      "text": "coolest, fastest growing companies in",
      "offset": 296.639,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "the world and just a huge range of",
      "offset": 298.639,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "companies. So it's everything from you",
      "offset": 300.479,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "know apps like SIDS which he'll share",
      "offset": 302.24,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "about to things like clay.com you know",
      "offset": 304.08,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "which is like a sales sort of outreach",
      "offset": 306.639,
      "duration": 5.441
    },
    {
      "lang": "en",
      "text": "tool to like alien companion apps to",
      "offset": 308.24,
      "duration": 5.679
    },
    {
      "lang": "en",
      "text": "coding assistance. It's just this insane",
      "offset": 312.08,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "range of products and so I get I think",
      "offset": 313.919,
      "duration": 5.361
    },
    {
      "lang": "en",
      "text": "we get to see so much of like what works",
      "offset": 316.24,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "what doesn't work.",
      "offset": 319.28,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "We are also like it's not just all",
      "offset": 321.36,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "secondhand like we also have a massive",
      "offset": 323.199,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "uh AI pipeline where you know every",
      "offset": 326.56,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "single event that we receive is being",
      "offset": 328.479,
      "duration": 3.761
    },
    {
      "lang": "en",
      "text": "analyzed is being kind of divvied up in",
      "offset": 330.32,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "some way and we're kind of like you know",
      "offset": 332.24,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "we have this product we're also kind of",
      "offset": 334.72,
      "duration": 3.759
    },
    {
      "lang": "en",
      "text": "this like stealth frontier lab of some",
      "offset": 336.16,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "sort of where we are kind of shipping",
      "offset": 338.479,
      "duration": 3.121
    },
    {
      "lang": "en",
      "text": "some of the coolest AI features I've",
      "offset": 340.24,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "ever seen. Um we have like tools like",
      "offset": 341.6,
      "duration": 3.439
    },
    {
      "lang": "en",
      "text": "deep search that allows people to go",
      "offset": 343.36,
      "duration": 3.119
    },
    {
      "lang": "en",
      "text": "really deep into their production data",
      "offset": 345.039,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "and build just classifiers from just a",
      "offset": 346.479,
      "duration": 5.681
    },
    {
      "lang": "en",
      "text": "few examples. So, it's been cool to sort",
      "offset": 348.96,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "of build this intuition both from",
      "offset": 352.16,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "firsthand from our customers and kind of",
      "offset": 353.6,
      "duration": 4.879
    },
    {
      "lang": "en",
      "text": "merge that and I think we've we've have",
      "offset": 356,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "a pretty good intuition of what actually",
      "offset": 358.479,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "works right now.",
      "offset": 359.84,
      "duration": 6.079
    },
    {
      "lang": "en",
      "text": "One question I get a lot is",
      "offset": 362.08,
      "duration": 5.839
    },
    {
      "lang": "en",
      "text": "will it get easier to make AI products,",
      "offset": 365.919,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "right? Like how much of this is just a",
      "offset": 367.919,
      "duration": 3.521
    },
    {
      "lang": "en",
      "text": "moment in time? I think this is a very",
      "offset": 369.199,
      "duration": 3.361
    },
    {
      "lang": "en",
      "text": "very interesting question and I think",
      "offset": 371.44,
      "duration": 3.599
    },
    {
      "lang": "en",
      "text": "the answer is actually twofold, right?",
      "offset": 372.56,
      "duration": 4.479
    },
    {
      "lang": "en",
      "text": "So, the first answer is yes. Like yes,",
      "offset": 375.039,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "it will get easier. Uh, and we know this",
      "offset": 377.039,
      "duration": 4.481
    },
    {
      "lang": "en",
      "text": "because we've seen it. A year ago, you",
      "offset": 379.12,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "had to give, you know, threaten to kill",
      "offset": 381.52,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "your, you know, GPG4 in order to get it",
      "offset": 383.52,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "to output JSON, right? Like it was like",
      "offset": 386.16,
      "duration": 2.879
    },
    {
      "lang": "en",
      "text": "you have to threaten to kill its",
      "offset": 388.16,
      "duration": 2.64
    },
    {
      "lang": "en",
      "text": "firstborn or something. And now it's",
      "offset": 389.039,
      "duration": 3.521
    },
    {
      "lang": "en",
      "text": "just like a parameter in the API. Like",
      "offset": 390.8,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "you're just like, in fact, here's the",
      "offset": 392.56,
      "duration": 3.199
    },
    {
      "lang": "en",
      "text": "exact schema I want you to output. It",
      "offset": 394.4,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "just works. So those sort of things will",
      "offset": 395.759,
      "duration": 4.241
    },
    {
      "lang": "en",
      "text": "get easier. But I think the second part",
      "offset": 397.68,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "of this answer is actually no. Like like",
      "offset": 400,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "in a lot of ways, it's not going to get",
      "offset": 401.84,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "easier. And I think that comes from the",
      "offset": 403.6,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "fact that communication is hard. like",
      "offset": 406,
      "duration": 5.039
    },
    {
      "lang": "en",
      "text": "communication is a hard thing. Um, what",
      "offset": 407.6,
      "duration": 6.719
    },
    {
      "lang": "en",
      "text": "do I mean by this? I actually um I'm a",
      "offset": 411.039,
      "duration": 4.961
    },
    {
      "lang": "en",
      "text": "big Paul Graham fan. I'm sure a lot of a",
      "offset": 414.319,
      "duration": 2.961
    },
    {
      "lang": "en",
      "text": "lot of us are, but I actually really",
      "offset": 416,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "really disagree with this. And the",
      "offset": 417.28,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "reason why is so so he says it seems to",
      "offset": 419.36,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "me AGI would mean the end of prompt",
      "offset": 421.52,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "engineering. Moderately intelligent",
      "offset": 423.12,
      "duration": 2.799
    },
    {
      "lang": "en",
      "text": "humans can figure out what you want",
      "offset": 424.72,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "without elaborate prompts. I don't think",
      "offset": 425.919,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "that's true. Like I I think that if you",
      "offset": 427.84,
      "duration": 3.359
    },
    {
      "lang": "en",
      "text": "can think of all the times, you know,",
      "offset": 430.08,
      "duration": 2.88
    },
    {
      "lang": "en",
      "text": "you've your partner has told you",
      "offset": 431.199,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "something and you've gotten it wrong,",
      "offset": 432.96,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "right? like you completely",
      "offset": 434.8,
      "duration": 3.119
    },
    {
      "lang": "en",
      "text": "misinterpreted what they wanted, right?",
      "offset": 436.08,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "What their goal was. If you think about",
      "offset": 437.919,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "onboarding a new hire, right? And like",
      "offset": 439.28,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "like you told them to do something and",
      "offset": 441.52,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "they come back, what what the hell is",
      "offset": 442.96,
      "duration": 4.239
    },
    {
      "lang": "en",
      "text": "this? Right? Um I think it's really",
      "offset": 444.56,
      "duration": 4.639
    },
    {
      "lang": "en",
      "text": "really hard to communicate what you want",
      "offset": 447.199,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "to someone, especially someone that",
      "offset": 449.199,
      "duration": 4.801
    },
    {
      "lang": "en",
      "text": "doesn't have a lot of context.",
      "offset": 450.88,
      "duration": 5.599
    },
    {
      "lang": "en",
      "text": "So yes, I think this is wrong.",
      "offset": 454,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "The other reason why I'm not sure it's",
      "offset": 456.479,
      "duration": 3.761
    },
    {
      "lang": "en",
      "text": "going to get that much easier in a lot",
      "offset": 458.16,
      "duration": 5.439
    },
    {
      "lang": "en",
      "text": "of ways is that as these models, as our",
      "offset": 460.24,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "products become more capable, there's",
      "offset": 463.599,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "just more undefined behavior, right?",
      "offset": 465.68,
      "duration": 3.359
    },
    {
      "lang": "en",
      "text": "There's more edge cases you didn't think",
      "offset": 467.52,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "about. And this is only becoming more",
      "offset": 469.039,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "true, you know, as our products have to",
      "offset": 470.96,
      "duration": 4.639
    },
    {
      "lang": "en",
      "text": "start integrating with other tools",
      "offset": 474.319,
      "duration": 3.121
    },
    {
      "lang": "en",
      "text": "through like MCP, for example. There's",
      "offset": 475.599,
      "duration": 3.521
    },
    {
      "lang": "en",
      "text": "going to be new data formats, new ways",
      "offset": 477.44,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "of doing things. So I I think that as",
      "offset": 479.12,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "our products become more capable, as the",
      "offset": 481.28,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "a as these models get more intelligent,",
      "offset": 483.039,
      "duration": 4.481
    },
    {
      "lang": "en",
      "text": "we're it's a little bit uh we're kind of",
      "offset": 485.84,
      "duration": 4.639
    },
    {
      "lang": "en",
      "text": "stuck in the same same situation.",
      "offset": 487.52,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "So this is this is how I like to think",
      "offset": 490.479,
      "duration": 3.521
    },
    {
      "lang": "en",
      "text": "about it. I think you can't define the",
      "offset": 492.16,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "entire scope of your product's behavior",
      "offset": 494,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "up front anymore. You can't just say",
      "offset": 496.72,
      "duration": 3.039
    },
    {
      "lang": "en",
      "text": "like, you know, here's the PRD, here's",
      "offset": 498.319,
      "duration": 2.72
    },
    {
      "lang": "en",
      "text": "the document of everything I want my",
      "offset": 499.759,
      "duration": 4.481
    },
    {
      "lang": "en",
      "text": "product to do. Like you actually have to",
      "offset": 501.039,
      "duration": 4.961
    },
    {
      "lang": "en",
      "text": "iterate on it. You have to kind of ship",
      "offset": 504.24,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "it, see what it does, and then iterate",
      "offset": 506,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "on it.",
      "offset": 507.68,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "So",
      "offset": 510.319,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "I think eval are a very very important",
      "offset": 511.84,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "part of this actually but I also think",
      "offset": 514.159,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "there's a lot of confusion. You know I",
      "offset": 517.12,
      "duration": 4.479
    },
    {
      "lang": "en",
      "text": "use the word lie is a little spicy but I",
      "offset": 519.599,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "think there's there's a lot of sort of",
      "offset": 521.599,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "misinformation around evals. So I'm not",
      "offset": 523.279,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "going to share I'm not going to like",
      "offset": 525.68,
      "duration": 2.96
    },
    {
      "lang": "en",
      "text": "rehash what eval are. I'm not going to",
      "offset": 526.959,
      "duration": 3.281
    },
    {
      "lang": "en",
      "text": "kind of go into all the details but I",
      "offset": 528.64,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "will talk about I think some like common",
      "offset": 530.24,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "misconceptions I've seen around evals.",
      "offset": 532,
      "duration": 6.16
    },
    {
      "lang": "en",
      "text": "So, one is that this idea that eval are",
      "offset": 534.64,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "going to tell you how good your product",
      "offset": 538.16,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "is. They're not. Um, they're really not.",
      "offset": 539.36,
      "duration": 3.039
    },
    {
      "lang": "en",
      "text": "Uh, if you're not familiar with",
      "offset": 541.44,
      "duration": 2.32
    },
    {
      "lang": "en",
      "text": "Goodart's law, it's like kind of the",
      "offset": 542.399,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "reason for this. Um,",
      "offset": 543.76,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "the eval that you collect are only the",
      "offset": 546.56,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "things you already know of. It's going",
      "offset": 548.24,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "to be easy to saturate them. If you look",
      "offset": 549.76,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "at recent model launches, a lot of them",
      "offset": 551.68,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "are actually performing lower on eval,",
      "offset": 553.44,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "you know, previous ones, but they're",
      "offset": 555.44,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "just way better in real world use. So,",
      "offset": 556.88,
      "duration": 4.959
    },
    {
      "lang": "en",
      "text": "it's not going to do this.",
      "offset": 558.72,
      "duration": 5.679
    },
    {
      "lang": "en",
      "text": "The other lie is this idea that like oh",
      "offset": 561.839,
      "duration": 4.241
    },
    {
      "lang": "en",
      "text": "okay well if you have a sort of like",
      "offset": 564.399,
      "duration": 3.281
    },
    {
      "lang": "en",
      "text": "imagine you have something like how",
      "offset": 566.08,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "funny is my joke you know that my app is",
      "offset": 567.68,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "generating. This is the example I always",
      "offset": 569.68,
      "duration": 3.279
    },
    {
      "lang": "en",
      "text": "hear used. You'll just like ask an LM to",
      "offset": 570.88,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "judge how funny your joke is. Um I this",
      "offset": 572.959,
      "duration": 6.32
    },
    {
      "lang": "en",
      "text": "doesn't work like largely does not work.",
      "offset": 576.64,
      "duration": 6.4
    },
    {
      "lang": "en",
      "text": "Uh uh they're tempting because you know",
      "offset": 579.279,
      "duration": 6.081
    },
    {
      "lang": "en",
      "text": "these LM judges take text as an input",
      "offset": 583.04,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "and they output a score they output a",
      "offset": 585.36,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "decision whatever it is. um like largely",
      "offset": 586.959,
      "duration": 5.681
    },
    {
      "lang": "en",
      "text": "the best companies are not doing this.",
      "offset": 590.64,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "They're they're not they're they're the",
      "offset": 592.64,
      "duration": 2.96
    },
    {
      "lang": "en",
      "text": "best companies are using highly curated",
      "offset": 594.08,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "data sets. They're using autogradable",
      "offset": 595.6,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "evals. Autogradable here meaning like",
      "offset": 597.44,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "you know there's some way of in some",
      "offset": 599.76,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "deterministic way figuring out if the",
      "offset": 601.6,
      "duration": 4.239
    },
    {
      "lang": "en",
      "text": "model passed or not. Um they're not",
      "offset": 603.68,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "really using LM as judges. Um there's",
      "offset": 605.839,
      "duration": 3.521
    },
    {
      "lang": "en",
      "text": "some edge cases here but just like",
      "offset": 608,
      "duration": 2.72
    },
    {
      "lang": "en",
      "text": "largely this is not the thing you should",
      "offset": 609.36,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "reach for.",
      "offset": 610.72,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "The last one I see, which also really",
      "offset": 612.8,
      "duration": 3.039
    },
    {
      "lang": "en",
      "text": "confuses me, which I don't think is",
      "offset": 614.48,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "real, is like eval production data. Um,",
      "offset": 615.839,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "there's this idea that you should just",
      "offset": 618.48,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "move your offline evals online. You use",
      "offset": 619.68,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "the same judges, the same scoring. Um,",
      "offset": 622,
      "duration": 5.92
    },
    {
      "lang": "en",
      "text": "largely doesn't work either. I think",
      "offset": 625.2,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "that a it could be very expensive,",
      "offset": 627.92,
      "duration": 2.8
    },
    {
      "lang": "en",
      "text": "especially if you're, you know, you have",
      "offset": 629.44,
      "duration": 2.639
    },
    {
      "lang": "en",
      "text": "some sort of judge that requires the",
      "offset": 630.72,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "model to be a lot smarter. Um, so it's",
      "offset": 632.079,
      "duration": 4.241
    },
    {
      "lang": "en",
      "text": "either it's really expensive or you're",
      "offset": 634.48,
      "duration": 3.039
    },
    {
      "lang": "en",
      "text": "only doing a small percentage of",
      "offset": 636.32,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "production traffic. Um, it's really hard",
      "offset": 637.519,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "to set up accurately. you're not really",
      "offset": 639.68,
      "duration": 4.719
    },
    {
      "lang": "en",
      "text": "getting the patterns that are emerging.",
      "offset": 641.839,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "Um, it's often limited to what you",
      "offset": 644.399,
      "duration": 4.241
    },
    {
      "lang": "en",
      "text": "already know. Even OpenAI talks about",
      "offset": 646,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "this. So, they have like this kind of",
      "offset": 648.64,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "really weird behavioral issue with",
      "offset": 650.079,
      "duration": 4.481
    },
    {
      "lang": "en",
      "text": "chatbt recently and they talk about this",
      "offset": 651.76,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "in their postmortem. They're like, you",
      "offset": 654.56,
      "duration": 2.959
    },
    {
      "lang": "en",
      "text": "know, our emails aren't going to catch",
      "offset": 656.16,
      "duration": 2.72
    },
    {
      "lang": "en",
      "text": "everything, right? The eval catching",
      "offset": 657.519,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "things we already knew and real world",
      "offset": 658.88,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "use is what helps us spot problems.",
      "offset": 661.6,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "And so, to build reliable AI apps, you",
      "offset": 664.88,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "really need signals.",
      "offset": 666.88,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "If you think about issues in an app like",
      "offset": 669.04,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "Sentry,",
      "offset": 670.88,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "you have what the issue is, but then you",
      "offset": 673.2,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "have how many times it happened and how",
      "offset": 675.2,
      "duration": 4.639
    },
    {
      "lang": "en",
      "text": "many users it affected.",
      "offset": 676.88,
      "duration": 5.199
    },
    {
      "lang": "en",
      "text": "But for AI apps, there is no concrete",
      "offset": 679.839,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "error, right? There's no exception being",
      "offset": 682.079,
      "duration": 4.241
    },
    {
      "lang": "en",
      "text": "thrown. And that's why like I think",
      "offset": 683.92,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "signals are really the thing you need to",
      "offset": 686.32,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "be looking at.",
      "offset": 687.76,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "And signals I define as like and at",
      "offset": 690.72,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "Rindrop we call them like ground truthy",
      "offset": 692.72,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "indicators of your app's performance.",
      "offset": 694.64,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "And so the anatomy of an AI issue looks",
      "offset": 697.44,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "like some combination of signals",
      "offset": 699.44,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "implicit and explicit and then intents",
      "offset": 701.04,
      "duration": 4.479
    },
    {
      "lang": "en",
      "text": "which what which are what the users are",
      "offset": 703.68,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "trying to do.",
      "offset": 705.519,
      "duration": 4.481
    },
    {
      "lang": "en",
      "text": "And there's this process of essentially",
      "offset": 708.16,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "defining these signals, exploring these",
      "offset": 710,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "signals and refining them.",
      "offset": 712.079,
      "duration": 5.521
    },
    {
      "lang": "en",
      "text": "So briefly let's talk about defining",
      "offset": 714.88,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "signals. There's explicit signals which",
      "offset": 717.6,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "is almost like an analytics event your",
      "offset": 720.16,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "app can send. And then there's implicit",
      "offset": 721.76,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "data that's sort of hiding in your data.",
      "offset": 723.68,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "uh sorry, implicit signals.",
      "offset": 725.839,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "So a common explicit signal is thumbs",
      "offset": 728.16,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "up, thumbs down, but there really are",
      "offset": 730,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "way more signals than that. So chatbt",
      "offset": 732.24,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "themselves actually track what portion",
      "offset": 734.88,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "of a message you copy out of chatbt.",
      "offset": 736.88,
      "duration": 3.759
    },
    {
      "lang": "en",
      "text": "That's something that they track. That's",
      "offset": 739.6,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "a signal that they're tracking.",
      "offset": 740.639,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "They do preference data, right? You may",
      "offset": 743.36,
      "duration": 2.88
    },
    {
      "lang": "en",
      "text": "have seen this sort of AB, which",
      "offset": 744.959,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "response do you prefer.",
      "offset": 746.24,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "There's a whole host of possible both",
      "offset": 748.56,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "positive and negative signals.",
      "offset": 750.399,
      "duration": 3.761
    },
    {
      "lang": "en",
      "text": "Everything from errors to regenerating",
      "offset": 752,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "to like syntax errors if you're a coding",
      "offset": 754.16,
      "duration": 6.359
    },
    {
      "lang": "en",
      "text": "assistant to copy, sharing, suggesting.",
      "offset": 756,
      "duration": 4.519
    },
    {
      "lang": "en",
      "text": "We actually use this. So we have a flow",
      "offset": 760.72,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "where users can search for data and we",
      "offset": 762.399,
      "duration": 3.521
    },
    {
      "lang": "en",
      "text": "actually look at how many were marked",
      "offset": 764,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "correct, how many were marked wrong and",
      "offset": 765.92,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "we can use that to figure out an RL on",
      "offset": 767.6,
      "duration": 4.239
    },
    {
      "lang": "en",
      "text": "like how and improve the quality of our",
      "offset": 770,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "searches. It's a super interesting",
      "offset": 771.839,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "signal. But there's also implicit",
      "offset": 773.2,
      "duration": 4.879
    },
    {
      "lang": "en",
      "text": "signals which are like essentially",
      "offset": 775.519,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "detecting rather than judging. So we",
      "offset": 778.079,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "detect things like refusals, task",
      "offset": 780.399,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "failure, user frustration. And if you",
      "offset": 782.48,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "think about like the Grock example, when",
      "offset": 784.959,
      "duration": 2.88
    },
    {
      "lang": "en",
      "text": "you cluster them, it gets very",
      "offset": 786.72,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "interesting. So we can look at and say,",
      "offset": 787.839,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "okay, there's this cluster of user",
      "offset": 789.76,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "frustration, and it's all around people",
      "offset": 791.44,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "trying to search for tweets.",
      "offset": 793.2,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "And that's where exploring comes in. So",
      "offset": 795.68,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "just like you can explore tags in",
      "offset": 797.44,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "Sentry, you need some way of exploring",
      "offset": 798.8,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "tags and metadata,",
      "offset": 801.44,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "for us that's like properties, models,",
      "offset": 804.16,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "etc.,",
      "offset": 806.56,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "keywords and intents because like I just",
      "offset": 807.6,
      "duration": 4.479
    },
    {
      "lang": "en",
      "text": "said the intent really changes what the",
      "offset": 810.16,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "actual issue is. So again that's why we",
      "offset": 812.079,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "talk about the anatomy of an AI issue",
      "offset": 814.079,
      "duration": 5.601
    },
    {
      "lang": "en",
      "text": "being a the signal with the intent.",
      "offset": 815.68,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "Just parting thoughts here. You really",
      "offset": 819.68,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "need a constant IV of your app's data.",
      "offset": 821.12,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "We send Slack notifications. You can do",
      "offset": 823.839,
      "duration": 2.8
    },
    {
      "lang": "en",
      "text": "whatever you want but you need to be",
      "offset": 825.44,
      "duration": 2.399
    },
    {
      "lang": "en",
      "text": "looking at your data whether that's",
      "offset": 826.639,
      "duration": 4.481
    },
    {
      "lang": "en",
      "text": "searching it etc. And then you really",
      "offset": 827.839,
      "duration": 4.641
    },
    {
      "lang": "en",
      "text": "need to just refine and define new",
      "offset": 831.12,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "issues which means you look find these",
      "offset": 832.48,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "patterns. Look at your data. talk to",
      "offset": 834.56,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "your users, find new definitions of",
      "offset": 836.16,
      "duration": 3.679
    },
    {
      "lang": "en",
      "text": "issues you weren't expecting, and then",
      "offset": 838,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "start tracking them. So, I'm going to",
      "offset": 839.839,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "cut this part. If you want to know how",
      "offset": 842.24,
      "duration": 3.599
    },
    {
      "lang": "en",
      "text": "to fix these things, I'm happy to talk",
      "offset": 844,
      "duration": 3.279
    },
    {
      "lang": "en",
      "text": "about some of the advancements in SFT",
      "offset": 845.839,
      "duration": 3.201
    },
    {
      "lang": "en",
      "text": "and things I've seen work, but let's uh",
      "offset": 847.279,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "move over to Sid. Cool. Thanks, Ben.",
      "offset": 849.04,
      "duration": 4.479
    },
    {
      "lang": "en",
      "text": "Hey, everybody. I'm Sid. I'm the",
      "offset": 852.079,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "co-founder of Aliv, and we're building a",
      "offset": 853.519,
      "duration": 4.641
    },
    {
      "lang": "en",
      "text": "portfolio of consumer products that have",
      "offset": 855.519,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "with the aim of building products that",
      "offset": 858.16,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "are fulfilling and productive for",
      "offset": 860.399,
      "duration": 3.361
    },
    {
      "lang": "en",
      "text": "people's lives. We're a tiny team based",
      "offset": 861.92,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "out of New York that successfully scaled",
      "offset": 863.76,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "viral products around $6 million an hour",
      "offset": 865.36,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "profitably and generated about half a",
      "offset": 867.36,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "billion views on socials.",
      "offset": 869.12,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "Today I'm going to talk about the",
      "offset": 872,
      "duration": 2.959
    },
    {
      "lang": "en",
      "text": "framework that drives the success which",
      "offset": 873.12,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "is powered by raindrop.",
      "offset": 874.959,
      "duration": 4.721
    },
    {
      "lang": "en",
      "text": "There are two features of a viral AI",
      "offset": 877.6,
      "duration": 4.479
    },
    {
      "lang": "en",
      "text": "product for it to be successful. The",
      "offset": 879.68,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "first part is a wow factor for virality",
      "offset": 882.079,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "and the second part is reliable",
      "offset": 884.16,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "consistent user experiences. The problem",
      "offset": 886,
      "duration": 4.959
    },
    {
      "lang": "en",
      "text": "is AI is chaotic and nondeterministic.",
      "offset": 888.32,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "And this begs for a structure and",
      "offset": 890.959,
      "duration": 3.521
    },
    {
      "lang": "en",
      "text": "approach that allows us to create some",
      "offset": 892.88,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "sort of scaling system that still caters",
      "offset": 894.48,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "to the AI magic that is",
      "offset": 897.199,
      "duration": 4.281
    },
    {
      "lang": "en",
      "text": "nondeterministic.",
      "offset": 898.48,
      "duration": 3
    },
    {
      "lang": "en",
      "text": "The idea is that we want to have a",
      "offset": 901.6,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "systematic approach for continuously",
      "offset": 903.279,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "improving our AI experiences so that we",
      "offset": 904.72,
      "duration": 4.239
    },
    {
      "lang": "en",
      "text": "can scale to millions of users worldwide",
      "offset": 907.199,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "and keep experiences reliable without",
      "offset": 908.959,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "taking away the magic of AI that people",
      "offset": 911.36,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "fall in love with. We need some way to",
      "offset": 913.12,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "guide the chaos instead of eliminating",
      "offset": 915.12,
      "duration": 2.8
    },
    {
      "lang": "en",
      "text": "it.",
      "offset": 916.72,
      "duration": 2.799
    },
    {
      "lang": "en",
      "text": "This is why we came up with Trellis.",
      "offset": 917.92,
      "duration": 3.279
    },
    {
      "lang": "en",
      "text": "Trellis is our framework for",
      "offset": 919.519,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "continuously refining our AI experiences",
      "offset": 921.199,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "so that we can systematically improve",
      "offset": 923.199,
      "duration": 3.361
    },
    {
      "lang": "en",
      "text": "the user experiences across our AI",
      "offset": 924.88,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "products at scale designed specifically",
      "offset": 926.56,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "around our virality engine. There are",
      "offset": 928.24,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "three core aims to trus. One is",
      "offset": 930.88,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "discretization where we take the",
      "offset": 932.8,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "infinite output space and break it down",
      "offset": 934.56,
      "duration": 4.639
    },
    {
      "lang": "en",
      "text": "into specific buckets of focus. Then we",
      "offset": 936.32,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "prioritize. This involves ranking those",
      "offset": 939.199,
      "duration": 4.241
    },
    {
      "lang": "en",
      "text": "bucket spaces by what will drive the",
      "offset": 941.6,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "most impact for your business. And",
      "offset": 943.44,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "finally, recursive refinement. We repeat",
      "offset": 945.04,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "this process within those buckets of",
      "offset": 947.279,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "output spaces so that we can continue to",
      "offset": 949.12,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "create structure and order within the",
      "offset": 950.959,
      "duration": 5.361
    },
    {
      "lang": "en",
      "text": "chaotic uh output plane. There",
      "offset": 952.959,
      "duration": 5.761
    },
    {
      "lang": "en",
      "text": "effectively six steps to trus. A lot of",
      "offset": 956.32,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "this has been shared by Ben in terms of",
      "offset": 958.72,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "the the grounding principles of it. The",
      "offset": 960.639,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "first is you want to initialize an",
      "offset": 962.639,
      "duration": 3.521
    },
    {
      "lang": "en",
      "text": "output space by launching an MVP agent",
      "offset": 964.079,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "that is informed by some product priors",
      "offset": 966.16,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "and some product expectations. But the",
      "offset": 968.399,
      "duration": 3.201
    },
    {
      "lang": "en",
      "text": "goal is really to collect a lot of user",
      "offset": 970.079,
      "duration": 4.241
    },
    {
      "lang": "en",
      "text": "data. The second step is once you've",
      "offset": 971.6,
      "duration": 4.239
    },
    {
      "lang": "en",
      "text": "unders on once you have all this user",
      "offset": 974.32,
      "duration": 2.879
    },
    {
      "lang": "en",
      "text": "data, you want to correctly classify",
      "offset": 975.839,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "these into intents based on usage",
      "offset": 977.199,
      "duration": 3.361
    },
    {
      "lang": "en",
      "text": "patterns. The goal is you want to",
      "offset": 978.959,
      "duration": 3.201
    },
    {
      "lang": "en",
      "text": "understand exactly why people are",
      "offset": 980.56,
      "duration": 2.639
    },
    {
      "lang": "en",
      "text": "sticking to your product and what",
      "offset": 982.16,
      "duration": 2.32
    },
    {
      "lang": "en",
      "text": "they're using in your product,",
      "offset": 983.199,
      "duration": 2.961
    },
    {
      "lang": "en",
      "text": "especially when it's a conversational",
      "offset": 984.48,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "open-ended AI agent experience. The",
      "offset": 986.16,
      "duration": 4.479
    },
    {
      "lang": "en",
      "text": "third step is converting these intents",
      "offset": 988.8,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "into dedicated semi- semi-deterministic",
      "offset": 990.639,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "workflows. A workflow is a predefined",
      "offset": 993.36,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "set of steps that allows you to achieve",
      "offset": 995.519,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "a certain output. The goal is you want",
      "offset": 997.36,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "these workflows to be broad enough to be",
      "offset": 999.44,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "useful for many possibilities but narrow",
      "offset": 1001.36,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "enough to be reliable. After you have",
      "offset": 1003.36,
      "duration": 3.599
    },
    {
      "lang": "en",
      "text": "your workflows, you want to prioritize",
      "offset": 1005.519,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "them by some scoring mechanism. This has",
      "offset": 1006.959,
      "duration": 3.281
    },
    {
      "lang": "en",
      "text": "to be something that's tied to your",
      "offset": 1008.959,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "company's KPIs. Um, and finally, you",
      "offset": 1010.24,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "want to analyze these workflows from",
      "offset": 1012.8,
      "duration": 2.479
    },
    {
      "lang": "en",
      "text": "within. You want to understand the",
      "offset": 1014.24,
      "duration": 2.64
    },
    {
      "lang": "en",
      "text": "failure patterns within them. You want",
      "offset": 1015.279,
      "duration": 2.961
    },
    {
      "lang": "en",
      "text": "to understand the sub intents and you",
      "offset": 1016.88,
      "duration": 2.639
    },
    {
      "lang": "en",
      "text": "want to keep recursing from there, which",
      "offset": 1018.24,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "is what step six involves.",
      "offset": 1019.519,
      "duration": 4.641
    },
    {
      "lang": "en",
      "text": "A quick note on prioritization. There's",
      "offset": 1022.16,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "a simple and naive way to do it, which",
      "offset": 1024.16,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "is volume only. This involves focusing",
      "offset": 1025.76,
      "duration": 3.439
    },
    {
      "lang": "en",
      "text": "on the workflows that have the most",
      "offset": 1027.76,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "volume. However, this leaves a lot of",
      "offset": 1029.199,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "room on the table for improving general",
      "offset": 1031.52,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "satisfaction across your product. A more",
      "offset": 1033.679,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "recommended approach is volume times",
      "offset": 1035.76,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "negative sentiment score. In this, we",
      "offset": 1037.28,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "try to score the ex the expected lift",
      "offset": 1040,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "you'd like to get by focusing on a",
      "offset": 1042.88,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "workflow that might be generating a lot",
      "offset": 1044.48,
      "duration": 2.8
    },
    {
      "lang": "en",
      "text": "of negative satisfaction on your",
      "offset": 1046,
      "duration": 3.679
    },
    {
      "lang": "en",
      "text": "product. An even more informed score is",
      "offset": 1047.28,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "negative sentiment times volume times",
      "offset": 1049.679,
      "duration": 3.521
    },
    {
      "lang": "en",
      "text": "estimated achievable delta times some",
      "offset": 1051.6,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "strategic relevance. The idea of",
      "offset": 1053.2,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "estimated achievable delta is comes down",
      "offset": 1054.96,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "to you coming up with a way to score the",
      "offset": 1057.6,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "actual achievable delta you can gain",
      "offset": 1059.52,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "from working on that workflow and",
      "offset": 1061.84,
      "duration": 2.56
    },
    {
      "lang": "en",
      "text": "improving the product. If you're going",
      "offset": 1063.2,
      "duration": 2.64
    },
    {
      "lang": "en",
      "text": "to need to train a foundational model to",
      "offset": 1064.4,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "improve something, its achievable delta",
      "offset": 1065.84,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "is probably near zero depending on the",
      "offset": 1067.44,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "kind of company you are.",
      "offset": 1069.28,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "All in all, the goal is once you have",
      "offset": 1071.52,
      "duration": 3.039
    },
    {
      "lang": "en",
      "text": "these intents identified, you can build",
      "offset": 1072.88,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "structured workflows where each workflow",
      "offset": 1074.559,
      "duration": 4.881
    },
    {
      "lang": "en",
      "text": "is self-attributable, deterministic,",
      "offset": 1076.48,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "and is self-bound, which means which",
      "offset": 1079.44,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "which allows your teams to move much",
      "offset": 1082.24,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "more quickly because when you when you",
      "offset": 1083.76,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "uh improve a specific workflow,",
      "offset": 1086.559,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "all those changes are contained and",
      "offset": 1089.36,
      "duration": 2.64
    },
    {
      "lang": "en",
      "text": "self-countable to that one workflow",
      "offset": 1090.799,
      "duration": 2.481
    },
    {
      "lang": "en",
      "text": "instead of spilling over into other",
      "offset": 1092,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "workflows. This allows your team to move",
      "offset": 1093.28,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "more reliably.",
      "offset": 1095.12,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "And uh while we have a few more seconds,",
      "offset": 1097.52,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "you can continue to further refine this",
      "offset": 1099.28,
      "duration": 3.279
    },
    {
      "lang": "en",
      "text": "process going deeper and deeper into all",
      "offset": 1100.96,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "your workflows. And at the end of the",
      "offset": 1102.559,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "day, you create magic which is",
      "offset": 1104.24,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "engineered, repeatable, testable, and",
      "offset": 1105.919,
      "duration": 3.441
    },
    {
      "lang": "en",
      "text": "attributable, but not accidental. If",
      "offset": 1107.28,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "you'd like to read more about this, feel",
      "offset": 1109.36,
      "duration": 2.88
    },
    {
      "lang": "en",
      "text": "free to scan this QR code to read about",
      "offset": 1110.64,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "our blog post on the Trellis framework.",
      "offset": 1112.24,
      "duration": 6.6
    },
    {
      "lang": "en",
      "text": "Thank you for having me.",
      "offset": 1115.2,
      "duration": 3.64
    }
  ],
  "cleanText": "[Music]\n\nUh, my name is Ben Hylak, and uh, also just feeling really grateful to be with all of you guys today.\nUh, it's pretty exciting, and we're here to talk about building AI products that actually work.\nUm, I'll introduce this guy in a second.\nSorry, it wasn't the right word.\nUh, so I tweeted last night.\nI was kind of like, what should we uh, what should we talk about today?\nUh, and the overwhelming response I got was like, please no more eval.\nUh, apparently there's a lot of eval tracks.\nWe'll touch on eval still just a little bit, but mainly we're going to be focusing on how to iterate on AI products.\nAnd so I think iteration is actually one of the most important parts of building AI products that actually work.\nSo again, just a little bit about us.\nSo, I'm the CTO of a company called Raindrop.\nAnd Raindrop helps companies find and fix issues in their AI products.\nUh, before that, I was actually kind of a weird background, but I used to be really into robotics.\nI did avionics at SpaceX for a little bit.\nUm, and then most recently, I was an engineer and then on the design team at Apple for almost four years.\nAnd, uh, we also have Sid.\nSo, uh, in the spirit of sharing how to build things that actually work, uh, I brought Sid, who actually knows how to build products that actually work.\nSo, I think Sid is like, uh, the co-founder of a company called Oleve.\nUm, with just four people, they grew a suite of viral apps to over six million AR.\nSo, Sid is going to share again how to build products that actually work.\nI think it's actually a really exciting time for AI products.\nAnd I say it's an exciting time because in the last year, we've seen that it's possible to really focus on a use case, really focus on something and make that thing exceptional, like really, really crack it.\nUm, we've seen that it's possible to train like small models, really, really tiny models to just be exceptional at specific tasks if you focus on a specific use case.\nAnd we're also seeing that increasingly providers right are actually focusing on on launching those sort of products, which is, you know, that might be the scary part.\nUm, but deep research is a great example, right, where chat GPT just focused on how do we, you know, how do we collect a data set, how do we train something to just be exceptionally good at searching the web, and they were, I think it's one of the best products that they've released.\nBut even OpenAI is not immune to shipping like not-so-great products, right?\nI think like, to me, I, I don't know, uh, what your guys' experience is, but I think that like I've actually had a lot of trouble with codeex, and I don't know that it's like exceptionally better than uh, other things that exist.\nLike this is kind of a funny one.\nI was like, write some tests, and it, it actually correctly generated this hash for the word hello, you know, but it's like, I'm not sure this is like, you know, when I think about writing tests for my back end, I'm not sure that this is what I wanted, right?\nUm, and it's not just OpenAI, right?\nLike I think that increasingly in the last year, AI products, still even in the last couple months, couple weeks, like there's all these weird issues like...\nYeah, this is a funny one, right?\nSo, Virgin Money, their chatbot was threatening to cut off their customers for using the word virgin, right?\nSo, uh, just the other day I was using uh, uh, Google Cloud, and I asked it where my credits are, and it was like, \"Are you talking about Azure credits or Roblox credits?\"\nYou know, and I was like, \"What?\nHow is this possible?\"\nIt's funny because I tweeted this, and it's like, \"This isn't just a one-off thing, right?\nLike someone's like, \"Oh, yeah.\nThis exact same thing happened to me, right?\"\nUm, just a few weeks ago, Grock had this crazy thing, right, where people were asking in this case about enterprise software, and it's like, oh, by the way, you know, let's talk about uh, the, you know, claims of white genocide in South Africa, you know, just completely off off the rails here, and we only see, we only caught something like this only kind of entered the public, you know, awareness because Grock is public and because you can kind of see everything.\nFunny enough, um, I, I actually tweet a lot about, if you follow me, you know I tweet a lot about AI products and where they fail.\nAnd so last night when I was like rushing to get this presentation, my part of it done, uh, I asked it to find tweets of mine about AI failures, and it says, I don't have access to your personal Twitter.\nI can't search tweets.\nI was like, I think I can.\nSo I, I double down.\nI'm like, you are literally Grock, you know, like this is what you're made for.\nAnd it's like, oh, you're right.\nI can, I just don't have your username, you know?\nSo it's absurd.\nAnd I actually like, like this is yesterday, right?\nThis is still a bug that they have.\nSo, I feel really lucky to be, you know, like, like I mentioned, I, I'm a CTO, co-founder of a company called Raindrop, and we're in this really cool position where we get to work with some of the coolest, fastest-growing companies in the world and just a huge range of companies.\nSo it's everything from, you know, apps like Sids, which he'll share about, to things like clay.com, you know, which is like a sales sort of outreach tool, to like alien companion apps, to coding assistance.\nIt's just this insane range of products, and so I get, I think we get to see so much of like what works, what doesn't work.\nWe are also like, it's not just all secondhand, like we also have a massive uh, AI pipeline where, you know, every single event that we receive is being analyzed, is being kind of divvied up in some way, and we're kind of like, you know, we have this product, we're also kind of this like stealth frontier lab of some sort of where we are kind of shipping some of the coolest AI features I've ever seen.\nUm, we have like tools like deep search that allows people to go really deep into their production data and build just classifiers from just a few examples.\nSo, it's been cool to sort of build this intuition both from firsthand from our customers and kind of merge that, and I think we've, we have a pretty good intuition of what actually works right now.\nOne question I get a lot is, will it get easier to make AI products, right?\nLike how much of this is just a moment in time?\nI think this is a very, very interesting question, and I think the answer is actually twofold, right?\nSo, the first answer is yes.\nLike yes, it will get easier.\nUh, and we know this because we've seen it.\nA year ago, you had to give, you know, threaten to kill your, you know, GPG4 in order to get it to output JSON, right?\nLike it was like you have to threaten to kill its firstborn or something.\nAnd now it's just like a parameter in the API.\nLike you're just like, in fact, here's the exact schema I want you to output.\nIt just works.\nSo those sort of things will get easier.\nBut I think the second part of this answer is actually no.\nLike, like in a lot of ways, it's not going to get easier.\nAnd I think that comes from the fact that communication is hard.\nLike communication is a hard thing.\nUm, what do I mean by this?\nI actually, um, I'm a big Paul Graham fan.\nI'm sure a lot of us are, but I actually really, really disagree with this.\nAnd the reason why is, so, so he says, it seems to me AGI would mean the end of prompt engineering.\nModerately intelligent humans can figure out what you want without elaborate prompts.\nI don't think that's true.\nLike I, I think that if you can think of all the times, you know, you've, your partner has told you something and you've gotten it wrong, right?\nLike you completely misinterpreted what they wanted, right?\nWhat their goal was.\nIf you think about onboarding a new hire, right?\nAnd like, like you told them to do something and they come back, what, what the hell is this?\nRight?\nUm, I think it's really, really hard to communicate what you want to someone, especially someone that doesn't have a lot of context.\nSo yes, I think this is wrong.\nThe other reason why I'm not sure it's going to get that much easier in a lot of ways is that as these models, as our products become more capable, there's just more undefined behavior, right?\nThere's more edge cases you didn't think about.\nAnd this is only becoming more true, you know, as our products have to start integrating with other tools through like MCP, for example.\nThere's going to be new data formats, new ways of doing things.\nSo I, I think that as our products become more capable, as the, as these models get more intelligent, we're, it's a little bit, uh, we're kind of stuck in the same, same situation.\nSo this is, this is how I like to think about it.\nI think you can't define the entire scope of your product's behavior up front anymore.\nYou can't just say like, you know, here's the PRD, here's the document of everything I want my product to do.\nLike you actually have to iterate on it.\nYou have to kind of ship it, see what it does, and then iterate on it.\nSo, I think eval are a very, very important part of this actually, but I also think there's a lot of confusion.\nYou know, I use the word lie is a little spicy, but I think there's, there's a lot of sort of misinformation around evals.\nSo I'm not going to share, I'm not going to like rehash what eval are.\nI'm not going to kind of go into all the details, but I will talk about I think some like common misconceptions I've seen around evals.\nSo, one is that this idea that eval are going to tell you how good your product is.\nThey're not.\nUm, they're really not.\nUh, if you're not familiar with Goodhart's law, it's like kind of the reason for this.\nUm, the eval that you collect are only the things you already know of.\nIt's going to be easy to saturate them.\nIf you look at recent model launches, a lot of them are actually performing lower on eval, you know, previous ones, but they're just way better in real-world use.\nSo, it's not going to do this.\nThe other lie is this idea that like, oh, okay, well, if you have a sort of like, imagine you have something like how funny is my joke, you know, that my app is generating.\nThis is the example I always hear used.\nYou'll just like ask an LM to judge how funny your joke is.\nUm, I, this doesn't work, like largely does not work.\nUh, uh, they're tempting because, you know, these LM judges take text as an input and they output a score, they output a decision, whatever it is.\nUm, like largely the best companies are not doing this.\nThey're, they're not, they're, the best companies are using highly curated data sets.\nThey're using autogradable evals.\nAutogradable here meaning like, you know, there's some way of, in some deterministic way, figuring out if the model passed or not.\nUm, they're not really using LM as judges.\nUm, there's some edge cases here, but just like largely this is not the thing you should reach for.\nThe last one I see, which also really confuses me, which I don't think is real, is like eval production data.\nUm, there's this idea that you should just move your offline evals online.\nYou use the same judges, the same scoring.\nUm, largely doesn't work either.\nI think that a, it could be very expensive, especially if you're, you know, you have some sort of judge that requires the model to be a lot smarter.\nUm, so it's either, it's really expensive or you're only doing a small percentage of production traffic.\nUm, it's really hard to set up accurately.\nYou're not really getting the patterns that are emerging.\nUm, it's often limited to what you already know.\nEven OpenAI talks about this.\nSo, they have like this kind of really weird behavioral issue with chatbt recently, and they talk about this in their postmortem.\nThey're like, you know, our emails aren't going to catch everything, right?\nThe eval catching things we already knew and real-world use is what helps us spot problems.\nAnd so, to build reliable AI apps, you really need signals.\nIf you think about issues in an app like Sentry, you have what the issue is, but then you have how many times it happened and how many users it affected.\nBut for AI apps, there is no concrete error, right?\nThere's no exception being thrown.\nAnd that's why like I think signals are really the thing you need to be looking at.\nAnd signals I define as like, and at Rindrop we call them like ground-truthy indicators of your app's performance.\nAnd so the anatomy of an AI issue looks like some combination of signals, implicit and explicit, and then intents, which are what the users are trying to do.\nAnd there's this process of essentially defining these signals, exploring these signals, and refining them.\nSo briefly, let's talk about defining signals.\nThere's explicit signals, which is almost like an analytics event your app can send.\nAnd then there's implicit data that's sort of hiding in your data.\nUh, sorry, implicit signals.\nSo a common explicit signal is thumbs up, thumbs down, but there really are way more signals than that.\nSo chatbt themselves actually track what portion of a message you copy out of chatbt.\nThat's something that they track.\nThat's a signal that they're tracking.\nThey do preference data, right?\nYou may have seen this sort of AB, which response do you prefer.\nThere's a whole host of possible both positive and negative signals.\nEverything from errors to regenerating to like syntax errors if you're a coding assistant to copy, sharing, suggesting.\nWe actually use this.\nSo we have a flow where users can search for data, and we actually look at how many were marked correct, how many were marked wrong, and we can use that to figure out an RL on like how and improve the quality of our searches.\nIt's a super interesting signal.\nBut there's also implicit signals, which are like essentially detecting rather than judging.\nSo we detect things like refusals, task failure, user frustration.\nAnd if you think about like the Grock example, when you cluster them, it gets very interesting.\nSo we can look at and say, okay, there's this cluster of user frustration, and it's all around people trying to search for tweets.\nAnd that's where exploring comes in.\nSo just like you can explore tags in Sentry, you need some way of exploring tags and metadata.\n\n\nFor us, that's like properties, models, etc., keywords and intents because, like I just said, the intent really changes what the actual issue is.\nSo, again, that's why we talk about the anatomy of an AI issue being the signal with the intent.\nJust parting thoughts here.\nYou really need a constant IV of your app's data.\nWe send Slack notifications.\nYou can do whatever you want, but you need to be looking at your data, whether that's searching it, etc.\nAnd then you really need to just refine and define new issues, which means you look, find these patterns, look at your data, talk to your users, find new definitions of issues you weren't expecting, and then start tracking them.\nSo, I'm going to cut this part.\nIf you want to know how to fix these things, I'm happy to talk about some of the advancements in SFT and things I've seen work, but let's uh move over to Sid.\nCool.\nThanks, Ben.\nHey, everybody.\nI'm Sid.\nI'm the co-founder of Oleve, and we're building a portfolio of consumer products that have with the aim of building products that are fulfilling and productive for people's lives.\nWe're a tiny team based out of New York that successfully scaled viral products around $6 million an hour profitably and generated about half a billion views on socials.\nToday I'm going to talk about the framework that drives the success which is powered by Raindrop.\nThere are two features of a viral AI product for it to be successful.\nThe first part is a wow factor for virality, and the second part is reliable, consistent user experiences.\nThe problem is AI is chaotic and nondeterministic.\nAnd this begs for a structure and approach that allows us to create some sort of scaling system that still caters to the AI magic that is nondeterministic.\nThe idea is that we want to have a systematic approach for continuously improving our AI experiences so that we can scale to millions of users worldwide and keep experiences reliable without taking away the magic of AI that people fall in love with.\nWe need some way to guide the chaos instead of eliminating it.\nThis is why we came up with Trellis.\nTrellis is our framework for continuously refining our AI experiences so that we can systematically improve the user experiences across our AI products at scale designed specifically around our virality engine.\nThere are three core aims to Trellis.\nOne is discretization, where we take the infinite output space and break it down into specific buckets of focus.\nThen we prioritize.\nThis involves ranking those bucket spaces by what will drive the most impact for your business.\nAnd finally, recursive refinement.\nWe repeat this process within those buckets of output spaces so that we can continue to create structure and order within the chaotic uh output plane.\nThere effectively six steps to Trellis.\nA lot of this has been shared by Ben in terms of the the grounding principles of it.\nThe first is you want to initialize an output space by launching an MVP agent that is informed by some product priors and some product expectations.\nBut the goal is really to collect a lot of user data.\nThe second step is once you've unders on once you have all this user data, you want to correctly classify these into intents based on usage patterns.\nThe goal is you want to understand exactly why people are sticking to your product and what they're using in your product, especially when it's a conversational open-ended AI agent experience.\nThe third step is converting these intents into dedicated semi- semi-deterministic workflows.\nA workflow is a predefined set of steps that allows you to achieve a certain output.\nThe goal is you want these workflows to be broad enough to be useful for many possibilities but narrow enough to be reliable.\nAfter you have your workflows, you want to prioritize them by some scoring mechanism.\nThis has to be something that's tied to your company's KPIs.\nUm, and finally, you want to analyze these workflows from within.\nYou want to understand the failure patterns within them.\nYou want to understand the sub intents, and you want to keep recursing from there, which is what step six involves.\nA quick note on prioritization.\nThere's a simple and naive way to do it, which is volume only.\nThis involves focusing on the workflows that have the most volume.\nHowever, this leaves a lot of room on the table for improving general satisfaction across your product.\nA more recommended approach is volume times negative sentiment score.\nIn this, we try to score the ex the expected lift you'd like to get by focusing on a workflow that might be generating a lot of negative satisfaction on your product.\nAn even more informed score is negative sentiment times volume times estimated achievable delta times some strategic relevance.\nThe idea of estimated achievable delta is comes down to you coming up with a way to score the actual achievable delta you can gain from working on that workflow and improving the product.\nIf you're going to need to train a foundational model to improve something, its achievable delta is probably near zero depending on the kind of company you are.\nAll in all, the goal is once you have these intents identified, you can build structured workflows where each workflow is self-attributable, deterministic, and is self-bound, which means which which allows your teams to move much more quickly because when you when you uh improve a specific workflow, all those changes are contained and self-countable to that one workflow instead of spilling over into other workflows.\nThis allows your team to move more reliably.\nAnd uh while we have a few more seconds, you can continue to further refine this process going deeper and deeper into all your workflows.\nAnd at the end of the day, you create magic which is engineered, repeatable, testable, and attributable, but not accidental.\nIf you'd like to read more about this, feel free to scan this QR code to read about our blog post on the Trellis framework.\nThank you for having me.\n",
  "dumpedAt": "2025-07-21T18:43:25.635Z"
}