{
  "episodeId": "bcygOasrldM",
  "channelSlug": "@datacamp",
  "title": "Grok 4 Full Breakdown: Deep Dive and 7 Practical Examples",
  "publishedAt": "2025-07-11T19:51:35.000Z",
  "rawLines": [
    {
      "lang": "en",
      "text": "What's up everybody? Adele here. Today's",
      "offset": 0.08,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "video is going to be looking at the Gro",
      "offset": 2.32,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "4 model, the brand new model coming from",
      "offset": 4.16,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "XAI. We're going to put the model",
      "offset": 7.12,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "through its spaces, compare it to",
      "offset": 9.04,
      "duration": 3.679
    },
    {
      "lang": "en",
      "text": "different models today on the market,",
      "offset": 10.88,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "and test on a bunch of use cases related",
      "offset": 12.719,
      "duration": 5.201
    },
    {
      "lang": "en",
      "text": "to math, reasoning, and coding. Now, if",
      "offset": 14.88,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "you want to learn more about AI and how",
      "offset": 17.92,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "other models are being put to use today,",
      "offset": 19.76,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "make sure to subscribe to this YouTube",
      "offset": 22,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "channel or check out our blog for more",
      "offset": 23.6,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "details. With that, happy learning.",
      "offset": 26.24,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "Hello everyone and welcome to this",
      "offset": 28.24,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "session. My name is Joseph Far. I'm a",
      "offset": 29.76,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "data scientist and technical writer. And",
      "offset": 31.76,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "today I'm here to walk you through one",
      "offset": 33.68,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "of the biggest announcement of",
      "offset": 35.68,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "artificial intelligent of this year. And",
      "offset": 37.2,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "it is the launch of Grock 4. For those",
      "offset": 39.12,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "of you wondering what's Grock, basically",
      "offset": 41.28,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "it is the large language model family of",
      "offset": 43.2,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "XAI, the artificial intelligence company",
      "offset": 45.44,
      "duration": 5.439
    },
    {
      "lang": "en",
      "text": "of Elon Musk. So Grock 4 is its latest",
      "offset": 47.68,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "model and it was launched the last 9th",
      "offset": 50.879,
      "duration": 5.041
    },
    {
      "lang": "en",
      "text": "July. It is quite crazy to think that",
      "offset": 53.36,
      "duration": 4.879
    },
    {
      "lang": "en",
      "text": "Grock 3, the previous model was just",
      "offset": 55.92,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "launched 3 months ago and basically this",
      "offset": 58.239,
      "duration": 4.721
    },
    {
      "lang": "en",
      "text": "indicates us how fast the artificial",
      "offset": 60.8,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "intelligent world is growing. However,",
      "offset": 62.96,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "today's landscape is still shaped by the",
      "offset": 65.28,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "giants of Google's Germany's family,",
      "offset": 68,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "OpenAI's GP's family and anthropics",
      "offset": 70.56,
      "duration": 4.879
    },
    {
      "lang": "en",
      "text": "plots family. But Ellen Musk is quite",
      "offset": 73.2,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "obsessed to change this and actually",
      "offset": 75.439,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "he's already stated that Grock 4 is the",
      "offset": 77.119,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "most smart language model and it has",
      "offset": 79.759,
      "duration": 5.121
    },
    {
      "lang": "en",
      "text": "more knowledge than any PhD in any",
      "offset": 82.479,
      "duration": 4.721
    },
    {
      "lang": "en",
      "text": "field. This is why today what I want to",
      "offset": 84.88,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "do with you is first have a good",
      "offset": 87.2,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "understanding of this model of Groc 4",
      "offset": 88.88,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "and understand its main features. The",
      "offset": 90.96,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "second point would be perform some daily",
      "offset": 93.36,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "task in order to you to see that it is",
      "offset": 95.84,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "super easy to access it and actually",
      "offset": 98.4,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "that you can take advantage of it and",
      "offset": 100.159,
      "duration": 3.121
    },
    {
      "lang": "en",
      "text": "you can incorporate it in your daily",
      "offset": 101.6,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "work. The third point would be compare",
      "offset": 103.28,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "it with other models both its previous",
      "offset": 105.36,
      "duration": 4.799
    },
    {
      "lang": "en",
      "text": "models like Gro 3 and its top",
      "offset": 108.24,
      "duration": 3.519
    },
    {
      "lang": "en",
      "text": "competitors and actually check a little",
      "offset": 110.159,
      "duration": 3.201
    },
    {
      "lang": "en",
      "text": "bit the benchmarkings and see what's the",
      "offset": 111.759,
      "duration": 4.241
    },
    {
      "lang": "en",
      "text": "position of Grock 4. Finally, I would",
      "offset": 113.36,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "like to discuss the future of the Grock",
      "offset": 116,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "family. So if you're interested in",
      "offset": 118,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "artificial intelligence, please stay",
      "offset": 120,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "with me. Let's go for it. Now, let's",
      "offset": 121.84,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "just start with the basics. What exactly",
      "offset": 124.399,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "is Croc 4? As I said before, Croc 4 is",
      "offset": 125.84,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "XAI's latest multimodel large language",
      "offset": 128.399,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "model. The company claims it's the most",
      "offset": 130.56,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "intelligent model available today in the",
      "offset": 132.8,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "market, which in the end all companies",
      "offset": 134.8,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "do. However, in this case, the benchmark",
      "offset": 136.72,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "results do point in that direction,",
      "offset": 139.12,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "which is quite interesting. After having",
      "offset": 140.72,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "listened on the live stream, there's",
      "offset": 142.64,
      "duration": 4.239
    },
    {
      "lang": "en",
      "text": "nothing particularly groundbreaking in",
      "offset": 144.64,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "terms of engineering. So the gains seem",
      "offset": 146.879,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "to come from a series of smaller tweaks",
      "offset": 149.36,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "and a significant increase in compute.",
      "offset": 151.04,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "For those of you wondering what does an",
      "offset": 153.28,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "increase of compute means, basically it",
      "offset": 154.879,
      "duration": 4.481
    },
    {
      "lang": "en",
      "text": "means that Groc 4 has been trained on",
      "offset": 156.8,
      "duration": 5.439
    },
    {
      "lang": "en",
      "text": "100 times more data than its predecessor",
      "offset": 159.36,
      "duration": 6.4
    },
    {
      "lang": "en",
      "text": "Groc 2 and it's powered by 10 more times",
      "offset": 162.239,
      "duration": 5.441
    },
    {
      "lang": "en",
      "text": "reinforcement learning compute than any",
      "offset": 165.76,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "other model currently available in the",
      "offset": 167.68,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "market including Groc 3, its direct",
      "offset": 169.76,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "predecessor.",
      "offset": 172.08,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "We will see more about the features",
      "offset": 173.68,
      "duration": 3.279
    },
    {
      "lang": "en",
      "text": "later, but the most important highlights",
      "offset": 175.2,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "of the model are that right now it",
      "offset": 176.959,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "presents one of the biggest context",
      "offset": 179.28,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "window in the market with 256k tokens",
      "offset": 180.8,
      "duration": 6.799
    },
    {
      "lang": "en",
      "text": "which is triceaker than gro 3. It",
      "offset": 184.8,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "presents real-time data search but",
      "offset": 187.599,
      "duration": 3.201
    },
    {
      "lang": "en",
      "text": "actually this is not as impressive",
      "offset": 189.44,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "because most of the competitors already",
      "offset": 190.8,
      "duration": 4.799
    },
    {
      "lang": "en",
      "text": "present it. It has been natively trained",
      "offset": 192.8,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "to use tools. Actually this is quite",
      "offset": 195.599,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "impressive. We will see uh more about",
      "offset": 197.76,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "this later. It has advanced voice",
      "offset": 199.76,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "capabilities but only for mobile phone",
      "offset": 201.92,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "apps. So we won't be able to use it",
      "offset": 203.76,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "today. And finally it presents some",
      "offset": 205.84,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "aentic abilities. The first thing of",
      "offset": 208.08,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "course just go into a web browser. Use",
      "offset": 210.4,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "whatever you want. And then I'm going to",
      "offset": 212.159,
      "duration": 6.321
    },
    {
      "lang": "en",
      "text": "go to Google and just look for Groc",
      "offset": 214.08,
      "duration": 7.84
    },
    {
      "lang": "en",
      "text": "here. I will go to the first option. And",
      "offset": 218.48,
      "duration": 7.119
    },
    {
      "lang": "en",
      "text": "um now I will see the landing cover of",
      "offset": 221.92,
      "duration": 6.64
    },
    {
      "lang": "en",
      "text": "the XAI company and the Gro interface.",
      "offset": 225.599,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "Basically here there are like two",
      "offset": 228.56,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "different triggers that can just pop up",
      "offset": 230,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "the grab interface. This box here that",
      "offset": 231.84,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "allows me to send a prom directly to the",
      "offset": 234.159,
      "duration": 4.961
    },
    {
      "lang": "en",
      "text": "model or the button here of try Grock.",
      "offset": 236.159,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "I'm going to just use the button and I",
      "offset": 239.12,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "will see now the interface of Groc. As",
      "offset": 241.599,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "you can see it is quite a minimalist",
      "offset": 243.92,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "interface. It's just the same as any",
      "offset": 245.68,
      "duration": 4.639
    },
    {
      "lang": "en",
      "text": "other competitor uh namely Chad GBT",
      "offset": 247.68,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "Google Germany wherever. But the first",
      "offset": 250.319,
      "duration": 4.241
    },
    {
      "lang": "en",
      "text": "thing to start using it you can see that",
      "offset": 252.64,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "by default it comes Groc 3 and uh for",
      "offset": 254.56,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "Grock 4 I need to sign in or sign up if",
      "offset": 257.28,
      "duration": 4.799
    },
    {
      "lang": "en",
      "text": "uh you don't have an account and",
      "offset": 260.56,
      "duration": 2.96
    },
    {
      "lang": "en",
      "text": "basically we will see that we have a",
      "offset": 262.079,
      "duration": 4.481
    },
    {
      "lang": "en",
      "text": "membership as well",
      "offset": 263.52,
      "duration": 5.679
    },
    {
      "lang": "en",
      "text": "and now we will have the whole",
      "offset": 266.56,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "interface. So as you can see here we",
      "offset": 269.199,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "have the name we have a box to send the",
      "offset": 271.04,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "prompts we have a button to attach files",
      "offset": 272.8,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "we have here to choose the model we will",
      "offset": 275.68,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "see by default it will come Grock 3 but",
      "offset": 277.44,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "we will have uh Gro for here available",
      "offset": 279.759,
      "duration": 5.281
    },
    {
      "lang": "en",
      "text": "to just choose it and Grock for heavy we",
      "offset": 282.4,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "will see later what's the main",
      "offset": 285.04,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "difference and then we have this sidebar",
      "offset": 286.16,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "here with different functionalities and",
      "offset": 288.8,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "then um my user settings here you can",
      "offset": 291.52,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "see my little image um down there and",
      "offset": 294.24,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "then we will have the history right Now",
      "offset": 297.52,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "I don't have any history. I don't have",
      "offset": 299.6,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "any chats because I just deleted them",
      "offset": 300.96,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "for uh today's video. Then we have the",
      "offset": 302.88,
      "duration": 4.879
    },
    {
      "lang": "en",
      "text": "projects functionality. For me it is",
      "offset": 306,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "quite useful but actually it is present",
      "offset": 307.759,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "in many of its competitors. Basically I",
      "offset": 309.44,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "can just organize my chats uh and just",
      "offset": 311.84,
      "duration": 5.359
    },
    {
      "lang": "en",
      "text": "put them within projects. So basically I",
      "offset": 315.12,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "can have somewhere uh a structure when I",
      "offset": 317.199,
      "duration": 5.361
    },
    {
      "lang": "en",
      "text": "just interact with these models uh in",
      "offset": 320.4,
      "duration": 4.239
    },
    {
      "lang": "en",
      "text": "this case with croc. And then there's",
      "offset": 322.56,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "like the task functionality. I really",
      "offset": 324.639,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "like it. Basically, it allows the user",
      "offset": 326.479,
      "duration": 4.961
    },
    {
      "lang": "en",
      "text": "to just ask for a specific task to the",
      "offset": 328.56,
      "duration": 5.199
    },
    {
      "lang": "en",
      "text": "model and give it a frequency. So, the",
      "offset": 331.44,
      "duration": 5.199
    },
    {
      "lang": "en",
      "text": "model just does it uh every time that",
      "offset": 333.759,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "you just set this frequency. This means",
      "offset": 336.639,
      "duration": 2.961
    },
    {
      "lang": "en",
      "text": "that for instance, in my case, I",
      "offset": 338.16,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "generated the daily tech digest task.",
      "offset": 339.6,
      "duration": 5.439
    },
    {
      "lang": "en",
      "text": "So, basically every day at 6 p.m. I want",
      "offset": 342.08,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "grock to just have a daily tech digest.",
      "offset": 345.039,
      "duration": 4.481
    },
    {
      "lang": "en",
      "text": "You can see here the prompt that I",
      "offset": 347.6,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "shared with the model and here uh you",
      "offset": 349.52,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "can see um one of the outputs that it",
      "offset": 352.08,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "gave me.",
      "offset": 354.88,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "All right. So, uh, and then there's like",
      "offset": 357.44,
      "duration": 4.479
    },
    {
      "lang": "en",
      "text": "the files feature that here basically it",
      "offset": 359.36,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "stores all the files that, uh, I either",
      "offset": 361.919,
      "duration": 3.761
    },
    {
      "lang": "en",
      "text": "share with the model or that the model",
      "offset": 364,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "outputs me. So, we will see more about",
      "offset": 365.68,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "this later, but now let's just start",
      "offset": 368.16,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "with the chat. Um, let's go to Gro 4",
      "offset": 369.68,
      "duration": 8
    },
    {
      "lang": "en",
      "text": "and, um, let's ask it to reason why the",
      "offset": 372.56,
      "duration": 7.04
    },
    {
      "lang": "en",
      "text": "temperature",
      "offset": 377.68,
      "duration": 7.32
    },
    {
      "lang": "en",
      "text": "on Earth is rising.",
      "offset": 379.6,
      "duration": 5.4
    },
    {
      "lang": "en",
      "text": "The first thing we can see is that the",
      "offset": 385.039,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "model tells us that it is thinking. I",
      "offset": 386.4,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "really like this feature and actually um",
      "offset": 388.639,
      "duration": 3.201
    },
    {
      "lang": "en",
      "text": "it's something that has not been",
      "offset": 390.479,
      "duration": 3.201
    },
    {
      "lang": "en",
      "text": "implemented in many of the of the",
      "offset": 391.84,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "models. Um Tajibity for instance doesn't",
      "offset": 393.68,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "have it and this recalls me of deepse.",
      "offset": 395.84,
      "duration": 4.479
    },
    {
      "lang": "en",
      "text": "So basically this allows us to see the",
      "offset": 398,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "reasoning the process uh that the gro in",
      "offset": 400.319,
      "duration": 5.201
    },
    {
      "lang": "en",
      "text": "this case is making in order to generate",
      "offset": 403.36,
      "duration": 5.92
    },
    {
      "lang": "en",
      "text": "an output for our question. All right.",
      "offset": 405.52,
      "duration": 7.119
    },
    {
      "lang": "en",
      "text": "So now we can see quite um a formulated",
      "offset": 409.28,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "answer here in the beginning. Um we can",
      "offset": 412.639,
      "duration": 4.721
    },
    {
      "lang": "en",
      "text": "see that the thought uh just lasted 26",
      "offset": 414.88,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "seconds is a feature that I really liked",
      "offset": 417.36,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "as well. It lets us know basically how",
      "offset": 419.12,
      "duration": 4.799
    },
    {
      "lang": "en",
      "text": "long does it take for the model to just",
      "offset": 421.84,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "generate a response for our prompt. And",
      "offset": 423.919,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "then you can see like a quite structured",
      "offset": 426.16,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "answer and with different uh sources and",
      "offset": 428.24,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "sites. So basically it is quite uh a",
      "offset": 431.28,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "nice output but like it's uh uh in the",
      "offset": 434.24,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "end it's just like a response of a model",
      "offset": 436.8,
      "duration": 5.119
    },
    {
      "lang": "en",
      "text": "but now if we go to compare it well it's",
      "offset": 439.12,
      "duration": 5.84
    },
    {
      "lang": "en",
      "text": "still finishing.",
      "offset": 441.919,
      "duration": 6.241
    },
    {
      "lang": "en",
      "text": "So let's wait for a bit until it just",
      "offset": 444.96,
      "duration": 5.679
    },
    {
      "lang": "en",
      "text": "finishes and then what we will do is",
      "offset": 448.16,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "just go back to Gro 3 and see the",
      "offset": 450.639,
      "duration": 5.041
    },
    {
      "lang": "en",
      "text": "difference between the output. Now it is",
      "offset": 453.52,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "done. So the thought just lasted 26",
      "offset": 455.68,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "seconds and then the output just took a",
      "offset": 458.08,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "little bit longer. So now uh let's just",
      "offset": 460.08,
      "duration": 7.6
    },
    {
      "lang": "en",
      "text": "copy the same prompt as before",
      "offset": 462.88,
      "duration": 10.08
    },
    {
      "lang": "en",
      "text": "and use gro 3 for it.",
      "offset": 467.68,
      "duration": 7.04
    },
    {
      "lang": "en",
      "text": "So in this case we see that first the",
      "offset": 472.96,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "output is right away. There's no",
      "offset": 474.72,
      "duration": 5.759
    },
    {
      "lang": "en",
      "text": "thinking time and there um graph doesn't",
      "offset": 476.24,
      "duration": 6.56
    },
    {
      "lang": "en",
      "text": "show us uh the process or the reasoning",
      "offset": 480.479,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "behind the output that it's uh",
      "offset": 482.8,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "formulating and we don't have any uh",
      "offset": 484.479,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "sources or any sites on on the on the",
      "offset": 486.72,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "response. So basically we can uh already",
      "offset": 489.599,
      "duration": 5.201
    },
    {
      "lang": "en",
      "text": "see the big differences between Grock 4",
      "offset": 492.16,
      "duration": 5.039
    },
    {
      "lang": "en",
      "text": "and Gro 3 and the big upgrade that Grock",
      "offset": 494.8,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "4 represents uh when compared to its uh",
      "offset": 497.199,
      "duration": 5.84
    },
    {
      "lang": "en",
      "text": "prior model that was um Grock 3. All",
      "offset": 500.16,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "right. So now that we have already",
      "offset": 503.039,
      "duration": 2.88
    },
    {
      "lang": "en",
      "text": "interacted a little bit with the model,",
      "offset": 504.479,
      "duration": 3.361
    },
    {
      "lang": "en",
      "text": "what we are going to do is just uh",
      "offset": 505.919,
      "duration": 3.441
    },
    {
      "lang": "en",
      "text": "discuss a little bit the differences",
      "offset": 507.84,
      "duration": 5.199
    },
    {
      "lang": "en",
      "text": "between Grock 4 and Grock for heavy. So",
      "offset": 509.36,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "remember that if we go to select the",
      "offset": 513.039,
      "duration": 3.521
    },
    {
      "lang": "en",
      "text": "model here, we will see two different",
      "offset": 515.12,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "options. Grock 4 and Gro for heavy. And",
      "offset": 516.56,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "I'm pretty sure most of you are still",
      "offset": 518.8,
      "duration": 2.56
    },
    {
      "lang": "en",
      "text": "wondering uh what's the difference",
      "offset": 520.08,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "between these two models to make um",
      "offset": 521.36,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "clearly the difference between them. I'm",
      "offset": 523.919,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "going to use the pricing uh web. So you",
      "offset": 525.44,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "can see there's different pricings to",
      "offset": 528,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "access Gro for and to access Gro for",
      "offset": 529.76,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "heavy and one of them is clearly more",
      "offset": 532.32,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "expensive than the other. So the main",
      "offset": 534,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "difference between them is that Gro for",
      "offset": 536.24,
      "duration": 3.279
    },
    {
      "lang": "en",
      "text": "is the normal model. It has all the",
      "offset": 537.76,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "upgrades. It has all the improvements",
      "offset": 539.519,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "but it is a single agent model. This",
      "offset": 541.44,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "means that whenever we ask this model a",
      "offset": 543.36,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "task, only one AI agent will uh perform",
      "offset": 545.36,
      "duration": 5.919
    },
    {
      "lang": "en",
      "text": "this task for us. On the other side,",
      "offset": 548.8,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "Grock for heavy, it's a multi- aent",
      "offset": 551.279,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "model. This means that we have different",
      "offset": 553.6,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "AI agents working at the same time in",
      "offset": 555.12,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "the same task and then they will share",
      "offset": 557.6,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "the results and find the optimal",
      "offset": 559.68,
      "duration": 2.88
    },
    {
      "lang": "en",
      "text": "solution together. In order to",
      "offset": 561.2,
      "duration": 2.96
    },
    {
      "lang": "en",
      "text": "understand this, let's make a simple",
      "offset": 562.56,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "analogy. Imagine you you are the CEO of",
      "offset": 564.16,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "a big company and you have a complicated",
      "offset": 566.8,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "project to do. So what you can do is",
      "offset": 568.8,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "just take four different engineers and",
      "offset": 571.12,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "ask them to do the same project. The",
      "offset": 573.68,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "thing is all of them will just work on",
      "offset": 576.48,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "the same project but independently okay",
      "offset": 579.04,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "on their own but in a couple weeks they",
      "offset": 581.92,
      "duration": 3.599
    },
    {
      "lang": "en",
      "text": "will come back and they will share the",
      "offset": 584.08,
      "duration": 3.199
    },
    {
      "lang": "en",
      "text": "results with the others and what they",
      "offset": 585.519,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "will do is they will see which is the",
      "offset": 587.279,
      "duration": 5.201
    },
    {
      "lang": "en",
      "text": "optimal solution or collaboratively they",
      "offset": 589.68,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "will improve the the process that each",
      "offset": 592.48,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "of them did to find the best solution",
      "offset": 594.64,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "basically. So that's the main difference",
      "offset": 596.88,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "between both models. Grocer is a single",
      "offset": 598.48,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "agent while Gro for heavy is multi-",
      "offset": 600.88,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "aent. And now let's talk about the",
      "offset": 603.44,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "pricing. Groc 3 the predecessor of this",
      "offset": 605.279,
      "duration": 4.961
    },
    {
      "lang": "en",
      "text": "model will always be free. Okay. So",
      "offset": 607.92,
      "duration": 5.039
    },
    {
      "lang": "en",
      "text": "basically you have uh access to it a",
      "offset": 610.24,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "little bit limited but still enough to",
      "offset": 612.959,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "just use it uh in a daily basis. And",
      "offset": 614.72,
      "duration": 4.559
    },
    {
      "lang": "en",
      "text": "then we have true main membership that",
      "offset": 617.12,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "can be monthly or yearly as you can",
      "offset": 619.279,
      "duration": 5.281
    },
    {
      "lang": "en",
      "text": "observe here. So basically the $30 per",
      "offset": 621.44,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "month uh gives you unlimited access to",
      "offset": 624.56,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "Grock 4 basically and then we have a",
      "offset": 626.88,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "$300 uh subscription that is like the",
      "offset": 629.36,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "super Grock heavy that gives you",
      "offset": 632.16,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "unlimited access of Grock 4 of course",
      "offset": 634.24,
      "duration": 3.599
    },
    {
      "lang": "en",
      "text": "and then gives you access to Grock for",
      "offset": 636,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "heavy. The main difference between them",
      "offset": 637.839,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "of course is the usage of Grock for",
      "offset": 639.68,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "heavy. We will see later that Grock for",
      "offset": 641.44,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "heavy actually has like a better",
      "offset": 643.6,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "performance than Grock for but still",
      "offset": 645.6,
      "duration": 2.96
    },
    {
      "lang": "en",
      "text": "Grock for has a really really good",
      "offset": 647.04,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "performance. And on the other side what",
      "offset": 648.56,
      "duration": 6.56
    },
    {
      "lang": "en",
      "text": "we will see is that um it will have",
      "offset": 651.36,
      "duration": 5.599
    },
    {
      "lang": "en",
      "text": "early access to the new features that",
      "offset": 655.12,
      "duration": 6.399
    },
    {
      "lang": "en",
      "text": "are um that the model gets over time and",
      "offset": 656.959,
      "duration": 6.481
    },
    {
      "lang": "en",
      "text": "then we can access this model using",
      "offset": 661.519,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "another way and it is the API. This is a",
      "offset": 663.44,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "more technical way to access the model.",
      "offset": 665.519,
      "duration": 4.241
    },
    {
      "lang": "en",
      "text": "So basically what we will see here is",
      "offset": 667.92,
      "duration": 3.599
    },
    {
      "lang": "en",
      "text": "that we have different APIs that we can",
      "offset": 669.76,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "use to access uh these models. And the",
      "offset": 671.519,
      "duration": 5.041
    },
    {
      "lang": "en",
      "text": "most important thing for me is that",
      "offset": 674.56,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "Grock 4 and Gro 3 have exactly the same",
      "offset": 676.56,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "price which is quite impressive. They",
      "offset": 679.04,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "maintain the the price is quite low. You",
      "offset": 681.2,
      "duration": 4.879
    },
    {
      "lang": "en",
      "text": "can see Grock 3 here it has like uh $3",
      "offset": 682.8,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "per million tokens while Gro 4 has like",
      "offset": 686.079,
      "duration": 4.561
    },
    {
      "lang": "en",
      "text": "$3 per million tokens as well. The main",
      "offset": 688.48,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "differences between them is um that the",
      "offset": 690.64,
      "duration": 5.439
    },
    {
      "lang": "en",
      "text": "context of Grock 4 is way bigger uh as",
      "offset": 692.88,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "we uh said before but there's um a",
      "offset": 696.079,
      "duration": 5.681
    },
    {
      "lang": "en",
      "text": "limitation of 60 requests uh per minute",
      "offset": 698.88,
      "duration": 5.519
    },
    {
      "lang": "en",
      "text": "while in graph 3 uh you have a 600. So",
      "offset": 701.76,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "actually this is quite a big limitation",
      "offset": 704.399,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "when you are you want to scale uh",
      "offset": 705.92,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "whatever you're using for the large",
      "offset": 708.399,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "language model you want to scale the the",
      "offset": 709.92,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "application but still for testing and",
      "offset": 711.839,
      "duration": 3.761
    },
    {
      "lang": "en",
      "text": "for developing uh it is quite nice to",
      "offset": 713.36,
      "duration": 4.719
    },
    {
      "lang": "en",
      "text": "have like this quite low price and this",
      "offset": 715.6,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "is uh the two main ways you can access",
      "offset": 718.079,
      "duration": 4.961
    },
    {
      "lang": "en",
      "text": "uh gro either using the interface uh by",
      "offset": 720.48,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "paying this membership or uh using the",
      "offset": 723.04,
      "duration": 6.239
    },
    {
      "lang": "en",
      "text": "API and as you've seen um the prices in",
      "offset": 725.68,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "this case are quite similar for both",
      "offset": 729.279,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "Groc 3 and Groc 4. Now let's focus a",
      "offset": 731.04,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "little bit on the new features that this",
      "offset": 733.44,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "model presents. Uh so for me one of the",
      "offset": 735.04,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "most important ones is the context",
      "offset": 737.44,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "window. As I have already said before,",
      "offset": 738.8,
      "duration": 4.719
    },
    {
      "lang": "en",
      "text": "it doubles the size uh of croc 3 and now",
      "offset": 740.56,
      "duration": 6.24
    },
    {
      "lang": "en",
      "text": "it presents a context window of 256,000",
      "offset": 743.519,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "tokens. To make it clear, basically this",
      "offset": 746.8,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "means that we can just uh send longer",
      "offset": 748.639,
      "duration": 5.041
    },
    {
      "lang": "en",
      "text": "prompts for every interaction we have",
      "offset": 752.16,
      "duration": 3.119
    },
    {
      "lang": "en",
      "text": "with the model. And this means that we",
      "offset": 753.68,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "can just contextualize better and give",
      "offset": 755.279,
      "duration": 3.761
    },
    {
      "lang": "en",
      "text": "more information to the task we expect",
      "offset": 757.12,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "it to perform for us. Another uh good",
      "offset": 759.04,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "improvement is the reasoning and",
      "offset": 761.279,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "especially the academic reasoning. We",
      "offset": 763.04,
      "duration": 2.72
    },
    {
      "lang": "en",
      "text": "will see later in the benchmarks but",
      "offset": 764.399,
      "duration": 3.201
    },
    {
      "lang": "en",
      "text": "basically the scores are quite amazing",
      "offset": 765.76,
      "duration": 2.879
    },
    {
      "lang": "en",
      "text": "especially when compared to the",
      "offset": 767.6,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "predecessor and they outperform uh all",
      "offset": 768.639,
      "duration": 5.361
    },
    {
      "lang": "en",
      "text": "the top competitors of Grock 4. Another",
      "offset": 772,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "important feature that uh uh during the",
      "offset": 774,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "live stream they gave a lot of uh",
      "offset": 776.32,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "importance. It was that it has been",
      "offset": 777.92,
      "duration": 5.039
    },
    {
      "lang": "en",
      "text": "natively trained to use tools. So uh it",
      "offset": 780,
      "duration": 4.639
    },
    {
      "lang": "en",
      "text": "means that it doesn't rely on the",
      "offset": 782.959,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "built-in knowledge but it knows how to",
      "offset": 784.639,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "reach out, how to retrieve data and how",
      "offset": 786.399,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "to apply it. And this is a big big",
      "offset": 788.24,
      "duration": 3.599
    },
    {
      "lang": "en",
      "text": "upgrade when compared to the",
      "offset": 790.56,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "predecessor. Another uh feature is the",
      "offset": 791.839,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "agentic design. This means that uh",
      "offset": 794.24,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "basically Grog 4 can act more like a",
      "offset": 796.639,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "thinking system, right? Um either if we",
      "offset": 799.36,
      "duration": 6.159
    },
    {
      "lang": "en",
      "text": "use um the normal version, the Gro 4 or",
      "offset": 802.399,
      "duration": 5.201
    },
    {
      "lang": "en",
      "text": "the Gro for heavy, but basically we have",
      "offset": 805.519,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "agents that can just work behind the",
      "offset": 807.6,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "scenes and perform uh whatever task uh",
      "offset": 809.279,
      "duration": 4.721
    },
    {
      "lang": "en",
      "text": "we ask. And finally uh there's another",
      "offset": 811.6,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "feature, but it's only for the mobile",
      "offset": 814,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "phone apps and it is basically the boys",
      "offset": 815.76,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "mode. uh it presents uh a new voice",
      "offset": 817.76,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "called if uh it is British sounding and",
      "offset": 820.24,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "basically uh it improves way better and",
      "offset": 822.72,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "it sounds more natural but uh as I said",
      "offset": 824.72,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "before this is not something that uh can",
      "offset": 826.639,
      "duration": 4.481
    },
    {
      "lang": "en",
      "text": "be accessed uh using the the computer",
      "offset": 828.639,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "and finally um I would like to mention a",
      "offset": 831.12,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "limitation and basically it is the image",
      "offset": 833.279,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "generation we will actually work on it",
      "offset": 834.88,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "uh in a couple minutes and we will see",
      "offset": 837.12,
      "duration": 4.719
    },
    {
      "lang": "en",
      "text": "but uh basically the image generation is",
      "offset": 839.199,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "not the best so I think it's one of the",
      "offset": 841.839,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "most important limitation of the model",
      "offset": 843.6,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "but still they have said that in the",
      "offset": 845.279,
      "duration": 3.521
    },
    {
      "lang": "en",
      "text": "coming weeks uh they want to work on",
      "offset": 847.12,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "this and upgrade the image generation of",
      "offset": 848.8,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "croc 4. All right. So now let us start",
      "offset": 850.72,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "playing a little bit with the model and",
      "offset": 852.959,
      "duration": 3.521
    },
    {
      "lang": "en",
      "text": "see how it behaves and uh I've prepared",
      "offset": 854.24,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "different task in order to just uh check",
      "offset": 856.48,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "it a little bit. So the first one is",
      "offset": 858.88,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "just uh I want to check the knowledge uh",
      "offset": 860.56,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "that uh the model has and um the fact",
      "offset": 862.8,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "checking ability. The first thing we",
      "offset": 865.6,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "need to do is like make sure we're using",
      "offset": 867.04,
      "duration": 3.599
    },
    {
      "lang": "en",
      "text": "gro 4. Okay, by default it's always",
      "offset": 868.72,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "going to be Groc 3. So um my first",
      "offset": 870.639,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "prompt is going to be what was the",
      "offset": 873.6,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "outcome of the 2024 US presidential",
      "offset": 875.04,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "election including the winner keyboard",
      "offset": 877.12,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "margins in swing states and any major",
      "offset": 879.12,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "post-election events up to July 2025",
      "offset": 880.959,
      "duration": 4.721
    },
    {
      "lang": "en",
      "text": "cross check against reliable sources",
      "offset": 883.68,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "that avoid outdated or inaccurate",
      "offset": 885.68,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "information. All right so the first",
      "offset": 887.44,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "thing I'm going to see is uh it's going",
      "offset": 889.6,
      "duration": 3.359
    },
    {
      "lang": "en",
      "text": "to start uh thinking and it's going to",
      "offset": 891.12,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "start showing me the whole process of",
      "offset": 892.959,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "the thinking. And now this is going to",
      "offset": 895.12,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "take uh uh a little bit of a time but we",
      "offset": 896.88,
      "duration": 5.84
    },
    {
      "lang": "en",
      "text": "will see that uh we can actually check",
      "offset": 900.16,
      "duration": 4.479
    },
    {
      "lang": "en",
      "text": "um that uh for instance it was checking",
      "offset": 902.72,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "Wikipedia now it's checking CNN, Fox",
      "offset": 904.639,
      "duration": 4.721
    },
    {
      "lang": "en",
      "text": "News. So we can see that uh the model",
      "offset": 906.72,
      "duration": 4.799
    },
    {
      "lang": "en",
      "text": "actually just goes to the web and",
      "offset": 909.36,
      "duration": 5.279
    },
    {
      "lang": "en",
      "text": "searches for uh aligned information um",
      "offset": 911.519,
      "duration": 6.481
    },
    {
      "lang": "en",
      "text": "to what I've asked and it actually um",
      "offset": 914.639,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "works and uh starts um getting",
      "offset": 918,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "information from different sources.",
      "offset": 920.399,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "Right? So this is something that I asked",
      "offset": 922.24,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "it to do and uh um that I wanted to",
      "offset": 923.839,
      "duration": 4.481
    },
    {
      "lang": "en",
      "text": "cross check against reliable sources.",
      "offset": 926.399,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "This new feature that it shows me the",
      "offset": 928.32,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "whole process of thinking. It's really",
      "offset": 930.32,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "helpful to see if the model is actually",
      "offset": 932.32,
      "duration": 6.759
    },
    {
      "lang": "en",
      "text": "doing what I ask it to do or not.",
      "offset": 934.56,
      "duration": 4.519
    },
    {
      "lang": "en",
      "text": "All right. So now it says that the",
      "offset": 944.079,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "thought was for 24 seconds and now",
      "offset": 945.68,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "generating uh a proper output. It's",
      "offset": 947.519,
      "duration": 5.281
    },
    {
      "lang": "en",
      "text": "working this time and we can see that",
      "offset": 950.48,
      "duration": 5.84
    },
    {
      "lang": "en",
      "text": "it's kind of an elaborated response. Um",
      "offset": 952.8,
      "duration": 5.599
    },
    {
      "lang": "en",
      "text": "it actually uh went to the swing state",
      "offset": 956.32,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "that I asked and um added the",
      "offset": 958.399,
      "duration": 3.521
    },
    {
      "lang": "en",
      "text": "information. We can check that this",
      "offset": 960.48,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "information um is is correct. So uh",
      "offset": 961.92,
      "duration": 6.4
    },
    {
      "lang": "en",
      "text": "basically it performed uh quite well the",
      "offset": 965.92,
      "duration": 6.88
    },
    {
      "lang": "en",
      "text": "task that I first asked it to do.",
      "offset": 968.32,
      "duration": 6.639
    },
    {
      "lang": "en",
      "text": "We can see that it's just finished. So",
      "offset": 972.8,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "it takes quite a long time to think. it",
      "offset": 974.959,
      "duration": 8
    },
    {
      "lang": "en",
      "text": "was around 80 seconds 84 and um still",
      "offset": 977.44,
      "duration": 8.56
    },
    {
      "lang": "en",
      "text": "the answer is quite fast once uh it has",
      "offset": 982.959,
      "duration": 5.921
    },
    {
      "lang": "en",
      "text": "had all the all the thinking process now",
      "offset": 986,
      "duration": 5.199
    },
    {
      "lang": "en",
      "text": "let's just go for the second task in",
      "offset": 988.88,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "this case I want to check the",
      "offset": 991.199,
      "duration": 2.721
    },
    {
      "lang": "en",
      "text": "mathematical reasoning and I'm going to",
      "offset": 992.32,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "start with a prompt that GPT for at some",
      "offset": 993.92,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "point um didn't perform properly and it",
      "offset": 996.32,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "is if x and y are the 10th digit and the",
      "offset": 999.44,
      "duration": 4.639
    },
    {
      "lang": "en",
      "text": "unit digit respectively of the product",
      "offset": 1001.68,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "of these two numbers what is the value",
      "offset": 1004.079,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "of x + y. Can you explain the easy",
      "offset": 1006.24,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "solution without calculating the whole",
      "offset": 1008.639,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "number? So let's see basically um how it",
      "offset": 1010.16,
      "duration": 5.84
    },
    {
      "lang": "en",
      "text": "proceeds and how does like the whole",
      "offset": 1014.079,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "reasoning and see if the mathematical uh",
      "offset": 1016,
      "duration": 5.519
    },
    {
      "lang": "en",
      "text": "procedure of um rock for it was quite",
      "offset": 1018.399,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "fast to be very honest. It only took 8",
      "offset": 1021.519,
      "duration": 6.32
    },
    {
      "lang": "en",
      "text": "seconds for it to respond and the answer",
      "offset": 1023.759,
      "duration": 7.521
    },
    {
      "lang": "en",
      "text": "is correct because it is 12. So actually",
      "offset": 1027.839,
      "duration": 5.761
    },
    {
      "lang": "en",
      "text": "it was really really fast. Uh I'm quite",
      "offset": 1031.28,
      "duration": 5.279
    },
    {
      "lang": "en",
      "text": "surprised about it and um the whole",
      "offset": 1033.6,
      "duration": 7.12
    },
    {
      "lang": "en",
      "text": "process is uh quite um neat. Right. So a",
      "offset": 1036.559,
      "duration": 6.88
    },
    {
      "lang": "en",
      "text": "second uh thing I want to try uh I have",
      "offset": 1040.72,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "another prompt here is uh another",
      "offset": 1043.439,
      "duration": 5.041
    },
    {
      "lang": "en",
      "text": "mathematical problem to see uh if this",
      "offset": 1046.16,
      "duration": 5.519
    },
    {
      "lang": "en",
      "text": "time it takes longer or um it just goes",
      "offset": 1048.48,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "super fast as well. In this case it is",
      "offset": 1051.679,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "use all digits from 0 to 9 exactly once",
      "offset": 1053.44,
      "duration": 5.84
    },
    {
      "lang": "en",
      "text": "to make three numbers x y z such that x",
      "offset": 1055.84,
      "duration": 7.68
    },
    {
      "lang": "en",
      "text": "+ y equals z. And now um we will see it",
      "offset": 1059.28,
      "duration": 6.08
    },
    {
      "lang": "en",
      "text": "is analyzing the problem. It is doing",
      "offset": 1063.52,
      "duration": 5.48
    },
    {
      "lang": "en",
      "text": "like the whole reasoning.",
      "offset": 1065.36,
      "duration": 3.64
    },
    {
      "lang": "en",
      "text": "We can see it keeps showing us like the",
      "offset": 1070.4,
      "duration": 6.36
    },
    {
      "lang": "en",
      "text": "thinking it it does",
      "offset": 1072.96,
      "duration": 3.8
    },
    {
      "lang": "en",
      "text": "now. It is executing some code.",
      "offset": 1076.799,
      "duration": 4.361
    },
    {
      "lang": "en",
      "text": "All right. Like it gave us one possible",
      "offset": 1085.28,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "solution and uh it is correct. It took a",
      "offset": 1087.36,
      "duration": 6.4
    },
    {
      "lang": "en",
      "text": "a little bit of a time 125 uh seconds,",
      "offset": 1090.72,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "but still the the final output is is",
      "offset": 1093.76,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "good. Now let's go for the third task.",
      "offset": 1096.16,
      "duration": 2.96
    },
    {
      "lang": "en",
      "text": "In this case, what I want to see is",
      "offset": 1097.919,
      "duration": 3.441
    },
    {
      "lang": "en",
      "text": "first the integration of Grock with X.",
      "offset": 1099.12,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "In the end, they are both part of the",
      "offset": 1101.36,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "same uh company. And uh on the other",
      "offset": 1103.2,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "side to see um how it can use this tools",
      "offset": 1105.76,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "to effectively um get or fetch the data",
      "offset": 1108.32,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "that we're asking for. So in this case,",
      "offset": 1111.28,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "the prompt I'm going to use is tell me",
      "offset": 1113.2,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "about data cam's latest post on on the",
      "offset": 1115.36,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "exocial network and then find the latest",
      "offset": 1117.28,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "blog on their website, summarize",
      "offset": 1119.679,
      "duration": 2.801
    },
    {
      "lang": "en",
      "text": "information contained and provide the",
      "offset": 1121.12,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "link to the post. So let's see first how",
      "offset": 1122.48,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "long does it take to do all of this and",
      "offset": 1125.84,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "then if it does it correctly. I'm going",
      "offset": 1127.84,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "to check uh the latest um x post of data",
      "offset": 1129.36,
      "duration": 6.08
    },
    {
      "lang": "en",
      "text": "cam and see uh what it does. Here we can",
      "offset": 1133.28,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "see that it's uh guessing the cam's x",
      "offset": 1135.44,
      "duration": 4.239
    },
    {
      "lang": "en",
      "text": "handle is likely data cam. Uh in this",
      "offset": 1137.679,
      "duration": 3.761
    },
    {
      "lang": "en",
      "text": "case it's correct but we will see how it",
      "offset": 1139.679,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "goes and how long uh it takes to perform",
      "offset": 1141.44,
      "duration": 5.8
    },
    {
      "lang": "en",
      "text": "the whole thing.",
      "offset": 1143.76,
      "duration": 3.48
    },
    {
      "lang": "en",
      "text": "Now it's go going to data cam's blog and",
      "offset": 1147.76,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "uh it's checking different sources um to",
      "offset": 1150.32,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "see it's browsing actually the data",
      "offset": 1152.64,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "cam's blog to see the latest.",
      "offset": 1154.32,
      "duration": 5.92
    },
    {
      "lang": "en",
      "text": "We can see that the latest uh data cam's",
      "offset": 1157.44,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "post uh uh article is about gro 4",
      "offset": 1160.24,
      "duration": 4.559
    },
    {
      "lang": "en",
      "text": "actually.",
      "offset": 1162.72,
      "duration": 6.92
    },
    {
      "lang": "en",
      "text": "And now it is browsing it. That's good.",
      "offset": 1164.799,
      "duration": 4.841
    },
    {
      "lang": "en",
      "text": "Okay, it says dataccom's most recent",
      "offset": 1171.2,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "post on the X social network dated July",
      "offset": 1172.96,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "10 promotes a free webinar aimed to",
      "offset": 1175.039,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "individual deciding between careers as a",
      "offset": 1177.12,
      "duration": 3.679
    },
    {
      "lang": "en",
      "text": "data scientist or analytics engineer.",
      "offset": 1178.88,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "Okay, so let's just check it and we can",
      "offset": 1180.799,
      "duration": 5.281
    },
    {
      "lang": "en",
      "text": "see that it is correct trying to choose",
      "offset": 1183.12,
      "duration": 4.799
    },
    {
      "lang": "en",
      "text": "between uh being a data scientist or",
      "offset": 1186.08,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "analytics engineer at uh this free",
      "offset": 1187.919,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "webinar. Okay, so that's perfectly",
      "offset": 1190.16,
      "duration": 3.759
    },
    {
      "lang": "en",
      "text": "correct. It says that the latest blog on",
      "offset": 1192,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "datacam's website is titled Grock for",
      "offset": 1193.919,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "test features benchmark access and more",
      "offset": 1196.24,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "published on July 10 which is actually",
      "offset": 1198.24,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "correct as well and we can see here that",
      "offset": 1200.24,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "it performs correctly the task and then",
      "offset": 1202,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "it summarizes and has like the key",
      "offset": 1204.08,
      "duration": 5.599
    },
    {
      "lang": "en",
      "text": "features of this data cam block. So this",
      "offset": 1205.919,
      "duration": 6.481
    },
    {
      "lang": "en",
      "text": "is perfect uh it's done it uh perfectly",
      "offset": 1209.679,
      "duration": 4.961
    },
    {
      "lang": "en",
      "text": "fine. All right now let's go for the",
      "offset": 1212.4,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "fourth task. In this case, what I want",
      "offset": 1214.64,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "to do is first um check the extended um",
      "offset": 1216.08,
      "duration": 7.92
    },
    {
      "lang": "en",
      "text": "Windows context of gro and test another",
      "offset": 1220.16,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "um use case that many people use and",
      "offset": 1224,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "basically is to use this kind of chat",
      "offset": 1225.84,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "bots to summarize and analyze reports.",
      "offset": 1227.76,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "So in this case what I'm going to use is",
      "offset": 1230.88,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "the future of jobs uh report for the",
      "offset": 1232.48,
      "duration": 6.16
    },
    {
      "lang": "en",
      "text": "world economic forum uh of 2025. So the",
      "offset": 1234.96,
      "duration": 8.959
    },
    {
      "lang": "en",
      "text": "prompt is going to be the following one.",
      "offset": 1238.64,
      "duration": 10.399
    },
    {
      "lang": "en",
      "text": "And now I'm going to upload",
      "offset": 1243.919,
      "duration": 8.801
    },
    {
      "lang": "en",
      "text": "the document itself that I have it here.",
      "offset": 1249.039,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "So basically what I'm going to do is",
      "offset": 1252.72,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "like I'm going to attach the the PDF the",
      "offset": 1253.919,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "document and I want it to analyze the",
      "offset": 1256.24,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "entire report identify the three most",
      "offset": 1258.32,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "informative graph summarize each one and",
      "offset": 1260,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "let me know which page of PDF they",
      "offset": 1262.08,
      "duration": 5.24
    },
    {
      "lang": "en",
      "text": "appear on.",
      "offset": 1263.919,
      "duration": 3.401
    },
    {
      "lang": "en",
      "text": "All right, it's already finished. It",
      "offset": 1271.44,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "took 21 seconds and then it says that",
      "offset": 1273.039,
      "duration": 6.161
    },
    {
      "lang": "en",
      "text": "the figure 2.5 job growth on decline on",
      "offset": 1275.84,
      "duration": 6.56
    },
    {
      "lang": "en",
      "text": "page 24. So that's I'm going to check it",
      "offset": 1279.2,
      "duration": 6.479
    },
    {
      "lang": "en",
      "text": "right now. So this is correct uh in the",
      "offset": 1282.4,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "page 24 there's like this uh figure and",
      "offset": 1285.679,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "actually it's it's one of the most",
      "offset": 1288.08,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "important of on the report and basically",
      "offset": 1289.919,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "it says uh which jobs are going to grow",
      "offset": 1292.4,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "and which ones are going to decrease",
      "offset": 1295.039,
      "duration": 5.041
    },
    {
      "lang": "en",
      "text": "basically and have less uh job openings",
      "offset": 1297.28,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "in the future. And then it says two",
      "offset": 1300.08,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "other figures that we can check. But as",
      "offset": 1302.08,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "we can see the the task was performed",
      "offset": 1304.64,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "correctly and um it just analyzed in a",
      "offset": 1307.44,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "really really short amount of time just",
      "offset": 1310.32,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "21 seconds a report that is over 200 uh",
      "offset": 1312.08,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "pages and it um answered correctly the",
      "offset": 1315.36,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "task. So that's perfectly fine. And",
      "offset": 1317.76,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "actually you can use this on your own",
      "offset": 1320.08,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "just to um chat with any PDF document or",
      "offset": 1322.32,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "just upload it and let Grock for analyze",
      "offset": 1325.36,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "it for you and get like the most",
      "offset": 1327.84,
      "duration": 2.88
    },
    {
      "lang": "en",
      "text": "important insights. All right. Right. So",
      "offset": 1329.12,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "now let's go for the next task.",
      "offset": 1330.72,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "Basically in this case what I want to",
      "offset": 1332.72,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "see I want to check is the advanced",
      "offset": 1334.32,
      "duration": 4.479
    },
    {
      "lang": "en",
      "text": "reasoning of super grog and especially",
      "offset": 1336.559,
      "duration": 6.081
    },
    {
      "lang": "en",
      "text": "to see how it behaves when I ask uh",
      "offset": 1338.799,
      "duration": 5.441
    },
    {
      "lang": "en",
      "text": "quite an advanced question. In this case",
      "offset": 1342.64,
      "duration": 2.72
    },
    {
      "lang": "en",
      "text": "it's going to be like a physics",
      "offset": 1344.24,
      "duration": 2.24
    },
    {
      "lang": "en",
      "text": "question. The first thing I'm going to",
      "offset": 1345.36,
      "duration": 4.559
    },
    {
      "lang": "en",
      "text": "do is just uh put here the prompt. I",
      "offset": 1346.48,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "want to evaluate your ability to solve",
      "offset": 1349.919,
      "duration": 3.441
    },
    {
      "lang": "en",
      "text": "PhD level physics problems involving",
      "offset": 1351.44,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "electromagnetism. Attach is a multifar",
      "offset": 1353.36,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "question entitled problem two.",
      "offset": 1355.44,
      "duration": 3.359
    },
    {
      "lang": "en",
      "text": "Electromagnetism true. And then I",
      "offset": 1356.88,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "describe the whole thing here. And just",
      "offset": 1358.799,
      "duration": 4.641
    },
    {
      "lang": "en",
      "text": "in case I emphasize again that I attach",
      "offset": 1360.96,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "the problem as a PNG image. So now what",
      "offset": 1363.44,
      "duration": 5.92
    },
    {
      "lang": "en",
      "text": "I'm going to do is just attach the",
      "offset": 1366.64,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "problem here. This is a problem of Yale",
      "offset": 1369.36,
      "duration": 5.679
    },
    {
      "lang": "en",
      "text": "for uh physics uh student basically. So",
      "offset": 1371.2,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "what I want to see with this is first",
      "offset": 1375.039,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "how the model processes the whole thing.",
      "offset": 1376.64,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "And then as we will see later in the",
      "offset": 1379.2,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "benchmarkings um Grock is supposed to be",
      "offset": 1381.039,
      "duration": 5.441
    },
    {
      "lang": "en",
      "text": "quite good at uh PhD level of questions",
      "offset": 1383.52,
      "duration": 7.039
    },
    {
      "lang": "en",
      "text": "in uh almost all fields. Um so now we",
      "offset": 1386.48,
      "duration": 6.88
    },
    {
      "lang": "en",
      "text": "will see how it starts just checking",
      "offset": 1390.559,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "analyzing the problem and getting um",
      "offset": 1393.36,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "aligned uh knowledge and content uh to",
      "offset": 1395.919,
      "duration": 4.721
    },
    {
      "lang": "en",
      "text": "solve it. A thing that I really like",
      "offset": 1398.64,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "about the interface of Grock is",
      "offset": 1400.64,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "basically that I can still keep seeing",
      "offset": 1402.96,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "my prompt but the thinking process just",
      "offset": 1405.44,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "keeps scrolling down. So basically what",
      "offset": 1408.96,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "I can see here is that I can just keep",
      "offset": 1411.44,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "seeing all steps of the processing of",
      "offset": 1413.28,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "the model but still I can see the",
      "offset": 1415.44,
      "duration": 3.359
    },
    {
      "lang": "en",
      "text": "prompt. So, I think this is a really",
      "offset": 1416.96,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "really good upgrade and um UX- wise is",
      "offset": 1418.799,
      "duration": 6.481
    },
    {
      "lang": "en",
      "text": "really nice just to be able to just keep",
      "offset": 1422.72,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "reading and following the whole process",
      "offset": 1425.28,
      "duration": 4.879
    },
    {
      "lang": "en",
      "text": "but still um have the prompt on screen",
      "offset": 1427.52,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "as well just to check that uh everything",
      "offset": 1430.159,
      "duration": 6.281
    },
    {
      "lang": "en",
      "text": "is on track.",
      "offset": 1432.64,
      "duration": 3.8
    },
    {
      "lang": "en",
      "text": "Now we see it's like uh just revisiting",
      "offset": 1439.44,
      "duration": 3.599
    },
    {
      "lang": "en",
      "text": "calculations and making sure like all",
      "offset": 1441.6,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "the process uh it has done is uh",
      "offset": 1443.039,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "properly done actually. So it is quite",
      "offset": 1445.12,
      "duration": 5.039
    },
    {
      "lang": "en",
      "text": "nice to just keep following um the the",
      "offset": 1447.44,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "whole process and the and the whole uh",
      "offset": 1450.159,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "chain of thoughts that the model is",
      "offset": 1452.48,
      "duration": 4.679
    },
    {
      "lang": "en",
      "text": "having.",
      "offset": 1454.159,
      "duration": 3
    },
    {
      "lang": "en",
      "text": "All right. So it seems we finally have",
      "offset": 1461.279,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "an answer. It took quite a long time",
      "offset": 1463.44,
      "duration": 6.64
    },
    {
      "lang": "en",
      "text": "over 350 seconds basically but we see it",
      "offset": 1465.679,
      "duration": 7.201
    },
    {
      "lang": "en",
      "text": "uh got like a final answer for all the",
      "offset": 1470.08,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "problem. One thing that I actually don't",
      "offset": 1472.88,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "like is that the mathematical",
      "offset": 1474.96,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "formulation is not properly done. Like",
      "offset": 1477.12,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "you see here, you can find like the",
      "offset": 1479.52,
      "duration": 5.279
    },
    {
      "lang": "en",
      "text": "latex um way of writing, but it's not um",
      "offset": 1481.2,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "shaped like a proper mathematical",
      "offset": 1484.799,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "formulation. So that's something I don't",
      "offset": 1486.72,
      "duration": 4.559
    },
    {
      "lang": "en",
      "text": "actually like. But like the whole",
      "offset": 1488.96,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "response is quite um well argumentated",
      "offset": 1491.279,
      "duration": 4.481
    },
    {
      "lang": "en",
      "text": "like we could see all the process. So it",
      "offset": 1493.76,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "was actually quite well done. And as we",
      "offset": 1495.76,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "will see later, the benchmarking for",
      "offset": 1498.64,
      "duration": 3.519
    },
    {
      "lang": "en",
      "text": "these kind of problems model GRO 4 is",
      "offset": 1500.08,
      "duration": 3.199
    },
    {
      "lang": "en",
      "text": "quite good.",
      "offset": 1502.159,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "Um but again um one of the things I",
      "offset": 1503.279,
      "duration": 5.041
    },
    {
      "lang": "en",
      "text": "don't like is the the way it writes the",
      "offset": 1505.919,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "this mathematical formulation is not uh",
      "offset": 1508.32,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "it's not nice and it's not friendly for",
      "offset": 1511.039,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "the user just to just to use it. Now",
      "offset": 1512.96,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "let's go for the next task. Uh I think",
      "offset": 1515.2,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "it's the sixth task now and um the main",
      "offset": 1517.279,
      "duration": 5.361
    },
    {
      "lang": "en",
      "text": "idea is to check the ability to code and",
      "offset": 1520.08,
      "duration": 4.479
    },
    {
      "lang": "en",
      "text": "to understand code of gro. You know, one",
      "offset": 1522.64,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "of the most important use cases of this",
      "offset": 1524.559,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "kind of class language models is to help",
      "offset": 1526.08,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "us while coding help us understand the",
      "offset": 1528.159,
      "duration": 4.241
    },
    {
      "lang": "en",
      "text": "code we have and help us understand uh",
      "offset": 1530.08,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "if there's some errors or correct the",
      "offset": 1532.4,
      "duration": 3.759
    },
    {
      "lang": "en",
      "text": "code or generate new code. Basically,",
      "offset": 1534.08,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "what I'm going to share with Grock now",
      "offset": 1536.159,
      "duration": 5.281
    },
    {
      "lang": "en",
      "text": "is the following prompt and it is can",
      "offset": 1538.64,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "you review the following Python function",
      "offset": 1541.44,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "and tell me if it's correct implementing",
      "offset": 1543.12,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "the Fibonacci sequence. If it's",
      "offset": 1545.2,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "incorrect, please explain what's wrong",
      "offset": 1547.039,
      "duration": 3.041
    },
    {
      "lang": "en",
      "text": "and provide the corrected version of the",
      "offset": 1548.4,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "function. And here goes a function. So,",
      "offset": 1550.08,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "let's see. Basically the function is uh",
      "offset": 1552.96,
      "duration": 4.719
    },
    {
      "lang": "en",
      "text": "wrong implemented because the order uh",
      "offset": 1555.44,
      "duration": 4.719
    },
    {
      "lang": "en",
      "text": "that is it deleting is on reverse. So",
      "offset": 1557.679,
      "duration": 5.281
    },
    {
      "lang": "en",
      "text": "let's see if the the model can",
      "offset": 1560.159,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "understand.",
      "offset": 1562.96,
      "duration": 6.56
    },
    {
      "lang": "en",
      "text": "Now we see it's basically reviewing. We",
      "offset": 1565.919,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "see that now",
      "offset": 1569.52,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "it understood what's wrong but this",
      "offset": 1571.679,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "order is incorrect for dependencies.",
      "offset": 1573.44,
      "duration": 6.32
    },
    {
      "lang": "en",
      "text": "Let's see if it keeps going well. So we",
      "offset": 1576.799,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "saw that it just took 26 seconds. It was",
      "offset": 1579.76,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "super super fast and basically it says",
      "offset": 1582.799,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "the provided function does not correctly",
      "offset": 1585.52,
      "duration": 3.759
    },
    {
      "lang": "en",
      "text": "implement the sign of human sequence. So",
      "offset": 1587.039,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "basically it assessed correctly that the",
      "offset": 1589.279,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "function is wrong and now uh it it is",
      "offset": 1591.36,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "solving it. What's wrong? Incorrect",
      "offset": 1594.159,
      "duration": 4.721
    },
    {
      "lang": "en",
      "text": "recurrence relation wrong loop direction",
      "offset": 1596.24,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "uh resulting behavior corrected version.",
      "offset": 1598.88,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "So now it corrected and it gave me the",
      "offset": 1601.36,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "correct version. So of course this is",
      "offset": 1604.08,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "quite a simple uh task about coding but",
      "offset": 1606.08,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "in the end we saw that it was quite",
      "offset": 1608.96,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "fast. it um assessed correctly what I",
      "offset": 1610.72,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "was expecting and it gave me a correct",
      "offset": 1614.24,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "version of this uh Fibonacci uh function",
      "offset": 1616.32,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "in this task. It performed super super",
      "offset": 1619.36,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "well. All right, now let's go for the",
      "offset": 1621.2,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "last task. Um I want to check the image",
      "offset": 1623.12,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "generation abilities of super grock of",
      "offset": 1625.44,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "Grock 4 basically because uh I know it's",
      "offset": 1627.36,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "one of its biggest limitations. So I",
      "offset": 1630,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "want to see if it's um performing super",
      "offset": 1631.6,
      "duration": 6.079
    },
    {
      "lang": "en",
      "text": "bad or it's just average or it's even a",
      "offset": 1634.72,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "little bit good but not as good as uh",
      "offset": 1637.679,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "the competitors. We all know that uh",
      "offset": 1639.6,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "Chad GBT latest uh update was amazing",
      "offset": 1641.36,
      "duration": 5.199
    },
    {
      "lang": "en",
      "text": "and the images um that it generates are",
      "offset": 1643.679,
      "duration": 4.961
    },
    {
      "lang": "en",
      "text": "really really good. So I just want to",
      "offset": 1646.559,
      "duration": 4.641
    },
    {
      "lang": "en",
      "text": "see the difference between both models.",
      "offset": 1648.64,
      "duration": 6.48
    },
    {
      "lang": "en",
      "text": "And what I'm going to do is just um use",
      "offset": 1651.2,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "the prompt of convert the following",
      "offset": 1655.12,
      "duration": 3.679
    },
    {
      "lang": "en",
      "text": "image into studio kiblay style. And I'm",
      "offset": 1656.64,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "going to share one of my images with the",
      "offset": 1658.799,
      "duration": 5.441
    },
    {
      "lang": "en",
      "text": "model. I have it here. Okay, I'm going",
      "offset": 1661.52,
      "duration": 6.32
    },
    {
      "lang": "en",
      "text": "to put it and let's see how it goes. One",
      "offset": 1664.24,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "of the things that impressed me the most",
      "offset": 1667.84,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "about Grock for is the speed that it",
      "offset": 1669.84,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "generates images. If you have tried",
      "offset": 1672.4,
      "duration": 3.759
    },
    {
      "lang": "en",
      "text": "other other language models on image",
      "offset": 1674,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "generations, they usually take quite a",
      "offset": 1676.159,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "long time. So in this first case, we see",
      "offset": 1678.48,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "uh two versions of the original image.",
      "offset": 1681.679,
      "duration": 3.521
    },
    {
      "lang": "en",
      "text": "In this case, for instance, it changed",
      "offset": 1683.76,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "the color of the pants of my pants, but",
      "offset": 1685.2,
      "duration": 7.28
    },
    {
      "lang": "en",
      "text": "still um they're quite all good. Um I'm",
      "offset": 1688.24,
      "duration": 9.36
    },
    {
      "lang": "en",
      "text": "going to add the the the TGBD output for",
      "offset": 1692.48,
      "duration": 7.52
    },
    {
      "lang": "en",
      "text": "this same uh prompt and image so you can",
      "offset": 1697.6,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "compare. But actually the studio gibly",
      "offset": 1700,
      "duration": 6.64
    },
    {
      "lang": "en",
      "text": "one is not um bad at all. But now let's",
      "offset": 1701.919,
      "duration": 8
    },
    {
      "lang": "en",
      "text": "uh check again but in this case for",
      "offset": 1706.64,
      "duration": 7.039
    },
    {
      "lang": "en",
      "text": "pixer and not for studio key. So in this",
      "offset": 1709.919,
      "duration": 6.081
    },
    {
      "lang": "en",
      "text": "case I'm going to add again my image",
      "offset": 1713.679,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "here",
      "offset": 1716,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "and we will see how the model implements",
      "offset": 1717.52,
      "duration": 6.159
    },
    {
      "lang": "en",
      "text": "it. All right. So in this case we can",
      "offset": 1721.12,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "see um that it's not as good like this",
      "offset": 1723.679,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "one. Actually it seems like the same",
      "offset": 1726.24,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "image but just uh um with some kind of",
      "offset": 1728.399,
      "duration": 5.201
    },
    {
      "lang": "en",
      "text": "filter that makes it a little bit",
      "offset": 1731.6,
      "duration": 5.199
    },
    {
      "lang": "en",
      "text": "realistic but it's like bad performed",
      "offset": 1733.6,
      "duration": 6.24
    },
    {
      "lang": "en",
      "text": "and it's not pixel a pixel style at all.",
      "offset": 1736.799,
      "duration": 5.681
    },
    {
      "lang": "en",
      "text": "And then this one here, it's not pixer",
      "offset": 1739.84,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "uh neither because in the end it's like",
      "offset": 1742.48,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "not really. It's like just uh 2D even",
      "offset": 1743.919,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "though like the style resembles a bit",
      "offset": 1746.32,
      "duration": 3.599
    },
    {
      "lang": "en",
      "text": "but it's like uh more similar to the",
      "offset": 1747.919,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "previous one but um with more",
      "offset": 1749.919,
      "duration": 4.961
    },
    {
      "lang": "en",
      "text": "Americanized way I think. Basically uh",
      "offset": 1751.919,
      "duration": 5.521
    },
    {
      "lang": "en",
      "text": "we now you will see the comparison of",
      "offset": 1754.88,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "like the output of um chhatt for the",
      "offset": 1757.44,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "same prompt and the same image. You will",
      "offset": 1760,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "see the difference is uh so so big. So",
      "offset": 1761.44,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "basically um we can confirm that the",
      "offset": 1764.24,
      "duration": 3.679
    },
    {
      "lang": "en",
      "text": "image generation of Grock 4 is not the",
      "offset": 1766.08,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "best. Uh but still the speed is quite",
      "offset": 1767.919,
      "duration": 5.041
    },
    {
      "lang": "en",
      "text": "fast and if you find like some specific",
      "offset": 1770.32,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "and good uh use case for it I think the",
      "offset": 1772.96,
      "duration": 5.199
    },
    {
      "lang": "en",
      "text": "speed is really really an advantage of",
      "offset": 1775.6,
      "duration": 4.959
    },
    {
      "lang": "en",
      "text": "of this model but still the results are",
      "offset": 1778.159,
      "duration": 5.281
    },
    {
      "lang": "en",
      "text": "not are not the best. Now let's try to",
      "offset": 1780.559,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "place a little bit the Grock family",
      "offset": 1783.44,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "within the large language model space.",
      "offset": 1784.799,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "So the main idea is that the Grog family",
      "offset": 1787.12,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "was debuted in 2023 with the first",
      "offset": 1788.88,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "version and it went directly vital",
      "offset": 1791.36,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "because it had a really strong",
      "offset": 1793.279,
      "duration": 3.041
    },
    {
      "lang": "en",
      "text": "personality and especially it was",
      "offset": 1794.64,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "designed to be more humorous and",
      "offset": 1796.32,
      "duration": 3.599
    },
    {
      "lang": "en",
      "text": "rebellious than the typical chatbots at",
      "offset": 1798,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "the moment. Remember that most chatbots",
      "offset": 1799.919,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "have a lot of restrictions. After that",
      "offset": 1801.6,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "we had an intermediate version Grock 1.5",
      "offset": 1803.84,
      "duration": 4.719
    },
    {
      "lang": "en",
      "text": "that just improved a little bit the",
      "offset": 1806.96,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "reasoning but only five months later we",
      "offset": 1808.559,
      "duration": 5.281
    },
    {
      "lang": "en",
      "text": "had Grock 2 that introduced for the face",
      "offset": 1811.039,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "first time basic coding and multimmodal",
      "offset": 1813.84,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "capabilities to the family. 3 months ago",
      "offset": 1815.919,
      "duration": 4.961
    },
    {
      "lang": "en",
      "text": "we had Gro 3. Grock 3 um basically",
      "offset": 1817.919,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "raised the bar in knowledge and started",
      "offset": 1820.88,
      "duration": 5.039
    },
    {
      "lang": "en",
      "text": "to approach GPT4 levels. So basically it",
      "offset": 1823.039,
      "duration": 5.201
    },
    {
      "lang": "en",
      "text": "was the best model of the family until",
      "offset": 1825.919,
      "duration": 4.721
    },
    {
      "lang": "en",
      "text": "now that we have Gro 4. Grock 4 pushes",
      "offset": 1828.24,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "the limits not only because it has 100",
      "offset": 1830.64,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "more times training data than Grog 2 and",
      "offset": 1833.2,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "presents 10 times more reinforcement",
      "offset": 1835.44,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "learning than any other model of the",
      "offset": 1837.44,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "family but because it introduces a gent",
      "offset": 1839.84,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "architecture either with a single agent",
      "offset": 1842.48,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "or multiple agents and it is natively",
      "offset": 1844.48,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "trained to work with tools which",
      "offset": 1846.88,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "actually gives it a better performance",
      "offset": 1848.799,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "and it makes it responds better to any",
      "offset": 1850.72,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "task we give it. All right. So now let's",
      "offset": 1852.64,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "try to see how Grocker compares to its",
      "offset": 1854.72,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "main competitors and um just check the",
      "offset": 1856.72,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "scores it obtained in the benchmarking.",
      "offset": 1859.84,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "Let's get started with humanity's last",
      "offset": 1862,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "exam. In this case it is a benchmark",
      "offset": 1863.76,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "made up of 2500 handcreated PhD level",
      "offset": 1865.52,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "questions spanning from math, physics,",
      "offset": 1868.88,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "chemistry to linguistics or engineering.",
      "offset": 1871.12,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "In this case we have two versions.",
      "offset": 1873.52,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "There's this version that we cannot use",
      "offset": 1875.44,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "tools. So basically the models don't",
      "offset": 1877.36,
      "duration": 3.439
    },
    {
      "lang": "en",
      "text": "have any access to tools to solve the",
      "offset": 1878.96,
      "duration": 4.959
    },
    {
      "lang": "en",
      "text": "questions. And then um there's the other",
      "offset": 1880.799,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "uh type that it is basically that these",
      "offset": 1883.919,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "models have access to these tools. So uh",
      "offset": 1885.919,
      "duration": 4.721
    },
    {
      "lang": "en",
      "text": "they can use tools while uh answering uh",
      "offset": 1888.24,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "the questions. We see that in both",
      "offset": 1890.64,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "modalities Gro uh the Gros models Grock",
      "offset": 1892.399,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "4 and Grock 4 heavy just outperform all",
      "offset": 1895.6,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "the competitors. But specifically when",
      "offset": 1897.919,
      "duration": 4.961
    },
    {
      "lang": "en",
      "text": "using tools we see that Grock heavy",
      "offset": 1900.72,
      "duration": 4.559
    },
    {
      "lang": "en",
      "text": "almost gets a 45%",
      "offset": 1902.88,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "uh of a score. So basically is about to",
      "offset": 1905.279,
      "duration": 5.201
    },
    {
      "lang": "en",
      "text": "double the result of the Geminis tool",
      "offset": 1908.08,
      "duration": 4.719
    },
    {
      "lang": "en",
      "text": "assisted score. This means that Grog for",
      "offset": 1910.48,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "not only outperforms other living models",
      "offset": 1912.799,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "but the multi- aent Grock for heavy",
      "offset": 1914.72,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "nearly doubles the competition",
      "offset": 1916.64,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "showcasing an ability to reason across",
      "offset": 1918.48,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "disciplines at the research level depth.",
      "offset": 1920.72,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "If we now check other benchmarkings",
      "offset": 1923.12,
      "duration": 3.439
    },
    {
      "lang": "en",
      "text": "Grock 4 is showcasing some pretty",
      "offset": 1924.88,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "amazing results in academic style test.",
      "offset": 1926.559,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "So now you can see the following chart",
      "offset": 1928.64,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "that has like different um scientific",
      "offset": 1930.64,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "style benchmarkings and you can see that",
      "offset": 1934,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "both Grock 4 and Gro for heavy are",
      "offset": 1935.84,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "outperforming all the competitors in",
      "offset": 1937.76,
      "duration": 6.24
    },
    {
      "lang": "en",
      "text": "every single task. So for instance, if",
      "offset": 1940,
      "duration": 7.44
    },
    {
      "lang": "en",
      "text": "we focus on the GPQA uh benchmark that",
      "offset": 1944,
      "duration": 6.159
    },
    {
      "lang": "en",
      "text": "in this case it's um physics questions",
      "offset": 1947.44,
      "duration": 5.92
    },
    {
      "lang": "en",
      "text": "at grad school, we see that both Grocs",
      "offset": 1950.159,
      "duration": 7.12
    },
    {
      "lang": "en",
      "text": "uh get around 89% of a score which is",
      "offset": 1953.36,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "really really high. All right, so now",
      "offset": 1957.279,
      "duration": 3.361
    },
    {
      "lang": "en",
      "text": "let's go for another interesting",
      "offset": 1959.12,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "benchmarking. In this case, we're going",
      "offset": 1960.64,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "to talk about the ARC AGI which",
      "offset": 1962.24,
      "duration": 3.679
    },
    {
      "lang": "en",
      "text": "basically means abstract reasoning",
      "offset": 1964.32,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "corpus artificial general intelligence.",
      "offset": 1965.919,
      "duration": 5.281
    },
    {
      "lang": "en",
      "text": "And as the title already mentions, this",
      "offset": 1968.32,
      "duration": 4.959
    },
    {
      "lang": "en",
      "text": "benchmark basically evaluates abstract",
      "offset": 1971.2,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "and visual reasoning and it is designed",
      "offset": 1973.279,
      "duration": 4.561
    },
    {
      "lang": "en",
      "text": "to measure how close a large language",
      "offset": 1975.2,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "model is to artificial general",
      "offset": 1977.84,
      "duration": 2.959
    },
    {
      "lang": "en",
      "text": "intelligence. You can see now the chart",
      "offset": 1979.2,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "on screen and here you can see that Grog",
      "offset": 1980.799,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "for gets a 16% a little bit more. So it",
      "offset": 1982.96,
      "duration": 5.92
    },
    {
      "lang": "en",
      "text": "almost doubles its closest competitor",
      "offset": 1986.799,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "that is cla oppos. And the most",
      "offset": 1988.88,
      "duration": 3.679
    },
    {
      "lang": "en",
      "text": "important insight of this chart",
      "offset": 1991.039,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "basically is that Grock 4 is the first",
      "offset": 1992.559,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "commercial large language model to break",
      "offset": 1994.64,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "the 10% barrier. So this means that this",
      "offset": 1996.159,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "model is the closest to AGI level that",
      "offset": 1998.96,
      "duration": 5.839
    },
    {
      "lang": "en",
      "text": "has been um developed so far. Another",
      "offset": 2001.919,
      "duration": 5.041
    },
    {
      "lang": "en",
      "text": "interesting benchmark is the vending",
      "offset": 2004.799,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "bench. Now you can see the chart on",
      "offset": 2006.96,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "screen again and uh basically this test",
      "offset": 2008.72,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "evaluates how well a model can operate a",
      "offset": 2011.12,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "real vending machine performing actions",
      "offset": 2013.12,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "like purchasing inventory, adjusting",
      "offset": 2015.039,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "pricing or maximizing profit. So",
      "offset": 2016.96,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "basically it evaluates the autonomy of",
      "offset": 2018.96,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "these models and again Grog for has",
      "offset": 2021.12,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "obtained the best performance so far",
      "offset": 2023.44,
      "duration": 4.479
    },
    {
      "lang": "en",
      "text": "with around $4,500",
      "offset": 2025.039,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "and it more than doubles its closest",
      "offset": 2027.919,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "competitor clot oppos that just made",
      "offset": 2029.919,
      "duration": 5.201
    },
    {
      "lang": "en",
      "text": "around $2,000.",
      "offset": 2032.559,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "All right, as we've just seen together",
      "offset": 2035.12,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "we've unpacked what Grock for is",
      "offset": 2037.279,
      "duration": 2.961
    },
    {
      "lang": "en",
      "text": "explored its main features and",
      "offset": 2039.039,
      "duration": 3.201
    },
    {
      "lang": "en",
      "text": "advantages and walk through how actually",
      "offset": 2040.24,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "use it. The main takeaway of today is",
      "offset": 2042.24,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "that Gro 4 represents a big big leap",
      "offset": 2044.559,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "forward for XAI and the Gro family of",
      "offset": 2046.72,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "models and especially when compared to",
      "offset": 2048.96,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "the previous version Gro 3 which",
      "offset": 2050.879,
      "duration": 4.641
    },
    {
      "lang": "en",
      "text": "performance is way way worse. It's",
      "offset": 2053.359,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "definitely not perfect but it's",
      "offset": 2055.52,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "seriously impressive. And as we just saw",
      "offset": 2056.879,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "in the benchmarks, Grock 4 is now",
      "offset": 2059.599,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "positioning itself as a serious player",
      "offset": 2061.359,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "in the artificial intelligence field,",
      "offset": 2063.359,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "matching or even outperforming some of",
      "offset": 2065.359,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "the top models out there. We've seen",
      "offset": 2067.359,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "that it really stands out when it comes",
      "offset": 2069.28,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "to reasoning and tools use tackling even",
      "offset": 2071.04,
      "duration": 5.359
    },
    {
      "lang": "en",
      "text": "complex problems and planning task even",
      "offset": 2073.76,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "handling PhD levels questions with ease",
      "offset": 2076.399,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "even though it takes quite a long time",
      "offset": 2078.8,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "to do so. That said, it still struggles",
      "offset": 2080.48,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "quite a bit with image generation and",
      "offset": 2082.96,
      "duration": 3.679
    },
    {
      "lang": "en",
      "text": "the way it handles mathematical notation",
      "offset": 2084.72,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "leaves a lot to be desired. But this is",
      "offset": 2086.639,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "something more about UX and not",
      "offset": 2088.72,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "specifically the model itself. One thing",
      "offset": 2090.879,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "I want to highlight is that all of this",
      "offset": 2092.8,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "performance comes even without using the",
      "offset": 2094.72,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "heavy version of Croc 4. So basically",
      "offset": 2096.72,
      "duration": 5.119
    },
    {
      "lang": "en",
      "text": "we're just using the normal model. Okay,",
      "offset": 2099.52,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "just to clarify, Croc 4 is available in",
      "offset": 2101.839,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "two different versions. Remember there's",
      "offset": 2103.92,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "like a cheaper and a more expensive one.",
      "offset": 2105.599,
      "duration": 4.961
    },
    {
      "lang": "en",
      "text": "Gro 4 that is the normal model that only",
      "offset": 2108.24,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "have one agent is single agent and Gro",
      "offset": 2110.56,
      "duration": 5.039
    },
    {
      "lang": "en",
      "text": "for heavy that is multiple agent. What's",
      "offset": 2113.2,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "most exciting about this new launch of",
      "offset": 2115.599,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "Grock 4 is not the launch itself, but",
      "offset": 2117.359,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "what's coming next because actually XAI",
      "offset": 2119.68,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "has laid out an ambitious road map for",
      "offset": 2122.079,
      "duration": 4.641
    },
    {
      "lang": "en",
      "text": "the next few months. So basically in",
      "offset": 2124.4,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "August, this means next month, they're",
      "offset": 2126.72,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "launching a new model specifically",
      "offset": 2128.8,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "designed for coding faster and more",
      "offset": 2130.32,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "accurate for developers. Basically, in",
      "offset": 2132.32,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "September, we'll see the release of a",
      "offset": 2134.48,
      "duration": 3.599
    },
    {
      "lang": "en",
      "text": "true multimodel agent that can",
      "offset": 2136.32,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "understand not just text, but also",
      "offset": 2138.079,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "images, audio, and video much more",
      "offset": 2140,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "effectively than the current model we",
      "offset": 2142.079,
      "duration": 4.561
    },
    {
      "lang": "en",
      "text": "have right now. And finally, in October,",
      "offset": 2144.32,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "they're planning to release a brand new",
      "offset": 2146.64,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "video generation model that's been",
      "offset": 2148.8,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "trained from scratch. So, let's see in",
      "offset": 2150.16,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "this case how the generation of images",
      "offset": 2152.16,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "and videos uh is performed and if it is",
      "offset": 2154.8,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "improved. If we zoom out and think about",
      "offset": 2157.68,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "the bigger picture, the future of",
      "offset": 2159.92,
      "duration": 3.439
    },
    {
      "lang": "en",
      "text": "artificial intelligence on large",
      "offset": 2161.839,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "language models, we need to keep in mind",
      "offset": 2163.359,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "that many of today's top tech leaders",
      "offset": 2165.68,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "are aiming for AGI or what's the same",
      "offset": 2167.599,
      "duration": 5.361
    },
    {
      "lang": "en",
      "text": "artificial general intelligence. Elon",
      "offset": 2170.079,
      "duration": 4.721
    },
    {
      "lang": "en",
      "text": "Musk actually mentioned this during the",
      "offset": 2172.96,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "live stream, saying that to truly reach",
      "offset": 2174.8,
      "duration": 4.799
    },
    {
      "lang": "en",
      "text": "this AGI, these large language models",
      "offset": 2177.04,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "will eventually need a body, a way to",
      "offset": 2179.599,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "sense and interact with the real world.",
      "offset": 2182.24,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "According to this mental road map, Grock",
      "offset": 2184.079,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "will eventually be equipped with that",
      "offset": 2186.079,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "kind of embodiment on its capabilities.",
      "offset": 2187.68,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "So we will assume that at some point it",
      "offset": 2190.079,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "will have kind of like a robot or more",
      "offset": 2192,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "sensors to interact with our real world.",
      "offset": 2193.839,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "So what does this mean for us? It likely",
      "offset": 2196.64,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "means that in the years ahead we'll",
      "offset": 2199.119,
      "duration": 3.441
    },
    {
      "lang": "en",
      "text": "start seeing these kind of models",
      "offset": 2200.88,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "embedded in our devices as now we see in",
      "offset": 2202.56,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "our phones and maybe even into robots.",
      "offset": 2204.88,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "We will see. What's clear is that the",
      "offset": 2207.76,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "artificial intelligence field is still",
      "offset": 2210,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "in its early days and it's going to",
      "offset": 2211.68,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "transform our lives. That's why if",
      "offset": 2213.52,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "you're curious about it, I really really",
      "offset": 2215.839,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "encourage you to just go and check rock",
      "offset": 2217.68,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "for uh for yourself and try to integrate",
      "offset": 2220,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "it in your daily work because actually",
      "offset": 2222.72,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "these kind of tools can really leverage",
      "offset": 2224.96,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "your time. It can really leverage your",
      "offset": 2227.28,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "effort. And if you're interested in",
      "offset": 2229.76,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "going deeper into the world of",
      "offset": 2231.68,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "artificial intelligence, I really",
      "offset": 2232.96,
      "duration": 3.119
    },
    {
      "lang": "en",
      "text": "encourage you as well to check out",
      "offset": 2234.8,
      "duration": 3.279
    },
    {
      "lang": "en",
      "text": "dataccom's courses and tutorials because",
      "offset": 2236.079,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "they're a great way to get started and",
      "offset": 2238.079,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "they offer some fantastic content.",
      "offset": 2240.24,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "Basically, they have a course",
      "offset": 2242.079,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "specifically designed on developing",
      "offset": 2244,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "large language models or they have a new",
      "offset": 2245.599,
      "duration": 5.281
    },
    {
      "lang": "en",
      "text": "uh course focused on AI agents that",
      "offset": 2248.8,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "we've seen that they're really",
      "offset": 2250.88,
      "duration": 2.719
    },
    {
      "lang": "en",
      "text": "important. So, thank you so much for",
      "offset": 2252,
      "duration": 3.599
    },
    {
      "lang": "en",
      "text": "joining me today. I hope it was",
      "offset": 2253.599,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "interesting and let's see where this",
      "offset": 2255.599,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "fastmoving race toward a smarter",
      "offset": 2257.68,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "artificial intelligent takes us next",
      "offset": 2259.52,
      "duration": 4.559
    },
    {
      "lang": "en",
      "text": "time. Thank you so much and have a nice",
      "offset": 2261.44,
      "duration": 5.639
    },
    {
      "lang": "en",
      "text": "day.",
      "offset": 2264.079,
      "duration": 3
    },
    {
      "lang": "en",
      "text": "[Music]",
      "offset": 2268.1,
      "duration": 15.599
    }
  ],
  "cleanText": "What's up everybody? Adele here. Today's video is going to be looking at the Grok 4 model, the brand new model coming from xAI. We're going to put the model through its paces, compare it to different models today on the market, and test on a bunch of use cases related to math, reasoning, and coding. Now, if you want to learn more about AI and how other models are being put to use today, make sure to subscribe to this YouTube channel or check out our blog for more details. With that, happy learning.\n\nHello everyone and welcome to this session. My name is Joseph Far. I'm a data scientist and technical writer. And today I'm here to walk you through one of the biggest announcements of artificial intelligence of this year. And it is the launch of Grok 4. For those of you wondering what's Grok, basically it is the large language model family of xAI, the artificial intelligence company of Elon Musk. So Grok 4 is its latest model and it was launched the last 9th July. It is quite crazy to think that Grok 3, the previous model was just launched 3 months ago and basically this indicates us how fast the artificial intelligence world is growing. However, today's landscape is still shaped by the giants of Google's Gemini family, OpenAI's GPT's family and Anthropic's Claude family. But Elon Musk is quite obsessed to change this and actually he's already stated that Grok 4 is the most smart language model and it has more knowledge than any PhD in any field. This is why today what I want to do with you is first have a good understanding of this model of Grok 4 and understand its main features. The second point would be perform some daily task in order to you to see that it is super easy to access it and actually that you can take advantage of it and you can incorporate it in your daily work. The third point would be compare it with other models both its previous models like Grok 3 and its top competitors and actually check a little bit the benchmarkings and see what's the position of Grok 4. Finally, I would like to discuss the future of the Grok family. So if you're interested in artificial intelligence, please stay with me. Let's go for it.\n\nNow, let's just start with the basics. What exactly is Grok 4? As I said before, Grok 4 is xAI's latest multimodel large language model. The company claims it's the most intelligent model available today in the market, which in the end all companies do. However, in this case, the benchmark results do point in that direction, which is quite interesting. After having listened on the live stream, there's nothing particularly groundbreaking in terms of engineering. So the gains seem to come from a series of smaller tweaks and a significant increase in compute. For those of you wondering what does an increase of compute means, basically it means that Grok 4 has been trained on 100 times more data than its predecessor Grok 2 and it's powered by 10 more times reinforcement learning compute than any other model currently available in the market including Grok 3, its direct predecessor.\n\nWe will see more about the features later, but the most important highlights of the model are that right now it presents one of the biggest context window in the market with 256k tokens which is triceaker than Grok 3. It presents real-time data search but actually this is not as impressive because most of the competitors already present it. It has been natively trained to use tools. Actually this is quite impressive. We will see more about this later. It has advanced voice capabilities but only for mobile phone apps. So we won't be able to use it today. And finally it presents some aentic abilities.\n\nThe first thing of course just go into a web browser. Use whatever you want. And then I'm going to go to Google and just look for Grok here. I will go to the first option. And um now I will see the landing cover of the xAI company and the Grok interface. Basically here there are like two different triggers that can just pop up the grab interface. This box here that allows me to send a prompt directly to the model or the button here of try Grok. I'm going to just use the button and I will see now the interface of Grok. As you can see it is quite a minimalist interface. It's just the same as any other competitor namely Chad GBT, Google Germany wherever. But the first thing to start using it you can see that by default it comes Grok 3 and for Grok 4 I need to sign in or sign up if you don't have an account and basically we will see that we have a membership as well and now we will have the whole interface. So as you can see here we have the name, we have a box to send the prompts, we have a button to attach files, we have here to choose the model, we will see by default it will come Grok 3 but we will have Grok 4 here available to just choose it and Grok 4 Heavy, we will see later what's the main difference and then we have this sidebar here with different functionalities and then um my user settings here you can see my little image um down there and then we will have the history. Right now I don't have any history. I don't have any chats because I just deleted them for today's video. Then we have the projects functionality. For me it is quite useful but actually it is present in many of its competitors. Basically I can just organize my chats and just put them within projects. So basically I can have somewhere a structure when I just interact with these models in this case with Grok. And then there's like the task functionality. I really like it. Basically, it allows the user to just ask for a specific task to the model and give it a frequency. So, the model just does it every time that you just set this frequency. This means that for instance, in my case, I generated the daily tech digest task. So, basically every day at 6 p.m. I want Grok to just have a daily tech digest. You can see here the prompt that I shared with the model and here you can see one of the outputs that it gave me.\n\nAll right. So, and then there's like the files feature that here basically it stores all the files that I either share with the model or that the model outputs me. So, we will see more about this later, but now let's just start with the chat. Um, let's go to Grok 4 and, um, let's ask it to reason why the temperature on Earth is rising.\n\nThe first thing we can see is that the model tells us that it is thinking. I really like this feature and actually um it's something that has not been implemented in many of the models. Um, ChatGPT for instance doesn't have it and this recalls me of DeepMind. So basically this allows us to see the reasoning the process that the Grok in this case is making in order to generate an output for our question. All right. So now we can see quite a formulated answer here in the beginning. Um we can see that the thought just lasted 26 seconds is a feature that I really liked as well. It lets us know basically how long does it take for the model to just generate a response for our prompt. And then you can see like a quite structured answer and with different sources and sites. So basically it is quite a nice output but like it's in the end it's just like a response of a model but now if we go to compare it well it's still finishing. So let's wait for a bit until it just finishes and then what we will do is just go back to Grok 3 and see the difference between the output. Now it is done. So the thought just lasted 26 seconds and then the output just took a little bit longer. So now let's just copy the same prompt as before and use Grok 3 for it. So in this case we see that first the output is right away. There's no thinking time and there Grok doesn't show us the process or the reasoning behind the output that it's formulating and we don't have any sources or any sites on the on the response. So basically we can already see the big differences between Grok 4 and Grok 3 and the big upgrade that Grok 4 represents when compared to its prior model that was Grok 3. All right.\n\nSo now that we have already interacted a little bit with the model, what we are going to do is just discuss a little bit the differences between Grok 4 and Grok 4 Heavy. So remember that if we go to select the model here, we will see two different options: Grok 4 and Grok 4 Heavy. And I'm pretty sure most of you are still wondering what's the difference between these two models. To make clearly the difference between them, I'm going to use the pricing web. So you can see there's different pricings to access Grok 4 and to access Grok 4 Heavy and one of them is clearly more expensive than the other. So the main difference between them is that Grok 4 is the normal model. It has all the upgrades. It has all the improvements but it is a single agent model. This means that whenever we ask this model a task, only one AI agent will perform this task for us. On the other side, Grok 4 Heavy, it's a multi-agent model. This means that we have different AI agents working at the same time in the same task and then they will share the results and find the optimal solution together. In order to understand this, let's make a simple analogy. Imagine you you are the CEO of a big company and you have a complicated project to do. So what you can do is just take four different engineers and ask them to do the same project. The thing is all of them will just work on the same project but independently okay on their own but in a couple weeks they will come back and they will share the results with the others and what they will do is they will see which is the optimal solution or collaboratively they will improve the process that each of them did to find the best solution basically. So that's the main difference between both models. Grok is a single agent while Grok 4 Heavy is multi-agent. And now let's talk about the pricing. Grok 3, the predecessor of this model will always be free. Okay. So basically you have access to it a little bit limited but still enough to just use it in a daily basis. And then we have two main memberships that can be monthly or yearly as you can observe here. So basically the $30 per month gives you unlimited access to Grok 4 basically and then we have a $300 subscription that is like the super Grok Heavy that gives you unlimited access of Grok 4 of course and then gives you access to Grok 4 Heavy. The main difference between them of course is the usage of Grok 4 Heavy. We will see later that Grok 4 Heavy actually has like a better performance than Grok 4 but still Grok 4 has a really, really good performance. And on the other side what we will see is that it will have early access to the new features that are that the model gets over time and then we can access this model using another way and it is the API. This is a more technical way to access the model. So basically what we will see here is that we have different APIs that we can use to access these models. And the most important thing for me is that Grok 4 and Grok 3 have exactly the same price which is quite impressive. They maintain the price is quite low. You can see Grok 3 here it has like $3 per million tokens while Grok 4 has like $3 per million tokens as well. The main differences between them is that the context of Grok 4 is way bigger as we said before but there's a limitation of 60 requests per minute while in Grok 3 you have a 600. So actually this is quite a big limitation when you are you want to scale whatever you're using for the large language model you want to scale the application but still for testing and for developing it is quite nice to have like this quite low price and this is the two main ways you can access Grok either using the interface by paying this membership or using the API and as you've seen the prices in this case are quite similar for both Grok 3 and Grok 4.\n\nNow let's focus a little bit on the new features that this model presents. So for me one of the most important ones is the context window. As I have already said before, it doubles the size of Grok 3 and now it presents a context window of 256,000 tokens. To make it clear, basically this means that we can just send longer prompts for every interaction we have with the model. And this means that we can just contextualize better and give more information to the task we expect it to perform for us. Another good improvement is the reasoning and especially the academic reasoning. We will see later in the benchmarks but basically the scores are quite amazing especially when compared to the predecessor and they outperform all the top competitors of Grok 4. Another important feature that during the live stream they gave a lot of importance. It was that it has been natively trained to use tools. So it means that it doesn't rely on the built-in knowledge but it knows how to reach out, how to retrieve data and how to apply it. And this is a big, big upgrade when compared to the predecessor. Another feature is the agentic design. This means that basically Grok 4 can act more like a thinking system, right? Either if we use the normal version, the Grok 4 or the Grok 4 Heavy, but basically we have agents that can just work behind the scenes and perform whatever task we ask. And finally there's another feature, but it's only for the mobile phone apps and it is basically the voice mode. It presents a new voice called if it is British sounding and basically it improves way better and it sounds more natural but as I said before this is not something that can be accessed using the computer and finally I would like to mention a limitation and basically it is the image generation we will actually work on it in a couple minutes and we will see but basically the image generation is not the best so I think it's one of the most important limitation of the model but still they have said that in the coming weeks they want to work on this and upgrade the image generation of Grok 4. All right. So now let us start playing a little bit with the model and see how it behaves and I've prepared different task in order to just check it a little bit. So the first one is just I want to check the knowledge that the model has and the fact checking ability. The first thing we need to do is like make sure we're using Grok 4. Okay, by default it's always going to be Grok 3. So my first prompt is going to be what was the outcome of the 2024 US presidential election including the winner keyboard margins in swing states and any major post-election events up to July 2025 cross check\n\n\nAgainst reliable sources\nthat avoid outdated or inaccurate\ninformation.\nAll right, so the first\nthing I'm going to see is, uh, it's going\nto start, uh, thinking, and it's going to\nstart showing me the whole process of\nthe thinking.\nAnd now this is going to\ntake, uh, a little bit of a time, but we\nwill see that, uh, we can actually check\num, that, uh, for instance, it was checking\nWikipedia, now it's checking CNN, Fox\nNews.\nSo we can see that, uh, the model\nactually just goes to the web and\nsearches for, uh, aligned information, um,\nto what I've asked, and it actually, um,\nworks and, uh, starts, um, getting\ninformation from different sources.\nRight?\nSo this is something that I asked\nit to do and, uh, um, that I wanted to\ncross-check against reliable sources.\nThis new feature that it shows me the\nwhole process of thinking.\nIt's really\nhelpful to see if the model is actually\ndoing what I ask it to do or not.\nAll right.\nSo now it says that the\nthought was for 24 seconds and now\ngenerating, uh, a proper output.\nIt's\nworking this time, and we can see that\nit's kind of an elaborated response.\nUm,\nit actually, uh, went to the swing state\nthat I asked and, um, added the\ninformation.\nWe can check that this\ninformation, um, is is correct.\nSo, uh,\nbasically, it performed, uh, quite well the\ntask that I first asked it to do.\nWe can see that it's just finished.\nSo\nit takes quite a long time to think.\nIt\nwas around 80 seconds, 84, and, um, still\nthe answer is quite fast once, uh, it has\nhad all the all the thinking process.\nNow\nlet's just go for the second task.\nIn\nthis case, I want to check the\nmathematical reasoning, and I'm going to\nstart with a prompt that GPT 4 at some\npoint, um, didn't perform properly, and it\nis, if x and y are the 10th digit and the\nunit digit respectively of the product\nof these two numbers, what is the value\nof x + y.\nCan you explain the easy\nsolution without calculating the whole\nnumber?\nSo let's see, basically, um, how it\nproceeds and how does like the whole\nreasoning and see if the mathematical, uh,\nprocedure of, um, Grok 4, it was quite\nfast to be very honest.\nIt only took 8\nseconds for it to respond, and the answer\nis correct because it is 12.\nSo actually\nit was really, really fast.\nUh, I'm quite\nsurprised about it, and, um, the whole\nprocess is, uh, quite, um, neat.\nRight.\nSo a second, uh, thing I want to try, uh, I have\nanother prompt here is, uh, another\nmathematical problem to see, uh, if this\ntime it takes longer or, um, it just goes\nsuper fast as well.\nIn this case, it is\nuse all digits from 0 to 9 exactly once\nto make three numbers x y z such that x\n+ y equals z.\nAnd now, um, we will see it\nis analyzing the problem.\nIt is doing\nlike the whole reasoning.\nWe can see it keeps showing us like the\nthinking it it does\nnow.\nIt is executing some code.\nAll right.\nLike it gave us one possible\nsolution and, uh, it is correct.\nIt took a\na little bit of a time, 125, uh, seconds,\nbut still the the final output is is\ngood.\nNow let's go for the third task.\nIn this case, what I want to see is\nfirst the integration of Grok with xAI.\nIn the end, they are both part of the\nsame, uh, company.\nAnd, uh, on the other\nside to see, um, how it can use this tools\nto effectively, um, get or fetch the data\nthat we're asking for.\nSo in this case,\nthe prompt I'm going to use is tell me\nabout datacamp's latest post on on the\nexocial network and then find the latest\nblog on their website, summarize\ninformation contained and provide the\nlink to the post.\nSo let's see first how\nlong does it take to do all of this and\nthen if it does it correctly.\nI'm going\nto check, uh, the latest, um, x post of\ndatacamp and see, uh, what it does.\nHere we can\nsee that it's, uh, guessing the datacamp's x\nhandle is likely datacamp.\nUh, in this\ncase it's correct, but we will see how it\ngoes and how long, uh, it takes to perform\nthe whole thing.\nNow it's go going to datacamp's blog and\nuh, it's checking different sources, um, to\nsee it's browsing actually the datacamp's\nblog to see the latest.\nWe can see that the latest, uh, datacamp's\npost, uh, article is about Grok 4\nactually.\nAnd now it is browsing it.\nThat's good.\nOkay, it says datacamp's most recent\npost on the X social network dated July\n10 promotes a free webinar aimed to\nindividual deciding between careers as a\ndata scientist or analytics engineer.\nOkay, so let's just check it and we can\nsee that it is correct trying to choose\nbetween, uh, being a data scientist or\nanalytics engineer at, uh, this free\nwebinar.\nOkay, so that's perfectly\ncorrect.\nIt says that the latest blog on\ndatacamp's website is titled Grok 4 test\nfeatures benchmark access and more\npublished on July 10, which is actually\ncorrect as well, and we can see here that\nit performs correctly the task and then\nit summarizes and has like the key\nfeatures of this datacamp block.\nSo this\nis perfect, uh, it's done it, uh, perfectly\nfine.\nAll right, now let's go for the\nfourth task.\nIn this case, what I want\nto do is first, um, check the extended, um,\nWindows context of Grok and test another,\num, use case that many people use, and\nbasically is to use this kind of chat\nbots to summarize and analyze reports.\nSo in this case what I'm going to use is\nthe future of jobs, uh, report for the\nWorld Economic Forum, uh, of 2025.\nSo the\nprompt is going to be the following one.\nAnd now I'm going to upload\nthe document itself that I have it here.\nSo basically what I'm going to do is\nlike I'm going to attach the the PDF, the\ndocument, and I want it to analyze the\nentire report, identify the three most\ninformative graph, summarize each one and\nlet me know which page of PDF they\nappear on.\nAll right, it's already finished.\nIt\ntook 21 seconds and then it says that\nthe figure 2.5 job growth on decline on\npage 24.\nSo that's I'm going to check it\nright now.\nSo this is correct, uh, in the\npage 24 there's like this, uh, figure and\nactually it's it's one of the most\nimportant of on the report and basically\nit says, uh, which jobs are going to grow\nand which ones are going to decrease\nbasically and have less, uh, job openings\nin the future.\nAnd then it says two\nother figures that we can check.\nBut as\nwe can see the the task was performed\ncorrectly and, um, it just analyzed in a\nreally, really short amount of time, just\n21 seconds, a report that is over 200, uh,\npages and it, um, answered correctly the\ntask.\nSo that's perfectly fine.\nAnd\nactually you can use this on your own\njust to, um, chat with any PDF document or\njust upload it and let Grok 4 analyze\nit for you and get like the most\nimportant insights.\nAll right.\nRight.\nSo\nnow let's go for the next task.\nBasically in this case what I want to\nsee, I want to check is the advanced\nreasoning of super Grok and especially\nto see how it behaves when I ask, uh,\nquite an advanced question.\nIn this case\nit's going to be like a physics\nquestion.\nThe first thing I'm going to\ndo is just, uh, put here the prompt.\nI\nwant to evaluate your ability to solve\nPhD level physics problems involving\nelectromagnetism.\nAttach is a multifar\nquestion entitled problem two.\nElectromagnetism true.\nAnd then I\ndescribe the whole thing here.\nAnd just\nin case I emphasize again that I attach\nthe problem as a PNG image.\nSo now what\nI'm going to do is just attach the\nproblem here.\nThis is a problem of Yale\nfor, uh, physics, uh, student basically.\nSo\nwhat I want to see with this is first\nhow the model processes the whole thing.\nAnd then as we will see later in the\nbenchmarkings, um, Grok is supposed to be\nquite good at, uh, PhD level of questions\nin, uh, almost all fields.\nUm, so now we\nwill see how it starts just checking,\nanalyzing the problem and getting, um,\naligned, uh, knowledge and content, uh, to\nsolve it.\nA thing that I really like\nabout the interface of Grok is\nbasically that I can still keep seeing\nmy prompt, but the thinking process just\nkeeps scrolling down.\nSo basically what\nI can see here is that I can just keep\nseeing all steps of the processing of\nthe model, but still I can see the\nprompt.\nSo, I think this is a really,\nreally good upgrade and, um, UX- wise is\nreally nice just to be able to just keep\nreading and following the whole process\nbut still, um, have the prompt on screen\nas well just to check that, uh, everything\nis on track.\nNow we see it's like, uh, just revisiting\ncalculations and making sure like all\nthe process, uh, it has done is, uh,\nproperly done actually.\nSo it is quite\nnice to just keep following, um, the the\nwhole process and the and the whole, uh,\nchain of thoughts that the model is\nhaving.\nAll right.\nSo it seems we finally have\nan answer.\nIt took quite a long time,\nover 350 seconds basically, but we see it\nuh, got like a final answer for all the\nproblem.\nOne thing that I actually don't\nlike is that the mathematical\nformulation is not properly done.\nLike\nyou see here, you can find like the\nlatex, um, way of writing, but it's not, um,\nshaped like a proper mathematical\nformulation.\nSo that's something I don't\nactually like.\nBut like the whole\nresponse is quite, um, well argumentated,\nlike we could see all the process.\nSo it\nwas actually quite well done.\nAnd as we\nwill see later, the benchmarking for\nthese kind of problems model Grok 4 is\nquite good.\nUm, but again, um, one of the things I\ndon't like is the the way it writes the\nthis mathematical formulation is not, uh,\nit's not nice and it's not friendly for\nthe user just to just to use it.\nNow\nlet's go for the next task.\nUh, I think\nit's the sixth task now, and, um, the main\nidea is to check the ability to code and\nto understand code of Grok.\nYou know, one\nof the most important use cases of this\nkind of class language models is to help\nus while coding, help us understand the\ncode we have and help us understand, uh,\nif there's some errors or correct the\ncode or generate new code.\nBasically,\nwhat I'm going to share with Grok now\nis the following prompt and it is can\nyou review the following Python function\nand tell me if it's correct implementing\nthe Fibonacci sequence.\nIf it's\nincorrect, please explain what's wrong\nand provide the corrected version of the\nfunction.\nAnd here goes a function.\nSo,\nlet's see.\nBasically the function is, uh,\nwrong implemented because the order, uh,\nthat is it deleting is on reverse.\nSo\nlet's see if the the model can\nunderstand.\nNow we see it's basically reviewing.\nWe\nsee that now\nit understood what's wrong, but this\norder is incorrect for dependencies.\nLet's see if it keeps going well.\nSo we\nsaw that it just took 26 seconds.\nIt was\nsuper, super fast and basically it says\nthe provided function does not correctly\nimplement the sign of human sequence.\nSo\nbasically it assessed correctly that the\nfunction is wrong and now, uh, it it is\nsolving it.\nWhat's wrong?\nIncorrect\nrecurrence relation, wrong loop direction,\nuh, resulting behavior, corrected version.\nSo now it corrected and it gave me the\ncorrect version.\nSo of course this is\nquite a simple, uh, task about coding, but\nin the end we saw that it was quite\nfast.\nIt, um, assessed correctly what I\nwas expecting and it gave me a correct\nversion of this, uh, Fibonacci, uh, function\nin this task.\nIt performed super, super\nwell.\nAll right, now let's go for the\nlast task.\nUm, I want to check the image\ngeneration abilities of super Grok of\nGrok 4 basically because, uh, I know it's\none of its biggest limitations.\nSo I\nwant to see if it's, um, performing super\nbad or it's just average or it's even a\nlittle bit good, but not as good as, uh,\nthe competitors.\nWe all know that, uh,\nChad GBT latest, uh, update was amazing\nand the images, um, that it generates are\nreally, really good.\nSo I just want to\nsee the difference between both models.\nAnd what I'm going to do is just, um, use\nthe prompt of convert the following\nimage into studio kiblay style.\nAnd I'm\ngoing to share one of my images with the\nmodel.\nI have it here.\nOkay, I'm going\nto put it and let's see how it goes.\nOne\nof the things that impressed me the most\nabout Grok 4 is the speed that it\ngenerates images.\nIf you have tried\nother other language models on image\ngenerations, they usually take quite a\nlong time.\nSo in this first case, we see\nuh, two versions of the original image.\nIn this case, for instance, it changed\nthe color of the pants of my pants, but\nstill, um, they're quite all good.\nUm, I'm\ngoing to add the the the TGBD output for\nthis same, uh, prompt and image so you can\ncompare.\nBut actually the studio gibly\none is not, um, bad at all.\nBut now let's\nuh, check again, but in this case for\npixer and not for studio key.\nSo in this\ncase I'm going to add again my image\nhere\nand we will see how the model implements\nit.\nAll right.\nSo in this case we can\nsee, um, that it's not as good like this\none.\nActually it seems like the same\nimage, but just, uh, um, with some kind of\nfilter that makes it a little bit\nrealistic, but it's like bad performed\nand it's not pixel a pixel style at all.\nAnd then this one here, it's not pixer\nuh, neither because in the end it's like\nnot really.\nIt's like just, uh, 2D even\nthough like the style resembles a bit\nbut it's like, uh, more similar to the\nprevious one, but, um, with more\nAmericanized way I think.\nBasically, uh,\nwe now you will see the comparison of\nlike the output of, um, chhatt for the\nsame prompt and the same image.\nYou will\nsee the difference is, uh, so so big.\nSo\nbasically, um, we can confirm that the\nimage generation of Grok 4 is not the\nbest.\nUh, but still the speed is quite\nfast and if you find like some specific\nand good, uh, use case for it, I think the\nspeed is really, really an advantage of\nof this model, but still the results are\nnot are not the best.\nNow let's try to\nplace a little bit the Grok family\nwithin the large language model space.\nSo the main idea is that the Grok family\nwas debuted in 2023 with the first\nversion and it went directly vital\nbecause it had a really strong\npersonality and especially it was\ndesigned to be more humorous and\nrebellious than the typical chatbots at\nthe moment.\nRemember that most chatbots\nhave a lot of restrictions.\nAfter that\nwe had an intermediate version Grok 1.5\nthat just improved a little bit the\nreasoning, but only five months later we\nhad Grok 2 that introduced for the face\nfirst time basic coding and multimmodal\ncapabilities to the family.\n3 months ago\nwe had Grok 3.\nGrok 3, um, basically\nraised the bar in knowledge and started\nto approach GPT4 levels.\nSo basically it\nwas the best model of the family until\nnow that we have Grok 4.\nGrok 4 pushes\nthe limits not only because it has 100\nmore times training data than Grok 2 and\npresents 10 times more reinforcement\nlearning than any other model of the\nfamily, but because it introduces a gent\narchitecture either with a single agent\nor multiple agents and it is natively\ntrained to work with tools which\nactually gives it a better performance\nand it makes it responds better to any\ntask we give it.\nAll right.\nSo now let's\ntry to see how Grok compares to its\nmain competitors and, um, just check the\n\n\nScores it obtained in the benchmarking.\nLet's get started with humanity's last exam.\nIn this case, it is a benchmark made up of 2500 hand-created PhD level questions spanning from math, physics, chemistry to linguistics or engineering.\nIn this case, we have two versions.\nThere's this version that we cannot use tools.\nSo basically, the models don't have any access to tools to solve the questions.\nAnd then, um, there's the other type that it is basically that these models have access to these tools.\nSo, uh, they can use tools while, uh, answering, uh, the questions.\nWe see that in both modalities, Gro, uh, the Gros models, Grok 4 and Grok 4 Heavy, just outperform all the competitors.\nBut specifically when using tools, we see that Grok Heavy almost gets a 45% uh of a score.\nSo basically is about to double the result of the Geminis tool-assisted score.\nThis means that Grok 4 not only outperforms other living models, but the multi-agent Grok 4 Heavy nearly doubles the competition, showcasing an ability to reason across disciplines at the research level depth.\nIf we now check other benchmarkings, Grok 4 is showcasing some pretty amazing results in academic style tests.\nSo now you can see the following chart that has like different, um, scientific style benchmarkings, and you can see that both Grok 4 and Grok 4 Heavy are outperforming all the competitors in every single task.\nSo for instance, if we focus on the GPQA, uh, benchmark that in this case it's, um, physics questions at grad school, we see that both Groks, uh, get around 89% of a score, which is really, really high.\nAll right, so now let's go for another interesting benchmarking.\nIn this case, we're going to talk about the ARC AGI, which basically means abstract reasoning corpus artificial general intelligence.\nAnd as the title already mentions, this benchmark basically evaluates abstract and visual reasoning, and it is designed to measure how close a large language model is to artificial general intelligence.\nYou can see now the chart on screen, and here you can see that Grok 4 gets a 16% a little bit more.\nSo it almost doubles its closest competitor that is cla oppos.\nAnd the most important insight of this chart basically is that Grok 4 is the first commercial large language model to break the 10% barrier.\nSo this means that this model is the closest to AGI level that has been, um, developed so far.\nAnother interesting benchmark is the vending bench.\nNow you can see the chart on screen again, and, uh, basically this test evaluates how well a model can operate a real vending machine, performing actions like purchasing inventory, adjusting pricing, or maximizing profit.\nSo basically it evaluates the autonomy of these models, and again Grok 4 has obtained the best performance so far with around $4,500, and it more than doubles its closest competitor clot oppos that just made around $2,000.\nAll right, as we've just seen together, we've unpacked what Grok 4 is, explored its main features and advantages, and walked through how actually use it.\nThe main takeaway of today is that Grok 4 represents a big, big leap forward for xAI and the Grok family of models, and especially when compared to the previous version Grok 3, which performance is way, way worse.\nIt's definitely not perfect, but it's seriously impressive.\nAnd as we just saw in the benchmarks, Grok 4 is now positioning itself as a serious player in the artificial intelligence field, matching or even outperforming some of the top models out there.\nWe've seen that it really stands out when it comes to reasoning and tools use, tackling even complex problems and planning task, even handling PhD levels questions with ease, even though it takes quite a long time to do so.\nThat said, it still struggles quite a bit with image generation, and the way it handles mathematical notation leaves a lot to be desired.\nBut this is something more about UX and not specifically the model itself.\nOne thing I want to highlight is that all of this performance comes even without using the heavy version of Croc 4.\nSo basically, we're just using the normal model.\nOkay, just to clarify, Crok 4 is available in two different versions.\nRemember there's like a cheaper and a more expensive one.\nGrok 4 that is the normal model that only have one agent is single agent and Grok 4 Heavy that is multiple agent.\nWhat's most exciting about this new launch of Grok 4 is not the launch itself, but what's coming next because actually xAI has laid out an ambitious road map for the next few months.\nSo basically in August, this means next month, they're launching a new model specifically designed for coding faster and more accurate for developers.\nBasically, in September, we'll see the release of a true multimodel agent that can understand not just text, but also images, audio, and video much more effectively than the current model we have right now.\nAnd finally, in October, they're planning to release a brand new video generation model that's been trained from scratch.\nSo, let's see in this case how the generation of images and videos, uh, is performed and if it is improved.\nIf we zoom out and think about the bigger picture, the future of artificial intelligence on large language models, we need to keep in mind that many of today's top tech leaders are aiming for AGI or what's the same artificial general intelligence.\nElon Musk actually mentioned this during the live stream, saying that to truly reach this AGI, these large language models will eventually need a body, a way to sense and interact with the real world.\nAccording to this mental road map, Grok will eventually be equipped with that kind of embodiment on its capabilities.\nSo we will assume that at some point it will have kind of like a robot or more sensors to interact with our real world.\nSo what does this mean for us?\nIt likely means that in the years ahead we'll start seeing these kind of models embedded in our devices as now we see in our phones and maybe even into robots.\nWe will see.\nWhat's clear is that the artificial intelligence field is still in its early days and it's going to transform our lives.\nThat's why if you're curious about it, I really, really encourage you to just go and check rock for, uh, for yourself and try to integrate it in your daily work because actually these kind of tools can really leverage your time.\nIt can really leverage your effort.\nAnd if you're interested in going deeper into the world of artificial intelligence, I really encourage you as well to check out datacamp's courses and tutorials because they're a great way to get started and they offer some fantastic content.\nBasically, they have a course specifically designed on developing large language models or they have a new, uh, course focused on AI agents that we've seen that they're really important.\nSo, thank you so much for joining me today.\nI hope it was interesting and let's see where this fast-moving race toward a smarter artificial intelligent takes us next time.\nThank you so much and have a nice day.\n[Music]\n",
  "dumpedAt": "2025-07-21T18:43:25.285Z"
}