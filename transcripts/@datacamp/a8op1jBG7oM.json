{
  "episodeId": "a8op1jBG7oM",
  "channelSlug": "@datacamp",
  "title": "Keras Crash Course | Deep Learning, Image Modelling, RNNs and More",
  "publishedAt": "2025-04-18T17:13:50.000Z",
  "rawLines": [
    {
      "lang": "en",
      "text": "what's up everybody today's video is a",
      "offset": 0.08,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "collection of course videos from our",
      "offset": 2.32,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "CARAS fundamental skill track In these",
      "offset": 3.919,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "videos you'll learn all about how to",
      "offset": 6.48,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "build neural networks with KAS how to",
      "offset": 8.32,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "approach image modeling and",
      "offset": 10.559,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "convolutional networks with Caris how to",
      "offset": 11.92,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "build sequential neural networks and a",
      "offset": 14.16,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "lot more If you enjoyed these videos and",
      "offset": 16.72,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "you want to actually apply what you",
      "offset": 19.68,
      "duration": 2.88
    },
    {
      "lang": "en",
      "text": "learned in these videos right in the",
      "offset": 21.039,
      "duration": 3.041
    },
    {
      "lang": "en",
      "text": "browser check out the link in the",
      "offset": 22.56,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "description below And with that happy",
      "offset": 24.08,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "learning",
      "offset": 26.24,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "Welcome to this course on deep learning",
      "offset": 27.84,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "I'm Miguel and I'm very excited to be",
      "offset": 29.92,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "teaching you KAS here on data cam This",
      "offset": 32.239,
      "duration": 5.121
    },
    {
      "lang": "en",
      "text": "course will add KAS as a powerful tool",
      "offset": 34.88,
      "duration": 5.519
    },
    {
      "lang": "en",
      "text": "to your arsenal KAS is a highle deep",
      "offset": 37.36,
      "duration": 4.879
    },
    {
      "lang": "en",
      "text": "learning framework To understand what is",
      "offset": 40.399,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "meant by that we can compare it to a",
      "offset": 42.239,
      "duration": 4.721
    },
    {
      "lang": "en",
      "text": "lower level framework like Theo Building",
      "offset": 44.239,
      "duration": 4.721
    },
    {
      "lang": "en",
      "text": "a neural network in Theo can take many",
      "offset": 46.96,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "lines of code and it requires a deep",
      "offset": 48.96,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "understanding of how they work",
      "offset": 51.12,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "internally",
      "offset": 52.48,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "Building and training this very same",
      "offset": 54.16,
      "duration": 4.76
    },
    {
      "lang": "en",
      "text": "network in KAS only takes a few lines of",
      "offset": 56,
      "duration": 5.32
    },
    {
      "lang": "en",
      "text": "code Much quicker",
      "offset": 58.92,
      "duration": 5.16
    },
    {
      "lang": "en",
      "text": "right kas is an open-source deep",
      "offset": 61.32,
      "duration": 4.92
    },
    {
      "lang": "en",
      "text": "learning library that enables fast",
      "offset": 64.08,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "experimentation with neural networks It",
      "offset": 66.24,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "runs on top of other frameworks like",
      "offset": 68.88,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "TensorFlow Tiano or CNTK And it was",
      "offset": 70.88,
      "duration": 6.12
    },
    {
      "lang": "en",
      "text": "created by French AI researcher",
      "offset": 74,
      "duration": 5.92
    },
    {
      "lang": "en",
      "text": "Francois So why use KAS instead of other",
      "offset": 77,
      "duration": 5.56
    },
    {
      "lang": "en",
      "text": "low-level libraries like TensorFlow",
      "offset": 79.92,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "well with KAS you can build industry",
      "offset": 82.56,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "ready models in no time with much less",
      "offset": 84.64,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "code than Theo as we saw before and a",
      "offset": 86.88,
      "duration": 4.68
    },
    {
      "lang": "en",
      "text": "higher abstraction than that offered by",
      "offset": 89.2,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "TensorFlow This allows for quickly and",
      "offset": 91.56,
      "duration": 4.199
    },
    {
      "lang": "en",
      "text": "easily checking if a neural network will",
      "offset": 93.84,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "get your problem solved In addition you",
      "offset": 95.759,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "can build any architecture you can",
      "offset": 98.159,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "imagine from simple networks to more",
      "offset": 99.68,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "complex ones like autoenccoders",
      "offset": 101.84,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "convolutional or recurrent neural",
      "offset": 103.759,
      "duration": 3.201
    },
    {
      "lang": "en",
      "text": "networks",
      "offset": 105.36,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "KAS models can also be deployed across a",
      "offset": 106.96,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "wide range of platforms like Android iOS",
      "offset": 109.2,
      "duration": 4.68
    },
    {
      "lang": "en",
      "text": "web apps",
      "offset": 112,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "etc It is the best moment to be learning",
      "offset": 113.88,
      "duration": 5.559
    },
    {
      "lang": "en",
      "text": "KAS KAS is now fully integrated into",
      "offset": 116.56,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "TensorFlow 2.0 so you can use the best",
      "offset": 119.439,
      "duration": 4.481
    },
    {
      "lang": "en",
      "text": "of both worlds as needed and in the same",
      "offset": 121.84,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "code pipeline If as you dive into deep",
      "offset": 123.92,
      "duration": 4.559
    },
    {
      "lang": "en",
      "text": "learning you find yourself needing to",
      "offset": 126.56,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "use low-level features for instance to",
      "offset": 128.479,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "have a finer control of how your network",
      "offset": 130.479,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "applies gradients you could use",
      "offset": 132.319,
      "duration": 3.881
    },
    {
      "lang": "en",
      "text": "TensorFlow and tweak whatever you",
      "offset": 134.08,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "need Now that you know better what KAS",
      "offset": 136.2,
      "duration": 5.16
    },
    {
      "lang": "en",
      "text": "is and why to use it perhaps we should",
      "offset": 139.04,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "discuss when and why to use a neural",
      "offset": 141.36,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "network in the first place Neural",
      "offset": 143.36,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "networks are good feature structures",
      "offset": 145.92,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "since they learn the best way to make",
      "offset": 148,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "sense of unstructured data Previously it",
      "offset": 149.76,
      "duration": 4.559
    },
    {
      "lang": "en",
      "text": "was the domain expert that had to set",
      "offset": 152.48,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "rules based on experimentation and",
      "offset": 154.319,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "heristics to extract the relevant",
      "offset": 156.16,
      "duration": 4.799
    },
    {
      "lang": "en",
      "text": "features of data Neural networks can",
      "offset": 158.16,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "learn the best features and their",
      "offset": 160.959,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "combination They can perform feature",
      "offset": 162.16,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "engineering themselves and that's why",
      "offset": 164.319,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "they are so useful But what is",
      "offset": 166.4,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "unstructured data unstructured data is",
      "offset": 168.879,
      "duration": 5.681
    },
    {
      "lang": "en",
      "text": "data that is not easily put into a table",
      "offset": 172.08,
      "duration": 7.28
    },
    {
      "lang": "en",
      "text": "For instance sound videos images etc It",
      "offset": 174.56,
      "duration": 6.399
    },
    {
      "lang": "en",
      "text": "is also the type of data where",
      "offset": 179.36,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "performing feature engineering can be",
      "offset": 180.959,
      "duration": 3.441
    },
    {
      "lang": "en",
      "text": "more challenging and that's why leaving",
      "offset": 182.72,
      "duration": 4.2
    },
    {
      "lang": "en",
      "text": "this task to neural networks is a good",
      "offset": 184.4,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "idea If you are dealing with",
      "offset": 186.92,
      "duration": 3.8
    },
    {
      "lang": "en",
      "text": "unstructured data you don't need to",
      "offset": 188.72,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "interpret the results and your problem",
      "offset": 190.72,
      "duration": 4.239
    },
    {
      "lang": "en",
      "text": "can benefit from an ownarchitecture Then",
      "offset": 192.8,
      "duration": 4.359
    },
    {
      "lang": "en",
      "text": "you probably should use neural",
      "offset": 194.959,
      "duration": 4.801
    },
    {
      "lang": "en",
      "text": "networks For instance when classifying",
      "offset": 197.159,
      "duration": 5
    },
    {
      "lang": "en",
      "text": "images of cats and dogs images are",
      "offset": 199.76,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "unstructured data We don't care as much",
      "offset": 202.159,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "about why the network knows it is a cat",
      "offset": 204.4,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "or a dog And we can benefit from",
      "offset": 206.48,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "convolutional neural networks So it is",
      "offset": 208.319,
      "duration": 4.801
    },
    {
      "lang": "en",
      "text": "wise to use neural networks You will",
      "offset": 210.48,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "learn more about the usefulness of",
      "offset": 213.12,
      "duration": 2.96
    },
    {
      "lang": "en",
      "text": "convolutional neural networks later on",
      "offset": 214.4,
      "duration": 2.759
    },
    {
      "lang": "en",
      "text": "in the",
      "offset": 216.08,
      "duration": 3.48
    },
    {
      "lang": "en",
      "text": "course Let's start building neural",
      "offset": 217.159,
      "duration": 5
    },
    {
      "lang": "en",
      "text": "networks In a nutshell a neural network",
      "offset": 219.56,
      "duration": 4.36
    },
    {
      "lang": "en",
      "text": "is a machine learning algorithm that is",
      "offset": 222.159,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "fetched with training data for its input",
      "offset": 223.92,
      "duration": 3.679
    },
    {
      "lang": "en",
      "text": "layer to then predict a value at its",
      "offset": 225.84,
      "duration": 4.479
    },
    {
      "lang": "en",
      "text": "output layer Each connection from one",
      "offset": 227.599,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "neuron to another has an associated",
      "offset": 230.319,
      "duration": 5.041
    },
    {
      "lang": "en",
      "text": "weight w and each neuron except the",
      "offset": 232.159,
      "duration": 5.121
    },
    {
      "lang": "en",
      "text": "input layer which just holds the input",
      "offset": 235.36,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "value also has an extra weight and we",
      "offset": 237.28,
      "duration": 5.519
    },
    {
      "lang": "en",
      "text": "call this the bias weight B During fit",
      "offset": 239.36,
      "duration": 5.519
    },
    {
      "lang": "en",
      "text": "forward our input gets transformed by",
      "offset": 242.799,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "weight multiplications and additions at",
      "offset": 244.879,
      "duration": 4.881
    },
    {
      "lang": "en",
      "text": "each layer The output of each neuron can",
      "offset": 246.64,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "also get transformed by the application",
      "offset": 249.76,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "of what we call an activation function",
      "offset": 251.28,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "Learning in neural networks consists of",
      "offset": 254.159,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "tuning the weights or parameters to give",
      "offset": 256.16,
      "duration": 4.479
    },
    {
      "lang": "en",
      "text": "the desired output One way of achieving",
      "offset": 258.079,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "this is by using the famous gradient",
      "offset": 260.639,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "descent algorithm and applying weight",
      "offset": 262.4,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "updates incrementally via a process",
      "offset": 264.8,
      "duration": 3.32
    },
    {
      "lang": "en",
      "text": "known as back",
      "offset": 266.88,
      "duration": 3.759
    },
    {
      "lang": "en",
      "text": "propagation That was a lot of theory The",
      "offset": 268.12,
      "duration": 4.68
    },
    {
      "lang": "en",
      "text": "code in Keras is much simpler as we will",
      "offset": 270.639,
      "duration": 4.801
    },
    {
      "lang": "en",
      "text": "see now Keras allows you to build models",
      "offset": 272.8,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "in two different ways using either the",
      "offset": 275.44,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "functional API or the sequential API We",
      "offset": 277.52,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "will focus on the sequential API This is",
      "offset": 280.4,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "a simple yet very powerful way of",
      "offset": 282.72,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "building neural networks that will get",
      "offset": 284.56,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "you covered for most use cases With the",
      "offset": 286.32,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "sequential API you're essentially",
      "offset": 288.8,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "building a model as a stack of layers",
      "offset": 290.479,
      "duration": 5.041
    },
    {
      "lang": "en",
      "text": "You can start with an input layer add a",
      "offset": 292.8,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "couple of hidden layers and finally your",
      "offset": 295.52,
      "duration": 4.959
    },
    {
      "lang": "en",
      "text": "model by adding an output layer Let's go",
      "offset": 298.24,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "through a code example To create a",
      "offset": 300.479,
      "duration": 4.241
    },
    {
      "lang": "en",
      "text": "simple neuron network we will do the",
      "offset": 303.12,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "following First import the sequential",
      "offset": 304.72,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "model from TensorFlow KAS models Second",
      "offset": 306.96,
      "duration": 4.959
    },
    {
      "lang": "en",
      "text": "import a dense layer also known as a",
      "offset": 310.16,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "fully connected layer from TensorFlow",
      "offset": 311.919,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "kas layers We can then create an",
      "offset": 314,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "instance of a sequential model In this",
      "offset": 316.639,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "next line of code we add two layers a",
      "offset": 319.44,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "two neuron dense fully connected layer",
      "offset": 321.759,
      "duration": 4.28
    },
    {
      "lang": "en",
      "text": "and an input layer consisting of three",
      "offset": 323.84,
      "duration": 4.799
    },
    {
      "lang": "en",
      "text": "neurons The input layer is defined with",
      "offset": 326.039,
      "duration": 4.841
    },
    {
      "lang": "en",
      "text": "the input shape parameter and it matches",
      "offset": 328.639,
      "duration": 5.041
    },
    {
      "lang": "en",
      "text": "the dimension of our input data We",
      "offset": 330.88,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "finally add another fully connected",
      "offset": 333.68,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "layer this time with one neon And we",
      "offset": 335.6,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "have just built the network to the right",
      "offset": 338,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "In order to add an activation function",
      "offset": 340.72,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "to our layers we can make use of the",
      "offset": 342.56,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "activation argument For instance this is",
      "offset": 344.32,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "how we will add a ReLU activation to our",
      "offset": 347.36,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "hidden layer Don't worry about the",
      "offset": 349.28,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "choice of activation functions that will",
      "offset": 351.36,
      "duration": 3.72
    },
    {
      "lang": "en",
      "text": "be covered later on in the",
      "offset": 353.28,
      "duration": 4.479
    },
    {
      "lang": "en",
      "text": "course Once we have created our model we",
      "offset": 355.08,
      "duration": 5
    },
    {
      "lang": "en",
      "text": "can call the summary method on it This",
      "offset": 357.759,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "displays a table with three columns The",
      "offset": 360.08,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "first with the layers name and type The",
      "offset": 362.16,
      "duration": 3.759
    },
    {
      "lang": "en",
      "text": "second with the shape of the outputs",
      "offset": 364.479,
      "duration": 3.761
    },
    {
      "lang": "en",
      "text": "produced by each layer and the third",
      "offset": 365.919,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "containing the number of parameters",
      "offset": 368.24,
      "duration": 3.679
    },
    {
      "lang": "en",
      "text": "These are the weights including the bias",
      "offset": 369.919,
      "duration": 4.641
    },
    {
      "lang": "en",
      "text": "weight of each neuron in the layer When",
      "offset": 371.919,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "the input layer is defined by the input",
      "offset": 374.56,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "shape parameter as we did before it is",
      "offset": 376.639,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "not shown as a layer in the summary but",
      "offset": 378.72,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "it is included in the layer where it was",
      "offset": 380.639,
      "duration": 3.881
    },
    {
      "lang": "en",
      "text": "defined in this case the dense free",
      "offset": 382.4,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "layer That's why we see that this layer",
      "offset": 384.52,
      "duration": 5.08
    },
    {
      "lang": "en",
      "text": "has eight parameters These parameters or",
      "offset": 386.96,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "weights come from the connections of the",
      "offset": 389.6,
      "duration": 3.439
    },
    {
      "lang": "en",
      "text": "free input neurons to the two neurons in",
      "offset": 391.12,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "this layer The missing two parameters",
      "offset": 393.039,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "come from the bias weights B 0 and B1",
      "offset": 395.6,
      "duration": 6.08
    },
    {
      "lang": "en",
      "text": "One per each neuron in the hidden layer",
      "offset": 398.639,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "These are up to eight different",
      "offset": 401.68,
      "duration": 4.04
    },
    {
      "lang": "en",
      "text": "parameters Use what we had in our",
      "offset": 402.96,
      "duration": 5.359
    },
    {
      "lang": "en",
      "text": "summary Welcome back We are going to",
      "offset": 405.72,
      "duration": 4.36
    },
    {
      "lang": "en",
      "text": "learn just what you were missing to be",
      "offset": 408.319,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "able to save the Earth from a meteor",
      "offset": 410.08,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "strike But first let's see how to",
      "offset": 411.919,
      "duration": 4.521
    },
    {
      "lang": "en",
      "text": "compile train and predict with your",
      "offset": 414,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "models In the previous lesson we saw how",
      "offset": 416.44,
      "duration": 5.4
    },
    {
      "lang": "en",
      "text": "easy it was to create a model with caris",
      "offset": 419.28,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "You instantiate your sequential model",
      "offset": 421.84,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "add a couple of layers and activations",
      "offset": 423.68,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "and that's it You've built a simple",
      "offset": 425.919,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "model in no time A model needs to be",
      "offset": 427.599,
      "duration": 5.281
    },
    {
      "lang": "en",
      "text": "compiled before training We can compile",
      "offset": 430.639,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "our model by calling the compile method",
      "offset": 432.88,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "on it The compile method receives an",
      "offset": 434.72,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "optimizer which we can see as the",
      "offset": 437.199,
      "duration": 3.201
    },
    {
      "lang": "en",
      "text": "algorithm that will be used to update",
      "offset": 438.88,
      "duration": 3.599
    },
    {
      "lang": "en",
      "text": "our neural network weights and a loss",
      "offset": 440.4,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "function which is the function we want",
      "offset": 442.479,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "to minimize during training In this case",
      "offset": 444.24,
      "duration": 5.359
    },
    {
      "lang": "en",
      "text": "we chose add-on as our optimizer and min",
      "offset": 446.88,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "square error as our loss function",
      "offset": 449.599,
      "duration": 4.561
    },
    {
      "lang": "en",
      "text": "Optimizers and loss functions will be",
      "offset": 452.16,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "covered later on in the course So don't",
      "offset": 454.16,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "worry about it for now Compiling our",
      "offset": 456.08,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "model produces no output Our model is",
      "offset": 458.319,
      "duration": 5.521
    },
    {
      "lang": "en",
      "text": "now ready to train Creating a model is",
      "offset": 460.96,
      "duration": 5.359
    },
    {
      "lang": "en",
      "text": "useless if we don't train it We train",
      "offset": 463.84,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "our model by calling the fit method and",
      "offset": 466.319,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "passing the features in X train the",
      "offset": 468.08,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "labels in Y train and the number of",
      "offset": 470.24,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "epochs to train for During an epoch our",
      "offset": 472.24,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "entire training data processed through",
      "offset": 475.36,
      "duration": 3.279
    },
    {
      "lang": "en",
      "text": "the network and the respective weight",
      "offset": 476.96,
      "duration": 3.4
    },
    {
      "lang": "en",
      "text": "updates take place using back",
      "offset": 478.639,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "propagation As our model is being",
      "offset": 480.36,
      "duration": 4.119
    },
    {
      "lang": "en",
      "text": "trained we will get some output showing",
      "offset": 482.479,
      "duration": 4.481
    },
    {
      "lang": "en",
      "text": "it progress We can see the model is",
      "offset": 484.479,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "improving since the mean square error",
      "offset": 486.96,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "loss is decreasing at each epoch To",
      "offset": 488.639,
      "duration": 4.801
    },
    {
      "lang": "en",
      "text": "obtain predictions from our train model",
      "offset": 491.68,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "we just need to call predict on the new",
      "offset": 493.44,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "set of data We can store the predictions",
      "offset": 495.12,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "in a variable for later use The",
      "offset": 497.599,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "predictions are used numbers in a numpy",
      "offset": 500.16,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "array We will interpret this depending",
      "offset": 502,
      "duration": 4.879
    },
    {
      "lang": "en",
      "text": "on our data set on problem at 10 To",
      "offset": 504.08,
      "duration": 4.559
    },
    {
      "lang": "en",
      "text": "quickly evaluate how well our model",
      "offset": 506.879,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "performs on unseen data we can use the",
      "offset": 508.639,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "models evaluate method This performs fit",
      "offset": 510.72,
      "duration": 4.879
    },
    {
      "lang": "en",
      "text": "forward with all samples in our test",
      "offset": 513.839,
      "duration": 4.801
    },
    {
      "lang": "en",
      "text": "data set X test Fit forward consists in",
      "offset": 515.599,
      "duration": 4.961
    },
    {
      "lang": "en",
      "text": "computing a model's output from a given",
      "offset": 518.64,
      "duration": 4.959
    },
    {
      "lang": "en",
      "text": "set of inputs It then computes the error",
      "offset": 520.56,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "comparing the results to the true values",
      "offset": 523.599,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "stored in Y test In this particular",
      "offset": 525.6,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "example the model we trained for five",
      "offset": 528,
      "duration": 5.399
    },
    {
      "lang": "en",
      "text": "epochs before has a mean square error of",
      "offset": 529.68,
      "duration": 6.32
    },
    {
      "lang": "en",
      "text": "0.25 Are you ready a meteor is",
      "offset": 533.399,
      "duration": 3.961
    },
    {
      "lang": "en",
      "text": "approaching the Earth and we want to",
      "offset": 536,
      "duration": 3.279
    },
    {
      "lang": "en",
      "text": "make sure it won't take us to extinction",
      "offset": 537.36,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "A group of scientists is trying to",
      "offset": 539.279,
      "duration": 3.281
    },
    {
      "lang": "en",
      "text": "estimate the orbit by using historical",
      "offset": 540.72,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "data gathered about previous orbits of",
      "offset": 542.56,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "similar meteors Scientists have used",
      "offset": 544.24,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "this data alongside their knowledge to",
      "offset": 546.8,
      "duration": 4.479
    },
    {
      "lang": "en",
      "text": "estimate an 8 minute orbit That is an",
      "offset": 548.88,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "orbit from -40 minutes to + 40 minutes",
      "offset": 551.279,
      "duration": 5.361
    },
    {
      "lang": "en",
      "text": "T0 corresponds to the time of crossing",
      "offset": 554.56,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "the impact region It looks like the",
      "offset": 556.64,
      "duration": 4.639
    },
    {
      "lang": "en",
      "text": "meter will be close Perhaps it won't hit",
      "offset": 558.959,
      "duration": 4.721
    },
    {
      "lang": "en",
      "text": "us but we must make sure we are right",
      "offset": 561.279,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "You have data for the path a previous",
      "offset": 563.68,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "meteor took during a period of 20",
      "offset": 565.6,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "minutes 10 minutes before and 10 minutes",
      "offset": 567.68,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "after crossing the impact region You",
      "offset": 570.08,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "will train a model on this data and then",
      "offset": 572.48,
      "duration": 3.359
    },
    {
      "lang": "en",
      "text": "extrapolate your predictions to an",
      "offset": 574.24,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "80minute orbit to see how it compares to",
      "offset": 575.839,
      "duration": 4.801
    },
    {
      "lang": "en",
      "text": "the scientist prediction Will your orbit",
      "offset": 578,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "be similar to that of the scientists or",
      "offset": 580.64,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "are we facing distinction of humanity as",
      "offset": 582.32,
      "duration": 4.639
    },
    {
      "lang": "en",
      "text": "we know it you are now ready to learn",
      "offset": 584.16,
      "duration": 4.799
    },
    {
      "lang": "en",
      "text": "about binary classification So let's",
      "offset": 586.959,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "dive in You will use binary",
      "offset": 588.959,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "classification when you want to solve",
      "offset": 591.04,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "problems where you predict whether an",
      "offset": 592.64,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "observation belongs to one of two",
      "offset": 594.24,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "possible classes A simple binary",
      "offset": 596.08,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "classification problem could be learning",
      "offset": 598.64,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "the boundaries to separate blue from red",
      "offset": 600.48,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "circles as shown in the image The data",
      "offset": 602.48,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "set for this problem is very simple The",
      "offset": 605.6,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "coordinates are pairs of values",
      "offset": 607.92,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "corresponding to the x and y coordinates",
      "offset": 609.519,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "of each circle in the graph The labels",
      "offset": 611.44,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "are one for red circles and zero for the",
      "offset": 613.68,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "blue circles We can make use of",
      "offset": 615.92,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "seaburn's perplot function to explore a",
      "offset": 618.48,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "small data set and identify whether our",
      "offset": 620.56,
      "duration": 4.279
    },
    {
      "lang": "en",
      "text": "classification program will be easily",
      "offset": 622.56,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "separable We can get an intuition for",
      "offset": 624.839,
      "duration": 4.201
    },
    {
      "lang": "en",
      "text": "this If we see that the classes separate",
      "offset": 627.12,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "well enough along several variables In",
      "offset": 629.04,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "this case for the circles data set there",
      "offset": 632,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "is a very clear boundary The red circles",
      "offset": 634.16,
      "duration": 4.239
    },
    {
      "lang": "en",
      "text": "concentrate at the center while the blue",
      "offset": 636.399,
      "duration": 4.641
    },
    {
      "lang": "en",
      "text": "are outside It should be easy for our",
      "offset": 638.399,
      "duration": 4.481
    },
    {
      "lang": "en",
      "text": "network to find a way to separate them",
      "offset": 641.04,
      "duration": 4.039
    },
    {
      "lang": "en",
      "text": "just based on x and y",
      "offset": 642.88,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "coordinates This is the neural network",
      "offset": 645.079,
      "duration": 3.721
    },
    {
      "lang": "en",
      "text": "we will build to classify red and blue",
      "offset": 647.2,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "dots in our graph We have two neurons as",
      "offset": 648.8,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "an input layer One for the x coordinate",
      "offset": 651.519,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "and another for the y-coordinate of each",
      "offset": 653.68,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "of the red and blue circles in the graph",
      "offset": 655.44,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "Then we have one hidden layer with four",
      "offset": 657.839,
      "duration": 4.641
    },
    {
      "lang": "en",
      "text": "neurons Four is a good enough number to",
      "offset": 660,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "learn the separation of classes in this",
      "offset": 662.48,
      "duration": 3.96
    },
    {
      "lang": "en",
      "text": "data set This was found by",
      "offset": 664,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "experimentation We finally output a",
      "offset": 666.44,
      "duration": 4.12
    },
    {
      "lang": "en",
      "text": "single output neuron which makes use of",
      "offset": 669.04,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "the sigmoid activation function It is",
      "offset": 670.56,
      "duration": 4.719
    },
    {
      "lang": "en",
      "text": "important to note that regardless of the",
      "offset": 673.36,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "activation functions used for the",
      "offset": 675.279,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "previous layers we do need the sig mode",
      "offset": 676.88,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "activation function for this last output",
      "offset": 678.88,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "node The sigmo activation function",
      "offset": 680.8,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "squashes the neuron output of the second",
      "offset": 683.6,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "to last layer to a floating point number",
      "offset": 685.2,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "between zero and one You can consider",
      "offset": 687.36,
      "duration": 4.479
    },
    {
      "lang": "en",
      "text": "the output of the sit function as the",
      "offset": 690,
      "duration": 3.519
    },
    {
      "lang": "en",
      "text": "probability of a pair of coordinates",
      "offset": 691.839,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "being in one class or another So we can",
      "offset": 693.519,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "set a threshold and say that everything",
      "offset": 696,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "below 0.5 will be a blue circle and",
      "offset": 697.68,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "everything above a red one So let's",
      "offset": 700.079,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "build our model in caras We start by",
      "offset": 702.64,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "importing the sequential model and the",
      "offset": 704.959,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "dense layer We then instantiate a",
      "offset": 706.64,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "sequential model We add a hidden layer",
      "offset": 709.12,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "of four neurons and we define an input",
      "offset": 711.76,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "shape which consists of two neurons We",
      "offset": 713.6,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "use the tanh as the activation function",
      "offset": 716.32,
      "duration": 4.639
    },
    {
      "lang": "en",
      "text": "for this hidden layer Activation",
      "offset": 718.48,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "functions are covered later in the",
      "offset": 720.959,
      "duration": 2.801
    },
    {
      "lang": "en",
      "text": "course So don't worry about this choice",
      "offset": 722.399,
      "duration": 4.641
    },
    {
      "lang": "en",
      "text": "for now We finally add an output layer",
      "offset": 723.76,
      "duration": 5.92
    },
    {
      "lang": "en",
      "text": "which contains a single neuron We make",
      "offset": 727.04,
      "duration": 4.479
    },
    {
      "lang": "en",
      "text": "use of the sigmo activation function so",
      "offset": 729.68,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "that we achieve the behavior we expect",
      "offset": 731.519,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "from this network that is obtaining a",
      "offset": 733.2,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "value between zero and one Our model is",
      "offset": 735.36,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "now ready to be trained Just as before",
      "offset": 737.92,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "we need to compile our model before",
      "offset": 740.88,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "training We will use stoastic gradient",
      "offset": 742.48,
      "duration": 4.799
    },
    {
      "lang": "en",
      "text": "descent as an optimizer and binary",
      "offset": 745.279,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "crosropy as our loss function Binary",
      "offset": 747.279,
      "duration": 5.281
    },
    {
      "lang": "en",
      "text": "centropy is the function we use when our",
      "offset": 750.399,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "output neuron is using sigmoid as it",
      "offset": 752.56,
      "duration": 4.959
    },
    {
      "lang": "en",
      "text": "activation function We train our model",
      "offset": 754.72,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "for 20 epochs passing our coordinates",
      "offset": 757.519,
      "duration": 3.241
    },
    {
      "lang": "en",
      "text": "and labels as",
      "offset": 759.44,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "parameters Then we obtain the predicted",
      "offset": 760.76,
      "duration": 4.639
    },
    {
      "lang": "en",
      "text": "labels by calling predict on",
      "offset": 763.12,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "coordinates These are the boundaries",
      "offset": 765.399,
      "duration": 3.521
    },
    {
      "lang": "en",
      "text": "that were learned to classify our",
      "offset": 767.279,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "circles It looks like our model did",
      "offset": 768.92,
      "duration": 4.2
    },
    {
      "lang": "en",
      "text": "pretty well",
      "offset": 771.2,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "What about when we have more than two",
      "offset": 773.12,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "classes to classify we run into a",
      "offset": 774.48,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "multiclass classification problem But",
      "offset": 776.88,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "don't worry we just have to make a minor",
      "offset": 779.04,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "tweak to our neural network architecture",
      "offset": 780.88,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "Identifying who flew which dart in a",
      "offset": 783.36,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "gain of darts is a good example of a",
      "offset": 785.279,
      "duration": 4.481
    },
    {
      "lang": "en",
      "text": "multiclass classification problem Each",
      "offset": 787.12,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "dart can only be thrown by one",
      "offset": 789.76,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "competitor And that means that our",
      "offset": 791.36,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "classes are mutually exclusive since no",
      "offset": 793.12,
      "duration": 3.519
    },
    {
      "lang": "en",
      "text": "dart can be thrown by two different",
      "offset": 795.12,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "competitors simultaneously",
      "offset": 796.639,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "The dart data set consists of dart",
      "offset": 798.8,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "throws by different competitors The",
      "offset": 800.639,
      "duration": 4.801
    },
    {
      "lang": "en",
      "text": "coordinate pairs X core and Y core show",
      "offset": 802.72,
      "duration": 4.44
    },
    {
      "lang": "en",
      "text": "where each dart",
      "offset": 805.44,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "landed Based on the landing position of",
      "offset": 807.16,
      "duration": 4.52
    },
    {
      "lang": "en",
      "text": "previously thrown darts we should be",
      "offset": 809.839,
      "duration": 3.521
    },
    {
      "lang": "en",
      "text": "able to distinguish between throwers if",
      "offset": 811.68,
      "duration": 3.32
    },
    {
      "lang": "en",
      "text": "there's enough variation between their",
      "offset": 813.36,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "throws In our pair plot we can see that",
      "offset": 815,
      "duration": 4.519
    },
    {
      "lang": "en",
      "text": "different players tend to end at",
      "offset": 817.76,
      "duration": 3.4
    },
    {
      "lang": "en",
      "text": "specific regions of the",
      "offset": 819.519,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "board The model for this data set has",
      "offset": 821.16,
      "duration": 4.2
    },
    {
      "lang": "en",
      "text": "two neurons as inputs since our",
      "offset": 823.6,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "predictors are X chord and Y chord",
      "offset": 825.36,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "We will define them using the input",
      "offset": 828.24,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "shape argument just as we've done before",
      "offset": 830,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "In between there will be a series of",
      "offset": 832.56,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "hidden layers We are using three dense",
      "offset": 834.24,
      "duration": 6.8
    },
    {
      "lang": "en",
      "text": "layers of 128 64 and 32 neurons each As",
      "offset": 836.399,
      "duration": 6.88
    },
    {
      "lang": "en",
      "text": "outputs we have four neurons one per",
      "offset": 841.04,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "competitor Let's look closer at the",
      "offset": 843.279,
      "duration": 5.761
    },
    {
      "lang": "en",
      "text": "output layer Now we have four outputs",
      "offset": 845.36,
      "duration": 6.159
    },
    {
      "lang": "en",
      "text": "each linked to a possible competitor",
      "offset": 849.04,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "Each competitor has a probability of",
      "offset": 851.519,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "having thrown a given dart So we must",
      "offset": 853.44,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "make sure that the total sum of",
      "offset": 855.519,
      "duration": 3.041
    },
    {
      "lang": "en",
      "text": "probabilities for the output neurons",
      "offset": 856.8,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "equals one We achieve this with the",
      "offset": 858.56,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "softmass activation function Once we",
      "offset": 861.12,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "have a probability per output neuron we",
      "offset": 864.24,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "then choose as our prediction the",
      "offset": 866.24,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "competitor whose associated output has",
      "offset": 867.76,
      "duration": 3.4
    },
    {
      "lang": "en",
      "text": "the highest",
      "offset": 869.76,
      "duration": 3.519
    },
    {
      "lang": "en",
      "text": "probability You can build this model as",
      "offset": 871.16,
      "duration": 4.119
    },
    {
      "lang": "en",
      "text": "we did in the previous lesson",
      "offset": 873.279,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "Instantiate a sequential model add a",
      "offset": 875.279,
      "duration": 4.641
    },
    {
      "lang": "en",
      "text": "hidden layer also defining an input",
      "offset": 877.839,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "layer with the input shape parameter and",
      "offset": 879.92,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "finish by adding the remaining hidden",
      "offset": 882,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "layers and an output layer with soft",
      "offset": 883.92,
      "duration": 2.2
    },
    {
      "lang": "en",
      "text": "mass",
      "offset": 885.36,
      "duration": 2.88
    },
    {
      "lang": "en",
      "text": "activation You will do all this yourself",
      "offset": 886.12,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "in the",
      "offset": 888.24,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "exercises when compiling your model",
      "offset": 889.48,
      "duration": 4.359
    },
    {
      "lang": "en",
      "text": "Instead of binary cross entropy as we",
      "offset": 892,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "used before we now use categorical cross",
      "offset": 893.839,
      "duration": 5.201
    },
    {
      "lang": "en",
      "text": "entropy or loss Categorical cross",
      "offset": 895.92,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "entropy measures the difference between",
      "offset": 899.04,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "the predicted probabilities and the true",
      "offset": 901.04,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "labels of the class we should have",
      "offset": 902.8,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "predicted So if we should have predicted",
      "offset": 904.24,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "one for a given class taking a look at",
      "offset": 906.48,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "the graph we see that we will get high",
      "offset": 908.8,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "loss values for predicting close to zero",
      "offset": 910.8,
      "duration": 4.719
    },
    {
      "lang": "en",
      "text": "since we will be very wrong and low loss",
      "offset": 912.8,
      "duration": 4.719
    },
    {
      "lang": "en",
      "text": "values for predicting closer to one the",
      "offset": 915.519,
      "duration": 2.68
    },
    {
      "lang": "en",
      "text": "true",
      "offset": 917.519,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "label Since our outputs are vectors",
      "offset": 918.199,
      "duration": 4.361
    },
    {
      "lang": "en",
      "text": "containing the probabilities of each",
      "offset": 920.959,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "class our neural network must also be",
      "offset": 922.56,
      "duration": 4.519
    },
    {
      "lang": "en",
      "text": "trained with vectors representing this",
      "offset": 924.88,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "concept To achieve that we make use of",
      "offset": 927.079,
      "duration": 4.681
    },
    {
      "lang": "en",
      "text": "the terms of locas utils to categorical",
      "offset": 929.44,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "function We first turn our response",
      "offset": 931.76,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "variable into a categorical variable",
      "offset": 934.72,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "with bandax categorical This allow us to",
      "offset": 936.48,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "redefine the column using the",
      "offset": 939.36,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "categorical codes cat codes of the",
      "offset": 940.72,
      "duration": 3.32
    },
    {
      "lang": "en",
      "text": "different",
      "offset": 943.199,
      "duration": 3.281
    },
    {
      "lang": "en",
      "text": "categories Now that our categories are",
      "offset": 944.04,
      "duration": 4.84
    },
    {
      "lang": "en",
      "text": "each represented by a unique integer we",
      "offset": 946.48,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "can use the to categorical function to",
      "offset": 948.88,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "turn them into one hot encoded vectors",
      "offset": 950.639,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "where each component is zero except for",
      "offset": 952.959,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "the one corresponding to the label",
      "offset": 955.04,
      "duration": 3.599
    },
    {
      "lang": "en",
      "text": "categories",
      "offset": 956.639,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "Car to categorical essentially perform",
      "offset": 958.639,
      "duration": 4.281
    },
    {
      "lang": "en",
      "text": "the process described in the picture",
      "offset": 960.72,
      "duration": 5.359
    },
    {
      "lang": "en",
      "text": "above Label encoded apple chicken and",
      "offset": 962.92,
      "duration": 5.32
    },
    {
      "lang": "en",
      "text": "broccoli turned into a vector of three",
      "offset": 966.079,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "components A one is placed to represent",
      "offset": 968.24,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "the presence of the class and a zero to",
      "offset": 970.639,
      "duration": 4.281
    },
    {
      "lang": "en",
      "text": "indicate its",
      "offset": 973.04,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "assence Now that you know how multiclass",
      "offset": 974.92,
      "duration": 4.359
    },
    {
      "lang": "en",
      "text": "classification works we can take a look",
      "offset": 977.44,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "at multilel classification",
      "offset": 979.279,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "They both deal with predicting classes",
      "offset": 981.6,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "But in multilel classification a single",
      "offset": 983.839,
      "duration": 4.281
    },
    {
      "lang": "en",
      "text": "input can be assigned to more than one",
      "offset": 986,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "class We could use multilel",
      "offset": 988.12,
      "duration": 4.12
    },
    {
      "lang": "en",
      "text": "classification for instance to tack a",
      "offset": 990.24,
      "duration": 4.279
    },
    {
      "lang": "en",
      "text": "series generous by plot",
      "offset": 992.24,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "summary Making models that deal with",
      "offset": 994.519,
      "duration": 4.521
    },
    {
      "lang": "en",
      "text": "text or images is not covered and",
      "offset": 996.88,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "discourse in depth We will learn more",
      "offset": 999.04,
      "duration": 4.799
    },
    {
      "lang": "en",
      "text": "about it on chapter 4 Imagine we had",
      "offset": 1000.959,
      "duration": 6.161
    },
    {
      "lang": "en",
      "text": "three classes sun moon and clouds In",
      "offset": 1003.839,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "multiclass problems if we took a sample",
      "offset": 1007.12,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "of our observations each individual in",
      "offset": 1008.959,
      "duration": 4.961
    },
    {
      "lang": "en",
      "text": "the sample will belong to a unique class",
      "offset": 1011.199,
      "duration": 5.121
    },
    {
      "lang": "en",
      "text": "However in a multilabel problem each",
      "offset": 1013.92,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "individual in the sample can have all",
      "offset": 1016.32,
      "duration": 4.439
    },
    {
      "lang": "en",
      "text": "none or as a set of the available",
      "offset": 1018.48,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "classes As you can see in the image",
      "offset": 1020.759,
      "duration": 4.68
    },
    {
      "lang": "en",
      "text": "multilel vectors are also one whole",
      "offset": 1023.12,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "encoded There is a one or a zero",
      "offset": 1025.439,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "representing the presence or accents of",
      "offset": 1027.76,
      "duration": 3.679
    },
    {
      "lang": "en",
      "text": "each class",
      "offset": 1029.679,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "Making a multilabel model for this",
      "offset": 1031.439,
      "duration": 3.441
    },
    {
      "lang": "en",
      "text": "problem is not that different to what",
      "offset": 1033.28,
      "duration": 3.399
    },
    {
      "lang": "en",
      "text": "you did when building your multiclass",
      "offset": 1034.88,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "model We first instantiate a sequential",
      "offset": 1036.679,
      "duration": 5.321
    },
    {
      "lang": "en",
      "text": "model For the sake of this example we",
      "offset": 1039.36,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "will assume that to differentiate",
      "offset": 1042,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "between these three classes we need just",
      "offset": 1043.36,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "one input and two hidden neurons The",
      "offset": 1045.12,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "biggest changes happen in the output",
      "offset": 1047.679,
      "duration": 4.801
    },
    {
      "lang": "en",
      "text": "layer and in activation function In the",
      "offset": 1049.6,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "output layer we use as many neurons as",
      "offset": 1052.48,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "possible classes but we use sit mode",
      "offset": 1054.72,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "activation This time we use sigmoid",
      "offset": 1056.72,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "outputs because we no longer care about",
      "offset": 1059.2,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "the sum of probabilities We want each",
      "offset": 1061.28,
      "duration": 4.639
    },
    {
      "lang": "en",
      "text": "output neuron to be able to individually",
      "offset": 1063.6,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "take a value between 0 and one This can",
      "offset": 1065.919,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "be achieved with the situ activation",
      "offset": 1068.48,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "because it constrains our neuron output",
      "offset": 1070.32,
      "duration": 3
    },
    {
      "lang": "en",
      "text": "in the range",
      "offset": 1072.16,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "01 That's what we did in binary",
      "offset": 1073.32,
      "duration": 3.88
    },
    {
      "lang": "en",
      "text": "classification though we only had one",
      "offset": 1075.52,
      "duration": 5.039
    },
    {
      "lang": "en",
      "text": "output neuron there Binary cross entropy",
      "offset": 1077.2,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "is now used as the loss function when",
      "offset": 1080.559,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "compiling the model You can look at it",
      "offset": 1082.48,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "as if you were performing several binary",
      "offset": 1084.48,
      "duration": 4.559
    },
    {
      "lang": "en",
      "text": "classification problems For each output",
      "offset": 1086.559,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "we are deciding whether or not it",
      "offset": 1089.039,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "corresponding label is present given the",
      "offset": 1090.88,
      "duration": 3
    },
    {
      "lang": "en",
      "text": "current",
      "offset": 1093.039,
      "duration": 3.441
    },
    {
      "lang": "en",
      "text": "input When training our model we can use",
      "offset": 1093.88,
      "duration": 4.36
    },
    {
      "lang": "en",
      "text": "the validation split argument to print",
      "offset": 1096.48,
      "duration": 4.52
    },
    {
      "lang": "en",
      "text": "validation loss and accuracy as it",
      "offset": 1098.24,
      "duration": 5.439
    },
    {
      "lang": "en",
      "text": "trains By using validation split a",
      "offset": 1101,
      "duration": 4.6
    },
    {
      "lang": "en",
      "text": "percentage of the training data is left",
      "offset": 1103.679,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "out for testing at each epoch You can",
      "offset": 1105.6,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "see how using neural networks for",
      "offset": 1108.559,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "multi-level classification can be",
      "offset": 1110.32,
      "duration": 3.56
    },
    {
      "lang": "en",
      "text": "performed with minor tweaks to our model",
      "offset": 1111.919,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "architecture If we were to use a",
      "offset": 1113.88,
      "duration": 3.64
    },
    {
      "lang": "en",
      "text": "classical machine learning approach to",
      "offset": 1115.84,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "solve multille problems we will need",
      "offset": 1117.52,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "more complex methods One way to do so",
      "offset": 1119.52,
      "duration": 5.039
    },
    {
      "lang": "en",
      "text": "consists of training several classifiers",
      "offset": 1122.24,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "to distinguish each particular class",
      "offset": 1124.559,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "from the rest This is called one versus",
      "offset": 1126.48,
      "duration": 3.88
    },
    {
      "lang": "en",
      "text": "rest",
      "offset": 1129.039,
      "duration": 3.281
    },
    {
      "lang": "en",
      "text": "classification Let's tackle a new",
      "offset": 1130.36,
      "duration": 4.6
    },
    {
      "lang": "en",
      "text": "problem A farm field has an array of 20",
      "offset": 1132.32,
      "duration": 5.4
    },
    {
      "lang": "en",
      "text": "sensors distributed along three crop",
      "offset": 1134.96,
      "duration": 5.599
    },
    {
      "lang": "en",
      "text": "fields These sensors measure among other",
      "offset": 1137.72,
      "duration": 4.68
    },
    {
      "lang": "en",
      "text": "things the humidity of the soil",
      "offset": 1140.559,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "radiation of the sun etc Your task is to",
      "offset": 1142.4,
      "duration": 5.279
    },
    {
      "lang": "en",
      "text": "use the combination of measurements from",
      "offset": 1145.919,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "these sensors to decide which partial to",
      "offset": 1147.679,
      "duration": 4.721
    },
    {
      "lang": "en",
      "text": "water given each parcel has a different",
      "offset": 1150,
      "duration": 3.64
    },
    {
      "lang": "en",
      "text": "environmental",
      "offset": 1152.4,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "requirement Each sensor measures an",
      "offset": 1153.64,
      "duration": 5.48
    },
    {
      "lang": "en",
      "text": "integer value between zero and 13 volts",
      "offset": 1156,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "Parcels can be represented as one hot",
      "offset": 1159.12,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "encoded vectors of length three where",
      "offset": 1161.44,
      "duration": 4.28
    },
    {
      "lang": "en",
      "text": "each index is one of the",
      "offset": 1163.76,
      "duration": 5.96
    },
    {
      "lang": "en",
      "text": "parcels Parcels can be watered",
      "offset": 1165.72,
      "duration": 6.199
    },
    {
      "lang": "en",
      "text": "simultaneously By now you've trained a",
      "offset": 1169.72,
      "duration": 4.36
    },
    {
      "lang": "en",
      "text": "lot of models It is time to learn more",
      "offset": 1171.919,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "about how to better control and",
      "offset": 1174.08,
      "duration": 3.88
    },
    {
      "lang": "en",
      "text": "supervise model training by using",
      "offset": 1175.76,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "callbacks A call back is a function that",
      "offset": 1177.96,
      "duration": 4.92
    },
    {
      "lang": "en",
      "text": "is executed after some other function",
      "offset": 1180.72,
      "duration": 4.959
    },
    {
      "lang": "en",
      "text": "event or task has finished For instance",
      "offset": 1182.88,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "when you touch your phone screen a block",
      "offset": 1185.679,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "of code that identifies the type of",
      "offset": 1187.76,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "gesture will be triggered Since this",
      "offset": 1189.28,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "blood of code has been called after the",
      "offset": 1191.44,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "touching event occurred it is a call",
      "offset": 1193.2,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "back In the same way a caras call back",
      "offset": 1195.12,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "is a blood of code that gets executed",
      "offset": 1198.16,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "after each epoch during training or",
      "offset": 1200,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "after the training is finished They are",
      "offset": 1201.84,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "useful to store metrics as the model",
      "offset": 1204.24,
      "duration": 3.679
    },
    {
      "lang": "en",
      "text": "trains and to make decisions as the",
      "offset": 1206.08,
      "duration": 4.479
    },
    {
      "lang": "en",
      "text": "training goes by Every time you call the",
      "offset": 1207.919,
      "duration": 4.721
    },
    {
      "lang": "en",
      "text": "fit method on a kuras model there is a",
      "offset": 1210.559,
      "duration": 3.761
    },
    {
      "lang": "en",
      "text": "callback object that gets returned after",
      "offset": 1212.64,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "the model finishes training This is the",
      "offset": 1214.32,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "history object Accessing the history",
      "offset": 1216.64,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "attribute which is a Python dictionary",
      "offset": 1219.2,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "we can check the safe metrics of the",
      "offset": 1221.36,
      "duration": 3.88
    },
    {
      "lang": "en",
      "text": "model during training as an array of",
      "offset": 1222.96,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "numbers To get the most out of the",
      "offset": 1225.24,
      "duration": 3.72
    },
    {
      "lang": "en",
      "text": "history object we should use the",
      "offset": 1227.52,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "validation data parameter in our fit",
      "offset": 1228.96,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "method passing X test and Y test as a",
      "offset": 1230.96,
      "duration": 6.24
    },
    {
      "lang": "en",
      "text": "taple The validation split parameter can",
      "offset": 1233.84,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "be used too specifying a percentage of",
      "offset": 1237.2,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "the training data that will be left out",
      "offset": 1239.6,
      "duration": 3.16
    },
    {
      "lang": "en",
      "text": "for testing",
      "offset": 1241.28,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "purposes That way we not only have the",
      "offset": 1242.76,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "training metrics but also the validation",
      "offset": 1245.12,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "metrics You can compare training and",
      "offset": 1247.48,
      "duration": 4.439
    },
    {
      "lang": "en",
      "text": "validation metrics with a few ml lip",
      "offset": 1249.84,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "comments We just need to define a figure",
      "offset": 1251.919,
      "duration": 4.721
    },
    {
      "lang": "en",
      "text": "plot the values of the history attribute",
      "offset": 1254.88,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "for the training accuracy and the",
      "offset": 1256.64,
      "duration": 3.279
    },
    {
      "lang": "en",
      "text": "validation accuracy",
      "offset": 1258,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "We can then make our graph prettier by",
      "offset": 1259.919,
      "duration": 5.161
    },
    {
      "lang": "en",
      "text": "adding a title axis labels and a",
      "offset": 1261.84,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "legend We can see our model accuracy",
      "offset": 1265.08,
      "duration": 4.599
    },
    {
      "lang": "en",
      "text": "increases for both training and test",
      "offset": 1267.84,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "sets till it reaches epoch 25 Then",
      "offset": 1269.679,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "accuracy flattens for the test set which",
      "offset": 1273.44,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "the training keeps improving Overfitting",
      "offset": 1275.679,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "is taking place since we see the",
      "offset": 1278.24,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "training accuracy keeps improving the",
      "offset": 1279.76,
      "duration": 5.039
    },
    {
      "lang": "en",
      "text": "text data decreases in accuracy More on",
      "offset": 1282,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "this in the next chapter",
      "offset": 1284.799,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "Early stopping a model can solve the",
      "offset": 1287.12,
      "duration": 3.679
    },
    {
      "lang": "en",
      "text": "overfitting problem since it stops",
      "offset": 1288.72,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "training when it no longer improves This",
      "offset": 1290.799,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "is extremely useful since deep neural",
      "offset": 1293.28,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "models can take a long time to train and",
      "offset": 1295.2,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "we don't know beforehand how many epochs",
      "offset": 1297.2,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "will be needed Early stopping like the",
      "offset": 1299.2,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "other kas callbacks can be imported from",
      "offset": 1301.84,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "TensorFlow kas callbacks We don't need",
      "offset": 1304.08,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "to instantiate it The early stopping",
      "offset": 1306.72,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "callback can monitor several metrics",
      "offset": 1309.36,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "like validation accuracy validation loss",
      "offset": 1311.28,
      "duration": 5.96
    },
    {
      "lang": "en",
      "text": "etc This can be specified in the monitor",
      "offset": 1314,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "parameter It is also important to define",
      "offset": 1317.24,
      "duration": 4.6
    },
    {
      "lang": "en",
      "text": "a patient argument that is the number of",
      "offset": 1319.76,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "epochs to wait for the motor to improve",
      "offset": 1321.84,
      "duration": 3.719
    },
    {
      "lang": "en",
      "text": "before stopping it",
      "offset": 1324.08,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "training There's no rules to decide",
      "offset": 1325.559,
      "duration": 4.201
    },
    {
      "lang": "en",
      "text": "which patient number works best at all",
      "offset": 1327.76,
      "duration": 4.039
    },
    {
      "lang": "en",
      "text": "times This depends on the",
      "offset": 1329.76,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "implementation It is good to avoid low",
      "offset": 1331.799,
      "duration": 4.041
    },
    {
      "lang": "en",
      "text": "values That way your model has a chance",
      "offset": 1334.08,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "to improve a later epoch The call bus is",
      "offset": 1335.84,
      "duration": 4.719
    },
    {
      "lang": "en",
      "text": "passed as a list to the callbacks",
      "offset": 1339.12,
      "duration": 4.559
    },
    {
      "lang": "en",
      "text": "parameter in the model fit method The",
      "offset": 1340.559,
      "duration": 4.881
    },
    {
      "lang": "en",
      "text": "model checkpoint callback can also be",
      "offset": 1343.679,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "imported from KAS callbacks This",
      "offset": 1345.44,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "callback allow us to save our model as",
      "offset": 1348,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "it trains We specify the model file name",
      "offset": 1350.4,
      "duration": 6.56
    },
    {
      "lang": "en",
      "text": "with a name and the point HDF5 extension",
      "offset": 1353.36,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "You can also decide what to monitor to",
      "offset": 1356.96,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "determine which model is best with the",
      "offset": 1358.88,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "monitor parameter By default validation",
      "offset": 1360.64,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "loss is monitored",
      "offset": 1363.28,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "Setting the safe best only parameter to",
      "offset": 1365.52,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "true guarantees that the latest best",
      "offset": 1367.679,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "model according to the quantity monitor",
      "offset": 1369.919,
      "duration": 3.721
    },
    {
      "lang": "en",
      "text": "will not be",
      "offset": 1371.84,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "overridden Learning curves provide a lot",
      "offset": 1373.64,
      "duration": 5.08
    },
    {
      "lang": "en",
      "text": "of information about your model Now that",
      "offset": 1376.159,
      "duration": 4.241
    },
    {
      "lang": "en",
      "text": "you know how to use the history callback",
      "offset": 1378.72,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "to plot them you will learn how to read",
      "offset": 1380.4,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "them to get the most value out of them",
      "offset": 1382.24,
      "duration": 4.799
    },
    {
      "lang": "en",
      "text": "So far we've seen two types of learning",
      "offset": 1384.96,
      "duration": 5.199
    },
    {
      "lang": "en",
      "text": "curves Loss curves and accuracy curves",
      "offset": 1387.039,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "Loss tends to decrease as epochs go by",
      "offset": 1390.159,
      "duration": 4.961
    },
    {
      "lang": "en",
      "text": "This is expected since our model is",
      "offset": 1393.039,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "essentially learning to minimize the",
      "offset": 1395.12,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "loss function Ebooks are shown on the",
      "offset": 1396.64,
      "duration": 6.48
    },
    {
      "lang": "en",
      "text": "x-axis and loss on the y-axis As epochs",
      "offset": 1399.6,
      "duration": 6.8
    },
    {
      "lang": "en",
      "text": "go by our loss value decreases After a",
      "offset": 1403.12,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "certain amount of epochs the value",
      "offset": 1406.4,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "converge meaning it no longer gets much",
      "offset": 1408,
      "duration": 4.44
    },
    {
      "lang": "en",
      "text": "lower than that We have arrived at a",
      "offset": 1410.4,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "minimum Accuracy curves are similar but",
      "offset": 1412.44,
      "duration": 5.239
    },
    {
      "lang": "en",
      "text": "opposite in tendency If the y-axis shows",
      "offset": 1415.2,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "accuracy it now tends to increase as",
      "offset": 1417.679,
      "duration": 4.721
    },
    {
      "lang": "en",
      "text": "epochs go by This shows that our model",
      "offset": 1419.52,
      "duration": 4.92
    },
    {
      "lang": "en",
      "text": "makes fewer mistakes as it",
      "offset": 1422.4,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "learns If we plot training versus",
      "offset": 1424.44,
      "duration": 4.719
    },
    {
      "lang": "en",
      "text": "validation data we can identify",
      "offset": 1426.88,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "overfitting We will see that the",
      "offset": 1429.159,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "training and validation curves start to",
      "offset": 1430.96,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "diverge Overfitting is when our model",
      "offset": 1432.919,
      "duration": 4.521
    },
    {
      "lang": "en",
      "text": "starts learning particularities of our",
      "offset": 1435.52,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "training data which don't generalize",
      "offset": 1437.44,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "well on unseen data The early stopping",
      "offset": 1439.44,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "callback is useful to stop our model",
      "offset": 1442.32,
      "duration": 3.32
    },
    {
      "lang": "en",
      "text": "before it starts",
      "offset": 1444.32,
      "duration": 3.359
    },
    {
      "lang": "en",
      "text": "overfitting But not all curves are",
      "offset": 1445.64,
      "duration": 4.279
    },
    {
      "lang": "en",
      "text": "smooth and pretty Many times we will",
      "offset": 1447.679,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "find unstable curves There are many",
      "offset": 1449.919,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "reasons that can lead to unstable",
      "offset": 1452.08,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "learning curves The chosen optimizer",
      "offset": 1453.679,
      "duration": 4.561
    },
    {
      "lang": "en",
      "text": "learning rate batch size network",
      "offset": 1456.08,
      "duration": 5.599
    },
    {
      "lang": "en",
      "text": "architecture weight initialization etc",
      "offset": 1458.24,
      "duration": 5.439
    },
    {
      "lang": "en",
      "text": "All of these parameters can be tuned to",
      "offset": 1461.679,
      "duration": 4.561
    },
    {
      "lang": "en",
      "text": "improve our model learning curves as we",
      "offset": 1463.679,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "aim for better accuracy and",
      "offset": 1466.24,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "generalization power We will cover this",
      "offset": 1467.6,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "in the following videos",
      "offset": 1470.08,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "Neural networks are well known for",
      "offset": 1472.24,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "surpassing traditional machine learning",
      "offset": 1474.08,
      "duration": 3.599
    },
    {
      "lang": "en",
      "text": "techniques As we increase the size of",
      "offset": 1475.84,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "our data sets we can check whether",
      "offset": 1477.679,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "collecting more data will increase a",
      "offset": 1479.84,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "model's generalization and accuracy We",
      "offset": 1481.52,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "aim at producing a graph like this one",
      "offset": 1484.4,
      "duration": 3.519
    },
    {
      "lang": "en",
      "text": "where we have fitted our model with",
      "offset": 1486.4,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "increasing amounts of training data and",
      "offset": 1487.919,
      "duration": 3.521
    },
    {
      "lang": "en",
      "text": "plotted the values for the training and",
      "offset": 1489.84,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "text accuracies of each run If after",
      "offset": 1491.44,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "using all our data we see that our test",
      "offset": 1494.32,
      "duration": 5.359
    },
    {
      "lang": "en",
      "text": "still has a tendency to improve that is",
      "offset": 1497.12,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "it is not parallel to our training set",
      "offset": 1499.679,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "curve and it is increasing then it is",
      "offset": 1501.52,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "worth it to add more data if possible to",
      "offset": 1504.559,
      "duration": 3.72
    },
    {
      "lang": "en",
      "text": "allow the model to keep",
      "offset": 1506.72,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "learning How will we go about coding a",
      "offset": 1508.279,
      "duration": 4.841
    },
    {
      "lang": "en",
      "text": "graph like the previous one imagine we",
      "offset": 1510.72,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "want to evaluate an already built and",
      "offset": 1513.12,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "compiled model and that we have",
      "offset": 1514.96,
      "duration": 3.599
    },
    {
      "lang": "en",
      "text": "partitioned our data into X train Y",
      "offset": 1516.4,
      "duration": 5.279
    },
    {
      "lang": "en",
      "text": "train X test and Y test We first store",
      "offset": 1518.559,
      "duration": 5.201
    },
    {
      "lang": "en",
      "text": "the model initial weights This is done",
      "offset": 1521.679,
      "duration": 4.561
    },
    {
      "lang": "en",
      "text": "by calling get weights on our model We",
      "offset": 1523.76,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "then initialize two list to store train",
      "offset": 1526.24,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "and test accuracies We loop over a",
      "offset": 1528.4,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "predefined list of train sizes And for",
      "offset": 1531.12,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "each training size we get the",
      "offset": 1533.52,
      "duration": 3.399
    },
    {
      "lang": "en",
      "text": "corresponding training data",
      "offset": 1535.2,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "fraction Before any training we make",
      "offset": 1536.919,
      "duration": 4.12
    },
    {
      "lang": "en",
      "text": "sure our model starts with the same set",
      "offset": 1539.279,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "of weights by setting them to the",
      "offset": 1541.039,
      "duration": 3.801
    },
    {
      "lang": "en",
      "text": "initial weights using the set weights",
      "offset": 1542.559,
      "duration": 5.041
    },
    {
      "lang": "en",
      "text": "function After that we can fit our model",
      "offset": 1544.84,
      "duration": 5.48
    },
    {
      "lang": "en",
      "text": "on the training fraction We use an early",
      "offset": 1547.6,
      "duration": 5.199
    },
    {
      "lang": "en",
      "text": "stopping callback which monitor loss But",
      "offset": 1550.32,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "it is important to note that it's not",
      "offset": 1552.799,
      "duration": 3.281
    },
    {
      "lang": "en",
      "text": "validation loss since we haven't",
      "offset": 1554.4,
      "duration": 3.879
    },
    {
      "lang": "en",
      "text": "provided the fit method with validation",
      "offset": 1556.08,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "data After the training is done we can",
      "offset": 1558.279,
      "duration": 4.601
    },
    {
      "lang": "en",
      "text": "get the accuracy for the training set",
      "offset": 1561.2,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "fraction and the accuracy from the test",
      "offset": 1562.88,
      "duration": 4.279
    },
    {
      "lang": "en",
      "text": "set and append it to our list of",
      "offset": 1564.72,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "accuracies Observe that the same",
      "offset": 1567.159,
      "duration": 4.441
    },
    {
      "lang": "en",
      "text": "quantity of test data observations were",
      "offset": 1569.44,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "used to evaluate each iteration",
      "offset": 1571.6,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "So far we have been using several",
      "offset": 1575.44,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "activation functions in our models but",
      "offset": 1577.12,
      "duration": 3.679
    },
    {
      "lang": "en",
      "text": "we haven't yet covered their role in",
      "offset": 1579.2,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "neural networks other than when it comes",
      "offset": 1580.799,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "to obtaining the output we want in our",
      "offset": 1582.64,
      "duration": 4.639
    },
    {
      "lang": "en",
      "text": "output layer Inside the neurons of any",
      "offset": 1584.4,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "neural network the same process takes",
      "offset": 1587.279,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "place Assumation of the inputs reaching",
      "offset": 1589.2,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "the neuron multiplied by the witch",
      "offset": 1591.36,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "connection and the addition of the bias",
      "offset": 1593.36,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "weight This operation results in a",
      "offset": 1594.96,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "number a which can be anything It is not",
      "offset": 1597.2,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "bounded We pass this number into an",
      "offset": 1600.08,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "activation function that essentially",
      "offset": 1602.48,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "takes it as an input and decides how the",
      "offset": 1604.4,
      "duration": 3.8
    },
    {
      "lang": "en",
      "text": "neuron fires and which output it",
      "offset": 1606.4,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "produces Activation functions impact",
      "offset": 1608.2,
      "duration": 4.52
    },
    {
      "lang": "en",
      "text": "learning time making our model converge",
      "offset": 1610.72,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "faster or slower and achieving lower or",
      "offset": 1612.72,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "higher accuracy They also allow us to",
      "offset": 1615.039,
      "duration": 5.281
    },
    {
      "lang": "en",
      "text": "learn more complex functions Four very",
      "offset": 1617.52,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "well-known activation functions are the",
      "offset": 1620.32,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "sigmoid which varies between zero and",
      "offset": 1622.72,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "one for all possible x input values The",
      "offset": 1624.72,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "10H or hyperbolic tangent which is",
      "offset": 1628,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "similar to the sigmoid in shape but",
      "offset": 1630.32,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "varies between minus1 and one The relu",
      "offset": 1632.08,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "rectified linear unit which varies",
      "offset": 1634.88,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "between zero and infinity And the leaky",
      "offset": 1636.88,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "relu which we can look as a smoothed",
      "offset": 1639.76,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "version of that doesn't sit at zero",
      "offset": 1641.76,
      "duration": 4.84
    },
    {
      "lang": "en",
      "text": "allowing negative values for negative",
      "offset": 1643.919,
      "duration": 5.041
    },
    {
      "lang": "en",
      "text": "inputs Changing the activation function",
      "offset": 1646.6,
      "duration": 4.12
    },
    {
      "lang": "en",
      "text": "used in the hidden layer of the model we",
      "offset": 1648.96,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "built for binary classification results",
      "offset": 1650.72,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "in different classification boundaries",
      "offset": 1652.88,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "We can see that the previous model",
      "offset": 1655.36,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "cannot completely separate red crosses",
      "offset": 1657.2,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "from blue circles if we use a signal",
      "offset": 1659.44,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "activation function in the hidden layer",
      "offset": 1661.6,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "Some blue circles are mclassified as red",
      "offset": 1664.4,
      "duration": 3.879
    },
    {
      "lang": "en",
      "text": "crosses along the",
      "offset": 1666.72,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "diagonal However when we use the t we",
      "offset": 1668.279,
      "duration": 5.081
    },
    {
      "lang": "en",
      "text": "completely separate red crosses from",
      "offset": 1671.52,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "blue circles The separation region for",
      "offset": 1673.36,
      "duration": 4.6
    },
    {
      "lang": "en",
      "text": "the blue and red classification is",
      "offset": 1675.44,
      "duration": 5.359
    },
    {
      "lang": "en",
      "text": "smooth Using a reu activation function",
      "offset": 1677.96,
      "duration": 5.24
    },
    {
      "lang": "en",
      "text": "we obtain sharper boundaries The leaky",
      "offset": 1680.799,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "really shows similar behavior for this",
      "offset": 1683.2,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "data set It is important to note that",
      "offset": 1684.96,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "these boundaries will be different for",
      "offset": 1688,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "every round of the same model because of",
      "offset": 1689.6,
      "duration": 3.679
    },
    {
      "lang": "en",
      "text": "the random initialization of weights and",
      "offset": 1691.36,
      "duration": 4.559
    },
    {
      "lang": "en",
      "text": "other random variables that aren't fix",
      "offset": 1693.279,
      "duration": 4.481
    },
    {
      "lang": "en",
      "text": "All activation functions come with their",
      "offset": 1695.919,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "pros and cons There's no easy way to",
      "offset": 1697.76,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "determine which activation function is",
      "offset": 1700.159,
      "duration": 4.801
    },
    {
      "lang": "en",
      "text": "best to use based on their properties",
      "offset": 1702.159,
      "duration": 4.961
    },
    {
      "lang": "en",
      "text": "the problem at hand and the layer we are",
      "offset": 1704.96,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "looking at in our network One activation",
      "offset": 1707.12,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "function will perform better in terms of",
      "offset": 1709.279,
      "duration": 4.801
    },
    {
      "lang": "en",
      "text": "achieving our goal A way to go is to",
      "offset": 1711.039,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "start with really as they train fast and",
      "offset": 1714.08,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "will tend to generalize well to most",
      "offset": 1716.159,
      "duration": 4.76
    },
    {
      "lang": "en",
      "text": "problems Avoid sigmoids and tune with",
      "offset": 1717.919,
      "duration": 5.041
    },
    {
      "lang": "en",
      "text": "experimentation It is easy to compare",
      "offset": 1720.919,
      "duration": 3.64
    },
    {
      "lang": "en",
      "text": "how models with different activation",
      "offset": 1722.96,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "functions perform if they are small",
      "offset": 1724.559,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "enough and train fast It is important to",
      "offset": 1726.24,
      "duration": 4.559
    },
    {
      "lang": "en",
      "text": "set a random seat with numpy That way",
      "offset": 1728.72,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "the model weights are initialized the",
      "offset": 1730.799,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "same for each activation function We",
      "offset": 1732.48,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "then define a function that returns a",
      "offset": 1734.96,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "fresh new model each time using the act",
      "offset": 1736.96,
      "duration": 4.959
    },
    {
      "lang": "en",
      "text": "function parameter We can then use this",
      "offset": 1739.279,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "function as we loop over several",
      "offset": 1741.919,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "activation functions training different",
      "offset": 1743.44,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "models and saving their history callback",
      "offset": 1745.52,
      "duration": 4.68
    },
    {
      "lang": "en",
      "text": "We store all of these callbacks in a",
      "offset": 1748.08,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "dictionary With this dictionary of",
      "offset": 1750.2,
      "duration": 4.04
    },
    {
      "lang": "en",
      "text": "histories we can extract the metrics we",
      "offset": 1752.399,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "want to plot build a pandas data frame",
      "offset": 1754.24,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "and plot it",
      "offset": 1756.48,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "It is time to learn the concepts of",
      "offset": 1758.72,
      "duration": 4.559
    },
    {
      "lang": "en",
      "text": "batch size and batch normalization A",
      "offset": 1760.399,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "mini batch is as a set of data samples",
      "offset": 1763.279,
      "duration": 4.241
    },
    {
      "lang": "en",
      "text": "If we were training a neural network",
      "offset": 1765.919,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "with images each image in our training",
      "offset": 1767.52,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "set will be a sample and we could take",
      "offset": 1769.679,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "many batches of different sizes from the",
      "offset": 1771.6,
      "duration": 3.4
    },
    {
      "lang": "en",
      "text": "training set",
      "offset": 1773.76,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "batch Remember that during an epoch we",
      "offset": 1775,
      "duration": 5.399
    },
    {
      "lang": "en",
      "text": "fit our network calculate the errors and",
      "offset": 1777.919,
      "duration": 4.961
    },
    {
      "lang": "en",
      "text": "update the network weights It is not",
      "offset": 1780.399,
      "duration": 4.241
    },
    {
      "lang": "en",
      "text": "very practical to update our network",
      "offset": 1782.88,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "weights only once per epoch after",
      "offset": 1784.64,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "looking at the error produced by all",
      "offset": 1787.36,
      "duration": 4.559
    },
    {
      "lang": "en",
      "text": "training samples In practice we take a",
      "offset": 1789.12,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "mini batch of training samples and that",
      "offset": 1791.919,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "way if our training set has nine images",
      "offset": 1794,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "and we choose a batch size of three we",
      "offset": 1796.24,
      "duration": 3.96
    },
    {
      "lang": "en",
      "text": "will perform three weight updates per",
      "offset": 1798.24,
      "duration": 6.24
    },
    {
      "lang": "en",
      "text": "ebook one per mini batch Networks tend",
      "offset": 1800.2,
      "duration": 6.44
    },
    {
      "lang": "en",
      "text": "to train faster with mini batches since",
      "offset": 1804.48,
      "duration": 3.799
    },
    {
      "lang": "en",
      "text": "weights are updated",
      "offset": 1806.64,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "often Sometimes data set are so huge",
      "offset": 1808.279,
      "duration": 4.841
    },
    {
      "lang": "en",
      "text": "that they will struggle to fit in RAM",
      "offset": 1811.2,
      "duration": 4.719
    },
    {
      "lang": "en",
      "text": "memory if we didn't use mini batches",
      "offset": 1813.12,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "Also the noise produced by a small batch",
      "offset": 1815.919,
      "duration": 5.601
    },
    {
      "lang": "en",
      "text": "size can help escape local minimum A",
      "offset": 1818.32,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "couple of disadvantages are the need for",
      "offset": 1821.52,
      "duration": 4.759
    },
    {
      "lang": "en",
      "text": "more iterations and finding a good batch",
      "offset": 1823.52,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "size Here you can see how different",
      "offset": 1826.279,
      "duration": 5
    },
    {
      "lang": "en",
      "text": "batch sizes converge towards a minimum",
      "offset": 1828.96,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "as training goes by Training with all",
      "offset": 1831.279,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "samples is shown in blue Mini batching",
      "offset": 1833.84,
      "duration": 4.959
    },
    {
      "lang": "en",
      "text": "is shown in green Stoastic gradient",
      "offset": 1836.559,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "descent in red uses a batch size of one",
      "offset": 1838.799,
      "duration": 5.681
    },
    {
      "lang": "en",
      "text": "We can see how the path towards the best",
      "offset": 1842.559,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "value for our ways is no easier the",
      "offset": 1844.48,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "smaller the batch size They reach the",
      "offset": 1846.799,
      "duration": 5.561
    },
    {
      "lang": "en",
      "text": "same value after a different number of",
      "offset": 1849.6,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "iterations You can set your own batch",
      "offset": 1852.36,
      "duration": 4.52
    },
    {
      "lang": "en",
      "text": "size with the batch size parameter on",
      "offset": 1854.72,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "the models fit method Kas uses a default",
      "offset": 1856.88,
      "duration": 6.64
    },
    {
      "lang": "en",
      "text": "batch size of 32 Increasing powers of",
      "offset": 1860.24,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "two tend to be used As a rule of thumb",
      "offset": 1863.52,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "you tend to make your batch size bigger",
      "offset": 1866,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "the bigger your data set Normalization",
      "offset": 1867.76,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "is a common prep-processing step in",
      "offset": 1871.12,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "machine learning algorithms especially",
      "offset": 1872.96,
      "duration": 4.959
    },
    {
      "lang": "en",
      "text": "when features have different scales One",
      "offset": 1875.12,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "way to normalize data is to subtract its",
      "offset": 1877.919,
      "duration": 4.601
    },
    {
      "lang": "en",
      "text": "mean value and divide by the standard",
      "offset": 1880.32,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "deviation We always tend to normalize",
      "offset": 1882.52,
      "duration": 4.92
    },
    {
      "lang": "en",
      "text": "our model inputs This avoids problems",
      "offset": 1884.88,
      "duration": 4.6
    },
    {
      "lang": "en",
      "text": "with activation functions and",
      "offset": 1887.44,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "gradients This leaves everything",
      "offset": 1889.48,
      "duration": 3.799
    },
    {
      "lang": "en",
      "text": "centered around zero with a standard",
      "offset": 1891.44,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "deviation of one",
      "offset": 1893.279,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "Normalizing neural networks inputs",
      "offset": 1895.44,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "improves our model but deeper layers are",
      "offset": 1897.279,
      "duration": 5.041
    },
    {
      "lang": "en",
      "text": "trained based on previous layer outputs",
      "offset": 1900.08,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "And since weights get updated via",
      "offset": 1902.32,
      "duration": 4.239
    },
    {
      "lang": "en",
      "text": "gradient descent consecutive layers no",
      "offset": 1904.08,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "longer benefit from normalization and",
      "offset": 1906.559,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "they need to adapt to previous layers",
      "offset": 1908.96,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "weight changes Finding more trouble to",
      "offset": 1910.72,
      "duration": 3.959
    },
    {
      "lang": "en",
      "text": "learn their own",
      "offset": 1913.44,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "weights Batch normalization makes that",
      "offset": 1914.679,
      "duration": 6.201
    },
    {
      "lang": "en",
      "text": "independently of the changes the inputs",
      "offset": 1918.48,
      "duration": 5.439
    },
    {
      "lang": "en",
      "text": "to the next layer are normalized It does",
      "offset": 1920.88,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "this in a smart way with trainable",
      "offset": 1923.919,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "parameters that also learn how much of",
      "offset": 1926,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "this normalization is kept scaling or",
      "offset": 1928.159,
      "duration": 6.24
    },
    {
      "lang": "en",
      "text": "shifting it This improves gradient flow",
      "offset": 1930.72,
      "duration": 6.64
    },
    {
      "lang": "en",
      "text": "allows for higher learning rates reduce",
      "offset": 1934.399,
      "duration": 4.681
    },
    {
      "lang": "en",
      "text": "weightiness in",
      "offset": 1937.36,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "dependence adds regularization to our",
      "offset": 1939.08,
      "duration": 5
    },
    {
      "lang": "en",
      "text": "networks and limits internal coariate",
      "offset": 1941.679,
      "duration": 4.641
    },
    {
      "lang": "en",
      "text": "shift which is a funny name for a",
      "offset": 1944.08,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "layer's dependence on the previous layer",
      "offset": 1946.32,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "outputs when learning it weights Batch",
      "offset": 1948.159,
      "duration": 5.201
    },
    {
      "lang": "en",
      "text": "normalization is widely used today in",
      "offset": 1951.12,
      "duration": 3.72
    },
    {
      "lang": "en",
      "text": "many deep learning",
      "offset": 1953.36,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "models Batch normalization in KAS is",
      "offset": 1954.84,
      "duration": 5.4
    },
    {
      "lang": "en",
      "text": "applied as a layer so we can place it in",
      "offset": 1957.76,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "between two layers We import batch",
      "offset": 1960.24,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "normalization from TensorFlow KAS layers",
      "offset": 1962.96,
      "duration": 6.16
    },
    {
      "lang": "en",
      "text": "We then instantiate a sequential model",
      "offset": 1966.24,
      "duration": 5.919
    },
    {
      "lang": "en",
      "text": "add an input layer and then add a batch",
      "offset": 1969.12,
      "duration": 5.919
    },
    {
      "lang": "en",
      "text": "normalization layer We finalize this",
      "offset": 1972.159,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "binary classification model with an",
      "offset": 1975.039,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "output layer",
      "offset": 1977.039,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "You now know everything you need to",
      "offset": 1979.279,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "perform deeper parameter tuning in",
      "offset": 1981.039,
      "duration": 5.041
    },
    {
      "lang": "en",
      "text": "neural networks Our aim is to identify",
      "offset": 1982.88,
      "duration": 5.039
    },
    {
      "lang": "en",
      "text": "those parameters that make our model",
      "offset": 1986.08,
      "duration": 4.719
    },
    {
      "lang": "en",
      "text": "generalized better A neural network is",
      "offset": 1987.919,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "full of parameters that can be tweaked",
      "offset": 1990.799,
      "duration": 4.961
    },
    {
      "lang": "en",
      "text": "The number of layers neurons per layer",
      "offset": 1993.279,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "the order of search layers the",
      "offset": 1995.76,
      "duration": 3.759
    },
    {
      "lang": "en",
      "text": "activation functions patch sizes",
      "offset": 1997.44,
      "duration": 4.239
    },
    {
      "lang": "en",
      "text": "learning rate optimizers a lot of things",
      "offset": 1999.519,
      "duration": 4.961
    },
    {
      "lang": "en",
      "text": "to keep in mind In scikitlearn we can",
      "offset": 2001.679,
      "duration": 4.961
    },
    {
      "lang": "en",
      "text": "perform a perparameter search by using",
      "offset": 2004.48,
      "duration": 5.439
    },
    {
      "lang": "en",
      "text": "methods like randomize search CV We",
      "offset": 2006.64,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "import randomize search CV from",
      "offset": 2009.919,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "scikitlearn model selection We",
      "offset": 2011.76,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "instantiate a model define a dictionary",
      "offset": 2014,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "with a series of model parameters to try",
      "offset": 2016.72,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "and finally instantiate and randomize",
      "offset": 2018.96,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "search CV object passing our model The",
      "offset": 2021.039,
      "duration": 4.561
    },
    {
      "lang": "en",
      "text": "parameters and a number of cross",
      "offset": 2023.84,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "validation faults We fit it on our data",
      "offset": 2025.6,
      "duration": 4.959
    },
    {
      "lang": "en",
      "text": "and print the best resulting combination",
      "offset": 2028.72,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "of parameters For this example a mean",
      "offset": 2030.559,
      "duration": 5.84
    },
    {
      "lang": "en",
      "text": "sample lift of one free max features and",
      "offset": 2033.76,
      "duration": 5.48
    },
    {
      "lang": "en",
      "text": "a max dep of three gave us the best",
      "offset": 2036.399,
      "duration": 4.961
    },
    {
      "lang": "en",
      "text": "results We can do the same with our",
      "offset": 2039.24,
      "duration": 4.52
    },
    {
      "lang": "en",
      "text": "keras models but we first have to",
      "offset": 2041.36,
      "duration": 4.52
    },
    {
      "lang": "en",
      "text": "transform them into scikitlearn",
      "offset": 2043.76,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "estimators We do this by first defining",
      "offset": 2045.88,
      "duration": 5.799
    },
    {
      "lang": "en",
      "text": "a function that creates our model Then",
      "offset": 2048.56,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "we import the kas classifier wrapper",
      "offset": 2051.679,
      "duration": 5.521
    },
    {
      "lang": "en",
      "text": "from tensorflow kerasikitlearn wrappers",
      "offset": 2053.76,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "We finish by simply instantiating a",
      "offset": 2057.2,
      "duration": 4.639
    },
    {
      "lang": "en",
      "text": "curas classifier object passing create",
      "offset": 2059.44,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "model as the building function Other",
      "offset": 2061.839,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "parameters like epochs and batch size",
      "offset": 2064.48,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "are optional but should be passed if we",
      "offset": 2066.639,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "want to specify them This is very cool",
      "offset": 2068.56,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "Our model is not just like any other",
      "offset": 2071.919,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "cycling learning estimator So we can for",
      "offset": 2073.76,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "instance perform cross validation on it",
      "offset": 2076.079,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "to see the stability of it predictions",
      "offset": 2078.159,
      "duration": 4.801
    },
    {
      "lang": "en",
      "text": "across faults import cross path score",
      "offset": 2079.919,
      "duration": 5.361
    },
    {
      "lang": "en",
      "text": "core passing in our recently converted",
      "offset": 2082.96,
      "duration": 5.119
    },
    {
      "lang": "en",
      "text": "kas model predictors labels and the",
      "offset": 2085.28,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "number of faults We can then check the",
      "offset": 2088.079,
      "duration": 5.721
    },
    {
      "lang": "en",
      "text": "mean accuracy per full or the standard",
      "offset": 2090.72,
      "duration": 5.679
    },
    {
      "lang": "en",
      "text": "deviation Note that six epochs and a",
      "offset": 2093.8,
      "duration": 5
    },
    {
      "lang": "en",
      "text": "batch size of 16 were used since we",
      "offset": 2096.399,
      "duration": 3.881
    },
    {
      "lang": "en",
      "text": "specified it",
      "offset": 2098.8,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "before It is much more probable that a",
      "offset": 2100.28,
      "duration": 4.68
    },
    {
      "lang": "en",
      "text": "good combination of parameters will be",
      "offset": 2102.88,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "found by using random search instead of",
      "offset": 2104.96,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "an exhaustive grid search Grid search",
      "offset": 2107.2,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "loops over all possible combination of",
      "offset": 2110.48,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "parameters while random search trace a",
      "offset": 2112.48,
      "duration": 4.119
    },
    {
      "lang": "en",
      "text": "given number of random",
      "offset": 2114.96,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "combinations Normally not many epochs",
      "offset": 2116.599,
      "duration": 4.441
    },
    {
      "lang": "en",
      "text": "are needed to check how well your model",
      "offset": 2119.28,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "is performing Using a smaller",
      "offset": 2121.04,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "representative sample of your data set",
      "offset": 2123.52,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "makes faster if you got a huge data set",
      "offset": 2125.68,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "It is easier to play with things like",
      "offset": 2128.72,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "optimizer batch sizes activations and",
      "offset": 2130.4,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "learning rates To perform randomized",
      "offset": 2132.88,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "search on a kas model we just need to",
      "offset": 2135.68,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "define the parameters to try We can try",
      "offset": 2137.68,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "different optimizers activation",
      "offset": 2140.48,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "functions for the hidden layers and",
      "offset": 2142.4,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "batch sizes The keys in the parameter",
      "offset": 2144.16,
      "duration": 4.959
    },
    {
      "lang": "en",
      "text": "dictionary must be named exactly as the",
      "offset": 2146.88,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "parameters in our create model function",
      "offset": 2149.119,
      "duration": 5.121
    },
    {
      "lang": "en",
      "text": "We then instantiate a randomized search",
      "offset": 2152,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "CV object passing our model and",
      "offset": 2154.24,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "parameters with freeall cross validation",
      "offset": 2156.32,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "We end up fitting our random search",
      "offset": 2159.28,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "object to obtain the results We can",
      "offset": 2161.2,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "print the best score and the parameters",
      "offset": 2163.92,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "that were used We get an accuracy of 94%",
      "offset": 2165.599,
      "duration": 6.161
    },
    {
      "lang": "en",
      "text": "with the add optimizer free epoch a",
      "offset": 2169.04,
      "duration": 5.319
    },
    {
      "lang": "en",
      "text": "batch size of 10 and redu",
      "offset": 2171.76,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "activation Parameters like the number of",
      "offset": 2174.359,
      "duration": 4.601
    },
    {
      "lang": "en",
      "text": "neons per layer and the number of layers",
      "offset": 2176.64,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "can also be tuned using the same method",
      "offset": 2178.96,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "We just need to make some smart changes",
      "offset": 2181.28,
      "duration": 3.24
    },
    {
      "lang": "en",
      "text": "in our create model",
      "offset": 2182.96,
      "duration": 4.639
    },
    {
      "lang": "en",
      "text": "function The nl parameter determines the",
      "offset": 2184.52,
      "duration": 5.319
    },
    {
      "lang": "en",
      "text": "number of hidden layers and nn the",
      "offset": 2187.599,
      "duration": 4.801
    },
    {
      "lang": "en",
      "text": "number of neurons in these layers We can",
      "offset": 2189.839,
      "duration": 4.641
    },
    {
      "lang": "en",
      "text": "have a loop inside our function and add",
      "offset": 2192.4,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "to our sequential model as many layers",
      "offset": 2194.48,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "as provided in NL with the given number",
      "offset": 2196.88,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "of neurons Then we just need to use the",
      "offset": 2199.2,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "exact same names in the parameter",
      "offset": 2202.32,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "dictionary as we have in our function",
      "offset": 2203.92,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "and repeat the process The best result",
      "offset": 2206,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "is 87% accuracy with two hidden layers",
      "offset": 2208.72,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "of 128 neurons each",
      "offset": 2211.52,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "Now that you know how to tune your",
      "offset": 2214.72,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "models it is time to better understand",
      "offset": 2216.32,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "how they work internally and to explore",
      "offset": 2218.16,
      "duration": 3.16
    },
    {
      "lang": "en",
      "text": "newer network",
      "offset": 2220,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "architectures Model layers are easily",
      "offset": 2221.32,
      "duration": 4.36
    },
    {
      "lang": "en",
      "text": "accessible We just need to go layers on",
      "offset": 2223.68,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "a built model and access the index of",
      "offset": 2225.68,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "the layer we want From a chosen layer we",
      "offset": 2227.599,
      "duration": 6.081
    },
    {
      "lang": "en",
      "text": "can print its inputs outputs and weights",
      "offset": 2230.48,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "You can see inputs and outputs are",
      "offset": 2233.68,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "tensors of a given shape built with",
      "offset": 2235.2,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "TensorFlow tensor objects Weights are",
      "offset": 2236.88,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "TensorFlow variable objects which are",
      "offset": 2240,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "just tensors that change their value as",
      "offset": 2242.16,
      "duration": 3.56
    },
    {
      "lang": "en",
      "text": "the neural network learn the best",
      "offset": 2243.76,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "weights Tensors are the main data",
      "offset": 2245.72,
      "duration": 5.639
    },
    {
      "lang": "en",
      "text": "structures used in deep learning Inputs",
      "offset": 2248.16,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "outputs and transformations in neural",
      "offset": 2251.359,
      "duration": 3.521
    },
    {
      "lang": "en",
      "text": "networks are all represented using",
      "offset": 2253.2,
      "duration": 3.24
    },
    {
      "lang": "en",
      "text": "tensors and tensor",
      "offset": 2254.88,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "multiplication A tensor is a",
      "offset": 2256.44,
      "duration": 4.6
    },
    {
      "lang": "en",
      "text": "multi-dimensional array of numbers A",
      "offset": 2258.56,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "two-dimensional tensor is a matrix A",
      "offset": 2261.04,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "three-dimensional tensor is an array of",
      "offset": 2263.44,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "matrices If we import the kas back end",
      "offset": 2265.2,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "we can build a function that takes in an",
      "offset": 2268.24,
      "duration": 3.599
    },
    {
      "lang": "en",
      "text": "input tensor from a given layer and",
      "offset": 2270,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "returns an output tensor from another or",
      "offset": 2271.839,
      "duration": 4.481
    },
    {
      "lang": "en",
      "text": "the same layer TensorFlow is the back",
      "offset": 2273.76,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "end kas is using in this course but it",
      "offset": 2276.32,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "could be any other like fiano To define",
      "offset": 2278.32,
      "duration": 4.799
    },
    {
      "lang": "en",
      "text": "the functions with our back end K we",
      "offset": 2281.28,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "need to give it a list of inputs and",
      "offset": 2283.119,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "outputs Even if we just want one input",
      "offset": 2284.64,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "and one output then we can use it on a",
      "offset": 2286.8,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "tensor with the same shape as the input",
      "offset": 2289.52,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "layer given during this definition If",
      "offset": 2291.28,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "the weights of the layer between our",
      "offset": 2293.839,
      "duration": 3.361
    },
    {
      "lang": "en",
      "text": "input and output change the function",
      "offset": 2295.2,
      "duration": 4.28
    },
    {
      "lang": "en",
      "text": "output for the same input will change as",
      "offset": 2297.2,
      "duration": 4.639
    },
    {
      "lang": "en",
      "text": "well We can use this to see how the",
      "offset": 2299.48,
      "duration": 4.359
    },
    {
      "lang": "en",
      "text": "output of certain layers change as",
      "offset": 2301.839,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "weights are adjusted during training We",
      "offset": 2303.839,
      "duration": 3.721
    },
    {
      "lang": "en",
      "text": "will check this in the",
      "offset": 2306,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "exercises It is time to introduce a new",
      "offset": 2307.56,
      "duration": 5.64
    },
    {
      "lang": "en",
      "text": "architecture outers Autoenoders are",
      "offset": 2309.92,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "models that end up at producing the same",
      "offset": 2313.2,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "inputs as outputs This test alone",
      "offset": 2314.88,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "wouldn't be very useful but since along",
      "offset": 2317.68,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "the way we decrease the number of",
      "offset": 2319.52,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "neurons we are effectively making our",
      "offset": 2320.88,
      "duration": 4.239
    },
    {
      "lang": "en",
      "text": "network learn to compress it inputs into",
      "offset": 2322.96,
      "duration": 5.119
    },
    {
      "lang": "en",
      "text": "a smaller set of neurons This makes out",
      "offset": 2325.119,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "coders useful for things like",
      "offset": 2328.079,
      "duration": 3.201
    },
    {
      "lang": "en",
      "text": "dimensionality reduction since we can",
      "offset": 2329.44,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "obtain a smaller dimensional space",
      "offset": 2331.28,
      "duration": 3.16
    },
    {
      "lang": "en",
      "text": "representation of our",
      "offset": 2332.96,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "inputs D noising if trained with clear",
      "offset": 2334.44,
      "duration": 4.679
    },
    {
      "lang": "en",
      "text": "data and then fed with noisy data they",
      "offset": 2337.119,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "will be able to decode back a good",
      "offset": 2339.119,
      "duration": 3.641
    },
    {
      "lang": "en",
      "text": "representation of the input data without",
      "offset": 2340.72,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "noise Anomaly detection If you train an",
      "offset": 2342.76,
      "duration": 4.52
    },
    {
      "lang": "en",
      "text": "autoenccoder to map inputs to output",
      "offset": 2345.44,
      "duration": 3.679
    },
    {
      "lang": "en",
      "text": "with data but you then pass in strange",
      "offset": 2347.28,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "values the network will fail at giving",
      "offset": 2349.119,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "accurate output values And we can",
      "offset": 2351.04,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "measure this as a loss Many other",
      "offset": 2352.8,
      "duration": 5.559
    },
    {
      "lang": "en",
      "text": "applications can also benefit from this",
      "offset": 2355.52,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "architecture To make an autoenccoder",
      "offset": 2358.359,
      "duration": 4.681
    },
    {
      "lang": "en",
      "text": "that maps 100 inputs to 100 outputs",
      "offset": 2360.48,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "encoding the inputs into a layer of four",
      "offset": 2363.04,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "neurons we will do the following",
      "offset": 2364.88,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "Instantiate a sequential model Add a",
      "offset": 2367.359,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "dense layer of four neurons with an",
      "offset": 2369.76,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "input shape of 100 and n with an output",
      "offset": 2371.52,
      "duration": 3.8
    },
    {
      "lang": "en",
      "text": "layer of 100",
      "offset": 2374.16,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "neurons We use activation sigmoid",
      "offset": 2375.32,
      "duration": 4.12
    },
    {
      "lang": "en",
      "text": "because we assume that our output can",
      "offset": 2377.92,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "take a value between zero and one We end",
      "offset": 2379.44,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "compiling our model with an optimizer",
      "offset": 2382.48,
      "duration": 4.599
    },
    {
      "lang": "en",
      "text": "and binary coy loss Since we use",
      "offset": 2384.32,
      "duration": 4.799
    },
    {
      "lang": "en",
      "text": "sigmoid once you've built and trained",
      "offset": 2387.079,
      "duration": 3.881
    },
    {
      "lang": "en",
      "text": "your outenoder you might want to encode",
      "offset": 2389.119,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "your inputs To do this you just have to",
      "offset": 2390.96,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "build a new model which uses the first",
      "offset": 2393.04,
      "duration": 3.48
    },
    {
      "lang": "en",
      "text": "layer of the previously trained",
      "offset": 2395.04,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "autoenccoder This new model predictions",
      "offset": 2396.52,
      "duration": 4.36
    },
    {
      "lang": "en",
      "text": "returns the four numbers given by the",
      "offset": 2399.119,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "four neurons of the hidden layer It is",
      "offset": 2400.88,
      "duration": 4.239
    },
    {
      "lang": "en",
      "text": "effectively returning a far number",
      "offset": 2403.44,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "encoding of feature servation in the",
      "offset": 2405.119,
      "duration": 3.72
    },
    {
      "lang": "en",
      "text": "input data",
      "offset": 2406.96,
      "duration": 4.639
    },
    {
      "lang": "en",
      "text": "set Let's introduce convolutional neural",
      "offset": 2408.839,
      "duration": 4.601
    },
    {
      "lang": "en",
      "text": "networks a different type of network",
      "offset": 2411.599,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "that has led to a lot of advances in",
      "offset": 2413.44,
      "duration": 3.88
    },
    {
      "lang": "en",
      "text": "computer vision as well as in many other",
      "offset": 2415.2,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "areas A convolutional model uses",
      "offset": 2417.32,
      "duration": 5.16
    },
    {
      "lang": "en",
      "text": "convolutional layers A convolution is a",
      "offset": 2419.76,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "simple mathematical operation that",
      "offset": 2422.48,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "preserves spatial relationships When",
      "offset": 2424.16,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "applied to images it can detect relevant",
      "offset": 2426.56,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "areas of interest like edges corners",
      "offset": 2428.64,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "vertical lines etc It consists of",
      "offset": 2430.96,
      "duration": 5.119
    },
    {
      "lang": "en",
      "text": "applying a filter also known as a kernel",
      "offset": 2433.92,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "of a given size In this image we are",
      "offset": 2436.079,
      "duration": 5.681
    },
    {
      "lang": "en",
      "text": "applying a 3x3 kernel We center the",
      "offset": 2438.72,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "kernel matrix of numbers as we slide",
      "offset": 2441.76,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "through each pixel in the image",
      "offset": 2443.68,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "multiplying the kernel and pixel values",
      "offset": 2445.28,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "at each location and abering the sum of",
      "offset": 2447.28,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "values obtained This effectively",
      "offset": 2449.599,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "computes a new image where certain",
      "offset": 2452,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "characteristics are amplified depending",
      "offset": 2453.76,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "on the filter use The secret source of",
      "offset": 2455.68,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "CNN's resides in letting the network",
      "offset": 2458.24,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "itself find the best filter values and",
      "offset": 2460.079,
      "duration": 4.561
    },
    {
      "lang": "en",
      "text": "to combine them to achieve a given task",
      "offset": 2462,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "For a classification problem with many",
      "offset": 2464.64,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "possible classes CNN's tend to become",
      "offset": 2466.4,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "very deep Architectures consist of",
      "offset": 2468.64,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "concatenations of convolutional layers",
      "offset": 2470.96,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "among other layers known as pooling",
      "offset": 2472.96,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "layers that we won't cover here",
      "offset": 2474.8,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "Convolutional layers perform feature",
      "offset": 2477.119,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "learning We then flatten the outputs",
      "offset": 2478.96,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "into a undimensional vector and pass it",
      "offset": 2481.119,
      "duration": 5.24
    },
    {
      "lang": "en",
      "text": "to fully connected layers that carry out",
      "offset": 2483.359,
      "duration": 5.521
    },
    {
      "lang": "en",
      "text": "classification Images are 3D tensors",
      "offset": 2486.359,
      "duration": 5.24
    },
    {
      "lang": "en",
      "text": "They have width height and depth This",
      "offset": 2488.88,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "depth is given by the color channels If",
      "offset": 2491.599,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "we use black and white images we will",
      "offset": 2493.92,
      "duration": 3.439
    },
    {
      "lang": "en",
      "text": "just have one channel So the depth will",
      "offset": 2495.599,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "be one To build a CNN in KAS we first",
      "offset": 2497.359,
      "duration": 5.041
    },
    {
      "lang": "en",
      "text": "import the convolutional 2D and flatten",
      "offset": 2500.319,
      "duration": 4.881
    },
    {
      "lang": "en",
      "text": "layers from TensorFlow caras layers We",
      "offset": 2502.4,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "instantiate our model and add a",
      "offset": 2505.2,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "convolutional layer This first",
      "offset": 2506.64,
      "duration": 4.959
    },
    {
      "lang": "en",
      "text": "convolutional layer has 32 filters This",
      "offset": 2508.8,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "means it will learn 32 different",
      "offset": 2511.599,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "convolutional masks This mask will be",
      "offset": 2513.28,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "squares of 3x3 as defined in the kernel",
      "offset": 2516.319,
      "duration": 6.641
    },
    {
      "lang": "en",
      "text": "size For 28 * 28 black and white images",
      "offset": 2518.96,
      "duration": 5.92
    },
    {
      "lang": "en",
      "text": "with only one channel we use an input",
      "offset": 2522.96,
      "duration": 4.639
    },
    {
      "lang": "en",
      "text": "shape of 28 281 We can use any",
      "offset": 2524.88,
      "duration": 5.92
    },
    {
      "lang": "en",
      "text": "activation as usual We then add another",
      "offset": 2527.599,
      "duration": 5.041
    },
    {
      "lang": "en",
      "text": "convolutional layer and then flattening",
      "offset": 2530.8,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "this 2D layer into a un dimensional",
      "offset": 2532.64,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "layer with a flatten layer We finish",
      "offset": 2534.8,
      "duration": 4.279
    },
    {
      "lang": "en",
      "text": "with an output dense",
      "offset": 2537.44,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "layer ResNet 50 is a 50 layer deep model",
      "offset": 2539.079,
      "duration": 5.561
    },
    {
      "lang": "en",
      "text": "that performs well on the imageet data",
      "offset": 2542.56,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "set A huge data set of more than 14",
      "offset": 2544.64,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "million images Resident 50 can",
      "offset": 2547.28,
      "duration": 4.44
    },
    {
      "lang": "en",
      "text": "distinguish between a thousand different",
      "offset": 2549.92,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "classes This model would take too long",
      "offset": 2551.72,
      "duration": 4.599
    },
    {
      "lang": "en",
      "text": "to train on a regular computer but KAS",
      "offset": 2553.92,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "makes it easy for us to use it We just",
      "offset": 2556.319,
      "duration": 3.441
    },
    {
      "lang": "en",
      "text": "need to prepare the image we want to",
      "offset": 2558.48,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "classify for the model predict the",
      "offset": 2559.76,
      "duration": 4.04
    },
    {
      "lang": "en",
      "text": "processed image and decode the",
      "offset": 2561.76,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "predictions To use pre-trained models to",
      "offset": 2563.8,
      "duration": 4.36
    },
    {
      "lang": "en",
      "text": "classify images we first have to adapt",
      "offset": 2566.16,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "these images so that they can be",
      "offset": 2568.16,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "understood by the model To prepare",
      "offset": 2569.44,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "images for ResNet 50 we will do the",
      "offset": 2572,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "following First import image from",
      "offset": 2574,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "TensorFlow caras prep-processing and",
      "offset": 2576.16,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "reprocess input from TensorFlow caras",
      "offset": 2578,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "application RestNet 50 We then load our",
      "offset": 2579.92,
      "duration": 5.199
    },
    {
      "lang": "en",
      "text": "image with load image providing the",
      "offset": 2583.2,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "target size For this particular model",
      "offset": 2585.119,
      "duration": 4.681
    },
    {
      "lang": "en",
      "text": "that is 224x",
      "offset": 2587.44,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "224 We turn the image into a numpy array",
      "offset": 2589.8,
      "duration": 5.48
    },
    {
      "lang": "en",
      "text": "with image to array We span the",
      "offset": 2592.96,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "dimensions of the array and preprocess",
      "offset": 2595.28,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "the input in the same way the training",
      "offset": 2597.28,
      "duration": 5.039
    },
    {
      "lang": "en",
      "text": "images were We import ResNet 50 and",
      "offset": 2598.88,
      "duration": 6.08
    },
    {
      "lang": "en",
      "text": "decode predictions load the model with",
      "offset": 2602.319,
      "duration": 5.441
    },
    {
      "lang": "en",
      "text": "imageet pre-trained weights predict on",
      "offset": 2604.96,
      "duration": 5.359
    },
    {
      "lang": "en",
      "text": "our image and decode the predictions",
      "offset": 2607.76,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "that is getting the predicted classes",
      "offset": 2610.319,
      "duration": 3.561
    },
    {
      "lang": "en",
      "text": "with the highest",
      "offset": 2612.24,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "probabilities inside CNN we can check",
      "offset": 2613.88,
      "duration": 4.439
    },
    {
      "lang": "en",
      "text": "how the different filters activate in",
      "offset": 2616.48,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "response to an input image we will",
      "offset": 2618.319,
      "duration": 3.721
    },
    {
      "lang": "en",
      "text": "explore this in the",
      "offset": 2620.319,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "exercises it is time to briefly",
      "offset": 2622.04,
      "duration": 4.68
    },
    {
      "lang": "en",
      "text": "introduce longterm memory networks also",
      "offset": 2624.24,
      "duration": 3.8
    },
    {
      "lang": "en",
      "text": "known as",
      "offset": 2626.72,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "LSTMs LSTMs are a type of recurrent",
      "offset": 2628.04,
      "duration": 6.12
    },
    {
      "lang": "en",
      "text": "neural network RNM for short A simple",
      "offset": 2630.96,
      "duration": 5.359
    },
    {
      "lang": "en",
      "text": "RNN is a neural network that can use",
      "offset": 2634.16,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "past predictions in order to infer new",
      "offset": 2636.319,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "ones This allow us to solve problems",
      "offset": 2638.48,
      "duration": 3.879
    },
    {
      "lang": "en",
      "text": "where there is a dependence on past",
      "offset": 2640.64,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "inputs LSTM neurons are pretty complex",
      "offset": 2642.359,
      "duration": 5.641
    },
    {
      "lang": "en",
      "text": "They're actually called units or cells",
      "offset": 2645.44,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "They have an internal state that is",
      "offset": 2648,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "passed between units You can see this as",
      "offset": 2649.599,
      "duration": 5.441
    },
    {
      "lang": "en",
      "text": "a memory of past steps A unit receives",
      "offset": 2651.839,
      "duration": 5.361
    },
    {
      "lang": "en",
      "text": "the internal state an output from the",
      "offset": 2655.04,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "previous unit and a new input at time t",
      "offset": 2657.2,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "Then it updates the state and produces a",
      "offset": 2660.4,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "new output that is returned as well as",
      "offset": 2662.88,
      "duration": 4.479
    },
    {
      "lang": "en",
      "text": "pass as an input to the following unit",
      "offset": 2664.72,
      "duration": 5.599
    },
    {
      "lang": "en",
      "text": "LSTN units perform several operations",
      "offset": 2667.359,
      "duration": 5.361
    },
    {
      "lang": "en",
      "text": "They learn what to ignore what to keep",
      "offset": 2670.319,
      "duration": 4.241
    },
    {
      "lang": "en",
      "text": "and to select the most important pieces",
      "offset": 2672.72,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "of past information in order to predict",
      "offset": 2674.56,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "the future They tend to work better than",
      "offset": 2676.64,
      "duration": 5.84
    },
    {
      "lang": "en",
      "text": "simple RNN for most problems",
      "offset": 2679.44,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "LSTDMs have been used for image",
      "offset": 2682.48,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "captioning speechto text text",
      "offset": 2684.24,
      "duration": 4.599
    },
    {
      "lang": "en",
      "text": "translation document summarization text",
      "offset": 2686.319,
      "duration": 5.401
    },
    {
      "lang": "en",
      "text": "generation musical composition and many",
      "offset": 2688.839,
      "duration": 5.721
    },
    {
      "lang": "en",
      "text": "more Let's go over an example on how to",
      "offset": 2691.72,
      "duration": 5.48
    },
    {
      "lang": "en",
      "text": "use LSTMs with text data to predict the",
      "offset": 2694.56,
      "duration": 4.12
    },
    {
      "lang": "en",
      "text": "next word in a",
      "offset": 2697.2,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "sentence Neural networks can only deal",
      "offset": 2698.68,
      "duration": 4.919
    },
    {
      "lang": "en",
      "text": "with numbers not text We need to",
      "offset": 2701.2,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "transform each unique word into a number",
      "offset": 2703.599,
      "duration": 4.881
    },
    {
      "lang": "en",
      "text": "Then these numbers can be used as inputs",
      "offset": 2706.16,
      "duration": 5.439
    },
    {
      "lang": "en",
      "text": "to an embedding layer Embedding layers",
      "offset": 2708.48,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "learn to represent words as vectors of a",
      "offset": 2711.599,
      "duration": 5.281
    },
    {
      "lang": "en",
      "text": "predetermined size These vectors encode",
      "offset": 2713.92,
      "duration": 4.84
    },
    {
      "lang": "en",
      "text": "meaning and are used by subsequent",
      "offset": 2716.88,
      "duration": 4.239
    },
    {
      "lang": "en",
      "text": "layers We first define some text and",
      "offset": 2718.76,
      "duration": 4.359
    },
    {
      "lang": "en",
      "text": "choose a sequence length With a sequence",
      "offset": 2721.119,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "length of three we would end up fitting",
      "offset": 2723.119,
      "duration": 3.521
    },
    {
      "lang": "en",
      "text": "our model with two words and it will",
      "offset": 2724.96,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "predict the third one We split the text",
      "offset": 2726.64,
      "duration": 4.719
    },
    {
      "lang": "en",
      "text": "into words with the split method The",
      "offset": 2729.2,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "output looks like this We then need to",
      "offset": 2731.359,
      "duration": 5.121
    },
    {
      "lang": "en",
      "text": "turn these words into consecutive lines",
      "offset": 2734.56,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "of three words each We can loop from",
      "offset": 2736.48,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "sequence length to the number of force",
      "offset": 2738.8,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "plus one and store each line The end",
      "offset": 2740.319,
      "duration": 5
    },
    {
      "lang": "en",
      "text": "results looks like",
      "offset": 2742.96,
      "duration": 4.879
    },
    {
      "lang": "en",
      "text": "this After that we turn our test",
      "offset": 2745.319,
      "duration": 5.241
    },
    {
      "lang": "en",
      "text": "sequences into numbers We import keras",
      "offset": 2747.839,
      "duration": 4.76
    },
    {
      "lang": "en",
      "text": "tokenizer from the prep-processing text",
      "offset": 2750.56,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "module Instantiate it fit it on lines",
      "offset": 2752.599,
      "duration": 5.48
    },
    {
      "lang": "en",
      "text": "and then turn those lines into numeric",
      "offset": 2756,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "sequences This is how the three word",
      "offset": 2758.079,
      "duration": 3.24
    },
    {
      "lang": "en",
      "text": "lines look",
      "offset": 2760.16,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "Now the tokenizer object stores the word",
      "offset": 2761.319,
      "duration": 4.921
    },
    {
      "lang": "en",
      "text": "to number mapping There are two",
      "offset": 2764.319,
      "duration": 4.921
    },
    {
      "lang": "en",
      "text": "dictionaries the index word and the word",
      "offset": 2766.24,
      "duration": 6.48
    },
    {
      "lang": "en",
      "text": "index Here the index word is printed",
      "offset": 2769.24,
      "duration": 5.4
    },
    {
      "lang": "en",
      "text": "which shows the encoded word for each",
      "offset": 2772.72,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "index We can use this dictionary to",
      "offset": 2774.64,
      "duration": 6.6
    },
    {
      "lang": "en",
      "text": "decode our outputs ming numbers back to",
      "offset": 2776.96,
      "duration": 7.6
    },
    {
      "lang": "en",
      "text": "words Our data is ready to be processed",
      "offset": 2781.24,
      "duration": 6.359
    },
    {
      "lang": "en",
      "text": "Now we are ready to build the LSTM model",
      "offset": 2784.56,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "We start by importing the dense LSTM and",
      "offset": 2787.599,
      "duration": 4.881
    },
    {
      "lang": "en",
      "text": "embedding layers from TensorFlow caras",
      "offset": 2790.24,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "layers We then store the book up size",
      "offset": 2792.48,
      "duration": 4.92
    },
    {
      "lang": "en",
      "text": "since we will use it when defining our",
      "offset": 2795.52,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "layers The book size is the len of the",
      "offset": 2797.4,
      "duration": 5.8
    },
    {
      "lang": "en",
      "text": "tokenizer dictionary plus one The plus",
      "offset": 2800.24,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "one is because we account for zero as an",
      "offset": 2803.2,
      "duration": 4.28
    },
    {
      "lang": "en",
      "text": "integer reserved for a special",
      "offset": 2805.68,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "characters As we saw our dictionary",
      "offset": 2807.48,
      "duration": 5.48
    },
    {
      "lang": "en",
      "text": "starts at one not zero We add an",
      "offset": 2810.16,
      "duration": 4.959
    },
    {
      "lang": "en",
      "text": "embedding layer The input dimension is",
      "offset": 2812.96,
      "duration": 4.639
    },
    {
      "lang": "en",
      "text": "the vocap size variable We will turn our",
      "offset": 2815.119,
      "duration": 4.521
    },
    {
      "lang": "en",
      "text": "word numbers into eight dimensional",
      "offset": 2817.599,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "vectors and need to declare the input",
      "offset": 2819.64,
      "duration": 3.959
    },
    {
      "lang": "en",
      "text": "length so that our model understands",
      "offset": 2821.92,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "that two words will be passed",
      "offset": 2823.599,
      "duration": 3.081
    },
    {
      "lang": "en",
      "text": "simultaneously as a",
      "offset": 2824.96,
      "duration": 4.879
    },
    {
      "lang": "en",
      "text": "sequence We end by adding an LSTM layer",
      "offset": 2826.68,
      "duration": 5.56
    },
    {
      "lang": "en",
      "text": "of eight units a helium layer and an",
      "offset": 2829.839,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "output layer with submax and as many",
      "offset": 2832.24,
      "duration": 4.28
    },
    {
      "lang": "en",
      "text": "outputs as possible",
      "offset": 2834.24,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "words If you have finished the whole",
      "offset": 2836.52,
      "duration": 3.72
    },
    {
      "lang": "en",
      "text": "course you have probably put a lot of",
      "offset": 2838.64,
      "duration": 3.439
    },
    {
      "lang": "en",
      "text": "energy and work into understanding all",
      "offset": 2840.24,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "of these new concepts So congratulations",
      "offset": 2842.079,
      "duration": 4.961
    },
    {
      "lang": "en",
      "text": "I hope you have fun Now you have a",
      "offset": 2844.8,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "better understanding of many key points",
      "offset": 2847.04,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "when it comes to building a variety of",
      "offset": 2848.72,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "neural networks and what you can use",
      "offset": 2850.48,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "them for You have learned a lot You",
      "offset": 2852.16,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "completed 44 exercises and 14 lessons",
      "offset": 2854.319,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "You should be proud You have a lot of",
      "offset": 2857.44,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "power in your hands You have learned the",
      "offset": 2859.119,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "basics of neural networks built",
      "offset": 2861.52,
      "duration": 3.599
    },
    {
      "lang": "en",
      "text": "sequential models and learned to solve",
      "offset": 2863.2,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "regression binary classification",
      "offset": 2865.119,
      "duration": 3.441
    },
    {
      "lang": "en",
      "text": "multiclass and multilel problems with",
      "offset": 2866.8,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "neural networks You have explored",
      "offset": 2868.56,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "activation functions and carried out",
      "offset": 2870.64,
      "duration": 4.479
    },
    {
      "lang": "en",
      "text": "imperameter tuning turning your keras",
      "offset": 2872.48,
      "duration": 5.119
    },
    {
      "lang": "en",
      "text": "models into psych learn estimators You",
      "offset": 2875.119,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "have used autoenccoders and den noiseise",
      "offset": 2877.599,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "images with them You have learned key",
      "offset": 2879.52,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "concepts about CNN networks and use the",
      "offset": 2881.52,
      "duration": 4.799
    },
    {
      "lang": "en",
      "text": "pre-trained reset 50 model to classify",
      "offset": 2884,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "images You visualize convolutions for",
      "offset": 2886.319,
      "duration": 5.361
    },
    {
      "lang": "en",
      "text": "the mn data set You learned about LSTM",
      "offset": 2888.8,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "concepts and work with text and",
      "offset": 2891.68,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "embedding layers You've used a lot of",
      "offset": 2893.44,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "different data sets along the way also",
      "offset": 2895.44,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "learning a lot of KAS utility functions",
      "offset": 2897.2,
      "duration": 4.639
    },
    {
      "lang": "en",
      "text": "To keep on improving your understanding",
      "offset": 2900.16,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "and learning on neural networks you",
      "offset": 2901.839,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "should go deeper into CNN's There's some",
      "offset": 2903.68,
      "duration": 4.639
    },
    {
      "lang": "en",
      "text": "specific course here on data camp You",
      "offset": 2906,
      "duration": 4.559
    },
    {
      "lang": "en",
      "text": "can also go deeper into LSTMs There's a",
      "offset": 2908.319,
      "duration": 4.881
    },
    {
      "lang": "en",
      "text": "lot more to learn You could also check",
      "offset": 2910.559,
      "duration": 4.241
    },
    {
      "lang": "en",
      "text": "how to work with the caras functional",
      "offset": 2913.2,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "API which allows you to build more",
      "offset": 2914.8,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "powerful models with shared layers and",
      "offset": 2916.64,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "several branches And finally consider",
      "offset": 2918.4,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "getting creative with generative",
      "offset": 2921.2,
      "duration": 3.359
    },
    {
      "lang": "en",
      "text": "reversal networks and taking on some",
      "offset": 2922.48,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "deep learning projects of your own If",
      "offset": 2924.559,
      "duration": 4.241
    },
    {
      "lang": "en",
      "text": "you like this course consider spreading",
      "offset": 2926.96,
      "duration": 3.359
    },
    {
      "lang": "en",
      "text": "the word so other people can also",
      "offset": 2928.8,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "experience your journey And feel free to",
      "offset": 2930.319,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "give me a follow on Twitter or linking",
      "offset": 2932.4,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "if you would like And remember your",
      "offset": 2934.24,
      "duration": 6.079
    },
    {
      "lang": "en",
      "text": "adventures with neural networks just",
      "offset": 2936.559,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "begun Hi I'm Zach Dean Mayer And in this",
      "offset": 2940.599,
      "duration": 6.921
    },
    {
      "lang": "en",
      "text": "course I'll be teaching you advanced",
      "offset": 2944.96,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "deep learning concepts using the CARIS",
      "offset": 2947.52,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "functional API",
      "offset": 2950.24,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "You will learn how to build functional",
      "offset": 2952.48,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "caris models including advanced topics",
      "offset": 2954.4,
      "duration": 6.12
    },
    {
      "lang": "en",
      "text": "such as shared layers categorical",
      "offset": 2957.44,
      "duration": 6.36
    },
    {
      "lang": "en",
      "text": "embeddings multiple inputs and multiple",
      "offset": 2960.52,
      "duration": 6.36
    },
    {
      "lang": "en",
      "text": "outputs The CARIS functional API is",
      "offset": 2963.8,
      "duration": 6.92
    },
    {
      "lang": "en",
      "text": "extremely simple yet immensely powerful",
      "offset": 2966.88,
      "duration": 5.92
    },
    {
      "lang": "en",
      "text": "By the end of this class you will build",
      "offset": 2970.72,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "a model that is capable of solving a",
      "offset": 2972.8,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "regression and a classification problem",
      "offset": 2975.28,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "at the same time",
      "offset": 2978.16,
      "duration": 4.959
    },
    {
      "lang": "en",
      "text": "Chapter 1 is a refresher on building",
      "offset": 2980.72,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "simple models where you will learn how",
      "offset": 2983.119,
      "duration": 4.44
    },
    {
      "lang": "en",
      "text": "to use the caris functional",
      "offset": 2985.44,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "API In chapter 2 you will build a caris",
      "offset": 2987.559,
      "duration": 7.321
    },
    {
      "lang": "en",
      "text": "model with two inputs In chapter 3 you",
      "offset": 2991.04,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "will learn how to generalize your",
      "offset": 2994.88,
      "duration": 5.84
    },
    {
      "lang": "en",
      "text": "twoinput model to three or more inputs",
      "offset": 2996.64,
      "duration": 7.28
    },
    {
      "lang": "en",
      "text": "And finally in chapter 4 you will build",
      "offset": 3000.72,
      "duration": 5.599
    },
    {
      "lang": "en",
      "text": "models with multiple outputs that can",
      "offset": 3003.92,
      "duration": 5.919
    },
    {
      "lang": "en",
      "text": "solve multiple problems",
      "offset": 3006.319,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "You will be using two data sets of",
      "offset": 3009.839,
      "duration": 5.081
    },
    {
      "lang": "en",
      "text": "college basketball games from American",
      "offset": 3012.319,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "colleges The first data set is from the",
      "offset": 3014.92,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "regular season and has the following",
      "offset": 3017.839,
      "duration": 5.161
    },
    {
      "lang": "en",
      "text": "data The IDs of the two teams that",
      "offset": 3019.88,
      "duration": 5.8
    },
    {
      "lang": "en",
      "text": "played whether the first team was home",
      "offset": 3023,
      "duration": 6.44
    },
    {
      "lang": "en",
      "text": "or away whether the first team won or",
      "offset": 3025.68,
      "duration": 7.12
    },
    {
      "lang": "en",
      "text": "lost the game and by how many points the",
      "offset": 3029.44,
      "duration": 6.159
    },
    {
      "lang": "en",
      "text": "first team won or lost",
      "offset": 3032.8,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "For the tournament data set you also",
      "offset": 3035.599,
      "duration": 5.601
    },
    {
      "lang": "en",
      "text": "have the tournament seed which is a",
      "offset": 3038,
      "duration": 5.96
    },
    {
      "lang": "en",
      "text": "pre-ournament ranking for each",
      "offset": 3041.2,
      "duration": 7.04
    },
    {
      "lang": "en",
      "text": "team These seeds range from 1 to 16",
      "offset": 3043.96,
      "duration": 6.44
    },
    {
      "lang": "en",
      "text": "where the best four teams get a seed of",
      "offset": 3048.24,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "one and the worst four teams get a seed",
      "offset": 3050.4,
      "duration": 3.64
    },
    {
      "lang": "en",
      "text": "of",
      "offset": 3052.96,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "16 You will use the difference in the",
      "offset": 3054.04,
      "duration": 6.72
    },
    {
      "lang": "en",
      "text": "two team seeds as an input to your",
      "offset": 3056.72,
      "duration": 6.879
    },
    {
      "lang": "en",
      "text": "model Here are the first five rows of",
      "offset": 3060.76,
      "duration": 4.839
    },
    {
      "lang": "en",
      "text": "both the data sets",
      "offset": 3063.599,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "You can see that the team variables are",
      "offset": 3065.599,
      "duration": 4.801
    },
    {
      "lang": "en",
      "text": "encoded as integers and the tournament",
      "offset": 3067.76,
      "duration": 5.92
    },
    {
      "lang": "en",
      "text": "data set has one additional column The",
      "offset": 3070.4,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "difference between the tournament seeds",
      "offset": 3073.68,
      "duration": 3.48
    },
    {
      "lang": "en",
      "text": "for both",
      "offset": 3075.92,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "teams Other than the seed difference the",
      "offset": 3077.16,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "two data sets have identical",
      "offset": 3080.319,
      "duration": 5.601
    },
    {
      "lang": "en",
      "text": "columns Within a given year a team's",
      "offset": 3082.92,
      "duration": 6.12
    },
    {
      "lang": "en",
      "text": "roster stays relatively constant but",
      "offset": 3085.92,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "between years it can change a lot as",
      "offset": 3089.04,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "seniors graduate and freshmen start",
      "offset": 3091.52,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "Therefore for every year each school is",
      "offset": 3094.64,
      "duration": 5.959
    },
    {
      "lang": "en",
      "text": "given a unique integer",
      "offset": 3097.52,
      "duration": 6.319
    },
    {
      "lang": "en",
      "text": "ID Caris models at their simplest are",
      "offset": 3100.599,
      "duration": 6.281
    },
    {
      "lang": "en",
      "text": "fundamentally composed of two parts an",
      "offset": 3103.839,
      "duration": 6.321
    },
    {
      "lang": "en",
      "text": "input layer and an output layer",
      "offset": 3106.88,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "To start I'll define a very simple caris",
      "offset": 3110.16,
      "duration": 5.64
    },
    {
      "lang": "en",
      "text": "model which only expects a single",
      "offset": 3112.88,
      "duration": 6.16
    },
    {
      "lang": "en",
      "text": "input I'll specify this using the input",
      "offset": 3115.8,
      "duration": 6.559
    },
    {
      "lang": "en",
      "text": "function from the caris.layers",
      "offset": 3119.04,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "module The number of columns in the",
      "offset": 3122.359,
      "duration": 5.361
    },
    {
      "lang": "en",
      "text": "input is specified using the shape",
      "offset": 3124.72,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "parameter This tells the model how much",
      "offset": 3127.72,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "data to",
      "offset": 3130.4,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "expect Note that the shape argument",
      "offset": 3131.72,
      "duration": 5.16
    },
    {
      "lang": "en",
      "text": "expects a tpple",
      "offset": 3134.319,
      "duration": 5.921
    },
    {
      "lang": "en",
      "text": "The input function returns a tensor If",
      "offset": 3136.88,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "you print this tensor you'll see that it",
      "offset": 3140.24,
      "duration": 5.839
    },
    {
      "lang": "en",
      "text": "is a tf.tensor object which indicates it",
      "offset": 3142.24,
      "duration": 6.92
    },
    {
      "lang": "en",
      "text": "is ready to be used by our model as",
      "offset": 3146.079,
      "duration": 5.681
    },
    {
      "lang": "en",
      "text": "input Now that we've defined our input",
      "offset": 3149.16,
      "duration": 5.199
    },
    {
      "lang": "en",
      "text": "layer let's define the output",
      "offset": 3151.76,
      "duration": 5.839
    },
    {
      "lang": "en",
      "text": "layer Outputs in caris are most commonly",
      "offset": 3154.359,
      "duration": 6.521
    },
    {
      "lang": "en",
      "text": "a single dense layer which specifies the",
      "offset": 3157.599,
      "duration": 6.24
    },
    {
      "lang": "en",
      "text": "shape of the expected output",
      "offset": 3160.88,
      "duration": 5.199
    },
    {
      "lang": "en",
      "text": "In this case we are expecting our model",
      "offset": 3163.839,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "to predict a single value So we pass one",
      "offset": 3166.079,
      "duration": 6.641
    },
    {
      "lang": "en",
      "text": "unit to the dense layer If you print the",
      "offset": 3169.359,
      "duration": 6.161
    },
    {
      "lang": "en",
      "text": "output layer the result is not a",
      "offset": 3172.72,
      "duration": 6.32
    },
    {
      "lang": "en",
      "text": "tensorflow tensor It is a function which",
      "offset": 3175.52,
      "duration": 6.559
    },
    {
      "lang": "en",
      "text": "takes a tensor as input and produces a",
      "offset": 3179.04,
      "duration": 4.279
    },
    {
      "lang": "en",
      "text": "tensor as",
      "offset": 3182.079,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "output The difference between layers and",
      "offset": 3183.319,
      "duration": 5.481
    },
    {
      "lang": "en",
      "text": "tensors is key to understanding the",
      "offset": 3186.079,
      "duration": 5.201
    },
    {
      "lang": "en",
      "text": "caris functional API",
      "offset": 3188.8,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "Layers are used to construct a deep",
      "offset": 3191.28,
      "duration": 6.16
    },
    {
      "lang": "en",
      "text": "learning model and tensors are used to",
      "offset": 3194,
      "duration": 6.68
    },
    {
      "lang": "en",
      "text": "define the data flow through the",
      "offset": 3197.44,
      "duration": 6.32
    },
    {
      "lang": "en",
      "text": "model In this case the input layer",
      "offset": 3200.68,
      "duration": 5.72
    },
    {
      "lang": "en",
      "text": "defines a tensor which we then pass to",
      "offset": 3203.76,
      "duration": 4.839
    },
    {
      "lang": "en",
      "text": "the output layer",
      "offset": 3206.4,
      "duration": 4.719
    },
    {
      "lang": "en",
      "text": "function The final output of our model",
      "offset": 3208.599,
      "duration": 5.921
    },
    {
      "lang": "en",
      "text": "is a tensor",
      "offset": 3211.119,
      "duration": 3.401
    },
    {
      "lang": "en",
      "text": "In this lesson I will show you how to",
      "offset": 3214.96,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "turn the collection of layers you",
      "offset": 3217.359,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "assembled in lesson one into an actual",
      "offset": 3219.28,
      "duration": 5.279
    },
    {
      "lang": "en",
      "text": "model that you can fit to the data and",
      "offset": 3222.319,
      "duration": 4.52
    },
    {
      "lang": "en",
      "text": "then use to predict on new",
      "offset": 3224.559,
      "duration": 4.961
    },
    {
      "lang": "en",
      "text": "data I will start with the two simple",
      "offset": 3226.839,
      "duration": 5.961
    },
    {
      "lang": "en",
      "text": "caris layers you defined in lesson one",
      "offset": 3229.52,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "Note that I've taken a shortcut here",
      "offset": 3232.8,
      "duration": 5.039
    },
    {
      "lang": "en",
      "text": "Rather than defining the output layer in",
      "offset": 3235.52,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "one line and then the output tensor in",
      "offset": 3237.839,
      "duration": 5.841
    },
    {
      "lang": "en",
      "text": "the next I'm using one line to both",
      "offset": 3240.4,
      "duration": 5.919
    },
    {
      "lang": "en",
      "text": "create the layer function and then call",
      "offset": 3243.68,
      "duration": 4.6
    },
    {
      "lang": "en",
      "text": "it to produce a",
      "offset": 3246.319,
      "duration": 4.641
    },
    {
      "lang": "en",
      "text": "tensor There are two sets of parenthesis",
      "offset": 3248.28,
      "duration": 5.48
    },
    {
      "lang": "en",
      "text": "in that line because we both create the",
      "offset": 3250.96,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "function and then call it in the same",
      "offset": 3253.76,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "line",
      "offset": 3255.92,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "To build a model you simply import the",
      "offset": 3257.92,
      "duration": 4.36
    },
    {
      "lang": "en",
      "text": "model class from",
      "offset": 3260.48,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "caris.mmodels and pass your input and",
      "offset": 3262.28,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "output to this",
      "offset": 3264.8,
      "duration": 4.559
    },
    {
      "lang": "en",
      "text": "class In this case we only have a single",
      "offset": 3266.52,
      "duration": 5.88
    },
    {
      "lang": "en",
      "text": "input and a single output which we pass",
      "offset": 3269.359,
      "duration": 4.601
    },
    {
      "lang": "en",
      "text": "directly to the",
      "offset": 3272.4,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "model However later in this class you",
      "offset": 3273.96,
      "duration": 5.159
    },
    {
      "lang": "en",
      "text": "will work with multiple inputs and",
      "offset": 3277.04,
      "duration": 4.559
    },
    {
      "lang": "en",
      "text": "multiple outputs in which case you will",
      "offset": 3279.119,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "pass lists of inputs or lists of outputs",
      "offset": 3281.599,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "to the model",
      "offset": 3284.559,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "Finally you must compile the model",
      "offset": 3286.559,
      "duration": 4.641
    },
    {
      "lang": "en",
      "text": "before fitting it to the data The",
      "offset": 3288.559,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "compilation step finalizes the model and",
      "offset": 3291.2,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "gets it completely ready for use in",
      "offset": 3293.839,
      "duration": 4.28
    },
    {
      "lang": "en",
      "text": "fitting and",
      "offset": 3296.4,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "predicting During compilation you select",
      "offset": 3298.119,
      "duration": 5.96
    },
    {
      "lang": "en",
      "text": "an optimizer I almost always use the",
      "offset": 3300.88,
      "duration": 5.439
    },
    {
      "lang": "en",
      "text": "atom optimizer and you will find it",
      "offset": 3304.079,
      "duration": 4.121
    },
    {
      "lang": "en",
      "text": "typically gives good",
      "offset": 3306.319,
      "duration": 4.641
    },
    {
      "lang": "en",
      "text": "results During compilation you also",
      "offset": 3308.2,
      "duration": 6.28
    },
    {
      "lang": "en",
      "text": "select a loss function In this case we",
      "offset": 3310.96,
      "duration": 6.879
    },
    {
      "lang": "en",
      "text": "use mean absolute error which is a good",
      "offset": 3314.48,
      "duration": 5.599
    },
    {
      "lang": "en",
      "text": "generalpurpose error function for caris",
      "offset": 3317.839,
      "duration": 4.641
    },
    {
      "lang": "en",
      "text": "models as it is a little bit less",
      "offset": 3320.079,
      "duration": 3.561
    },
    {
      "lang": "en",
      "text": "sensitive to",
      "offset": 3322.48,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "outliers You could also use mean squared",
      "offset": 3323.64,
      "duration": 5.32
    },
    {
      "lang": "en",
      "text": "error which would be equivalent to",
      "offset": 3326.88,
      "duration": 4.84
    },
    {
      "lang": "en",
      "text": "traditional linear",
      "offset": 3328.96,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "regression Before fitting my models I",
      "offset": 3331.72,
      "duration": 5.32
    },
    {
      "lang": "en",
      "text": "also like to summarize them You can do",
      "offset": 3334.4,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "this by calling the summary method on",
      "offset": 3337.04,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "the model object This gives you a nice",
      "offset": 3339.2,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "table of the layers in the model so you",
      "offset": 3342.24,
      "duration": 5.839
    },
    {
      "lang": "en",
      "text": "can confirm they are as you expect In",
      "offset": 3344.8,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "this case you can see your input layer",
      "offset": 3348.079,
      "duration": 4.881
    },
    {
      "lang": "en",
      "text": "and your output layer The output layer",
      "offset": 3350,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "has two parameters which makes sense as",
      "offset": 3352.96,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "you have one input and one output The",
      "offset": 3355.52,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "model you have defined here is a",
      "offset": 3358.72,
      "duration": 4.639
    },
    {
      "lang": "en",
      "text": "standard linear regression model",
      "offset": 3360.72,
      "duration": 8.079
    },
    {
      "lang": "en",
      "text": "equivalent to y = mx + b M and B are the",
      "offset": 3363.359,
      "duration": 7.921
    },
    {
      "lang": "en",
      "text": "two parameters In the terminology of",
      "offset": 3368.799,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "linear regression M is the slope and B",
      "offset": 3371.28,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "is the intercept In the terminology of",
      "offset": 3374.559,
      "duration": 5.361
    },
    {
      "lang": "en",
      "text": "CARIS M is the weight of the dense layer",
      "offset": 3377.28,
      "duration": 5.4
    },
    {
      "lang": "en",
      "text": "and B is the bias of the dense",
      "offset": 3379.92,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "layer It is also useful to plot the",
      "offset": 3382.68,
      "duration": 5.639
    },
    {
      "lang": "en",
      "text": "model before fitting it A plot gives you",
      "offset": 3385.44,
      "duration": 5
    },
    {
      "lang": "en",
      "text": "a little bit more information than a",
      "offset": 3388.319,
      "duration": 4.641
    },
    {
      "lang": "en",
      "text": "summary It shows you how the layers",
      "offset": 3390.44,
      "duration": 5.639
    },
    {
      "lang": "en",
      "text": "connect together visually",
      "offset": 3392.96,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "In this case the input layer connects",
      "offset": 3396.079,
      "duration": 4.601
    },
    {
      "lang": "en",
      "text": "directly to the output layer which is",
      "offset": 3398.24,
      "duration": 5.119
    },
    {
      "lang": "en",
      "text": "dense Note that in the code for this",
      "offset": 3400.68,
      "duration": 6.119
    },
    {
      "lang": "en",
      "text": "example I've named the dense layer Names",
      "offset": 3403.359,
      "duration": 5.361
    },
    {
      "lang": "en",
      "text": "are useful when you're looking at model",
      "offset": 3406.799,
      "duration": 4.481
    },
    {
      "lang": "en",
      "text": "plots to help keep track of which layer",
      "offset": 3408.72,
      "duration": 5.92
    },
    {
      "lang": "en",
      "text": "in the plot is which layer in the code",
      "offset": 3411.28,
      "duration": 6.079
    },
    {
      "lang": "en",
      "text": "Plot model saves the image to a file",
      "offset": 3414.64,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "which we can then display using Mattplot",
      "offset": 3417.359,
      "duration": 5.921
    },
    {
      "lang": "en",
      "text": "Lib's im read and im show functions as",
      "offset": 3420,
      "duration": 6.599
    },
    {
      "lang": "en",
      "text": "shown here",
      "offset": 3423.28,
      "duration": 3.319
    },
    {
      "lang": "en",
      "text": "In this lesson you will take the model",
      "offset": 3427.119,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "you compiled in lesson two and fit it to",
      "offset": 3429.359,
      "duration": 4.361
    },
    {
      "lang": "en",
      "text": "college basketball",
      "offset": 3432.079,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "data Your goal is to predict which team",
      "offset": 3433.72,
      "duration": 4.879
    },
    {
      "lang": "en",
      "text": "will win a tournament",
      "offset": 3436.799,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "game The only data you have to work with",
      "offset": 3438.599,
      "duration": 6.121
    },
    {
      "lang": "en",
      "text": "are the teams seeds which are assigned",
      "offset": 3441.599,
      "duration": 6.161
    },
    {
      "lang": "en",
      "text": "by the tournament organizers and are a",
      "offset": 3444.72,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "rating of how good the team is",
      "offset": 3447.76,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "A seed of one is a very good team and a",
      "offset": 3450.48,
      "duration": 6.56
    },
    {
      "lang": "en",
      "text": "seed of 16 is a very bad team In the 30",
      "offset": 3453.2,
      "duration": 6.96
    },
    {
      "lang": "en",
      "text": "plus year history of the tournament a 16",
      "offset": 3457.04,
      "duration": 6.88
    },
    {
      "lang": "en",
      "text": "seed has beat a one seed exactly once It",
      "offset": 3460.16,
      "duration": 6.56
    },
    {
      "lang": "en",
      "text": "was in 2018 which was a very exciting",
      "offset": 3463.92,
      "duration": 5.56
    },
    {
      "lang": "en",
      "text": "year for college basketball",
      "offset": 3466.72,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "fans Your input will be the difference",
      "offset": 3469.48,
      "duration": 5.96
    },
    {
      "lang": "en",
      "text": "in seed between the two teams For",
      "offset": 3472.24,
      "duration": 6.8
    },
    {
      "lang": "en",
      "text": "example if a seven seed plays a 10 seed",
      "offset": 3475.44,
      "duration": 7.56
    },
    {
      "lang": "en",
      "text": "their seed difference is 7 minus 10 org",
      "offset": 3479.04,
      "duration": 7.36
    },
    {
      "lang": "en",
      "text": "-3 If an 11 seed plays a seven seed",
      "offset": 3483,
      "duration": 7.599
    },
    {
      "lang": "en",
      "text": "their seed difference is 11 - 7 or",
      "offset": 3486.4,
      "duration": 7.28
    },
    {
      "lang": "en",
      "text": "4 Your output will be the difference in",
      "offset": 3490.599,
      "duration": 6.921
    },
    {
      "lang": "en",
      "text": "score between the two teams For example",
      "offset": 3493.68,
      "duration": 6.879
    },
    {
      "lang": "en",
      "text": "if team one scores 41 points and team",
      "offset": 3497.52,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "two scores 50 points the score",
      "offset": 3500.559,
      "duration": 6.201
    },
    {
      "lang": "en",
      "text": "difference is 41 minus 50 or",
      "offset": 3503.04,
      "duration": 7.279
    },
    {
      "lang": "en",
      "text": "-9 On the other hand if team one scores",
      "offset": 3506.76,
      "duration": 7.799
    },
    {
      "lang": "en",
      "text": "61 points and team 2 scores 55 points",
      "offset": 3510.319,
      "duration": 7.921
    },
    {
      "lang": "en",
      "text": "the score difference is 61 minus 55 or",
      "offset": 3514.559,
      "duration": 5.56
    },
    {
      "lang": "en",
      "text": "positive",
      "offset": 3518.24,
      "duration": 5.599
    },
    {
      "lang": "en",
      "text": "6 Therefore your model has one input and",
      "offset": 3520.119,
      "duration": 7.321
    },
    {
      "lang": "en",
      "text": "one output This is exactly the model you",
      "offset": 3523.839,
      "duration": 5.681
    },
    {
      "lang": "en",
      "text": "created in lesson one and lesson two of",
      "offset": 3527.44,
      "duration": 3
    },
    {
      "lang": "en",
      "text": "this",
      "offset": 3529.52,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "chapter You will use the difference in",
      "offset": 3530.44,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "seeds as your",
      "offset": 3532.96,
      "duration": 5.599
    },
    {
      "lang": "en",
      "text": "input Note that you have both a 16 seed",
      "offset": 3534.52,
      "duration": 6.36
    },
    {
      "lang": "en",
      "text": "playing a one seed and a one seed",
      "offset": 3538.559,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "playing a 16 seed in your data So you'll",
      "offset": 3540.88,
      "duration": 6.8
    },
    {
      "lang": "en",
      "text": "have seed differences ranging from -15",
      "offset": 3544.079,
      "duration": 6.801
    },
    {
      "lang": "en",
      "text": "to positive 15",
      "offset": 3547.68,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "A seed difference of positive 15 means",
      "offset": 3550.88,
      "duration": 5.679
    },
    {
      "lang": "en",
      "text": "that team one has a seed of 16 and is",
      "offset": 3553.68,
      "duration": 6.639
    },
    {
      "lang": "en",
      "text": "playing a team of seed of one This means",
      "offset": 3556.559,
      "duration": 7.401
    },
    {
      "lang": "en",
      "text": "team one is likely though not certain to",
      "offset": 3560.319,
      "duration": 7.841
    },
    {
      "lang": "en",
      "text": "lose A seed difference of -15 means that",
      "offset": 3563.96,
      "duration": 7.08
    },
    {
      "lang": "en",
      "text": "team one has a seed of one and is",
      "offset": 3568.16,
      "duration": 5.32
    },
    {
      "lang": "en",
      "text": "playing a team of seed of",
      "offset": 3571.04,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "16 This means team one is likely though",
      "offset": 3573.48,
      "duration": 6.44
    },
    {
      "lang": "en",
      "text": "not certain to win",
      "offset": 3577.04,
      "duration": 5.519
    },
    {
      "lang": "en",
      "text": "So a positive seed difference is usually",
      "offset": 3579.92,
      "duration": 4.36
    },
    {
      "lang": "en",
      "text": "predictive of a negative score",
      "offset": 3582.559,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "difference and a negative seed",
      "offset": 3584.28,
      "duration": 4.36
    },
    {
      "lang": "en",
      "text": "difference is usually predictive of a",
      "offset": 3586.4,
      "duration": 3.88
    },
    {
      "lang": "en",
      "text": "positive score",
      "offset": 3588.64,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "difference Our target variable is the",
      "offset": 3590.28,
      "duration": 4.68
    },
    {
      "lang": "en",
      "text": "game score difference and ranges from",
      "offset": 3592.799,
      "duration": 4.921
    },
    {
      "lang": "en",
      "text": "about -50 to positive",
      "offset": 3594.96,
      "duration": 5.599
    },
    {
      "lang": "en",
      "text": "50 This means you have games where team",
      "offset": 3597.72,
      "duration": 5.399
    },
    {
      "lang": "en",
      "text": "one lost by 50 points and games where",
      "offset": 3600.559,
      "duration": 6.081
    },
    {
      "lang": "en",
      "text": "they won by 50 points",
      "offset": 3603.119,
      "duration": 5.601
    },
    {
      "lang": "en",
      "text": "Note that both the regular season and",
      "offset": 3606.64,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "the tournament data sets have two rows",
      "offset": 3608.72,
      "duration": 6.96
    },
    {
      "lang": "en",
      "text": "per game Where the second row has the",
      "offset": 3611.76,
      "duration": 7.2
    },
    {
      "lang": "en",
      "text": "opposite signs of the first row In other",
      "offset": 3615.68,
      "duration": 5.679
    },
    {
      "lang": "en",
      "text": "words for a given game where the first",
      "offset": 3618.96,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "team won there is also a row in the data",
      "offset": 3621.359,
      "duration": 4.801
    },
    {
      "lang": "en",
      "text": "set where team one and team two are",
      "offset": 3624.16,
      "duration": 5
    },
    {
      "lang": "en",
      "text": "swapped and the first team",
      "offset": 3626.16,
      "duration": 5.84
    },
    {
      "lang": "en",
      "text": "lost Here is the model from lessons one",
      "offset": 3629.16,
      "duration": 6.199
    },
    {
      "lang": "en",
      "text": "and two defined in a single code chunk",
      "offset": 3632,
      "duration": 5.839
    },
    {
      "lang": "en",
      "text": "This is a very basic caris regression",
      "offset": 3635.359,
      "duration": 6.161
    },
    {
      "lang": "en",
      "text": "model with one input and one output You",
      "offset": 3637.839,
      "duration": 5.841
    },
    {
      "lang": "en",
      "text": "could use this model for any regression",
      "offset": 3641.52,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "problem with a single predictor in a",
      "offset": 3643.68,
      "duration": 3.639
    },
    {
      "lang": "en",
      "text": "single",
      "offset": 3645.839,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "outcome To fit the model load the",
      "offset": 3647.319,
      "duration": 4.76
    },
    {
      "lang": "en",
      "text": "basketball tournament data set from a",
      "offset": 3650.16,
      "duration": 5.439
    },
    {
      "lang": "en",
      "text": "CSV file using pandas and then call",
      "offset": 3652.079,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "model.fit",
      "offset": 3655.599,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "Use the seed diff column from the data",
      "offset": 3658.079,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "set as the input and the score diff",
      "offset": 3660.079,
      "duration": 6.24
    },
    {
      "lang": "en",
      "text": "column from the data set as the output",
      "offset": 3662.799,
      "duration": 5.601
    },
    {
      "lang": "en",
      "text": "The fit method has some additional",
      "offset": 3666.319,
      "duration": 4.28
    },
    {
      "lang": "en",
      "text": "arguments which can be",
      "offset": 3668.4,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "useful Batch size sets how many rows of",
      "offset": 3670.599,
      "duration": 5.321
    },
    {
      "lang": "en",
      "text": "data are used for each step of",
      "offset": 3673.76,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "stochastic gradient descent In this case",
      "offset": 3675.92,
      "duration": 6.879
    },
    {
      "lang": "en",
      "text": "you'll train on 64 rows at a time",
      "offset": 3679.28,
      "duration": 5.92
    },
    {
      "lang": "en",
      "text": "Validation split tells Caris to use a",
      "offset": 3682.799,
      "duration": 5.121
    },
    {
      "lang": "en",
      "text": "hold out set and return metrics on",
      "offset": 3685.2,
      "duration": 6.48
    },
    {
      "lang": "en",
      "text": "accuracy using that data This can be",
      "offset": 3687.92,
      "duration": 6.24
    },
    {
      "lang": "en",
      "text": "useful for validating that your models",
      "offset": 3691.68,
      "duration": 4.76
    },
    {
      "lang": "en",
      "text": "will perform well on new",
      "offset": 3694.16,
      "duration": 6.399
    },
    {
      "lang": "en",
      "text": "data When verbose is set to true caris",
      "offset": 3696.44,
      "duration": 7.24
    },
    {
      "lang": "en",
      "text": "prints a log during training This can be",
      "offset": 3700.559,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "useful for debugging but usually I set",
      "offset": 3703.68,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "it to false once I like how the model",
      "offset": 3706.079,
      "duration": 4.561
    },
    {
      "lang": "en",
      "text": "works",
      "offset": 3708.24,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "Once you fit a model it is useful to",
      "offset": 3710.64,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "evaluate it on new data Even if you use",
      "offset": 3712.88,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "a validation set during training you",
      "offset": 3716.24,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "often want to do a second check using a",
      "offset": 3718.64,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "new data set to make sure the model is",
      "offset": 3721.68,
      "duration": 4.439
    },
    {
      "lang": "en",
      "text": "predicting as",
      "offset": 3724.4,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "expected To do this you can use the",
      "offset": 3726.119,
      "duration": 6.041
    },
    {
      "lang": "en",
      "text": "evaluate method of the model and pass it",
      "offset": 3729.04,
      "duration": 7.519
    },
    {
      "lang": "en",
      "text": "the X and Y variables from the new data",
      "offset": 3732.16,
      "duration": 7.439
    },
    {
      "lang": "en",
      "text": "When you do this Caris will report error",
      "offset": 3736.559,
      "duration": 6.081
    },
    {
      "lang": "en",
      "text": "metrics on the new",
      "offset": 3739.599,
      "duration": 3.041
    },
    {
      "lang": "en",
      "text": "data In chapter 1 our data set of",
      "offset": 3743,
      "duration": 5.559
    },
    {
      "lang": "en",
      "text": "tournament games only contained about",
      "offset": 3746.319,
      "duration": 3.48
    },
    {
      "lang": "en",
      "text": "4,000",
      "offset": 3748.559,
      "duration": 4.721
    },
    {
      "lang": "en",
      "text": "rows However we have a much bigger data",
      "offset": 3749.799,
      "duration": 7.361
    },
    {
      "lang": "en",
      "text": "set with over 300,000 regular season",
      "offset": 3753.28,
      "duration": 6.64
    },
    {
      "lang": "en",
      "text": "games Let's see what we can learn from a",
      "offset": 3757.16,
      "duration": 4.639
    },
    {
      "lang": "en",
      "text": "much larger sample of",
      "offset": 3759.92,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "data In the two basketball data sets you",
      "offset": 3761.799,
      "duration": 5.641
    },
    {
      "lang": "en",
      "text": "will be using in this course there are a",
      "offset": 3764.96,
      "duration": 6.24
    },
    {
      "lang": "en",
      "text": "little under 11,000 teams Each team is",
      "offset": 3767.44,
      "duration": 5.919
    },
    {
      "lang": "en",
      "text": "coded as an integer starting with one",
      "offset": 3771.2,
      "duration": 5.359
    },
    {
      "lang": "en",
      "text": "and ending with",
      "offset": 3773.359,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "10,887 In this lesson you will learn how",
      "offset": 3777.079,
      "duration": 6.28
    },
    {
      "lang": "en",
      "text": "to use those team IDs as inputs to a",
      "offset": 3779.92,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "model that learns the strength of each",
      "offset": 3783.359,
      "duration": 4.801
    },
    {
      "lang": "en",
      "text": "team",
      "offset": 3785.92,
      "duration": 4.879
    },
    {
      "lang": "en",
      "text": "Categorical embeddings are an advanced",
      "offset": 3788.16,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "type of layer only available in deep",
      "offset": 3790.799,
      "duration": 5.681
    },
    {
      "lang": "en",
      "text": "learning libraries They are extremely",
      "offset": 3793.68,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "useful for dealing with high cardality",
      "offset": 3796.48,
      "duration": 6.24
    },
    {
      "lang": "en",
      "text": "categorical data In this data set the",
      "offset": 3799.2,
      "duration": 6.44
    },
    {
      "lang": "en",
      "text": "team ID variable has high",
      "offset": 3802.72,
      "duration": 6.079
    },
    {
      "lang": "en",
      "text": "cardality Embedding layers are also very",
      "offset": 3805.64,
      "duration": 5.719
    },
    {
      "lang": "en",
      "text": "useful for dealing with text data such",
      "offset": 3808.799,
      "duration": 5.601
    },
    {
      "lang": "en",
      "text": "as in wordtovec models but that is",
      "offset": 3811.359,
      "duration": 6.081
    },
    {
      "lang": "en",
      "text": "beyond the scope of this course",
      "offset": 3814.4,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "To model these teams in the basketball",
      "offset": 3817.44,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "data you'll use a very simple model that",
      "offset": 3819.52,
      "duration": 6.64
    },
    {
      "lang": "en",
      "text": "learns a strength rating for each team",
      "offset": 3822.48,
      "duration": 6.359
    },
    {
      "lang": "en",
      "text": "and uses those ratings to make",
      "offset": 3826.16,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "predictions To map the integer team IDs",
      "offset": 3828.839,
      "duration": 5.72
    },
    {
      "lang": "en",
      "text": "to a decimal rating we will use an",
      "offset": 3831.76,
      "duration": 4.599
    },
    {
      "lang": "en",
      "text": "embedding",
      "offset": 3834.559,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "layer To get started with category",
      "offset": 3836.359,
      "duration": 5.641
    },
    {
      "lang": "en",
      "text": "embeddings you will need an input layer",
      "offset": 3838.799,
      "duration": 5.361
    },
    {
      "lang": "en",
      "text": "In this case your input is a single",
      "offset": 3842,
      "duration": 5.319
    },
    {
      "lang": "en",
      "text": "number ranging from 1 to",
      "offset": 3844.16,
      "duration": 6.56
    },
    {
      "lang": "en",
      "text": "10,887 which represents each team's",
      "offset": 3847.319,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "unique",
      "offset": 3850.72,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "ID Note that this data set covers about",
      "offset": 3851.72,
      "duration": 5.16
    },
    {
      "lang": "en",
      "text": "30 years of data and has about 400",
      "offset": 3854.559,
      "duration": 5.641
    },
    {
      "lang": "en",
      "text": "unique schools giving us close to 12,000",
      "offset": 3856.88,
      "duration": 6.479
    },
    {
      "lang": "en",
      "text": "IDs We only have about 11,000 of those",
      "offset": 3860.2,
      "duration": 6.28
    },
    {
      "lang": "en",
      "text": "team year combinations because not every",
      "offset": 3863.359,
      "duration": 7.281
    },
    {
      "lang": "en",
      "text": "school has a basketball team every year",
      "offset": 3866.48,
      "duration": 6.319
    },
    {
      "lang": "en",
      "text": "To create an embedding layer use the",
      "offset": 3870.64,
      "duration": 4.52
    },
    {
      "lang": "en",
      "text": "embedding function from",
      "offset": 3872.799,
      "duration": 4.841
    },
    {
      "lang": "en",
      "text": "caris.layers Since you have",
      "offset": 3875.16,
      "duration": 5.32
    },
    {
      "lang": "en",
      "text": "10,887 unique teams in the data set you",
      "offset": 3877.64,
      "duration": 4.919
    },
    {
      "lang": "en",
      "text": "will define the input dimension of the",
      "offset": 3880.48,
      "duration": 5.92
    },
    {
      "lang": "en",
      "text": "embedding layer as",
      "offset": 3882.559,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "10,887 As you are representing each team",
      "offset": 3886.839,
      "duration": 5.72
    },
    {
      "lang": "en",
      "text": "as a single integer use an input length",
      "offset": 3889.599,
      "duration": 3.801
    },
    {
      "lang": "en",
      "text": "of",
      "offset": 3892.559,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "1 You want to produce a single team",
      "offset": 3893.4,
      "duration": 5.159
    },
    {
      "lang": "en",
      "text": "strength rating so use an output",
      "offset": 3896.4,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "dimension of one",
      "offset": 3898.559,
      "duration": 4.641
    },
    {
      "lang": "en",
      "text": "Finally name your layer so you can",
      "offset": 3900.72,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "easily find it when looking at the model",
      "offset": 3903.2,
      "duration": 4.359
    },
    {
      "lang": "en",
      "text": "summary or",
      "offset": 3905.44,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "plot To use the embedding layer connect",
      "offset": 3907.559,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "it to the tensor produced by the input",
      "offset": 3910.72,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "layer This will produce an embedding",
      "offset": 3913.319,
      "duration": 4.561
    },
    {
      "lang": "en",
      "text": "output",
      "offset": 3916.24,
      "duration": 4.559
    },
    {
      "lang": "en",
      "text": "tensor Embedding layers increase the",
      "offset": 3917.88,
      "duration": 5.719
    },
    {
      "lang": "en",
      "text": "dimensionality of your data The input",
      "offset": 3920.799,
      "duration": 6.56
    },
    {
      "lang": "en",
      "text": "CSV has two dimensions rows and columns",
      "offset": 3923.599,
      "duration": 6.921
    },
    {
      "lang": "en",
      "text": "but the embedding layers add a third",
      "offset": 3927.359,
      "duration": 5.601
    },
    {
      "lang": "en",
      "text": "dimension This third dimension can be",
      "offset": 3930.52,
      "duration": 5.48
    },
    {
      "lang": "en",
      "text": "useful when dealing with images and text",
      "offset": 3932.96,
      "duration": 5.48
    },
    {
      "lang": "en",
      "text": "so it is not as relevant to this",
      "offset": 3936,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "course Therefore we use the flatten",
      "offset": 3938.44,
      "duration": 6.119
    },
    {
      "lang": "en",
      "text": "layer to flatten the embeddings from 3D",
      "offset": 3941.68,
      "duration": 6.639
    },
    {
      "lang": "en",
      "text": "to 2D The flatten layer is also the",
      "offset": 3944.559,
      "duration": 7.28
    },
    {
      "lang": "en",
      "text": "output layer for the embedding process",
      "offset": 3948.319,
      "duration": 5.841
    },
    {
      "lang": "en",
      "text": "Flatten layers are an advanced layer for",
      "offset": 3951.839,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "deep learning models and can be used to",
      "offset": 3954.16,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "transform data from multiple dimensions",
      "offset": 3957.119,
      "duration": 4.2
    },
    {
      "lang": "en",
      "text": "back down to two",
      "offset": 3959.52,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "dimensions They are useful for dealing",
      "offset": 3961.319,
      "duration": 7.121
    },
    {
      "lang": "en",
      "text": "with a time series data text data and",
      "offset": 3963.599,
      "duration": 7.52
    },
    {
      "lang": "en",
      "text": "images Now you can wrap your embedding",
      "offset": 3968.44,
      "duration": 5.639
    },
    {
      "lang": "en",
      "text": "layer in a model This will allow you to",
      "offset": 3971.119,
      "duration": 5.121
    },
    {
      "lang": "en",
      "text": "reuse the model for multiple inputs in",
      "offset": 3974.079,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "the data set",
      "offset": 3976.24,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "You do this by defining an input layer",
      "offset": 3978,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "and then an embedding layer then a",
      "offset": 3980.48,
      "duration": 3.72
    },
    {
      "lang": "en",
      "text": "flatten layer for the",
      "offset": 3982.72,
      "duration": 5.119
    },
    {
      "lang": "en",
      "text": "output Finally wrap the input tensor in",
      "offset": 3984.2,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "flatten tensor in a",
      "offset": 3987.839,
      "duration": 5.041
    },
    {
      "lang": "en",
      "text": "model This model can be treated exactly",
      "offset": 3989.96,
      "duration": 6.28
    },
    {
      "lang": "en",
      "text": "the same as a layer and reused inside of",
      "offset": 3992.88,
      "duration": 6.76
    },
    {
      "lang": "en",
      "text": "another model",
      "offset": 3996.24,
      "duration": 3.4
    },
    {
      "lang": "en",
      "text": "In this chapter you will create a model",
      "offset": 4000.16,
      "duration": 6.159
    },
    {
      "lang": "en",
      "text": "with two inputs one for each team in the",
      "offset": 4002.72,
      "duration": 5
    },
    {
      "lang": "en",
      "text": "basketball data",
      "offset": 4006.319,
      "duration": 5.201
    },
    {
      "lang": "en",
      "text": "set However you want these two teams to",
      "offset": 4007.72,
      "duration": 6.44
    },
    {
      "lang": "en",
      "text": "each use the same embedding layer you",
      "offset": 4011.52,
      "duration": 4.599
    },
    {
      "lang": "en",
      "text": "defined in the previous",
      "offset": 4014.16,
      "duration": 4.639
    },
    {
      "lang": "en",
      "text": "lesson Accomplishing this requires a",
      "offset": 4016.119,
      "duration": 4.761
    },
    {
      "lang": "en",
      "text": "shared layer",
      "offset": 4018.799,
      "duration": 4.481
    },
    {
      "lang": "en",
      "text": "Shared layers are an advanced deep",
      "offset": 4020.88,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "learning concept and are only possible",
      "offset": 4023.28,
      "duration": 5.16
    },
    {
      "lang": "en",
      "text": "with the CARIS functional",
      "offset": 4026.48,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "API They allow you to define an",
      "offset": 4028.44,
      "duration": 6.159
    },
    {
      "lang": "en",
      "text": "operation and then apply the exact same",
      "offset": 4030.88,
      "duration": 7.04
    },
    {
      "lang": "en",
      "text": "operation with the exact same weights on",
      "offset": 4034.599,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "different",
      "offset": 4037.92,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "inputs In this model we will share team",
      "offset": 4038.92,
      "duration": 5.639
    },
    {
      "lang": "en",
      "text": "rating for both inputs",
      "offset": 4042.079,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "The learned rating will be the same",
      "offset": 4044.559,
      "duration": 5.721
    },
    {
      "lang": "en",
      "text": "whether it applies to team one or team",
      "offset": 4046.799,
      "duration": 6.481
    },
    {
      "lang": "en",
      "text": "two To create a shared layer you must",
      "offset": 4050.28,
      "duration": 6.519
    },
    {
      "lang": "en",
      "text": "first create two or more inputs each of",
      "offset": 4053.28,
      "duration": 5.96
    },
    {
      "lang": "en",
      "text": "which will be passed to the shared",
      "offset": 4056.799,
      "duration": 6.681
    },
    {
      "lang": "en",
      "text": "layer In this case you will use two",
      "offset": 4059.24,
      "duration": 7.319
    },
    {
      "lang": "en",
      "text": "inputs Once you have two inputs the",
      "offset": 4063.48,
      "duration": 5.639
    },
    {
      "lang": "en",
      "text": "magic of the caris functional API",
      "offset": 4066.559,
      "duration": 4.881
    },
    {
      "lang": "en",
      "text": "becomes apparent",
      "offset": 4069.119,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "Recall from chapter 1 that the dense",
      "offset": 4071.44,
      "duration": 5.48
    },
    {
      "lang": "en",
      "text": "function returns a function as its",
      "offset": 4073.839,
      "duration": 6.561
    },
    {
      "lang": "en",
      "text": "output This function which dense outputs",
      "offset": 4076.92,
      "duration": 7.08
    },
    {
      "lang": "en",
      "text": "takes a tensor as input and produces a",
      "offset": 4080.4,
      "duration": 5.24
    },
    {
      "lang": "en",
      "text": "tensor as",
      "offset": 4084,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "output You can use the same dense",
      "offset": 4085.64,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "function to create a shared",
      "offset": 4088.319,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "layer Doing so is as simple as calling",
      "offset": 4091.16,
      "duration": 5.48
    },
    {
      "lang": "en",
      "text": "the function twice with a different",
      "offset": 4094.319,
      "duration": 5.601
    },
    {
      "lang": "en",
      "text": "input tensor each time",
      "offset": 4096.64,
      "duration": 5.519
    },
    {
      "lang": "en",
      "text": "Recall the category embedding model we",
      "offset": 4099.92,
      "duration": 4.359
    },
    {
      "lang": "en",
      "text": "made in the previous",
      "offset": 4102.159,
      "duration": 5.441
    },
    {
      "lang": "en",
      "text": "lesson This model first embeds an input",
      "offset": 4104.279,
      "duration": 6.681
    },
    {
      "lang": "en",
      "text": "and then flattens it You can also share",
      "offset": 4107.6,
      "duration": 6.719
    },
    {
      "lang": "en",
      "text": "models not just layers This is really",
      "offset": 4110.96,
      "duration": 5.839
    },
    {
      "lang": "en",
      "text": "cool and is what makes the functional",
      "offset": 4114.319,
      "duration": 6.561
    },
    {
      "lang": "en",
      "text": "API so useful You can define modular",
      "offset": 4116.799,
      "duration": 7.4
    },
    {
      "lang": "en",
      "text": "components of models and then reuse",
      "offset": 4120.88,
      "duration": 6.16
    },
    {
      "lang": "en",
      "text": "them We define an embedding layer and",
      "offset": 4124.199,
      "duration": 5
    },
    {
      "lang": "en",
      "text": "wrap it in a model",
      "offset": 4127.04,
      "duration": 4.799
    },
    {
      "lang": "en",
      "text": "We then define two input tensors and",
      "offset": 4129.199,
      "duration": 4.681
    },
    {
      "lang": "en",
      "text": "pass each one to the same model",
      "offset": 4131.839,
      "duration": 4.36
    },
    {
      "lang": "en",
      "text": "producing two output",
      "offset": 4133.88,
      "duration": 5
    },
    {
      "lang": "en",
      "text": "tensors This will use the same model",
      "offset": 4136.199,
      "duration": 4.681
    },
    {
      "lang": "en",
      "text": "with the same layers and the same",
      "offset": 4138.88,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "weights for mapping each input to its",
      "offset": 4140.88,
      "duration": 4.6
    },
    {
      "lang": "en",
      "text": "corresponding",
      "offset": 4143.92,
      "duration": 4.239
    },
    {
      "lang": "en",
      "text": "output In other words you can take an",
      "offset": 4145.48,
      "duration": 5.319
    },
    {
      "lang": "en",
      "text": "arbitrary sequence of caris layers and",
      "offset": 4148.159,
      "duration": 5.761
    },
    {
      "lang": "en",
      "text": "wrap them up in a model Once you have a",
      "offset": 4150.799,
      "duration": 6.241
    },
    {
      "lang": "en",
      "text": "model you can reuse that model to share",
      "offset": 4153.92,
      "duration": 5.279
    },
    {
      "lang": "en",
      "text": "that sequence of steps for different",
      "offset": 4157.04,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "input",
      "offset": 4159.199,
      "duration": 2.321
    },
    {
      "lang": "en",
      "text": "layers Now that you've got multiple",
      "offset": 4162.6,
      "duration": 5.48
    },
    {
      "lang": "en",
      "text": "inputs and a shared layer you need to",
      "offset": 4164.96,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "combine your inputs into a single layer",
      "offset": 4168.08,
      "duration": 5.079
    },
    {
      "lang": "en",
      "text": "that you can use to predict a single",
      "offset": 4170.56,
      "duration": 6.96
    },
    {
      "lang": "en",
      "text": "output This requires a merge layer Merge",
      "offset": 4173.159,
      "duration": 7.08
    },
    {
      "lang": "en",
      "text": "layers allow you to define advanced",
      "offset": 4177.52,
      "duration": 5.759
    },
    {
      "lang": "en",
      "text": "nonsequential network topologies",
      "offset": 4180.239,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "This can give you a lot of flexibility",
      "offset": 4183.279,
      "duration": 5.121
    },
    {
      "lang": "en",
      "text": "to creatively design networks to solve",
      "offset": 4185.359,
      "duration": 4.761
    },
    {
      "lang": "en",
      "text": "specific",
      "offset": 4188.4,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "problems There are many kinds of merge",
      "offset": 4190.12,
      "duration": 6.76
    },
    {
      "lang": "en",
      "text": "layers available in caris Add subtract",
      "offset": 4192.88,
      "duration": 7.4
    },
    {
      "lang": "en",
      "text": "and multiply layers do simple arithmetic",
      "offset": 4196.88,
      "duration": 6.08
    },
    {
      "lang": "en",
      "text": "operations by element on the input",
      "offset": 4200.28,
      "duration": 5.24
    },
    {
      "lang": "en",
      "text": "layers and require them to be the same",
      "offset": 4202.96,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "shape",
      "offset": 4205.52,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "For example if we wanted to multiply our",
      "offset": 4206.96,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "team strength ratings together we could",
      "offset": 4209.92,
      "duration": 4.04
    },
    {
      "lang": "en",
      "text": "use a multiply",
      "offset": 4212.56,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "layer Concatenate layers simply append",
      "offset": 4213.96,
      "duration": 6.04
    },
    {
      "lang": "en",
      "text": "the two layers together similar to the",
      "offset": 4217.12,
      "duration": 5
    },
    {
      "lang": "en",
      "text": "hstack function from",
      "offset": 4220,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "NumPy Unlike the other merge layers the",
      "offset": 4222.12,
      "duration": 6.2
    },
    {
      "lang": "en",
      "text": "concatenate layer can operate on layers",
      "offset": 4225.36,
      "duration": 6.64
    },
    {
      "lang": "en",
      "text": "with different numbers of columns",
      "offset": 4228.32,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "Let's build a simple caris model that",
      "offset": 4232,
      "duration": 4.84
    },
    {
      "lang": "en",
      "text": "takes in two numbers and adds them",
      "offset": 4234,
      "duration": 5.199
    },
    {
      "lang": "en",
      "text": "together You can accomplish this by",
      "offset": 4236.84,
      "duration": 5.24
    },
    {
      "lang": "en",
      "text": "defining two input layers and using the",
      "offset": 4239.199,
      "duration": 5.321
    },
    {
      "lang": "en",
      "text": "add layer to add them",
      "offset": 4242.08,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "together If you'd like to add together",
      "offset": 4244.52,
      "duration": 5.719
    },
    {
      "lang": "en",
      "text": "many inputs you can pass a list with",
      "offset": 4247.12,
      "duration": 5.64
    },
    {
      "lang": "en",
      "text": "more than two elements to an ad",
      "offset": 4250.239,
      "duration": 5.201
    },
    {
      "lang": "en",
      "text": "layer Note that all of the inputs are",
      "offset": 4252.76,
      "duration": 5.08
    },
    {
      "lang": "en",
      "text": "required to have the same shape so they",
      "offset": 4255.44,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "can be combined elementwise",
      "offset": 4257.84,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "These subtract and multiply layers work",
      "offset": 4260.96,
      "duration": 3.96
    },
    {
      "lang": "en",
      "text": "the same",
      "offset": 4263.52,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "way Now you can wrap the output from",
      "offset": 4264.92,
      "duration": 5.56
    },
    {
      "lang": "en",
      "text": "your ad layer inside a model which will",
      "offset": 4267.84,
      "duration": 4.6
    },
    {
      "lang": "en",
      "text": "then allow you to fit it to",
      "offset": 4270.48,
      "duration": 5.199
    },
    {
      "lang": "en",
      "text": "data Note that the model takes in a list",
      "offset": 4272.44,
      "duration": 6.96
    },
    {
      "lang": "en",
      "text": "of inputs because it has more than one",
      "offset": 4275.679,
      "duration": 6.56
    },
    {
      "lang": "en",
      "text": "input As with other caris models you",
      "offset": 4279.4,
      "duration": 5.88
    },
    {
      "lang": "en",
      "text": "need to compile it before fitting",
      "offset": 4282.239,
      "duration": 6.641
    },
    {
      "lang": "en",
      "text": "Use the atom optimizer and mean absolute",
      "offset": 4285.28,
      "duration": 6.399
    },
    {
      "lang": "en",
      "text": "error as a loss",
      "offset": 4288.88,
      "duration": 2.799
    },
    {
      "lang": "en",
      "text": "function Caris models with multiple",
      "offset": 4292.6,
      "duration": 4.92
    },
    {
      "lang": "en",
      "text": "inputs work just like caris models with",
      "offset": 4295.04,
      "duration": 6.159
    },
    {
      "lang": "en",
      "text": "a single input They use the same fit",
      "offset": 4297.52,
      "duration": 7.44
    },
    {
      "lang": "en",
      "text": "evaluate and predict methods The only",
      "offset": 4301.199,
      "duration": 6.161
    },
    {
      "lang": "en",
      "text": "difference is that all of these methods",
      "offset": 4304.96,
      "duration": 5.279
    },
    {
      "lang": "en",
      "text": "take a list of inputs rather than a",
      "offset": 4307.36,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "single input",
      "offset": 4310.239,
      "duration": 4.641
    },
    {
      "lang": "en",
      "text": "To fit a model with multiple inputs",
      "offset": 4312.56,
      "duration": 5.679
    },
    {
      "lang": "en",
      "text": "provide the model a list of inputs In",
      "offset": 4314.88,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "this case since you have two inputs the",
      "offset": 4318.239,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "model needs to have an input list of",
      "offset": 4320.64,
      "duration": 3.16
    },
    {
      "lang": "en",
      "text": "length",
      "offset": 4322.719,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "two You want to use this model to",
      "offset": 4323.8,
      "duration": 5.24
    },
    {
      "lang": "en",
      "text": "predict a single target So the target",
      "offset": 4326.32,
      "duration": 5.32
    },
    {
      "lang": "en",
      "text": "for training is still a single",
      "offset": 4329.04,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "object While this network is very simple",
      "offset": 4331.64,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "the concept it illustrates is quite",
      "offset": 4334.64,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "advanced",
      "offset": 4337.08,
      "duration": 3.72
    },
    {
      "lang": "en",
      "text": "Later in the course you will process",
      "offset": 4338.64,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "different inputs to the network in",
      "offset": 4340.8,
      "duration": 2.76
    },
    {
      "lang": "en",
      "text": "different",
      "offset": 4342.64,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "ways In other words multiple inputs let",
      "offset": 4343.56,
      "duration": 6.36
    },
    {
      "lang": "en",
      "text": "you do data prep-processing as part of",
      "offset": 4347.12,
      "duration": 4.84
    },
    {
      "lang": "en",
      "text": "the model you",
      "offset": 4349.92,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "learn To make predictions from a model",
      "offset": 4351.96,
      "duration": 5.88
    },
    {
      "lang": "en",
      "text": "with two inputs you also need to provide",
      "offset": 4354.64,
      "duration": 6.4
    },
    {
      "lang": "en",
      "text": "two inputs to the model's predict method",
      "offset": 4357.84,
      "duration": 6.48
    },
    {
      "lang": "en",
      "text": "again as a list In this case I've",
      "offset": 4361.04,
      "duration": 6.8
    },
    {
      "lang": "en",
      "text": "defined a model that adds numbers So in",
      "offset": 4364.32,
      "duration": 7.2
    },
    {
      "lang": "en",
      "text": "order to add one and two first convert",
      "offset": 4367.84,
      "duration": 7.92
    },
    {
      "lang": "en",
      "text": "one and two into 2D numpy arrays then",
      "offset": 4371.52,
      "duration": 7.52
    },
    {
      "lang": "en",
      "text": "pass one as the first input and two as",
      "offset": 4375.76,
      "duration": 4.2
    },
    {
      "lang": "en",
      "text": "the second",
      "offset": 4379.04,
      "duration": 3.96
    },
    {
      "lang": "en",
      "text": "input The model outputs",
      "offset": 4379.96,
      "duration": 5.88
    },
    {
      "lang": "en",
      "text": "three Note that the data type of the",
      "offset": 4383,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "output is float",
      "offset": 4385.84,
      "duration": 5.839
    },
    {
      "lang": "en",
      "text": "32 You can also add other numbers with",
      "offset": 4388.36,
      "duration": 7.2
    },
    {
      "lang": "en",
      "text": "this simple model for example 42 and",
      "offset": 4391.679,
      "duration": 7.321
    },
    {
      "lang": "en",
      "text": "119 which add up to",
      "offset": 4395.56,
      "duration": 6.28
    },
    {
      "lang": "en",
      "text": "161 To evaluate a model with multiple",
      "offset": 4399,
      "duration": 6.36
    },
    {
      "lang": "en",
      "text": "inputs simply give it a list of inputs",
      "offset": 4401.84,
      "duration": 6.64
    },
    {
      "lang": "en",
      "text": "along with a single output and the model",
      "offset": 4405.36,
      "duration": 5.799
    },
    {
      "lang": "en",
      "text": "will return its loss on the new",
      "offset": 4408.48,
      "duration": 5.92
    },
    {
      "lang": "en",
      "text": "data In this case since I've hardcoded",
      "offset": 4411.159,
      "duration": 6.121
    },
    {
      "lang": "en",
      "text": "the model to add the two inputs the",
      "offset": 4414.4,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "evaluation error on the test data is",
      "offset": 4417.28,
      "duration": 5.24
    },
    {
      "lang": "en",
      "text": "zero",
      "offset": 4419.52,
      "duration": 3
    },
    {
      "lang": "en",
      "text": "In this chapter you'll extend your",
      "offset": 4423.76,
      "duration": 6.2
    },
    {
      "lang": "en",
      "text": "twoinput model to three inputs and",
      "offset": 4426.32,
      "duration": 6.32
    },
    {
      "lang": "en",
      "text": "beyond This demonstrates the power of",
      "offset": 4429.96,
      "duration": 5.88
    },
    {
      "lang": "en",
      "text": "the CARIS functional API Once you have",
      "offset": 4432.64,
      "duration": 5.039
    },
    {
      "lang": "en",
      "text": "learned how to work with two input",
      "offset": 4435.84,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "networks it is trivial to extend that",
      "offset": 4437.679,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "knowledge to three or more input",
      "offset": 4440.159,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "networks",
      "offset": 4442.239,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "Making a caris model with three inputs",
      "offset": 4444.48,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "is almost exactly the same as making a",
      "offset": 4446.719,
      "duration": 6.96
    },
    {
      "lang": "en",
      "text": "caris model with two inputs To start",
      "offset": 4449.44,
      "duration": 7.36
    },
    {
      "lang": "en",
      "text": "create three different input layers In",
      "offset": 4453.679,
      "duration": 5.681
    },
    {
      "lang": "en",
      "text": "this case you'll use a concatenate layer",
      "offset": 4456.8,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "to combine the inputs but recall from",
      "offset": 4459.36,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "the previous chapters that you could",
      "offset": 4462.48,
      "duration": 5.32
    },
    {
      "lang": "en",
      "text": "also use an add or subtract",
      "offset": 4464.8,
      "duration": 6.16
    },
    {
      "lang": "en",
      "text": "layer In the concatenate layer simply",
      "offset": 4467.8,
      "duration": 6.399
    },
    {
      "lang": "en",
      "text": "pass a list of three inputs rather than",
      "offset": 4470.96,
      "duration": 6.96
    },
    {
      "lang": "en",
      "text": "two Finally add a dense layer to reduce",
      "offset": 4474.199,
      "duration": 6.641
    },
    {
      "lang": "en",
      "text": "the three inputs to a single",
      "offset": 4477.92,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "output When creating a model with three",
      "offset": 4480.84,
      "duration": 5.399
    },
    {
      "lang": "en",
      "text": "inputs simply pass a list with three",
      "offset": 4483.44,
      "duration": 5.799
    },
    {
      "lang": "en",
      "text": "input layers and one output",
      "offset": 4486.239,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "layer In the exercises for this chapter",
      "offset": 4489.239,
      "duration": 5.321
    },
    {
      "lang": "en",
      "text": "you will also practice using a shared",
      "offset": 4492.239,
      "duration": 4.561
    },
    {
      "lang": "en",
      "text": "layer in a model with more than two",
      "offset": 4494.56,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "inputs",
      "offset": 4496.8,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "For example you can pass the first two",
      "offset": 4498.32,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "inputs to a shared layer and then",
      "offset": 4500.88,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "concatenate the result of that shared",
      "offset": 4503.76,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "layer with the third input In other",
      "offset": 4506.08,
      "duration": 5.84
    },
    {
      "lang": "en",
      "text": "words you can define a caris model in",
      "offset": 4508.96,
      "duration": 6.239
    },
    {
      "lang": "en",
      "text": "any way you want This gives you a lot of",
      "offset": 4511.92,
      "duration": 5.92
    },
    {
      "lang": "en",
      "text": "flexibility to customize the model to",
      "offset": 4515.199,
      "duration": 4.681
    },
    {
      "lang": "en",
      "text": "the problem you want to",
      "offset": 4517.84,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "solve As before we pass the original",
      "offset": 4519.88,
      "duration": 6.359
    },
    {
      "lang": "en",
      "text": "three inputs to the model function when",
      "offset": 4523.28,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "creating a model",
      "offset": 4526.239,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "As with any caris model you must compile",
      "offset": 4528.96,
      "duration": 3.96
    },
    {
      "lang": "en",
      "text": "it before",
      "offset": 4531.679,
      "duration": 4.641
    },
    {
      "lang": "en",
      "text": "fitting During compilation you specify a",
      "offset": 4532.92,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "loss function and an",
      "offset": 4536.32,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "optimizer When fitting a threeinput",
      "offset": 4538.44,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "model provide a list with three input",
      "offset": 4540.96,
      "duration": 6.719
    },
    {
      "lang": "en",
      "text": "columns rather than two Since this model",
      "offset": 4543.8,
      "duration": 6.84
    },
    {
      "lang": "en",
      "text": "only has one output use a single output",
      "offset": 4547.679,
      "duration": 5.121
    },
    {
      "lang": "en",
      "text": "in your model",
      "offset": 4550.64,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "Similarly when evaluating your model on",
      "offset": 4552.8,
      "duration": 5.16
    },
    {
      "lang": "en",
      "text": "new data using",
      "offset": 4555.36,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "model.evaluate pass three inputs in a",
      "offset": 4557.96,
      "duration": 6.12
    },
    {
      "lang": "en",
      "text": "list and one",
      "offset": 4560.96,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "output In this lesson you will take a",
      "offset": 4564.679,
      "duration": 5.48
    },
    {
      "lang": "en",
      "text": "closer look at your threeinput model",
      "offset": 4567.6,
      "duration": 7.4
    },
    {
      "lang": "en",
      "text": "using Caris's built-in summary and plot",
      "offset": 4570.159,
      "duration": 7.601
    },
    {
      "lang": "en",
      "text": "methods Here is the summary for a Caris",
      "offset": 4575,
      "duration": 5.88
    },
    {
      "lang": "en",
      "text": "model The summary shows you all the",
      "offset": 4577.76,
      "duration": 6.28
    },
    {
      "lang": "en",
      "text": "layers in the model as well as how many",
      "offset": 4580.88,
      "duration": 5.48
    },
    {
      "lang": "en",
      "text": "parameters each layer",
      "offset": 4584.04,
      "duration": 6.28
    },
    {
      "lang": "en",
      "text": "has Importantly caris models can have",
      "offset": 4586.36,
      "duration": 6.76
    },
    {
      "lang": "en",
      "text": "non-trainable parameters that are fixed",
      "offset": 4590.32,
      "duration": 5.839
    },
    {
      "lang": "en",
      "text": "and do not change as well as trainable",
      "offset": 4593.12,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "parameters that are learned from the",
      "offset": 4596.159,
      "duration": 4.361
    },
    {
      "lang": "en",
      "text": "data when the model is",
      "offset": 4598.48,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "fit Models with more trainable",
      "offset": 4600.52,
      "duration": 6.199
    },
    {
      "lang": "en",
      "text": "parameters are typically more flexible",
      "offset": 4603.36,
      "duration": 6.52
    },
    {
      "lang": "en",
      "text": "This can also make them more prone to",
      "offset": 4606.719,
      "duration": 5.761
    },
    {
      "lang": "en",
      "text": "overfitting Models with fewer trainable",
      "offset": 4609.88,
      "duration": 5.16
    },
    {
      "lang": "en",
      "text": "parameters are less flexible but",
      "offset": 4612.48,
      "duration": 5.16
    },
    {
      "lang": "en",
      "text": "therefore less likely to",
      "offset": 4615.04,
      "duration": 6.199
    },
    {
      "lang": "en",
      "text": "overfit In this case the model has three",
      "offset": 4617.64,
      "duration": 6.599
    },
    {
      "lang": "en",
      "text": "inputs Since all three of them feed into",
      "offset": 4621.239,
      "duration": 6.241
    },
    {
      "lang": "en",
      "text": "one dense layer the model has four",
      "offset": 4624.239,
      "duration": 7.801
    },
    {
      "lang": "en",
      "text": "parameters one per input plus a bias or",
      "offset": 4627.48,
      "duration": 6.84
    },
    {
      "lang": "en",
      "text": "intercept All of these parameters are",
      "offset": 4632.04,
      "duration": 3.8
    },
    {
      "lang": "en",
      "text": "trainable",
      "offset": 4634.32,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "A model's trainable parameters are",
      "offset": 4635.84,
      "duration": 5.16
    },
    {
      "lang": "en",
      "text": "usually in its dense",
      "offset": 4638.239,
      "duration": 5.601
    },
    {
      "lang": "en",
      "text": "layers Here is the summary of a slightly",
      "offset": 4641,
      "duration": 6.12
    },
    {
      "lang": "en",
      "text": "more complicated model You can see that",
      "offset": 4643.84,
      "duration": 6.64
    },
    {
      "lang": "en",
      "text": "this model has an embedding layer Even",
      "offset": 4647.12,
      "duration": 5.92
    },
    {
      "lang": "en",
      "text": "though the dense layer still only has",
      "offset": 4650.48,
      "duration": 6.32
    },
    {
      "lang": "en",
      "text": "four parameters the model has many more",
      "offset": 4653.04,
      "duration": 6.08
    },
    {
      "lang": "en",
      "text": "trainable parameters because of the",
      "offset": 4656.8,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "embedding layer",
      "offset": 4659.12,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "It's important to remember that",
      "offset": 4661.04,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "embedding layers often add a very large",
      "offset": 4662.64,
      "duration": 6.12
    },
    {
      "lang": "en",
      "text": "number of trainable parameters to a",
      "offset": 4665.84,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "model Recall that embedding layers map",
      "offset": 4668.76,
      "duration": 6.52
    },
    {
      "lang": "en",
      "text": "integers to floats Each unique value of",
      "offset": 4671.84,
      "duration": 6.319
    },
    {
      "lang": "en",
      "text": "the embedding input gets a parameter for",
      "offset": 4675.28,
      "duration": 4.439
    },
    {
      "lang": "en",
      "text": "its",
      "offset": 4678.159,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "output Here is the plot for a very",
      "offset": 4679.719,
      "duration": 5.48
    },
    {
      "lang": "en",
      "text": "complicated model The box at the bottom",
      "offset": 4682.32,
      "duration": 4.879
    },
    {
      "lang": "en",
      "text": "of the image represents the model's",
      "offset": 4685.199,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "output",
      "offset": 4687.199,
      "duration": 4.361
    },
    {
      "lang": "en",
      "text": "In this case the model has one",
      "offset": 4688.719,
      "duration": 5.601
    },
    {
      "lang": "en",
      "text": "output Note that output layers have",
      "offset": 4691.56,
      "duration": 6.48
    },
    {
      "lang": "en",
      "text": "arrows coming in but no arrows going",
      "offset": 4694.32,
      "duration": 6.96
    },
    {
      "lang": "en",
      "text": "out The boxes in the middle of the image",
      "offset": 4698.04,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "represent intermediate steps in the",
      "offset": 4701.28,
      "duration": 6.16
    },
    {
      "lang": "en",
      "text": "model These boxes have arrows coming in",
      "offset": 4704.04,
      "duration": 6.04
    },
    {
      "lang": "en",
      "text": "and arrows going out",
      "offset": 4707.44,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "Note that this model has a shared model",
      "offset": 4710.08,
      "duration": 6.159
    },
    {
      "lang": "en",
      "text": "the team strength model which is applied",
      "offset": 4712.88,
      "duration": 6.799
    },
    {
      "lang": "en",
      "text": "to two of the inputs before they are",
      "offset": 4716.239,
      "duration": 6.161
    },
    {
      "lang": "en",
      "text": "combined in the concatenate layer with",
      "offset": 4719.679,
      "duration": 4.121
    },
    {
      "lang": "en",
      "text": "the third",
      "offset": 4722.4,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "input The boxes at the top of the image",
      "offset": 4723.8,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "represent the",
      "offset": 4726.8,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "inputs These boxes only have one arrow",
      "offset": 4728.6,
      "duration": 7.48
    },
    {
      "lang": "en",
      "text": "going out and none coming in",
      "offset": 4732,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "Here's another way of looking at the",
      "offset": 4736.08,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "same model using the network diagrams",
      "offset": 4737.76,
      "duration": 5.32
    },
    {
      "lang": "en",
      "text": "I've made for the previous chapters",
      "offset": 4740.239,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "models Shared models work exactly the",
      "offset": 4743.08,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "same as shared",
      "offset": 4746.239,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "layers This is a useful abstraction",
      "offset": 4747.64,
      "duration": 4.84
    },
    {
      "lang": "en",
      "text": "because you can put together a sequence",
      "offset": 4750.56,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "of layers to define a custom model and",
      "offset": 4752.48,
      "duration": 6.32
    },
    {
      "lang": "en",
      "text": "then share the entire model in exactly",
      "offset": 4756.08,
      "duration": 5
    },
    {
      "lang": "en",
      "text": "the same way you'd share a",
      "offset": 4758.8,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "layer It's a little prettier when you",
      "offset": 4761.08,
      "duration": 4.28
    },
    {
      "lang": "en",
      "text": "make them by hand",
      "offset": 4763.44,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "But the autoplotting function in caris",
      "offset": 4765.36,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "does a good job representing the actual",
      "offset": 4767.76,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "structure of the",
      "offset": 4770.64,
      "duration": 2.72
    },
    {
      "lang": "en",
      "text": "model In this video I will introduce you",
      "offset": 4774.92,
      "duration": 6.68
    },
    {
      "lang": "en",
      "text": "to the concept of model stacking or",
      "offset": 4778.159,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "using the predictions from one model as",
      "offset": 4781.6,
      "duration": 6.24
    },
    {
      "lang": "en",
      "text": "an input to another model Model stacking",
      "offset": 4784.159,
      "duration": 7.04
    },
    {
      "lang": "en",
      "text": "is a very advanced data science concept",
      "offset": 4787.84,
      "duration": 5.92
    },
    {
      "lang": "en",
      "text": "It is the most sophisticated way of",
      "offset": 4791.199,
      "duration": 6.161
    },
    {
      "lang": "en",
      "text": "combining models and when done right can",
      "offset": 4793.76,
      "duration": 6.08
    },
    {
      "lang": "en",
      "text": "yield some of the most accurate models",
      "offset": 4797.36,
      "duration": 3.48
    },
    {
      "lang": "en",
      "text": "in",
      "offset": 4799.84,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "existence Model stacking is often",
      "offset": 4800.84,
      "duration": 5.56
    },
    {
      "lang": "en",
      "text": "employed to win popular predictive",
      "offset": 4803.679,
      "duration": 4.281
    },
    {
      "lang": "en",
      "text": "modeling",
      "offset": 4806.4,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "competitions In this course you have",
      "offset": 4807.96,
      "duration": 5.239
    },
    {
      "lang": "en",
      "text": "been working with two data sets The",
      "offset": 4810.32,
      "duration": 4.879
    },
    {
      "lang": "en",
      "text": "college basketball data from the regular",
      "offset": 4813.199,
      "duration": 4.561
    },
    {
      "lang": "en",
      "text": "season and the college basketball data",
      "offset": 4815.199,
      "duration": 5.441
    },
    {
      "lang": "en",
      "text": "from the postseason tournament",
      "offset": 4817.76,
      "duration": 5.399
    },
    {
      "lang": "en",
      "text": "Both data sets contain the two teams",
      "offset": 4820.64,
      "duration": 6.4
    },
    {
      "lang": "en",
      "text": "playing whether team one is home or away",
      "offset": 4823.159,
      "duration": 6.08
    },
    {
      "lang": "en",
      "text": "and the score difference of the",
      "offset": 4827.04,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "games The tournament data set",
      "offset": 4829.239,
      "duration": 4.761
    },
    {
      "lang": "en",
      "text": "additionally contains the difference in",
      "offset": 4831.76,
      "duration": 5.24
    },
    {
      "lang": "en",
      "text": "seeds of the two teams",
      "offset": 4834,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "playing There's a lot more data on",
      "offset": 4837,
      "duration": 3.96
    },
    {
      "lang": "en",
      "text": "regular season games than there is on",
      "offset": 4839.28,
      "duration": 3.439
    },
    {
      "lang": "en",
      "text": "tournament games",
      "offset": 4840.96,
      "duration": 4.239
    },
    {
      "lang": "en",
      "text": "The regular season data set has over",
      "offset": 4842.719,
      "duration": 5.601
    },
    {
      "lang": "en",
      "text": "300,000 rows but the tournament data set",
      "offset": 4845.199,
      "duration": 7.281
    },
    {
      "lang": "en",
      "text": "has only about 4,000 rows 4,000 rows of",
      "offset": 4848.32,
      "duration": 7.04
    },
    {
      "lang": "en",
      "text": "data is pretty small Recall that our",
      "offset": 4852.48,
      "duration": 6.56
    },
    {
      "lang": "en",
      "text": "embedding layer has about 11,000 inputs",
      "offset": 4855.36,
      "duration": 6.48
    },
    {
      "lang": "en",
      "text": "4,000 rows of data is not enough to",
      "offset": 4859.04,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "learn all 11,000 parameters in our",
      "offset": 4861.84,
      "duration": 3.879
    },
    {
      "lang": "en",
      "text": "embedding",
      "offset": 4864.56,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "layer In the previous lesson you built a",
      "offset": 4865.719,
      "duration": 5.321
    },
    {
      "lang": "en",
      "text": "threeinput model on the regular season",
      "offset": 4868.719,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "data",
      "offset": 4871.04,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "You can reuse this model to add",
      "offset": 4872.4,
      "duration": 3.759
    },
    {
      "lang": "en",
      "text": "predictions from the regular season",
      "offset": 4874.48,
      "duration": 4.759
    },
    {
      "lang": "en",
      "text": "model to the tournament data",
      "offset": 4876.159,
      "duration": 6.641
    },
    {
      "lang": "en",
      "text": "set This diagram shows the process for",
      "offset": 4879.239,
      "duration": 6.44
    },
    {
      "lang": "en",
      "text": "stacking these two models You start with",
      "offset": 4882.8,
      "duration": 5.439
    },
    {
      "lang": "en",
      "text": "the regular season data set and fit a",
      "offset": 4885.679,
      "duration": 5.841
    },
    {
      "lang": "en",
      "text": "model to it You then predict on the",
      "offset": 4888.239,
      "duration": 6.96
    },
    {
      "lang": "en",
      "text": "tournament data set using this model",
      "offset": 4891.52,
      "duration": 6.04
    },
    {
      "lang": "en",
      "text": "This gives you predicted tournament",
      "offset": 4895.199,
      "duration": 4.881
    },
    {
      "lang": "en",
      "text": "outcomes which you can now use to build",
      "offset": 4897.56,
      "duration": 5.84
    },
    {
      "lang": "en",
      "text": "a better model of the actual tournament",
      "offset": 4900.08,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "outcomes You additionally use the",
      "offset": 4903.4,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "tournament seeds when modeling the",
      "offset": 4905.52,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "tournament These tournament seeds come",
      "offset": 4908.04,
      "duration": 5
    },
    {
      "lang": "en",
      "text": "from a committee and are intended to",
      "offset": 4910.4,
      "duration": 5.839
    },
    {
      "lang": "en",
      "text": "like your model capture each team's",
      "offset": 4913.04,
      "duration": 5.679
    },
    {
      "lang": "en",
      "text": "strength without using an embedding",
      "offset": 4916.239,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "layer",
      "offset": 4918.719,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "The tournament seeds can be thought of",
      "offset": 4920.239,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "as a simplified version of your team",
      "offset": 4922.32,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "strength model determined by a human",
      "offset": 4924.639,
      "duration": 5.08
    },
    {
      "lang": "en",
      "text": "rather than a",
      "offset": 4927.92,
      "duration": 4.239
    },
    {
      "lang": "en",
      "text": "computer The prediction from the regular",
      "offset": 4929.719,
      "duration": 4.44
    },
    {
      "lang": "en",
      "text": "season model captures the effects of",
      "offset": 4932.159,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "team one and team two which means you",
      "offset": 4934.159,
      "duration": 4.961
    },
    {
      "lang": "en",
      "text": "now don't need to use those two",
      "offset": 4937.199,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "variables in the tournament model and",
      "offset": 4939.12,
      "duration": 6.16
    },
    {
      "lang": "en",
      "text": "can avoid the use of an embedding layer",
      "offset": 4941.6,
      "duration": 5.599
    },
    {
      "lang": "en",
      "text": "You can focus your modeling efforts on",
      "offset": 4945.28,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "the purely numeric data which is a",
      "offset": 4947.199,
      "duration": 5.361
    },
    {
      "lang": "en",
      "text": "little easier to work with With purely",
      "offset": 4949.84,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "numeric inputs you can pass all of them",
      "offset": 4952.56,
      "duration": 3.96
    },
    {
      "lang": "en",
      "text": "to a single input",
      "offset": 4954.88,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "layer In other words an input layer with",
      "offset": 4956.52,
      "duration": 5
    },
    {
      "lang": "en",
      "text": "a shape of three is another way of",
      "offset": 4959.36,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "defining a threeinput model The only",
      "offset": 4961.52,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "drawback of this approach is that all",
      "offset": 4964.8,
      "duration": 4.6
    },
    {
      "lang": "en",
      "text": "the inputs must be",
      "offset": 4966.96,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "numeric A huge advantage of this",
      "offset": 4969.4,
      "duration": 5.239
    },
    {
      "lang": "en",
      "text": "approach is simplicity You can create a",
      "offset": 4971.76,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "model with a single input tensor and an",
      "offset": 4974.639,
      "duration": 5.121
    },
    {
      "lang": "en",
      "text": "output tensor and fit it using a single",
      "offset": 4976.96,
      "duration": 6.56
    },
    {
      "lang": "en",
      "text": "data set Similarly evaluating the model",
      "offset": 4979.76,
      "duration": 7.16
    },
    {
      "lang": "en",
      "text": "requires a single data set rather than a",
      "offset": 4983.52,
      "duration": 6.8
    },
    {
      "lang": "en",
      "text": "list As you can see this stacked model",
      "offset": 4986.92,
      "duration": 7
    },
    {
      "lang": "en",
      "text": "is pretty accurate It's off on average",
      "offset": 4990.32,
      "duration": 7.04
    },
    {
      "lang": "en",
      "text": "by about nine points in a given game",
      "offset": 4993.92,
      "duration": 6.64
    },
    {
      "lang": "en",
      "text": "To recap stacking caris models means",
      "offset": 4997.36,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "using the predictions from one model as",
      "offset": 5000.56,
      "duration": 5.119
    },
    {
      "lang": "en",
      "text": "an input to the second model When",
      "offset": 5002.96,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "stacking it's important to use different",
      "offset": 5005.679,
      "duration": 5.121
    },
    {
      "lang": "en",
      "text": "data sets for each model In this case",
      "offset": 5007.84,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "you use the regular season data for one",
      "offset": 5010.8,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "model and the tournament data set for",
      "offset": 5012.96,
      "duration": 3.16
    },
    {
      "lang": "en",
      "text": "the second",
      "offset": 5015.199,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "model Finally if your input data set is",
      "offset": 5016.12,
      "duration": 5.48
    },
    {
      "lang": "en",
      "text": "purely numeric you can put multiple",
      "offset": 5019.28,
      "duration": 7
    },
    {
      "lang": "en",
      "text": "inputs in a single input layer",
      "offset": 5021.6,
      "duration": 4.68
    },
    {
      "lang": "en",
      "text": "In this chapter I will cover neural",
      "offset": 5027.36,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "networks with two outputs These sorts of",
      "offset": 5029.76,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "networks make predictions for two",
      "offset": 5033.12,
      "duration": 5.039
    },
    {
      "lang": "en",
      "text": "targets at once For example you could",
      "offset": 5035.04,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "use a single model to predict the scores",
      "offset": 5038.159,
      "duration": 5.121
    },
    {
      "lang": "en",
      "text": "of both teams in a basketball game or",
      "offset": 5040.56,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "use a single model to predict both the",
      "offset": 5043.28,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "score difference and the win loss",
      "offset": 5045.36,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "outcome of that game",
      "offset": 5047.199,
      "duration": 4.641
    },
    {
      "lang": "en",
      "text": "To me this is the most interesting",
      "offset": 5049.52,
      "duration": 4.639
    },
    {
      "lang": "en",
      "text": "chapter in the class because it teaches",
      "offset": 5051.84,
      "duration": 4.68
    },
    {
      "lang": "en",
      "text": "you things that only neural networks can",
      "offset": 5054.159,
      "duration": 5.121
    },
    {
      "lang": "en",
      "text": "do At the end of the chapter I will show",
      "offset": 5056.52,
      "duration": 4.6
    },
    {
      "lang": "en",
      "text": "you how to make a single model that is",
      "offset": 5059.28,
      "duration": 5
    },
    {
      "lang": "en",
      "text": "both a classifier and a",
      "offset": 5061.12,
      "duration": 5.519
    },
    {
      "lang": "en",
      "text": "regressor To create a model with two",
      "offset": 5064.28,
      "duration": 5.48
    },
    {
      "lang": "en",
      "text": "outputs we start with an input layer As",
      "offset": 5066.639,
      "duration": 6.161
    },
    {
      "lang": "en",
      "text": "with all caris models in this example",
      "offset": 5069.76,
      "duration": 5.439
    },
    {
      "lang": "en",
      "text": "there is only one predictor So I use an",
      "offset": 5072.8,
      "duration": 4.28
    },
    {
      "lang": "en",
      "text": "input layer with one",
      "offset": 5075.199,
      "duration": 4.801
    },
    {
      "lang": "en",
      "text": "input To make a two output model I",
      "offset": 5077.08,
      "duration": 5.559
    },
    {
      "lang": "en",
      "text": "simply make a dense layer with two units",
      "offset": 5080,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "for the output layer The model will now",
      "offset": 5082.639,
      "duration": 4.761
    },
    {
      "lang": "en",
      "text": "make two",
      "offset": 5085.52,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "predictions Contrast this model with",
      "offset": 5087.4,
      "duration": 4.839
    },
    {
      "lang": "en",
      "text": "models from previous chapters which all",
      "offset": 5089.679,
      "duration": 5.361
    },
    {
      "lang": "en",
      "text": "had single outputs and therefore dense",
      "offset": 5092.239,
      "duration": 6.161
    },
    {
      "lang": "en",
      "text": "output layers with a single unit",
      "offset": 5095.04,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "The only difference between the two",
      "offset": 5098.4,
      "duration": 3.759
    },
    {
      "lang": "en",
      "text": "output model and the one output model is",
      "offset": 5099.92,
      "duration": 4.84
    },
    {
      "lang": "en",
      "text": "the size of the output",
      "offset": 5102.159,
      "duration": 5.841
    },
    {
      "lang": "en",
      "text": "layer The API for creating a two output",
      "offset": 5104.76,
      "duration": 6.28
    },
    {
      "lang": "en",
      "text": "model in compiling it is exactly the",
      "offset": 5108,
      "duration": 6.239
    },
    {
      "lang": "en",
      "text": "same as for a single output model Wrap",
      "offset": 5111.04,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "the input and output tensors in your",
      "offset": 5114.239,
      "duration": 5.041
    },
    {
      "lang": "en",
      "text": "call to model and then compile it using",
      "offset": 5116.32,
      "duration": 6.28
    },
    {
      "lang": "en",
      "text": "the atom optimizer and mean absolute",
      "offset": 5119.28,
      "duration": 6.08
    },
    {
      "lang": "en",
      "text": "error To fit a model with two outputs",
      "offset": 5122.6,
      "duration": 4.84
    },
    {
      "lang": "en",
      "text": "you use a data set with two columns for",
      "offset": 5125.36,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "the Y variable In this case the training",
      "offset": 5127.44,
      "duration": 5.48
    },
    {
      "lang": "en",
      "text": "set has the seed difference for the two",
      "offset": 5130.8,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "teams as well as the team's scores for",
      "offset": 5132.92,
      "duration": 6.2
    },
    {
      "lang": "en",
      "text": "the game The model's single input is",
      "offset": 5136,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "seed difference and the two outputs are",
      "offset": 5139.12,
      "duration": 4.2
    },
    {
      "lang": "en",
      "text": "the scores for each",
      "offset": 5141.52,
      "duration": 5.119
    },
    {
      "lang": "en",
      "text": "team The fit call is then exactly the",
      "offset": 5143.32,
      "duration": 5.96
    },
    {
      "lang": "en",
      "text": "same as a single input single output",
      "offset": 5146.639,
      "duration": 5.281
    },
    {
      "lang": "en",
      "text": "model The difference is that the y",
      "offset": 5149.28,
      "duration": 5.32
    },
    {
      "lang": "en",
      "text": "variable has two columns",
      "offset": 5151.92,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "Now this particular model takes a while",
      "offset": 5154.6,
      "duration": 6.32
    },
    {
      "lang": "en",
      "text": "to converge So I use 500 epochs in the",
      "offset": 5157.44,
      "duration": 6.799
    },
    {
      "lang": "en",
      "text": "fit For the exercises you will use some",
      "offset": 5160.92,
      "duration": 5.48
    },
    {
      "lang": "en",
      "text": "additional data in the model that will",
      "offset": 5164.239,
      "duration": 4.521
    },
    {
      "lang": "en",
      "text": "help it converge",
      "offset": 5166.4,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "faster Now that the model is fit you can",
      "offset": 5168.76,
      "duration": 6.36
    },
    {
      "lang": "en",
      "text": "take a look at what it learned The dense",
      "offset": 5171.92,
      "duration": 7.04
    },
    {
      "lang": "en",
      "text": "layer has two weights and two biases The",
      "offset": 5175.12,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "weights indicate that each additional",
      "offset": 5178.96,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "unit of seed difference for the input",
      "offset": 5181.12,
      "duration": 4.2
    },
    {
      "lang": "en",
      "text": "data equals",
      "offset": 5183.52,
      "duration": 5.119
    },
    {
      "lang": "en",
      "text": "about60 additional points for team one",
      "offset": 5185.32,
      "duration": 7.56
    },
    {
      "lang": "en",
      "text": "and 60 fewer points for team two The",
      "offset": 5188.639,
      "duration": 7.121
    },
    {
      "lang": "en",
      "text": "bias or intercept term for each team is",
      "offset": 5192.88,
      "duration": 6.08
    },
    {
      "lang": "en",
      "text": "about 70 points indicating that we",
      "offset": 5195.76,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "expect an average basketball team to",
      "offset": 5198.96,
      "duration": 5.759
    },
    {
      "lang": "en",
      "text": "score about 70 points in an average game",
      "offset": 5201.28,
      "duration": 5.84
    },
    {
      "lang": "en",
      "text": "In other words two teams with a",
      "offset": 5204.719,
      "duration": 4.561
    },
    {
      "lang": "en",
      "text": "one-point seed difference would be",
      "offset": 5207.12,
      "duration": 5.48
    },
    {
      "lang": "en",
      "text": "expected to have a score of about 69 to",
      "offset": 5209.28,
      "duration": 6.72
    },
    {
      "lang": "en",
      "text": "71 while two teams with a 10point seed",
      "offset": 5212.6,
      "duration": 5.24
    },
    {
      "lang": "en",
      "text": "difference would be expected to have a",
      "offset": 5216,
      "duration": 6.08
    },
    {
      "lang": "en",
      "text": "score of about 64 to 76",
      "offset": 5217.84,
      "duration": 6.799
    },
    {
      "lang": "en",
      "text": "Evaluating a model with two outputs is",
      "offset": 5222.08,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "very similar to evaluating a model with",
      "offset": 5224.639,
      "duration": 4.881
    },
    {
      "lang": "en",
      "text": "one output except you provide the",
      "offset": 5226.96,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "evaluation function a data set with two",
      "offset": 5229.52,
      "duration": 4.76
    },
    {
      "lang": "en",
      "text": "columns of data for the",
      "offset": 5232.32,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "target In this case the model performs",
      "offset": 5234.28,
      "duration": 5.399
    },
    {
      "lang": "en",
      "text": "reasonably well on the test set but in",
      "offset": 5237.36,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "the exercises you will add some more",
      "offset": 5239.679,
      "duration": 6.921
    },
    {
      "lang": "en",
      "text": "data to get better predictions",
      "offset": 5242.4,
      "duration": 4.2
    },
    {
      "lang": "en",
      "text": "In this lesson I will demonstrate how to",
      "offset": 5247.36,
      "duration": 5.56
    },
    {
      "lang": "en",
      "text": "build a simple model that performs both",
      "offset": 5249.92,
      "duration": 5.239
    },
    {
      "lang": "en",
      "text": "classification and",
      "offset": 5252.92,
      "duration": 4.84
    },
    {
      "lang": "en",
      "text": "regression This is another example of a",
      "offset": 5255.159,
      "duration": 5.321
    },
    {
      "lang": "en",
      "text": "model with two outputs In this case",
      "offset": 5257.76,
      "duration": 5.439
    },
    {
      "lang": "en",
      "text": "however rather than using two regression",
      "offset": 5260.48,
      "duration": 5.84
    },
    {
      "lang": "en",
      "text": "outputs I have a regression output and a",
      "offset": 5263.199,
      "duration": 6.721
    },
    {
      "lang": "en",
      "text": "classification output As before I define",
      "offset": 5266.32,
      "duration": 5.919
    },
    {
      "lang": "en",
      "text": "the regression part of this model with a",
      "offset": 5269.92,
      "duration": 4.799
    },
    {
      "lang": "en",
      "text": "single input and a dense output layer",
      "offset": 5272.239,
      "duration": 3.641
    },
    {
      "lang": "en",
      "text": "with a single",
      "offset": 5274.719,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "unit For the classification part of the",
      "offset": 5275.88,
      "duration": 5
    },
    {
      "lang": "en",
      "text": "model I use the regression model",
      "offset": 5278.639,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "prediction as input and then add another",
      "offset": 5280.88,
      "duration": 6.16
    },
    {
      "lang": "en",
      "text": "dense output layer on top of it using",
      "offset": 5284.159,
      "duration": 4.201
    },
    {
      "lang": "en",
      "text": "the sigmoid",
      "offset": 5287.04,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "activation which will map the predicted",
      "offset": 5288.36,
      "duration": 5.24
    },
    {
      "lang": "en",
      "text": "score differences to probabilities that",
      "offset": 5290.96,
      "duration": 5.199
    },
    {
      "lang": "en",
      "text": "team one wins",
      "offset": 5293.6,
      "duration": 5.599
    },
    {
      "lang": "en",
      "text": "With two output models each output needs",
      "offset": 5296.159,
      "duration": 4.441
    },
    {
      "lang": "en",
      "text": "its own loss",
      "offset": 5299.199,
      "duration": 4.881
    },
    {
      "lang": "en",
      "text": "function For this model I've specified",
      "offset": 5300.6,
      "duration": 5.96
    },
    {
      "lang": "en",
      "text": "two different loss functions One for the",
      "offset": 5304.08,
      "duration": 4.559
    },
    {
      "lang": "en",
      "text": "regression model and one for the",
      "offset": 5306.56,
      "duration": 3.56
    },
    {
      "lang": "en",
      "text": "classification",
      "offset": 5308.639,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "model As with all the models in this",
      "offset": 5310.12,
      "duration": 5.84
    },
    {
      "lang": "en",
      "text": "course I used Adam for the",
      "offset": 5312.719,
      "duration": 5.601
    },
    {
      "lang": "en",
      "text": "optimizer To fit the combination",
      "offset": 5315.96,
      "duration": 4.6
    },
    {
      "lang": "en",
      "text": "classification regression model you must",
      "offset": 5318.32,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "provide the Y data as a list",
      "offset": 5320.56,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "Recall that this is similar to the way",
      "offset": 5323.84,
      "duration": 5.24
    },
    {
      "lang": "en",
      "text": "you built two input models in chapter",
      "offset": 5325.6,
      "duration": 6.639
    },
    {
      "lang": "en",
      "text": "2 Use seed difference as the only input",
      "offset": 5329.08,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "to this",
      "offset": 5332.239,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "model For the regression output I use",
      "offset": 5333.239,
      "duration": 4.521
    },
    {
      "lang": "en",
      "text": "score difference And for the",
      "offset": 5336.159,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "classification output I use whether or",
      "offset": 5337.76,
      "duration": 6.08
    },
    {
      "lang": "en",
      "text": "not team one won the game I split both",
      "offset": 5340.08,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "of these variables out from the training",
      "offset": 5343.84,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "set and pass them to the fit method as a",
      "offset": 5345.6,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "list",
      "offset": 5348.159,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "This model fits a bit more quickly than",
      "offset": 5349.679,
      "duration": 5.641
    },
    {
      "lang": "en",
      "text": "the last one so I only use 100",
      "offset": 5351.679,
      "duration": 6.321
    },
    {
      "lang": "en",
      "text": "epochs This model's weight structure is",
      "offset": 5355.32,
      "duration": 5
    },
    {
      "lang": "en",
      "text": "a bit different from the last model",
      "offset": 5358,
      "duration": 5.159
    },
    {
      "lang": "en",
      "text": "where both outputs were regression",
      "offset": 5360.32,
      "duration": 5.8
    },
    {
      "lang": "en",
      "text": "targets The first layer has a weight of",
      "offset": 5363.159,
      "duration": 5.761
    },
    {
      "lang": "en",
      "text": "1.24 and a bias of almost",
      "offset": 5366.12,
      "duration": 5.559
    },
    {
      "lang": "en",
      "text": "zero This means that a one unitit change",
      "offset": 5368.92,
      "duration": 5.16
    },
    {
      "lang": "en",
      "text": "in the team's seed difference yields",
      "offset": 5371.679,
      "duration": 5.281
    },
    {
      "lang": "en",
      "text": "about 1.24 additional points in their",
      "offset": 5374.08,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "score difference",
      "offset": 5376.96,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "So two teams with a seed difference of",
      "offset": 5378.8,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "one would be expected to have team one",
      "offset": 5380.8,
      "duration": 6.72
    },
    {
      "lang": "en",
      "text": "win by 1.2 points but two teams with a",
      "offset": 5383.84,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "seed difference of 10 would be expected",
      "offset": 5387.52,
      "duration": 5.8
    },
    {
      "lang": "en",
      "text": "to have team one win by 12",
      "offset": 5389.84,
      "duration": 6.319
    },
    {
      "lang": "en",
      "text": "points The next layer maps predicted",
      "offset": 5393.32,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "score difference to predicted win",
      "offset": 5396.159,
      "duration": 5.361
    },
    {
      "lang": "en",
      "text": "loss Recall that the final layer in the",
      "offset": 5398.84,
      "duration": 6.359
    },
    {
      "lang": "en",
      "text": "model uses sigmoid activation",
      "offset": 5401.52,
      "duration": 5.679
    },
    {
      "lang": "en",
      "text": "You can manually calculate the final",
      "offset": 5405.199,
      "duration": 4.561
    },
    {
      "lang": "en",
      "text": "layer in the model for some example data",
      "offset": 5407.199,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "to get an understanding of how the model",
      "offset": 5409.76,
      "duration": 4.959
    },
    {
      "lang": "en",
      "text": "has learned to relate score difference",
      "offset": 5412.239,
      "duration": 4.041
    },
    {
      "lang": "en",
      "text": "to win",
      "offset": 5414.719,
      "duration": 4.761
    },
    {
      "lang": "en",
      "text": "probabilities Sci has a function called",
      "offset": 5416.28,
      "duration": 6.04
    },
    {
      "lang": "en",
      "text": "XIT which is an efficient implementation",
      "offset": 5419.48,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "of the sigmoid",
      "offset": 5422.32,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "function Let's manually calculate the",
      "offset": 5423.8,
      "duration": 4.6
    },
    {
      "lang": "en",
      "text": "win probability for two teams that are",
      "offset": 5426.32,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "predicted to have a score difference of",
      "offset": 5428.4,
      "duration": 3.319
    },
    {
      "lang": "en",
      "text": "one",
      "offset": 5430,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "First multiply one by the weight for the",
      "offset": 5431.719,
      "duration": 6.641
    },
    {
      "lang": "en",
      "text": "final layer in the model",
      "offset": 5434.96,
      "duration": 8.56
    },
    {
      "lang": "en",
      "text": "0.14 Add the bias for the final layer",
      "offset": 5438.36,
      "duration": 5.16
    },
    {
      "lang": "en",
      "text": "0.7 Since the bias is very close to zero",
      "offset": 5443.719,
      "duration": 6.241
    },
    {
      "lang": "en",
      "text": "the result is still",
      "offset": 5447.12,
      "duration": 5.92
    },
    {
      "lang": "en",
      "text": "0.14 Finally we can apply the sigmoid",
      "offset": 5449.96,
      "duration": 5.88
    },
    {
      "lang": "en",
      "text": "function to 0.14 which yields a",
      "offset": 5453.04,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "prediction of 0.54",
      "offset": 5455.84,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "In other words the model has learned",
      "offset": 5458.56,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "that an expected score difference of one",
      "offset": 5460.56,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "point is equal to an expected win",
      "offset": 5462.8,
      "duration": 5
    },
    {
      "lang": "en",
      "text": "probability of",
      "offset": 5465.44,
      "duration": 5.199
    },
    {
      "lang": "en",
      "text": "54% Finally you can evaluate the model",
      "offset": 5467.8,
      "duration": 6.76
    },
    {
      "lang": "en",
      "text": "on new data First split the evaluation",
      "offset": 5470.639,
      "duration": 6.401
    },
    {
      "lang": "en",
      "text": "data set into a regression target and a",
      "offset": 5474.56,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "classification target and provide the",
      "offset": 5477.04,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "same list of two targets to the evaluate",
      "offset": 5479.76,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "method",
      "offset": 5482.4,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "This outputs three numbers now instead",
      "offset": 5484.08,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "of one as with the models we looked at",
      "offset": 5486.719,
      "duration": 2.841
    },
    {
      "lang": "en",
      "text": "in other",
      "offset": 5488.56,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "chapters The first number is the loss",
      "offset": 5489.56,
      "duration": 5.72
    },
    {
      "lang": "en",
      "text": "function used by the model which is the",
      "offset": 5492.4,
      "duration": 5.319
    },
    {
      "lang": "en",
      "text": "sum of all the output",
      "offset": 5495.28,
      "duration": 5.359
    },
    {
      "lang": "en",
      "text": "losses The second number is the loss for",
      "offset": 5497.719,
      "duration": 5.96
    },
    {
      "lang": "en",
      "text": "the regression part of the model And the",
      "offset": 5500.639,
      "duration": 4.801
    },
    {
      "lang": "en",
      "text": "third number is the loss for the",
      "offset": 5503.679,
      "duration": 3.641
    },
    {
      "lang": "en",
      "text": "classification part of the",
      "offset": 5505.44,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "model So our model has a mean absolute",
      "offset": 5507.32,
      "duration": 7.08
    },
    {
      "lang": "en",
      "text": "error of 9.28 28 and a log loss of 0.58",
      "offset": 5510.48,
      "duration": 6.239
    },
    {
      "lang": "en",
      "text": "which is pretty good but I think you can",
      "offset": 5514.4,
      "duration": 4.799
    },
    {
      "lang": "en",
      "text": "do better with more data when you try",
      "offset": 5516.719,
      "duration": 4.641
    },
    {
      "lang": "en",
      "text": "for",
      "offset": 5519.199,
      "duration": 2.161
    },
    {
      "lang": "en",
      "text": "yourself In this course I've tried to",
      "offset": 5522.6,
      "duration": 5.24
    },
    {
      "lang": "en",
      "text": "focus on designing network topologies",
      "offset": 5525.52,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "that can be used to solve interesting",
      "offset": 5527.84,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "problems",
      "offset": 5530,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "You learned how to build functional",
      "offset": 5531.679,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "caris models including advanced topics",
      "offset": 5533.28,
      "duration": 5.72
    },
    {
      "lang": "en",
      "text": "such as shared layers categorical",
      "offset": 5536.08,
      "duration": 6.36
    },
    {
      "lang": "en",
      "text": "embeddings multiple inputs and multiple",
      "offset": 5539,
      "duration": 6.04
    },
    {
      "lang": "en",
      "text": "outputs You can now build a model",
      "offset": 5542.44,
      "duration": 5.08
    },
    {
      "lang": "en",
      "text": "capable of solving a regression and a",
      "offset": 5545.04,
      "duration": 5.56
    },
    {
      "lang": "en",
      "text": "classification problem",
      "offset": 5547.52,
      "duration": 5.679
    },
    {
      "lang": "en",
      "text": "simultaneously In this final video I'd",
      "offset": 5550.6,
      "duration": 4.599
    },
    {
      "lang": "en",
      "text": "like to discuss some real world use",
      "offset": 5553.199,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "cases of what you've learned",
      "offset": 5555.199,
      "duration": 5.601
    },
    {
      "lang": "en",
      "text": "Shared layers are incredibly useful when",
      "offset": 5558.239,
      "duration": 4.44
    },
    {
      "lang": "en",
      "text": "you want to compare two",
      "offset": 5560.8,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "things For example we compared two",
      "offset": 5562.679,
      "duration": 5.721
    },
    {
      "lang": "en",
      "text": "basketball teams to decide how different",
      "offset": 5566,
      "duration": 4.719
    },
    {
      "lang": "en",
      "text": "they were and their ability to score",
      "offset": 5568.4,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "points in a basketball game using a",
      "offset": 5570.719,
      "duration": 5.681
    },
    {
      "lang": "en",
      "text": "shared embedding model",
      "offset": 5573.44,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "In academic research shared models are",
      "offset": 5576.4,
      "duration": 6.08
    },
    {
      "lang": "en",
      "text": "known as Siamese networks which are used",
      "offset": 5579.12,
      "duration": 6.119
    },
    {
      "lang": "en",
      "text": "to calculate things like document",
      "offset": 5582.48,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "similarity using a shared embedding",
      "offset": 5585.239,
      "duration": 5.721
    },
    {
      "lang": "en",
      "text": "layer and a shared long short-term",
      "offset": 5587.84,
      "duration": 6.48
    },
    {
      "lang": "en",
      "text": "memory layer or LSTM layer and then",
      "offset": 5590.96,
      "duration": 6.4
    },
    {
      "lang": "en",
      "text": "comparing the LSTM outputs",
      "offset": 5594.32,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "Since both documents are encoded with",
      "offset": 5597.36,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "the same embedding layer and the same",
      "offset": 5599.36,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "LSTM layer the model learns a",
      "offset": 5601.04,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "representation of the documents that can",
      "offset": 5603.92,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "be used to compare them Here are some",
      "offset": 5606,
      "duration": 5
    },
    {
      "lang": "en",
      "text": "links to further",
      "offset": 5609.12,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "reading Multiple input networks are",
      "offset": 5611,
      "duration": 5.08
    },
    {
      "lang": "en",
      "text": "especially useful when you want to",
      "offset": 5613.76,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "process different types of data within",
      "offset": 5616.08,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "your model",
      "offset": 5618,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "For example in our basketball models we",
      "offset": 5619.6,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "process team IDs separately using an",
      "offset": 5622.08,
      "duration": 6.32
    },
    {
      "lang": "en",
      "text": "embedding layer For numeric data such as",
      "offset": 5624.96,
      "duration": 6.239
    },
    {
      "lang": "en",
      "text": "home versus away we skip the embedding",
      "offset": 5628.4,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "step and passed it directly to the",
      "offset": 5631.199,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "output",
      "offset": 5633.6,
      "duration": 3.599
    },
    {
      "lang": "en",
      "text": "You can extend this concept to build a",
      "offset": 5635.12,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "network that for example uses an LSTM to",
      "offset": 5637.199,
      "duration": 6.801
    },
    {
      "lang": "en",
      "text": "process text a standard dense layer to",
      "offset": 5640.88,
      "duration": 5.839
    },
    {
      "lang": "en",
      "text": "process numeric and a convolutional",
      "offset": 5644,
      "duration": 5.4
    },
    {
      "lang": "en",
      "text": "layer or CNN to process",
      "offset": 5646.719,
      "duration": 6.321
    },
    {
      "lang": "en",
      "text": "images I didn't cover LSTMs or CNN's in",
      "offset": 5649.4,
      "duration": 6.52
    },
    {
      "lang": "en",
      "text": "this course but once you understand them",
      "offset": 5653.04,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "you can use this concept to make",
      "offset": 5655.92,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "networks that understand both text and",
      "offset": 5657.92,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "images",
      "offset": 5661.12,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "The multiple output network you built in",
      "offset": 5663.28,
      "duration": 4.84
    },
    {
      "lang": "en",
      "text": "chapter 4 is the coolest model of the",
      "offset": 5665.52,
      "duration": 7.159
    },
    {
      "lang": "en",
      "text": "course It can do both classification and",
      "offset": 5668.12,
      "duration": 7
    },
    {
      "lang": "en",
      "text": "regression I like this model a lot",
      "offset": 5672.679,
      "duration": 4.761
    },
    {
      "lang": "en",
      "text": "because the regression problem turns out",
      "offset": 5675.12,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "to be a lot easier than the",
      "offset": 5677.44,
      "duration": 4.719
    },
    {
      "lang": "en",
      "text": "classification problem In the regression",
      "offset": 5679.12,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "problem the neural network gets",
      "offset": 5682.159,
      "duration": 5.201
    },
    {
      "lang": "en",
      "text": "penalized less for random chance For",
      "offset": 5683.84,
      "duration": 6.319
    },
    {
      "lang": "en",
      "text": "example a team that wins by one point",
      "offset": 5687.36,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "got really lucky and the model can use",
      "offset": 5690.159,
      "duration": 3.641
    },
    {
      "lang": "en",
      "text": "that",
      "offset": 5692.96,
      "duration": 2.8
    },
    {
      "lang": "en",
      "text": "information However in the",
      "offset": 5693.8,
      "duration": 4.359
    },
    {
      "lang": "en",
      "text": "classification model winning by one",
      "offset": 5695.76,
      "duration": 4.919
    },
    {
      "lang": "en",
      "text": "point is the same as winning by 10",
      "offset": 5698.159,
      "duration": 5.121
    },
    {
      "lang": "en",
      "text": "points I think it's pretty cool that we",
      "offset": 5700.679,
      "duration": 5
    },
    {
      "lang": "en",
      "text": "can use the output from the easier",
      "offset": 5703.28,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "regression problem to help solve the",
      "offset": 5705.679,
      "duration": 6.48
    },
    {
      "lang": "en",
      "text": "more difficult classification problem",
      "offset": 5708.48,
      "duration": 5.679
    },
    {
      "lang": "en",
      "text": "Here's a final example that we didn't",
      "offset": 5712.159,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "explicitly cover in the class but that",
      "offset": 5714.159,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "is trivially easy now that you know how",
      "offset": 5716.48,
      "duration": 3.96
    },
    {
      "lang": "en",
      "text": "to use a concatenate",
      "offset": 5718.56,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "layer In a paper called visualizing the",
      "offset": 5720.44,
      "duration": 6.52
    },
    {
      "lang": "en",
      "text": "lost landscape of neural nets Leeadall",
      "offset": 5724,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "proposed a method called skip",
      "offset": 5726.96,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "connections to simplify the optimization",
      "offset": 5728.8,
      "duration": 6.32
    },
    {
      "lang": "en",
      "text": "of neural networks To summarize a very",
      "offset": 5731.76,
      "duration": 5.84
    },
    {
      "lang": "en",
      "text": "long and interesting paper skip",
      "offset": 5735.12,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "connections make it a lot easier for the",
      "offset": 5737.6,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "atom optimizer to find the global",
      "offset": 5739.92,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "minimum of the network's loss function",
      "offset": 5742.32,
      "duration": 5.919
    },
    {
      "lang": "en",
      "text": "In caris implementing a skip connection",
      "offset": 5745.36,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "is as simple as using the concatenate",
      "offset": 5748.239,
      "duration": 4.801
    },
    {
      "lang": "en",
      "text": "layer to concatenate the inputs to the",
      "offset": 5750.48,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "deep network's outputs right before the",
      "offset": 5753.04,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "final output layer",
      "offset": 5755.76,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "I hope you enjoyed taking a deep dive",
      "offset": 5758.48,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "into the Caris functional API with me",
      "offset": 5760.56,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "and that the flexibility of these neural",
      "offset": 5762.96,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "networks will give you a lot of creative",
      "offset": 5765.44,
      "duration": 5.239
    },
    {
      "lang": "en",
      "text": "ways to solve your data science",
      "offset": 5768.08,
      "duration": 4.639
    },
    {
      "lang": "en",
      "text": "problems Thank you for taking this",
      "offset": 5770.679,
      "duration": 4.681
    },
    {
      "lang": "en",
      "text": "course and best of luck building deep",
      "offset": 5772.719,
      "duration": 5.041
    },
    {
      "lang": "en",
      "text": "neural",
      "offset": 5775.36,
      "duration": 2.4
    },
    {
      "lang": "en",
      "text": "networks Hello my name is Ariel Rom and",
      "offset": 5778.679,
      "duration": 6.121
    },
    {
      "lang": "en",
      "text": "I am a data scientist",
      "offset": 5782.4,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "In this course you will learn about",
      "offset": 5784.8,
      "duration": 6.28
    },
    {
      "lang": "en",
      "text": "convolutional neural networks or",
      "offset": 5786.8,
      "duration": 6.56
    },
    {
      "lang": "en",
      "text": "CNN's Imagine that you work for a",
      "offset": 5791.08,
      "duration": 5.599
    },
    {
      "lang": "en",
      "text": "company that is building a self-driving",
      "offset": 5793.36,
      "duration": 6.319
    },
    {
      "lang": "en",
      "text": "car One of the challenges you face is",
      "offset": 5796.679,
      "duration": 5.56
    },
    {
      "lang": "en",
      "text": "that your car needs to quickly be able",
      "offset": 5799.679,
      "duration": 6.241
    },
    {
      "lang": "en",
      "text": "to determine what is happening around it",
      "offset": 5802.239,
      "duration": 7.201
    },
    {
      "lang": "en",
      "text": "For example your self-driving car should",
      "offset": 5805.92,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "be able to tell whether the sign at an",
      "offset": 5809.44,
      "duration": 6.04
    },
    {
      "lang": "en",
      "text": "intersection is a stop sign or a yield",
      "offset": 5811.6,
      "duration": 7.2
    },
    {
      "lang": "en",
      "text": "sign CNN's are powerful algorithms for",
      "offset": 5815.48,
      "duration": 5.8
    },
    {
      "lang": "en",
      "text": "processing images In fact these",
      "offset": 5818.8,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "algorithms are currently the best",
      "offset": 5821.28,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "algorithms we have for automated",
      "offset": 5823.36,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "processing of images And they are used",
      "offset": 5825.52,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "by many different companies to do things",
      "offset": 5828,
      "duration": 6.96
    },
    {
      "lang": "en",
      "text": "like identifying the objects in an image",
      "offset": 5830.56,
      "duration": 7.04
    },
    {
      "lang": "en",
      "text": "After completing this course you will be",
      "offset": 5834.96,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "able to build an algorithm that",
      "offset": 5837.6,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "processes images of different objects",
      "offset": 5839.28,
      "duration": 4.839
    },
    {
      "lang": "en",
      "text": "and can distinguish between",
      "offset": 5841.84,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "them We will use caris which is a",
      "offset": 5844.119,
      "duration": 5.961
    },
    {
      "lang": "en",
      "text": "Python-based library that implements the",
      "offset": 5847.6,
      "duration": 4.559
    },
    {
      "lang": "en",
      "text": "building blocks you need to build your",
      "offset": 5850.08,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "own CNN's",
      "offset": 5852.159,
      "duration": 4.641
    },
    {
      "lang": "en",
      "text": "I assume that you have taken data camp's",
      "offset": 5854.8,
      "duration": 5.319
    },
    {
      "lang": "en",
      "text": "deep learning course which introduces",
      "offset": 5856.8,
      "duration": 6.319
    },
    {
      "lang": "en",
      "text": "caris because CNN's are a type of",
      "offset": 5860.119,
      "duration": 5.961
    },
    {
      "lang": "en",
      "text": "machine learning algorithm I also assume",
      "offset": 5863.119,
      "duration": 5.281
    },
    {
      "lang": "en",
      "text": "that you have a working knowledge of",
      "offset": 5866.08,
      "duration": 4.639
    },
    {
      "lang": "en",
      "text": "basic principles of machine learning",
      "offset": 5868.4,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "such as overfitting and model evaluation",
      "offset": 5870.719,
      "duration": 5.361
    },
    {
      "lang": "en",
      "text": "through cross",
      "offset": 5873.44,
      "duration": 2.64
    },
    {
      "lang": "en",
      "text": "validation Images contain data Using",
      "offset": 5876.6,
      "duration": 6.36
    },
    {
      "lang": "en",
      "text": "mapplot lib you can import an image into",
      "offset": 5880.08,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "memory from a file and then display it",
      "offset": 5882.96,
      "duration": 6.44
    },
    {
      "lang": "en",
      "text": "using a plotting command as shown",
      "offset": 5885.84,
      "duration": 6.16
    },
    {
      "lang": "en",
      "text": "here But the computer doesn't see the",
      "offset": 5889.4,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "image All it sees is an array of",
      "offset": 5892,
      "duration": 6.239
    },
    {
      "lang": "en",
      "text": "numbers Color images are stored in",
      "offset": 5895.4,
      "duration": 4.239
    },
    {
      "lang": "en",
      "text": "three-dimensional",
      "offset": 5898.239,
      "duration": 4.241
    },
    {
      "lang": "en",
      "text": "arrays The first two dimensions",
      "offset": 5899.639,
      "duration": 5.08
    },
    {
      "lang": "en",
      "text": "correspond to the height and width of",
      "offset": 5902.48,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "the image the number of pixels",
      "offset": 5904.719,
      "duration": 6.081
    },
    {
      "lang": "en",
      "text": "The last dimension corresponds to the",
      "offset": 5908.08,
      "duration": 6.159
    },
    {
      "lang": "en",
      "text": "red green and blue colors present in",
      "offset": 5910.8,
      "duration": 4.76
    },
    {
      "lang": "en",
      "text": "each",
      "offset": 5914.239,
      "duration": 4.801
    },
    {
      "lang": "en",
      "text": "pixel To examine the red green and blue",
      "offset": 5915.56,
      "duration": 6.84
    },
    {
      "lang": "en",
      "text": "data in a particular pixel in the image",
      "offset": 5919.04,
      "duration": 5.92
    },
    {
      "lang": "en",
      "text": "we index into both of the spatial",
      "offset": 5922.4,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "dimensions of the image",
      "offset": 5924.96,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "For example when we index on both of the",
      "offset": 5927.76,
      "duration": 5.919
    },
    {
      "lang": "en",
      "text": "spatial dimensions we can choose a pixel",
      "offset": 5930.48,
      "duration": 6.08
    },
    {
      "lang": "en",
      "text": "that is inside the stop sign by setting",
      "offset": 5933.679,
      "duration": 5.841
    },
    {
      "lang": "en",
      "text": "the row index to a,000 and the column",
      "offset": 5936.56,
      "duration": 5
    },
    {
      "lang": "en",
      "text": "index to",
      "offset": 5939.52,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "1500 This pixel has a high intensity in",
      "offset": 5941.56,
      "duration": 7.24
    },
    {
      "lang": "en",
      "text": "the red channel So this is its color",
      "offset": 5944.88,
      "duration": 6.4
    },
    {
      "lang": "en",
      "text": "On the other hand the pixel with row",
      "offset": 5948.8,
      "duration": 7.6
    },
    {
      "lang": "en",
      "text": "index 250 and column index of 3500 is in",
      "offset": 5951.28,
      "duration": 7.76
    },
    {
      "lang": "en",
      "text": "the part of the image containing the sky",
      "offset": 5956.4,
      "duration": 5.48
    },
    {
      "lang": "en",
      "text": "and has a high intensity in the blue",
      "offset": 5959.04,
      "duration": 5.56
    },
    {
      "lang": "en",
      "text": "channel So it has this",
      "offset": 5961.88,
      "duration": 5.799
    },
    {
      "lang": "en",
      "text": "color We can also change the image by",
      "offset": 5964.6,
      "duration": 7
    },
    {
      "lang": "en",
      "text": "changing the array data For example here",
      "offset": 5967.679,
      "duration": 6.56
    },
    {
      "lang": "en",
      "text": "we set the green and blue values of the",
      "offset": 5971.6,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "pixels to zero",
      "offset": 5974.239,
      "duration": 5.121
    },
    {
      "lang": "en",
      "text": "The result is an image that contains",
      "offset": 5976.88,
      "duration": 5.96
    },
    {
      "lang": "en",
      "text": "only the information in the red",
      "offset": 5979.36,
      "duration": 6.56
    },
    {
      "lang": "en",
      "text": "channel Alternatively we could set all",
      "offset": 5982.84,
      "duration": 5.64
    },
    {
      "lang": "en",
      "text": "the pixels within some part of the image",
      "offset": 5985.92,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "to have no red and no blue but full",
      "offset": 5988.48,
      "duration": 5.32
    },
    {
      "lang": "en",
      "text": "intensity in the green",
      "offset": 5991.6,
      "duration": 5.039
    },
    {
      "lang": "en",
      "text": "channel This results in an image with a",
      "offset": 5993.8,
      "duration": 4.879
    },
    {
      "lang": "en",
      "text": "green square in",
      "offset": 5996.639,
      "duration": 5.441
    },
    {
      "lang": "en",
      "text": "it In this course we will mostly look at",
      "offset": 5998.679,
      "duration": 6.201
    },
    {
      "lang": "en",
      "text": "black and white images",
      "offset": 6002.08,
      "duration": 5.92
    },
    {
      "lang": "en",
      "text": "For example consider these three images",
      "offset": 6004.88,
      "duration": 6.56
    },
    {
      "lang": "en",
      "text": "of three different items of clothing A",
      "offset": 6008,
      "duration": 6.199
    },
    {
      "lang": "en",
      "text": "dress a t-shirt and a",
      "offset": 6011.44,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "shoe What the computer sees are the",
      "offset": 6014.199,
      "duration": 4.92
    },
    {
      "lang": "en",
      "text": "numbers that represent the intensity of",
      "offset": 6017.04,
      "duration": 3.8
    },
    {
      "lang": "en",
      "text": "the image in each",
      "offset": 6019.119,
      "duration": 4.721
    },
    {
      "lang": "en",
      "text": "pixel High numbers represent parts of",
      "offset": 6020.84,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "the image that are",
      "offset": 6023.84,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "brighter and low numbers represent parts",
      "offset": 6025.4,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "of the image that are",
      "offset": 6028.8,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "darker In these images as well we can",
      "offset": 6030.92,
      "duration": 5.319
    },
    {
      "lang": "en",
      "text": "select a part of the image using",
      "offset": 6034.08,
      "duration": 4.639
    },
    {
      "lang": "en",
      "text": "indexing on the rows and columns of the",
      "offset": 6036.239,
      "duration": 5.761
    },
    {
      "lang": "en",
      "text": "array and slicing and change part of the",
      "offset": 6038.719,
      "duration": 6.321
    },
    {
      "lang": "en",
      "text": "array using",
      "offset": 6042,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "assignment Next let's consider what to",
      "offset": 6046.199,
      "duration": 4.801
    },
    {
      "lang": "en",
      "text": "do in order to classify",
      "offset": 6048.88,
      "duration": 5.56
    },
    {
      "lang": "en",
      "text": "images We have images of three different",
      "offset": 6051,
      "duration": 7.96
    },
    {
      "lang": "en",
      "text": "classes: dresses t-shirts and shoes",
      "offset": 6054.44,
      "duration": 6.759
    },
    {
      "lang": "en",
      "text": "We'd like to build an algorithm that can",
      "offset": 6058.96,
      "duration": 3.88
    },
    {
      "lang": "en",
      "text": "distinguish between these",
      "offset": 6061.199,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "classes In machine learning this is",
      "offset": 6062.84,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "called a classification",
      "offset": 6065.119,
      "duration": 4.961
    },
    {
      "lang": "en",
      "text": "task In the training phase we present",
      "offset": 6067.159,
      "duration": 4.761
    },
    {
      "lang": "en",
      "text": "the algorithm with samples from these",
      "offset": 6070.08,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "three different classes together with",
      "offset": 6071.92,
      "duration": 4.44
    },
    {
      "lang": "en",
      "text": "the class labels for each",
      "offset": 6074.159,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "image Over the course of training the",
      "offset": 6076.36,
      "duration": 4.759
    },
    {
      "lang": "en",
      "text": "algorithm adjusts its parameters to",
      "offset": 6079.119,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "learn the patterns in the data that",
      "offset": 6081.119,
      "duration": 2.881
    },
    {
      "lang": "en",
      "text": "distinguish between the three different",
      "offset": 6082.639,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "classes of clothing",
      "offset": 6084,
      "duration": 4.639
    },
    {
      "lang": "en",
      "text": "At the end of training we would like to",
      "offset": 6086.639,
      "duration": 5.201
    },
    {
      "lang": "en",
      "text": "know how well our classifier does To",
      "offset": 6088.639,
      "duration": 4.801
    },
    {
      "lang": "en",
      "text": "avoid an estimate that is overly",
      "offset": 6091.84,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "optimistic because of overfitting we",
      "offset": 6093.44,
      "duration": 4.239
    },
    {
      "lang": "en",
      "text": "evaluate it by testing it on portion of",
      "offset": 6095.6,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "the data that has been set aside in",
      "offset": 6097.679,
      "duration": 3.801
    },
    {
      "lang": "en",
      "text": "advance for this",
      "offset": 6099.52,
      "duration": 5.199
    },
    {
      "lang": "en",
      "text": "purpose In this case the classifier is",
      "offset": 6101.48,
      "duration": 5.159
    },
    {
      "lang": "en",
      "text": "able to correctly classify some of the",
      "offset": 6104.719,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "images but incorrectly classifies an",
      "offset": 6106.639,
      "duration": 4.961
    },
    {
      "lang": "en",
      "text": "image of a dress as a t-shirt and an",
      "offset": 6109.199,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "image of a t-shirt as a shoe",
      "offset": 6111.6,
      "duration": 5.639
    },
    {
      "lang": "en",
      "text": "How do we represent data for",
      "offset": 6115.199,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "classification consider the following",
      "offset": 6117.239,
      "duration": 3.121
    },
    {
      "lang": "en",
      "text": "series of",
      "offset": 6119.36,
      "duration": 3.759
    },
    {
      "lang": "en",
      "text": "labels One mathematically convenient way",
      "offset": 6120.36,
      "duration": 5.08
    },
    {
      "lang": "en",
      "text": "of representing this data is called one",
      "offset": 6123.119,
      "duration": 3.641
    },
    {
      "lang": "en",
      "text": "hot",
      "offset": 6125.44,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "encoding In this one hot encoding array",
      "offset": 6126.76,
      "duration": 6.76
    },
    {
      "lang": "en",
      "text": "each row represents one sample and each",
      "offset": 6130.32,
      "duration": 6.24
    },
    {
      "lang": "en",
      "text": "column corresponds to one of the classes",
      "offset": 6133.52,
      "duration": 5.599
    },
    {
      "lang": "en",
      "text": "In each row all of the values are set to",
      "offset": 6136.56,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "zero except in the column corresponding",
      "offset": 6139.119,
      "duration": 5.56
    },
    {
      "lang": "en",
      "text": "to the class from which this image is",
      "offset": 6141.6,
      "duration": 6.079
    },
    {
      "lang": "en",
      "text": "taken For example here is a one hot",
      "offset": 6144.679,
      "duration": 6.04
    },
    {
      "lang": "en",
      "text": "encoding of three images a t-shirt a",
      "offset": 6147.679,
      "duration": 4.921
    },
    {
      "lang": "en",
      "text": "dress and a",
      "offset": 6150.719,
      "duration": 4.801
    },
    {
      "lang": "en",
      "text": "shoe To generate a one hot encoding of",
      "offset": 6152.6,
      "duration": 5.92
    },
    {
      "lang": "en",
      "text": "these samples we generate an array of",
      "offset": 6155.52,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "categories We initialize an array of",
      "offset": 6158.52,
      "duration": 5.08
    },
    {
      "lang": "en",
      "text": "zeros and then we iterate over the list",
      "offset": 6160.8,
      "duration": 6.24
    },
    {
      "lang": "en",
      "text": "of labels For each sample we find the",
      "offset": 6163.6,
      "duration": 5.84
    },
    {
      "lang": "en",
      "text": "index into the categories array that",
      "offset": 6167.04,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "corresponds to the current sample We set",
      "offset": 6169.44,
      "duration": 5.92
    },
    {
      "lang": "en",
      "text": "the item in the corresponding row and",
      "offset": 6173.04,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "column to one and continue on to the",
      "offset": 6175.36,
      "duration": 5.279
    },
    {
      "lang": "en",
      "text": "next label until we have iterated over",
      "offset": 6178.32,
      "duration": 3.799
    },
    {
      "lang": "en",
      "text": "all",
      "offset": 6180.639,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "labels For example we can use the one",
      "offset": 6182.119,
      "duration": 5.241
    },
    {
      "lang": "en",
      "text": "hot encoded array to determine how many",
      "offset": 6184.96,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "predictions were correct",
      "offset": 6187.36,
      "duration": 5.879
    },
    {
      "lang": "en",
      "text": "In this case we predicted two samples",
      "offset": 6190.4,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "incorrectly out of eight samples in the",
      "offset": 6193.239,
      "duration": 5.721
    },
    {
      "lang": "en",
      "text": "test set The sum of the product of the",
      "offset": 6195.6,
      "duration": 6.32
    },
    {
      "lang": "en",
      "text": "two arrays is six which is the number of",
      "offset": 6198.96,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "correct",
      "offset": 6201.92,
      "duration": 2.4
    },
    {
      "lang": "en",
      "text": "classifications Let's use caris to",
      "offset": 6205.8,
      "duration": 5.72
    },
    {
      "lang": "en",
      "text": "classify images We'll start by using a",
      "offset": 6207.92,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "fully connected network like the one",
      "offset": 6211.52,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "that you saw in the deep learning course",
      "offset": 6213.6,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "We start by importing the sequential",
      "offset": 6217.28,
      "duration": 4.04
    },
    {
      "lang": "en",
      "text": "model and initializing",
      "offset": 6219.28,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "it To construct our network we will use",
      "offset": 6221.32,
      "duration": 6.2
    },
    {
      "lang": "en",
      "text": "densely connected layers Every unit in",
      "offset": 6224.4,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "every layer is connected to all the",
      "offset": 6227.52,
      "duration": 5.119
    },
    {
      "lang": "en",
      "text": "units in the previous layer The first",
      "offset": 6229.6,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "layer of the network is connected to all",
      "offset": 6232.639,
      "duration": 4.6
    },
    {
      "lang": "en",
      "text": "the pixels in the input",
      "offset": 6234.96,
      "duration": 5.279
    },
    {
      "lang": "en",
      "text": "image The training data in this case are",
      "offset": 6237.239,
      "duration": 7.561
    },
    {
      "lang": "en",
      "text": "images of clothes 50 samples each of 28x",
      "offset": 6240.239,
      "duration": 5.96
    },
    {
      "lang": "en",
      "text": "28",
      "offset": 6244.8,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "pixels The last dimension has length one",
      "offset": 6246.199,
      "duration": 5.92
    },
    {
      "lang": "en",
      "text": "because the images are black and",
      "offset": 6249.6,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "white 50 is a rather small number of",
      "offset": 6252.119,
      "duration": 5
    },
    {
      "lang": "en",
      "text": "training samples but we'll use that here",
      "offset": 6254.88,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "for simplicity and so that the training",
      "offset": 6257.119,
      "duration": 3.881
    },
    {
      "lang": "en",
      "text": "proceeds",
      "offset": 6259.52,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "rapidly The first layer is a set of",
      "offset": 6261,
      "duration": 5.56
    },
    {
      "lang": "en",
      "text": "densely connected units We'll use 10",
      "offset": 6263.6,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "units here but you could use another",
      "offset": 6266.56,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "number",
      "offset": 6268.48,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "More units would increase the complexity",
      "offset": 6269.92,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "of the network and its capacity to",
      "offset": 6272.08,
      "duration": 4.119
    },
    {
      "lang": "en",
      "text": "represent complex",
      "offset": 6274.4,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "inputs To facilitate learning we're",
      "offset": 6276.199,
      "duration": 6.281
    },
    {
      "lang": "en",
      "text": "using a rectified linear unit or relu as",
      "offset": 6278.96,
      "duration": 4.52
    },
    {
      "lang": "en",
      "text": "the",
      "offset": 6282.48,
      "duration": 3.199
    },
    {
      "lang": "en",
      "text": "activation This should be familiar from",
      "offset": 6283.48,
      "duration": 5.4
    },
    {
      "lang": "en",
      "text": "the deep learning course The input shape",
      "offset": 6285.679,
      "duration": 5.361
    },
    {
      "lang": "en",
      "text": "keyword argument tells us how many",
      "offset": 6288.88,
      "duration": 4.359
    },
    {
      "lang": "en",
      "text": "inputs each of these units should",
      "offset": 6291.04,
      "duration": 6.159
    },
    {
      "lang": "en",
      "text": "expect In this case it is 784",
      "offset": 6293.239,
      "duration": 5.88
    },
    {
      "lang": "en",
      "text": "one connection from each one of the",
      "offset": 6297.199,
      "duration": 7.081
    },
    {
      "lang": "en",
      "text": "pixels in the image 28 by 28 is",
      "offset": 6299.119,
      "duration": 8.641
    },
    {
      "lang": "en",
      "text": "784 We add another hidden layer also",
      "offset": 6304.28,
      "duration": 6.879
    },
    {
      "lang": "en",
      "text": "with 10 units also with the relu",
      "offset": 6307.76,
      "duration": 6.08
    },
    {
      "lang": "en",
      "text": "activation The output of our network is",
      "offset": 6311.159,
      "duration": 5
    },
    {
      "lang": "en",
      "text": "a fully connected layer with a unit for",
      "offset": 6313.84,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "each class of inputs Three classes for",
      "offset": 6316.159,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "the three types of clothing",
      "offset": 6319.28,
      "duration": 4.68
    },
    {
      "lang": "en",
      "text": "The output unit uses a softmax",
      "offset": 6321.679,
      "duration": 5.361
    },
    {
      "lang": "en",
      "text": "activation to decide which of the three",
      "offset": 6323.96,
      "duration": 5.279
    },
    {
      "lang": "en",
      "text": "classes was",
      "offset": 6327.04,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "presented This diagram shows the network",
      "offset": 6329.239,
      "duration": 5.281
    },
    {
      "lang": "en",
      "text": "and all its",
      "offset": 6332.32,
      "duration": 5.919
    },
    {
      "lang": "en",
      "text": "connections Next we compile the model We",
      "offset": 6334.52,
      "duration": 6.76
    },
    {
      "lang": "en",
      "text": "choose the optimizer to use atom and a",
      "offset": 6338.239,
      "duration": 5.761
    },
    {
      "lang": "en",
      "text": "loss function categorical cross entropy",
      "offset": 6341.28,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "which is appropriate for the",
      "offset": 6344,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "classification task",
      "offset": 6345.6,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "Setting metrics to accuracy tells the",
      "offset": 6348.4,
      "duration": 6.08
    },
    {
      "lang": "en",
      "text": "model to report accuracy as well The",
      "offset": 6350.88,
      "duration": 6.319
    },
    {
      "lang": "en",
      "text": "model expects samples to be rows in an",
      "offset": 6354.48,
      "duration": 5.84
    },
    {
      "lang": "en",
      "text": "array and each column to represent a",
      "offset": 6357.199,
      "duration": 6.321
    },
    {
      "lang": "en",
      "text": "pixel in the image So before we fit the",
      "offset": 6360.32,
      "duration": 6.799
    },
    {
      "lang": "en",
      "text": "model we need to convert the images into",
      "offset": 6363.52,
      "duration": 6.48
    },
    {
      "lang": "en",
      "text": "a two-dimensional table using the",
      "offset": 6367.119,
      "duration": 4.921
    },
    {
      "lang": "en",
      "text": "reshape",
      "offset": 6370,
      "duration": 6.08
    },
    {
      "lang": "en",
      "text": "method We fit the model to training data",
      "offset": 6372.04,
      "duration": 6.599
    },
    {
      "lang": "en",
      "text": "During training the network adjusts its",
      "offset": 6376.08,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "weights through back propagation and",
      "offset": 6378.639,
      "duration": 3.961
    },
    {
      "lang": "en",
      "text": "gradient",
      "offset": 6381.36,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "descent We might go through the data",
      "offset": 6382.6,
      "duration": 4.84
    },
    {
      "lang": "en",
      "text": "several times until the network can",
      "offset": 6385.28,
      "duration": 4.28
    },
    {
      "lang": "en",
      "text": "accurately classify the",
      "offset": 6387.44,
      "duration": 5.799
    },
    {
      "lang": "en",
      "text": "images Here the model will run for three",
      "offset": 6389.56,
      "duration": 6.679
    },
    {
      "lang": "en",
      "text": "epochs meaning that it will go over all",
      "offset": 6393.239,
      "duration": 5.761
    },
    {
      "lang": "en",
      "text": "of the training data three",
      "offset": 6396.239,
      "duration": 5.281
    },
    {
      "lang": "en",
      "text": "times How do we know that the algorithm",
      "offset": 6399,
      "duration": 5.159
    },
    {
      "lang": "en",
      "text": "has reached a good set of weights",
      "offset": 6401.52,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "we worry that the algorithm might",
      "offset": 6404.159,
      "duration": 5.921
    },
    {
      "lang": "en",
      "text": "overfit to the training data That is",
      "offset": 6406.4,
      "duration": 6.48
    },
    {
      "lang": "en",
      "text": "that the weights result in very small",
      "offset": 6410.08,
      "duration": 5.92
    },
    {
      "lang": "en",
      "text": "error on the training set but would not",
      "offset": 6412.88,
      "duration": 6.359
    },
    {
      "lang": "en",
      "text": "generalize well to another data",
      "offset": 6416,
      "duration": 7.76
    },
    {
      "lang": "en",
      "text": "set To avoid overfitting we set aside a",
      "offset": 6419.239,
      "duration": 7
    },
    {
      "lang": "en",
      "text": "set of validation images",
      "offset": 6423.76,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "At the end of every epoch of training",
      "offset": 6426.239,
      "duration": 5.641
    },
    {
      "lang": "en",
      "text": "we'll test the model on this validation",
      "offset": 6428.88,
      "duration": 6.92
    },
    {
      "lang": "en",
      "text": "set Here we use 20% of the images for",
      "offset": 6431.88,
      "duration": 6.92
    },
    {
      "lang": "en",
      "text": "validation by setting validation split",
      "offset": 6435.8,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "to",
      "offset": 6438.8,
      "duration": 6.319
    },
    {
      "lang": "en",
      "text": "0.2 This is the output In each epoch the",
      "offset": 6441.08,
      "duration": 6.2
    },
    {
      "lang": "en",
      "text": "program tracks progress through the data",
      "offset": 6445.119,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "set and at the end of the epoch prints",
      "offset": 6447.28,
      "duration": 6.68
    },
    {
      "lang": "en",
      "text": "the values of the loss function and the",
      "offset": 6450.239,
      "duration": 7.041
    },
    {
      "lang": "en",
      "text": "accuracy Accuracy is still rather low",
      "offset": 6453.96,
      "duration": 5.56
    },
    {
      "lang": "en",
      "text": "because we used a small amount of data",
      "offset": 6457.28,
      "duration": 6.2
    },
    {
      "lang": "en",
      "text": "and we trained for only a few",
      "offset": 6459.52,
      "duration": 7.44
    },
    {
      "lang": "en",
      "text": "epochs Another evaluation of the model",
      "offset": 6463.48,
      "duration": 6.12
    },
    {
      "lang": "en",
      "text": "should be done on a separate test set",
      "offset": 6466.96,
      "duration": 5.08
    },
    {
      "lang": "en",
      "text": "that was not used during",
      "offset": 6469.6,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "training This gives us a realistic",
      "offset": 6472.04,
      "duration": 6.04
    },
    {
      "lang": "en",
      "text": "separate evaluation of the model quality",
      "offset": 6474.96,
      "duration": 9.64
    },
    {
      "lang": "en",
      "text": "Loss is 1.019 and accuracy is 40%",
      "offset": 6478.08,
      "duration": 6.52
    },
    {
      "lang": "en",
      "text": "In the neural network that we previously",
      "offset": 6485.6,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "constructed each unit in the first layer",
      "offset": 6488.36,
      "duration": 4.759
    },
    {
      "lang": "en",
      "text": "had a weight connecting it separately",
      "offset": 6491.04,
      "duration": 5
    },
    {
      "lang": "en",
      "text": "with every pixel in the",
      "offset": 6493.119,
      "duration": 5.841
    },
    {
      "lang": "en",
      "text": "image But we know that pixels in most",
      "offset": 6496.04,
      "duration": 6.32
    },
    {
      "lang": "en",
      "text": "images are not independent from their",
      "offset": 6498.96,
      "duration": 6.64
    },
    {
      "lang": "en",
      "text": "neighbors For example images of objects",
      "offset": 6502.36,
      "duration": 6.04
    },
    {
      "lang": "en",
      "text": "contain edges and neighboring pixels",
      "offset": 6505.6,
      "duration": 5.039
    },
    {
      "lang": "en",
      "text": "along an edge tend to have similar",
      "offset": 6508.4,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "patterns",
      "offset": 6510.639,
      "duration": 5.241
    },
    {
      "lang": "en",
      "text": "How can we use these correlations to our",
      "offset": 6512.96,
      "duration": 6.239
    },
    {
      "lang": "en",
      "text": "advantage our own visual system uses",
      "offset": 6515.88,
      "duration": 6.04
    },
    {
      "lang": "en",
      "text": "these correlations and each nerve cell",
      "offset": 6519.199,
      "duration": 4.881
    },
    {
      "lang": "en",
      "text": "in the visual areas in our brain",
      "offset": 6521.92,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "responds to oriented edges at a",
      "offset": 6524.08,
      "duration": 6.119
    },
    {
      "lang": "en",
      "text": "particular location in the visual",
      "offset": 6526.4,
      "duration": 7.12
    },
    {
      "lang": "en",
      "text": "field This image depicts a small part of",
      "offset": 6530.199,
      "duration": 6.361
    },
    {
      "lang": "en",
      "text": "the visual cortex The scale bar is 1",
      "offset": 6533.52,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "millm in size",
      "offset": 6536.56,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "Each part of the image responds to some",
      "offset": 6538.96,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "part of the visual field and to the",
      "offset": 6541.6,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "orientation depicted by the colors on",
      "offset": 6543.92,
      "duration": 3.64
    },
    {
      "lang": "en",
      "text": "the",
      "offset": 6546.32,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "right Looking for the same feature such",
      "offset": 6547.56,
      "duration": 6.2
    },
    {
      "lang": "en",
      "text": "as a particular orientation in every",
      "offset": 6550.8,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "location in an image is like a",
      "offset": 6553.76,
      "duration": 5.959
    },
    {
      "lang": "en",
      "text": "mathematical operation called a",
      "offset": 6556.4,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "convolution This is the fundamental",
      "offset": 6559.719,
      "duration": 4.92
    },
    {
      "lang": "en",
      "text": "operation that convolutional neural",
      "offset": 6562.08,
      "duration": 7.039
    },
    {
      "lang": "en",
      "text": "networks use to process images",
      "offset": 6564.639,
      "duration": 7.201
    },
    {
      "lang": "en",
      "text": "Let's start with a simple version A",
      "offset": 6569.119,
      "duration": 5
    },
    {
      "lang": "en",
      "text": "convolution in one",
      "offset": 6571.84,
      "duration": 5.279
    },
    {
      "lang": "en",
      "text": "dimension We create here an array that",
      "offset": 6574.119,
      "duration": 6.721
    },
    {
      "lang": "en",
      "text": "contains five zeros followed by five",
      "offset": 6577.119,
      "duration": 7.201
    },
    {
      "lang": "en",
      "text": "ones This array contains an edge in the",
      "offset": 6580.84,
      "duration": 7.6
    },
    {
      "lang": "en",
      "text": "middle where the values go from zero to",
      "offset": 6584.32,
      "duration": 7.839
    },
    {
      "lang": "en",
      "text": "one The kernel defines the feature that",
      "offset": 6588.44,
      "duration": 6.12
    },
    {
      "lang": "en",
      "text": "we are looking for",
      "offset": 6592.159,
      "duration": 5.361
    },
    {
      "lang": "en",
      "text": "In this case we are looking for a change",
      "offset": 6594.56,
      "duration": 5.679
    },
    {
      "lang": "en",
      "text": "from small values on the left to large",
      "offset": 6597.52,
      "duration": 4.679
    },
    {
      "lang": "en",
      "text": "values on the",
      "offset": 6600.239,
      "duration": 5.321
    },
    {
      "lang": "en",
      "text": "right We start the result as all",
      "offset": 6602.199,
      "duration": 8
    },
    {
      "lang": "en",
      "text": "zeros Then we slide the kernel along the",
      "offset": 6605.56,
      "duration": 8.36
    },
    {
      "lang": "en",
      "text": "array In each location we multiply the",
      "offset": 6610.199,
      "duration": 6.361
    },
    {
      "lang": "en",
      "text": "values in the array with the values in",
      "offset": 6613.92,
      "duration": 5.08
    },
    {
      "lang": "en",
      "text": "the kernel and sum them",
      "offset": 6616.56,
      "duration": 7.679
    },
    {
      "lang": "en",
      "text": "up This is the result for that location",
      "offset": 6619,
      "duration": 8.199
    },
    {
      "lang": "en",
      "text": "In this example the array goes between 0",
      "offset": 6624.239,
      "duration": 4.361
    },
    {
      "lang": "en",
      "text": "and one",
      "offset": 6627.199,
      "duration": 4.721
    },
    {
      "lang": "en",
      "text": "twice In this case the edges that go",
      "offset": 6628.6,
      "duration": 6.92
    },
    {
      "lang": "en",
      "text": "from 0 to one match the kernel but the",
      "offset": 6631.92,
      "duration": 6.319
    },
    {
      "lang": "en",
      "text": "edges from one to zero are the opposite",
      "offset": 6635.52,
      "duration": 3.56
    },
    {
      "lang": "en",
      "text": "of the",
      "offset": 6638.239,
      "duration": 3.761
    },
    {
      "lang": "en",
      "text": "kernel In these locations the",
      "offset": 6639.08,
      "duration": 6.36
    },
    {
      "lang": "en",
      "text": "convolution becomes",
      "offset": 6642,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "negative Convolutions of images do the",
      "offset": 6645.48,
      "duration": 7.159
    },
    {
      "lang": "en",
      "text": "same operation but in two dimensions",
      "offset": 6648.56,
      "duration": 6.88
    },
    {
      "lang": "en",
      "text": "In this case we convolve the image of a",
      "offset": 6652.639,
      "duration": 5.121
    },
    {
      "lang": "en",
      "text": "dress with a kernel that matches",
      "offset": 6655.44,
      "duration": 5.48
    },
    {
      "lang": "en",
      "text": "vertical edges on the",
      "offset": 6657.76,
      "duration": 6.479
    },
    {
      "lang": "en",
      "text": "left This means that when we convolve",
      "offset": 6660.92,
      "duration": 6.279
    },
    {
      "lang": "en",
      "text": "the image with this kernel the left edge",
      "offset": 6664.239,
      "duration": 4.361
    },
    {
      "lang": "en",
      "text": "is",
      "offset": 6667.199,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "emphasized The right side of the dress",
      "offset": 6668.6,
      "duration": 5
    },
    {
      "lang": "en",
      "text": "is the opposite of this kernel and the",
      "offset": 6671.119,
      "duration": 6.241
    },
    {
      "lang": "en",
      "text": "convolution is negative there",
      "offset": 6673.6,
      "duration": 6.24
    },
    {
      "lang": "en",
      "text": "Now let's look at an implementation of",
      "offset": 6677.36,
      "duration": 4.68
    },
    {
      "lang": "en",
      "text": "convolution in",
      "offset": 6679.84,
      "duration": 5.48
    },
    {
      "lang": "en",
      "text": "code First we create the",
      "offset": 6682.04,
      "duration": 6.28
    },
    {
      "lang": "en",
      "text": "kernel Then we create the array that",
      "offset": 6685.32,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "will store the results of the",
      "offset": 6688.32,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "convolution We iterate over all the",
      "offset": 6691,
      "duration": 6.52
    },
    {
      "lang": "en",
      "text": "locations in the image In each location",
      "offset": 6693.6,
      "duration": 6.48
    },
    {
      "lang": "en",
      "text": "we select a window that is the size of",
      "offset": 6697.52,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "the kernel We multiply that window with",
      "offset": 6700.08,
      "duration": 6.72
    },
    {
      "lang": "en",
      "text": "the kernel and then sum it up",
      "offset": 6703.28,
      "duration": 6.24
    },
    {
      "lang": "en",
      "text": "This sum is then entered as the value of",
      "offset": 6706.8,
      "duration": 5.96
    },
    {
      "lang": "en",
      "text": "the convolved image in that",
      "offset": 6709.52,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "location At the end of the loop the",
      "offset": 6712.76,
      "duration": 6.72
    },
    {
      "lang": "en",
      "text": "array will contain the results of the",
      "offset": 6715.52,
      "duration": 6.48
    },
    {
      "lang": "en",
      "text": "convolution Here is a graphic that",
      "offset": 6719.48,
      "duration": 4.639
    },
    {
      "lang": "en",
      "text": "demonstrates the convolution",
      "offset": 6722,
      "duration": 6.4
    },
    {
      "lang": "en",
      "text": "operation The kernel is the gray 3x3 box",
      "offset": 6724.119,
      "duration": 7.161
    },
    {
      "lang": "en",
      "text": "that slides over the blue input image at",
      "offset": 6728.4,
      "duration": 3.56
    },
    {
      "lang": "en",
      "text": "the",
      "offset": 6731.28,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "bottom In each location the window is",
      "offset": 6731.96,
      "duration": 5.8
    },
    {
      "lang": "en",
      "text": "multiplied with the values in the kernel",
      "offset": 6735.36,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "and added up to create the value of one",
      "offset": 6737.76,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "of the pixels in the resulting green",
      "offset": 6740.48,
      "duration": 4.6
    },
    {
      "lang": "en",
      "text": "array at the",
      "offset": 6742.8,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "top In neural networks we call this",
      "offset": 6745.08,
      "duration": 6.68
    },
    {
      "lang": "en",
      "text": "resulting array a feature map because it",
      "offset": 6748.48,
      "duration": 5.679
    },
    {
      "lang": "en",
      "text": "contains a map of the locations in the",
      "offset": 6751.76,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "image that match the feature represented",
      "offset": 6754.159,
      "duration": 6.121
    },
    {
      "lang": "en",
      "text": "by this kernel",
      "offset": 6756.8,
      "duration": 3.48
    },
    {
      "lang": "en",
      "text": "Caris has objects to represent",
      "offset": 6761.52,
      "duration": 5.119
    },
    {
      "lang": "en",
      "text": "convolution layers Here we have a",
      "offset": 6763.36,
      "duration": 5.839
    },
    {
      "lang": "en",
      "text": "two-dimensional convolution that we can",
      "offset": 6766.639,
      "duration": 4.441
    },
    {
      "lang": "en",
      "text": "use to analyze",
      "offset": 6769.199,
      "duration": 5.201
    },
    {
      "lang": "en",
      "text": "images It resembles the dense layers but",
      "offset": 6771.08,
      "duration": 5.559
    },
    {
      "lang": "en",
      "text": "instead of having every unit in the",
      "offset": 6774.4,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "layer connected to every unit in the",
      "offset": 6776.639,
      "duration": 4.801
    },
    {
      "lang": "en",
      "text": "previous layer these connect to the",
      "offset": 6778.96,
      "duration": 4.759
    },
    {
      "lang": "en",
      "text": "previous layer through a convolution",
      "offset": 6781.44,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "kernel This means that the output of",
      "offset": 6783.719,
      "duration": 5.96
    },
    {
      "lang": "en",
      "text": "each unit in this layer is a convolution",
      "offset": 6786.8,
      "duration": 5.72
    },
    {
      "lang": "en",
      "text": "of a kernel over the image",
      "offset": 6789.679,
      "duration": 6.52
    },
    {
      "lang": "en",
      "text": "input Here we have 10 convolution",
      "offset": 6792.52,
      "duration": 6.199
    },
    {
      "lang": "en",
      "text": "units During training of a neural",
      "offset": 6796.199,
      "duration": 5.241
    },
    {
      "lang": "en",
      "text": "network that has convolutional layers",
      "offset": 6798.719,
      "duration": 5.121
    },
    {
      "lang": "en",
      "text": "the kernels in each unit would be",
      "offset": 6801.44,
      "duration": 5.92
    },
    {
      "lang": "en",
      "text": "adjusted using back propagation",
      "offset": 6803.84,
      "duration": 6.08
    },
    {
      "lang": "en",
      "text": "The principle is the same as learning in",
      "offset": 6807.36,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "the dense layers that we have seen so",
      "offset": 6809.92,
      "duration": 4.759
    },
    {
      "lang": "en",
      "text": "far but with fewer",
      "offset": 6811.84,
      "duration": 6.64
    },
    {
      "lang": "en",
      "text": "weights A dense layer has one weight for",
      "offset": 6814.679,
      "duration": 6.44
    },
    {
      "lang": "en",
      "text": "each pixel in the image But a",
      "offset": 6818.48,
      "duration": 5.84
    },
    {
      "lang": "en",
      "text": "convolution layer has only one weight",
      "offset": 6821.119,
      "duration": 6.321
    },
    {
      "lang": "en",
      "text": "for each pixel in the kernel",
      "offset": 6824.32,
      "duration": 6.16
    },
    {
      "lang": "en",
      "text": "For example if we set the kernel size",
      "offset": 6827.44,
      "duration": 6.159
    },
    {
      "lang": "en",
      "text": "argument to three that means that the",
      "offset": 6830.48,
      "duration": 6.199
    },
    {
      "lang": "en",
      "text": "kernel of each unit has nine",
      "offset": 6833.599,
      "duration": 6.801
    },
    {
      "lang": "en",
      "text": "pixels If the layer has 10 units it",
      "offset": 6836.679,
      "duration": 7.361
    },
    {
      "lang": "en",
      "text": "would have 90 parameters for these",
      "offset": 6840.4,
      "duration": 6.64
    },
    {
      "lang": "en",
      "text": "kernels To build a network that contains",
      "offset": 6844.04,
      "duration": 5.559
    },
    {
      "lang": "en",
      "text": "a convolution layer we need to import",
      "offset": 6847.04,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "the sequential model And we will need",
      "offset": 6849.599,
      "duration": 6.361
    },
    {
      "lang": "en",
      "text": "the dense as well as the conve 2D",
      "offset": 6852.08,
      "duration": 6.639
    },
    {
      "lang": "en",
      "text": "layers In addition to these layers we",
      "offset": 6855.96,
      "duration": 6.04
    },
    {
      "lang": "en",
      "text": "will also need a flatten layer This",
      "offset": 6858.719,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "serves as a connector between",
      "offset": 6862,
      "duration": 5.159
    },
    {
      "lang": "en",
      "text": "convolution and densely connected",
      "offset": 6863.679,
      "duration": 6.96
    },
    {
      "lang": "en",
      "text": "layers We initialize a sequential model",
      "offset": 6867.159,
      "duration": 5.921
    },
    {
      "lang": "en",
      "text": "and add a first convolution",
      "offset": 6870.639,
      "duration": 4.801
    },
    {
      "lang": "en",
      "text": "layer In addition to the function",
      "offset": 6873.08,
      "duration": 4.92
    },
    {
      "lang": "en",
      "text": "arguments that I showed you before the",
      "offset": 6875.44,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "number of units the kernel size and the",
      "offset": 6878,
      "duration": 6.28
    },
    {
      "lang": "en",
      "text": "activation function here we use the relu",
      "offset": 6880.88,
      "duration": 6.839
    },
    {
      "lang": "en",
      "text": "activation We also add here the input",
      "offset": 6884.28,
      "duration": 6.2
    },
    {
      "lang": "en",
      "text": "shape This is the size of each of the",
      "offset": 6887.719,
      "duration": 6.601
    },
    {
      "lang": "en",
      "text": "input images to the network For example",
      "offset": 6890.48,
      "duration": 5.92
    },
    {
      "lang": "en",
      "text": "for the images of clothing that we have",
      "offset": 6894.32,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "been using we might have image rows and",
      "offset": 6896.4,
      "duration": 7.36
    },
    {
      "lang": "en",
      "text": "image calls both equal to 28",
      "offset": 6899.76,
      "duration": 6.479
    },
    {
      "lang": "en",
      "text": "To connect this layer to the next one we",
      "offset": 6903.76,
      "duration": 3.8
    },
    {
      "lang": "en",
      "text": "add a flatten",
      "offset": 6906.239,
      "duration": 3.761
    },
    {
      "lang": "en",
      "text": "layer This takes the output of the",
      "offset": 6907.56,
      "duration": 4.679
    },
    {
      "lang": "en",
      "text": "convolution that we previously referred",
      "offset": 6910,
      "duration": 5.199
    },
    {
      "lang": "en",
      "text": "to as a feature map and flattens it into",
      "offset": 6912.239,
      "duration": 4.601
    },
    {
      "lang": "en",
      "text": "a one-dimensional",
      "offset": 6915.199,
      "duration": 4.561
    },
    {
      "lang": "en",
      "text": "array This is the expected input into",
      "offset": 6916.84,
      "duration": 5.16
    },
    {
      "lang": "en",
      "text": "the densely connected layer that is then",
      "offset": 6919.76,
      "duration": 5.16
    },
    {
      "lang": "en",
      "text": "added to the network as an output",
      "offset": 6922,
      "duration": 6.48
    },
    {
      "lang": "en",
      "text": "layer Here the output is one of three",
      "offset": 6924.92,
      "duration": 6.88
    },
    {
      "lang": "en",
      "text": "classes of clothing So there are three",
      "offset": 6928.48,
      "duration": 6.4
    },
    {
      "lang": "en",
      "text": "units To classify among the categories",
      "offset": 6931.8,
      "duration": 5.48
    },
    {
      "lang": "en",
      "text": "represented by the three units we use",
      "offset": 6934.88,
      "duration": 5.319
    },
    {
      "lang": "en",
      "text": "the softmax activation",
      "offset": 6937.28,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "function This is a diagram that",
      "offset": 6940.199,
      "duration": 5
    },
    {
      "lang": "en",
      "text": "describes the network that we created",
      "offset": 6942.4,
      "duration": 7.199
    },
    {
      "lang": "en",
      "text": "The inputs are images of 28x 28 pixels",
      "offset": 6945.199,
      "duration": 7.44
    },
    {
      "lang": "en",
      "text": "The con 2D operation goes to 10 feature",
      "offset": 6949.599,
      "duration": 6.801
    },
    {
      "lang": "en",
      "text": "maps of 28x 28 pixels each And the",
      "offset": 6952.639,
      "duration": 6.161
    },
    {
      "lang": "en",
      "text": "flatten operation takes us to three",
      "offset": 6956.4,
      "duration": 4.04
    },
    {
      "lang": "en",
      "text": "units of the",
      "offset": 6958.8,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "output Just like before the next step is",
      "offset": 6960.44,
      "duration": 5.4
    },
    {
      "lang": "en",
      "text": "to compile the model choosing the",
      "offset": 6963.76,
      "duration": 4.479
    },
    {
      "lang": "en",
      "text": "optimizer and the loss function that we",
      "offset": 6965.84,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "would like to use for fitting for",
      "offset": 6968.239,
      "duration": 5.281
    },
    {
      "lang": "en",
      "text": "classification tasks Categorical cross",
      "offset": 6971.04,
      "duration": 4.92
    },
    {
      "lang": "en",
      "text": "entropy is an appropriate loss",
      "offset": 6973.52,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "function We can also specify the metrics",
      "offset": 6975.96,
      "duration": 4.52
    },
    {
      "lang": "en",
      "text": "that we would like to see during",
      "offset": 6978.96,
      "duration": 4.04
    },
    {
      "lang": "en",
      "text": "training Here just the",
      "offset": 6980.48,
      "duration": 5.679
    },
    {
      "lang": "en",
      "text": "accuracy Our training data are 50",
      "offset": 6983,
      "duration": 6.76
    },
    {
      "lang": "en",
      "text": "samples of images of clothing Each",
      "offset": 6986.159,
      "duration": 7.44
    },
    {
      "lang": "en",
      "text": "training item is a 28x 28 pixel image",
      "offset": 6989.76,
      "duration": 5.399
    },
    {
      "lang": "en",
      "text": "with one",
      "offset": 6993.599,
      "duration": 4.241
    },
    {
      "lang": "en",
      "text": "channel When we trained on a fully",
      "offset": 6995.159,
      "duration": 5.401
    },
    {
      "lang": "en",
      "text": "connected network composed entirely of",
      "offset": 6997.84,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "densely connected layers we had to",
      "offset": 7000.56,
      "duration": 5.039
    },
    {
      "lang": "en",
      "text": "reshape this input before feeding it to",
      "offset": 7003.28,
      "duration": 3
    },
    {
      "lang": "en",
      "text": "the",
      "offset": 7005.599,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "network Here we would like the pixels to",
      "offset": 7006.28,
      "duration": 6.2
    },
    {
      "lang": "en",
      "text": "retain their spatial relationships So we",
      "offset": 7009.679,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "don't do that",
      "offset": 7012.48,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "That is why we had to specify the input",
      "offset": 7014.08,
      "duration": 5.96
    },
    {
      "lang": "en",
      "text": "shape when we define the convolutional",
      "offset": 7016.56,
      "duration": 6.48
    },
    {
      "lang": "en",
      "text": "layer We fit the model with training",
      "offset": 7020.04,
      "duration": 6.04
    },
    {
      "lang": "en",
      "text": "data and training labels after which we",
      "offset": 7023.04,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "can test the accuracy of the model on a",
      "offset": 7026.08,
      "duration": 5.84
    },
    {
      "lang": "en",
      "text": "separate test data",
      "offset": 7028.8,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "set Let's talk about the details of",
      "offset": 7033.08,
      "duration": 5.159
    },
    {
      "lang": "en",
      "text": "convolutions and how you might tweak",
      "offset": 7035.88,
      "duration": 6.68
    },
    {
      "lang": "en",
      "text": "them to do things slightly differently",
      "offset": 7038.239,
      "duration": 6.641
    },
    {
      "lang": "en",
      "text": "This is an animation of a convolution",
      "offset": 7042.56,
      "duration": 4.44
    },
    {
      "lang": "en",
      "text": "that you have seen",
      "offset": 7044.88,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "before One thing that you might have",
      "offset": 7047,
      "duration": 5.239
    },
    {
      "lang": "en",
      "text": "noticed before is that the blue input",
      "offset": 7049.28,
      "duration": 6.52
    },
    {
      "lang": "en",
      "text": "image is larger than the green output",
      "offset": 7052.239,
      "duration": 6.161
    },
    {
      "lang": "en",
      "text": "image This is because the convolution",
      "offset": 7055.8,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "kernel has the size of 3x3",
      "offset": 7058.4,
      "duration": 6.64
    },
    {
      "lang": "en",
      "text": "pixels In this case it converts a 3x3",
      "offset": 7061.56,
      "duration": 6.119
    },
    {
      "lang": "en",
      "text": "window into one pixel in the output",
      "offset": 7065.04,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "image",
      "offset": 7067.679,
      "duration": 4.881
    },
    {
      "lang": "en",
      "text": "One way to deal with this issue is to",
      "offset": 7070.08,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "zero pad the input image Here's what",
      "offset": 7072.56,
      "duration": 6.159
    },
    {
      "lang": "en",
      "text": "that looks like The dashed boxes around",
      "offset": 7075.76,
      "duration": 5.439
    },
    {
      "lang": "en",
      "text": "the central image are zeros that are",
      "offset": 7078.719,
      "duration": 3.561
    },
    {
      "lang": "en",
      "text": "added to the",
      "offset": 7081.199,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "image As you can see when the input",
      "offset": 7082.28,
      "duration": 6.12
    },
    {
      "lang": "en",
      "text": "image is zero padded the output feature",
      "offset": 7085.199,
      "duration": 6.52
    },
    {
      "lang": "en",
      "text": "map has the same size as the",
      "offset": 7088.4,
      "duration": 6.16
    },
    {
      "lang": "en",
      "text": "input This can be useful if you want to",
      "offset": 7091.719,
      "duration": 6.161
    },
    {
      "lang": "en",
      "text": "build a network that has many layers",
      "offset": 7094.56,
      "duration": 6.159
    },
    {
      "lang": "en",
      "text": "Otherwise you might lose a pixel off the",
      "offset": 7097.88,
      "duration": 6.319
    },
    {
      "lang": "en",
      "text": "edge of the image in each subsequent",
      "offset": 7100.719,
      "duration": 7.121
    },
    {
      "lang": "en",
      "text": "layer To implement zero padding in caris",
      "offset": 7104.199,
      "duration": 7
    },
    {
      "lang": "en",
      "text": "we will use the con2d objects padding",
      "offset": 7107.84,
      "duration": 4.6
    },
    {
      "lang": "en",
      "text": "keyword",
      "offset": 7111.199,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "argument If we provide the value valid",
      "offset": 7112.44,
      "duration": 7
    },
    {
      "lang": "en",
      "text": "no zero padding is added This is also",
      "offset": 7116.159,
      "duration": 5.841
    },
    {
      "lang": "en",
      "text": "the default behavior So if you don't",
      "offset": 7119.44,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "specify padding this is what you will",
      "offset": 7122,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "get",
      "offset": 7124.56,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "On the other hand if we provide the",
      "offset": 7126.56,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "value same zero padding will be applied",
      "offset": 7128.639,
      "duration": 6.56
    },
    {
      "lang": "en",
      "text": "to the input to this layer so that the",
      "offset": 7131.92,
      "duration": 5.92
    },
    {
      "lang": "en",
      "text": "output of the convolution has the same",
      "offset": 7135.199,
      "duration": 6.281
    },
    {
      "lang": "en",
      "text": "size as the input into the",
      "offset": 7137.84,
      "duration": 6.319
    },
    {
      "lang": "en",
      "text": "convolution Another factor that affects",
      "offset": 7141.48,
      "duration": 5.56
    },
    {
      "lang": "en",
      "text": "the size of the output of a convolution",
      "offset": 7144.159,
      "duration": 5.121
    },
    {
      "lang": "en",
      "text": "is the size of the step that we take",
      "offset": 7147.04,
      "duration": 5.92
    },
    {
      "lang": "en",
      "text": "with the kernel between input pixels",
      "offset": 7149.28,
      "duration": 7.12
    },
    {
      "lang": "en",
      "text": "This is called the size of the stride",
      "offset": 7152.96,
      "duration": 6.56
    },
    {
      "lang": "en",
      "text": "For example in this animation the kernel",
      "offset": 7156.4,
      "duration": 6.839
    },
    {
      "lang": "en",
      "text": "is strided by two pixels in each",
      "offset": 7159.52,
      "duration": 6.88
    },
    {
      "lang": "en",
      "text": "step This means again that the output",
      "offset": 7163.239,
      "duration": 7.121
    },
    {
      "lang": "en",
      "text": "size is smaller than the input",
      "offset": 7166.4,
      "duration": 7.36
    },
    {
      "lang": "en",
      "text": "size Strides are also implemented as a",
      "offset": 7170.36,
      "duration": 6.4
    },
    {
      "lang": "en",
      "text": "keyword argument to the conve 2D",
      "offset": 7173.76,
      "duration": 6.16
    },
    {
      "lang": "en",
      "text": "layers The default is for the stride to",
      "offset": 7176.76,
      "duration": 6.76
    },
    {
      "lang": "en",
      "text": "be set to one This means that the kernel",
      "offset": 7179.92,
      "duration": 6.319
    },
    {
      "lang": "en",
      "text": "slides along the image and is multiplied",
      "offset": 7183.52,
      "duration": 6.119
    },
    {
      "lang": "en",
      "text": "and summed with each pixel",
      "offset": 7186.239,
      "duration": 6.241
    },
    {
      "lang": "en",
      "text": "location If the stride is set to more",
      "offset": 7189.639,
      "duration": 6.04
    },
    {
      "lang": "en",
      "text": "than one the kernel jumps in steps of",
      "offset": 7192.48,
      "duration": 4.92
    },
    {
      "lang": "en",
      "text": "that number of",
      "offset": 7195.679,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "pixels This also means that the output",
      "offset": 7197.4,
      "duration": 6.279
    },
    {
      "lang": "en",
      "text": "will be smaller",
      "offset": 7201.119,
      "duration": 6.48
    },
    {
      "lang": "en",
      "text": "For example if the input image is 5x5",
      "offset": 7203.679,
      "duration": 6.641
    },
    {
      "lang": "en",
      "text": "and there is both zero padding and",
      "offset": 7207.599,
      "duration": 6.161
    },
    {
      "lang": "en",
      "text": "strides set to two the output will have",
      "offset": 7210.32,
      "duration": 6.24
    },
    {
      "lang": "en",
      "text": "a size of",
      "offset": 7213.76,
      "duration": 2.8
    },
    {
      "lang": "en",
      "text": "3x3 Generally we can calculate the size",
      "offset": 7216.599,
      "duration": 7.881
    },
    {
      "lang": "en",
      "text": "of the output using a simple formula I",
      "offset": 7220.08,
      "duration": 11.2
    },
    {
      "lang": "en",
      "text": "minus K + 2 P / S + 1 where I is the",
      "offset": 7224.48,
      "duration": 10.08
    },
    {
      "lang": "en",
      "text": "size of the input K is the size of the",
      "offset": 7231.28,
      "duration": 6.879
    },
    {
      "lang": "en",
      "text": "kernel P is the size of the zero padding",
      "offset": 7234.56,
      "duration": 5.48
    },
    {
      "lang": "en",
      "text": "and S is the",
      "offset": 7238.159,
      "duration": 5.401
    },
    {
      "lang": "en",
      "text": "stride For example if the input is 28",
      "offset": 7240.04,
      "duration": 5.92
    },
    {
      "lang": "en",
      "text": "pixels the kernel is",
      "offset": 7243.56,
      "duration": 5.559
    },
    {
      "lang": "en",
      "text": "3x3 the padding is of 1 and the stride",
      "offset": 7245.96,
      "duration": 9.48
    },
    {
      "lang": "en",
      "text": "is 1 this number will be 28 minus 3 + 2",
      "offset": 7249.119,
      "duration": 10.721
    },
    {
      "lang": "en",
      "text": "/ 1 + 1 = 28",
      "offset": 7255.44,
      "duration": 7.36
    },
    {
      "lang": "en",
      "text": "If instead the stride is three the",
      "offset": 7259.84,
      "duration": 5.64
    },
    {
      "lang": "en",
      "text": "output size would be 10 by",
      "offset": 7262.8,
      "duration": 5.919
    },
    {
      "lang": "en",
      "text": "10 Finally you can also tweak the",
      "offset": 7265.48,
      "duration": 5.719
    },
    {
      "lang": "en",
      "text": "spacing between the pixels affected by",
      "offset": 7268.719,
      "duration": 3.161
    },
    {
      "lang": "en",
      "text": "the",
      "offset": 7271.199,
      "duration": 3.801
    },
    {
      "lang": "en",
      "text": "kernel This is called a dilated",
      "offset": 7271.88,
      "duration": 5.799
    },
    {
      "lang": "en",
      "text": "convolution In this case the convolution",
      "offset": 7275,
      "duration": 5.48
    },
    {
      "lang": "en",
      "text": "kernel has only nine parameters but it",
      "offset": 7277.679,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "has the same field of view as a kernel",
      "offset": 7280.48,
      "duration": 6.08
    },
    {
      "lang": "en",
      "text": "that would have the size 5x5",
      "offset": 7282.719,
      "duration": 6.321
    },
    {
      "lang": "en",
      "text": "This is useful in cases where you need",
      "offset": 7286.56,
      "duration": 6.44
    },
    {
      "lang": "en",
      "text": "to aggregate information across multiple",
      "offset": 7289.04,
      "duration": 6.639
    },
    {
      "lang": "en",
      "text": "scales This too is controlled through a",
      "offset": 7293,
      "duration": 5.96
    },
    {
      "lang": "en",
      "text": "keyword argument dilation rate that sets",
      "offset": 7295.679,
      "duration": 7.121
    },
    {
      "lang": "en",
      "text": "the distance between subsequent",
      "offset": 7298.96,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "pixels One of the major strengths of",
      "offset": 7303.639,
      "duration": 5.801
    },
    {
      "lang": "en",
      "text": "convolutional neural networks comes from",
      "offset": 7306.56,
      "duration": 5.119
    },
    {
      "lang": "en",
      "text": "building networks with multiple layers",
      "offset": 7309.44,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "of convolutional filters",
      "offset": 7311.679,
      "duration": 5.201
    },
    {
      "lang": "en",
      "text": "This is why using artificial neural",
      "offset": 7314.56,
      "duration": 7.079
    },
    {
      "lang": "en",
      "text": "networks is sometimes also called deep",
      "offset": 7316.88,
      "duration": 7.12
    },
    {
      "lang": "en",
      "text": "learning This is the diagram that",
      "offset": 7321.639,
      "duration": 5.241
    },
    {
      "lang": "en",
      "text": "describes the network that we saw before",
      "offset": 7324,
      "duration": 5.92
    },
    {
      "lang": "en",
      "text": "It has one convolutional layer followed",
      "offset": 7326.88,
      "duration": 5.839
    },
    {
      "lang": "en",
      "text": "by a flattening and readout with a fully",
      "offset": 7329.92,
      "duration": 4.759
    },
    {
      "lang": "en",
      "text": "connected layer with three",
      "offset": 7332.719,
      "duration": 4.561
    },
    {
      "lang": "en",
      "text": "units And here is the code that",
      "offset": 7334.679,
      "duration": 4.721
    },
    {
      "lang": "en",
      "text": "implements this",
      "offset": 7337.28,
      "duration": 5.439
    },
    {
      "lang": "en",
      "text": "network In this diagram we have added",
      "offset": 7339.4,
      "duration": 6.68
    },
    {
      "lang": "en",
      "text": "one more convolutional layer This layer",
      "offset": 7342.719,
      "duration": 6.88
    },
    {
      "lang": "en",
      "text": "also has 10 feature maps Instead of",
      "offset": 7346.08,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "operating directly on the image the",
      "offset": 7349.599,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "convolutions in this layer operate on",
      "offset": 7351.84,
      "duration": 4.799
    },
    {
      "lang": "en",
      "text": "each of the feature maps in the first",
      "offset": 7354.639,
      "duration": 5.361
    },
    {
      "lang": "en",
      "text": "convolutional layer After the second",
      "offset": 7356.639,
      "duration": 5.841
    },
    {
      "lang": "en",
      "text": "layer we again flatten the output of the",
      "offset": 7360,
      "duration": 5.119
    },
    {
      "lang": "en",
      "text": "convolutions and then pass on the",
      "offset": 7362.48,
      "duration": 5.92
    },
    {
      "lang": "en",
      "text": "flattened output to a threeunit fully",
      "offset": 7365.119,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "connected layer that then provides the",
      "offset": 7368.4,
      "duration": 3.56
    },
    {
      "lang": "en",
      "text": "output of the",
      "offset": 7370.639,
      "duration": 4.52
    },
    {
      "lang": "en",
      "text": "network Let's see how we might implement",
      "offset": 7371.96,
      "duration": 6.679
    },
    {
      "lang": "en",
      "text": "this Here is the code for this network",
      "offset": 7375.159,
      "duration": 5.921
    },
    {
      "lang": "en",
      "text": "First we create the input",
      "offset": 7378.639,
      "duration": 5.201
    },
    {
      "lang": "en",
      "text": "layer This is the same convolutional",
      "offset": 7381.08,
      "duration": 4.36
    },
    {
      "lang": "en",
      "text": "layer that we had in our previous",
      "offset": 7383.84,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "network",
      "offset": 7385.44,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "Then we add one more convolutional layer",
      "offset": 7387.44,
      "duration": 3.96
    },
    {
      "lang": "en",
      "text": "to the",
      "offset": 7390.4,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "network Because this layer receives its",
      "offset": 7391.4,
      "duration": 5.16
    },
    {
      "lang": "en",
      "text": "inputs from the first convolutional",
      "offset": 7394.08,
      "duration": 5.519
    },
    {
      "lang": "en",
      "text": "layer it doesn't require the input shape",
      "offset": 7396.56,
      "duration": 5.96
    },
    {
      "lang": "en",
      "text": "keyword argument to be",
      "offset": 7399.599,
      "duration": 6.08
    },
    {
      "lang": "en",
      "text": "provided Finally we flatten the output",
      "offset": 7402.52,
      "duration": 5.88
    },
    {
      "lang": "en",
      "text": "of the second layer and pass it to a",
      "offset": 7405.679,
      "duration": 5.841
    },
    {
      "lang": "en",
      "text": "dense layer with softmax activation to",
      "offset": 7408.4,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "decide on the output",
      "offset": 7411.52,
      "duration": 4.719
    },
    {
      "lang": "en",
      "text": "Why do we want to add additional layers",
      "offset": 7414,
      "duration": 3.239
    },
    {
      "lang": "en",
      "text": "to a",
      "offset": 7416.239,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "network this is again motivated by our",
      "offset": 7417.239,
      "duration": 5.241
    },
    {
      "lang": "en",
      "text": "own visual system which has multiple",
      "offset": 7419.92,
      "duration": 4.6
    },
    {
      "lang": "en",
      "text": "layers of processing in",
      "offset": 7422.48,
      "duration": 5.759
    },
    {
      "lang": "en",
      "text": "it For example this is the architecture",
      "offset": 7424.52,
      "duration": 5.96
    },
    {
      "lang": "en",
      "text": "of a network developed by Google",
      "offset": 7428.239,
      "duration": 4.121
    },
    {
      "lang": "en",
      "text": "researchers in",
      "offset": 7430.48,
      "duration": 5.92
    },
    {
      "lang": "en",
      "text": "2014 It has 22 layers of convolutions",
      "offset": 7432.36,
      "duration": 6.12
    },
    {
      "lang": "en",
      "text": "and some other kinds of layers like",
      "offset": 7436.4,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "pooling layers that we will discuss in a",
      "offset": 7438.48,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "subsequent lesson",
      "offset": 7440.8,
      "duration": 5.359
    },
    {
      "lang": "en",
      "text": "For the time being one way to understand",
      "offset": 7443.28,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "why we would want a network this deep is",
      "offset": 7446.159,
      "duration": 5.361
    },
    {
      "lang": "en",
      "text": "by looking at the kinds of things that",
      "offset": 7448.96,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "the kernels and feature maps in the",
      "offset": 7451.52,
      "duration": 5.719
    },
    {
      "lang": "en",
      "text": "different layers tend to respond",
      "offset": 7454.08,
      "duration": 6.4
    },
    {
      "lang": "en",
      "text": "to For example these are the kinds of",
      "offset": 7457.239,
      "duration": 5.4
    },
    {
      "lang": "en",
      "text": "things that layers in the early part of",
      "offset": 7460.48,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "the network tend to respond to oriented",
      "offset": 7462.639,
      "duration": 6.56
    },
    {
      "lang": "en",
      "text": "lines or simple textures",
      "offset": 7465.92,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "Intermediate layers of the network tend",
      "offset": 7469.199,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "to respond to more complex features that",
      "offset": 7471.52,
      "duration": 6.84
    },
    {
      "lang": "en",
      "text": "include simple objects such as",
      "offset": 7474.639,
      "duration": 6.801
    },
    {
      "lang": "en",
      "text": "eyes By the time the information travels",
      "offset": 7478.36,
      "duration": 6.44
    },
    {
      "lang": "en",
      "text": "up to higher layers of the network the",
      "offset": 7481.44,
      "duration": 6.32
    },
    {
      "lang": "en",
      "text": "feature maps tend to extract specific",
      "offset": 7484.8,
      "duration": 5.439
    },
    {
      "lang": "en",
      "text": "types of objects",
      "offset": 7487.76,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "This allows the fully connected layers",
      "offset": 7490.239,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "at the top of the network to extract",
      "offset": 7492.48,
      "duration": 5.08
    },
    {
      "lang": "en",
      "text": "useful information for object",
      "offset": 7495.119,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "classification based on the responses of",
      "offset": 7497.56,
      "duration": 5.079
    },
    {
      "lang": "en",
      "text": "these layers",
      "offset": 7500.239,
      "duration": 5.601
    },
    {
      "lang": "en",
      "text": "In other words having multiple layers of",
      "offset": 7502.639,
      "duration": 5.921
    },
    {
      "lang": "en",
      "text": "convolutions in the network allows the",
      "offset": 7505.84,
      "duration": 4.92
    },
    {
      "lang": "en",
      "text": "network to gradually build up",
      "offset": 7508.56,
      "duration": 5.679
    },
    {
      "lang": "en",
      "text": "representations of objects in the images",
      "offset": 7510.76,
      "duration": 6.28
    },
    {
      "lang": "en",
      "text": "from simple features to more complex",
      "offset": 7514.239,
      "duration": 5.281
    },
    {
      "lang": "en",
      "text": "features and up to sensitivity to",
      "offset": 7517.04,
      "duration": 5.48
    },
    {
      "lang": "en",
      "text": "distinct categories of",
      "offset": 7519.52,
      "duration": 6.48
    },
    {
      "lang": "en",
      "text": "objects How deep should your network be",
      "offset": 7522.52,
      "duration": 6.199
    },
    {
      "lang": "en",
      "text": "consider the following Despite the",
      "offset": 7526,
      "duration": 5.92
    },
    {
      "lang": "en",
      "text": "advantages mentioned above depth does",
      "offset": 7528.719,
      "duration": 7.121
    },
    {
      "lang": "en",
      "text": "come at a computational cost In addition",
      "offset": 7531.92,
      "duration": 6.48
    },
    {
      "lang": "en",
      "text": "to train a very deep network you might",
      "offset": 7535.84,
      "duration": 6.64
    },
    {
      "lang": "en",
      "text": "need a larger amount of training",
      "offset": 7538.4,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "data When considering the architecture",
      "offset": 7543.159,
      "duration": 5.721
    },
    {
      "lang": "en",
      "text": "of networks it is sometimes useful to",
      "offset": 7545.84,
      "duration": 5.279
    },
    {
      "lang": "en",
      "text": "think about the number of parameters in",
      "offset": 7548.88,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "the network",
      "offset": 7551.119,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "Consider this dense two-layer network",
      "offset": 7553.04,
      "duration": 6.52
    },
    {
      "lang": "en",
      "text": "that processes images with 28x 28",
      "offset": 7555.599,
      "duration": 8.321
    },
    {
      "lang": "en",
      "text": "pixels The first layer has 10 units Each",
      "offset": 7559.56,
      "duration": 6.679
    },
    {
      "lang": "en",
      "text": "one of them is connected to each one of",
      "offset": 7563.92,
      "duration": 5.48
    },
    {
      "lang": "en",
      "text": "the pixels in the image through a",
      "offset": 7566.239,
      "duration": 7.36
    },
    {
      "lang": "en",
      "text": "weight The second layer has 10 units and",
      "offset": 7569.4,
      "duration": 6.279
    },
    {
      "lang": "en",
      "text": "each one of these is connected to all",
      "offset": 7573.599,
      "duration": 5.241
    },
    {
      "lang": "en",
      "text": "the units in the first layer",
      "offset": 7575.679,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "Finally each one of the units in the",
      "offset": 7578.84,
      "duration": 4.839
    },
    {
      "lang": "en",
      "text": "last layer is connected to each of the",
      "offset": 7581.119,
      "duration": 4.761
    },
    {
      "lang": "en",
      "text": "units in layer",
      "offset": 7583.679,
      "duration": 5.601
    },
    {
      "lang": "en",
      "text": "2 When you construct a caris model you",
      "offset": 7585.88,
      "duration": 5.799
    },
    {
      "lang": "en",
      "text": "can get a description of this model by",
      "offset": 7589.28,
      "duration": 5.16
    },
    {
      "lang": "en",
      "text": "calling the models summary",
      "offset": 7591.679,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "method This tells us that the total",
      "offset": 7594.44,
      "duration": 5.32
    },
    {
      "lang": "en",
      "text": "number of parameters in the model is",
      "offset": 7597.119,
      "duration": 5.641
    },
    {
      "lang": "en",
      "text": "7,993",
      "offset": 7599.76,
      "duration": 3
    },
    {
      "lang": "en",
      "text": "The first layer has",
      "offset": 7604.159,
      "duration": 4.361
    },
    {
      "lang": "en",
      "text": "7,850",
      "offset": 7606.92,
      "duration": 4.52
    },
    {
      "lang": "en",
      "text": "parameters That's one for every pixel in",
      "offset": 7608.52,
      "duration": 6.079
    },
    {
      "lang": "en",
      "text": "the image 784",
      "offset": 7611.44,
      "duration": 6.159
    },
    {
      "lang": "en",
      "text": "pixels times the number of units in this",
      "offset": 7614.599,
      "duration": 7.08
    },
    {
      "lang": "en",
      "text": "layer 10 units plus 10 parameters for",
      "offset": 7617.599,
      "duration": 7.921
    },
    {
      "lang": "en",
      "text": "biased terms in every one of these units",
      "offset": 7621.679,
      "duration": 6.161
    },
    {
      "lang": "en",
      "text": "In the second layer there's one",
      "offset": 7625.52,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "parameter for every unit in layer 1",
      "offset": 7627.84,
      "duration": 6.08
    },
    {
      "lang": "en",
      "text": "times the number of units in this layer",
      "offset": 7630.96,
      "duration": 5.719
    },
    {
      "lang": "en",
      "text": "plus 10 parameters for bias",
      "offset": 7633.92,
      "duration": 6.319
    },
    {
      "lang": "en",
      "text": "terms The last layer has one parameter",
      "offset": 7636.679,
      "duration": 6.44
    },
    {
      "lang": "en",
      "text": "for every unit in layer 2 times the",
      "offset": 7640.239,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "three units in this layer plus three",
      "offset": 7643.119,
      "duration": 5.841
    },
    {
      "lang": "en",
      "text": "bias terms That's why the total number",
      "offset": 7645.679,
      "duration": 7.801
    },
    {
      "lang": "en",
      "text": "of parameters is 7,993",
      "offset": 7648.96,
      "duration": 4.52
    },
    {
      "lang": "en",
      "text": "And that's what the summary shows us",
      "offset": 7655.28,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "here What does that look like for a",
      "offset": 7658.36,
      "duration": 4.839
    },
    {
      "lang": "en",
      "text": "convolutional network with a similar",
      "offset": 7660.8,
      "duration": 4.439
    },
    {
      "lang": "en",
      "text": "number of",
      "offset": 7663.199,
      "duration": 5.121
    },
    {
      "lang": "en",
      "text": "units here is the code implementing a",
      "offset": 7665.239,
      "duration": 5.721
    },
    {
      "lang": "en",
      "text": "CNN with the same number of layers and",
      "offset": 7668.32,
      "duration": 5.48
    },
    {
      "lang": "en",
      "text": "units as our densely connected",
      "offset": 7670.96,
      "duration": 5.92
    },
    {
      "lang": "en",
      "text": "network We run its summary method to",
      "offset": 7673.8,
      "duration": 5.56
    },
    {
      "lang": "en",
      "text": "find the number of parameters which is",
      "offset": 7676.88,
      "duration": 5.48
    },
    {
      "lang": "en",
      "text": "24,533",
      "offset": 7679.36,
      "duration": 3
    },
    {
      "lang": "en",
      "text": "Let's do the math In the first layer",
      "offset": 7684.56,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "there are 10 kernels with nine",
      "offset": 7688,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "parameters each plus 10 bias terms",
      "offset": 7690.56,
      "duration": 4.519
    },
    {
      "lang": "en",
      "text": "That's",
      "offset": 7694,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "100 In the second layer each unit is",
      "offset": 7695.079,
      "duration": 6.6
    },
    {
      "lang": "en",
      "text": "connected through a convolutional kernel",
      "offset": 7698.88,
      "duration": 6.239
    },
    {
      "lang": "en",
      "text": "to each feature map in the first layer",
      "offset": 7701.679,
      "duration": 7.681
    },
    {
      "lang": "en",
      "text": "That's 10 * 9 * 10 parameters which is",
      "offset": 7705.119,
      "duration": 7.681
    },
    {
      "lang": "en",
      "text": "900 and a bias term for each unit which",
      "offset": 7709.36,
      "duration": 5.879
    },
    {
      "lang": "en",
      "text": "is a total of",
      "offset": 7712.8,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "910 The flatten layer has no parameters",
      "offset": 7715.239,
      "duration": 5.721
    },
    {
      "lang": "en",
      "text": "at all It just takes the output from the",
      "offset": 7718.32,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "feature maps in layer 2 and flattens",
      "offset": 7720.96,
      "duration": 5.159
    },
    {
      "lang": "en",
      "text": "them into one big",
      "offset": 7723.76,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "array Because there is zero padding here",
      "offset": 7726.119,
      "duration": 5.801
    },
    {
      "lang": "en",
      "text": "the convolution leaves the same number",
      "offset": 7729.28,
      "duration": 5.359
    },
    {
      "lang": "en",
      "text": "of pixels in each subsequent layer So we",
      "offset": 7731.92,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "end up with 28x 28 pixels in each",
      "offset": 7734.639,
      "duration": 7.08
    },
    {
      "lang": "en",
      "text": "feature map with 10 feature maps or",
      "offset": 7737.52,
      "duration": 7.76
    },
    {
      "lang": "en",
      "text": "7,840 pixels in total times three units",
      "offset": 7741.719,
      "duration": 7.601
    },
    {
      "lang": "en",
      "text": "in the last layer is",
      "offset": 7745.28,
      "duration": 9.439
    },
    {
      "lang": "en",
      "text": "23,520 plus three bias terms is",
      "offset": 7749.32,
      "duration": 5.399
    },
    {
      "lang": "en",
      "text": "23,523 Adding together we get",
      "offset": 7755.4,
      "duration": 5
    },
    {
      "lang": "en",
      "text": "24,533 So convolutional layers don't",
      "offset": 7761.4,
      "duration": 4.52
    },
    {
      "lang": "en",
      "text": "necessarily reduce the number of",
      "offset": 7764.159,
      "duration": 3.281
    },
    {
      "lang": "en",
      "text": "parameters",
      "offset": 7765.92,
      "duration": 3.239
    },
    {
      "lang": "en",
      "text": "Let's look at another",
      "offset": 7767.44,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "example Here is a densely connected",
      "offset": 7769.159,
      "duration": 4.92
    },
    {
      "lang": "en",
      "text": "network with an increasing number of",
      "offset": 7771.76,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "units in each layer How many parameters",
      "offset": 7774.079,
      "duration": 5.08
    },
    {
      "lang": "en",
      "text": "does this network",
      "offset": 7777.76,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "have for this architecture a lot of the",
      "offset": 7779.159,
      "duration": 6.201
    },
    {
      "lang": "en",
      "text": "parameters are concentrated at the first",
      "offset": 7782.48,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "layer of the network and then subsequent",
      "offset": 7785.36,
      "duration": 5.16
    },
    {
      "lang": "en",
      "text": "layers have much fewer",
      "offset": 7787.52,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "parameters This is the convolutional",
      "offset": 7790.52,
      "duration": 4.119
    },
    {
      "lang": "en",
      "text": "network with the equivalent number of",
      "offset": 7792.8,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "units in each layer",
      "offset": 7794.639,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "In contrast to the densely connected",
      "offset": 7797.199,
      "duration": 4.801
    },
    {
      "lang": "en",
      "text": "neural network when we run the summary",
      "offset": 7799.199,
      "duration": 5.681
    },
    {
      "lang": "en",
      "text": "method on this network we see that the",
      "offset": 7802,
      "duration": 5.56
    },
    {
      "lang": "en",
      "text": "very first layers use very few",
      "offset": 7804.88,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "parameters while the last layer uses a",
      "offset": 7807.56,
      "duration": 5.4
    },
    {
      "lang": "en",
      "text": "lot of parameters",
      "offset": 7810.48,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "One way to think about this is that the",
      "offset": 7812.96,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "convolutions have more expressive power",
      "offset": 7815.36,
      "duration": 6.319
    },
    {
      "lang": "en",
      "text": "So they require less parameters but",
      "offset": 7818.56,
      "duration": 5.4
    },
    {
      "lang": "en",
      "text": "reading out these more expressive",
      "offset": 7821.679,
      "duration": 4.801
    },
    {
      "lang": "en",
      "text": "representations then requires many more",
      "offset": 7823.96,
      "duration": 6.119
    },
    {
      "lang": "en",
      "text": "parameters on the output",
      "offset": 7826.48,
      "duration": 3.599
    },
    {
      "lang": "en",
      "text": "side One of the challenges in fitting",
      "offset": 7830.599,
      "duration": 5.241
    },
    {
      "lang": "en",
      "text": "neural networks is the large number of",
      "offset": 7833.44,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "parameters",
      "offset": 7835.84,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "One way to mitigate this is to summarize",
      "offset": 7837.84,
      "duration": 5.279
    },
    {
      "lang": "en",
      "text": "the output of convolutional layers in a",
      "offset": 7840.56,
      "duration": 3.8
    },
    {
      "lang": "en",
      "text": "concise",
      "offset": 7843.119,
      "duration": 5.48
    },
    {
      "lang": "en",
      "text": "manner To do this we can use pooling",
      "offset": 7844.36,
      "duration": 6.839
    },
    {
      "lang": "en",
      "text": "operations For example we might",
      "offset": 7848.599,
      "duration": 5.48
    },
    {
      "lang": "en",
      "text": "summarize a group of pixels based on its",
      "offset": 7851.199,
      "duration": 3.88
    },
    {
      "lang": "en",
      "text": "maximal",
      "offset": 7854.079,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "value This is called max pooling",
      "offset": 7855.079,
      "duration": 6.681
    },
    {
      "lang": "en",
      "text": "In this image we might start with the",
      "offset": 7858.719,
      "duration": 6.321
    },
    {
      "lang": "en",
      "text": "top left corner extracting the pixels in",
      "offset": 7861.76,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "this part of the image and calculating",
      "offset": 7865.04,
      "duration": 6.32
    },
    {
      "lang": "en",
      "text": "the maximal value of the pixels there In",
      "offset": 7867.76,
      "duration": 6.959
    },
    {
      "lang": "en",
      "text": "the output we replace these pixels with",
      "offset": 7871.36,
      "duration": 6.4
    },
    {
      "lang": "en",
      "text": "one large pixel that stores this maximal",
      "offset": 7874.719,
      "duration": 4.721
    },
    {
      "lang": "en",
      "text": "value",
      "offset": 7877.76,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "We shift our window and calculate the",
      "offset": 7879.44,
      "duration": 4.6
    },
    {
      "lang": "en",
      "text": "maximal value in the pixels in the next",
      "offset": 7881.84,
      "duration": 5.279
    },
    {
      "lang": "en",
      "text": "window Replacing that part of the image",
      "offset": 7884.04,
      "duration": 5.639
    },
    {
      "lang": "en",
      "text": "with one large pixel with the maximal",
      "offset": 7887.119,
      "duration": 5
    },
    {
      "lang": "en",
      "text": "value in that part of the",
      "offset": 7889.679,
      "duration": 5.761
    },
    {
      "lang": "en",
      "text": "image If we repeat this operation in",
      "offset": 7892.119,
      "duration": 6.52
    },
    {
      "lang": "en",
      "text": "multiple windows of size 2x two we end",
      "offset": 7895.44,
      "duration": 6.08
    },
    {
      "lang": "en",
      "text": "up with an image that has a quarter of",
      "offset": 7898.639,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "the number of the original pixels and",
      "offset": 7901.52,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "retains only the brightest feature in",
      "offset": 7904.159,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "each part of the image",
      "offset": 7906.8,
      "duration": 5.439
    },
    {
      "lang": "en",
      "text": "To understand this operation let's see",
      "offset": 7909.599,
      "duration": 4.201
    },
    {
      "lang": "en",
      "text": "how to implement",
      "offset": 7912.239,
      "duration": 5.201
    },
    {
      "lang": "en",
      "text": "it We start by allocating the output",
      "offset": 7913.8,
      "duration": 6.2
    },
    {
      "lang": "en",
      "text": "This has half as many pixels on each",
      "offset": 7917.44,
      "duration": 4.92
    },
    {
      "lang": "en",
      "text": "dimension as the",
      "offset": 7920,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "input We start from the first coordinate",
      "offset": 7922.36,
      "duration": 5.719
    },
    {
      "lang": "en",
      "text": "in the output Calculating the maximum of",
      "offset": 7925.04,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "the image in the first two coordinates",
      "offset": 7928.079,
      "duration": 5.441
    },
    {
      "lang": "en",
      "text": "on each dimension of the input",
      "offset": 7930.48,
      "duration": 5.84
    },
    {
      "lang": "en",
      "text": "Next we slide along the window by two",
      "offset": 7933.52,
      "duration": 5.599
    },
    {
      "lang": "en",
      "text": "pixels along the first dimension",
      "offset": 7936.32,
      "duration": 5.16
    },
    {
      "lang": "en",
      "text": "calculating the maximum for this",
      "offset": 7939.119,
      "duration": 5.361
    },
    {
      "lang": "en",
      "text": "window We keep going like that until we",
      "offset": 7941.48,
      "duration": 5.639
    },
    {
      "lang": "en",
      "text": "are done with the first row in the input",
      "offset": 7944.48,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "We then move the window to the beginning",
      "offset": 7947.119,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "of the second row in the input",
      "offset": 7949.44,
      "duration": 3.759
    },
    {
      "lang": "en",
      "text": "calculating the maximum for the",
      "offset": 7951.599,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "coordinates in the third and fourth rows",
      "offset": 7953.199,
      "duration": 4.681
    },
    {
      "lang": "en",
      "text": "in the input for this",
      "offset": 7955.76,
      "duration": 5.08
    },
    {
      "lang": "en",
      "text": "location We continue sliding the window",
      "offset": 7957.88,
      "duration": 6.44
    },
    {
      "lang": "en",
      "text": "along Ultimately in each location in the",
      "offset": 7960.84,
      "duration": 6.279
    },
    {
      "lang": "en",
      "text": "output we calculate the maximum for a",
      "offset": 7964.32,
      "duration": 5.359
    },
    {
      "lang": "en",
      "text": "window of 2x two pixels at the",
      "offset": 7967.119,
      "duration": 5.321
    },
    {
      "lang": "en",
      "text": "corresponding location in the",
      "offset": 7969.679,
      "duration": 5.281
    },
    {
      "lang": "en",
      "text": "input Another way of implementing this",
      "offset": 7972.44,
      "duration": 5.48
    },
    {
      "lang": "en",
      "text": "operation is with a loop In each",
      "offset": 7974.96,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "iteration we first select the",
      "offset": 7977.92,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "corresponding rows from the current row",
      "offset": 7980,
      "duration": 7.199
    },
    {
      "lang": "en",
      "text": "in the output index ii times 2 and until",
      "offset": 7982.88,
      "duration": 5.96
    },
    {
      "lang": "en",
      "text": "two pixels beyond",
      "offset": 7987.199,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "that and the same for the internal loop",
      "offset": 7988.84,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "on the column index",
      "offset": 7991.599,
      "duration": 6.401
    },
    {
      "lang": "en",
      "text": "JJ This performs the same operation that",
      "offset": 7994.52,
      "duration": 7.04
    },
    {
      "lang": "en",
      "text": "we previously broke down row by",
      "offset": 7998,
      "duration": 6.159
    },
    {
      "lang": "en",
      "text": "row We can integrate max pooling",
      "offset": 8001.56,
      "duration": 5
    },
    {
      "lang": "en",
      "text": "operations into a caris convolutional",
      "offset": 8004.159,
      "duration": 6.761
    },
    {
      "lang": "en",
      "text": "neural network using the max pool 2d",
      "offset": 8006.56,
      "duration": 7.599
    },
    {
      "lang": "en",
      "text": "object After importing this object in",
      "offset": 8010.92,
      "duration": 5.64
    },
    {
      "lang": "en",
      "text": "addition to the other objects we'll need",
      "offset": 8014.159,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "we start off building a convolutional",
      "offset": 8016.56,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "neural network just like before But",
      "offset": 8018.48,
      "duration": 5.84
    },
    {
      "lang": "en",
      "text": "after each convolutional layer we'll add",
      "offset": 8022,
      "duration": 3.639
    },
    {
      "lang": "en",
      "text": "a pooling",
      "offset": 8024.32,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "layer The input to the max pool 2D",
      "offset": 8025.639,
      "duration": 5.96
    },
    {
      "lang": "en",
      "text": "object two in this case is the size of",
      "offset": 8028.639,
      "duration": 6.241
    },
    {
      "lang": "en",
      "text": "the pooling window That means that here",
      "offset": 8031.599,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "pooling will take the max over a window",
      "offset": 8034.88,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "of 2x two pixels from the input for each",
      "offset": 8037.199,
      "duration": 4.761
    },
    {
      "lang": "en",
      "text": "location in the",
      "offset": 8040.56,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "output We add a second convolutional",
      "offset": 8041.96,
      "duration": 5.279
    },
    {
      "lang": "en",
      "text": "layer followed by another max pooling",
      "offset": 8044.56,
      "duration": 5.119
    },
    {
      "lang": "en",
      "text": "layer The summarization part of the",
      "offset": 8047.239,
      "duration": 4.521
    },
    {
      "lang": "en",
      "text": "network is the same as before A",
      "offset": 8049.679,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "flattening layer followed by a dense",
      "offset": 8051.76,
      "duration": 5.16
    },
    {
      "lang": "en",
      "text": "layer with softmax",
      "offset": 8054.239,
      "duration": 4.721
    },
    {
      "lang": "en",
      "text": "activation How does this affect the",
      "offset": 8056.92,
      "duration": 3.96
    },
    {
      "lang": "en",
      "text": "number of parameters",
      "offset": 8058.96,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "running the summary method for this",
      "offset": 8060.88,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "model we can see that using the pooling",
      "offset": 8062.48,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "operation dramatically reduces the",
      "offset": 8064.8,
      "duration": 4.279
    },
    {
      "lang": "en",
      "text": "number of parameters in the",
      "offset": 8067.04,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "model Instead of more than 30,000",
      "offset": 8069.079,
      "duration": 5.08
    },
    {
      "lang": "en",
      "text": "parameters that this m model had with no",
      "offset": 8071.76,
      "duration": 5.439
    },
    {
      "lang": "en",
      "text": "pooling operations we now have less than",
      "offset": 8074.159,
      "duration": 4.761
    },
    {
      "lang": "en",
      "text": "2,000",
      "offset": 8077.199,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "parameters There are of course",
      "offset": 8078.92,
      "duration": 5.4
    },
    {
      "lang": "en",
      "text": "trade-offs to reducing the number of",
      "offset": 8080.719,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "parameters During learning the weights",
      "offset": 8085,
      "duration": 5.8
    },
    {
      "lang": "en",
      "text": "used by the network change",
      "offset": 8088.32,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "And as they change the network becomes",
      "offset": 8090.8,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "more attuned to the features of the",
      "offset": 8093.44,
      "duration": 4.6
    },
    {
      "lang": "en",
      "text": "images that discriminate between",
      "offset": 8095.28,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "classes This means that the loss",
      "offset": 8098.04,
      "duration": 4.76
    },
    {
      "lang": "en",
      "text": "function we use for training becomes",
      "offset": 8100.4,
      "duration": 4.12
    },
    {
      "lang": "en",
      "text": "smaller and",
      "offset": 8102.8,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "smaller Looking at the change in the",
      "offset": 8104.52,
      "duration": 5.079
    },
    {
      "lang": "en",
      "text": "loss with learning can be helpful to see",
      "offset": 8106.96,
      "duration": 5.32
    },
    {
      "lang": "en",
      "text": "whether learning is progressing as",
      "offset": 8109.599,
      "duration": 5.201
    },
    {
      "lang": "en",
      "text": "expected and whether the network has",
      "offset": 8112.28,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "learned",
      "offset": 8114.8,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "enough As long as learning is",
      "offset": 8116.52,
      "duration": 4.44
    },
    {
      "lang": "en",
      "text": "progressing well we might expect the",
      "offset": 8118.88,
      "duration": 4.44
    },
    {
      "lang": "en",
      "text": "loss function to keep going",
      "offset": 8120.96,
      "duration": 5.759
    },
    {
      "lang": "en",
      "text": "down For example here is a curve showing",
      "offset": 8123.32,
      "duration": 6.919
    },
    {
      "lang": "en",
      "text": "the categorical cross entropy loss in a",
      "offset": 8126.719,
      "duration": 5.281
    },
    {
      "lang": "en",
      "text": "network that is learning to classify",
      "offset": 8130.239,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "different types of clothing measured on",
      "offset": 8132,
      "duration": 3.88
    },
    {
      "lang": "en",
      "text": "the training",
      "offset": 8134.639,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "set You can see that loss rapidly",
      "offset": 8135.88,
      "duration": 5.279
    },
    {
      "lang": "en",
      "text": "decreases in the first few epochs of",
      "offset": 8138.8,
      "duration": 6.799
    },
    {
      "lang": "en",
      "text": "training after which learning slows down",
      "offset": 8141.159,
      "duration": 6.44
    },
    {
      "lang": "en",
      "text": "This is a sign that learning is going",
      "offset": 8145.599,
      "duration": 3.48
    },
    {
      "lang": "en",
      "text": "rather",
      "offset": 8147.599,
      "duration": 4.961
    },
    {
      "lang": "en",
      "text": "well On the other hand if we add the",
      "offset": 8149.079,
      "duration": 5.961
    },
    {
      "lang": "en",
      "text": "validation loss to this plot we can see",
      "offset": 8152.56,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "that learning is progressing to some",
      "offset": 8155.04,
      "duration": 4.28
    },
    {
      "lang": "en",
      "text": "level of loss and then flattens",
      "offset": 8156.8,
      "duration": 4.839
    },
    {
      "lang": "en",
      "text": "out What's going",
      "offset": 8159.32,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "on this is a form of",
      "offset": 8161.639,
      "duration": 5
    },
    {
      "lang": "en",
      "text": "overfitting Because neural networks have",
      "offset": 8164.28,
      "duration": 5
    },
    {
      "lang": "en",
      "text": "so many parameters that can be adjusted",
      "offset": 8166.639,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "the weights can be adjusted to",
      "offset": 8169.28,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "accurately classify But this performance",
      "offset": 8171.04,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "does not generalize well outside of the",
      "offset": 8173.92,
      "duration": 3.48
    },
    {
      "lang": "en",
      "text": "training",
      "offset": 8176.4,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "set When validated against a separate",
      "offset": 8177.4,
      "duration": 5.92
    },
    {
      "lang": "en",
      "text": "set of data loss cannot become",
      "offset": 8180.32,
      "duration": 6.08
    },
    {
      "lang": "en",
      "text": "better In fact if we keep training for",
      "offset": 8183.32,
      "duration": 6.2
    },
    {
      "lang": "en",
      "text": "many epochs the validation accuracy can",
      "offset": 8186.4,
      "duration": 5.999
    },
    {
      "lang": "en",
      "text": "start increasing back up again This is a",
      "offset": 8189.52,
      "duration": 5.039
    },
    {
      "lang": "en",
      "text": "sign that we have passed the point at",
      "offset": 8192.399,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "which the model weights are being",
      "offset": 8194.559,
      "duration": 4.641
    },
    {
      "lang": "en",
      "text": "adjusted in a useful way and we are",
      "offset": 8196.319,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "starting to overfitit to the specifics",
      "offset": 8199.2,
      "duration": 4.279
    },
    {
      "lang": "en",
      "text": "of the training",
      "offset": 8201.359,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "data To generate these curves we need a",
      "offset": 8203.479,
      "duration": 5.761
    },
    {
      "lang": "en",
      "text": "model like the ones that you've seen",
      "offset": 8206.639,
      "duration": 5.281
    },
    {
      "lang": "en",
      "text": "before We capture the results of fitting",
      "offset": 8209.24,
      "duration": 5.239
    },
    {
      "lang": "en",
      "text": "our model into a training variable which",
      "offset": 8211.92,
      "duration": 4.719
    },
    {
      "lang": "en",
      "text": "has a dictionary that stores the",
      "offset": 8214.479,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "learning curves",
      "offset": 8216.639,
      "duration": 4.481
    },
    {
      "lang": "en",
      "text": "We can plot the loss in the training set",
      "offset": 8218.399,
      "duration": 4.801
    },
    {
      "lang": "en",
      "text": "and also add a plot of the loss in the",
      "offset": 8221.12,
      "duration": 4.519
    },
    {
      "lang": "en",
      "text": "validation",
      "offset": 8223.2,
      "duration": 5.279
    },
    {
      "lang": "en",
      "text": "set How do we use the best parameters",
      "offset": 8225.639,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "before the network starts",
      "offset": 8228.479,
      "duration": 4.481
    },
    {
      "lang": "en",
      "text": "overfitting by using the callbacks",
      "offset": 8230.679,
      "duration": 4.281
    },
    {
      "lang": "en",
      "text": "module from caris which contain",
      "offset": 8232.96,
      "duration": 4.559
    },
    {
      "lang": "en",
      "text": "functions that can be executed at the",
      "offset": 8234.96,
      "duration": 5.92
    },
    {
      "lang": "en",
      "text": "end of each training epoch",
      "offset": 8237.519,
      "duration": 5.281
    },
    {
      "lang": "en",
      "text": "One of these callbacks is a model",
      "offset": 8240.88,
      "duration": 4.799
    },
    {
      "lang": "en",
      "text": "checkpoint object that can be used to",
      "offset": 8242.8,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "store the weights of a network at the",
      "offset": 8245.679,
      "duration": 4.68
    },
    {
      "lang": "en",
      "text": "end of each epoch of",
      "offset": 8248.16,
      "duration": 5.8
    },
    {
      "lang": "en",
      "text": "learning When it is initialized an",
      "offset": 8250.359,
      "duration": 6.16
    },
    {
      "lang": "en",
      "text": "HDF5 file is",
      "offset": 8253.96,
      "duration": 6.92
    },
    {
      "lang": "en",
      "text": "created Here we call it",
      "offset": 8256.519,
      "duration": 4.361
    },
    {
      "lang": "en",
      "text": "weights.hdf5 The callback monitors the",
      "offset": 8261.399,
      "duration": 5.561
    },
    {
      "lang": "en",
      "text": "validation loss and will only overwrite",
      "offset": 8264.16,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "the weights whenever the validation loss",
      "offset": 8266.96,
      "duration": 3.759
    },
    {
      "lang": "en",
      "text": "shows improvement",
      "offset": 8269.2,
      "duration": 4.68
    },
    {
      "lang": "en",
      "text": "that is the validation loss",
      "offset": 8270.719,
      "duration": 6.201
    },
    {
      "lang": "en",
      "text": "decreases This means that if the network",
      "offset": 8273.88,
      "duration": 5.719
    },
    {
      "lang": "en",
      "text": "overfits the weights will be stored for",
      "offset": 8276.92,
      "duration": 5.08
    },
    {
      "lang": "en",
      "text": "the epoch at which the validation loss",
      "offset": 8279.599,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "was the smallest before it started",
      "offset": 8282,
      "duration": 3.719
    },
    {
      "lang": "en",
      "text": "rising back",
      "offset": 8284.479,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "up The checkpoint object is stored in a",
      "offset": 8285.719,
      "duration": 5.96
    },
    {
      "lang": "en",
      "text": "list and passed as input to the model",
      "offset": 8288.88,
      "duration": 4.2
    },
    {
      "lang": "en",
      "text": "fitting",
      "offset": 8291.679,
      "duration": 4.241
    },
    {
      "lang": "en",
      "text": "procedure After all epochs of fitting",
      "offset": 8293.08,
      "duration": 6.88
    },
    {
      "lang": "en",
      "text": "are done this file contains the best",
      "offset": 8295.92,
      "duration": 7.2
    },
    {
      "lang": "en",
      "text": "weights To use these weights we'll need",
      "offset": 8299.96,
      "duration": 5.559
    },
    {
      "lang": "en",
      "text": "to initialize the model again with the",
      "offset": 8303.12,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "same architecture the same layers with",
      "offset": 8305.519,
      "duration": 5.441
    },
    {
      "lang": "en",
      "text": "the same number of units in each We can",
      "offset": 8307.76,
      "duration": 6.16
    },
    {
      "lang": "en",
      "text": "then use the model's load weights method",
      "offset": 8310.96,
      "duration": 5.359
    },
    {
      "lang": "en",
      "text": "to bring the model weights back to their",
      "offset": 8313.92,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "value when the model was at its best",
      "offset": 8316.319,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "during training",
      "offset": 8319.12,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "We can then use the weights in all kinds",
      "offset": 8321.679,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "of ways For example we can use the model",
      "offset": 8323.439,
      "duration": 6.08
    },
    {
      "lang": "en",
      "text": "weights to predict the classes of a",
      "offset": 8326.719,
      "duration": 6.72
    },
    {
      "lang": "en",
      "text": "separate test image data set using the",
      "offset": 8329.519,
      "duration": 5.88
    },
    {
      "lang": "en",
      "text": "predict classes",
      "offset": 8333.439,
      "duration": 5.521
    },
    {
      "lang": "en",
      "text": "method Each entry in the result is the",
      "offset": 8335.399,
      "duration": 5.96
    },
    {
      "lang": "en",
      "text": "column corresponding to the clothing",
      "offset": 8338.96,
      "duration": 7.32
    },
    {
      "lang": "en",
      "text": "article in the one hot encoded array",
      "offset": 8341.359,
      "duration": 4.921
    },
    {
      "lang": "en",
      "text": "How do we prevent overfitting and make",
      "offset": 8347.28,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "the best out of our training data one of",
      "offset": 8349.679,
      "duration": 5.521
    },
    {
      "lang": "en",
      "text": "the strategies that has proven effective",
      "offset": 8352.8,
      "duration": 3.719
    },
    {
      "lang": "en",
      "text": "is",
      "offset": 8355.2,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "regularization Here we'll discuss two",
      "offset": 8356.519,
      "duration": 4.92
    },
    {
      "lang": "en",
      "text": "strategies for regularization of",
      "offset": 8359.359,
      "duration": 4.04
    },
    {
      "lang": "en",
      "text": "convolutional neural",
      "offset": 8361.439,
      "duration": 5.481
    },
    {
      "lang": "en",
      "text": "networks The first strategy is called",
      "offset": 8363.399,
      "duration": 6.441
    },
    {
      "lang": "en",
      "text": "dropout In each step of learning we",
      "offset": 8366.92,
      "duration": 5.639
    },
    {
      "lang": "en",
      "text": "choose a random subset of the units in a",
      "offset": 8369.84,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "layer and we ignore it",
      "offset": 8372.559,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "This group of units would be ignored",
      "offset": 8374.88,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "both on the forward pass through the",
      "offset": 8376.88,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "network as well as in the back",
      "offset": 8379.04,
      "duration": 3.88
    },
    {
      "lang": "en",
      "text": "propagation",
      "offset": 8381.28,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "stage Here is an image that explains",
      "offset": 8382.92,
      "duration": 5.24
    },
    {
      "lang": "en",
      "text": "this idea from the original paper by",
      "offset": 8385.359,
      "duration": 5.441
    },
    {
      "lang": "en",
      "text": "Nitish Sri Vastava and his colleagues",
      "offset": 8388.16,
      "duration": 5.88
    },
    {
      "lang": "en",
      "text": "that introduced this idea in",
      "offset": 8390.8,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "2014 On the left is a fully connected",
      "offset": 8394.04,
      "duration": 5.56
    },
    {
      "lang": "en",
      "text": "network and on the right is this network",
      "offset": 8396.8,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "with dropout applied to it during one",
      "offset": 8399.6,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "step of training",
      "offset": 8402.24,
      "duration": 4.239
    },
    {
      "lang": "en",
      "text": "This might sound strange but this",
      "offset": 8404.24,
      "duration": 5.079
    },
    {
      "lang": "en",
      "text": "regularization strategy can work really",
      "offset": 8406.479,
      "duration": 5.361
    },
    {
      "lang": "en",
      "text": "well This is because it allows us to",
      "offset": 8409.319,
      "duration": 4.761
    },
    {
      "lang": "en",
      "text": "train many different networks on",
      "offset": 8411.84,
      "duration": 5.92
    },
    {
      "lang": "en",
      "text": "different parts of the data Each time",
      "offset": 8414.08,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "the network that is trained is randomly",
      "offset": 8417.76,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "chosen from the full network",
      "offset": 8420.08,
      "duration": 5.84
    },
    {
      "lang": "en",
      "text": "This way if part of the network becomes",
      "offset": 8423.2,
      "duration": 5.84
    },
    {
      "lang": "en",
      "text": "too sensitive to some noise in the data",
      "offset": 8425.92,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "other parts will compensate for this",
      "offset": 8429.04,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "because they haven't seen the samples",
      "offset": 8431.68,
      "duration": 4.04
    },
    {
      "lang": "en",
      "text": "with this",
      "offset": 8433.76,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "noise It also helps prevent different",
      "offset": 8435.72,
      "duration": 5.24
    },
    {
      "lang": "en",
      "text": "units in the network from becoming",
      "offset": 8438.64,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "overly correlated in their activity",
      "offset": 8440.96,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "One way to think about this is that if",
      "offset": 8444,
      "duration": 5
    },
    {
      "lang": "en",
      "text": "one unit learns to prefer horizontal",
      "offset": 8446.08,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "orientations another unit would be",
      "offset": 8449,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "trained to prefer vertical",
      "offset": 8451.2,
      "duration": 6.159
    },
    {
      "lang": "en",
      "text": "ones In caris dropout is implemented as",
      "offset": 8453.399,
      "duration": 7.321
    },
    {
      "lang": "en",
      "text": "a layer When we construct the network we",
      "offset": 8457.359,
      "duration": 6.241
    },
    {
      "lang": "en",
      "text": "add a dropout layer after the layer for",
      "offset": 8460.72,
      "duration": 5.599
    },
    {
      "lang": "en",
      "text": "which we want units ignored",
      "offset": 8463.6,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "When using dropout we'll need to choose",
      "offset": 8466.319,
      "duration": 4.721
    },
    {
      "lang": "en",
      "text": "what proportion of the units in the",
      "offset": 8468.72,
      "duration": 5.4
    },
    {
      "lang": "en",
      "text": "layer to ignore in each learning",
      "offset": 8471.04,
      "duration": 6.64
    },
    {
      "lang": "en",
      "text": "step For example here I have chosen to",
      "offset": 8474.12,
      "duration": 6.8
    },
    {
      "lang": "en",
      "text": "drop 25% of the units in the first",
      "offset": 8477.68,
      "duration": 5.92
    },
    {
      "lang": "en",
      "text": "layer The rest of the model that follows",
      "offset": 8480.92,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "is",
      "offset": 8483.6,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "unchanged Compiling and training the",
      "offset": 8484.28,
      "duration": 5.96
    },
    {
      "lang": "en",
      "text": "model is also unchanged",
      "offset": 8486.72,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "Another form of regularization in",
      "offset": 8490.24,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "convolutional neural networks is called",
      "offset": 8492.08,
      "duration": 4.359
    },
    {
      "lang": "en",
      "text": "batch",
      "offset": 8494.88,
      "duration": 4.559
    },
    {
      "lang": "en",
      "text": "normalization As the name suggests this",
      "offset": 8496.439,
      "duration": 5.321
    },
    {
      "lang": "en",
      "text": "operation takes the output of a",
      "offset": 8499.439,
      "duration": 5.361
    },
    {
      "lang": "en",
      "text": "particular layer and rescales it so that",
      "offset": 8501.76,
      "duration": 5.679
    },
    {
      "lang": "en",
      "text": "it always has zero mean and standard",
      "offset": 8504.8,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "deviation of one in every batch of",
      "offset": 8507.439,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "training",
      "offset": 8509.84,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "This idea was proposed in a paper by",
      "offset": 8511.84,
      "duration": 6.68
    },
    {
      "lang": "en",
      "text": "Sergey Yof and Christian Jedi in",
      "offset": 8514.64,
      "duration": 6.799
    },
    {
      "lang": "en",
      "text": "2015 The algorithm solves the problem",
      "offset": 8518.52,
      "duration": 5.48
    },
    {
      "lang": "en",
      "text": "where different batches of input might",
      "offset": 8521.439,
      "duration": 4.801
    },
    {
      "lang": "en",
      "text": "produce wildly different distributions",
      "offset": 8524,
      "duration": 5.72
    },
    {
      "lang": "en",
      "text": "of outputs in any given layer in the",
      "offset": 8526.24,
      "duration": 6.56
    },
    {
      "lang": "en",
      "text": "network because the adjustments to the",
      "offset": 8529.72,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "weights through back",
      "offset": 8532.8,
      "duration": 4.639
    },
    {
      "lang": "en",
      "text": "propagation depend on the activation of",
      "offset": 8534.76,
      "duration": 5.639
    },
    {
      "lang": "en",
      "text": "the units in every step of learning This",
      "offset": 8537.439,
      "duration": 5.681
    },
    {
      "lang": "en",
      "text": "means that the network may progress very",
      "offset": 8540.399,
      "duration": 4.281
    },
    {
      "lang": "en",
      "text": "slowly through",
      "offset": 8543.12,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "training Batch normalization is also",
      "offset": 8544.68,
      "duration": 5.24
    },
    {
      "lang": "en",
      "text": "implemented as another type of layer",
      "offset": 8547.76,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "that can be added after each one of the",
      "offset": 8549.92,
      "duration": 4.439
    },
    {
      "lang": "en",
      "text": "layers whose output should be",
      "offset": 8552.24,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "normalized Here I have added a single",
      "offset": 8554.359,
      "duration": 5.561
    },
    {
      "lang": "en",
      "text": "batch normalization operation after the",
      "offset": 8557.28,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "first layer The rest of the network is",
      "offset": 8559.92,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "unchanged and compiling and training the",
      "offset": 8562.72,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "network would proceed as you have seen",
      "offset": 8565.2,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "before",
      "offset": 8566.96,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "Finally a word of warning Sometimes",
      "offset": 8568.96,
      "duration": 5.519
    },
    {
      "lang": "en",
      "text": "dropout and batch normalization do not",
      "offset": 8572.16,
      "duration": 3.4
    },
    {
      "lang": "en",
      "text": "work well",
      "offset": 8574.479,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "together This is because while dropout",
      "offset": 8575.56,
      "duration": 4.68
    },
    {
      "lang": "en",
      "text": "slows down learning making it more",
      "offset": 8578.16,
      "duration": 4.68
    },
    {
      "lang": "en",
      "text": "incremental and careful batch",
      "offset": 8580.24,
      "duration": 5.64
    },
    {
      "lang": "en",
      "text": "normalization tends to make learning go",
      "offset": 8582.84,
      "duration": 5.479
    },
    {
      "lang": "en",
      "text": "faster Their effects together may in",
      "offset": 8585.88,
      "duration": 4.84
    },
    {
      "lang": "en",
      "text": "fact counter each other and networks",
      "offset": 8588.319,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "sometimes perform worse when both of",
      "offset": 8590.72,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "these methods are used together than",
      "offset": 8593.439,
      "duration": 5.761
    },
    {
      "lang": "en",
      "text": "they would if neither were used This has",
      "offset": 8596.08,
      "duration": 5.279
    },
    {
      "lang": "en",
      "text": "been called the disharmony of batch",
      "offset": 8599.2,
      "duration": 5.199
    },
    {
      "lang": "en",
      "text": "normalization and",
      "offset": 8601.359,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "dropout One of the main criticisms of",
      "offset": 8605.16,
      "duration": 5.72
    },
    {
      "lang": "en",
      "text": "convolutional neural networks is that",
      "offset": 8608.319,
      "duration": 5.761
    },
    {
      "lang": "en",
      "text": "they are black boxes and that even when",
      "offset": 8610.88,
      "duration": 5.96
    },
    {
      "lang": "en",
      "text": "they work very well it is hard to",
      "offset": 8614.08,
      "duration": 6.319
    },
    {
      "lang": "en",
      "text": "understand why they work so well",
      "offset": 8616.84,
      "duration": 5.96
    },
    {
      "lang": "en",
      "text": "Many efforts are being made to improve",
      "offset": 8620.399,
      "duration": 5.681
    },
    {
      "lang": "en",
      "text": "the interpretability of neural networks",
      "offset": 8622.8,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "and this field is likely to evolve",
      "offset": 8626.08,
      "duration": 5.319
    },
    {
      "lang": "en",
      "text": "rapidly in the next few",
      "offset": 8628.08,
      "duration": 6.319
    },
    {
      "lang": "en",
      "text": "years One of the major thrusts of this",
      "offset": 8631.399,
      "duration": 5.321
    },
    {
      "lang": "en",
      "text": "evolution is that people are interested",
      "offset": 8634.399,
      "duration": 5.121
    },
    {
      "lang": "en",
      "text": "in visualizing what different parts of",
      "offset": 8636.72,
      "duration": 6.56
    },
    {
      "lang": "en",
      "text": "the network are doing Here I will show",
      "offset": 8639.52,
      "duration": 5.839
    },
    {
      "lang": "en",
      "text": "you how to take apart a trained",
      "offset": 8643.28,
      "duration": 5.039
    },
    {
      "lang": "en",
      "text": "convolutional network select particular",
      "offset": 8645.359,
      "duration": 7
    },
    {
      "lang": "en",
      "text": "parts of the network and analyze their",
      "offset": 8648.319,
      "duration": 7.241
    },
    {
      "lang": "en",
      "text": "behavior Once a model is constructed and",
      "offset": 8652.359,
      "duration": 6.04
    },
    {
      "lang": "en",
      "text": "compiled it will store its layers in an",
      "offset": 8655.56,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "attribute called",
      "offset": 8658.399,
      "duration": 5.441
    },
    {
      "lang": "en",
      "text": "layers This is a list of layer objects",
      "offset": 8660.12,
      "duration": 6.359
    },
    {
      "lang": "en",
      "text": "For example here is a network with two",
      "offset": 8663.84,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "convolutional layers followed by a",
      "offset": 8666.479,
      "duration": 4.641
    },
    {
      "lang": "en",
      "text": "flattening operation and read out with",
      "offset": 8668.72,
      "duration": 4.04
    },
    {
      "lang": "en",
      "text": "the dense",
      "offset": 8671.12,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "layer If we want to look at the first",
      "offset": 8672.76,
      "duration": 5.4
    },
    {
      "lang": "en",
      "text": "convolutional layer we can pull it out",
      "offset": 8675.84,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "by indexing the first item in this list",
      "offset": 8678.16,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "The weights for this layer are",
      "offset": 8681.12,
      "duration": 4.44
    },
    {
      "lang": "en",
      "text": "accessible through the get weights",
      "offset": 8683.04,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "method This method returns a list with",
      "offset": 8685.56,
      "duration": 6.36
    },
    {
      "lang": "en",
      "text": "two items The first item in this list is",
      "offset": 8688.72,
      "duration": 6.24
    },
    {
      "lang": "en",
      "text": "an array that holds the values of the",
      "offset": 8691.92,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "weights for the convolutional kernels",
      "offset": 8694.96,
      "duration": 3.8
    },
    {
      "lang": "en",
      "text": "for this",
      "offset": 8697.2,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "layer The kernels array has the shape 3x",
      "offset": 8698.76,
      "duration": 6.4
    },
    {
      "lang": "en",
      "text": "3x 1x",
      "offset": 8702.96,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "5 The first two dimensions denote the",
      "offset": 8705.16,
      "duration": 6.6
    },
    {
      "lang": "en",
      "text": "kernel size This network was initialized",
      "offset": 8708.64,
      "duration": 6.4
    },
    {
      "lang": "en",
      "text": "with a kernel size of three The third",
      "offset": 8711.76,
      "duration": 5.599
    },
    {
      "lang": "en",
      "text": "dimension denotes the number of channels",
      "offset": 8715.04,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "in the kernels This is one because the",
      "offset": 8717.359,
      "duration": 5.561
    },
    {
      "lang": "en",
      "text": "network was looking at black and white",
      "offset": 8720.24,
      "duration": 5.84
    },
    {
      "lang": "en",
      "text": "data The last dimension denotes the",
      "offset": 8722.92,
      "duration": 6.32
    },
    {
      "lang": "en",
      "text": "number of kernels in this layer",
      "offset": 8726.08,
      "duration": 5.84
    },
    {
      "lang": "en",
      "text": "five To pull out the first kernel in",
      "offset": 8729.24,
      "duration": 5.239
    },
    {
      "lang": "en",
      "text": "this layer we would use the index zero",
      "offset": 8731.92,
      "duration": 3.96
    },
    {
      "lang": "en",
      "text": "into the last",
      "offset": 8734.479,
      "duration": 3.441
    },
    {
      "lang": "en",
      "text": "dimension Because there is only one",
      "offset": 8735.88,
      "duration": 4.599
    },
    {
      "lang": "en",
      "text": "channel we can also index on the channel",
      "offset": 8737.92,
      "duration": 6.8
    },
    {
      "lang": "en",
      "text": "dimension to collapse that dimension",
      "offset": 8740.479,
      "duration": 6.721
    },
    {
      "lang": "en",
      "text": "This would return the 3x3 array",
      "offset": 8744.72,
      "duration": 5.48
    },
    {
      "lang": "en",
      "text": "containing this convolutional",
      "offset": 8747.2,
      "duration": 6.119
    },
    {
      "lang": "en",
      "text": "kernel We can then visualize this kernel",
      "offset": 8750.2,
      "duration": 5.88
    },
    {
      "lang": "en",
      "text": "directly But understanding what kinds of",
      "offset": 8753.319,
      "duration": 5.801
    },
    {
      "lang": "en",
      "text": "features this kernel is responding to",
      "offset": 8756.08,
      "duration": 5.88
    },
    {
      "lang": "en",
      "text": "may be hard just from direct",
      "offset": 8759.12,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "observation To understand what this",
      "offset": 8761.96,
      "duration": 4.68
    },
    {
      "lang": "en",
      "text": "kernel does it might sometimes be even",
      "offset": 8764.24,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "more useful to convolve one of the",
      "offset": 8766.64,
      "duration": 4.719
    },
    {
      "lang": "en",
      "text": "images from our test set with this",
      "offset": 8769.04,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "kernel and see what aspects of the image",
      "offset": 8771.359,
      "duration": 5.08
    },
    {
      "lang": "en",
      "text": "are emphasized by this",
      "offset": 8774.08,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "kernel Here we pick the fourth image",
      "offset": 8776.439,
      "duration": 6.841
    },
    {
      "lang": "en",
      "text": "from the test set an image of a shoe We",
      "offset": 8779.68,
      "duration": 5.84
    },
    {
      "lang": "en",
      "text": "convolve it with the kernel using the",
      "offset": 8783.28,
      "duration": 5.119
    },
    {
      "lang": "en",
      "text": "function that we created previously and",
      "offset": 8785.52,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "create a filtered image that is the",
      "offset": 8788.399,
      "duration": 4.721
    },
    {
      "lang": "en",
      "text": "result of this convolution",
      "offset": 8790.64,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "This filter seems to like the external",
      "offset": 8793.12,
      "duration": 4.44
    },
    {
      "lang": "en",
      "text": "edges of this image on the",
      "offset": 8795.12,
      "duration": 5.199
    },
    {
      "lang": "en",
      "text": "left We can confirm this by running the",
      "offset": 8797.56,
      "duration": 5.799
    },
    {
      "lang": "en",
      "text": "convolution over another image Here",
      "offset": 8800.319,
      "duration": 4.881
    },
    {
      "lang": "en",
      "text": "we've picked the fifth image from the",
      "offset": 8803.359,
      "duration": 3.801
    },
    {
      "lang": "en",
      "text": "set an image of a",
      "offset": 8805.2,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "t-shirt We see that here as well",
      "offset": 8807.16,
      "duration": 4.84
    },
    {
      "lang": "en",
      "text": "vertical edges on the left side of the",
      "offset": 8809.92,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "object are emphasized and on the right",
      "offset": 8812,
      "duration": 4.04
    },
    {
      "lang": "en",
      "text": "side are",
      "offset": 8814.319,
      "duration": 3.761
    },
    {
      "lang": "en",
      "text": "deemphasized We can do the same thing",
      "offset": 8816.04,
      "duration": 5
    },
    {
      "lang": "en",
      "text": "with another one of our kernels Here we",
      "offset": 8818.08,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "select the second kernel and convolve",
      "offset": 8821.04,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "the t-shirt image with this kernel This",
      "offset": 8823.28,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "kernel seems to have learned to detect",
      "offset": 8826,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "horizontal edges particularly on the",
      "offset": 8828.16,
      "duration": 4.279
    },
    {
      "lang": "en",
      "text": "bottom of the",
      "offset": 8830.8,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "object Taken together this gives us an",
      "offset": 8832.439,
      "duration": 5.801
    },
    {
      "lang": "en",
      "text": "intuition for the kinds of things that",
      "offset": 8835.52,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "the first layer of the network has",
      "offset": 8838.24,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "learned and can help interpreting the",
      "offset": 8839.92,
      "duration": 4.479
    },
    {
      "lang": "en",
      "text": "results you see from using this network",
      "offset": 8842.16,
      "duration": 4.199
    },
    {
      "lang": "en",
      "text": "for a particular",
      "offset": 8844.399,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "task",
      "offset": 8846.359,
      "duration": 3
    },
    {
      "lang": "en",
      "text": "Congratulations you have completed this",
      "offset": 8849.72,
      "duration": 4.28
    },
    {
      "lang": "en",
      "text": "course on image processing with",
      "offset": 8851.84,
      "duration": 4.2
    },
    {
      "lang": "en",
      "text": "convolutional neural",
      "offset": 8854,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "networks These algorithms are the best",
      "offset": 8856.04,
      "duration": 6.319
    },
    {
      "lang": "en",
      "text": "we currently have for many computational",
      "offset": 8859.2,
      "duration": 7.32
    },
    {
      "lang": "en",
      "text": "tasks Here you learned about image",
      "offset": 8862.359,
      "duration": 6.521
    },
    {
      "lang": "en",
      "text": "classification Classification is a",
      "offset": 8866.52,
      "duration": 5.24
    },
    {
      "lang": "en",
      "text": "particularly useful task and one that",
      "offset": 8868.88,
      "duration": 6.16
    },
    {
      "lang": "en",
      "text": "convolutional neural networks excel at",
      "offset": 8871.76,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "You learned how to set up a training set",
      "offset": 8875.04,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "a validation set and a test set and how",
      "offset": 8877.28,
      "duration": 5.64
    },
    {
      "lang": "en",
      "text": "to use them in training a model for",
      "offset": 8880.72,
      "duration": 5
    },
    {
      "lang": "en",
      "text": "classification and how to evaluate",
      "offset": 8882.92,
      "duration": 5.399
    },
    {
      "lang": "en",
      "text": "it You learned about the fundamental",
      "offset": 8885.72,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "operations of these networks",
      "offset": 8888.319,
      "duration": 5.601
    },
    {
      "lang": "en",
      "text": "convolutions The development of",
      "offset": 8891.72,
      "duration": 5.48
    },
    {
      "lang": "en",
      "text": "convolutional layers for neural networks",
      "offset": 8893.92,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "ushered in the current golden age of",
      "offset": 8897.2,
      "duration": 5.239
    },
    {
      "lang": "en",
      "text": "computation with neural networks So",
      "offset": 8899.68,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "understanding how they work is",
      "offset": 8902.439,
      "duration": 5.401
    },
    {
      "lang": "en",
      "text": "particularly valuable even if you",
      "offset": 8905.04,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "continue to learn about other kinds of",
      "offset": 8907.84,
      "duration": 4.28
    },
    {
      "lang": "en",
      "text": "neural",
      "offset": 8910.24,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "networks One of the things that is",
      "offset": 8912.12,
      "duration": 5
    },
    {
      "lang": "en",
      "text": "remarkable about CNN's is that they have",
      "offset": 8914.319,
      "duration": 5.401
    },
    {
      "lang": "en",
      "text": "a very large number of",
      "offset": 8917.12,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "parameters This is one of the reasons",
      "offset": 8919.72,
      "duration": 5.32
    },
    {
      "lang": "en",
      "text": "that large amounts of data are usually",
      "offset": 8922.24,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "required to effectively and accurately",
      "offset": 8925.04,
      "duration": 5.279
    },
    {
      "lang": "en",
      "text": "train a neural network",
      "offset": 8927.92,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "We looked at a couple of approaches to",
      "offset": 8930.319,
      "duration": 5.361
    },
    {
      "lang": "en",
      "text": "reduce the number of parameters One is",
      "offset": 8932.8,
      "duration": 5.599
    },
    {
      "lang": "en",
      "text": "to tweak your convolutions and adapt",
      "offset": 8935.68,
      "duration": 6.16
    },
    {
      "lang": "en",
      "text": "them to your problem For example using",
      "offset": 8938.399,
      "duration": 4.841
    },
    {
      "lang": "en",
      "text": "strided",
      "offset": 8941.84,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "convolutions Another approach is to use",
      "offset": 8943.24,
      "duration": 5.64
    },
    {
      "lang": "en",
      "text": "pooling layers We also looked at a",
      "offset": 8946,
      "duration": 4.479
    },
    {
      "lang": "en",
      "text": "couple of approaches to improve your",
      "offset": 8948.88,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "network using regularization",
      "offset": 8950.479,
      "duration": 5.84
    },
    {
      "lang": "en",
      "text": "Finally you learned about ways to",
      "offset": 8954.08,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "understand your network and visualize",
      "offset": 8956.319,
      "duration": 4.881
    },
    {
      "lang": "en",
      "text": "both the progress of learning as well as",
      "offset": 8958.64,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "the final result of learning the",
      "offset": 8961.2,
      "duration": 4.199
    },
    {
      "lang": "en",
      "text": "parameters of the trained",
      "offset": 8962.88,
      "duration": 5.16
    },
    {
      "lang": "en",
      "text": "network If you found this topic to be",
      "offset": 8965.399,
      "duration": 5
    },
    {
      "lang": "en",
      "text": "interesting you might want to read this",
      "offset": 8968.04,
      "duration": 5.48
    },
    {
      "lang": "en",
      "text": "paper by Chris Ola and his colleagues",
      "offset": 8970.399,
      "duration": 5.401
    },
    {
      "lang": "en",
      "text": "that explores different aspects of",
      "offset": 8973.52,
      "duration": 7.4
    },
    {
      "lang": "en",
      "text": "visualization of neural network results",
      "offset": 8975.8,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "This is an exciting time to learn about",
      "offset": 8980.96,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "CNN's because the technology is rapidly",
      "offset": 8982.72,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "evolving and some of the most exciting",
      "offset": 8985.359,
      "duration": 4.521
    },
    {
      "lang": "en",
      "text": "developments are yet to",
      "offset": 8987.68,
      "duration": 5.16
    },
    {
      "lang": "en",
      "text": "come Where does the road lead to from",
      "offset": 8989.88,
      "duration": 5.8
    },
    {
      "lang": "en",
      "text": "here there is a wealth of methods and",
      "offset": 8992.84,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "ideas for you to dive",
      "offset": 8995.68,
      "duration": 4.719
    },
    {
      "lang": "en",
      "text": "into Here are a few things to learn",
      "offset": 8997.88,
      "duration": 5.64
    },
    {
      "lang": "en",
      "text": "about next In this course you learned",
      "offset": 9000.399,
      "duration": 5.92
    },
    {
      "lang": "en",
      "text": "about simple architectures where one",
      "offset": 9003.52,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "layer always connects only to the next",
      "offset": 9006.319,
      "duration": 4.641
    },
    {
      "lang": "en",
      "text": "But there are other architectures that",
      "offset": 9009.28,
      "duration": 3.88
    },
    {
      "lang": "en",
      "text": "provide a variety of computational",
      "offset": 9010.96,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "benefits For example you might want to",
      "offset": 9013.16,
      "duration": 5.56
    },
    {
      "lang": "en",
      "text": "learn about residual networks These",
      "offset": 9016,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "include connections that skip over",
      "offset": 9018.72,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "several layers And they are called",
      "offset": 9020.72,
      "duration": 4.639
    },
    {
      "lang": "en",
      "text": "residual networks because the network",
      "offset": 9023.12,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "will use this skipped connection to",
      "offset": 9025.359,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "compute a difference between the input",
      "offset": 9027.84,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "of a stack of layers and their output",
      "offset": 9029.76,
      "duration": 6.48
    },
    {
      "lang": "en",
      "text": "Learning this difference or residual",
      "offset": 9033.52,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "turns out to often be easier than",
      "offset": 9036.24,
      "duration": 3.32
    },
    {
      "lang": "en",
      "text": "learning the",
      "offset": 9038.56,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "output This means that these networks",
      "offset": 9039.56,
      "duration": 5.24
    },
    {
      "lang": "en",
      "text": "have been surprisingly effective at",
      "offset": 9042.399,
      "duration": 5.08
    },
    {
      "lang": "en",
      "text": "tasks such as",
      "offset": 9044.8,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "classification Another topic you might",
      "offset": 9047.479,
      "duration": 4.801
    },
    {
      "lang": "en",
      "text": "want to explore further is transfer",
      "offset": 9049.76,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "learning In this approach an already",
      "offset": 9052.28,
      "duration": 6.76
    },
    {
      "lang": "en",
      "text": "trained network is adapted to a new task",
      "offset": 9054.96,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "You've already learned how to read in",
      "offset": 9059.04,
      "duration": 3.319
    },
    {
      "lang": "en",
      "text": "weights into a network that you've",
      "offset": 9060.72,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "defined Now imagine training it again on",
      "offset": 9062.359,
      "duration": 7.08
    },
    {
      "lang": "en",
      "text": "another classification task Sounds weird",
      "offset": 9065.92,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "but it's a great strategy for cases",
      "offset": 9069.439,
      "duration": 3.88
    },
    {
      "lang": "en",
      "text": "where you don't have a lot of",
      "offset": 9071.52,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "data In addition to convolutional",
      "offset": 9073.319,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "networks that perform",
      "offset": 9075.92,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "classification there are so-called fully",
      "offset": 9077.64,
      "duration": 4.44
    },
    {
      "lang": "en",
      "text": "convolutional networks that take an",
      "offset": 9080.24,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "image as input and produce another image",
      "offset": 9082.08,
      "duration": 6.16
    },
    {
      "lang": "en",
      "text": "as output For example these networks can",
      "offset": 9084.399,
      "duration": 6.161
    },
    {
      "lang": "en",
      "text": "be used to find the part of an image",
      "offset": 9088.24,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "that contains a particular kind of",
      "offset": 9090.56,
      "duration": 6.28
    },
    {
      "lang": "en",
      "text": "object doing segmentation rather than",
      "offset": 9092.399,
      "duration": 6.401
    },
    {
      "lang": "en",
      "text": "classification A particularly",
      "offset": 9096.84,
      "duration": 4.44
    },
    {
      "lang": "en",
      "text": "interesting kind of networks are",
      "offset": 9098.8,
      "duration": 5.599
    },
    {
      "lang": "en",
      "text": "generative adversarial networks These",
      "offset": 9101.28,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "complex architectures can be used to",
      "offset": 9104.399,
      "duration": 4.561
    },
    {
      "lang": "en",
      "text": "train a network to create new images",
      "offset": 9106.64,
      "duration": 3.88
    },
    {
      "lang": "en",
      "text": "that didn't exist",
      "offset": 9108.96,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "before And there are many other topics",
      "offset": 9110.52,
      "duration": 4.28
    },
    {
      "lang": "en",
      "text": "to explore",
      "offset": 9113.04,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "Whichever way you decide to turn next",
      "offset": 9114.8,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "good luck",
      "offset": 9117.439,
      "duration": 5.92
    },
    {
      "lang": "en",
      "text": "Hi my name is David I'm a data scientist",
      "offset": 9119.92,
      "duration": 5.88
    },
    {
      "lang": "en",
      "text": "that focus on text data for real world",
      "offset": 9123.359,
      "duration": 4.561
    },
    {
      "lang": "en",
      "text": "applications and I'm proud to be your",
      "offset": 9125.8,
      "duration": 4.76
    },
    {
      "lang": "en",
      "text": "instructor for this course where you",
      "offset": 9127.92,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "will be introduced to four different",
      "offset": 9130.56,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "applications of language models using",
      "offset": 9132.64,
      "duration": 5.08
    },
    {
      "lang": "en",
      "text": "recurrent neuronet networks with",
      "offset": 9134.96,
      "duration": 6.64
    },
    {
      "lang": "en",
      "text": "Python So why learn to model language or",
      "offset": 9137.72,
      "duration": 6.2
    },
    {
      "lang": "en",
      "text": "text data",
      "offset": 9141.6,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "well we know that data science models",
      "offset": 9143.92,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "require data to be effective And one",
      "offset": 9146.8,
      "duration": 5.599
    },
    {
      "lang": "en",
      "text": "kind of data that is available on the",
      "offset": 9149.92,
      "duration": 3.96
    },
    {
      "lang": "en",
      "text": "internet is",
      "offset": 9152.399,
      "duration": 5.441
    },
    {
      "lang": "en",
      "text": "text From news articles to tweets the",
      "offset": 9153.88,
      "duration": 6.92
    },
    {
      "lang": "en",
      "text": "volume of text data is increasing fast",
      "offset": 9157.84,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "and is freely accessible to anyone with",
      "offset": 9160.8,
      "duration": 4.44
    },
    {
      "lang": "en",
      "text": "an internet",
      "offset": 9163.52,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "connection So what can data scientists",
      "offset": 9165.24,
      "duration": 6.52
    },
    {
      "lang": "en",
      "text": "do with all this data",
      "offset": 9168.8,
      "duration": 7.16
    },
    {
      "lang": "en",
      "text": "in this course you will introduce four",
      "offset": 9171.76,
      "duration": 6.36
    },
    {
      "lang": "en",
      "text": "applications Sentiment",
      "offset": 9175.96,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "analysis multiclass",
      "offset": 9178.12,
      "duration": 6.12
    },
    {
      "lang": "en",
      "text": "classification text generation and",
      "offset": 9180.6,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "machine",
      "offset": 9184.24,
      "duration": 5.199
    },
    {
      "lang": "en",
      "text": "neurotrans In the next slides we will",
      "offset": 9186.2,
      "duration": 6.68
    },
    {
      "lang": "en",
      "text": "define each of these applications",
      "offset": 9189.439,
      "duration": 5.96
    },
    {
      "lang": "en",
      "text": "If you have an online customer",
      "offset": 9192.88,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "interaction you may be interested in",
      "offset": 9195.399,
      "duration": 5.721
    },
    {
      "lang": "en",
      "text": "knowing how your customers feels towards",
      "offset": 9198.08,
      "duration": 4.68
    },
    {
      "lang": "en",
      "text": "your brand or",
      "offset": 9201.12,
      "duration": 5.199
    },
    {
      "lang": "en",
      "text": "product To do that you can use sentiment",
      "offset": 9202.76,
      "duration": 6.2
    },
    {
      "lang": "en",
      "text": "analysis models and classify their",
      "offset": 9206.319,
      "duration": 5.961
    },
    {
      "lang": "en",
      "text": "messages into positive or",
      "offset": 9208.96,
      "duration": 5.84
    },
    {
      "lang": "en",
      "text": "negative or you want to build a",
      "offset": 9212.28,
      "duration": 5.88
    },
    {
      "lang": "en",
      "text": "recommener system and need to categorize",
      "offset": 9214.8,
      "duration": 7.96
    },
    {
      "lang": "en",
      "text": "news articles into a set of predefined",
      "offset": 9218.16,
      "duration": 7.84
    },
    {
      "lang": "en",
      "text": "categories Also it is possible to",
      "offset": 9222.76,
      "duration": 6.679
    },
    {
      "lang": "en",
      "text": "generate text automatically using a",
      "offset": 9226,
      "duration": 6.88
    },
    {
      "lang": "en",
      "text": "specific writing style or automatically",
      "offset": 9229.439,
      "duration": 5.241
    },
    {
      "lang": "en",
      "text": "reply to",
      "offset": 9232.88,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "messages Lastly it is also possible to",
      "offset": 9234.68,
      "duration": 6.2
    },
    {
      "lang": "en",
      "text": "create models that translate from one",
      "offset": 9238.24,
      "duration": 5.119
    },
    {
      "lang": "en",
      "text": "language to another",
      "offset": 9240.88,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "All these applications are possible with",
      "offset": 9243.359,
      "duration": 4.881
    },
    {
      "lang": "en",
      "text": "a type of deep learning architecture",
      "offset": 9245.84,
      "duration": 5.08
    },
    {
      "lang": "en",
      "text": "called recurrent neuronet",
      "offset": 9248.24,
      "duration": 6.32
    },
    {
      "lang": "en",
      "text": "networks So what is different about RNN",
      "offset": 9250.92,
      "duration": 7.479
    },
    {
      "lang": "en",
      "text": "architectures and why do we use it",
      "offset": 9254.56,
      "duration": 7.6
    },
    {
      "lang": "en",
      "text": "the main advantages to use RNN for text",
      "offset": 9258.399,
      "duration": 6.801
    },
    {
      "lang": "en",
      "text": "data is that it reduces the number of",
      "offset": 9262.16,
      "duration": 6.72
    },
    {
      "lang": "en",
      "text": "parameters of the model by avoiding one",
      "offset": 9265.2,
      "duration": 7.04
    },
    {
      "lang": "en",
      "text": "hot encoding and it shares weights",
      "offset": 9268.88,
      "duration": 6.36
    },
    {
      "lang": "en",
      "text": "between different positions of the",
      "offset": 9272.24,
      "duration": 6.88
    },
    {
      "lang": "en",
      "text": "text In the example the model uses",
      "offset": 9275.24,
      "duration": 7
    },
    {
      "lang": "en",
      "text": "information from the all the words to",
      "offset": 9279.12,
      "duration": 6.08
    },
    {
      "lang": "en",
      "text": "predict if the movie review was good or",
      "offset": 9282.24,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "not",
      "offset": 9285.2,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "RNN's model sequence data and can have",
      "offset": 9287.04,
      "duration": 6.52
    },
    {
      "lang": "en",
      "text": "different lengths of inputs and",
      "offset": 9290.64,
      "duration": 6.48
    },
    {
      "lang": "en",
      "text": "outputs Many inputs to one output is",
      "offset": 9293.56,
      "duration": 6.68
    },
    {
      "lang": "en",
      "text": "commonly used for classification tasks",
      "offset": 9297.12,
      "duration": 6.52
    },
    {
      "lang": "en",
      "text": "where the final output is a probability",
      "offset": 9300.24,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "distribution This is used on sentiment",
      "offset": 9303.64,
      "duration": 5.08
    },
    {
      "lang": "en",
      "text": "analysis and multiclass classification",
      "offset": 9306.24,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "applications",
      "offset": 9308.72,
      "duration": 5.719
    },
    {
      "lang": "en",
      "text": "Many inputs to many outputs for text",
      "offset": 9311.2,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "generation start the same as in the",
      "offset": 9314.439,
      "duration": 5.641
    },
    {
      "lang": "en",
      "text": "classification case But for the outputs",
      "offset": 9316.96,
      "duration": 6.32
    },
    {
      "lang": "en",
      "text": "it uses the previous prediction as input",
      "offset": 9320.08,
      "duration": 5.399
    },
    {
      "lang": "en",
      "text": "to the next",
      "offset": 9323.28,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "prediction Many inputs to many outputs",
      "offset": 9325.479,
      "duration": 5.561
    },
    {
      "lang": "en",
      "text": "for neuromachine translation is",
      "offset": 9328.56,
      "duration": 5.919
    },
    {
      "lang": "en",
      "text": "separated in two blocks Encoder and",
      "offset": 9331.04,
      "duration": 5.279
    },
    {
      "lang": "en",
      "text": "decoder",
      "offset": 9334.479,
      "duration": 4.561
    },
    {
      "lang": "en",
      "text": "The encoder learns the characteristics",
      "offset": 9336.319,
      "duration": 6.481
    },
    {
      "lang": "en",
      "text": "of the input language while the decoder",
      "offset": 9339.04,
      "duration": 5.8
    },
    {
      "lang": "en",
      "text": "learns for the output",
      "offset": 9342.8,
      "duration": 5.84
    },
    {
      "lang": "en",
      "text": "language The encoder has no prediction",
      "offset": 9344.84,
      "duration": 7.16
    },
    {
      "lang": "en",
      "text": "no arrows going up And the decoder",
      "offset": 9348.64,
      "duration": 6.48
    },
    {
      "lang": "en",
      "text": "doesn't receive inputs no arrows from",
      "offset": 9352,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "below",
      "offset": 9355.12,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "Many inputs to many outputs for language",
      "offset": 9357.2,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "models starts with an artificial zero",
      "offset": 9360.08,
      "duration": 6.88
    },
    {
      "lang": "en",
      "text": "input and then for every input word I",
      "offset": 9362.96,
      "duration": 6.8
    },
    {
      "lang": "en",
      "text": "the model tries to predict the next word",
      "offset": 9366.96,
      "duration": 4.359
    },
    {
      "lang": "en",
      "text": "I +",
      "offset": 9369.76,
      "duration": 4.719
    },
    {
      "lang": "en",
      "text": "1 In this lesson you will learn in more",
      "offset": 9371.319,
      "duration": 5.961
    },
    {
      "lang": "en",
      "text": "detail how to create a language model",
      "offset": 9374.479,
      "duration": 6.561
    },
    {
      "lang": "en",
      "text": "from raw text data Language models",
      "offset": 9377.28,
      "duration": 7.039
    },
    {
      "lang": "en",
      "text": "represent the probability of a sentence",
      "offset": 9381.04,
      "duration": 6.24
    },
    {
      "lang": "en",
      "text": "For example what is the probability of",
      "offset": 9384.319,
      "duration": 6.641
    },
    {
      "lang": "en",
      "text": "the sentence I love this movie what is",
      "offset": 9387.28,
      "duration": 6.4
    },
    {
      "lang": "en",
      "text": "the probability of each word in the",
      "offset": 9390.96,
      "duration": 6.6
    },
    {
      "lang": "en",
      "text": "sentence to appear in this particular",
      "offset": 9393.68,
      "duration": 6.799
    },
    {
      "lang": "en",
      "text": "order the way this probability is",
      "offset": 9397.56,
      "duration": 5.799
    },
    {
      "lang": "en",
      "text": "computed changes from one model to",
      "offset": 9400.479,
      "duration": 5.121
    },
    {
      "lang": "en",
      "text": "another",
      "offset": 9403.359,
      "duration": 5.681
    },
    {
      "lang": "en",
      "text": "Unig models use the probability of each",
      "offset": 9405.6,
      "duration": 6.4
    },
    {
      "lang": "en",
      "text": "word inside the document and assume the",
      "offset": 9409.04,
      "duration": 5.56
    },
    {
      "lang": "en",
      "text": "probabilities are",
      "offset": 9412,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "independent Engram models use the",
      "offset": 9414.6,
      "duration": 6.12
    },
    {
      "lang": "en",
      "text": "probability of each word conditional to",
      "offset": 9417.6,
      "duration": 7.28
    },
    {
      "lang": "en",
      "text": "the previous n minus one words When n",
      "offset": 9420.72,
      "duration": 7.52
    },
    {
      "lang": "en",
      "text": "equals to two it's called bagram and",
      "offset": 9424.88,
      "duration": 7.16
    },
    {
      "lang": "en",
      "text": "when it's equal to three it's called",
      "offset": 9428.24,
      "duration": 6.96
    },
    {
      "lang": "en",
      "text": "triagram The skip gram model does the",
      "offset": 9432.04,
      "duration": 6.12
    },
    {
      "lang": "en",
      "text": "opposite Computes the probability of the",
      "offset": 9435.2,
      "duration": 6.48
    },
    {
      "lang": "en",
      "text": "context words or neighboring words given",
      "offset": 9438.16,
      "duration": 5.4
    },
    {
      "lang": "en",
      "text": "the center",
      "offset": 9441.68,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "word Neural networks models with a",
      "offset": 9443.56,
      "duration": 5.96
    },
    {
      "lang": "en",
      "text": "softmax function in the last layer of",
      "offset": 9447.04,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "the model with units equal to the size",
      "offset": 9449.52,
      "duration": 7.24
    },
    {
      "lang": "en",
      "text": "of the vocabulary are also language",
      "offset": 9452.72,
      "duration": 6.96
    },
    {
      "lang": "en",
      "text": "models when focusing on recurrent",
      "offset": 9456.76,
      "duration": 6.679
    },
    {
      "lang": "en",
      "text": "neuronet networks So how exactly are",
      "offset": 9459.68,
      "duration": 8.759
    },
    {
      "lang": "en",
      "text": "language models related to them well",
      "offset": 9463.439,
      "duration": 8
    },
    {
      "lang": "en",
      "text": "everywhere recurrent neuronet networks",
      "offset": 9468.439,
      "duration": 6.281
    },
    {
      "lang": "en",
      "text": "models are themselves language models",
      "offset": 9471.439,
      "duration": 6.88
    },
    {
      "lang": "en",
      "text": "when trained on text data because they",
      "offset": 9474.72,
      "duration": 6.4
    },
    {
      "lang": "en",
      "text": "give the probability of the next token",
      "offset": 9478.319,
      "duration": 7.04
    },
    {
      "lang": "en",
      "text": "given the previous K tokens",
      "offset": 9481.12,
      "duration": 7.279
    },
    {
      "lang": "en",
      "text": "Also an embedding layer can be used to",
      "offset": 9485.359,
      "duration": 5.361
    },
    {
      "lang": "en",
      "text": "create vector representations of the",
      "offset": 9488.399,
      "duration": 5.161
    },
    {
      "lang": "en",
      "text": "tokens as the first",
      "offset": 9490.72,
      "duration": 7.04
    },
    {
      "lang": "en",
      "text": "layer When creating RNN models we need",
      "offset": 9493.56,
      "duration": 6.919
    },
    {
      "lang": "en",
      "text": "to transform the text data into a",
      "offset": 9497.76,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "sequence of numbers which are the",
      "offset": 9500.479,
      "duration": 5.361
    },
    {
      "lang": "en",
      "text": "indexes of the tokens in the array of",
      "offset": 9503.12,
      "duration": 6.88
    },
    {
      "lang": "en",
      "text": "unique tokens the vocabulary",
      "offset": 9505.84,
      "duration": 7.12
    },
    {
      "lang": "en",
      "text": "To do that we first need to create an",
      "offset": 9510,
      "duration": 6.52
    },
    {
      "lang": "en",
      "text": "array containing each unique word of the",
      "offset": 9512.96,
      "duration": 6.8
    },
    {
      "lang": "en",
      "text": "corpus We can use the combination list",
      "offset": 9516.52,
      "duration": 6.48
    },
    {
      "lang": "en",
      "text": "set to create a list of unique",
      "offset": 9519.76,
      "duration": 6.48
    },
    {
      "lang": "en",
      "text": "words And we can get all words in the",
      "offset": 9523,
      "duration": 6.68
    },
    {
      "lang": "en",
      "text": "text by splitting the text using space",
      "offset": 9526.24,
      "duration": 6.239
    },
    {
      "lang": "en",
      "text": "as the separator",
      "offset": 9529.68,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "Other languages such as Chinese need",
      "offset": 9532.479,
      "duration": 5.92
    },
    {
      "lang": "en",
      "text": "additional steps to get words since",
      "offset": 9535.68,
      "duration": 5.799
    },
    {
      "lang": "en",
      "text": "there is no space between the",
      "offset": 9538.399,
      "duration": 5.361
    },
    {
      "lang": "en",
      "text": "characters We can now create",
      "offset": 9541.479,
      "duration": 5.561
    },
    {
      "lang": "en",
      "text": "dictionaries that map words to their",
      "offset": 9543.76,
      "duration": 6.48
    },
    {
      "lang": "en",
      "text": "index on the vocabulary and vice versa",
      "offset": 9547.04,
      "duration": 5.88
    },
    {
      "lang": "en",
      "text": "using dictionary",
      "offset": 9550.24,
      "duration": 6.079
    },
    {
      "lang": "en",
      "text": "comprehension By enumerating a list we",
      "offset": 9552.92,
      "duration": 7
    },
    {
      "lang": "en",
      "text": "obtain the numeric indexes and the items",
      "offset": 9556.319,
      "duration": 7.12
    },
    {
      "lang": "en",
      "text": "as tpples and we can use them to create",
      "offset": 9559.92,
      "duration": 5.479
    },
    {
      "lang": "en",
      "text": "key value",
      "offset": 9563.439,
      "duration": 5.281
    },
    {
      "lang": "en",
      "text": "dictionaries The first dictionary uses",
      "offset": 9565.399,
      "duration": 6.561
    },
    {
      "lang": "en",
      "text": "the words as keys and the indexes as",
      "offset": 9568.72,
      "duration": 6.32
    },
    {
      "lang": "en",
      "text": "values It can transform the text into",
      "offset": 9571.96,
      "duration": 5.399
    },
    {
      "lang": "en",
      "text": "numerical values",
      "offset": 9575.04,
      "duration": 5.279
    },
    {
      "lang": "en",
      "text": "The later one is used to go back from",
      "offset": 9577.359,
      "duration": 6.881
    },
    {
      "lang": "en",
      "text": "numbers to words since it has indexes as",
      "offset": 9580.319,
      "duration": 6.681
    },
    {
      "lang": "en",
      "text": "keys and words as",
      "offset": 9584.24,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "values With the created dictionaries we",
      "offset": 9587,
      "duration": 6.84
    },
    {
      "lang": "en",
      "text": "can prepare pairs of X and Y to be used",
      "offset": 9590.24,
      "duration": 6.28
    },
    {
      "lang": "en",
      "text": "on a supervised machine learning",
      "offset": 9593.84,
      "duration": 6.08
    },
    {
      "lang": "en",
      "text": "model For that we can loop into the",
      "offset": 9596.52,
      "duration": 6.52
    },
    {
      "lang": "en",
      "text": "sequences of numerical indexes in blocks",
      "offset": 9599.92,
      "duration": 6.559
    },
    {
      "lang": "en",
      "text": "of fixed length size",
      "offset": 9603.04,
      "duration": 6.64
    },
    {
      "lang": "en",
      "text": "We use the initial words as X and the",
      "offset": 9606.479,
      "duration": 6.96
    },
    {
      "lang": "en",
      "text": "final word as Y and shift the text step",
      "offset": 9609.68,
      "duration": 5.24
    },
    {
      "lang": "en",
      "text": "words",
      "offset": 9613.439,
      "duration": 5.841
    },
    {
      "lang": "en",
      "text": "forward If we use a step equal to two it",
      "offset": 9614.92,
      "duration": 7.32
    },
    {
      "lang": "en",
      "text": "means that the X sentences will be",
      "offset": 9619.28,
      "duration": 6.92
    },
    {
      "lang": "en",
      "text": "shifted by two words at a",
      "offset": 9622.24,
      "duration": 7.84
    },
    {
      "lang": "en",
      "text": "time When preparing new data we can use",
      "offset": 9626.2,
      "duration": 6.199
    },
    {
      "lang": "en",
      "text": "the dictionary to get the correct",
      "offset": 9630.08,
      "duration": 5.359
    },
    {
      "lang": "en",
      "text": "indexes for each word",
      "offset": 9632.399,
      "duration": 6.641
    },
    {
      "lang": "en",
      "text": "Using the example on the slide create a",
      "offset": 9635.439,
      "duration": 6.281
    },
    {
      "lang": "en",
      "text": "list that will contain the transformed",
      "offset": 9639.04,
      "duration": 6.319
    },
    {
      "lang": "en",
      "text": "text Loop all for every sentence of the",
      "offset": 9641.72,
      "duration": 7.56
    },
    {
      "lang": "en",
      "text": "new text Create a temporary list that",
      "offset": 9645.359,
      "duration": 6.521
    },
    {
      "lang": "en",
      "text": "will contain the current",
      "offset": 9649.28,
      "duration": 5.92
    },
    {
      "lang": "en",
      "text": "sentence Iterate over all words of the",
      "offset": 9651.88,
      "duration": 5.559
    },
    {
      "lang": "en",
      "text": "sentence by splitting the sentence on",
      "offset": 9655.2,
      "duration": 4.119
    },
    {
      "lang": "en",
      "text": "its white",
      "offset": 9657.439,
      "duration": 5.161
    },
    {
      "lang": "en",
      "text": "spaces Get that index using the",
      "offset": 9659.319,
      "duration": 6.12
    },
    {
      "lang": "en",
      "text": "dictionary Append the index to the",
      "offset": 9662.6,
      "duration": 6.36
    },
    {
      "lang": "en",
      "text": "sentence list Then append the sentence",
      "offset": 9665.439,
      "duration": 6.561
    },
    {
      "lang": "en",
      "text": "of indexes on the first list you created",
      "offset": 9668.96,
      "duration": 5.72
    },
    {
      "lang": "en",
      "text": "the new text",
      "offset": 9672,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "split You saw the language models gives",
      "offset": 9674.68,
      "duration": 5.719
    },
    {
      "lang": "en",
      "text": "the probability of a sentence To train",
      "offset": 9677.52,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "the model you first need to prepare the",
      "offset": 9680.399,
      "duration": 3.96
    },
    {
      "lang": "en",
      "text": "raw",
      "offset": 9682.8,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "text In this lesson we implement the RNN",
      "offset": 9684.359,
      "duration": 6.641
    },
    {
      "lang": "en",
      "text": "models using car",
      "offset": 9688.16,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "Previously you were introduced to the",
      "offset": 9691,
      "duration": 5.96
    },
    {
      "lang": "en",
      "text": "architecture of language models Now we",
      "offset": 9693.6,
      "duration": 7.64
    },
    {
      "lang": "en",
      "text": "will use KAS to create and train RNN",
      "offset": 9696.96,
      "duration": 8.64
    },
    {
      "lang": "en",
      "text": "models KAS is a highlevel API with deep",
      "offset": 9701.24,
      "duration": 7.48
    },
    {
      "lang": "en",
      "text": "learning frameworks as background It is",
      "offset": 9705.6,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "possible to configure KAS with",
      "offset": 9708.72,
      "duration": 5.08
    },
    {
      "lang": "en",
      "text": "TensorFlow CMTK or",
      "offset": 9710.72,
      "duration": 7.04
    },
    {
      "lang": "en",
      "text": "Theo To install caras we can simply use",
      "offset": 9713.8,
      "duration": 7.28
    },
    {
      "lang": "en",
      "text": "the Python package manager",
      "offset": 9717.76,
      "duration": 6.96
    },
    {
      "lang": "en",
      "text": "PIP After installation we can use its",
      "offset": 9721.08,
      "duration": 6.84
    },
    {
      "lang": "en",
      "text": "modules to execute fast experimentation",
      "offset": 9724.72,
      "duration": 4.92
    },
    {
      "lang": "en",
      "text": "and",
      "offset": 9727.92,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "research Next we will introduce the main",
      "offset": 9729.64,
      "duration": 5.88
    },
    {
      "lang": "en",
      "text": "modules of KAS that will be useful for",
      "offset": 9732.72,
      "duration": 4.759
    },
    {
      "lang": "en",
      "text": "the language",
      "offset": 9735.52,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "models KAS models contains two classes",
      "offset": 9737.479,
      "duration": 5.401
    },
    {
      "lang": "en",
      "text": "of models",
      "offset": 9741.04,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "The sequential class has a structure",
      "offset": 9742.88,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "where each layer is implemented one",
      "offset": 9745.52,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "after the other Meaning that the output",
      "offset": 9748.16,
      "duration": 7.4
    },
    {
      "lang": "en",
      "text": "of one layer is the input of the next",
      "offset": 9751.52,
      "duration": 7.36
    },
    {
      "lang": "en",
      "text": "one The model class is a generic",
      "offset": 9755.56,
      "duration": 6.04
    },
    {
      "lang": "en",
      "text": "definition of a model that is more",
      "offset": 9758.88,
      "duration": 5.599
    },
    {
      "lang": "en",
      "text": "flexible and allows multiple inputs and",
      "offset": 9761.6,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "outputs",
      "offset": 9764.479,
      "duration": 5.84
    },
    {
      "lang": "en",
      "text": "KAS layers contains the different types",
      "offset": 9767.28,
      "duration": 7.8
    },
    {
      "lang": "en",
      "text": "of layers including the LSTM and GRU",
      "offset": 9770.319,
      "duration": 8.641
    },
    {
      "lang": "en",
      "text": "cells Other layers that we will use are",
      "offset": 9775.08,
      "duration": 10.48
    },
    {
      "lang": "en",
      "text": "dense dropout embedding and birectional",
      "offset": 9778.96,
      "duration": 6.6
    },
    {
      "lang": "en",
      "text": "Caras prep-processing contains useful",
      "offset": 9785.6,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "functions for pre-processing the data",
      "offset": 9788.399,
      "duration": 6.721
    },
    {
      "lang": "en",
      "text": "such as the pad sequences method that",
      "offset": 9791.28,
      "duration": 7.8
    },
    {
      "lang": "en",
      "text": "transforms text data into fixed length",
      "offset": 9795.12,
      "duration": 7.199
    },
    {
      "lang": "en",
      "text": "vectors In the example we padded the",
      "offset": 9799.08,
      "duration": 6.56
    },
    {
      "lang": "en",
      "text": "text to equal length of",
      "offset": 9802.319,
      "duration": 6.801
    },
    {
      "lang": "en",
      "text": "three The data sets module contains",
      "offset": 9805.64,
      "duration": 6.44
    },
    {
      "lang": "en",
      "text": "useful data sets",
      "offset": 9809.12,
      "duration": 6.88
    },
    {
      "lang": "en",
      "text": "For example the IMDb movie reviews that",
      "offset": 9812.08,
      "duration": 6.359
    },
    {
      "lang": "en",
      "text": "is used for sentiment",
      "offset": 9816,
      "duration": 6.479
    },
    {
      "lang": "en",
      "text": "analysis Also the Reuters Newswire data",
      "offset": 9818.439,
      "duration": 7.481
    },
    {
      "lang": "en",
      "text": "set used for topic classification with",
      "offset": 9822.479,
      "duration": 5.481
    },
    {
      "lang": "en",
      "text": "46",
      "offset": 9825.92,
      "duration": 5.439
    },
    {
      "lang": "en",
      "text": "classes There are also other data sets",
      "offset": 9827.96,
      "duration": 7.04
    },
    {
      "lang": "en",
      "text": "that you can check on the CARAS",
      "offset": 9831.359,
      "duration": 6.641
    },
    {
      "lang": "en",
      "text": "website You can build a sequential model",
      "offset": 9835,
      "duration": 6.8
    },
    {
      "lang": "en",
      "text": "in KAS with just a few lines of code",
      "offset": 9838,
      "duration": 7.52
    },
    {
      "lang": "en",
      "text": "Import the required classes as from",
      "offset": 9841.8,
      "duration": 6.4
    },
    {
      "lang": "en",
      "text": "caras domodels import",
      "offset": 9845.52,
      "duration": 7.32
    },
    {
      "lang": "en",
      "text": "sequential from kas dot layers import",
      "offset": 9848.2,
      "duration": 8.36
    },
    {
      "lang": "en",
      "text": "dense then instantiate the class in the",
      "offset": 9852.84,
      "duration": 8.76
    },
    {
      "lang": "en",
      "text": "variable called model with model equals",
      "offset": 9856.56,
      "duration": 8.919
    },
    {
      "lang": "en",
      "text": "to sequential open and close",
      "offset": 9861.6,
      "duration": 7.36
    },
    {
      "lang": "en",
      "text": "parenthesis Add desired layers with the",
      "offset": 9865.479,
      "duration": 8.481
    },
    {
      "lang": "en",
      "text": "method add as in model do",
      "offset": 9868.96,
      "duration": 10.479
    },
    {
      "lang": "en",
      "text": "add dense 64 activation equals to the",
      "offset": 9873.96,
      "duration": 11.12
    },
    {
      "lang": "en",
      "text": "string relu input dim equals to",
      "offset": 9879.439,
      "duration": 9.761
    },
    {
      "lang": "en",
      "text": "100 The parameter input dimclares the",
      "offset": 9885.08,
      "duration": 6.92
    },
    {
      "lang": "en",
      "text": "shape of the input data which is",
      "offset": 9889.2,
      "duration": 5.119
    },
    {
      "lang": "en",
      "text": "mandatory for the first layer in the",
      "offset": 9892,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "model",
      "offset": 9894.319,
      "duration": 7.641
    },
    {
      "lang": "en",
      "text": "Then add the output layer model",
      "offset": 9896.88,
      "duration": 11.16
    },
    {
      "lang": "en",
      "text": "add one activation equal to the string",
      "offset": 9901.96,
      "duration": 9.96
    },
    {
      "lang": "en",
      "text": "sigmoid Finally we can compile the model",
      "offset": 9908.04,
      "duration": 7.6
    },
    {
      "lang": "en",
      "text": "by executing the compile method of the",
      "offset": 9911.92,
      "duration": 7.439
    },
    {
      "lang": "en",
      "text": "class We pass the string Adam to the",
      "offset": 9915.64,
      "duration": 7.16
    },
    {
      "lang": "en",
      "text": "optimizer parameter the string mean",
      "offset": 9919.359,
      "duration": 7.761
    },
    {
      "lang": "en",
      "text": "squared error to loss and a single",
      "offset": 9922.8,
      "duration": 6.8
    },
    {
      "lang": "en",
      "text": "element list containing the string",
      "offset": 9927.12,
      "duration": 5.96
    },
    {
      "lang": "en",
      "text": "accuracy to the matrix",
      "offset": 9929.6,
      "duration": 6.799
    },
    {
      "lang": "en",
      "text": "parameter To train the model we use the",
      "offset": 9933.08,
      "duration": 6.96
    },
    {
      "lang": "en",
      "text": "fit method on the training data For",
      "offset": 9936.399,
      "duration": 9.761
    },
    {
      "lang": "en",
      "text": "example model do fit x train y train epo",
      "offset": 9940.04,
      "duration": 11.2
    },
    {
      "lang": "en",
      "text": "equals to 10 batch size equal to",
      "offset": 9946.16,
      "duration": 8.8
    },
    {
      "lang": "en",
      "text": "32 Epoch is the number of iterations",
      "offset": 9951.24,
      "duration": 6.92
    },
    {
      "lang": "en",
      "text": "over the entire data set and defaults to",
      "offset": 9954.96,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "one",
      "offset": 9958.16,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "Batch size is the size of a subset of",
      "offset": 9959.84,
      "duration": 7.04
    },
    {
      "lang": "en",
      "text": "the data that will be used on each step",
      "offset": 9962.96,
      "duration": 6.319
    },
    {
      "lang": "en",
      "text": "When the data set cannot fit in the",
      "offset": 9966.88,
      "duration": 7.479
    },
    {
      "lang": "en",
      "text": "memory this is crucial It defaults to",
      "offset": 9969.279,
      "duration": 9.281
    },
    {
      "lang": "en",
      "text": "32 To analyze the model's performance we",
      "offset": 9974.359,
      "duration": 7.681
    },
    {
      "lang": "en",
      "text": "can use the method evaluate as",
      "offset": 9978.56,
      "duration": 9.12
    },
    {
      "lang": "en",
      "text": "model.ealuate x text test y test",
      "offset": 9982.04,
      "duration": 7.72
    },
    {
      "lang": "en",
      "text": "This method returns the loss and",
      "offset": 9987.68,
      "duration": 4.04
    },
    {
      "lang": "en",
      "text": "accuracy",
      "offset": 9989.76,
      "duration": 5.599
    },
    {
      "lang": "en",
      "text": "values To use the model on new data use",
      "offset": 9991.72,
      "duration": 7.8
    },
    {
      "lang": "en",
      "text": "the method predict as model dopredict",
      "offset": 9995.359,
      "duration": 5.721
    },
    {
      "lang": "en",
      "text": "new",
      "offset": 9999.52,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "data To create a full example let's",
      "offset": 10001.08,
      "duration": 5.84
    },
    {
      "lang": "en",
      "text": "instantiate the sequential",
      "offset": 10004.64,
      "duration": 5.92
    },
    {
      "lang": "en",
      "text": "class Add three layers Don't bother with",
      "offset": 10006.92,
      "duration": 6.04
    },
    {
      "lang": "en",
      "text": "the new layers for now We will explain",
      "offset": 10010.56,
      "duration": 6.68
    },
    {
      "lang": "en",
      "text": "them in details on chapter 2 and",
      "offset": 10012.96,
      "duration": 8.08
    },
    {
      "lang": "en",
      "text": "compile Next we can use the training set",
      "offset": 10017.24,
      "duration": 7.079
    },
    {
      "lang": "en",
      "text": "to fit the model and measure its",
      "offset": 10021.04,
      "duration": 5.88
    },
    {
      "lang": "en",
      "text": "accuracy on the test",
      "offset": 10024.319,
      "duration": 5.521
    },
    {
      "lang": "en",
      "text": "set You learn the main modules present",
      "offset": 10026.92,
      "duration": 6.359
    },
    {
      "lang": "en",
      "text": "in CARAS and how to create evaluate and",
      "offset": 10029.84,
      "duration": 5
    },
    {
      "lang": "en",
      "text": "use the",
      "offset": 10033.279,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "model You learned how to prepare text",
      "offset": 10034.84,
      "duration": 6.28
    },
    {
      "lang": "en",
      "text": "documents and use them on a RNN model to",
      "offset": 10037.6,
      "duration": 6.96
    },
    {
      "lang": "en",
      "text": "classify sentiment on movie reviews But",
      "offset": 10041.12,
      "duration": 6.88
    },
    {
      "lang": "en",
      "text": "the accuracy was not as expected In this",
      "offset": 10044.56,
      "duration": 5.839
    },
    {
      "lang": "en",
      "text": "lesson you will be introduced to some",
      "offset": 10048,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "pitfalls of vanilla RNN cells which are",
      "offset": 10050.399,
      "duration": 5.601
    },
    {
      "lang": "en",
      "text": "the vanishing or exploding gradient",
      "offset": 10053.76,
      "duration": 5.16
    },
    {
      "lang": "en",
      "text": "problems and how to deal with",
      "offset": 10056,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "them To understand the vanishing or",
      "offset": 10058.92,
      "duration": 5.32
    },
    {
      "lang": "en",
      "text": "exploding gradient problems you first",
      "offset": 10061.6,
      "duration": 5.64
    },
    {
      "lang": "en",
      "text": "need to understand how the RNN model is",
      "offset": 10064.24,
      "duration": 6.159
    },
    {
      "lang": "en",
      "text": "trained In other words how to perform",
      "offset": 10067.24,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "back",
      "offset": 10070.399,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "propagation In this picture you can see",
      "offset": 10071.64,
      "duration": 4.52
    },
    {
      "lang": "en",
      "text": "the forward propagation and back",
      "offset": 10074.399,
      "duration": 4.721
    },
    {
      "lang": "en",
      "text": "propagation directions The important",
      "offset": 10076.16,
      "duration": 5.4
    },
    {
      "lang": "en",
      "text": "part here is that they follow two",
      "offset": 10079.12,
      "duration": 5.359
    },
    {
      "lang": "en",
      "text": "directions Vertical between input and",
      "offset": 10081.56,
      "duration": 7.16
    },
    {
      "lang": "en",
      "text": "output and horizontal going through time",
      "offset": 10084.479,
      "duration": 6.8
    },
    {
      "lang": "en",
      "text": "Because of this horizontal direction",
      "offset": 10088.72,
      "duration": 5.599
    },
    {
      "lang": "en",
      "text": "back propagation is referred as back",
      "offset": 10091.279,
      "duration": 6.561
    },
    {
      "lang": "en",
      "text": "propagation through time",
      "offset": 10094.319,
      "duration": 6.401
    },
    {
      "lang": "en",
      "text": "In the forward propagation phase we",
      "offset": 10097.84,
      "duration": 6.479
    },
    {
      "lang": "en",
      "text": "compute a hidden state A that will carry",
      "offset": 10100.72,
      "duration": 6.28
    },
    {
      "lang": "en",
      "text": "past information by applying the linear",
      "offset": 10104.319,
      "duration": 6.08
    },
    {
      "lang": "en",
      "text": "combination over the previous step and",
      "offset": 10107,
      "duration": 5.439
    },
    {
      "lang": "en",
      "text": "the current",
      "offset": 10110.399,
      "duration": 5.841
    },
    {
      "lang": "en",
      "text": "input The output Y is computed only in",
      "offset": 10112.439,
      "duration": 6.441
    },
    {
      "lang": "en",
      "text": "the last hidden state often by applying",
      "offset": 10116.24,
      "duration": 5.119
    },
    {
      "lang": "en",
      "text": "a sigmoid or soft max activation",
      "offset": 10118.88,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "function",
      "offset": 10121.359,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "The loss function can be the cross",
      "offset": 10122.8,
      "duration": 5.679
    },
    {
      "lang": "en",
      "text": "entropy function and we use it to have a",
      "offset": 10125.2,
      "duration": 6.119
    },
    {
      "lang": "en",
      "text": "numeric value of the",
      "offset": 10128.479,
      "duration": 5.441
    },
    {
      "lang": "en",
      "text": "error We can see that the past",
      "offset": 10131.319,
      "duration": 5.08
    },
    {
      "lang": "en",
      "text": "information is carried out during the",
      "offset": 10133.92,
      "duration": 5
    },
    {
      "lang": "en",
      "text": "forward propagation with an",
      "offset": 10136.399,
      "duration": 5.681
    },
    {
      "lang": "en",
      "text": "example The second step combines the",
      "offset": 10138.92,
      "duration": 5.8
    },
    {
      "lang": "en",
      "text": "results from the first step and receive",
      "offset": 10142.08,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "the second word as input",
      "offset": 10144.72,
      "duration": 5.759
    },
    {
      "lang": "en",
      "text": "We can also see that the weight matrix",
      "offset": 10147.6,
      "duration": 7.44
    },
    {
      "lang": "en",
      "text": "WA is used on all steps which means the",
      "offset": 10150.479,
      "duration": 8.281
    },
    {
      "lang": "en",
      "text": "weights are shared among all the",
      "offset": 10155.04,
      "duration": 6.96
    },
    {
      "lang": "en",
      "text": "inputs In the back propagation phase we",
      "offset": 10158.76,
      "duration": 5.4
    },
    {
      "lang": "en",
      "text": "have to compute the derivative of the",
      "offset": 10162,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "loss function with respect to the",
      "offset": 10164.16,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "parameters",
      "offset": 10166.16,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "To compute the derivative of the loss",
      "offset": 10167.76,
      "duration": 5.84
    },
    {
      "lang": "en",
      "text": "with respect to the matrix W A we need",
      "offset": 10170.16,
      "duration": 6.48
    },
    {
      "lang": "en",
      "text": "to use the chain rule because Y hat",
      "offset": 10173.6,
      "duration": 7.96
    },
    {
      "lang": "en",
      "text": "depends on A which also depends on",
      "offset": 10176.64,
      "duration": 10.719
    },
    {
      "lang": "en",
      "text": "WA But 80 also depends on 80 minus one",
      "offset": 10181.56,
      "duration": 8.44
    },
    {
      "lang": "en",
      "text": "that depends on WA",
      "offset": 10187.359,
      "duration": 4.721
    },
    {
      "lang": "en",
      "text": "Thus we need to consider the",
      "offset": 10190,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "contribution of every previous step by",
      "offset": 10192.08,
      "duration": 5.359
    },
    {
      "lang": "en",
      "text": "summing up their derivatives with",
      "offset": 10195.12,
      "duration": 5.159
    },
    {
      "lang": "en",
      "text": "respect to the matrix W",
      "offset": 10197.439,
      "duration": 7.441
    },
    {
      "lang": "en",
      "text": "A Also the derivative of A with respect",
      "offset": 10200.279,
      "duration": 8.12
    },
    {
      "lang": "en",
      "text": "to W A also need the chain rule of",
      "offset": 10204.88,
      "duration": 6.16
    },
    {
      "lang": "en",
      "text": "derivatives and can be written as the",
      "offset": 10208.399,
      "duration": 5.601
    },
    {
      "lang": "en",
      "text": "product of the intermediate states",
      "offset": 10211.04,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "multiplied by the derivative of the",
      "offset": 10214,
      "duration": 6.88
    },
    {
      "lang": "en",
      "text": "first state with respect to the matrix",
      "offset": 10216.56,
      "duration": 7.08
    },
    {
      "lang": "en",
      "text": "Not going into too much detail on the",
      "offset": 10220.88,
      "duration": 5.92
    },
    {
      "lang": "en",
      "text": "math When computing the gradients of the",
      "offset": 10223.64,
      "duration": 5.719
    },
    {
      "lang": "en",
      "text": "loss function with respect to the weight",
      "offset": 10226.8,
      "duration": 7.04
    },
    {
      "lang": "en",
      "text": "matrix we obtain the matrix W A power T",
      "offset": 10229.359,
      "duration": 8.521
    },
    {
      "lang": "en",
      "text": "minus one multiplied by a term",
      "offset": 10233.84,
      "duration": 6.72
    },
    {
      "lang": "en",
      "text": "Intuitively if the values of the matrix",
      "offset": 10237.88,
      "duration": 5.88
    },
    {
      "lang": "en",
      "text": "are below one the series will converge",
      "offset": 10240.56,
      "duration": 6.879
    },
    {
      "lang": "en",
      "text": "to zero and if its values are above one",
      "offset": 10243.76,
      "duration": 6.519
    },
    {
      "lang": "en",
      "text": "it will diverge to",
      "offset": 10247.439,
      "duration": 5.281
    },
    {
      "lang": "en",
      "text": "infinity Researchers found some",
      "offset": 10250.279,
      "duration": 4.481
    },
    {
      "lang": "en",
      "text": "approaches to avoid those",
      "offset": 10252.72,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "problems Limiting the size of the",
      "offset": 10254.76,
      "duration": 5.16
    },
    {
      "lang": "en",
      "text": "gradients or scaling them can easily",
      "offset": 10257.12,
      "duration": 6.199
    },
    {
      "lang": "en",
      "text": "help us avoid the exploding gradient",
      "offset": 10259.92,
      "duration": 7.76
    },
    {
      "lang": "en",
      "text": "problem Initializing the matrix W as an",
      "offset": 10263.319,
      "duration": 6.441
    },
    {
      "lang": "en",
      "text": "orthogonal matrix make their",
      "offset": 10267.68,
      "duration": 6.48
    },
    {
      "lang": "en",
      "text": "multiplication always be equal to one",
      "offset": 10269.76,
      "duration": 7.36
    },
    {
      "lang": "en",
      "text": "Using regularization controls the size",
      "offset": 10274.16,
      "duration": 3.96
    },
    {
      "lang": "en",
      "text": "of the",
      "offset": 10277.12,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "entries By using the ReLU activation",
      "offset": 10278.12,
      "duration": 6.279
    },
    {
      "lang": "en",
      "text": "function the derivative becomes a",
      "offset": 10281.6,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "constant and thus doesn't increase or",
      "offset": 10284.399,
      "duration": 4.121
    },
    {
      "lang": "en",
      "text": "decrease",
      "offset": 10287.04,
      "duration": 5.399
    },
    {
      "lang": "en",
      "text": "exponentially Finally use other RNN",
      "offset": 10288.52,
      "duration": 8.919
    },
    {
      "lang": "en",
      "text": "cells such as GRU and LSTM that we will",
      "offset": 10292.439,
      "duration": 7.88
    },
    {
      "lang": "en",
      "text": "learn later",
      "offset": 10297.439,
      "duration": 5.761
    },
    {
      "lang": "en",
      "text": "You learned about the vanishing or",
      "offset": 10300.319,
      "duration": 5.08
    },
    {
      "lang": "en",
      "text": "exploding gradient",
      "offset": 10303.2,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "problem In this lesson you will learn",
      "offset": 10305.399,
      "duration": 5.561
    },
    {
      "lang": "en",
      "text": "about two different RNN cells that will",
      "offset": 10308.16,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "achieve good results in language",
      "offset": 10310.96,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "modeling and solve the vanishing",
      "offset": 10312.8,
      "duration": 3.88
    },
    {
      "lang": "en",
      "text": "gradient",
      "offset": 10315.2,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "problem Let's first have a detailed look",
      "offset": 10316.68,
      "duration": 6.679
    },
    {
      "lang": "en",
      "text": "on the simple RNN cell",
      "offset": 10319.92,
      "duration": 6.479
    },
    {
      "lang": "en",
      "text": "On every cell we compute the new memory",
      "offset": 10323.359,
      "duration": 5.841
    },
    {
      "lang": "en",
      "text": "state based on the previous memory state",
      "offset": 10326.399,
      "duration": 7.321
    },
    {
      "lang": "en",
      "text": "t minus one and the current input word",
      "offset": 10329.2,
      "duration": 8.32
    },
    {
      "lang": "en",
      "text": "xt In the computations we have a weight",
      "offset": 10333.72,
      "duration": 7.84
    },
    {
      "lang": "en",
      "text": "matrix wa that is shared between all",
      "offset": 10337.52,
      "duration": 6.959
    },
    {
      "lang": "en",
      "text": "steps We will consider the case of",
      "offset": 10341.56,
      "duration": 5.64
    },
    {
      "lang": "en",
      "text": "classification tasks and thus the output",
      "offset": 10344.479,
      "duration": 5.681
    },
    {
      "lang": "en",
      "text": "yhat will be computed only in the last",
      "offset": 10347.2,
      "duration": 5.199
    },
    {
      "lang": "en",
      "text": "step",
      "offset": 10350.16,
      "duration": 6.56
    },
    {
      "lang": "en",
      "text": "GRU cells were proposed in 2014 and add",
      "offset": 10352.399,
      "duration": 7.241
    },
    {
      "lang": "en",
      "text": "one gate to the vanilla RNN",
      "offset": 10356.72,
      "duration": 6.96
    },
    {
      "lang": "en",
      "text": "cell Now before updating the memory cell",
      "offset": 10359.64,
      "duration": 6.92
    },
    {
      "lang": "en",
      "text": "we first compute a candidate A tilda",
      "offset": 10363.68,
      "duration": 6.56
    },
    {
      "lang": "en",
      "text": "that will carry the present information",
      "offset": 10366.56,
      "duration": 7.839
    },
    {
      "lang": "en",
      "text": "Then we compute the update gate gu that",
      "offset": 10370.24,
      "duration": 7.039
    },
    {
      "lang": "en",
      "text": "will determine if the candidate a tild",
      "offset": 10374.399,
      "duration": 5.841
    },
    {
      "lang": "en",
      "text": "will be used as memory state or if we",
      "offset": 10377.279,
      "duration": 6.04
    },
    {
      "lang": "en",
      "text": "keep the past memory state a minus",
      "offset": 10380.24,
      "duration": 6.48
    },
    {
      "lang": "en",
      "text": "one If the gate is zero the network",
      "offset": 10383.319,
      "duration": 6.601
    },
    {
      "lang": "en",
      "text": "keeps the previous hidden state and if",
      "offset": 10386.72,
      "duration": 6.4
    },
    {
      "lang": "en",
      "text": "it's equal to one it uses the new value",
      "offset": 10389.92,
      "duration": 7.28
    },
    {
      "lang": "en",
      "text": "of a tild Other values will be a",
      "offset": 10393.12,
      "duration": 6.319
    },
    {
      "lang": "en",
      "text": "combination of the previous and the",
      "offset": 10397.2,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "candidate memory state but during",
      "offset": 10399.439,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "training it tends to get close to zero",
      "offset": 10401.76,
      "duration": 3.719
    },
    {
      "lang": "en",
      "text": "or",
      "offset": 10404.399,
      "duration": 6.641
    },
    {
      "lang": "en",
      "text": "one LSTM was first proposed in 1997 and",
      "offset": 10405.479,
      "duration": 8.88
    },
    {
      "lang": "en",
      "text": "adds three gates to the vanilla RNN",
      "offset": 10411.04,
      "duration": 7.84
    },
    {
      "lang": "en",
      "text": "cell The forget gate GF determines if",
      "offset": 10414.359,
      "duration": 8.281
    },
    {
      "lang": "en",
      "text": "the previous state CT minus one state",
      "offset": 10418.88,
      "duration": 6.399
    },
    {
      "lang": "en",
      "text": "should be forgotten",
      "offset": 10422.64,
      "duration": 6.28
    },
    {
      "lang": "en",
      "text": "meaning to have his value set to zero or",
      "offset": 10425.279,
      "duration": 7.601
    },
    {
      "lang": "en",
      "text": "not The update gate GU do the same for",
      "offset": 10428.92,
      "duration": 6.559
    },
    {
      "lang": "en",
      "text": "the candidate hidden state",
      "offset": 10432.88,
      "duration": 6.96
    },
    {
      "lang": "en",
      "text": "situ The output gate go do the same for",
      "offset": 10435.479,
      "duration": 6.96
    },
    {
      "lang": "en",
      "text": "the new hidden state",
      "offset": 10439.84,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "CT The green circles in the picture",
      "offset": 10442.439,
      "duration": 6.121
    },
    {
      "lang": "en",
      "text": "represent the gates We can think of them",
      "offset": 10445.6,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "as an open or closed gate allowing for",
      "offset": 10448.56,
      "duration": 6.56
    },
    {
      "lang": "en",
      "text": "the left side to pass through or not if",
      "offset": 10451.6,
      "duration": 7.56
    },
    {
      "lang": "en",
      "text": "the gates values are zero or one",
      "offset": 10455.12,
      "duration": 8.72
    },
    {
      "lang": "en",
      "text": "respectively Because GRU and LSTM cells",
      "offset": 10459.16,
      "duration": 7.8
    },
    {
      "lang": "en",
      "text": "add gates to the equations the gradients",
      "offset": 10463.84,
      "duration": 5.439
    },
    {
      "lang": "en",
      "text": "are no longer only dependent on the",
      "offset": 10466.96,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "memory cell state The derivative of the",
      "offset": 10469.279,
      "duration": 5.441
    },
    {
      "lang": "en",
      "text": "loss function with respect to the",
      "offset": 10472.72,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "weights matrix depends on all the gates",
      "offset": 10474.72,
      "duration": 5.679
    },
    {
      "lang": "en",
      "text": "and on the memory cell summing each of",
      "offset": 10477.68,
      "duration": 3.56
    },
    {
      "lang": "en",
      "text": "its",
      "offset": 10480.399,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "parts Without going into deeper details",
      "offset": 10481.24,
      "duration": 6.52
    },
    {
      "lang": "en",
      "text": "on the math this architecture adds the",
      "offset": 10484.319,
      "duration": 6.16
    },
    {
      "lang": "en",
      "text": "different gradients corresponding to the",
      "offset": 10487.76,
      "duration": 5.32
    },
    {
      "lang": "en",
      "text": "gradients of each gate and the memory",
      "offset": 10490.479,
      "duration": 5.761
    },
    {
      "lang": "en",
      "text": "state making the total gradient stop",
      "offset": 10493.08,
      "duration": 6.16
    },
    {
      "lang": "en",
      "text": "converging to zero or",
      "offset": 10496.24,
      "duration": 6.239
    },
    {
      "lang": "en",
      "text": "diverging on every step If the gradient",
      "offset": 10499.24,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "is exponentially increasing or",
      "offset": 10502.479,
      "duration": 5.041
    },
    {
      "lang": "en",
      "text": "decreasing we expect the training phase",
      "offset": 10504.6,
      "duration": 5.4
    },
    {
      "lang": "en",
      "text": "to adjust the value of the corresponding",
      "offset": 10507.52,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "gate accordingly to stop this vanishing",
      "offset": 10510,
      "duration": 5.24
    },
    {
      "lang": "en",
      "text": "or exploding",
      "offset": 10512.96,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "tendency Without further discussing the",
      "offset": 10515.24,
      "duration": 5.159
    },
    {
      "lang": "en",
      "text": "intuition and the theory let's put the",
      "offset": 10517.84,
      "duration": 7.519
    },
    {
      "lang": "en",
      "text": "new RNN cells in practice inside KAS",
      "offset": 10520.399,
      "duration": 8.321
    },
    {
      "lang": "en",
      "text": "First the layers with the GRU and LSTM",
      "offset": 10525.359,
      "duration": 7.08
    },
    {
      "lang": "en",
      "text": "cells are available in the",
      "offset": 10528.72,
      "duration": 7.96
    },
    {
      "lang": "en",
      "text": "kas.layers.recurrent with a shortcut on",
      "offset": 10532.439,
      "duration": 8.601
    },
    {
      "lang": "en",
      "text": "kas.layers To use the gru and lstm cells",
      "offset": 10536.68,
      "duration": 7.96
    },
    {
      "lang": "en",
      "text": "on a kas model we simply add them as",
      "offset": 10541.04,
      "duration": 7.279
    },
    {
      "lang": "en",
      "text": "usual The important parameters are the",
      "offset": 10544.64,
      "duration": 5.92
    },
    {
      "lang": "en",
      "text": "number of units meaning the number of",
      "offset": 10548.319,
      "duration": 4.881
    },
    {
      "lang": "en",
      "text": "memory cells to keep track and the",
      "offset": 10550.56,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "return sequences parameter that is used",
      "offset": 10553.2,
      "duration": 5.72
    },
    {
      "lang": "en",
      "text": "when adding more than one layer in",
      "offset": 10556.24,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "sequence making all the cells to emit an",
      "offset": 10558.92,
      "duration": 6.04
    },
    {
      "lang": "en",
      "text": "output that will be fed to the next",
      "offset": 10562.24,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "layer as input",
      "offset": 10564.96,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "Now that you understand how to",
      "offset": 10568,
      "duration": 4.52
    },
    {
      "lang": "en",
      "text": "differentiate the arnant",
      "offset": 10569.76,
      "duration": 5.32
    },
    {
      "lang": "en",
      "text": "cells you will learn now about",
      "offset": 10572.52,
      "duration": 5.16
    },
    {
      "lang": "en",
      "text": "vectorization of a language model using",
      "offset": 10575.08,
      "duration": 5.399
    },
    {
      "lang": "en",
      "text": "the embedding layer in caras and how it",
      "offset": 10577.68,
      "duration": 6.16
    },
    {
      "lang": "en",
      "text": "can be used for transfer learning",
      "offset": 10580.479,
      "duration": 6.081
    },
    {
      "lang": "en",
      "text": "The first reason to use embeddings is",
      "offset": 10583.84,
      "duration": 4.639
    },
    {
      "lang": "en",
      "text": "because the one hot encoding of the",
      "offset": 10586.56,
      "duration": 5.32
    },
    {
      "lang": "en",
      "text": "tokens in a scenario with a very big",
      "offset": 10588.479,
      "duration": 7.281
    },
    {
      "lang": "en",
      "text": "vocabulary maybe 100,000 words demands a",
      "offset": 10591.88,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "lot of",
      "offset": 10595.76,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "memory An embedding layer with dimension",
      "offset": 10596.84,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "say 300 is more",
      "offset": 10599.92,
      "duration": 6.16
    },
    {
      "lang": "en",
      "text": "viable Also embeddings are a dense",
      "offset": 10602.52,
      "duration": 5.799
    },
    {
      "lang": "en",
      "text": "representation of the words and the",
      "offset": 10606.08,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "implementations give surprisingly nice",
      "offset": 10608.319,
      "duration": 5.441
    },
    {
      "lang": "en",
      "text": "understanding of the tokens like the",
      "offset": 10610.72,
      "duration": 6.639
    },
    {
      "lang": "en",
      "text": "famous king minus man plus woman equals",
      "offset": 10613.76,
      "duration": 4.36
    },
    {
      "lang": "en",
      "text": "to",
      "offset": 10617.359,
      "duration": 3.761
    },
    {
      "lang": "en",
      "text": "queen Finally it can be used for",
      "offset": 10618.12,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "transfer",
      "offset": 10621.12,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "learning On the other hand it demands",
      "offset": 10622.439,
      "duration": 5
    },
    {
      "lang": "en",
      "text": "training lots of parameters to learn",
      "offset": 10625.279,
      "duration": 4.241
    },
    {
      "lang": "en",
      "text": "this representation and can make",
      "offset": 10627.439,
      "duration": 3.801
    },
    {
      "lang": "en",
      "text": "training",
      "offset": 10629.52,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "slower To use the embedding layer in KAS",
      "offset": 10631.24,
      "duration": 7.36
    },
    {
      "lang": "en",
      "text": "we first import it from kas.layers",
      "offset": 10634.72,
      "duration": 7.12
    },
    {
      "lang": "en",
      "text": "module The embedding layer should be the",
      "offset": 10638.6,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "first layer of the",
      "offset": 10641.84,
      "duration": 5.439
    },
    {
      "lang": "en",
      "text": "model The relevant parameters include",
      "offset": 10643.56,
      "duration": 6.799
    },
    {
      "lang": "en",
      "text": "input dim which is the size of the",
      "offset": 10647.279,
      "duration": 5.521
    },
    {
      "lang": "en",
      "text": "vocabulary Output dim which is the",
      "offset": 10650.359,
      "duration": 5.801
    },
    {
      "lang": "en",
      "text": "dimension of the embedding space",
      "offset": 10652.8,
      "duration": 5.92
    },
    {
      "lang": "en",
      "text": "trainable that defines if this layer",
      "offset": 10656.16,
      "duration": 5.84
    },
    {
      "lang": "en",
      "text": "should have its weights updated or not",
      "offset": 10658.72,
      "duration": 5.48
    },
    {
      "lang": "en",
      "text": "during the training",
      "offset": 10662,
      "duration": 4.52
    },
    {
      "lang": "en",
      "text": "phase Embedding",
      "offset": 10664.2,
      "duration": 5.079
    },
    {
      "lang": "en",
      "text": "initializer that can be used to perform",
      "offset": 10666.52,
      "duration": 5.32
    },
    {
      "lang": "en",
      "text": "transfer learning by using pre-trained",
      "offset": 10669.279,
      "duration": 5.08
    },
    {
      "lang": "en",
      "text": "weights for the words in your",
      "offset": 10671.84,
      "duration": 5.439
    },
    {
      "lang": "en",
      "text": "vocabulary Often when using transfer",
      "offset": 10674.359,
      "duration": 6.201
    },
    {
      "lang": "en",
      "text": "learning we set trainable to false but",
      "offset": 10677.279,
      "duration": 6.16
    },
    {
      "lang": "en",
      "text": "it's not mandatory",
      "offset": 10680.56,
      "duration": 6.16
    },
    {
      "lang": "en",
      "text": "The final parameter is the input length",
      "offset": 10683.439,
      "duration": 5.721
    },
    {
      "lang": "en",
      "text": "which determines the size of the",
      "offset": 10686.72,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "sequences It assumes that you padded the",
      "offset": 10689.16,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "input synthesis",
      "offset": 10692,
      "duration": 5.359
    },
    {
      "lang": "en",
      "text": "beforehand There are many pre-trained",
      "offset": 10694.92,
      "duration": 4.92
    },
    {
      "lang": "en",
      "text": "vectors that were trained on big data",
      "offset": 10697.359,
      "duration": 6.721
    },
    {
      "lang": "en",
      "text": "sets such as the Wikipedia news articles",
      "offset": 10699.84,
      "duration": 5.519
    },
    {
      "lang": "en",
      "text": "etc",
      "offset": 10704.08,
      "duration": 4.239
    },
    {
      "lang": "en",
      "text": "to train a model on those big sets",
      "offset": 10705.359,
      "duration": 5.761
    },
    {
      "lang": "en",
      "text": "demand a lot of computer power but",
      "offset": 10708.319,
      "duration": 5.08
    },
    {
      "lang": "en",
      "text": "loading the weights does",
      "offset": 10711.12,
      "duration": 6.48
    },
    {
      "lang": "en",
      "text": "not Recent advances in NLP and language",
      "offset": 10713.399,
      "duration": 6.601
    },
    {
      "lang": "en",
      "text": "models research is based on",
      "offset": 10717.6,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "open-sourcing pre-trained weights on big",
      "offset": 10720,
      "duration": 6.64
    },
    {
      "lang": "en",
      "text": "data sets using popular models such as",
      "offset": 10722.8,
      "duration": 8.88
    },
    {
      "lang": "en",
      "text": "clove word vec and earth among others",
      "offset": 10726.64,
      "duration": 9.28
    },
    {
      "lang": "en",
      "text": "In kas we need to constant initializer",
      "offset": 10731.68,
      "duration": 6.799
    },
    {
      "lang": "en",
      "text": "to define the pre-trained matrix of the",
      "offset": 10735.92,
      "duration": 4.68
    },
    {
      "lang": "en",
      "text": "embedding",
      "offset": 10738.479,
      "duration": 5.92
    },
    {
      "lang": "en",
      "text": "layer Globe files contain rows separated",
      "offset": 10740.6,
      "duration": 7.08
    },
    {
      "lang": "en",
      "text": "by spaces where the first column is the",
      "offset": 10744.399,
      "duration": 5.92
    },
    {
      "lang": "en",
      "text": "word and the others are the weights",
      "offset": 10747.68,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "values for each dimension of the",
      "offset": 10750.319,
      "duration": 3.321
    },
    {
      "lang": "en",
      "text": "embedding",
      "offset": 10752.16,
      "duration": 5.119
    },
    {
      "lang": "en",
      "text": "space to read the values Then we loop",
      "offset": 10753.64,
      "duration": 6.839
    },
    {
      "lang": "en",
      "text": "over the rows of the file You split the",
      "offset": 10757.279,
      "duration": 7.12
    },
    {
      "lang": "en",
      "text": "line by spaces get the word as the first",
      "offset": 10760.479,
      "duration": 6.96
    },
    {
      "lang": "en",
      "text": "item of the list and the rest of the",
      "offset": 10764.399,
      "duration": 5.321
    },
    {
      "lang": "en",
      "text": "list are the",
      "offset": 10767.439,
      "duration": 5.84
    },
    {
      "lang": "en",
      "text": "weights We use dictionaries to easily",
      "offset": 10769.72,
      "duration": 8
    },
    {
      "lang": "en",
      "text": "store for each word an np array with the",
      "offset": 10773.279,
      "duration": 7.601
    },
    {
      "lang": "en",
      "text": "values We also cast the values to have",
      "offset": 10777.72,
      "duration": 6.44
    },
    {
      "lang": "en",
      "text": "float 32 type because it is the type",
      "offset": 10780.88,
      "duration": 6.96
    },
    {
      "lang": "en",
      "text": "used to create the vectors",
      "offset": 10784.16,
      "duration": 6.319
    },
    {
      "lang": "en",
      "text": "To use the globe vectors in a specific",
      "offset": 10787.84,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "task we can simply select the words",
      "offset": 10790.479,
      "duration": 5.84
    },
    {
      "lang": "en",
      "text": "present on the vocabulary list ignoring",
      "offset": 10793.6,
      "duration": 5.64
    },
    {
      "lang": "en",
      "text": "the other words to save",
      "offset": 10796.319,
      "duration": 5.761
    },
    {
      "lang": "en",
      "text": "memory We need the task specific",
      "offset": 10799.24,
      "duration": 5.96
    },
    {
      "lang": "en",
      "text": "vocabulary dictionary with words as keys",
      "offset": 10802.08,
      "duration": 7.279
    },
    {
      "lang": "en",
      "text": "and indexes as values the glove dict",
      "offset": 10805.2,
      "duration": 6.56
    },
    {
      "lang": "en",
      "text": "created in the previous slide and the",
      "offset": 10809.359,
      "duration": 5.801
    },
    {
      "lang": "en",
      "text": "dimension of the embedding space as",
      "offset": 10811.76,
      "duration": 6.96
    },
    {
      "lang": "en",
      "text": "inputs We define a matrix with shape",
      "offset": 10815.16,
      "duration": 6.279
    },
    {
      "lang": "en",
      "text": "equal to the number of words plus one",
      "offset": 10818.72,
      "duration": 6.88
    },
    {
      "lang": "en",
      "text": "and the embedding space limb We add one",
      "offset": 10821.439,
      "duration": 6.88
    },
    {
      "lang": "en",
      "text": "because the index zero is reserved for",
      "offset": 10825.6,
      "duration": 4.44
    },
    {
      "lang": "en",
      "text": "the padding",
      "offset": 10828.319,
      "duration": 5.801
    },
    {
      "lang": "en",
      "text": "token We iterate over the vocabulary",
      "offset": 10830.04,
      "duration": 7
    },
    {
      "lang": "en",
      "text": "words If the word is found in the globe",
      "offset": 10834.12,
      "duration": 5.64
    },
    {
      "lang": "en",
      "text": "vectors then we update this row of the",
      "offset": 10837.04,
      "duration": 6.399
    },
    {
      "lang": "en",
      "text": "matrix with the values for from",
      "offset": 10839.76,
      "duration": 3.679
    },
    {
      "lang": "en",
      "text": "globe You learned about different RNN",
      "offset": 10843.479,
      "duration": 7.721
    },
    {
      "lang": "en",
      "text": "architectures such as GRU and LSTM and",
      "offset": 10846.76,
      "duration": 7.8
    },
    {
      "lang": "en",
      "text": "also about the embedding layer Those are",
      "offset": 10851.2,
      "duration": 6.96
    },
    {
      "lang": "en",
      "text": "the first steps to tune a RNN model and",
      "offset": 10854.56,
      "duration": 4.68
    },
    {
      "lang": "en",
      "text": "improve",
      "offset": 10858.16,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "performance Let's put it all together to",
      "offset": 10859.24,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "form a better",
      "offset": 10862.16,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "model In the first chapter of this",
      "offset": 10864.04,
      "duration": 5.48
    },
    {
      "lang": "en",
      "text": "course you implemented a simple RNN",
      "offset": 10866.56,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "model to classify sentiment on the IMDb",
      "offset": 10869.52,
      "duration": 6.24
    },
    {
      "lang": "en",
      "text": "data set But the performance was really",
      "offset": 10872.56,
      "duration": 7.48
    },
    {
      "lang": "en",
      "text": "poor and achieved less than 50%",
      "offset": 10875.76,
      "duration": 7.28
    },
    {
      "lang": "en",
      "text": "accuracy You learned some approaches to",
      "offset": 10880.04,
      "duration": 5.399
    },
    {
      "lang": "en",
      "text": "improve the model's performance In",
      "offset": 10883.04,
      "duration": 6.72
    },
    {
      "lang": "en",
      "text": "summary we can add the embedding layer",
      "offset": 10885.439,
      "duration": 7.481
    },
    {
      "lang": "en",
      "text": "increase the number of layers tune the",
      "offset": 10889.76,
      "duration": 6.48
    },
    {
      "lang": "en",
      "text": "parameters increase the vocabulary size",
      "offset": 10892.92,
      "duration": 5.88
    },
    {
      "lang": "en",
      "text": "accept longer sentences with more memory",
      "offset": 10896.24,
      "duration": 5.039
    },
    {
      "lang": "en",
      "text": "cells",
      "offset": 10898.8,
      "duration": 5.84
    },
    {
      "lang": "en",
      "text": "RNN models can overfit even with a few",
      "offset": 10901.279,
      "duration": 5.241
    },
    {
      "lang": "en",
      "text": "epochs like",
      "offset": 10904.64,
      "duration": 5.839
    },
    {
      "lang": "en",
      "text": "10 If the model overfits we can test",
      "offset": 10906.52,
      "duration": 6.6
    },
    {
      "lang": "en",
      "text": "using different batches sizes because",
      "offset": 10910.479,
      "duration": 5.92
    },
    {
      "lang": "en",
      "text": "RNN models are very sensitive to them",
      "offset": 10913.12,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "since the batch size determines the",
      "offset": 10916.399,
      "duration": 4.721
    },
    {
      "lang": "en",
      "text": "number of updates in the weights that",
      "offset": 10918.8,
      "duration": 4.36
    },
    {
      "lang": "en",
      "text": "will be",
      "offset": 10921.12,
      "duration": 5.84
    },
    {
      "lang": "en",
      "text": "performed Also adding dropout layers and",
      "offset": 10923.16,
      "duration": 6.92
    },
    {
      "lang": "en",
      "text": "using the parameters drop out recurrent",
      "offset": 10926.96,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "dropout can add extra noise to the",
      "offset": 10930.08,
      "duration": 5.199
    },
    {
      "lang": "en",
      "text": "training data forcing the model to be",
      "offset": 10932.56,
      "duration": 6.799
    },
    {
      "lang": "en",
      "text": "more general and reduce overfeitting",
      "offset": 10935.279,
      "duration": 7.441
    },
    {
      "lang": "en",
      "text": "The parameter dropout on RNN layers",
      "offset": 10939.359,
      "duration": 6.801
    },
    {
      "lang": "en",
      "text": "removes a percentage of the input data",
      "offset": 10942.72,
      "duration": 6.08
    },
    {
      "lang": "en",
      "text": "while the recurrent dropout removes a",
      "offset": 10946.16,
      "duration": 5.72
    },
    {
      "lang": "en",
      "text": "percentage of the memory",
      "offset": 10948.8,
      "duration": 6.16
    },
    {
      "lang": "en",
      "text": "cell Despite not being in the scope of",
      "offset": 10951.88,
      "duration": 6.12
    },
    {
      "lang": "en",
      "text": "this course the mix of convolution and",
      "offset": 10954.96,
      "duration": 6.479
    },
    {
      "lang": "en",
      "text": "max pooling layers with RNN cells has",
      "offset": 10958,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "been used recently and achieved the",
      "offset": 10961.439,
      "duration": 6.241
    },
    {
      "lang": "en",
      "text": "state-of-the-art results in NLP problems",
      "offset": 10963.76,
      "duration": 6.639
    },
    {
      "lang": "en",
      "text": "In short the convolution layers has",
      "offset": 10967.68,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "filters that determines the output",
      "offset": 10970.399,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "dimension Kernel size which is the",
      "offset": 10972.72,
      "duration": 5.92
    },
    {
      "lang": "en",
      "text": "window size for convolution and padding",
      "offset": 10975.439,
      "duration": 5.84
    },
    {
      "lang": "en",
      "text": "which determines if the input should be",
      "offset": 10978.64,
      "duration": 6.92
    },
    {
      "lang": "en",
      "text": "padded add zeros around the matrix or",
      "offset": 10981.279,
      "duration": 7.2
    },
    {
      "lang": "en",
      "text": "not The max pooling contains the",
      "offset": 10985.56,
      "duration": 5.64
    },
    {
      "lang": "en",
      "text": "parameter pool size that determines the",
      "offset": 10988.479,
      "duration": 6.081
    },
    {
      "lang": "en",
      "text": "window to look for the max value",
      "offset": 10991.2,
      "duration": 5.84
    },
    {
      "lang": "en",
      "text": "For more details on convolution and max",
      "offset": 10994.56,
      "duration": 4.799
    },
    {
      "lang": "en",
      "text": "pooling layers search for convolution",
      "offset": 10997.04,
      "duration": 4.92
    },
    {
      "lang": "en",
      "text": "courses on data",
      "offset": 10999.359,
      "duration": 5.521
    },
    {
      "lang": "en",
      "text": "camp We created a model after some",
      "offset": 11001.96,
      "duration": 5.96
    },
    {
      "lang": "en",
      "text": "iterations of tests and parameter tuning",
      "offset": 11004.88,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "to obtain high accuracy on the sentiment",
      "offset": 11007.92,
      "duration": 4.28
    },
    {
      "lang": "en",
      "text": "classification",
      "offset": 11010.64,
      "duration": 5.759
    },
    {
      "lang": "en",
      "text": "task The model architecture is using the",
      "offset": 11012.2,
      "duration": 6.44
    },
    {
      "lang": "en",
      "text": "embedding layer in the first layer of",
      "offset": 11016.399,
      "duration": 8.601
    },
    {
      "lang": "en",
      "text": "the model Add a dance layer Add one LSTM",
      "offset": 11018.64,
      "duration": 11.6
    },
    {
      "lang": "en",
      "text": "layer Add one GRU layer Add two other",
      "offset": 11025,
      "duration": 9
    },
    {
      "lang": "en",
      "text": "dance layers Add another dance with one",
      "offset": 11030.24,
      "duration": 5.72
    },
    {
      "lang": "en",
      "text": "unit as output",
      "offset": 11034,
      "duration": 5.439
    },
    {
      "lang": "en",
      "text": "layer The dropout layers are to avoid",
      "offset": 11035.96,
      "duration": 6.12
    },
    {
      "lang": "en",
      "text": "overfitting by adding extra noise to the",
      "offset": 11039.439,
      "duration": 7.361
    },
    {
      "lang": "en",
      "text": "data by removing some of the inputs",
      "offset": 11042.08,
      "duration": 7.199
    },
    {
      "lang": "en",
      "text": "You saw that it is possible to play with",
      "offset": 11046.8,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "the models add new layers change",
      "offset": 11049.279,
      "duration": 4.04
    },
    {
      "lang": "en",
      "text": "parameters",
      "offset": 11051.92,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "etc The art of creating the best",
      "offset": 11053.319,
      "duration": 5.401
    },
    {
      "lang": "en",
      "text": "possible model demands experience and",
      "offset": 11056.08,
      "duration": 5.56
    },
    {
      "lang": "en",
      "text": "deep understanding of the",
      "offset": 11058.72,
      "duration": 5.599
    },
    {
      "lang": "en",
      "text": "parameters You learned before how to",
      "offset": 11061.64,
      "duration": 5.799
    },
    {
      "lang": "en",
      "text": "perform sentiment analysis on the IMTB",
      "offset": 11064.319,
      "duration": 6.641
    },
    {
      "lang": "en",
      "text": "data set Sentiment analysis was framed",
      "offset": 11067.439,
      "duration": 5.681
    },
    {
      "lang": "en",
      "text": "as a classification problem with two",
      "offset": 11070.96,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "classes",
      "offset": 11073.12,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "Let's learn now when there are more than",
      "offset": 11074.56,
      "duration": 3.799
    },
    {
      "lang": "en",
      "text": "two",
      "offset": 11076.8,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "classes Text classification can be",
      "offset": 11078.359,
      "duration": 5.441
    },
    {
      "lang": "en",
      "text": "applied to many different problems",
      "offset": 11081.12,
      "duration": 5.84
    },
    {
      "lang": "en",
      "text": "Historically it is studied as news",
      "offset": 11083.8,
      "duration": 5.4
    },
    {
      "lang": "en",
      "text": "articles classification into a",
      "offset": 11086.96,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "predetermined set of classes And based",
      "offset": 11089.2,
      "duration": 6.079
    },
    {
      "lang": "en",
      "text": "on the summary or the title or even the",
      "offset": 11092.56,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "whole body of the article the machine",
      "offset": 11095.279,
      "duration": 4.561
    },
    {
      "lang": "en",
      "text": "learning models determine if the news",
      "offset": 11097.68,
      "duration": 5.639
    },
    {
      "lang": "en",
      "text": "article is about economy sports real",
      "offset": 11099.84,
      "duration": 5.4
    },
    {
      "lang": "en",
      "text": "estate and so",
      "offset": 11103.319,
      "duration": 5.561
    },
    {
      "lang": "en",
      "text": "on It can also be used for classifying a",
      "offset": 11105.24,
      "duration": 6.199
    },
    {
      "lang": "en",
      "text": "company's documents into categories that",
      "offset": 11108.88,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "will be analyzed only by the",
      "offset": 11111.439,
      "duration": 4.201
    },
    {
      "lang": "en",
      "text": "corresponding department",
      "offset": 11113.279,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "Finally you can direct for example an",
      "offset": 11115.64,
      "duration": 6.28
    },
    {
      "lang": "en",
      "text": "online customer service representative",
      "offset": 11119.279,
      "duration": 5.281
    },
    {
      "lang": "en",
      "text": "to the specific problem by classifying",
      "offset": 11121.92,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "the query that the customer wrote when",
      "offset": 11124.56,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "contacting the service allowing to solve",
      "offset": 11127.2,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "the problem faster and increasing",
      "offset": 11130,
      "duration": 4.12
    },
    {
      "lang": "en",
      "text": "customer",
      "offset": 11132,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "satisfaction A few parameters change",
      "offset": 11134.12,
      "duration": 5.08
    },
    {
      "lang": "en",
      "text": "when going from binary to multiclass",
      "offset": 11136.88,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "classification",
      "offset": 11139.2,
      "duration": 5.119
    },
    {
      "lang": "en",
      "text": "The most notable ones being the shape of",
      "offset": 11140.8,
      "duration": 6.36
    },
    {
      "lang": "en",
      "text": "the variable y containing the",
      "offset": 11144.319,
      "duration": 5.681
    },
    {
      "lang": "en",
      "text": "classes the number of units on the",
      "offset": 11147.16,
      "duration": 6.44
    },
    {
      "lang": "en",
      "text": "output layer the activation function to",
      "offset": 11150,
      "duration": 9.16
    },
    {
      "lang": "en",
      "text": "use on the output layer and the loss",
      "offset": 11153.6,
      "duration": 8.799
    },
    {
      "lang": "en",
      "text": "function The shape of the variable y",
      "offset": 11159.16,
      "duration": 5.64
    },
    {
      "lang": "en",
      "text": "changes with the application of the one",
      "offset": 11162.399,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "hot encoding",
      "offset": 11164.8,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "Thus the output layer also need the",
      "offset": 11166.72,
      "duration": 5.88
    },
    {
      "lang": "en",
      "text": "number of classes as",
      "offset": 11169.6,
      "duration": 6.64
    },
    {
      "lang": "en",
      "text": "units One hot encoding makes all the",
      "offset": 11172.6,
      "duration": 5.759
    },
    {
      "lang": "en",
      "text": "classes to be",
      "offset": 11176.24,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "equidistant If we use numbers as",
      "offset": 11178.359,
      "duration": 4.841
    },
    {
      "lang": "en",
      "text": "representation for three different",
      "offset": 11181.12,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "classes we would imply that class one is",
      "offset": 11183.2,
      "duration": 7.119
    },
    {
      "lang": "en",
      "text": "closer to class two than it is to class",
      "offset": 11186.72,
      "duration": 6.719
    },
    {
      "lang": "en",
      "text": "three And in many applications this is",
      "offset": 11190.319,
      "duration": 4.441
    },
    {
      "lang": "en",
      "text": "not the",
      "offset": 11193.439,
      "duration": 4.721
    },
    {
      "lang": "en",
      "text": "case Also during the training of the",
      "offset": 11194.76,
      "duration": 6.519
    },
    {
      "lang": "en",
      "text": "model the loss function will show bigger",
      "offset": 11198.16,
      "duration": 6.159
    },
    {
      "lang": "en",
      "text": "error if mclassified class one as class",
      "offset": 11201.279,
      "duration": 6.321
    },
    {
      "lang": "en",
      "text": "3 than if it mclassified class one as",
      "offset": 11204.319,
      "duration": 6.361
    },
    {
      "lang": "en",
      "text": "class two and this is an",
      "offset": 11207.6,
      "duration": 6.96
    },
    {
      "lang": "en",
      "text": "error Using one hot all the classes will",
      "offset": 11210.68,
      "duration": 7.799
    },
    {
      "lang": "en",
      "text": "have a distance equal to one Furthermore",
      "offset": 11214.56,
      "duration": 6.48
    },
    {
      "lang": "en",
      "text": "the softmax function will return the",
      "offset": 11218.479,
      "duration": 5.361
    },
    {
      "lang": "en",
      "text": "probability of each class and we can",
      "offset": 11221.04,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "easily assign the document to the class",
      "offset": 11223.84,
      "duration": 5.519
    },
    {
      "lang": "en",
      "text": "that has higher probability and the loss",
      "offset": 11226.56,
      "duration": 6.28
    },
    {
      "lang": "en",
      "text": "function will work as",
      "offset": 11229.359,
      "duration": 6.08
    },
    {
      "lang": "en",
      "text": "expected The same goes for the",
      "offset": 11232.84,
      "duration": 5.8
    },
    {
      "lang": "en",
      "text": "activation function The sigmoid function",
      "offset": 11235.439,
      "duration": 6.121
    },
    {
      "lang": "en",
      "text": "is very useful and fast to separate two",
      "offset": 11238.64,
      "duration": 6.32
    },
    {
      "lang": "en",
      "text": "classes But when we have more than two",
      "offset": 11241.56,
      "duration": 7.32
    },
    {
      "lang": "en",
      "text": "it is not recommended Instead we use the",
      "offset": 11244.96,
      "duration": 6.16
    },
    {
      "lang": "en",
      "text": "soft max function that gives the",
      "offset": 11248.88,
      "duration": 4.68
    },
    {
      "lang": "en",
      "text": "probability of each class given the",
      "offset": 11251.12,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "inputs and we can choose the one with",
      "offset": 11253.56,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "higher",
      "offset": 11256.24,
      "duration": 5.119
    },
    {
      "lang": "en",
      "text": "probability Finally we were using the",
      "offset": 11258.04,
      "duration": 6.08
    },
    {
      "lang": "en",
      "text": "binary cross enthropy activation",
      "offset": 11261.359,
      "duration": 6.321
    },
    {
      "lang": "en",
      "text": "function But now we have more than two",
      "offset": 11264.12,
      "duration": 6.279
    },
    {
      "lang": "en",
      "text": "classes and is more appropriate to use",
      "offset": 11267.68,
      "duration": 5.4
    },
    {
      "lang": "en",
      "text": "the corresponding version called",
      "offset": 11270.399,
      "duration": 5.801
    },
    {
      "lang": "en",
      "text": "categorical cross",
      "offset": 11273.08,
      "duration": 7.88
    },
    {
      "lang": "en",
      "text": "entropy Sometimes our data uses text to",
      "offset": 11276.2,
      "duration": 8.84
    },
    {
      "lang": "en",
      "text": "represent the classes Then we can use",
      "offset": 11280.96,
      "duration": 7.76
    },
    {
      "lang": "en",
      "text": "panda series categoric data types to",
      "offset": 11285.04,
      "duration": 7.2
    },
    {
      "lang": "en",
      "text": "transform text into numbers by accessing",
      "offset": 11288.72,
      "duration": 6.44
    },
    {
      "lang": "en",
      "text": "its cat codes",
      "offset": 11292.24,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "attribute This is the first step for",
      "offset": 11295.16,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "preparing the",
      "offset": 11297.92,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "data The second step is to transform Y",
      "offset": 11299.24,
      "duration": 6.6
    },
    {
      "lang": "en",
      "text": "into one hot encoded values using the",
      "offset": 11302.88,
      "duration": 7.2
    },
    {
      "lang": "en",
      "text": "function two categorical from",
      "offset": 11305.84,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "carasut.nputs We simply apply it to the",
      "offset": 11312.359,
      "duration": 5.721
    },
    {
      "lang": "en",
      "text": "numeric vector of classes representation",
      "offset": 11315.279,
      "duration": 5.681
    },
    {
      "lang": "en",
      "text": "to obtain the one hot encoded version of",
      "offset": 11318.08,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "the vector",
      "offset": 11320.96,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "In the last chapter you were introduced",
      "offset": 11323.04,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "to transfer learning for language models",
      "offset": 11325.6,
      "duration": 6.32
    },
    {
      "lang": "en",
      "text": "using Glove Now let's have a closer look",
      "offset": 11327.92,
      "duration": 5.92
    },
    {
      "lang": "en",
      "text": "on the different available word",
      "offset": 11331.92,
      "duration": 4.76
    },
    {
      "lang": "en",
      "text": "embeddings that can be used for transfer",
      "offset": 11333.84,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "learning Depending on the problem at",
      "offset": 11336.68,
      "duration": 5.32
    },
    {
      "lang": "en",
      "text": "hand different ways to treat text can",
      "offset": 11339.2,
      "duration": 4.92
    },
    {
      "lang": "en",
      "text": "improve the model's",
      "offset": 11342,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "quality Transfer learning became popular",
      "offset": 11344.12,
      "duration": 5.88
    },
    {
      "lang": "en",
      "text": "initially for computer vision tasks",
      "offset": 11347.2,
      "duration": 6.6
    },
    {
      "lang": "en",
      "text": "Later it was also applied to language",
      "offset": 11350,
      "duration": 6.64
    },
    {
      "lang": "en",
      "text": "models Transfer learning provides a",
      "offset": 11353.8,
      "duration": 6.479
    },
    {
      "lang": "en",
      "text": "model with a better initialization",
      "offset": 11356.64,
      "duration": 6.08
    },
    {
      "lang": "en",
      "text": "values Meaning that instead of",
      "offset": 11360.279,
      "duration": 5
    },
    {
      "lang": "en",
      "text": "initializing the weights all equal to",
      "offset": 11362.72,
      "duration": 6.08
    },
    {
      "lang": "en",
      "text": "zero or with random numbers we use the",
      "offset": 11365.279,
      "duration": 6.441
    },
    {
      "lang": "en",
      "text": "values obtained previously in a similar",
      "offset": 11368.8,
      "duration": 6.08
    },
    {
      "lang": "en",
      "text": "task In other words we use knowledge",
      "offset": 11371.72,
      "duration": 6.04
    },
    {
      "lang": "en",
      "text": "already available",
      "offset": 11374.88,
      "duration": 5.519
    },
    {
      "lang": "en",
      "text": "Some research institutes and companies",
      "offset": 11377.76,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "started to use their computer power",
      "offset": 11380.399,
      "duration": 5.361
    },
    {
      "lang": "en",
      "text": "availability to train models on very big",
      "offset": 11382.56,
      "duration": 6.719
    },
    {
      "lang": "en",
      "text": "data sets and share the obtained weights",
      "offset": 11385.76,
      "duration": 4.679
    },
    {
      "lang": "en",
      "text": "with the",
      "offset": 11389.279,
      "duration": 4.721
    },
    {
      "lang": "en",
      "text": "community Glove is an example of this We",
      "offset": 11390.439,
      "duration": 5.481
    },
    {
      "lang": "en",
      "text": "were able to use the weights of the",
      "offset": 11394,
      "duration": 4.479
    },
    {
      "lang": "en",
      "text": "glove vectors trained on the whole",
      "offset": 11395.92,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "Wikipedia data task that would be",
      "offset": 11398.479,
      "duration": 7.601
    },
    {
      "lang": "en",
      "text": "impossible with limited computer power",
      "offset": 11401.92,
      "duration": 6.88
    },
    {
      "lang": "en",
      "text": "This allows many more researchers to",
      "offset": 11406.08,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "improve the current knowledge in many",
      "offset": 11408.8,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "fields by using those shared weights as",
      "offset": 11410.88,
      "duration": 7.16
    },
    {
      "lang": "en",
      "text": "a starting point and evolving from there",
      "offset": 11413.92,
      "duration": 7.04
    },
    {
      "lang": "en",
      "text": "Researchers with limited computer power",
      "offset": 11418.04,
      "duration": 5.48
    },
    {
      "lang": "en",
      "text": "could achieve state-of-the-art results",
      "offset": 11420.96,
      "duration": 6.12
    },
    {
      "lang": "en",
      "text": "because of this open sourcing of the",
      "offset": 11423.52,
      "duration": 6.64
    },
    {
      "lang": "en",
      "text": "models There are a few alternatives to",
      "offset": 11427.08,
      "duration": 5.239
    },
    {
      "lang": "en",
      "text": "Globe models",
      "offset": 11430.16,
      "duration": 6.08
    },
    {
      "lang": "en",
      "text": "Word tovac was created in 2013 by Google",
      "offset": 11432.319,
      "duration": 6.521
    },
    {
      "lang": "en",
      "text": "and contains two approaches to model a",
      "offset": 11436.24,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "corpus The continuous bag of words model",
      "offset": 11438.84,
      "duration": 6.92
    },
    {
      "lang": "en",
      "text": "and the skip grand model Continuous bag",
      "offset": 11442.24,
      "duration": 6.88
    },
    {
      "lang": "en",
      "text": "of words uses neighboring or context",
      "offset": 11445.76,
      "duration": 7.04
    },
    {
      "lang": "en",
      "text": "words to predict the center word While",
      "offset": 11449.12,
      "duration": 6.4
    },
    {
      "lang": "en",
      "text": "the skip grand model does the opposite",
      "offset": 11452.8,
      "duration": 5.519
    },
    {
      "lang": "en",
      "text": "which is to utilize the center word to",
      "offset": 11455.52,
      "duration": 5.48
    },
    {
      "lang": "en",
      "text": "predict its context",
      "offset": 11458.319,
      "duration": 6.321
    },
    {
      "lang": "en",
      "text": "words Fast text was created by Facebook",
      "offset": 11461,
      "duration": 7.319
    },
    {
      "lang": "en",
      "text": "in 2016 as an improvement of the word",
      "offset": 11464.64,
      "duration": 8
    },
    {
      "lang": "en",
      "text": "tove model It uses a word and engrams of",
      "offset": 11468.319,
      "duration": 7.721
    },
    {
      "lang": "en",
      "text": "its stars to train the model",
      "offset": 11472.64,
      "duration": 6.48
    },
    {
      "lang": "en",
      "text": "Finally Elmo was created by Allen",
      "offset": 11476.04,
      "duration": 6.439
    },
    {
      "lang": "en",
      "text": "Institute in 2018 and achieved a",
      "offset": 11479.12,
      "duration": 5.96
    },
    {
      "lang": "en",
      "text": "state-of-the-art in many LLP",
      "offset": 11482.479,
      "duration": 6.241
    },
    {
      "lang": "en",
      "text": "tasks It uses words and birectional",
      "offset": 11485.08,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "layers to train the language",
      "offset": 11488.72,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "model Word tovac and fast text are",
      "offset": 11490.76,
      "duration": 6.28
    },
    {
      "lang": "en",
      "text": "available in the package gansim while",
      "offset": 11493.92,
      "duration": 7.2
    },
    {
      "lang": "en",
      "text": "elmo is available on tensorflow hub Elmo",
      "offset": 11497.04,
      "duration": 8.08
    },
    {
      "lang": "en",
      "text": "is out of the scope of this course",
      "offset": 11501.12,
      "duration": 7.68
    },
    {
      "lang": "en",
      "text": "To use wordtovac in Python import the",
      "offset": 11505.12,
      "duration": 7.239
    },
    {
      "lang": "en",
      "text": "word tovac class from",
      "offset": 11508.8,
      "duration": 6.24
    },
    {
      "lang": "en",
      "text": "gensing.models To train a model we",
      "offset": 11512.359,
      "duration": 5.881
    },
    {
      "lang": "en",
      "text": "initialize the subclass word to passing",
      "offset": 11515.04,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "a corpus",
      "offset": 11518.24,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "Other parameters include size which is",
      "offset": 11520.24,
      "duration": 5.64
    },
    {
      "lang": "en",
      "text": "the dimension of the embedding vector to",
      "offset": 11523.2,
      "duration": 5.72
    },
    {
      "lang": "en",
      "text": "use window which is the number of",
      "offset": 11525.88,
      "duration": 7.36
    },
    {
      "lang": "en",
      "text": "neighbor words to use as context and",
      "offset": 11528.92,
      "duration": 7.24
    },
    {
      "lang": "en",
      "text": "ether which is the number of epochs to",
      "offset": 11533.24,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "train the",
      "offset": 11536.16,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "model We can use the model for example",
      "offset": 11537.319,
      "duration": 6.841
    },
    {
      "lang": "en",
      "text": "to find similar words in the corpus For",
      "offset": 11540.72,
      "duration": 6.4
    },
    {
      "lang": "en",
      "text": "that we access the word vectors",
      "offset": 11544.16,
      "duration": 7.68
    },
    {
      "lang": "en",
      "text": "attribute WV and the method most similar",
      "offset": 11547.12,
      "duration": 7.239
    },
    {
      "lang": "en",
      "text": "passing a list of words to find",
      "offset": 11551.84,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "similarities and the number of similar",
      "offset": 11554.359,
      "duration": 4.801
    },
    {
      "lang": "en",
      "text": "words to",
      "offset": 11556.88,
      "duration": 6.88
    },
    {
      "lang": "en",
      "text": "retrieve Same as word tovac fast text is",
      "offset": 11559.16,
      "duration": 7.56
    },
    {
      "lang": "en",
      "text": "also implemented in genansim and does",
      "offset": 11563.76,
      "duration": 6.08
    },
    {
      "lang": "en",
      "text": "share many attributes and methods We",
      "offset": 11566.72,
      "duration": 6.2
    },
    {
      "lang": "en",
      "text": "first import the class fast text from",
      "offset": 11569.84,
      "duration": 6.559
    },
    {
      "lang": "en",
      "text": "Gansim Then to train a model we have",
      "offset": 11572.92,
      "duration": 7.32
    },
    {
      "lang": "en",
      "text": "three steps First we instantiate the",
      "offset": 11576.399,
      "duration": 6.321
    },
    {
      "lang": "en",
      "text": "model with basic parameters like the",
      "offset": 11580.24,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "size of the embedding vector and the",
      "offset": 11582.72,
      "duration": 4.719
    },
    {
      "lang": "en",
      "text": "window containing the number of neighbor",
      "offset": 11585.2,
      "duration": 3.96
    },
    {
      "lang": "en",
      "text": "words to use as",
      "offset": 11587.439,
      "duration": 5.281
    },
    {
      "lang": "en",
      "text": "context Then we build the vocabulary",
      "offset": 11589.16,
      "duration": 6.56
    },
    {
      "lang": "en",
      "text": "based on the corpus",
      "offset": 11592.72,
      "duration": 5.679
    },
    {
      "lang": "en",
      "text": "Finally we train the model by passing",
      "offset": 11595.72,
      "duration": 5.32
    },
    {
      "lang": "en",
      "text": "the corpus the total number of documents",
      "offset": 11598.399,
      "duration": 5.361
    },
    {
      "lang": "en",
      "text": "or sentences in the corpus and the",
      "offset": 11601.04,
      "duration": 4.52
    },
    {
      "lang": "en",
      "text": "number of epochs to",
      "offset": 11603.76,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "train The same methods such as finding",
      "offset": 11605.56,
      "duration": 6.12
    },
    {
      "lang": "en",
      "text": "similar words are also available on the",
      "offset": 11609.04,
      "duration": 4.76
    },
    {
      "lang": "en",
      "text": "fast text",
      "offset": 11611.68,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "class Now you are going to build models",
      "offset": 11613.8,
      "duration": 5.92
    },
    {
      "lang": "en",
      "text": "in kas and see how to perform multiclass",
      "offset": 11616.64,
      "duration": 6.719
    },
    {
      "lang": "en",
      "text": "classification Let's dive in",
      "offset": 11619.72,
      "duration": 5.96
    },
    {
      "lang": "en",
      "text": "In the first chapter you learned to",
      "offset": 11623.359,
      "duration": 4.721
    },
    {
      "lang": "en",
      "text": "build a sentiment classification model",
      "offset": 11625.68,
      "duration": 5.599
    },
    {
      "lang": "en",
      "text": "using KAS The model was created using",
      "offset": 11628.08,
      "duration": 6.399
    },
    {
      "lang": "en",
      "text": "the sequential class the embedding layer",
      "offset": 11631.279,
      "duration": 6.08
    },
    {
      "lang": "en",
      "text": "one LSTM layer and the output layer with",
      "offset": 11634.479,
      "duration": 5.641
    },
    {
      "lang": "en",
      "text": "the sigmoid as the activation",
      "offset": 11637.359,
      "duration": 5.601
    },
    {
      "lang": "en",
      "text": "function We compile the model using",
      "offset": 11640.12,
      "duration": 5.64
    },
    {
      "lang": "en",
      "text": "binary cross entropy loss function the",
      "offset": 11642.96,
      "duration": 7.399
    },
    {
      "lang": "en",
      "text": "atom optimizer and accuracy as",
      "offset": 11645.76,
      "duration": 7.76
    },
    {
      "lang": "en",
      "text": "metric The same architecture used for",
      "offset": 11650.359,
      "duration": 5.721
    },
    {
      "lang": "en",
      "text": "sentiment classification can be used for",
      "offset": 11653.52,
      "duration": 4.6
    },
    {
      "lang": "en",
      "text": "multiclass",
      "offset": 11656.08,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "classification The only difference as",
      "offset": 11658.12,
      "duration": 4.84
    },
    {
      "lang": "en",
      "text": "mentioned before is that the last layer",
      "offset": 11660.479,
      "duration": 5.201
    },
    {
      "lang": "en",
      "text": "now has the number of classes units and",
      "offset": 11662.96,
      "duration": 6.72
    },
    {
      "lang": "en",
      "text": "uses soft max as activation function",
      "offset": 11665.68,
      "duration": 6.639
    },
    {
      "lang": "en",
      "text": "Also when compiling we use the",
      "offset": 11669.68,
      "duration": 6.719
    },
    {
      "lang": "en",
      "text": "categorical cross entropy loss function",
      "offset": 11672.319,
      "duration": 7.04
    },
    {
      "lang": "en",
      "text": "To implement multiclass classification",
      "offset": 11676.399,
      "duration": 5.92
    },
    {
      "lang": "en",
      "text": "we are going to use the 20 news groups",
      "offset": 11679.359,
      "duration": 4.201
    },
    {
      "lang": "en",
      "text": "data",
      "offset": 11682.319,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "set The data set is available in sklearn",
      "offset": 11683.56,
      "duration": 7.48
    },
    {
      "lang": "en",
      "text": "by the function fetch 20 news group",
      "offset": 11688.319,
      "duration": 6.881
    },
    {
      "lang": "en",
      "text": "contained in sklearn data set module",
      "offset": 11691.04,
      "duration": 6.8
    },
    {
      "lang": "en",
      "text": "We can download the train and test data",
      "offset": 11695.2,
      "duration": 6.079
    },
    {
      "lang": "en",
      "text": "separately by using the parameter subset",
      "offset": 11697.84,
      "duration": 8.72
    },
    {
      "lang": "en",
      "text": "as in new string equal to fetch 20 news",
      "offset": 11701.279,
      "duration": 10.481
    },
    {
      "lang": "en",
      "text": "groups Subset equal to string train Same",
      "offset": 11706.56,
      "duration": 7.64
    },
    {
      "lang": "en",
      "text": "goes to download the test",
      "offset": 11711.76,
      "duration": 5.92
    },
    {
      "lang": "en",
      "text": "set The fetched data has the following",
      "offset": 11714.2,
      "duration": 5.64
    },
    {
      "lang": "en",
      "text": "attributes",
      "offset": 11717.68,
      "duration": 3.96
    },
    {
      "lang": "en",
      "text": "The D E",
      "offset": 11719.84,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "SR contains the documentation of the",
      "offset": 11721.64,
      "duration": 6.719
    },
    {
      "lang": "en",
      "text": "data set including examples of",
      "offset": 11724.64,
      "duration": 7.28
    },
    {
      "lang": "en",
      "text": "usage Dot data is an array containing",
      "offset": 11728.359,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "the text of each news",
      "offset": 11731.92,
      "duration": 6.08
    },
    {
      "lang": "en",
      "text": "article Dot file names contains an array",
      "offset": 11734.359,
      "duration": 5.841
    },
    {
      "lang": "en",
      "text": "with the file names on",
      "offset": 11738,
      "duration": 5.84
    },
    {
      "lang": "en",
      "text": "disk Dot target contains an array with",
      "offset": 11740.2,
      "duration": 6.6
    },
    {
      "lang": "en",
      "text": "the numerical index of the true class of",
      "offset": 11743.84,
      "duration": 5.439
    },
    {
      "lang": "en",
      "text": "each news article",
      "offset": 11746.8,
      "duration": 6.08
    },
    {
      "lang": "en",
      "text": "dot target names is an array with the",
      "offset": 11749.279,
      "duration": 6.96
    },
    {
      "lang": "en",
      "text": "unique names of the",
      "offset": 11752.88,
      "duration": 3.359
    },
    {
      "lang": "en",
      "text": "classes We will use the raw text of the",
      "offset": 11756.439,
      "duration": 7.081
    },
    {
      "lang": "en",
      "text": "20 news groups data set So you can apply",
      "offset": 11760.319,
      "duration": 6.16
    },
    {
      "lang": "en",
      "text": "the same steps on any other data set you",
      "offset": 11763.52,
      "duration": 4.919
    },
    {
      "lang": "en",
      "text": "are interested",
      "offset": 11766.479,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "in To preprocess the text we will use",
      "offset": 11768.439,
      "duration": 5.96
    },
    {
      "lang": "en",
      "text": "the tokenizer class from",
      "offset": 11772.479,
      "duration": 4.481
    },
    {
      "lang": "en",
      "text": "caras.processing.ext",
      "offset": 11774.399,
      "duration": 5.84
    },
    {
      "lang": "en",
      "text": "text module and the pad sequences",
      "offset": 11776.96,
      "duration": 5.479
    },
    {
      "lang": "en",
      "text": "function from kas.p",
      "offset": 11780.239,
      "duration": 4.681
    },
    {
      "lang": "en",
      "text": "prep-processing sequence",
      "offset": 11782.439,
      "duration": 6.04
    },
    {
      "lang": "en",
      "text": "module to prep-process the targets we",
      "offset": 11784.92,
      "duration": 7.439
    },
    {
      "lang": "en",
      "text": "will use the function to categorical as",
      "offset": 11788.479,
      "duration": 7.361
    },
    {
      "lang": "en",
      "text": "before the tokenizer class would create",
      "offset": 11792.359,
      "duration": 6.201
    },
    {
      "lang": "en",
      "text": "numerical indexes of the vocabulary",
      "offset": 11795.84,
      "duration": 5.92
    },
    {
      "lang": "en",
      "text": "present on the training data so we can",
      "offset": 11798.56,
      "duration": 6.799
    },
    {
      "lang": "en",
      "text": "use on our RNN models we first",
      "offset": 11801.76,
      "duration": 6.639
    },
    {
      "lang": "en",
      "text": "instantiate the class and keep it on the",
      "offset": 11805.359,
      "duration": 6.321
    },
    {
      "lang": "en",
      "text": "variable tokenizer",
      "offset": 11808.399,
      "duration": 6.481
    },
    {
      "lang": "en",
      "text": "Then we use the method tokenizer.fit on",
      "offset": 11811.68,
      "duration": 6.799
    },
    {
      "lang": "en",
      "text": "texts and pass the new string data as",
      "offset": 11814.88,
      "duration": 7.519
    },
    {
      "lang": "en",
      "text": "the array to fit on This updates the",
      "offset": 11818.479,
      "duration": 6.481
    },
    {
      "lang": "en",
      "text": "tokenizer instance with the vocabulary",
      "offset": 11822.399,
      "duration": 5.121
    },
    {
      "lang": "en",
      "text": "and indexes",
      "offset": 11824.96,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "Next we transform the text data into a",
      "offset": 11827.52,
      "duration": 6.08
    },
    {
      "lang": "en",
      "text": "sequence of numerical indexes using the",
      "offset": 11830.96,
      "duration": 6.64
    },
    {
      "lang": "en",
      "text": "tokenizer dot text to sequences method",
      "offset": 11833.6,
      "duration": 7.48
    },
    {
      "lang": "en",
      "text": "and apply on the new strain dot",
      "offset": 11837.6,
      "duration": 8.12
    },
    {
      "lang": "en",
      "text": "data Save the results in the X train",
      "offset": 11841.08,
      "duration": 8.12
    },
    {
      "lang": "en",
      "text": "variable Now we pad the sequence for",
      "offset": 11845.72,
      "duration": 6.599
    },
    {
      "lang": "en",
      "text": "them to have the same length using the",
      "offset": 11849.2,
      "duration": 5.92
    },
    {
      "lang": "en",
      "text": "pad sequences function",
      "offset": 11852.319,
      "duration": 6.761
    },
    {
      "lang": "en",
      "text": "We use max length equal to 400 as an",
      "offset": 11855.12,
      "duration": 7.359
    },
    {
      "lang": "en",
      "text": "example This value should be big enough",
      "offset": 11859.08,
      "duration": 6.199
    },
    {
      "lang": "en",
      "text": "not to cut too much of the text and",
      "offset": 11862.479,
      "duration": 5.8
    },
    {
      "lang": "en",
      "text": "small enough to limit the size of the",
      "offset": 11865.279,
      "duration": 6.561
    },
    {
      "lang": "en",
      "text": "data If the text have similar length for",
      "offset": 11868.279,
      "duration": 6.601
    },
    {
      "lang": "en",
      "text": "example tweets you can use the maximum",
      "offset": 11871.84,
      "duration": 6.16
    },
    {
      "lang": "en",
      "text": "length of your sample as the value for",
      "offset": 11874.88,
      "duration": 6.24
    },
    {
      "lang": "en",
      "text": "example 200",
      "offset": 11878,
      "duration": 6.239
    },
    {
      "lang": "en",
      "text": "Finally we change the targets into a one",
      "offset": 11881.12,
      "duration": 6.92
    },
    {
      "lang": "en",
      "text": "hot encoded matrix using the function to",
      "offset": 11884.239,
      "duration": 7.761
    },
    {
      "lang": "en",
      "text": "categorical passing the new",
      "offset": 11888.04,
      "duration": 3.96
    },
    {
      "lang": "en",
      "text": "strain Having prep-processed the data we",
      "offset": 11892.279,
      "duration": 5.96
    },
    {
      "lang": "en",
      "text": "can use it on the caras model to train",
      "offset": 11895.6,
      "duration": 5.92
    },
    {
      "lang": "en",
      "text": "it We can also evaluate the performance",
      "offset": 11898.239,
      "duration": 7.681
    },
    {
      "lang": "en",
      "text": "of the model in a test set",
      "offset": 11901.52,
      "duration": 6.56
    },
    {
      "lang": "en",
      "text": "You learned how to build multiclass",
      "offset": 11905.92,
      "duration": 6.16
    },
    {
      "lang": "en",
      "text": "classification models in KAS Now we will",
      "offset": 11908.08,
      "duration": 7.96
    },
    {
      "lang": "en",
      "text": "see how to calculate the model's",
      "offset": 11912.08,
      "duration": 6.64
    },
    {
      "lang": "en",
      "text": "performance Imagine that you built a",
      "offset": 11916.04,
      "duration": 5.96
    },
    {
      "lang": "en",
      "text": "model and achieved 80% accuracy on the",
      "offset": 11918.72,
      "duration": 7.36
    },
    {
      "lang": "en",
      "text": "test data Is this model good",
      "offset": 11922,
      "duration": 6.72
    },
    {
      "lang": "en",
      "text": "can you say if the model is classifying",
      "offset": 11926.08,
      "duration": 4.44
    },
    {
      "lang": "en",
      "text": "all the classes",
      "offset": 11928.72,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "correctly or if the accuracy is the same",
      "offset": 11930.52,
      "duration": 7.48
    },
    {
      "lang": "en",
      "text": "for each class or if the model is",
      "offset": 11933.92,
      "duration": 6.8
    },
    {
      "lang": "en",
      "text": "predicting only the class with more",
      "offset": 11938,
      "duration": 6.12
    },
    {
      "lang": "en",
      "text": "observations and thus achieving high",
      "offset": 11940.72,
      "duration": 6.48
    },
    {
      "lang": "en",
      "text": "accuracy we cannot say looking only on",
      "offset": 11944.12,
      "duration": 5.72
    },
    {
      "lang": "en",
      "text": "the accuracy",
      "offset": 11947.2,
      "duration": 5.279
    },
    {
      "lang": "en",
      "text": "In the confusion matrix above we have",
      "offset": 11949.84,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "the predictions on the columns and the",
      "offset": 11952.479,
      "duration": 5.121
    },
    {
      "lang": "en",
      "text": "true labels on the rows The numbers",
      "offset": 11954.72,
      "duration": 5.519
    },
    {
      "lang": "en",
      "text": "represent the frequencies of prediction",
      "offset": 11957.6,
      "duration": 5.96
    },
    {
      "lang": "en",
      "text": "or true labels in each of the",
      "offset": 11960.239,
      "duration": 6.881
    },
    {
      "lang": "en",
      "text": "classes The total number of observations",
      "offset": 11963.56,
      "duration": 8.2
    },
    {
      "lang": "en",
      "text": "is 100 We can see that the model has 80%",
      "offset": 11967.12,
      "duration": 7.6
    },
    {
      "lang": "en",
      "text": "accuracy by summing the diagonal of the",
      "offset": 11971.76,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "matrix that corresponds to the corrected",
      "offset": 11974.72,
      "duration": 5
    },
    {
      "lang": "en",
      "text": "prediction of each",
      "offset": 11977.76,
      "duration": 3.719
    },
    {
      "lang": "en",
      "text": "class",
      "offset": 11979.72,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "sace",
      "offset": 11981.479,
      "duration": 5.561
    },
    {
      "lang": "en",
      "text": "out.ism and",
      "offset": 11983.64,
      "duration": 3.4
    },
    {
      "lang": "en",
      "text": "sock.religion.christian But we can see",
      "offset": 11988.04,
      "duration": 4.76
    },
    {
      "lang": "en",
      "text": "that the model predicts almost always",
      "offset": 11990.479,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "the class site.space",
      "offset": 11992.8,
      "duration": 6.16
    },
    {
      "lang": "en",
      "text": "This model is overfitted to this class",
      "offset": 11996.479,
      "duration": 5.84
    },
    {
      "lang": "en",
      "text": "and has poor performance on the others",
      "offset": 11998.96,
      "duration": 6.359
    },
    {
      "lang": "en",
      "text": "How can we make a better",
      "offset": 12002.319,
      "duration": 5.881
    },
    {
      "lang": "en",
      "text": "metric one possible metric is the",
      "offset": 12005.319,
      "duration": 6.281
    },
    {
      "lang": "en",
      "text": "precision It measures for each class if",
      "offset": 12008.2,
      "duration": 7.279
    },
    {
      "lang": "en",
      "text": "the model is accurately predicting this",
      "offset": 12011.6,
      "duration": 6.639
    },
    {
      "lang": "en",
      "text": "class Another is the recall that",
      "offset": 12015.479,
      "duration": 4.92
    },
    {
      "lang": "en",
      "text": "measures if the classes are being",
      "offset": 12018.239,
      "duration": 5.441
    },
    {
      "lang": "en",
      "text": "correctly classified",
      "offset": 12020.399,
      "duration": 7.361
    },
    {
      "lang": "en",
      "text": "F1 score is an weighted harmonic average",
      "offset": 12023.68,
      "duration": 7.16
    },
    {
      "lang": "en",
      "text": "between precision and",
      "offset": 12027.76,
      "duration": 5.679
    },
    {
      "lang": "en",
      "text": "recall We can compute the confusion",
      "offset": 12030.84,
      "duration": 5.519
    },
    {
      "lang": "en",
      "text": "matrix using function called",
      "offset": 12033.439,
      "duration": 7.081
    },
    {
      "lang": "en",
      "text": "confusion matrix from sklearn",
      "offset": 12036.359,
      "duration": 6.721
    },
    {
      "lang": "en",
      "text": "domatrix The function receives two",
      "offset": 12040.52,
      "duration": 5.719
    },
    {
      "lang": "en",
      "text": "parameters y true and y breath",
      "offset": 12043.08,
      "duration": 5.399
    },
    {
      "lang": "en",
      "text": "containing the correct and predicted",
      "offset": 12046.239,
      "duration": 4.481
    },
    {
      "lang": "en",
      "text": "values",
      "offset": 12048.479,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "We can see from the output that the",
      "offset": 12050.72,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "model seems to have higher accuracy for",
      "offset": 12052.8,
      "duration": 4.519
    },
    {
      "lang": "en",
      "text": "the first",
      "offset": 12055.68,
      "duration": 4.639
    },
    {
      "lang": "en",
      "text": "class Now let's see how to compute the",
      "offset": 12057.319,
      "duration": 4.721
    },
    {
      "lang": "en",
      "text": "performance matrix with",
      "offset": 12060.319,
      "duration": 4.881
    },
    {
      "lang": "en",
      "text": "Python We will use the implementation in",
      "offset": 12062.04,
      "duration": 6.12
    },
    {
      "lang": "en",
      "text": "skarn to compute the matrix The",
      "offset": 12065.2,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "performance matrix can be found in the",
      "offset": 12068.16,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "sklearn",
      "offset": 12070.56,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "module and we can import the confusion",
      "offset": 12072.8,
      "duration": 6.8
    },
    {
      "lang": "en",
      "text": "matrix precision score recall score F1",
      "offset": 12075.68,
      "duration": 8.759
    },
    {
      "lang": "en",
      "text": "score accuracy score and classification",
      "offset": 12079.6,
      "duration": 8.24
    },
    {
      "lang": "en",
      "text": "report The accuracy score gives the",
      "offset": 12084.439,
      "duration": 6.84
    },
    {
      "lang": "en",
      "text": "overall performance of the model To use",
      "offset": 12087.84,
      "duration": 6.24
    },
    {
      "lang": "en",
      "text": "the other functions we should pass the",
      "offset": 12091.279,
      "duration": 5.321
    },
    {
      "lang": "en",
      "text": "parameter average equal to",
      "offset": 12094.08,
      "duration": 6.64
    },
    {
      "lang": "en",
      "text": "none We will be explained later",
      "offset": 12096.6,
      "duration": 6.759
    },
    {
      "lang": "en",
      "text": "We can check the values of the matrix to",
      "offset": 12100.72,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "see that they change greatly from class",
      "offset": 12103.359,
      "duration": 7.08
    },
    {
      "lang": "en",
      "text": "to class F1 score of",
      "offset": 12106,
      "duration": 7.08
    },
    {
      "lang": "en",
      "text": "0.15 and",
      "offset": 12110.439,
      "duration": 5.88
    },
    {
      "lang": "en",
      "text": "0.35 for the second and third classes is",
      "offset": 12113.08,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "not a good",
      "offset": 12116.319,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "performance All those metrics can be",
      "offset": 12118.76,
      "duration": 4.519
    },
    {
      "lang": "en",
      "text": "computed in one function The",
      "offset": 12121.279,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "classification report This function can",
      "offset": 12123.279,
      "duration": 5.521
    },
    {
      "lang": "en",
      "text": "receive the parameter target names with",
      "offset": 12126.319,
      "duration": 5.841
    },
    {
      "lang": "en",
      "text": "the classes names for better print The",
      "offset": 12128.8,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "output is a formatted string with",
      "offset": 12132.16,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "precision recall F1 score and support",
      "offset": 12134.56,
      "duration": 4.759
    },
    {
      "lang": "en",
      "text": "for each",
      "offset": 12138.16,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "class Support is the number of",
      "offset": 12139.319,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "observations of the class present on the",
      "offset": 12142,
      "duration": 7.76
    },
    {
      "lang": "en",
      "text": "data At the end it also shows values for",
      "offset": 12145.319,
      "duration": 7.401
    },
    {
      "lang": "en",
      "text": "micro average micro average and weighted",
      "offset": 12149.76,
      "duration": 4.639
    },
    {
      "lang": "en",
      "text": "average",
      "offset": 12152.72,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "Micro average is an average between true",
      "offset": 12154.399,
      "duration": 5.601
    },
    {
      "lang": "en",
      "text": "positive false positive and false",
      "offset": 12157.52,
      "duration": 6.12
    },
    {
      "lang": "en",
      "text": "negative rates and is one value for all",
      "offset": 12160,
      "duration": 6.64
    },
    {
      "lang": "en",
      "text": "classes Micro average computes the",
      "offset": 12163.64,
      "duration": 6.28
    },
    {
      "lang": "en",
      "text": "average of precision recall and F1 score",
      "offset": 12166.64,
      "duration": 7.04
    },
    {
      "lang": "en",
      "text": "between all labels and weighted average",
      "offset": 12169.92,
      "duration": 7.479
    },
    {
      "lang": "en",
      "text": "is the average weighted by",
      "offset": 12173.68,
      "duration": 6.48
    },
    {
      "lang": "en",
      "text": "support This is the last chapter of this",
      "offset": 12177.399,
      "duration": 6.121
    },
    {
      "lang": "en",
      "text": "course and also the most challenging You",
      "offset": 12180.16,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "will learn about sequencetosequence",
      "offset": 12183.52,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "models and applications to text",
      "offset": 12185.6,
      "duration": 4.879
    },
    {
      "lang": "en",
      "text": "generation by creating a model that",
      "offset": 12188,
      "duration": 5.92
    },
    {
      "lang": "en",
      "text": "generate sentences based on the big bang",
      "offset": 12190.479,
      "duration": 6.8
    },
    {
      "lang": "en",
      "text": "theory character Sheldon A neuromachine",
      "offset": 12193.92,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "translation by creating a model to",
      "offset": 12197.279,
      "duration": 4.801
    },
    {
      "lang": "en",
      "text": "translate small sentences from",
      "offset": 12199.92,
      "duration": 4.84
    },
    {
      "lang": "en",
      "text": "Portuguese into",
      "offset": 12202.08,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "English Sequence tosequence models can",
      "offset": 12204.76,
      "duration": 6.28
    },
    {
      "lang": "en",
      "text": "be divided in two groups The ones with",
      "offset": 12207.68,
      "duration": 6.08
    },
    {
      "lang": "en",
      "text": "one output which we saw when doing",
      "offset": 12211.04,
      "duration": 5.319
    },
    {
      "lang": "en",
      "text": "sentiment analysis and multiclass",
      "offset": 12213.76,
      "duration": 5
    },
    {
      "lang": "en",
      "text": "classification and the one with many",
      "offset": 12216.359,
      "duration": 5.481
    },
    {
      "lang": "en",
      "text": "outputs which is the object of study in",
      "offset": 12218.76,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "this",
      "offset": 12221.84,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "chapter It contemplates text generation",
      "offset": 12222.76,
      "duration": 5.519
    },
    {
      "lang": "en",
      "text": "and neuromachine",
      "offset": 12226.08,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "translation Text generation is the",
      "offset": 12228.279,
      "duration": 5.08
    },
    {
      "lang": "en",
      "text": "process of automatically creating",
      "offset": 12230.96,
      "duration": 5.92
    },
    {
      "lang": "en",
      "text": "textual content State-of-the-art models",
      "offset": 12233.359,
      "duration": 6.481
    },
    {
      "lang": "en",
      "text": "perform so well that a person cannot",
      "offset": 12236.88,
      "duration": 6.92
    },
    {
      "lang": "en",
      "text": "identify that the text was created by a",
      "offset": 12239.84,
      "duration": 7.439
    },
    {
      "lang": "en",
      "text": "machine In the model above we can see",
      "offset": 12243.8,
      "duration": 6.28
    },
    {
      "lang": "en",
      "text": "that some words are not correct and can",
      "offset": 12247.279,
      "duration": 6.241
    },
    {
      "lang": "en",
      "text": "easily identify that it was generated by",
      "offset": 12250.08,
      "duration": 4.92
    },
    {
      "lang": "en",
      "text": "a",
      "offset": 12253.52,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "machine A text generation model should",
      "offset": 12255,
      "duration": 7
    },
    {
      "lang": "en",
      "text": "go through the same process as before",
      "offset": 12258.16,
      "duration": 6.88
    },
    {
      "lang": "en",
      "text": "First though you need to choose if your",
      "offset": 12262,
      "duration": 7.279
    },
    {
      "lang": "en",
      "text": "token will be characters or words If you",
      "offset": 12265.04,
      "duration": 7.359
    },
    {
      "lang": "en",
      "text": "choose words then you will need a very",
      "offset": 12269.279,
      "duration": 5.841
    },
    {
      "lang": "en",
      "text": "large data set to predict on the big",
      "offset": 12272.399,
      "duration": 4.681
    },
    {
      "lang": "en",
      "text": "size of the",
      "offset": 12275.12,
      "duration": 5.84
    },
    {
      "lang": "en",
      "text": "vocabulary If you choose chars then the",
      "offset": 12277.08,
      "duration": 6.04
    },
    {
      "lang": "en",
      "text": "size of the vocabulary will be much",
      "offset": 12280.96,
      "duration": 5.359
    },
    {
      "lang": "en",
      "text": "smaller because we have 26 letters on",
      "offset": 12283.12,
      "duration": 8.48
    },
    {
      "lang": "en",
      "text": "the alphabet plus some other punctuation",
      "offset": 12286.319,
      "duration": 8.761
    },
    {
      "lang": "en",
      "text": "Then you need to prepare the data for",
      "offset": 12291.6,
      "duration": 7.44
    },
    {
      "lang": "en",
      "text": "training That means to create vectors of",
      "offset": 12295.08,
      "duration": 6.08
    },
    {
      "lang": "en",
      "text": "past tokens and next",
      "offset": 12299.04,
      "duration": 5.279
    },
    {
      "lang": "en",
      "text": "token The next step is to design the",
      "offset": 12301.16,
      "duration": 6.44
    },
    {
      "lang": "en",
      "text": "architecture of the model choosing to",
      "offset": 12304.319,
      "duration": 6.881
    },
    {
      "lang": "en",
      "text": "use an embedding layer how many RNN",
      "offset": 12307.6,
      "duration": 8.32
    },
    {
      "lang": "en",
      "text": "layers and so on Finally frame the model",
      "offset": 12311.2,
      "duration": 9.44
    },
    {
      "lang": "en",
      "text": "see the outcome and make adjustments",
      "offset": 12315.92,
      "duration": 7.68
    },
    {
      "lang": "en",
      "text": "Neuromachine translation is the process",
      "offset": 12320.64,
      "duration": 5.679
    },
    {
      "lang": "en",
      "text": "to automatically translate one language",
      "offset": 12323.6,
      "duration": 6.56
    },
    {
      "lang": "en",
      "text": "to another It is used for example on",
      "offset": 12326.319,
      "duration": 5.481
    },
    {
      "lang": "en",
      "text": "Google",
      "offset": 12330.16,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "translator The model above was trained",
      "offset": 12331.8,
      "duration": 6.12
    },
    {
      "lang": "en",
      "text": "to translate small phrases such as this",
      "offset": 12334.64,
      "duration": 6.639
    },
    {
      "lang": "en",
      "text": "example with three words But it becomes",
      "offset": 12337.92,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "much more complex to train models that",
      "offset": 12341.279,
      "duration": 5.521
    },
    {
      "lang": "en",
      "text": "can translate a whole paragraph or an",
      "offset": 12343.6,
      "duration": 6.12
    },
    {
      "lang": "en",
      "text": "entire page or even a full",
      "offset": 12346.8,
      "duration": 6.24
    },
    {
      "lang": "en",
      "text": "document Since the text would be bigger",
      "offset": 12349.72,
      "duration": 6.92
    },
    {
      "lang": "en",
      "text": "we would need more units on the RNN cell",
      "offset": 12353.04,
      "duration": 6.84
    },
    {
      "lang": "en",
      "text": "meaning more memory cells to keep longer",
      "offset": 12356.64,
      "duration": 6.32
    },
    {
      "lang": "en",
      "text": "dependencies Thus it will be a much",
      "offset": 12359.88,
      "duration": 7.12
    },
    {
      "lang": "en",
      "text": "bigger model need more data and time to",
      "offset": 12362.96,
      "duration": 8.16
    },
    {
      "lang": "en",
      "text": "train The N&amp;T model is similar to the",
      "offset": 12367,
      "duration": 7.319
    },
    {
      "lang": "en",
      "text": "text generation model but it has to deal",
      "offset": 12371.12,
      "duration": 5.96
    },
    {
      "lang": "en",
      "text": "with two languages at the same",
      "offset": 12374.319,
      "duration": 6.241
    },
    {
      "lang": "en",
      "text": "time To acquire training data we can",
      "offset": 12377.08,
      "duration": 6.12
    },
    {
      "lang": "en",
      "text": "search for open-source projects such as",
      "offset": 12380.56,
      "duration": 3.879
    },
    {
      "lang": "en",
      "text": "the",
      "offset": 12383.2,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "Anki In the data preparation phase we",
      "offset": 12384.439,
      "duration": 6.84
    },
    {
      "lang": "en",
      "text": "need to tokenize the two languages It is",
      "offset": 12388,
      "duration": 6.239
    },
    {
      "lang": "en",
      "text": "also possible to use characters or words",
      "offset": 12391.279,
      "duration": 7
    },
    {
      "lang": "en",
      "text": "as tokens but words are used more",
      "offset": 12394.239,
      "duration": 7.281
    },
    {
      "lang": "en",
      "text": "often Then we have to design the model",
      "offset": 12398.279,
      "duration": 7.08
    },
    {
      "lang": "en",
      "text": "to be used and is separated in two parts",
      "offset": 12401.52,
      "duration": 6.52
    },
    {
      "lang": "en",
      "text": "The encoder and the",
      "offset": 12405.359,
      "duration": 5.601
    },
    {
      "lang": "en",
      "text": "decoder More details will be given",
      "offset": 12408.04,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "further in this",
      "offset": 12410.96,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "course Again as in all machine learning",
      "offset": 12412.84,
      "duration": 6.2
    },
    {
      "lang": "en",
      "text": "projects you need to experiment and",
      "offset": 12416.56,
      "duration": 4.879
    },
    {
      "lang": "en",
      "text": "evaluate the results then make",
      "offset": 12419.04,
      "duration": 4.76
    },
    {
      "lang": "en",
      "text": "adjustments as",
      "offset": 12421.439,
      "duration": 5.521
    },
    {
      "lang": "en",
      "text": "needed In this chapter you will learn in",
      "offset": 12423.8,
      "duration": 5.639
    },
    {
      "lang": "en",
      "text": "more details about text generation and",
      "offset": 12426.96,
      "duration": 5.84
    },
    {
      "lang": "en",
      "text": "neuromachine translation models First",
      "offset": 12429.439,
      "duration": 6.081
    },
    {
      "lang": "en",
      "text": "you will learn how to use a pre-trained",
      "offset": 12432.8,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "text generation model to generate",
      "offset": 12435.52,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "sentences",
      "offset": 12437.84,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "Then you will learn how to prepare the",
      "offset": 12439.359,
      "duration": 5.641
    },
    {
      "lang": "en",
      "text": "data and build the car model for this",
      "offset": 12441.84,
      "duration": 6.96
    },
    {
      "lang": "en",
      "text": "task Finally you will do both steps for",
      "offset": 12445,
      "duration": 6.439
    },
    {
      "lang": "en",
      "text": "neuromachine translation Prepare the",
      "offset": 12448.8,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "data build the model and use it to",
      "offset": 12451.439,
      "duration": 5.88
    },
    {
      "lang": "en",
      "text": "translate Portuguese to",
      "offset": 12453.92,
      "duration": 6.479
    },
    {
      "lang": "en",
      "text": "English In this lesson we are going to",
      "offset": 12457.319,
      "duration": 5.721
    },
    {
      "lang": "en",
      "text": "focus on how to generate phrases or",
      "offset": 12460.399,
      "duration": 6.401
    },
    {
      "lang": "en",
      "text": "custom text given a training model In",
      "offset": 12463.04,
      "duration": 6.16
    },
    {
      "lang": "en",
      "text": "some applications we want to generate",
      "offset": 12466.8,
      "duration": 6.08
    },
    {
      "lang": "en",
      "text": "only one sentence while in others we may",
      "offset": 12469.2,
      "duration": 6.96
    },
    {
      "lang": "en",
      "text": "be interested in a whole paragraph an",
      "offset": 12472.88,
      "duration": 4.68
    },
    {
      "lang": "en",
      "text": "entire book",
      "offset": 12476.16,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "even So let's see how to create rules",
      "offset": 12477.56,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "for the generated",
      "offset": 12480.88,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "text To generate sentences we need first",
      "offset": 12483,
      "duration": 6.52
    },
    {
      "lang": "en",
      "text": "to define what is a sentence so that we",
      "offset": 12486.64,
      "duration": 6.24
    },
    {
      "lang": "en",
      "text": "can create rules to generate them",
      "offset": 12489.52,
      "duration": 6.08
    },
    {
      "lang": "en",
      "text": "One definition is to use punctuation to",
      "offset": 12492.88,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "determine when the sentence ends For",
      "offset": 12495.6,
      "duration": 6.56
    },
    {
      "lang": "en",
      "text": "example we can use period exclamation or",
      "offset": 12498.64,
      "duration": 4.52
    },
    {
      "lang": "en",
      "text": "question",
      "offset": 12502.16,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "marks If we use this approach we must",
      "offset": 12503.16,
      "duration": 6.04
    },
    {
      "lang": "en",
      "text": "make sure that those punctuations are",
      "offset": 12506.64,
      "duration": 4.679
    },
    {
      "lang": "en",
      "text": "present in the",
      "offset": 12509.2,
      "duration": 5.199
    },
    {
      "lang": "en",
      "text": "vocabulary Another definition is to use",
      "offset": 12511.319,
      "duration": 5.721
    },
    {
      "lang": "en",
      "text": "special tokens for the beginning and end",
      "offset": 12514.399,
      "duration": 4.801
    },
    {
      "lang": "en",
      "text": "of a sentence",
      "offset": 12517.04,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "For example use token send to start the",
      "offset": 12519.2,
      "duration": 7.72
    },
    {
      "lang": "en",
      "text": "sentence and slash send to represent its",
      "offset": 12523.04,
      "duration": 6.88
    },
    {
      "lang": "en",
      "text": "send This approach needs the training",
      "offset": 12526.92,
      "duration": 5.88
    },
    {
      "lang": "en",
      "text": "data to be pre-processed to insert these",
      "offset": 12529.92,
      "duration": 6.68
    },
    {
      "lang": "en",
      "text": "tokens on all sentences before",
      "offset": 12532.8,
      "duration": 6.8
    },
    {
      "lang": "en",
      "text": "training To generate a sentence using",
      "offset": 12536.6,
      "duration": 5.799
    },
    {
      "lang": "en",
      "text": "period to define its send we first",
      "offset": 12539.6,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "initialize an empty string that will",
      "offset": 12542.399,
      "duration": 4.721
    },
    {
      "lang": "en",
      "text": "contain the sentence",
      "offset": 12544.72,
      "duration": 6.92
    },
    {
      "lang": "en",
      "text": "Then we loop until the model predicts a",
      "offset": 12547.12,
      "duration": 7.52
    },
    {
      "lang": "en",
      "text": "period We get the next prediction of the",
      "offset": 12551.64,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "model using the method",
      "offset": 12554.64,
      "duration": 5.92
    },
    {
      "lang": "en",
      "text": "predict The predict method returns an",
      "offset": 12557.64,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "array with one element containing the",
      "offset": 12560.56,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "predictions We use the first position",
      "offset": 12562.92,
      "duration": 4.92
    },
    {
      "lang": "en",
      "text": "only because we will generate one",
      "offset": 12565.52,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "character per step and use it to predict",
      "offset": 12567.84,
      "duration": 4.2
    },
    {
      "lang": "en",
      "text": "the next",
      "offset": 12570.88,
      "duration": 4.559
    },
    {
      "lang": "en",
      "text": "one Since the model returns a vector",
      "offset": 12572.04,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "with the size of the",
      "offset": 12575.439,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "vocabulary where each element has a",
      "offset": 12577,
      "duration": 5.16
    },
    {
      "lang": "en",
      "text": "probability of the next character to be",
      "offset": 12579.76,
      "duration": 6.76
    },
    {
      "lang": "en",
      "text": "that element We get the one with higher",
      "offset": 12582.16,
      "duration": 7.36
    },
    {
      "lang": "en",
      "text": "value Then we use the dictionary to",
      "offset": 12586.52,
      "duration": 6.32
    },
    {
      "lang": "en",
      "text": "transform the index to the corresponding",
      "offset": 12589.52,
      "duration": 6.4
    },
    {
      "lang": "en",
      "text": "character Finally we concatenate the",
      "offset": 12592.84,
      "duration": 6.519
    },
    {
      "lang": "en",
      "text": "next character on the sentence",
      "offset": 12595.92,
      "duration": 5.92
    },
    {
      "lang": "en",
      "text": "After this we need to update the",
      "offset": 12599.359,
      "duration": 5.281
    },
    {
      "lang": "en",
      "text": "variable X so that the next prediction",
      "offset": 12601.84,
      "duration": 4.84
    },
    {
      "lang": "en",
      "text": "will not be the",
      "offset": 12604.64,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "same To generate paragraphs or other",
      "offset": 12606.68,
      "duration": 6.36
    },
    {
      "lang": "en",
      "text": "kind of text blocks you can just change",
      "offset": 12609.92,
      "duration": 6.12
    },
    {
      "lang": "en",
      "text": "the conditions of the while",
      "offset": 12613.04,
      "duration": 6.239
    },
    {
      "lang": "en",
      "text": "loop One way to change the probability",
      "offset": 12616.04,
      "duration": 6.359
    },
    {
      "lang": "en",
      "text": "distribution over the vocabulary size is",
      "offset": 12619.279,
      "duration": 6.96
    },
    {
      "lang": "en",
      "text": "to use the scaling factor temperature",
      "offset": 12622.399,
      "duration": 6.721
    },
    {
      "lang": "en",
      "text": "This name comes from physics but all it",
      "offset": 12626.239,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "does is to make the distribution",
      "offset": 12629.12,
      "duration": 4.119
    },
    {
      "lang": "en",
      "text": "smoother or",
      "offset": 12631.439,
      "duration": 5.121
    },
    {
      "lang": "en",
      "text": "not It has positive values and the",
      "offset": 12633.239,
      "duration": 5.961
    },
    {
      "lang": "en",
      "text": "closer to zero it gets the model will",
      "offset": 12636.56,
      "duration": 5.64
    },
    {
      "lang": "en",
      "text": "emphasize the class with highest",
      "offset": 12639.2,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "probability This implies that the",
      "offset": 12642.2,
      "duration": 4.279
    },
    {
      "lang": "en",
      "text": "temperature will increase the",
      "offset": 12644.8,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "probability of the class with higher",
      "offset": 12646.479,
      "duration": 6.161
    },
    {
      "lang": "en",
      "text": "probability and decrease the others",
      "offset": 12648.8,
      "duration": 6.32
    },
    {
      "lang": "en",
      "text": "When the temperature is equal to one",
      "offset": 12652.64,
      "duration": 6.44
    },
    {
      "lang": "en",
      "text": "then there is no scaling on the soft max",
      "offset": 12655.12,
      "duration": 6.4
    },
    {
      "lang": "en",
      "text": "function For higher values of",
      "offset": 12659.08,
      "duration": 5
    },
    {
      "lang": "en",
      "text": "temperature the model is start to use",
      "offset": 12661.52,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "different words because it makes the",
      "offset": 12664.08,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "probability distribution is smoother",
      "offset": 12666.56,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "This means that the higher the value of",
      "offset": 12669.6,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "temperature the more equal the",
      "offset": 12671.76,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "probabilities become This leads to more",
      "offset": 12674.08,
      "duration": 6.159
    },
    {
      "lang": "en",
      "text": "creative outputs using words other than",
      "offset": 12677.2,
      "duration": 7.079
    },
    {
      "lang": "en",
      "text": "the expected one but also leads to more",
      "offset": 12680.239,
      "duration": 7
    },
    {
      "lang": "en",
      "text": "mistakes The temperature is a",
      "offset": 12684.279,
      "duration": 5.481
    },
    {
      "lang": "en",
      "text": "hyperparameter meaning that you can try",
      "offset": 12687.239,
      "duration": 4.921
    },
    {
      "lang": "en",
      "text": "different values to see how it changes",
      "offset": 12689.76,
      "duration": 4.719
    },
    {
      "lang": "en",
      "text": "the predictions or leave it with the",
      "offset": 12692.16,
      "duration": 4.76
    },
    {
      "lang": "en",
      "text": "default value of",
      "offset": 12694.479,
      "duration": 6.041
    },
    {
      "lang": "en",
      "text": "one The scaling function is relatively",
      "offset": 12696.92,
      "duration": 7.16
    },
    {
      "lang": "en",
      "text": "simple It has two parameters soft max",
      "offset": 12700.52,
      "duration": 5.799
    },
    {
      "lang": "en",
      "text": "spread that contains the probability",
      "offset": 12704.08,
      "duration": 5.279
    },
    {
      "lang": "en",
      "text": "values returned by the softmax function",
      "offset": 12706.319,
      "duration": 5.441
    },
    {
      "lang": "en",
      "text": "on the last layer of the model and",
      "offset": 12709.359,
      "duration": 5.401
    },
    {
      "lang": "en",
      "text": "temperature value defaulted to",
      "offset": 12711.76,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "one It takes the logarithm of the",
      "offset": 12714.76,
      "duration": 5.8
    },
    {
      "lang": "en",
      "text": "softmax output and divide each element",
      "offset": 12717.52,
      "duration": 6.56
    },
    {
      "lang": "en",
      "text": "in the vector by the temperature value",
      "offset": 12720.56,
      "duration": 6.08
    },
    {
      "lang": "en",
      "text": "Then it reapplies the exponential",
      "offset": 12724.08,
      "duration": 4.279
    },
    {
      "lang": "en",
      "text": "function",
      "offset": 12726.64,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "Next divide the obtained values by the",
      "offset": 12728.359,
      "duration": 5.641
    },
    {
      "lang": "en",
      "text": "sum of them to obtain the scale",
      "offset": 12731.52,
      "duration": 5.24
    },
    {
      "lang": "en",
      "text": "distribution with sum equal to",
      "offset": 12734,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "one The next step is to run one",
      "offset": 12736.76,
      "duration": 5.519
    },
    {
      "lang": "en",
      "text": "simulation of a multinnomial",
      "offset": 12740,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "distribution using as probability of",
      "offset": 12742.279,
      "duration": 5.401
    },
    {
      "lang": "en",
      "text": "each class the values obtained in the",
      "offset": 12745.12,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "previous step",
      "offset": 12747.68,
      "duration": 4.719
    },
    {
      "lang": "en",
      "text": "Finally we return the class that was",
      "offset": 12749.84,
      "duration": 5
    },
    {
      "lang": "en",
      "text": "obtained on the simulation of the",
      "offset": 12752.399,
      "duration": 5.121
    },
    {
      "lang": "en",
      "text": "multinnomial not necessarily the one",
      "offset": 12754.84,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "with higher",
      "offset": 12757.52,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "probability You saw how cool it can be",
      "offset": 12759.88,
      "duration": 6.84
    },
    {
      "lang": "en",
      "text": "to generate text using RNN models but",
      "offset": 12763.04,
      "duration": 6.319
    },
    {
      "lang": "en",
      "text": "you haven't actually seen the models",
      "offset": 12766.72,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "Let's fix that",
      "offset": 12769.359,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "The text generation models can be seen",
      "offset": 12771.84,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "as a multiclass classification model",
      "offset": 12774.239,
      "duration": 4.881
    },
    {
      "lang": "en",
      "text": "where the classes are each of the tokens",
      "offset": 12776.64,
      "duration": 3.799
    },
    {
      "lang": "en",
      "text": "in the",
      "offset": 12779.12,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "vocabulary As in the classification",
      "offset": 12780.439,
      "duration": 5.721
    },
    {
      "lang": "en",
      "text": "model it uses a soft max activation",
      "offset": 12783.2,
      "duration": 6.079
    },
    {
      "lang": "en",
      "text": "function on the last layer and uses",
      "offset": 12786.16,
      "duration": 6.76
    },
    {
      "lang": "en",
      "text": "categorical cross entropy for the loss",
      "offset": 12789.279,
      "duration": 7.441
    },
    {
      "lang": "en",
      "text": "function As an example model we create a",
      "offset": 12792.92,
      "duration": 8.12
    },
    {
      "lang": "en",
      "text": "sequential model with two LSTM layers We",
      "offset": 12796.72,
      "duration": 7.92
    },
    {
      "lang": "en",
      "text": "initialize the model class Then add the",
      "offset": 12801.04,
      "duration": 6.48
    },
    {
      "lang": "en",
      "text": "first LSTM layer defining the input",
      "offset": 12804.64,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "shape with shape of characters window",
      "offset": 12807.52,
      "duration": 6.799
    },
    {
      "lang": "en",
      "text": "and vocabulary size We also add dropout",
      "offset": 12810.08,
      "duration": 8.44
    },
    {
      "lang": "en",
      "text": "values to avoid overfitting and return",
      "offset": 12814.319,
      "duration": 8
    },
    {
      "lang": "en",
      "text": "sequences Next we add the second LSTM",
      "offset": 12818.52,
      "duration": 6.44
    },
    {
      "lang": "en",
      "text": "layer adding the dropout values and not",
      "offset": 12822.319,
      "duration": 5.281
    },
    {
      "lang": "en",
      "text": "returning sequences",
      "offset": 12824.96,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "Then add the output layer with soft max",
      "offset": 12827.6,
      "duration": 4.679
    },
    {
      "lang": "en",
      "text": "activation",
      "offset": 12830.56,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "function Finally compile the model with",
      "offset": 12832.279,
      "duration": 6.401
    },
    {
      "lang": "en",
      "text": "categorical cross entropy loss",
      "offset": 12835.52,
      "duration": 6.08
    },
    {
      "lang": "en",
      "text": "function The model architecture is the",
      "offset": 12838.68,
      "duration": 5.639
    },
    {
      "lang": "en",
      "text": "same as in classification model but the",
      "offset": 12841.6,
      "duration": 6.08
    },
    {
      "lang": "en",
      "text": "way we use the model is different",
      "offset": 12844.319,
      "duration": 5.601
    },
    {
      "lang": "en",
      "text": "During training and testing we don't",
      "offset": 12847.68,
      "duration": 4.679
    },
    {
      "lang": "en",
      "text": "compute performance metrics such as",
      "offset": 12849.92,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "accuracy because we are not interested",
      "offset": 12852.359,
      "duration": 5.441
    },
    {
      "lang": "en",
      "text": "in predicting exactly one specific",
      "offset": 12855.04,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "sentence but instead we want the model",
      "offset": 12857.8,
      "duration": 5.639
    },
    {
      "lang": "en",
      "text": "to be flexible and be able to generate",
      "offset": 12860.8,
      "duration": 4.76
    },
    {
      "lang": "en",
      "text": "sentences that make",
      "offset": 12863.439,
      "duration": 5.521
    },
    {
      "lang": "en",
      "text": "sense To measure the performance humans",
      "offset": 12865.56,
      "duration": 5.799
    },
    {
      "lang": "en",
      "text": "need to read the generated text and",
      "offset": 12868.96,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "determine if they are good",
      "offset": 12871.359,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "If they are not good we can train the",
      "offset": 12874.72,
      "duration": 5.599
    },
    {
      "lang": "en",
      "text": "model for more epochs or add complexity",
      "offset": 12877.359,
      "duration": 5.361
    },
    {
      "lang": "en",
      "text": "to the model by increasing the number of",
      "offset": 12880.319,
      "duration": 5.641
    },
    {
      "lang": "en",
      "text": "memory cells adding more layers",
      "offset": 12882.72,
      "duration": 6.88
    },
    {
      "lang": "en",
      "text": "etc Also depending on the task you are",
      "offset": 12885.96,
      "duration": 6.359
    },
    {
      "lang": "en",
      "text": "working on it will be of interest to",
      "offset": 12889.6,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "generate one character or word or",
      "offset": 12892.319,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "sentence or paragraph",
      "offset": 12894.88,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "etc",
      "offset": 12897.359,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "So the output of the model is not the",
      "offset": 12898.56,
      "duration": 6.6
    },
    {
      "lang": "en",
      "text": "final result and needs to be further",
      "offset": 12901.359,
      "duration": 6.801
    },
    {
      "lang": "en",
      "text": "managed Apart from generating text from",
      "offset": 12905.16,
      "duration": 6.44
    },
    {
      "lang": "en",
      "text": "TV shows characters or poetry there are",
      "offset": 12908.16,
      "duration": 5.8
    },
    {
      "lang": "en",
      "text": "other applications for text",
      "offset": 12911.6,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "generation For example it can create",
      "offset": 12913.96,
      "duration": 6.6
    },
    {
      "lang": "en",
      "text": "names such as baby names or new stars",
      "offset": 12916.8,
      "duration": 6.4
    },
    {
      "lang": "en",
      "text": "Also it is possible to generate market",
      "offset": 12920.56,
      "duration": 8.24
    },
    {
      "lang": "en",
      "text": "text such as lat markdown or XML",
      "offset": 12923.2,
      "duration": 8.88
    },
    {
      "lang": "en",
      "text": "Finally it can create news articles or",
      "offset": 12928.8,
      "duration": 5.72
    },
    {
      "lang": "en",
      "text": "be used on chat",
      "offset": 12932.08,
      "duration": 5.279
    },
    {
      "lang": "en",
      "text": "bots To prepare the data for text",
      "offset": 12934.52,
      "duration": 5.48
    },
    {
      "lang": "en",
      "text": "generation tasks we need to transform",
      "offset": 12937.359,
      "duration": 5.801
    },
    {
      "lang": "en",
      "text": "text into sequence of indexes As",
      "offset": 12940,
      "duration": 6.64
    },
    {
      "lang": "en",
      "text": "usual we will use characters as tokens",
      "offset": 12943.16,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "for text",
      "offset": 12946.64,
      "duration": 4.719
    },
    {
      "lang": "en",
      "text": "generation Then we need to create the",
      "offset": 12948.2,
      "duration": 5.88
    },
    {
      "lang": "en",
      "text": "data for supervised learning Meaning",
      "offset": 12951.359,
      "duration": 5.601
    },
    {
      "lang": "en",
      "text": "that we keep a sequence of characters in",
      "offset": 12954.08,
      "duration": 6.279
    },
    {
      "lang": "en",
      "text": "X and the next character on",
      "offset": 12956.96,
      "duration": 7.519
    },
    {
      "lang": "en",
      "text": "Y We p the sequences in X to have the",
      "offset": 12960.359,
      "duration": 7.241
    },
    {
      "lang": "en",
      "text": "same length This means that we will use",
      "offset": 12964.479,
      "duration": 5.84
    },
    {
      "lang": "en",
      "text": "the length of characters to predict the",
      "offset": 12967.6,
      "duration": 6.799
    },
    {
      "lang": "en",
      "text": "next one The variable is called chars",
      "offset": 12970.319,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "window",
      "offset": 12974.399,
      "duration": 5.521
    },
    {
      "lang": "en",
      "text": "Wise dimension is the vocabulary size or",
      "offset": 12976.319,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "the total number of characters in the",
      "offset": 12979.92,
      "duration": 6.68
    },
    {
      "lang": "en",
      "text": "training data and have to be one hot",
      "offset": 12982.319,
      "duration": 6.96
    },
    {
      "lang": "en",
      "text": "encoded In the previous lessons you",
      "offset": 12986.6,
      "duration": 5.639
    },
    {
      "lang": "en",
      "text": "learned about text generation models Now",
      "offset": 12989.279,
      "duration": 5.441
    },
    {
      "lang": "en",
      "text": "you will explore how to create machine",
      "offset": 12992.239,
      "duration": 4.12
    },
    {
      "lang": "en",
      "text": "translation",
      "offset": 12994.72,
      "duration": 4.719
    },
    {
      "lang": "en",
      "text": "models As seen before neuromachine",
      "offset": 12996.359,
      "duration": 5.601
    },
    {
      "lang": "en",
      "text": "translation models are divided in two",
      "offset": 12999.439,
      "duration": 5.361
    },
    {
      "lang": "en",
      "text": "parts the encoder that creates a",
      "offset": 13001.96,
      "duration": 5.08
    },
    {
      "lang": "en",
      "text": "language model for the input language",
      "offset": 13004.8,
      "duration": 5.24
    },
    {
      "lang": "en",
      "text": "and the decoder for the output",
      "offset": 13007.04,
      "duration": 6.6
    },
    {
      "lang": "en",
      "text": "language Let's create an example",
      "offset": 13010.04,
      "duration": 6.52
    },
    {
      "lang": "en",
      "text": "encoder We use the sequential class for",
      "offset": 13013.64,
      "duration": 6.2
    },
    {
      "lang": "en",
      "text": "the model Then we add the embedding",
      "offset": 13016.56,
      "duration": 5.919
    },
    {
      "lang": "en",
      "text": "layer that will create word vectors for",
      "offset": 13019.84,
      "duration": 3.8
    },
    {
      "lang": "en",
      "text": "the input",
      "offset": 13022.479,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "language The parameter mask zero inserts",
      "offset": 13023.64,
      "duration": 7.24
    },
    {
      "lang": "en",
      "text": "a zero token for the vocabulary",
      "offset": 13027.439,
      "duration": 9
    },
    {
      "lang": "en",
      "text": "Next we add one LSTM layer with 128",
      "offset": 13030.88,
      "duration": 8.8
    },
    {
      "lang": "en",
      "text": "units The next step is to repeat the",
      "offset": 13036.439,
      "duration": 6.281
    },
    {
      "lang": "en",
      "text": "last state of the LSTM layer the number",
      "offset": 13039.68,
      "duration": 6.4
    },
    {
      "lang": "en",
      "text": "of output language length meaning that",
      "offset": 13042.72,
      "duration": 5.84
    },
    {
      "lang": "en",
      "text": "this will be used as input for the",
      "offset": 13046.08,
      "duration": 6.399
    },
    {
      "lang": "en",
      "text": "decoder part of the model Note that",
      "offset": 13048.56,
      "duration": 6.48
    },
    {
      "lang": "en",
      "text": "repeat vector is a caras layer not",
      "offset": 13052.479,
      "duration": 4.92
    },
    {
      "lang": "en",
      "text": "introduced",
      "offset": 13055.04,
      "duration": 5.279
    },
    {
      "lang": "en",
      "text": "before Continuing right after the",
      "offset": 13057.399,
      "duration": 6.92
    },
    {
      "lang": "en",
      "text": "encoder we add one LSTM layer that will",
      "offset": 13060.319,
      "duration": 5.401
    },
    {
      "lang": "en",
      "text": "return the",
      "offset": 13064.319,
      "duration": 4.881
    },
    {
      "lang": "en",
      "text": "sequences Then we use time distributed",
      "offset": 13065.72,
      "duration": 6.12
    },
    {
      "lang": "en",
      "text": "together with dense layer to add one",
      "offset": 13069.2,
      "duration": 5.96
    },
    {
      "lang": "en",
      "text": "dense to each unit of the previous",
      "offset": 13071.84,
      "duration": 6.08
    },
    {
      "lang": "en",
      "text": "layer This is useful when we are",
      "offset": 13075.16,
      "duration": 5.159
    },
    {
      "lang": "en",
      "text": "comparing the whole sentence instead of",
      "offset": 13077.92,
      "duration": 5.399
    },
    {
      "lang": "en",
      "text": "the final result like in",
      "offset": 13080.319,
      "duration": 5.841
    },
    {
      "lang": "en",
      "text": "classification Keeping return sequences",
      "offset": 13083.319,
      "duration": 5.721
    },
    {
      "lang": "en",
      "text": "equal to false The loss function is",
      "offset": 13086.16,
      "duration": 6.48
    },
    {
      "lang": "en",
      "text": "computed only in the last token while",
      "offset": 13089.04,
      "duration": 6.239
    },
    {
      "lang": "en",
      "text": "keeping return sequences equal to true",
      "offset": 13092.64,
      "duration": 5.679
    },
    {
      "lang": "en",
      "text": "and using time distributed layer The",
      "offset": 13095.279,
      "duration": 6.281
    },
    {
      "lang": "en",
      "text": "loss function is applied in every",
      "offset": 13098.319,
      "duration": 7.881
    },
    {
      "lang": "en",
      "text": "token This kas layer is also newly",
      "offset": 13101.56,
      "duration": 7.799
    },
    {
      "lang": "en",
      "text": "introduced When preparing the data as",
      "offset": 13106.2,
      "duration": 5.64
    },
    {
      "lang": "en",
      "text": "before we need to transform the text",
      "offset": 13109.359,
      "duration": 6.08
    },
    {
      "lang": "en",
      "text": "into sequence of numerical indexes We do",
      "offset": 13111.84,
      "duration": 6.32
    },
    {
      "lang": "en",
      "text": "that for both languages in the encoder",
      "offset": 13115.439,
      "duration": 4.761
    },
    {
      "lang": "en",
      "text": "and decoder part of the",
      "offset": 13118.16,
      "duration": 5.279
    },
    {
      "lang": "en",
      "text": "model The encoder will transform the",
      "offset": 13120.2,
      "duration": 5.56
    },
    {
      "lang": "en",
      "text": "input language into a sequence of",
      "offset": 13123.439,
      "duration": 6.081
    },
    {
      "lang": "en",
      "text": "numerical indexes The decoder apart from",
      "offset": 13125.76,
      "duration": 6.32
    },
    {
      "lang": "en",
      "text": "transforming the text into a sequence of",
      "offset": 13129.52,
      "duration": 6.08
    },
    {
      "lang": "en",
      "text": "numerical indexes It is also needed to",
      "offset": 13132.08,
      "duration": 6.56
    },
    {
      "lang": "en",
      "text": "one hot encode each index to treat them",
      "offset": 13135.6,
      "duration": 5.759
    },
    {
      "lang": "en",
      "text": "as one class among the total vocabulary",
      "offset": 13138.64,
      "duration": 6.4
    },
    {
      "lang": "en",
      "text": "size of the output language",
      "offset": 13141.359,
      "duration": 6.88
    },
    {
      "lang": "en",
      "text": "To prepare the input language we first",
      "offset": 13145.04,
      "duration": 5.84
    },
    {
      "lang": "en",
      "text": "import the required objects being the",
      "offset": 13148.239,
      "duration": 6.04
    },
    {
      "lang": "en",
      "text": "tokenizer class from",
      "offset": 13150.88,
      "duration": 6.16
    },
    {
      "lang": "en",
      "text": "kas.processing.ext module and the pad",
      "offset": 13154.279,
      "duration": 6.481
    },
    {
      "lang": "en",
      "text": "sequences function from kas dot",
      "offset": 13157.04,
      "duration": 6.56
    },
    {
      "lang": "en",
      "text": "preprocessing.sequence module",
      "offset": 13160.76,
      "duration": 5.479
    },
    {
      "lang": "en",
      "text": "Then we instantiate the tokenizer and",
      "offset": 13163.6,
      "duration": 6.48
    },
    {
      "lang": "en",
      "text": "fit the object on the input texts that",
      "offset": 13166.239,
      "duration": 6.561
    },
    {
      "lang": "en",
      "text": "are a list like object containing the",
      "offset": 13170.08,
      "duration": 5.239
    },
    {
      "lang": "en",
      "text": "sentences in the input",
      "offset": 13172.8,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "language Then we transform the input",
      "offset": 13175.319,
      "duration": 5.92
    },
    {
      "lang": "en",
      "text": "sentences into sequence of numerical",
      "offset": 13178.56,
      "duration": 5.919
    },
    {
      "lang": "en",
      "text": "indexes by using the method text to",
      "offset": 13181.239,
      "duration": 5.281
    },
    {
      "lang": "en",
      "text": "sequences of the",
      "offset": 13184.479,
      "duration": 5.601
    },
    {
      "lang": "en",
      "text": "tokenizer Finally we p the text by",
      "offset": 13186.52,
      "duration": 7.799
    },
    {
      "lang": "en",
      "text": "inserting zero tokens to the right",
      "offset": 13190.08,
      "duration": 6.72
    },
    {
      "lang": "en",
      "text": "The first step for the output language",
      "offset": 13194.319,
      "duration": 5.761
    },
    {
      "lang": "en",
      "text": "is the same as in the input language We",
      "offset": 13196.8,
      "duration": 5.84
    },
    {
      "lang": "en",
      "text": "use the tokenizer and fit it on the",
      "offset": 13200.08,
      "duration": 4.199
    },
    {
      "lang": "en",
      "text": "output",
      "offset": 13202.64,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "text Then we transform the output text",
      "offset": 13204.279,
      "duration": 5.561
    },
    {
      "lang": "en",
      "text": "and pat the sequences of numerical",
      "offset": 13207.6,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "indexes",
      "offset": 13209.84,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "After transforming text into sequences",
      "offset": 13211.76,
      "duration": 6.639
    },
    {
      "lang": "en",
      "text": "of numbers we still need to one hot",
      "offset": 13214.64,
      "duration": 6.599
    },
    {
      "lang": "en",
      "text": "encode each of the",
      "offset": 13218.399,
      "duration": 6.801
    },
    {
      "lang": "en",
      "text": "indexes We create a temporary list Then",
      "offset": 13221.239,
      "duration": 7.601
    },
    {
      "lang": "en",
      "text": "we loop over each sentence of numerical",
      "offset": 13225.2,
      "duration": 6.239
    },
    {
      "lang": "en",
      "text": "indexes We use the function to",
      "offset": 13228.84,
      "duration": 5.399
    },
    {
      "lang": "en",
      "text": "categorical to transform each index in",
      "offset": 13231.439,
      "duration": 6.96
    },
    {
      "lang": "en",
      "text": "the sentence to the one hot vector The",
      "offset": 13234.239,
      "duration": 6.801
    },
    {
      "lang": "en",
      "text": "output language vocabulary size is the",
      "offset": 13238.399,
      "duration": 4.201
    },
    {
      "lang": "en",
      "text": "number of",
      "offset": 13241.04,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "classes Then we append it to the",
      "offset": 13242.6,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "temporary",
      "offset": 13245.6,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "list After the loop is completed we",
      "offset": 13246.92,
      "duration": 5.399
    },
    {
      "lang": "en",
      "text": "transform this temporary list into a",
      "offset": 13250,
      "duration": 5.88
    },
    {
      "lang": "en",
      "text": "numpy array and reshape it to have three",
      "offset": 13252.319,
      "duration": 7.04
    },
    {
      "lang": "en",
      "text": "dimensions Number of sentences sentence",
      "offset": 13255.88,
      "duration": 6.599
    },
    {
      "lang": "en",
      "text": "length and output languages vocabulary",
      "offset": 13259.359,
      "duration": 4.801
    },
    {
      "lang": "en",
      "text": "size",
      "offset": 13262.479,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "To train the model we just need to call",
      "offset": 13264.16,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "the method fit and pass the training",
      "offset": 13266.88,
      "duration": 5.88
    },
    {
      "lang": "en",
      "text": "data contained on variables X and",
      "offset": 13269.52,
      "duration": 7.04
    },
    {
      "lang": "en",
      "text": "Y To evaluate a translation model we can",
      "offset": 13272.76,
      "duration": 7.08
    },
    {
      "lang": "en",
      "text": "use the bilingual evaluation under study",
      "offset": 13276.56,
      "duration": 7.28
    },
    {
      "lang": "en",
      "text": "or blue metric This method is not in the",
      "offset": 13279.84,
      "duration": 6.399
    },
    {
      "lang": "en",
      "text": "scope of this course and for details on",
      "offset": 13283.84,
      "duration": 6.399
    },
    {
      "lang": "en",
      "text": "it check the NLTK documentation on subm",
      "offset": 13286.239,
      "duration": 7.521
    },
    {
      "lang": "en",
      "text": "module NLTK",
      "offset": 13290.239,
      "duration": 5.721
    },
    {
      "lang": "en",
      "text": "Blue",
      "offset": 13293.76,
      "duration": 5.599
    },
    {
      "lang": "en",
      "text": "score Congratulations You came a long",
      "offset": 13295.96,
      "duration": 5.8
    },
    {
      "lang": "en",
      "text": "way to the universe of language models",
      "offset": 13299.359,
      "duration": 4.681
    },
    {
      "lang": "en",
      "text": "using Python and",
      "offset": 13301.76,
      "duration": 5.519
    },
    {
      "lang": "en",
      "text": "KAS In this course you learned four",
      "offset": 13304.04,
      "duration": 5.08
    },
    {
      "lang": "en",
      "text": "different applications of language",
      "offset": 13307.279,
      "duration": 5.16
    },
    {
      "lang": "en",
      "text": "models using KAS Sentiment",
      "offset": 13309.12,
      "duration": 6.4
    },
    {
      "lang": "en",
      "text": "classification multiclass classification",
      "offset": 13312.439,
      "duration": 5.8
    },
    {
      "lang": "en",
      "text": "text generation and neuromachine",
      "offset": 13315.52,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "translation",
      "offset": 13318.239,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "Also you learned the different types of",
      "offset": 13320,
      "duration": 5.92
    },
    {
      "lang": "en",
      "text": "sequencetose sequence models Finally you",
      "offset": 13322.56,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "learned the main modules and packages in",
      "offset": 13325.92,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "KAS that make it possible to implement",
      "offset": 13328.08,
      "duration": 3.72
    },
    {
      "lang": "en",
      "text": "the",
      "offset": 13330.56,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "models You also learned about some",
      "offset": 13331.8,
      "duration": 5.4
    },
    {
      "lang": "en",
      "text": "pitfalls that occurs when implementing",
      "offset": 13334.56,
      "duration": 6.24
    },
    {
      "lang": "en",
      "text": "RNN modules The vanishing and exploding",
      "offset": 13337.2,
      "duration": 4.6
    },
    {
      "lang": "en",
      "text": "gradient",
      "offset": 13340.8,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "problems To deal with those problems you",
      "offset": 13341.8,
      "duration": 8.04
    },
    {
      "lang": "en",
      "text": "can use the GRU or LSTM cells Also you",
      "offset": 13344.96,
      "duration": 7.359
    },
    {
      "lang": "en",
      "text": "learned how to implement the embedding",
      "offset": 13349.84,
      "duration": 6.439
    },
    {
      "lang": "en",
      "text": "layer to create and or use more word",
      "offset": 13352.319,
      "duration": 7.441
    },
    {
      "lang": "en",
      "text": "vectors Finally you applied a few tuning",
      "offset": 13356.279,
      "duration": 5.721
    },
    {
      "lang": "en",
      "text": "techniques to improve the performance of",
      "offset": 13359.76,
      "duration": 4.36
    },
    {
      "lang": "en",
      "text": "the sentiment analysis",
      "offset": 13362,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "model When learning how to perform",
      "offset": 13364.12,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "multiclass",
      "offset": 13366.8,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "classification you learn how to prepare",
      "offset": 13368.439,
      "duration": 5.481
    },
    {
      "lang": "en",
      "text": "the data how to use trained word vectors",
      "offset": 13370.72,
      "duration": 5.84
    },
    {
      "lang": "en",
      "text": "for transfer learning how to create the",
      "offset": 13373.92,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "models in KAS and how to access the",
      "offset": 13376.56,
      "duration": 4.04
    },
    {
      "lang": "en",
      "text": "model's",
      "offset": 13379.2,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "performance In text generation you use",
      "offset": 13380.6,
      "duration": 5.96
    },
    {
      "lang": "en",
      "text": "characters as tokens and learned the",
      "offset": 13383.92,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "necessary steps to transform the text",
      "offset": 13386.56,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "into sequence of characters and next",
      "offset": 13389.04,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "character arrays",
      "offset": 13391.6,
      "duration": 5.839
    },
    {
      "lang": "en",
      "text": "Also you created a function to generate",
      "offset": 13394.16,
      "duration": 6.4
    },
    {
      "lang": "en",
      "text": "sentences mimicking Sheldon from the Big",
      "offset": 13397.439,
      "duration": 4.521
    },
    {
      "lang": "en",
      "text": "Bang",
      "offset": 13400.56,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "Theory In neuromachine translation you",
      "offset": 13401.96,
      "duration": 6.439
    },
    {
      "lang": "en",
      "text": "used words as tokens learned how to",
      "offset": 13405.12,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "prepare the different languages text",
      "offset": 13408.399,
      "duration": 5.681
    },
    {
      "lang": "en",
      "text": "data as encoder and decoder",
      "offset": 13410.64,
      "duration": 6.96
    },
    {
      "lang": "en",
      "text": "Then you learned how to build a NMT",
      "offset": 13414.08,
      "duration": 6.64
    },
    {
      "lang": "en",
      "text": "model in KAS and use it to translate",
      "offset": 13417.6,
      "duration": 6.2
    },
    {
      "lang": "en",
      "text": "Portuguese small sentences into",
      "offset": 13420.72,
      "duration": 6.16
    },
    {
      "lang": "en",
      "text": "English Again congratulations for",
      "offset": 13423.8,
      "duration": 5.399
    },
    {
      "lang": "en",
      "text": "finishing this course I hope that you",
      "offset": 13426.88,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "can use what you learned to other",
      "offset": 13429.199,
      "duration": 5.801
    },
    {
      "lang": "en",
      "text": "similar problems of your",
      "offset": 13430.88,
      "duration": 4.12
    },
    {
      "lang": "en",
      "text": "[Music]",
      "offset": 13436.59,
      "duration": 16.989
    }
  ],
  "cleanText": null,
  "dumpedAt": "2025-07-21T18:43:25.732Z"
}