{
  "episodeId": "lyTdUNUkBFA",
  "channelSlug": "@datacamp",
  "title": "#307 Human Guardrails in Generative AI: Wendy Gonzalez & Duncan Curtis, CEO & SVP of Gen AI at Sama",
  "publishedAt": "2025-06-23T11:43:53.000Z",
  "rawLines": [
    {
      "lang": "en",
      "text": "Welcome to dataf framed. This is Richie.",
      "offset": 0.24,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "There are now many great AI models that",
      "offset": 2.56,
      "duration": 4.719
    },
    {
      "lang": "en",
      "text": "perform well off the shelf, but for some",
      "offset": 4.88,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "business or scientific use cases,",
      "offset": 7.279,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "performance is still lacking. Behind",
      "offset": 9.28,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "every great model is a great data set.",
      "offset": 11.519,
      "duration": 4.481
    },
    {
      "lang": "en",
      "text": "And if you want your computer vision",
      "offset": 13.84,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "model to reliably detect your product or",
      "offset": 16,
      "duration": 5.359
    },
    {
      "lang": "en",
      "text": "you want your call center AI to reliably",
      "offset": 18.72,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "answer support questions that your",
      "offset": 21.359,
      "duration": 3.041
    },
    {
      "lang": "en",
      "text": "customers care about, then you're going",
      "offset": 23.119,
      "duration": 3.441
    },
    {
      "lang": "en",
      "text": "to have to provide your AI with your",
      "offset": 24.4,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "business data. Today we're looking at",
      "offset": 26.56,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "the process of collecting and enriching",
      "offset": 28.16,
      "duration": 4.239
    },
    {
      "lang": "en",
      "text": "your data, then feeding it to your AI",
      "offset": 30.08,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "for better performance. I also want to",
      "offset": 32.399,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "know about the data annotation workers",
      "offset": 34.32,
      "duration": 4.239
    },
    {
      "lang": "en",
      "text": "who are the hidden stars of the AI",
      "offset": 36.399,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "revolution. I have two guests for you",
      "offset": 38.559,
      "duration": 3.761
    },
    {
      "lang": "en",
      "text": "from the data annotation and model",
      "offset": 40.48,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "evaluation company. SAM Wendy Gonzalez",
      "offset": 42.32,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "is steering the ship as CEO, having",
      "offset": 45.2,
      "duration": 5.039
    },
    {
      "lang": "en",
      "text": "moved into the role from COO. She joined",
      "offset": 47.92,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "SAMA from a background as a product lead",
      "offset": 50.239,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "at an IoT startup and she's also spent",
      "offset": 52.16,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "uh time as a management consultant with",
      "offset": 54.879,
      "duration": 5.761
    },
    {
      "lang": "en",
      "text": "stints at EY and Capgeemini. In 2023,",
      "offset": 56.96,
      "duration": 6.399
    },
    {
      "lang": "en",
      "text": "Wendy made women tech networks 100",
      "offset": 60.64,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "executive women in tech to watch list.",
      "offset": 63.359,
      "duration": 4.481
    },
    {
      "lang": "en",
      "text": "Duncan Curtis is senior VP of product",
      "offset": 65.36,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "and technology. He's got 15 years",
      "offset": 67.84,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "experience as a product manager, having",
      "offset": 69.76,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "previously run Google Play games and",
      "offset": 71.68,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "also products at Zuks and Aptive. Let's",
      "offset": 74,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "find out how to make great data sets for",
      "offset": 77.28,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "your AI. Large language models are",
      "offset": 79.36,
      "duration": 5.119
    },
    {
      "lang": "en",
      "text": "really good at getting generic answers",
      "offset": 81.68,
      "duration": 4.479
    },
    {
      "lang": "en",
      "text": "right. However, when it comes down to",
      "offset": 84.479,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "actually doing what we do in our",
      "offset": 86.159,
      "duration": 3.441
    },
    {
      "lang": "en",
      "text": "day-to-day businesses, often requires",
      "offset": 87.759,
      "duration": 3.521
    },
    {
      "lang": "en",
      "text": "much more specialized knowledge. So,",
      "offset": 89.6,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "we've moved almost 70,000 people out of",
      "offset": 91.28,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "poverty since we have started um this",
      "offset": 93.2,
      "duration": 4.559
    },
    {
      "lang": "en",
      "text": "this company. What we do is we have an",
      "offset": 95.439,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "impact hiring model where we hire on the",
      "offset": 97.759,
      "duration": 4.801
    },
    {
      "lang": "en",
      "text": "basis of impact.",
      "offset": 100.159,
      "duration": 4.241
    },
    {
      "lang": "en",
      "text": "Hi there Wendy and Duncan. Welcome to",
      "offset": 102.56,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "the show. Thank you. Glad to be here.",
      "offset": 104.4,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "Brilliant. So there are a lot of really",
      "offset": 106.32,
      "duration": 5.119
    },
    {
      "lang": "en",
      "text": "great foundation large language models.",
      "offset": 108.32,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "So why do you need to use your own data",
      "offset": 111.439,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "rather than just an off-the-shelf model?",
      "offset": 113.6,
      "duration": 4.879
    },
    {
      "lang": "en",
      "text": "Large language models are really good at",
      "offset": 116.079,
      "duration": 4.801
    },
    {
      "lang": "en",
      "text": "getting generic answers right. And so",
      "offset": 118.479,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "they've been trained on a very large",
      "offset": 120.88,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "corpus of data across the internet or a",
      "offset": 122.399,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "large portion of it. However, when it",
      "offset": 124.88,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "comes down to actually doing what we do",
      "offset": 126.399,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "in our day-to-day businesses, it often",
      "offset": 128.72,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "requires much more specialized",
      "offset": 130.959,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "knowledge. And so what we find is that",
      "offset": 132.48,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "while models are really great for things",
      "offset": 135.28,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "like writing an email that's a generic",
      "offset": 136.879,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "email, it might actually really struggle",
      "offset": 139.04,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "if you wanted to do something within a",
      "offset": 140.879,
      "duration": 5.121
    },
    {
      "lang": "en",
      "text": "specific domain like referencing law or",
      "offset": 142.56,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "referencing, you know, HR policies or",
      "offset": 146,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "even better, what about referencing your",
      "offset": 148.08,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "own internal documents. So if you wanted",
      "offset": 149.84,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "to write an email out to your employees,",
      "offset": 152,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "but oh wait, I need to make sure that it",
      "offset": 154.08,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "actually, you know, follows our",
      "offset": 155.92,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "policies. That's not going to be as easy",
      "offset": 157.12,
      "duration": 4.479
    },
    {
      "lang": "en",
      "text": "to do with a generic model. We do have",
      "offset": 159.28,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "we do see people um doing something",
      "offset": 161.599,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "that's called distillation of models. So",
      "offset": 163.599,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "often when you see large language models",
      "offset": 165.519,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "come out you hear like oh you know Chad",
      "offset": 167.519,
      "duration": 5.281
    },
    {
      "lang": "en",
      "text": "GBT4.1 has just landed on Monday. But",
      "offset": 169.36,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "they also release smaller versions. And",
      "offset": 172.8,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "the reason they release smaller versions",
      "offset": 174.8,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "is they take that big model and they",
      "offset": 176.56,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "eliminate certain parts of it to try to",
      "offset": 178.959,
      "duration": 4.801
    },
    {
      "lang": "en",
      "text": "keep to get that model smaller but to",
      "offset": 181.68,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "try to retain as much of that bigger",
      "offset": 183.76,
      "duration": 3.199
    },
    {
      "lang": "en",
      "text": "information. And the reason you want it",
      "offset": 185.44,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "smaller is because you want it to be",
      "offset": 186.959,
      "duration": 3.521
    },
    {
      "lang": "en",
      "text": "faster. So, when you're actually more",
      "offset": 188.72,
      "duration": 3.599
    },
    {
      "lang": "en",
      "text": "real-time chat, but you also want it to",
      "offset": 190.48,
      "duration": 3.679
    },
    {
      "lang": "en",
      "text": "be cheaper to run and be able to run",
      "offset": 192.319,
      "duration": 4.801
    },
    {
      "lang": "en",
      "text": "more uh on on cheaper hardware. So,",
      "offset": 194.159,
      "duration": 5.121
    },
    {
      "lang": "en",
      "text": "that's uh hope that answers your",
      "offset": 197.12,
      "duration": 3.759
    },
    {
      "lang": "en",
      "text": "question. Okay. So, that makes a lot of",
      "offset": 199.28,
      "duration": 2.64
    },
    {
      "lang": "en",
      "text": "sense. If you're doing something that's",
      "offset": 200.879,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "a little bit out of the ordinary, not a",
      "offset": 201.92,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "generic question in some sense, then",
      "offset": 204.159,
      "duration": 3.521
    },
    {
      "lang": "en",
      "text": "that's when you're going to want to use",
      "offset": 206.48,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "your own data or get some domain",
      "offset": 207.68,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "specific data. Maybe we can dig into",
      "offset": 210,
      "duration": 3.599
    },
    {
      "lang": "en",
      "text": "some of these ways making your models",
      "offset": 212.08,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "faster and cheaper because both those",
      "offset": 213.599,
      "duration": 4.881
    },
    {
      "lang": "en",
      "text": "things are quite useful as well. Uh so,",
      "offset": 215.84,
      "duration": 4.479
    },
    {
      "lang": "en",
      "text": "yeah. Uh we'll get into that uh later",
      "offset": 218.48,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "perhaps. Um all right so I would love",
      "offset": 220.319,
      "duration": 4.801
    },
    {
      "lang": "en",
      "text": "some concrete examples. Uh do you have",
      "offset": 223.04,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "any real examples of where a company's",
      "offset": 225.12,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "trained or they've made you made use of",
      "offset": 227.36,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "data enrichment to improve their own",
      "offset": 229.68,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "model and make things better? Yeah,",
      "offset": 231.36,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "absolutely. So a great example would be",
      "offset": 233.599,
      "duration": 3.521
    },
    {
      "lang": "en",
      "text": "uh we were working with a company in the",
      "offset": 235.519,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "uh HR space and so one of the things",
      "offset": 237.12,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "they wanted to do was train a model to",
      "offset": 239.12,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "be able to understand what was in job",
      "offset": 241.36,
      "duration": 6.079
    },
    {
      "lang": "en",
      "text": "applicants uh resumes. So they had some",
      "offset": 243.84,
      "duration": 5.039
    },
    {
      "lang": "en",
      "text": "matching that they wanted to do where",
      "offset": 247.439,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "they had let's call it I think it was",
      "offset": 248.879,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "somewhere in the like 180 sort of skills",
      "offset": 251.12,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "that they wanted to tie to people's",
      "offset": 253.439,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "resumes but in those regimes you call",
      "offset": 255.04,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "different skills a lot of things. So",
      "offset": 258.239,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "let's say ex let's say uh executive",
      "offset": 259.84,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "presentations might be the the tag that",
      "offset": 262.56,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "they wanted to use but that in might",
      "offset": 264.8,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "appear in someone's resume as anything",
      "offset": 266.8,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "from presented to the board uh regularly",
      "offset": 268.72,
      "duration": 5.199
    },
    {
      "lang": "en",
      "text": "present to you know my executive team it",
      "offset": 271.199,
      "duration": 5.041
    },
    {
      "lang": "en",
      "text": "might be speaks at conferences and so",
      "offset": 273.919,
      "duration": 4.801
    },
    {
      "lang": "en",
      "text": "what we would do in that case is enrich",
      "offset": 276.24,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "a set of rums with getting those",
      "offset": 278.72,
      "duration": 5.84
    },
    {
      "lang": "en",
      "text": "different uh examples within rums and",
      "offset": 282,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "and aligning them with that taxonomy",
      "offset": 284.56,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "that that list that they had and then",
      "offset": 286.56,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "they can use that to uh train an AI or",
      "offset": 288.4,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "to uh to basically find new instances of",
      "offset": 290.96,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "that moving forward. Ah okay. Uh so this",
      "offset": 294,
      "duration": 4.639
    },
    {
      "lang": "en",
      "text": "is one of those high-risk use cases. I",
      "offset": 296.56,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "know certainly under the EU AI act uh",
      "offset": 298.639,
      "duration": 6.081
    },
    {
      "lang": "en",
      "text": "any kind of HR like AI use cases is",
      "offset": 301.52,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "considered high risk because there's a",
      "offset": 304.72,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "risk of discrimination happening there.",
      "offset": 306.32,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "So by the way you've got to be really",
      "offset": 308.72,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "really uh sure that the AI is highly",
      "offset": 310.639,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "accurate. And it's not just highly",
      "offset": 313.52,
      "duration": 2.959
    },
    {
      "lang": "en",
      "text": "accurate. I completely agree with you.",
      "offset": 315.199,
      "duration": 3.361
    },
    {
      "lang": "en",
      "text": "It's also not biased. I mean, we've seen",
      "offset": 316.479,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "things in the past where I think it was",
      "offset": 318.56,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "there was some very public ones where uh",
      "offset": 320.56,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "it turned out that AI had been trained",
      "offset": 323.12,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "on what previous good applicants looked",
      "offset": 325.12,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "like and it was extremely biased to",
      "offset": 327.6,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "people of color. And so it was quite",
      "offset": 330.16,
      "duration": 4.479
    },
    {
      "lang": "en",
      "text": "unfortunate that the way that that model",
      "offset": 332.8,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "training was designed um inherently",
      "offset": 334.639,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "picked up a set of bias there. And so",
      "offset": 336.56,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "one of the things that we do um not just",
      "offset": 338.56,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "when we're enriching data but uh as",
      "offset": 340.72,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "we're going through that process is that",
      "offset": 342.72,
      "duration": 3.199
    },
    {
      "lang": "en",
      "text": "we also work with our clients to show",
      "offset": 344.4,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "them the distribution of their data. So",
      "offset": 345.919,
      "duration": 4.241
    },
    {
      "lang": "en",
      "text": "you know in in something like a",
      "offset": 348.479,
      "duration": 3.361
    },
    {
      "lang": "en",
      "text": "self-driving car case it might be as",
      "offset": 350.16,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "easy as saying hey yes you've got a",
      "offset": 351.84,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "million vehicles but you only got 200",
      "offset": 354.72,
      "duration": 5.039
    },
    {
      "lang": "en",
      "text": "motorcycles you really let's find some",
      "offset": 357.12,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "more motorcycles within your data or you",
      "offset": 359.759,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "can collect some more so that you can",
      "offset": 361.68,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "represent motorcycles. Well, now in the",
      "offset": 363.199,
      "duration": 4.961
    },
    {
      "lang": "en",
      "text": "HR use case, it might be, hi, you don't",
      "offset": 365.44,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "have a good representation of gender.",
      "offset": 368.16,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "You don't have a good representation of",
      "offset": 370.16,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "educational background. Are we biasing",
      "offset": 371.68,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "towards particular schools because we're",
      "offset": 373.52,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "seeing this as, you know, is your",
      "offset": 376.4,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "training data set up in that way? Um, so",
      "offset": 378.24,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "we can we help with that um as well for",
      "offset": 380.479,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "our clients. Yeah, certainly. Even just",
      "offset": 382.4,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "crunching some numbers on what are the",
      "offset": 384.639,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "distribution of the outputs, that's",
      "offset": 386.88,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "going to give you a lot of transparency",
      "offset": 388.56,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "on what's the model doing, are you being",
      "offset": 390.16,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "fair in general? um if you're making",
      "offset": 392.16,
      "duration": 5.92
    },
    {
      "lang": "en",
      "text": "your own model or at least modifying",
      "offset": 395.6,
      "duration": 5.039
    },
    {
      "lang": "en",
      "text": "your own AI does that it sounds like",
      "offset": 398.08,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "it's quite an intensive process. So I'm",
      "offset": 400.639,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "wondering is this just something for big",
      "offset": 402.8,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "businesses or can anyone do this? Uh",
      "offset": 404.639,
      "duration": 4.481
    },
    {
      "lang": "en",
      "text": "maybe Wendy can you talk me through",
      "offset": 407.199,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "which industries or business types are",
      "offset": 409.12,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "making use of this? Yeah. So I mean a",
      "offset": 411.28,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "for a lot of enterprises they're",
      "offset": 413.44,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "leveraging these foundation models. It",
      "offset": 415.28,
      "duration": 3.759
    },
    {
      "lang": "en",
      "text": "doesn't make sense to build your own.",
      "offset": 417.28,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "you know, billions of dollars, lots of",
      "offset": 419.039,
      "duration": 5.041
    },
    {
      "lang": "en",
      "text": "GPUs, lots of cloud computing. It makes",
      "offset": 421.36,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "no sense. They're really advanced. You",
      "offset": 424.08,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "can find a way to apply them to your own",
      "offset": 425.84,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "use cases and as Duncan said, do things",
      "offset": 427.919,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "like rag embeddings which allow you to",
      "offset": 429.919,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "train the model on, you know, your own",
      "offset": 432.479,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "proprietary data for the right",
      "offset": 434.24,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "application. So, there's a lot uh that's",
      "offset": 435.759,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "happening there. But then in some cases,",
      "offset": 437.84,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "your your business, you know, it may be",
      "offset": 440.08,
      "duration": 3.519
    },
    {
      "lang": "en",
      "text": "so core to your business. So, some easy",
      "offset": 441.52,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "examples are self-driving cars. it is",
      "offset": 443.599,
      "duration": 4.801
    },
    {
      "lang": "en",
      "text": "core to the hardware in your vehicle,",
      "offset": 445.44,
      "duration": 4.479
    },
    {
      "lang": "en",
      "text": "the cameras, the sensors, and the",
      "offset": 448.4,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "placement. So, a lot of companies are",
      "offset": 449.919,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "building their own or, you know, they",
      "offset": 451.44,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "might be leveraging, for example, like",
      "offset": 453.199,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "Nvidia's platform, but they're still",
      "offset": 454.56,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "ultimately taking the time to build it",
      "offset": 456.639,
      "duration": 2.481
    },
    {
      "lang": "en",
      "text": "because it's part of the hardware",
      "offset": 458,
      "duration": 2.96
    },
    {
      "lang": "en",
      "text": "integration. Some cases, yep, companies",
      "offset": 459.12,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "are still building it or another example",
      "offset": 460.96,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "might be things like e-commerce, right?",
      "offset": 463.039,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "So, if you're going online, your product",
      "offset": 465.28,
      "duration": 4.479
    },
    {
      "lang": "en",
      "text": "catalog is key. the ability to search",
      "offset": 467.599,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "for products and to do some of the data",
      "offset": 469.759,
      "duration": 2.961
    },
    {
      "lang": "en",
      "text": "enrichment that Duncan had just",
      "offset": 471.52,
      "duration": 2.32
    },
    {
      "lang": "en",
      "text": "mentioned so that your products are",
      "offset": 472.72,
      "duration": 2.479
    },
    {
      "lang": "en",
      "text": "searchable and you can recommend things",
      "offset": 473.84,
      "duration": 3.199
    },
    {
      "lang": "en",
      "text": "appropriately. That's an another example",
      "offset": 475.199,
      "duration": 4.641
    },
    {
      "lang": "en",
      "text": "to where it's so core to the business of",
      "offset": 477.039,
      "duration": 4.801
    },
    {
      "lang": "en",
      "text": "actually selling the product that um",
      "offset": 479.84,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "even if you might be leveraging some",
      "offset": 481.84,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "models, a lot of companies are choosing",
      "offset": 483.759,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "to to make those investments themselves",
      "offset": 485.28,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "as well. I think a good example there",
      "offset": 487.039,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "would be say ThreadUp. Um so recently we",
      "offset": 489.36,
      "duration": 4.239
    },
    {
      "lang": "en",
      "text": "were at a conference called Shop Talk",
      "offset": 491.919,
      "duration": 3.361
    },
    {
      "lang": "en",
      "text": "and there was a great presentation by a",
      "offset": 493.599,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "company called Thread Up who um",
      "offset": 495.28,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "basically had allows uh secondhand",
      "offset": 496.879,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "clothes to be sold. So their product",
      "offset": 498.96,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "catalog each item is one each item is a",
      "offset": 500.879,
      "duration": 4.961
    },
    {
      "lang": "en",
      "text": "unique skew. Yes, they do have",
      "offset": 504,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "categories but I think it was uh when",
      "offset": 505.84,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "was it Kendrick Lamar at the Super Bowl.",
      "offset": 508.16,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "So it ended up with flared jeans and",
      "offset": 510.4,
      "duration": 3.199
    },
    {
      "lang": "en",
      "text": "everyone was like oh my god this is",
      "offset": 512.08,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "amazing and a new trend again. But they",
      "offset": 513.599,
      "duration": 4.481
    },
    {
      "lang": "en",
      "text": "they're using AI in a really interesting",
      "offset": 516,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "way because they and their problem is",
      "offset": 518.08,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "different to what you were mentioning in",
      "offset": 520.159,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "really large businesses where they have",
      "offset": 521.36,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "a unique issue where each item is being",
      "offset": 523.599,
      "duration": 5.441
    },
    {
      "lang": "en",
      "text": "uploaded in its custom and so looking at",
      "offset": 526.24,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "how they can match those and having an",
      "offset": 529.04,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "efficient system of data enrichment as",
      "offset": 531.2,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "well as AI to to help with that data",
      "offset": 532.88,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "enrichment as a first pass is really",
      "offset": 535.519,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "important to their um product and user",
      "offset": 537.76,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "experience straight out of the kit.",
      "offset": 539.519,
      "duration": 3.281
    },
    {
      "lang": "en",
      "text": "Okay. So those are quite wildly",
      "offset": 541.12,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "different use cases. Uh certainly I can",
      "offset": 542.8,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "see how a self-driving car you don't",
      "offset": 545.12,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "want to be sending your video data to",
      "offset": 546.88,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "chat GBT and saying well should I turn",
      "offset": 549.2,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "now uh yeah it's going to be a terrible",
      "offset": 551.36,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "thing. Uh so uh you want to build your",
      "offset": 553.04,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "own solution but uh the retail example",
      "offset": 555.36,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "also yeah I can see how you got loads of",
      "offset": 557.6,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "different products and you need to have",
      "offset": 559.68,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "I guess product descriptions for",
      "offset": 562.08,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "everything. You got to have photos for",
      "offset": 563.76,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "everything and assistants there just",
      "offset": 565.12,
      "duration": 6.24
    },
    {
      "lang": "en",
      "text": "managing or generating content. I'd like",
      "offset": 569.04,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "to know a bit more about what data",
      "offset": 571.36,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "enrichment involves because I guess in",
      "offset": 572.88,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "my mind it's like the sort of Amazon",
      "offset": 574.8,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "Turk type situations where you got a lot",
      "offset": 577.04,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "of people just staring at photos and",
      "offset": 578.72,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "writing descriptions of them. How",
      "offset": 580.48,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "accurate is that? Well, data annotation.",
      "offset": 582.56,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "So data annotation um and enrichment",
      "offset": 584.88,
      "duration": 6.079
    },
    {
      "lang": "en",
      "text": "it's really about tagging basically or",
      "offset": 588,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "enhancing unstructured data. Okay, so it",
      "offset": 590.959,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "could be visual data, it could be text",
      "offset": 593.68,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "data, it's about adding additional um",
      "offset": 595.519,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "attributes. And the reason why that's",
      "offset": 597.519,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "important is number one, you either are",
      "offset": 599.2,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "training a model to perform in some way.",
      "offset": 601.2,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "So a self-driving car is pretty clear.",
      "offset": 603.6,
      "duration": 3.679
    },
    {
      "lang": "en",
      "text": "You need to recognize lanes. You need to",
      "offset": 605.36,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "recognize traffic signs. You need to",
      "offset": 607.279,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "recognize pedestrians and other vehicles",
      "offset": 608.72,
      "duration": 4.239
    },
    {
      "lang": "en",
      "text": "to operate the to to do things like",
      "offset": 610.399,
      "duration": 4.641
    },
    {
      "lang": "en",
      "text": "collision avoidance. It also can be used",
      "offset": 612.959,
      "duration": 3.761
    },
    {
      "lang": "en",
      "text": "to validate that your model's performing",
      "offset": 615.04,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "properly. Okay, so you you need to know",
      "offset": 616.72,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "what does good look like, how is your",
      "offset": 619.2,
      "duration": 2.8
    },
    {
      "lang": "en",
      "text": "model performing against what the",
      "offset": 620.64,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "expectations are. And so that's really",
      "offset": 622,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "what uh data data annotation is about.",
      "offset": 624.48,
      "duration": 5.039
    },
    {
      "lang": "en",
      "text": "And oftentimes in a number of cases,",
      "offset": 627.36,
      "duration": 4.479
    },
    {
      "lang": "en",
      "text": "it's not just about uh capturing the",
      "offset": 629.519,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "right sort of class or the right uh",
      "offset": 631.839,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "descriptions. It can be enriching that",
      "offset": 633.839,
      "duration": 4.721
    },
    {
      "lang": "en",
      "text": "data. So I think a good example of this",
      "offset": 635.519,
      "duration": 4.721
    },
    {
      "lang": "en",
      "text": "just to kind of take the parallel from",
      "offset": 638.56,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "the retail example is think of like",
      "offset": 640.24,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "Spotify or think of like Apple Music,",
      "offset": 642.32,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "right? So they had to basically build a",
      "offset": 644.56,
      "duration": 4.719
    },
    {
      "lang": "en",
      "text": "genome of what is music and there are a",
      "offset": 646.72,
      "duration": 4.239
    },
    {
      "lang": "en",
      "text": "lot of attributes, right? I mean, this",
      "offset": 649.279,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "is where I suddenly realize when we're",
      "offset": 650.959,
      "duration": 2.961
    },
    {
      "lang": "en",
      "text": "talking about all the different",
      "offset": 652.959,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "descriptions of like, you know, K-punk,",
      "offset": 653.92,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "you know, I I wouldn't even know what",
      "offset": 656.399,
      "duration": 3.521
    },
    {
      "lang": "en",
      "text": "K-punk was like 10 years, you know, like",
      "offset": 657.76,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "2 years ago, probably as an example, but",
      "offset": 659.92,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "there there are so many different",
      "offset": 662.32,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "genres. And then you from the the song",
      "offset": 663.44,
      "duration": 6.56
    },
    {
      "lang": "en",
      "text": "itself, the, you know, the the AI needs",
      "offset": 666.8,
      "duration": 4.719
    },
    {
      "lang": "en",
      "text": "to say, &quot;Hey, where does it fit?&quot; And",
      "offset": 670,
      "duration": 2.959
    },
    {
      "lang": "en",
      "text": "it's it's literally G. I mean, there may",
      "offset": 671.519,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "be like 50 or 100 different attributes",
      "offset": 672.959,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "that can make something be a K-punk",
      "offset": 674.959,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "versus a K metal versus a K-pop type of",
      "offset": 677.12,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "song, right? Product cataloges run very",
      "offset": 679.36,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "similarly. Different products, lots of",
      "offset": 681.6,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "attributes. So, when it comes to um",
      "offset": 683.92,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "being able to to search, you know,",
      "offset": 685.76,
      "duration": 6.319
    },
    {
      "lang": "en",
      "text": "recommend um identify to allow the AI to",
      "offset": 688,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "really perform as as optimal as",
      "offset": 692.079,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "possible, you need to not only tag it,",
      "offset": 693.76,
      "duration": 3.519
    },
    {
      "lang": "en",
      "text": "but often times you need to enrich it.",
      "offset": 695.519,
      "duration": 3.201
    },
    {
      "lang": "en",
      "text": "Okay. Yeah. So, uh, it's not just",
      "offset": 697.279,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "writing descriptions. It's about, I",
      "offset": 698.72,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "guess, feature engineering stuff on",
      "offset": 700.399,
      "duration": 5.761
    },
    {
      "lang": "en",
      "text": "Yeah, certainly with music. Okay. Uh,",
      "offset": 703.44,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "you've got the people who are in the",
      "offset": 706.16,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "band and I guess the instruments they're",
      "offset": 708.72,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "playing and there's probably some kind",
      "offset": 710.24,
      "duration": 5.039
    },
    {
      "lang": "en",
      "text": "of chord progressions and tempos and,",
      "offset": 712,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "uh, yeah, this could very easily become",
      "offset": 715.279,
      "duration": 4.881
    },
    {
      "lang": "en",
      "text": "a very complex modeling situation. Just",
      "offset": 717.2,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "have subtle differences between genres.",
      "offset": 720.16,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "And it's interesting because like when",
      "offset": 722.72,
      "duration": 4.559
    },
    {
      "lang": "en",
      "text": "the reason you want to have this depth",
      "offset": 725.12,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "of attributes or genome as as Wendy was",
      "offset": 727.279,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "pointing out is because it allows that",
      "offset": 729.519,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "search relevance or that recommendation",
      "offset": 731.519,
      "duration": 4.241
    },
    {
      "lang": "en",
      "text": "the the end use case to be so much more",
      "offset": 733.44,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "personalized. Whereas if you just said",
      "offset": 735.76,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "you know if you just started with oh",
      "offset": 737.68,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "it's music and it's K-punk and that's it",
      "offset": 738.88,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "and that's all you had about it. it's",
      "offset": 741.839,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "you don't it makes it a lot harder for",
      "offset": 743.36,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "that next recommendation of a really",
      "offset": 745.76,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "great song to find its way to a listener",
      "offset": 747.76,
      "duration": 3.759
    },
    {
      "lang": "en",
      "text": "or for a really great product that's",
      "offset": 750,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "going to fit a need for someone um or",
      "offset": 751.519,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "for products to be matched near near",
      "offset": 753.6,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "each other or shown together. It um",
      "offset": 755.44,
      "duration": 4.639
    },
    {
      "lang": "en",
      "text": "really powers a lot of that ROI I'm",
      "offset": 757.76,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "going to say for the user experience",
      "offset": 760.079,
      "duration": 4.961
    },
    {
      "lang": "en",
      "text": "where getting good ads is like or good",
      "offset": 761.76,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "recommendations is such a better",
      "offset": 765.04,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "experience than getting just something",
      "offset": 766.72,
      "duration": 3.679
    },
    {
      "lang": "en",
      "text": "random or something near what you were",
      "offset": 768.56,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "looking for. Yeah. And bottom line, it",
      "offset": 770.399,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "increases, you know, cart sizes and",
      "offset": 772.16,
      "duration": 4.239
    },
    {
      "lang": "en",
      "text": "purchases online. So, it's core core",
      "offset": 774.24,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "part of it. And that's really where we",
      "offset": 776.399,
      "duration": 3.521
    },
    {
      "lang": "en",
      "text": "typically see AI being implemented is if",
      "offset": 777.68,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "it's going to make a core",
      "offset": 779.92,
      "duration": 2.24
    },
    {
      "lang": "en",
      "text": "differentiation in your product or it's",
      "offset": 780.72,
      "duration": 2.799
    },
    {
      "lang": "en",
      "text": "going to help you save money. Oh,",
      "offset": 782.16,
      "duration": 2.799
    },
    {
      "lang": "en",
      "text": "absolutely. I have to say uh a lot of",
      "offset": 783.519,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "the streaming music websites do this",
      "offset": 784.959,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "incredibly well. But for many retail",
      "offset": 787.2,
      "duration": 6.24
    },
    {
      "lang": "en",
      "text": "websites, absolutely terrible. So, the",
      "offset": 790.079,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "experience of searching something,",
      "offset": 793.44,
      "duration": 3.519
    },
    {
      "lang": "en",
      "text": "you're like, well, I know what I want. I",
      "offset": 795.519,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "can't see it in the results. And so",
      "offset": 796.959,
      "duration": 3.761
    },
    {
      "lang": "en",
      "text": "yeah, I can see this is incredibly",
      "offset": 799.2,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "important and a lot of shopping websites",
      "offset": 800.72,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "really need to take note. So hopefully",
      "offset": 803.2,
      "duration": 3.199
    },
    {
      "lang": "en",
      "text": "anyone in the audience working on a",
      "offset": 805.04,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "website. Yep. Better search is a good",
      "offset": 806.399,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "thing. Suppose you're interested in",
      "offset": 808.72,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "this. Um I guess to start you need to",
      "offset": 810.399,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "find yourself a data set. So where does",
      "offset": 813.68,
      "duration": 4.959
    },
    {
      "lang": "en",
      "text": "the data come from? Um if you decide you",
      "offset": 816.399,
      "duration": 5.041
    },
    {
      "lang": "en",
      "text": "want to get some data to feed into your",
      "offset": 818.639,
      "duration": 4.481
    },
    {
      "lang": "en",
      "text": "own model. What do you do? Data can come",
      "offset": 821.44,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "from so many places. Um, so let's say uh",
      "offset": 823.12,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "if I was taking a retail example, a lot",
      "offset": 825.36,
      "duration": 3.599
    },
    {
      "lang": "en",
      "text": "of that information is going to be",
      "offset": 827.44,
      "duration": 2.8
    },
    {
      "lang": "en",
      "text": "already there. So it's the product",
      "offset": 828.959,
      "duration": 2.801
    },
    {
      "lang": "en",
      "text": "catalog of all the images and",
      "offset": 830.24,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "descriptions that your vendors have",
      "offset": 831.76,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "uploaded. And so you've now got access",
      "offset": 834,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "to that data and you can enrich it from",
      "offset": 835.839,
      "duration": 3.521
    },
    {
      "lang": "en",
      "text": "there. If we're talking about something",
      "offset": 837.92,
      "duration": 3.599
    },
    {
      "lang": "en",
      "text": "like self-driving cars, you need to",
      "offset": 839.36,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "actually have a fleet of vehicles. You",
      "offset": 841.519,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "need to put cameras and LARS on them and",
      "offset": 843.279,
      "duration": 4.481
    },
    {
      "lang": "en",
      "text": "drive them around and actually record",
      "offset": 845.92,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "data. But there's also that's so that's",
      "offset": 847.76,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "for the raw data um collection. But I",
      "offset": 850,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "think we should also touch a little bit",
      "offset": 852.079,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "on um what kind of mix of synthetic data",
      "offset": 853.6,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "can also be part of your AI solution.",
      "offset": 856.639,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "When we look at how models are being",
      "offset": 858.88,
      "duration": 3.199
    },
    {
      "lang": "en",
      "text": "developed, especially even the large",
      "offset": 860.72,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "language models, we're now seeing",
      "offset": 862.079,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "synthetic data from the generation",
      "offset": 864,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "before being a large portion of the",
      "offset": 865.839,
      "duration": 4.961
    },
    {
      "lang": "en",
      "text": "training data for the next generation.",
      "offset": 867.92,
      "duration": 4.719
    },
    {
      "lang": "en",
      "text": "um because as the data needs are",
      "offset": 870.8,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "exploding in terms of they're running",
      "offset": 872.639,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "out of the internet to continue to",
      "offset": 874.48,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "scrape and so they're generating more",
      "offset": 876.72,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "more content more specific content from",
      "offset": 878.56,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "you know if you take for example uh with",
      "offset": 880.56,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "llama 4 out llama 3 actually produced a",
      "offset": 882.399,
      "duration": 6.161
    },
    {
      "lang": "en",
      "text": "large portion of the training data for",
      "offset": 885.6,
      "duration": 6.08
    },
    {
      "lang": "en",
      "text": "llama 4 and so you can see and if I if",
      "offset": 888.56,
      "duration": 5.279
    },
    {
      "lang": "en",
      "text": "we go to self-driving cars for example",
      "offset": 891.68,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "being able to generate um using",
      "offset": 893.839,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "top-of-the-line game engines or custom",
      "offset": 896.48,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "like if you think of if you think of the",
      "offset": 898.639,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "movies and video games, the",
      "offset": 900.48,
      "duration": 3.359
    },
    {
      "lang": "en",
      "text": "top-of-the-line ones we have today, are",
      "offset": 901.839,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "photo realistic. And so they're able to",
      "offset": 903.839,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "use those technologies to also simulate",
      "offset": 905.76,
      "duration": 4.879
    },
    {
      "lang": "en",
      "text": "uh um more hours of driving and see how",
      "offset": 908,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "the vehicle um can react there. Same",
      "offset": 910.639,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "with your product catalog is that you",
      "offset": 913.12,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "might have you might be going into a new",
      "offset": 915.04,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "category that you do not actually have",
      "offset": 916.8,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "information on. You can actually create",
      "offset": 918.56,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "synthetic data from you know image",
      "offset": 920.56,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "generation as well as product catalog",
      "offset": 922.399,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "description. you can actually build a",
      "offset": 924.32,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "syn synthetic data pipeline um in order",
      "offset": 925.839,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "to be able to have new training data",
      "offset": 928.639,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "let's say ahead of a new category that",
      "offset": 930.639,
      "duration": 3.521
    },
    {
      "lang": "en",
      "text": "you're going to have on your website.",
      "offset": 932.24,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "And so the funny thing about synthetic",
      "offset": 934.16,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "data though is that you have to be",
      "offset": 936.24,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "careful like what we were talking about",
      "offset": 938.56,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "before is taking inherent bias into your",
      "offset": 939.76,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "model. And so it's really important to",
      "offset": 942.24,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "have your synthetic data validated.",
      "offset": 944.32,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "Wendy, do you want to talk a little bit",
      "offset": 946.32,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "about um some of the was there? Yeah, I",
      "offset": 947.44,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "I was I was going to actually just touch",
      "offset": 949.92,
      "duration": 3.359
    },
    {
      "lang": "en",
      "text": "on the the exact same thing that you you",
      "offset": 951.36,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "can leverage a model to train a model,",
      "offset": 953.279,
      "duration": 3.761
    },
    {
      "lang": "en",
      "text": "but that model training a model could",
      "offset": 955.36,
      "duration": 3.599
    },
    {
      "lang": "en",
      "text": "carry forward biases from the previous",
      "offset": 957.04,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "model. So, at the end of the day, you",
      "offset": 958.959,
      "duration": 3.521
    },
    {
      "lang": "en",
      "text": "still have to know what good looks like,",
      "offset": 961.04,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "you still have to know how you evaluate",
      "offset": 962.48,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "your model and even if you're leveraging",
      "offset": 964.16,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "something like synthetic data, is it in",
      "offset": 966.399,
      "duration": 4.641
    },
    {
      "lang": "en",
      "text": "context? You know, is it realistic? Is",
      "offset": 968.72,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "it achieving? So, number one, you have",
      "offset": 971.04,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "to say, hey, what is I'm trying to build",
      "offset": 972.72,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "in terms of my data set? What's missing?",
      "offset": 974.72,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "What can synthetic data support? Then",
      "offset": 976.8,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "second is that synthetic data going to",
      "offset": 979.12,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "be of the quality that we expect it to",
      "offset": 980.639,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "be. So what happens often times",
      "offset": 982.56,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "especially in like image generation? You",
      "offset": 984.56,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "might like have a phone but maybe it's",
      "offset": 986.639,
      "duration": 4.241
    },
    {
      "lang": "en",
      "text": "floating exactly one centimeter above",
      "offset": 988.32,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "the table right there are these things",
      "offset": 990.88,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "that you know it is not perfect. Um and",
      "offset": 992.399,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "at the end of the day the quality of the",
      "offset": 994.959,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "data is what matters most. Whether it is",
      "offset": 996.399,
      "duration": 5.201
    },
    {
      "lang": "en",
      "text": "captured or synthetic or generated by a",
      "offset": 998.079,
      "duration": 5.281
    },
    {
      "lang": "en",
      "text": "model you still need to know how do I",
      "offset": 1001.6,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "evaluate it? Is it accurate? Okay that",
      "offset": 1003.36,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "makes a lot of sense. So if there are",
      "offset": 1006,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "cases where you don't have good real",
      "offset": 1007.68,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "data or it's very expensive to collect",
      "offset": 1010.32,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "then yeah uh I think uh that's going to",
      "offset": 1012.88,
      "duration": 4.639
    },
    {
      "lang": "en",
      "text": "be incredibly useful. I heard a case a",
      "offset": 1015.36,
      "duration": 5.279
    },
    {
      "lang": "en",
      "text": "while ago it was from the US Air Force",
      "offset": 1017.519,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "where they were trying to train their",
      "offset": 1020.639,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "drones to do something and they said",
      "offset": 1022.399,
      "duration": 5.121
    },
    {
      "lang": "en",
      "text": "well we only ever fly drones during the",
      "offset": 1025.039,
      "duration": 4.481
    },
    {
      "lang": "en",
      "text": "day so we don't have any data on how",
      "offset": 1027.52,
      "duration": 4.559
    },
    {
      "lang": "en",
      "text": "well they perform at night. Uh so they",
      "offset": 1029.52,
      "duration": 5.919
    },
    {
      "lang": "en",
      "text": "had to deep fake nighttime flying in",
      "offset": 1032.079,
      "duration": 5.281
    },
    {
      "lang": "en",
      "text": "order to generate a data set that they",
      "offset": 1035.439,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "could then train on. Uh yeah, I I like",
      "offset": 1037.36,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "that idea. Certainly I can see how if",
      "offset": 1039.76,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "you're generating garbage quality data",
      "offset": 1041.36,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "from a model, feeding that into another",
      "offset": 1043.52,
      "duration": 3.679
    },
    {
      "lang": "en",
      "text": "model, it's just got worse and worse and",
      "offset": 1045.439,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "worse and that's not going to benefit",
      "offset": 1047.199,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "anyone. Yeah, it's like a copy of a copy",
      "offset": 1048.799,
      "duration": 5.601
    },
    {
      "lang": "en",
      "text": "kind of a a scenario. And um we see it",
      "offset": 1050.88,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "uh synthetic data has has has good good",
      "offset": 1054.4,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "uses or great uses in edge cases. So",
      "offset": 1056.88,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "imagine like nobody wants to realtime",
      "offset": 1059.12,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "capture, you know, a stroller in the",
      "offset": 1061.84,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "street or an empty stroller or stroller",
      "offset": 1064.08,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "with a baby in it or I heard one",
      "offset": 1065.919,
      "duration": 3.361
    },
    {
      "lang": "en",
      "text": "actually from a from an auto company",
      "offset": 1067.6,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "client where they're like, you wouldn't",
      "offset": 1069.28,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "think of this, but sometimes hogs like",
      "offset": 1071.12,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "drop out of the sky and get in front of",
      "offset": 1073.52,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "vehicles. That's probably not something",
      "offset": 1075.28,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "you're ever going to catch. It has",
      "offset": 1076.96,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "happened before. Um it's probably not",
      "offset": 1078.88,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "something you're going to catch uh you",
      "offset": 1081.2,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "know in any regular real life. So, it's",
      "offset": 1082.88,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "a great example of some edge cases where",
      "offset": 1084.88,
      "duration": 2.96
    },
    {
      "lang": "en",
      "text": "it's like, okay, synthetic data makes",
      "offset": 1086.4,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "total sense. Okay, that feels like a",
      "offset": 1087.84,
      "duration": 6.079
    },
    {
      "lang": "en",
      "text": "very Texas scenario somehow. Uh, yeah.",
      "offset": 1090,
      "duration": 5.679
    },
    {
      "lang": "en",
      "text": "Uh, I can see how it's going be very",
      "offset": 1093.919,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "hard to create that kind of real uh that",
      "offset": 1095.679,
      "duration": 4.561
    },
    {
      "lang": "en",
      "text": "data in real life. Uh, but uh yeah, you",
      "offset": 1097.52,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "might need to deal with it at some",
      "offset": 1100.24,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "point. So, it's important to have a data",
      "offset": 1101.76,
      "duration": 6.08
    },
    {
      "lang": "en",
      "text": "set. So, suppose you've got your data uh",
      "offset": 1104.24,
      "duration": 6.48
    },
    {
      "lang": "en",
      "text": "some of it synthetic, some of it's real.",
      "offset": 1107.84,
      "duration": 5.839
    },
    {
      "lang": "en",
      "text": "What next? Um, I guess you have to",
      "offset": 1110.72,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "choose a model to enrich. Yeah, there's",
      "offset": 1113.679,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "some some really good benchmarks out",
      "offset": 1115.84,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "there. Um, but one of the really nice",
      "offset": 1117.36,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "things about where we're at today is",
      "offset": 1119.44,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "that it's actually very easy to just try",
      "offset": 1121.2,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "a model out. And so being able to pick",
      "offset": 1124.24,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "the right model for your use case can be",
      "offset": 1126.24,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "as simple as actually running through a",
      "offset": 1128.4,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "bunch of tasks or of the the type you",
      "offset": 1130.32,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "want and seeing what the performance of",
      "offset": 1132.4,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "those base models are. You know, for",
      "offset": 1134.16,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "example, Claude is extremely good at",
      "offset": 1135.6,
      "duration": 4.959
    },
    {
      "lang": "en",
      "text": "language um writing emails and writing",
      "offset": 1138,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "personalized responses. It it's a really",
      "offset": 1140.559,
      "duration": 5.681
    },
    {
      "lang": "en",
      "text": "it it far outperforms others even",
      "offset": 1143.12,
      "duration": 6.16
    },
    {
      "lang": "en",
      "text": "ignoring the benchmarking. Um uh it's",
      "offset": 1146.24,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "sorry even more so than the benchmarking",
      "offset": 1149.28,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "would would uh would show for example.",
      "offset": 1151.12,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "And so what it really comes down to is",
      "offset": 1152.96,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "test out the existing models for your",
      "offset": 1154.96,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "use case and see how it feels because at",
      "offset": 1157.2,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "the end of the day this is a almost all",
      "offset": 1159.52,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "of these come down to a customer",
      "offset": 1162.48,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "experience. um at for a lot a lot of",
      "offset": 1163.84,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "these and so being able to get those",
      "offset": 1166.48,
      "duration": 4.559
    },
    {
      "lang": "en",
      "text": "intangible human elements of that sounds",
      "offset": 1168.24,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "right that sounds better that's not",
      "offset": 1171.039,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "messing up in this way also set up a uh",
      "offset": 1172.88,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "before you begin you should also set up",
      "offset": 1175.36,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "how you want to assess these and so if",
      "offset": 1176.799,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "you're doing a like an image detection",
      "offset": 1178.88,
      "duration": 3.679
    },
    {
      "lang": "en",
      "text": "model and you wanted to start with",
      "offset": 1180.799,
      "duration": 4.481
    },
    {
      "lang": "en",
      "text": "something like yolo off the shelf great",
      "offset": 1182.559,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "you can also you can start with your",
      "offset": 1185.28,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "metrics being like oh okay well I care",
      "offset": 1186.72,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "about do I care more about accurately",
      "offset": 1188.48,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "detecting everything all the time and",
      "offset": 1191.12,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "I'm okay with detecting some things that",
      "offset": 1193.2,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "are the wrong things or is this case",
      "offset": 1195.12,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "actually it's really more it's okay if I",
      "offset": 1197.12,
      "duration": 3.679
    },
    {
      "lang": "en",
      "text": "miss some things but I should only",
      "offset": 1199.28,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "detect the thing that is the problem",
      "offset": 1200.799,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "that I'm looking for so you can set up",
      "offset": 1202.64,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "those uh metrics for yourself before you",
      "offset": 1204.72,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "uh begin your investigation yeah I I",
      "offset": 1206.64,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "like to just to tack on to that one",
      "offset": 1208.88,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "thing I share often with people are kind",
      "offset": 1211.52,
      "duration": 2.8
    },
    {
      "lang": "en",
      "text": "of contemplating well which model should",
      "offset": 1212.96,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "I use is models change all the time okay",
      "offset": 1214.32,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "4.5 just came out right and there's",
      "offset": 1217.039,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "going to be something that comes out in",
      "offset": 1219.6,
      "duration": 2.959
    },
    {
      "lang": "en",
      "text": "another two weeks and probably an open",
      "offset": 1221.039,
      "duration": 3.201
    },
    {
      "lang": "en",
      "text": "source version of it or an openweight",
      "offset": 1222.559,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "version of it I should say it'll happen",
      "offset": 1224.24,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "um and uh the one content though is",
      "offset": 1226.64,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "model evaluation you have to know what",
      "offset": 1229.28,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "are you trying to achieve with your",
      "offset": 1231.76,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "model what are the right outputs that",
      "offset": 1233.36,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "I'm expecting what are the appropriate",
      "offset": 1235.679,
      "duration": 2.961
    },
    {
      "lang": "en",
      "text": "parameters and then the you know the",
      "offset": 1237.12,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "models are like widgets they could come",
      "offset": 1238.64,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "and go and what we're seeing actually a",
      "offset": 1240.48,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "lot more is that companies are looking",
      "offset": 1242.48,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "for flexibility they know that there may",
      "offset": 1244.32,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "be a next better thing that's coming out",
      "offset": 1246.24,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "so how do I ensure that you know I have",
      "offset": 1248,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "the appropriate sort of um you know",
      "offset": 1250.32,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "forward and backwards compatibility and",
      "offset": 1252.64,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "an ability to to swap something out if",
      "offset": 1254.48,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "something better comes along, which it",
      "offset": 1256.4,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "inevitably will. Probably already has",
      "offset": 1257.76,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "today. You know, they're coming out like",
      "offset": 1259.44,
      "duration": 3.359
    },
    {
      "lang": "en",
      "text": "every single day, literally. That's",
      "offset": 1261.12,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "useful to know that you need to bear in",
      "offset": 1262.799,
      "duration": 4.641
    },
    {
      "lang": "en",
      "text": "mind that you're probably going to uh",
      "offset": 1264.72,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "swap out your model at some point,",
      "offset": 1267.44,
      "duration": 2.64
    },
    {
      "lang": "en",
      "text": "probably fairly regularly. But there's",
      "offset": 1268.799,
      "duration": 2.88
    },
    {
      "lang": "en",
      "text": "so many models around, it's relatively",
      "offset": 1270.08,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "easy to try different things. I guess",
      "offset": 1271.679,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "the trick is just uh make sure you got",
      "offset": 1273.84,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "something like some measure of how good",
      "offset": 1275.52,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "it is, so if you swap it out, you're not",
      "offset": 1278.08,
      "duration": 4.479
    },
    {
      "lang": "en",
      "text": "going to make things worse accidentally.",
      "offset": 1280.24,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "You can have a way of measuring is this",
      "offset": 1282.559,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "going to be better on whatever the use",
      "offset": 1284.4,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "case is. Yes. Yes. Especially as you",
      "offset": 1286.64,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "know models get more uh because it's all",
      "offset": 1289.6,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "about cost right. So certain models can",
      "offset": 1291.76,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "be cheaper to run as the technology",
      "offset": 1293.84,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "improves that's going to be a constant",
      "offset": 1295.44,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "evaluation just like people think of",
      "offset": 1296.96,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "like cloud optimization you know similar",
      "offset": 1298.96,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "kind of concept is it's always going to",
      "offset": 1301.44,
      "duration": 3.119
    },
    {
      "lang": "en",
      "text": "be evaluated for for the ROI and the",
      "offset": 1302.799,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "cost. Okay. Yeah. And I guess here we're",
      "offset": 1304.559,
      "duration": 3.521
    },
    {
      "lang": "en",
      "text": "mostly thinking about the inference",
      "offset": 1306.559,
      "duration": 4.801
    },
    {
      "lang": "en",
      "text": "cost. Um is that the primary expense",
      "offset": 1308.08,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "here? Yeah, gen that'll be your primary",
      "offset": 1311.36,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "your primary cost there which is as I",
      "offset": 1313.76,
      "duration": 2.96
    },
    {
      "lang": "en",
      "text": "was saying earlier one of the reasons",
      "offset": 1315.6,
      "duration": 2.88
    },
    {
      "lang": "en",
      "text": "people choose smaller models and for",
      "offset": 1316.72,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "example you might need a larger model",
      "offset": 1318.48,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "like you know you might be up in the",
      "offset": 1320.48,
      "duration": 3.199
    },
    {
      "lang": "en",
      "text": "several hundred billion parameters at",
      "offset": 1322,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "the moment uh like with your use case",
      "offset": 1323.679,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "and then something like a deep seat",
      "offset": 1325.919,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "comes along or you know two or three",
      "offset": 1328.08,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "generations later you can actually get",
      "offset": 1329.76,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "away with a 10 billion parameter because",
      "offset": 1331.12,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "it's more specific or it's more you know",
      "offset": 1332.88,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "um and so you could really drop your",
      "offset": 1335.2,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "inference costs over time. I guess if",
      "offset": 1337.039,
      "duration": 4.721
    },
    {
      "lang": "en",
      "text": "you have more specific data, is that",
      "offset": 1338.88,
      "duration": 5.919
    },
    {
      "lang": "en",
      "text": "also going to allow you to use a smaller",
      "offset": 1341.76,
      "duration": 5.279
    },
    {
      "lang": "en",
      "text": "model compared to having a general",
      "offset": 1344.799,
      "duration": 5.281
    },
    {
      "lang": "en",
      "text": "purpose one? Like do you need a larger",
      "offset": 1347.039,
      "duration": 4.801
    },
    {
      "lang": "en",
      "text": "general purpose model compared to a",
      "offset": 1350.08,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "smaller more targeted model to get the",
      "offset": 1351.84,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "same accuracy? That's a really good",
      "offset": 1354,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "question. I think the size of model",
      "offset": 1356.159,
      "duration": 5.121
    },
    {
      "lang": "en",
      "text": "generally relates to the capability",
      "offset": 1359.2,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "level, the general capabilities you",
      "offset": 1361.28,
      "duration": 3.759
    },
    {
      "lang": "en",
      "text": "need. So if you just need it to kind of",
      "offset": 1363.2,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "know how to how to talk and how to think",
      "offset": 1365.039,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "about the world, okay, you can go",
      "offset": 1367.36,
      "duration": 3.679
    },
    {
      "lang": "en",
      "text": "smaller. And the other side of that is",
      "offset": 1368.559,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "when you said is your data really",
      "offset": 1371.039,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "specific, I would look at it more as is",
      "offset": 1372.72,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "the data you have or can create or you",
      "offset": 1374.72,
      "duration": 4.959
    },
    {
      "lang": "en",
      "text": "know, as we talked about before, does it",
      "offset": 1377.52,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "really encompass the the entirety of",
      "offset": 1379.679,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "your problem? So if I took took an HR",
      "offset": 1381.919,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "example um is that maybe I'm doing that",
      "offset": 1384.08,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "regime rime piece where I'm just",
      "offset": 1387.039,
      "duration": 5.201
    },
    {
      "lang": "en",
      "text": "matching key words to a taxonomy but do",
      "offset": 1389.6,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "I need my model to do more about",
      "offset": 1392.24,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "understanding the the maybe the history",
      "offset": 1394.24,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "of someone or I need it to understand",
      "offset": 1396.4,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "all the different educational",
      "offset": 1398.64,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "institutions in the world is that really",
      "offset": 1400.24,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "captured within the data set that I've",
      "offset": 1402.559,
      "duration": 5.281
    },
    {
      "lang": "en",
      "text": "got or how much am I relying on the LLM",
      "offset": 1404.88,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "or the AI model to have that general",
      "offset": 1407.84,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "understanding there. So I would say the",
      "offset": 1410.48,
      "duration": 3.439
    },
    {
      "lang": "en",
      "text": "more complete your data your data is for",
      "offset": 1412,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "your problem another way you can also go",
      "offset": 1413.919,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "generally smaller. Okay. So this sounds",
      "offset": 1416,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "like it's be something a lot of people",
      "offset": 1418.32,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "might fall over because there's very",
      "offset": 1419.84,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "subtle differences in questions. What",
      "offset": 1422.32,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "university did this person go to is very",
      "offset": 1424.96,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "different from is this a good",
      "offset": 1427.12,
      "duration": 4.799
    },
    {
      "lang": "en",
      "text": "university? Was it a good university at",
      "offset": 1428.799,
      "duration": 5.521
    },
    {
      "lang": "en",
      "text": "this particular time? At that time.",
      "offset": 1431.919,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "Yeah. I mean wow. And it's something",
      "offset": 1434.32,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "that you could create or or have that",
      "offset": 1436.159,
      "duration": 4.801
    },
    {
      "lang": "en",
      "text": "data available as part of the the models",
      "offset": 1438.72,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "or what the model has access to. Or you",
      "offset": 1440.96,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "could be like, hey, and do you want your",
      "offset": 1442.96,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "model going and checking the internet",
      "offset": 1444.48,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "every time that it's doing a, you know,",
      "offset": 1446.4,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "a check here? That inference cost can go",
      "offset": 1448.799,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "much higher if you need to check each",
      "offset": 1451.12,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "university, each resume that you're",
      "offset": 1452.799,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "looking for um to go figure that out at",
      "offset": 1454.64,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "the same time, which is just interesting",
      "offset": 1456.88,
      "duration": 3.679
    },
    {
      "lang": "en",
      "text": "to think about the cost. Absolutely.",
      "offset": 1459.039,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "Okay. Uh so I guess the last step is how",
      "offset": 1460.559,
      "duration": 5.841
    },
    {
      "lang": "en",
      "text": "do you combine all your own custom data",
      "offset": 1463.12,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "with the LLM? So I know there are a few",
      "offset": 1466.4,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "techniques for this. I mean the simplest",
      "offset": 1468.24,
      "duration": 3.679
    },
    {
      "lang": "en",
      "text": "thing is just use retrieval augmented",
      "offset": 1469.6,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "generation rag and there are fine tuning",
      "offset": 1471.919,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "options and a bunch of other techniques.",
      "offset": 1473.76,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "So when do you choose each of the",
      "offset": 1476.159,
      "duration": 3.441
    },
    {
      "lang": "en",
      "text": "different options to combine your data",
      "offset": 1477.919,
      "duration": 4.801
    },
    {
      "lang": "en",
      "text": "with the LLM or other AI? Yeah. So I",
      "offset": 1479.6,
      "duration": 5.199
    },
    {
      "lang": "en",
      "text": "mean with things more like a like with",
      "offset": 1482.72,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "simpler models like say if you were",
      "offset": 1484.799,
      "duration": 3.441
    },
    {
      "lang": "en",
      "text": "using a vision detection from like YOLO",
      "offset": 1486.32,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "or something like that it can be very",
      "offset": 1488.24,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "cheap for you to actually add that data",
      "offset": 1490.24,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "and do a retraining or a fine tuning of",
      "offset": 1492.32,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "the model. But when we're getting up",
      "offset": 1494.08,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "into that LLM space is that it's",
      "offset": 1495.52,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "fine-tuning is probably not the right",
      "offset": 1498,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "term um as people think about it more",
      "offset": 1500,
      "duration": 3.679
    },
    {
      "lang": "en",
      "text": "from the sort of like traditional uh",
      "offset": 1501.84,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "like CV vision models. It's much more",
      "offset": 1503.679,
      "duration": 5.841
    },
    {
      "lang": "en",
      "text": "about how do you give the model the",
      "offset": 1506.88,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "right context and the right access to",
      "offset": 1509.52,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "the right data. So more in that sort of",
      "offset": 1511.6,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "rag kind of approach where you're like",
      "offset": 1513.36,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "okay here's my document storage and even",
      "offset": 1515.36,
      "duration": 4.799
    },
    {
      "lang": "en",
      "text": "for some use cases it can even with the",
      "offset": 1518.08,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "larger context windows we're seeing now",
      "offset": 1520.159,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "I'm we're actually seeing some clients",
      "offset": 1522.32,
      "duration": 4.239
    },
    {
      "lang": "en",
      "text": "that are able to incorporate the data",
      "offset": 1523.84,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "that the model needs into the into the",
      "offset": 1526.559,
      "duration": 4.641
    },
    {
      "lang": "en",
      "text": "prompt at inference time depending once",
      "offset": 1529.2,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "again depending on how large the data",
      "offset": 1531.2,
      "duration": 4.719
    },
    {
      "lang": "en",
      "text": "set size is. So you those are the two",
      "offset": 1532.88,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "common ways that we've been seeing for",
      "offset": 1535.919,
      "duration": 3.521
    },
    {
      "lang": "en",
      "text": "smaller problems that that only require",
      "offset": 1537.44,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "like a few documents worth for context",
      "offset": 1539.44,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "versus ones where you're like no I've",
      "offset": 1542.64,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "got millions of images that need to be",
      "offset": 1544.24,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "or millions of documents that need to be",
      "offset": 1546.4,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "included um and or or are regularly",
      "offset": 1548.32,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "changing. That's one of the other",
      "offset": 1550.96,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "advantages of a of a rag system is not",
      "offset": 1552.24,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "having a fixed like it's stopped at a",
      "offset": 1555.12,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "point in time. you can update the data",
      "offset": 1557.84,
      "duration": 4.719
    },
    {
      "lang": "en",
      "text": "sources as um as the world evolves and",
      "offset": 1559.52,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "you can keep your model uh continuing to",
      "offset": 1562.559,
      "duration": 4.881
    },
    {
      "lang": "en",
      "text": "perform there. Yeah, we we see I mean",
      "offset": 1564.48,
      "duration": 4.799
    },
    {
      "lang": "en",
      "text": "rag embeddings is definitely I think the",
      "offset": 1567.44,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "predominant the predominant approach. I",
      "offset": 1569.279,
      "duration": 4.561
    },
    {
      "lang": "en",
      "text": "I just I say that because supervised",
      "offset": 1571.6,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "fine-tuning for one models change all",
      "offset": 1573.84,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "the time right so as soon as you choose",
      "offset": 1576.24,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "to fine-tune a model it kind of limits",
      "offset": 1578.4,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "your ability to transition to another",
      "offset": 1580.64,
      "duration": 3.519
    },
    {
      "lang": "en",
      "text": "model. The second component is that it",
      "offset": 1582.4,
      "duration": 3.519
    },
    {
      "lang": "en",
      "text": "takes a decent amount of expertise,",
      "offset": 1584.159,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "right? And a lot of these models are,",
      "offset": 1585.919,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "you know, they're open weight or they're",
      "offset": 1588.08,
      "duration": 3.199
    },
    {
      "lang": "en",
      "text": "they're closed, right? You you don't",
      "offset": 1589.76,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "really know what's happening in the",
      "offset": 1591.279,
      "duration": 3.041
    },
    {
      "lang": "en",
      "text": "background to really understand those",
      "offset": 1592.88,
      "duration": 2.64
    },
    {
      "lang": "en",
      "text": "models and have the expertise to",
      "offset": 1594.32,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "fine-tune it. In addition to the fact",
      "offset": 1595.52,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "that um it makes a little bit harder to",
      "offset": 1597.52,
      "duration": 3.759
    },
    {
      "lang": "en",
      "text": "swap out or you might be losing some",
      "offset": 1599.76,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "sort of ROI in terms of being able to",
      "offset": 1601.279,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "transition to another model. Um, we're",
      "offset": 1603.12,
      "duration": 4.799
    },
    {
      "lang": "en",
      "text": "seeing that rag and and prompts like",
      "offset": 1605.919,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "Duncan was saying is really the most",
      "offset": 1607.919,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "predominant way most companies are",
      "offset": 1609.679,
      "duration": 3.441
    },
    {
      "lang": "en",
      "text": "thinking about it now. So, going back to",
      "offset": 1611.6,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "your ThreadUp example where anytime",
      "offset": 1613.12,
      "duration": 5.039
    },
    {
      "lang": "en",
      "text": "someone uploads a new clothing item, you",
      "offset": 1615.36,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "don't have to completely retune your",
      "offset": 1618.159,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "model. So, you say, &quot;Okay, I just want",
      "offset": 1620.48,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "to add it to a data store and then",
      "offset": 1622.32,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "that's done.&quot; Yeah. Just pull it in.",
      "offset": 1624.72,
      "duration": 4.559
    },
    {
      "lang": "en",
      "text": "Exactly. All right. Cool. So um from",
      "offset": 1626.72,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "that I guess the other big thing is how",
      "offset": 1629.279,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "much can you just leave these models to",
      "offset": 1631.84,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "just go and do stuff on their own? So",
      "offset": 1633.919,
      "duration": 5.521
    },
    {
      "lang": "en",
      "text": "when do you need a human involved? So",
      "offset": 1636.159,
      "duration": 5.281
    },
    {
      "lang": "en",
      "text": "what can you automate and what can't you",
      "offset": 1639.44,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "automate in these situations? I think uh",
      "offset": 1641.44,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "automation is a really interesting",
      "offset": 1643.6,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "topic. Um I think that automation should",
      "offset": 1644.72,
      "duration": 4.559
    },
    {
      "lang": "en",
      "text": "always be you should always ask yourself",
      "offset": 1647.52,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "the question what can I automate and",
      "offset": 1649.279,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "start with automation as your first",
      "offset": 1651.679,
      "duration": 3.521
    },
    {
      "lang": "en",
      "text": "place. What you then should be asking",
      "offset": 1653.2,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "yourself is where do I definitely need",
      "offset": 1655.2,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "humans involved here? Whether that's on",
      "offset": 1657.84,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "the data enrichment side, whether that's",
      "offset": 1659.76,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "checking the synthetic data quality,",
      "offset": 1661.36,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "whether it's also in an ongoing manner.",
      "offset": 1663.52,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "So one of the things that we found you",
      "offset": 1665.6,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "kind of mentioned that how much can you",
      "offset": 1667.52,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "just let them go? Um and with the rate",
      "offset": 1669.36,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "of change uh that we see in the world",
      "offset": 1672.24,
      "duration": 4.559
    },
    {
      "lang": "en",
      "text": "and the data sets for people is that",
      "offset": 1674.24,
      "duration": 5.84
    },
    {
      "lang": "en",
      "text": "having a an ongoing model evaluation or",
      "offset": 1676.799,
      "duration": 6.961
    },
    {
      "lang": "en",
      "text": "validation in an ongoing um nature is a",
      "offset": 1680.08,
      "duration": 5.599
    },
    {
      "lang": "en",
      "text": "really great way to be able to continue",
      "offset": 1683.76,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "to keep your model performing at a very",
      "offset": 1685.679,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "high rate. Let's let's take say Thread",
      "offset": 1687.52,
      "duration": 4.879
    },
    {
      "lang": "en",
      "text": "Up as an example is that if as fashion",
      "offset": 1689.52,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "maybe their models are performing",
      "offset": 1692.399,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "extremely well now, but um maybe they",
      "offset": 1693.679,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "weren't actually that great at the",
      "offset": 1696.24,
      "duration": 2.799
    },
    {
      "lang": "en",
      "text": "Sorry, what were the type of jeans",
      "offset": 1698,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "again? They were the flare jeans. Flare",
      "offset": 1699.039,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "jeans. Maybe flare jeans actually wasn't",
      "offset": 1701.36,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "something their model was actually",
      "offset": 1703.44,
      "duration": 2.8
    },
    {
      "lang": "en",
      "text": "performing particularly well at, but",
      "offset": 1704.64,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "it's become a really popular um thing",
      "offset": 1706.24,
      "duration": 4.799
    },
    {
      "lang": "en",
      "text": "because of uh because of that Super Bowl",
      "offset": 1708.559,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "um halftime song. And so what you could",
      "offset": 1711.039,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "detect on an ongoing basis is hey what",
      "offset": 1713.919,
      "duration": 3.521
    },
    {
      "lang": "en",
      "text": "are the most popular categories people",
      "offset": 1715.919,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "are looking for searching for and are we",
      "offset": 1717.44,
      "duration": 4.479
    },
    {
      "lang": "en",
      "text": "doing well at that data and so having a",
      "offset": 1719.84,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "set of humans who can actually on a",
      "offset": 1721.919,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "regular basis plug into how your to your",
      "offset": 1723.6,
      "duration": 6.24
    },
    {
      "lang": "en",
      "text": "use case and how it's evolving and check",
      "offset": 1727.679,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "that and see that the model's performing",
      "offset": 1729.84,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "and then being able to do something with",
      "offset": 1732,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "that response like actually it's not",
      "offset": 1733.84,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "performing really well. Okay, well let's",
      "offset": 1735.6,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "make sure that we go look at some of the",
      "offset": 1737.52,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "data for um for flare genes and actually",
      "offset": 1739.44,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "go and enrich that and great now the",
      "offset": 1741.919,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "model's back up to performing. So we see",
      "offset": 1744,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "it more as an ongoing process because",
      "offset": 1746.24,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "once you've found that business value",
      "offset": 1749.52,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "that sort of like hey this is actually",
      "offset": 1751.84,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "really valuable to customers. It's you",
      "offset": 1753.84,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "know increasing my cart size. It's you",
      "offset": 1755.679,
      "duration": 4.561
    },
    {
      "lang": "en",
      "text": "know lowering cart abandonment. what",
      "offset": 1758,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "whatever the business value you're",
      "offset": 1760.24,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "gaining there, you've got to ask",
      "offset": 1762.159,
      "duration": 3.441
    },
    {
      "lang": "en",
      "text": "yourself for each percentage of",
      "offset": 1763.52,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "performance in that model, what what's",
      "offset": 1765.6,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "it going to cost me? If am I willing to",
      "offset": 1767.919,
      "duration": 5.441
    },
    {
      "lang": "en",
      "text": "accept 5% less, 10% less where 1% like",
      "offset": 1769.679,
      "duration": 5.761
    },
    {
      "lang": "en",
      "text": "does each percent mean you like a",
      "offset": 1773.36,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "million a year in difference or $10",
      "offset": 1775.44,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "million depending on the scale of the",
      "offset": 1777.52,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "company and so then you can offset that",
      "offset": 1779.12,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "with um keeping having that human model",
      "offset": 1780.96,
      "duration": 5.439
    },
    {
      "lang": "en",
      "text": "validation occurring. Um yeah, keeping I",
      "offset": 1783.44,
      "duration": 5.359
    },
    {
      "lang": "en",
      "text": "mean that that's really the key is these",
      "offset": 1786.399,
      "duration": 4.721
    },
    {
      "lang": "en",
      "text": "AI models they're experimental as well.",
      "offset": 1788.799,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "Not only do they learn, you know, there",
      "offset": 1791.12,
      "duration": 3.279
    },
    {
      "lang": "en",
      "text": "are new edge cases, new data that comes",
      "offset": 1792.799,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "up like flare jeans or like whatever the",
      "offset": 1794.399,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "you know the the the the latest and",
      "offset": 1796.88,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "greatest current trend or event is um",
      "offset": 1798.32,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "but beyond that it learns something from",
      "offset": 1800,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "that. You need to make sure it doesn't",
      "offset": 1801.76,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "go off pieced. So model evaluation is",
      "offset": 1803.12,
      "duration": 3.679
    },
    {
      "lang": "en",
      "text": "really important because data is",
      "offset": 1805.12,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "constantly changing and you need to know",
      "offset": 1806.799,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "is it still performing as we expected it",
      "offset": 1809.2,
      "duration": 4.959
    },
    {
      "lang": "en",
      "text": "to perform. Another example to think of",
      "offset": 1811.12,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "simple one is like the self-driving car.",
      "offset": 1814.159,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "You may have a car that works really",
      "offset": 1816.24,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "really well um in you know Pacific",
      "offset": 1818.559,
      "duration": 4.961
    },
    {
      "lang": "en",
      "text": "Highway 101 here in California but you",
      "offset": 1821.12,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "take that you put it into you know Rio",
      "offset": 1823.52,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "di Janeiro where you also have coastline",
      "offset": 1825.279,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "and and you know roads and maybe it it",
      "offset": 1827.12,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "doesn't do so well and plus it doesn't",
      "offset": 1829.679,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "really understand Portuguese or doesn't",
      "offset": 1831.36,
      "duration": 3.039
    },
    {
      "lang": "en",
      "text": "understand the types of the cars. So",
      "offset": 1832.799,
      "duration": 3.441
    },
    {
      "lang": "en",
      "text": "there are is going to be edge case data",
      "offset": 1834.399,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "that's going to be important and given",
      "offset": 1836.24,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "that these technologies are global like",
      "offset": 1838.08,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "that's kind of the the trick. So like an",
      "offset": 1839.84,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "agriculture example that is you know",
      "offset": 1842.48,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "like wheat in Kenya looks different than",
      "offset": 1844.24,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "wheat in Russia. You can't just assume",
      "offset": 1846.48,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "that the model that's been trained right",
      "offset": 1848,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "is knows what the differences are. And",
      "offset": 1849.52,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "that's the thing about these models is",
      "offset": 1851.84,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "that yes they're they're trained on the",
      "offset": 1853.36,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "entire corpus of the internet. But does",
      "offset": 1854.96,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "anybody believe the internet is either",
      "offset": 1856.96,
      "duration": 2.8
    },
    {
      "lang": "en",
      "text": "unbiased or has every single piece of",
      "offset": 1858.32,
      "duration": 4.719
    },
    {
      "lang": "en",
      "text": "data on it for every application? Right.",
      "offset": 1859.76,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "So that's the other way to think of it.",
      "offset": 1863.039,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "I'd also mention Wendy that we think",
      "offset": 1864.88,
      "duration": 3.679
    },
    {
      "lang": "en",
      "text": "about automation in the same way as",
      "offset": 1867.2,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "well. while we're focusing on that human",
      "offset": 1868.559,
      "duration": 5.041
    },
    {
      "lang": "en",
      "text": "uh validation element uh we actually we",
      "offset": 1870.88,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "have automation that's built into our",
      "offset": 1873.6,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "processes as well. So if we were if we",
      "offset": 1875.36,
      "duration": 4.559
    },
    {
      "lang": "en",
      "text": "take that uh thread up example is that",
      "offset": 1877.52,
      "duration": 4.879
    },
    {
      "lang": "en",
      "text": "if we were doing data validation and",
      "offset": 1879.919,
      "duration": 4.721
    },
    {
      "lang": "en",
      "text": "saying hey do we have the right category",
      "offset": 1882.399,
      "duration": 5.121
    },
    {
      "lang": "en",
      "text": "for for the for this new product item is",
      "offset": 1884.64,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "that we're not just going to sit there",
      "offset": 1887.52,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "and have someone go okay let me look at",
      "offset": 1888.88,
      "duration": 5.279
    },
    {
      "lang": "en",
      "text": "the entire list of 10,000 options for",
      "offset": 1891.2,
      "duration": 4.959
    },
    {
      "lang": "en",
      "text": "where for what category this could be.",
      "offset": 1894.159,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "No we will introduce it. We have an LLM",
      "offset": 1896.159,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "at the beginning saying hey I think it's",
      "offset": 1898.48,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "one of these three categories. And that",
      "offset": 1900.399,
      "duration": 5.441
    },
    {
      "lang": "en",
      "text": "allows us to capture that human insight",
      "offset": 1902.88,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "in the most efficient way possible. And",
      "offset": 1905.84,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "so that's how we really think about um",
      "offset": 1907.84,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "sort of human in the loop in automation.",
      "offset": 1910.08,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "Okay. Uh that certainly makes a lot of",
      "offset": 1911.84,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "sense. If you've got uh severe",
      "offset": 1913.76,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "consequences uh when uh the AI makes a",
      "offset": 1915.36,
      "duration": 5.199
    },
    {
      "lang": "en",
      "text": "mistake, then you're going to need to",
      "offset": 1918.24,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "well you probably need to have both",
      "offset": 1920.559,
      "duration": 2.881
    },
    {
      "lang": "en",
      "text": "things. So you're going to need to have",
      "offset": 1922.24,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "a software monitoring tool that says,",
      "offset": 1923.44,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "okay, the AI has done something wrong.",
      "offset": 1925.44,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "And then you're going to have to have",
      "offset": 1928.08,
      "duration": 5.439
    },
    {
      "lang": "en",
      "text": "humans uh in as well just to make a",
      "offset": 1930,
      "duration": 6.559
    },
    {
      "lang": "en",
      "text": "decision on what to do next. Uh verify",
      "offset": 1933.519,
      "duration": 4.241
    },
    {
      "lang": "en",
      "text": "that there really has been a problem",
      "offset": 1936.559,
      "duration": 2.881
    },
    {
      "lang": "en",
      "text": "with your AI. I'd like to know a bit",
      "offset": 1937.76,
      "duration": 3.039
    },
    {
      "lang": "en",
      "text": "about how you go about implementing",
      "offset": 1939.44,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "these things. So suppose you say, okay,",
      "offset": 1940.799,
      "duration": 5.441
    },
    {
      "lang": "en",
      "text": "we need to have our own custom systems.",
      "offset": 1943.36,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "We're going to use our own data in an",
      "offset": 1946.24,
      "duration": 5.279
    },
    {
      "lang": "en",
      "text": "AI. Uh first of all, who tends to be in",
      "offset": 1948.48,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "charge of these projects? Is it going to",
      "offset": 1951.519,
      "duration": 3.441
    },
    {
      "lang": "en",
      "text": "be what? Chief technology officer, chief",
      "offset": 1952.96,
      "duration": 4.959
    },
    {
      "lang": "en",
      "text": "AI officer, chief data officer. um who",
      "offset": 1954.96,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "tends to run this sort of thing. Yeah,",
      "offset": 1957.919,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "it generally comes from the top down in",
      "offset": 1959.6,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "terms of how the need for the business",
      "offset": 1961.76,
      "duration": 4.799
    },
    {
      "lang": "en",
      "text": "to say like hey we need to be further",
      "offset": 1963.679,
      "duration": 5.041
    },
    {
      "lang": "en",
      "text": "ahead in AI. It's a very common thing",
      "offset": 1966.559,
      "duration": 3.761
    },
    {
      "lang": "en",
      "text": "that we're hearing and I'm sure a lot of",
      "offset": 1968.72,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "the audience are like my boss or my",
      "offset": 1970.32,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "board is telling me like why are you not",
      "offset": 1972.08,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "using more AI? That's generally where it",
      "offset": 1973.84,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "initi initially comes from. But in terms",
      "offset": 1975.76,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "of those running the projects, it goes",
      "offset": 1977.44,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "down the chain where you do we do see a",
      "offset": 1979.12,
      "duration": 4.559
    },
    {
      "lang": "en",
      "text": "much more prevalent uh set of like a",
      "offset": 1981.6,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "chief AI officer as a a much more common",
      "offset": 1983.679,
      "duration": 5.521
    },
    {
      "lang": "en",
      "text": "title. Now we're seeing that it then",
      "offset": 1986,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "goes down to sort of like your directors",
      "offset": 1989.2,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "of engineering or a director of product",
      "offset": 1990.96,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "who may have um a particular surface",
      "offset": 1993.279,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "area or part of a product um or service",
      "offset": 1995.76,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "that they they they manage. And that's",
      "offset": 1997.919,
      "duration": 3.201
    },
    {
      "lang": "en",
      "text": "when the project starts becoming more",
      "offset": 1999.76,
      "duration": 3.279
    },
    {
      "lang": "en",
      "text": "real because you've actually got people",
      "offset": 2001.12,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "who are you know partially if not",
      "offset": 2003.039,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "directly responsible for the P&amp;L of a",
      "offset": 2005.039,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "particular area and they're like great",
      "offset": 2007.2,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "okay I know what I need to move from a",
      "offset": 2008.88,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "business perspective I have a target",
      "offset": 2010.88,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "area because I know that you know let's",
      "offset": 2012.799,
      "duration": 3.041
    },
    {
      "lang": "en",
      "text": "say it was thread up for example it",
      "offset": 2014.48,
      "duration": 3.039
    },
    {
      "lang": "en",
      "text": "could be something where you've got okay",
      "offset": 2015.84,
      "duration": 4.559
    },
    {
      "lang": "en",
      "text": "well I'm in the uh recommendations team",
      "offset": 2017.519,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "okay well I know that our",
      "offset": 2020.399,
      "duration": 2.481
    },
    {
      "lang": "en",
      "text": "recommendations are performing like this",
      "offset": 2021.519,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "and I needed to perform at a at a",
      "offset": 2022.88,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "different level okay now I can get in",
      "offset": 2024.559,
      "duration": 4.641
    },
    {
      "lang": "en",
      "text": "and start saying well let's let's try to",
      "offset": 2026.96,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "address this with AI. What kind of",
      "offset": 2029.2,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "model, what kind of data are we going to",
      "offset": 2030.96,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "need? Oh, wait. I need human enrichment.",
      "offset": 2032.72,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "Uh, I should probably, you know, reach",
      "offset": 2034.96,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "out to Sama. Yeah. And and with the the",
      "offset": 2036.96,
      "duration": 4.559
    },
    {
      "lang": "en",
      "text": "fact that make AI easier to adopt, we're",
      "offset": 2039.6,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "seeing also a bit a bit more on the",
      "offset": 2041.519,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "business side. So, it's not unusual for",
      "offset": 2043.6,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "a head of customer experience to say,",
      "offset": 2045.6,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "hey, how am I going to integrate, you",
      "offset": 2047.2,
      "duration": 4.719
    },
    {
      "lang": "en",
      "text": "know, chatbot omni channel experience,",
      "offset": 2049.28,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "right? So, before you might experience",
      "offset": 2051.919,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "reaching out. Yeah, I think it's very",
      "offset": 2054.48,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "true that stuff like this tends to start",
      "offset": 2056.399,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "right at the top of the business. So",
      "offset": 2058.24,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "yeah, there's always a CE going yes,",
      "offset": 2060.24,
      "duration": 4.879
    },
    {
      "lang": "en",
      "text": "let's have more AI and then it has to",
      "offset": 2062.159,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "filter down to all the different",
      "offset": 2065.119,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "departments and yeah, I guess a lot of",
      "offset": 2066.24,
      "duration": 3.359
    },
    {
      "lang": "en",
      "text": "different departments end up having to",
      "offset": 2068.159,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "contribute in some way. I'd like to talk",
      "offset": 2069.599,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "a little bit about SAM itself. Uh I know",
      "offset": 2071.359,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "you have Bcore status. So uh just for",
      "offset": 2074.159,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "the international audience, uh can you",
      "offset": 2076.639,
      "duration": 5.921
    },
    {
      "lang": "en",
      "text": "explain what is a bore and just tell us",
      "offset": 2078.639,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "why did you choose this approach? Uh",
      "offset": 2082.56,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "Wendy, do you want to take this one?",
      "offset": 2084.639,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "Yeah. Yeah. So, a BC Corp stands for uh",
      "offset": 2086.24,
      "duration": 5.119
    },
    {
      "lang": "en",
      "text": "benefit corporation. So, as we are a",
      "offset": 2088.8,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "public benefit corporation, and it's",
      "offset": 2091.359,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "basically a designation um that states",
      "offset": 2093.2,
      "duration": 5.919
    },
    {
      "lang": "en",
      "text": "that a company has both a uh a a uh",
      "offset": 2095.2,
      "duration": 7.44
    },
    {
      "lang": "en",
      "text": "profit purpose, right? But also a social",
      "offset": 2099.119,
      "duration": 5.921
    },
    {
      "lang": "en",
      "text": "um or environmental purpose as well.",
      "offset": 2102.64,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "Okay. So, means that you can do it's",
      "offset": 2105.04,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "it's the the double bottom line or the",
      "offset": 2107.2,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "triple bottom line. BC Cororp and the",
      "offset": 2109.2,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "BCorp certification group is basically",
      "offset": 2111.359,
      "duration": 5.121
    },
    {
      "lang": "en",
      "text": "the best uh globally known standard for",
      "offset": 2113.52,
      "duration": 5.599
    },
    {
      "lang": "en",
      "text": "how you eval evaluate companies who have",
      "offset": 2116.48,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "purpose and profit. Um and so we are",
      "offset": 2119.119,
      "duration": 5.121
    },
    {
      "lang": "en",
      "text": "BCorp but they have a really uh rigorous",
      "offset": 2121.44,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "um evaluation process that is based off",
      "offset": 2124.24,
      "duration": 3.359
    },
    {
      "lang": "en",
      "text": "of the United Nations sustainable",
      "offset": 2126.16,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "development goals and um in our case uh",
      "offset": 2127.599,
      "duration": 6.48
    },
    {
      "lang": "en",
      "text": "we are really focused on on uh workers",
      "offset": 2130.72,
      "duration": 6.32
    },
    {
      "lang": "en",
      "text": "and impact. So part of our our our core",
      "offset": 2134.079,
      "duration": 5.121
    },
    {
      "lang": "en",
      "text": "social mission is to bring people from",
      "offset": 2137.04,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "underserved communities into the digital",
      "offset": 2139.2,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "economy by providing them not only",
      "offset": 2141.52,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "training but full-time employment uh not",
      "offset": 2143.04,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "on the basis of just their you know",
      "offset": 2145.76,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "their work experience or their resume",
      "offset": 2148.32,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "but on the basis of their impact and",
      "offset": 2149.68,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "then we provide the the upskilling and",
      "offset": 2151.44,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "training. So actually that sounds pretty",
      "offset": 2153.04,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "wonderful. I do like that you have a",
      "offset": 2154.64,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "social mission. So uh can you describe",
      "offset": 2156.48,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "some of the positive impacts you've had",
      "offset": 2159.52,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "so far? Yeah definitely we're super",
      "offset": 2161.2,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "proud of this. So we've moved uh almost",
      "offset": 2163.52,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "70,000 people out of poverty since we",
      "offset": 2166,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "have started um this this company and uh",
      "offset": 2168,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "what we do is we have an impact hiring",
      "offset": 2171.44,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "model where we hire on the basis of",
      "offset": 2173.76,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "impact. So that means household incomes",
      "offset": 2175.92,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "that fall below the world bank poverty",
      "offset": 2177.839,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "standard. Really the key here is that",
      "offset": 2179.52,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "there's so many talented people lots of",
      "offset": 2181.359,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "just incredibly talented people but they",
      "offset": 2183.68,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "lack the opportunity and so s means",
      "offset": 2185.44,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "equal in Sanskrit. We are really just",
      "offset": 2188.16,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "trying to level the playing field by",
      "offset": 2190.96,
      "duration": 2.879
    },
    {
      "lang": "en",
      "text": "providing job opportunities to people",
      "offset": 2192.24,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "who would have huge barriers otherwise,",
      "offset": 2193.839,
      "duration": 4.721
    },
    {
      "lang": "en",
      "text": "but they're still really talented. So,",
      "offset": 2197.04,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "we open the door, but our great and",
      "offset": 2198.56,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "talented workforce is the ones who walk",
      "offset": 2200.48,
      "duration": 5.119
    },
    {
      "lang": "en",
      "text": "through it. That's very cool. Um, and do",
      "offset": 2202.16,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "you want to describe some of the jobs",
      "offset": 2205.599,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "that these people are doing? Uh, yes.",
      "offset": 2206.96,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "So, we're doing a lot in the data",
      "offset": 2209.44,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "annotation validation space, data",
      "offset": 2211.52,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "insights, but I'll I'll give a couple of",
      "offset": 2213.44,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "examples. So we have uh people who are",
      "offset": 2215.76,
      "duration": 5.839
    },
    {
      "lang": "en",
      "text": "are helping um do annotation for",
      "offset": 2218.72,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "self-driving cars. So that could be you",
      "offset": 2221.599,
      "duration": 5.441
    },
    {
      "lang": "en",
      "text": "know complex uh sensor fusion 3D LAR and",
      "offset": 2223.92,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "2D data to help detect you know",
      "offset": 2227.04,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "vulnerable road users or traffic signs.",
      "offset": 2229.52,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "And it sounds uh fairly simple but it's",
      "offset": 2232.4,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "not. I I would actually challenge",
      "offset": 2234.48,
      "duration": 3.599
    },
    {
      "lang": "en",
      "text": "anybody to try to run some of these. It",
      "offset": 2235.92,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "requires you know depth perception like",
      "offset": 2238.079,
      "duration": 4.881
    },
    {
      "lang": "en",
      "text": "lots of you know complex taxonomy. In",
      "offset": 2240.4,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "other cases we're doing validation. So",
      "offset": 2242.96,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "an example that Duncan was using earlier",
      "offset": 2244.96,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "is uh you are building you know you you",
      "offset": 2246.88,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "you're you have a retail application you",
      "offset": 2250.24,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "have images but the images that were",
      "offset": 2252.48,
      "duration": 4.879
    },
    {
      "lang": "en",
      "text": "provided by your you know individual you",
      "offset": 2254.72,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "know small business don't include any",
      "offset": 2257.359,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "descriptions an LLM autogenerates the",
      "offset": 2259.119,
      "duration": 5.601
    },
    {
      "lang": "en",
      "text": "description but it's written out of",
      "offset": 2262.079,
      "duration": 5.441
    },
    {
      "lang": "en",
      "text": "context or has weird grammar or it's not",
      "offset": 2264.72,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "exactly accurate it's chartreuse instead",
      "offset": 2267.52,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "of green or you know examples like that",
      "offset": 2269.44,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "and so human loop might be there to help",
      "offset": 2272.32,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "validate the the reasoning, the context,",
      "offset": 2274.72,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "the accuracy. And then they're also",
      "offset": 2276.88,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "doing things really um intelligently. So",
      "offset": 2278.56,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "it's not uh just about um okay, let's",
      "offset": 2280.72,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "annotate this or annotate this edge",
      "offset": 2283.2,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "case, but it could be the evaluation of",
      "offset": 2284.88,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "the data set. Um so Duncan's example of",
      "offset": 2286.64,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "hey, there are not enough motorcycles or",
      "offset": 2289.28,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "we've noticed that there's a really",
      "offset": 2290.88,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "common failure point with your model. It",
      "offset": 2292.4,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "always fails when it sees, you know, a",
      "offset": 2294.72,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "red I don't know, vehicle. I'm making",
      "offset": 2296.56,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "that up. But the idea is that they're",
      "offset": 2298.64,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "evaluating, understanding the data, then",
      "offset": 2300.96,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "providing insights back to our clients",
      "offset": 2302.72,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "on how they can improve the accuracy of",
      "offset": 2304.64,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "their models. Yeah. So, I do feel like",
      "offset": 2306.48,
      "duration": 6.56
    },
    {
      "lang": "en",
      "text": "these are the unsung heroes of AI. Uh,",
      "offset": 2309.2,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "so because you got all these sort of",
      "offset": 2313.04,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "rockstar AI researchers earning a",
      "offset": 2314.32,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "fortune, but then actually in terms of",
      "offset": 2316.4,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "model quality, just getting correctly",
      "offset": 2317.76,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "annotated data in the background is",
      "offset": 2320.48,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "incredibly important. Uh, probably has",
      "offset": 2323.52,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "an equal impact, I think. Uh,",
      "offset": 2325.52,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "absolutely. I mean, it is still true to",
      "offset": 2327.2,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "this date. It really is garbage in,",
      "offset": 2329.52,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "garbage out. Like, data is king. You",
      "offset": 2331.28,
      "duration": 2.72
    },
    {
      "lang": "en",
      "text": "have to make sure you're using the right",
      "offset": 2332.96,
      "duration": 2.8
    },
    {
      "lang": "en",
      "text": "data and that data is valid. That's",
      "offset": 2334,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "that's the entire goal behind the social",
      "offset": 2335.76,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "mission is there's a lot of business",
      "offset": 2337.839,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "value that's being created. Want to",
      "offset": 2339.839,
      "duration": 3.121
    },
    {
      "lang": "en",
      "text": "create a lot of employment at living",
      "offset": 2341.44,
      "duration": 4.639
    },
    {
      "lang": "en",
      "text": "wages along the way and let let a larger",
      "offset": 2342.96,
      "duration": 5.119
    },
    {
      "lang": "en",
      "text": "group of people participate in you the",
      "offset": 2346.079,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "the effects of the digital economy. All",
      "offset": 2348.079,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "right. Wonderful. Uh so actually I have",
      "offset": 2350.079,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "a tricky question uh because this is the",
      "offset": 2352.24,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "one issue we tend to skirt around a lot",
      "offset": 2354.16,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "when we talk about AI since you're",
      "offset": 2356.16,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "running a socially conscious company. I",
      "offset": 2358.24,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "wanted to ask you about it. A lot of AI",
      "offset": 2359.92,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "particularly generative AI is incredibly",
      "offset": 2361.92,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "energyintensive.",
      "offset": 2364.72,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "So there's this trade-off between do we",
      "offset": 2366.64,
      "duration": 4.479
    },
    {
      "lang": "en",
      "text": "go all in on AI and just kind of burn",
      "offset": 2368.88,
      "duration": 5.92
    },
    {
      "lang": "en",
      "text": "the world or how do you deal with that?",
      "offset": 2371.119,
      "duration": 5.201
    },
    {
      "lang": "en",
      "text": "Um do you want to talk me through how",
      "offset": 2374.8,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "you think about these energy problems at",
      "offset": 2376.32,
      "duration": 4.799
    },
    {
      "lang": "en",
      "text": "SAM? Yeah, it's really interesting. Um,",
      "offset": 2378.32,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "we we all we also are actually part of",
      "offset": 2381.119,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "the science space climate action. So, we",
      "offset": 2383.2,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "have a we have a sustainability",
      "offset": 2385.119,
      "duration": 2.881
    },
    {
      "lang": "en",
      "text": "objective as well and we're carbon",
      "offset": 2386.48,
      "duration": 4.639
    },
    {
      "lang": "en",
      "text": "neutral in um all of our North American",
      "offset": 2388,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "offices and uh we are working towards",
      "offset": 2391.119,
      "duration": 4.881
    },
    {
      "lang": "en",
      "text": "that with our uh locations in East",
      "offset": 2393.44,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "Africa as well um and and tracking and",
      "offset": 2396,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "measuring that too. It is really uh",
      "offset": 2398.96,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "interesting as you can see the largest",
      "offset": 2401.52,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "uh tech companies right the hyperscalers",
      "offset": 2403.52,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "are literally doing things like buying",
      "offset": 2405.68,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "three mile island and building data",
      "offset": 2407.2,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "centers in billions and we got some",
      "offset": 2408.88,
      "duration": 4.719
    },
    {
      "lang": "en",
      "text": "pretty interesting uh data points that",
      "offset": 2411.04,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "uh you know even the the average uh",
      "offset": 2413.599,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "price of you know of utilities and",
      "offset": 2415.92,
      "duration": 3.439
    },
    {
      "lang": "en",
      "text": "energy is actually affected the average",
      "offset": 2417.68,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "person in Ireland because there is so",
      "offset": 2419.359,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "much energy that's being used because so",
      "offset": 2421.839,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "many tech companies are based um in that",
      "offset": 2423.599,
      "duration": 5.601
    },
    {
      "lang": "en",
      "text": "area. So I think it's an under discussed",
      "offset": 2425.839,
      "duration": 7.201
    },
    {
      "lang": "en",
      "text": "topic um that is uh something that um",
      "offset": 2429.2,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "should deserves deserves more because at",
      "offset": 2433.04,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "the end of the day the more sort of",
      "offset": 2435.2,
      "duration": 4.879
    },
    {
      "lang": "en",
      "text": "commoditized and lower the cost the AI",
      "offset": 2437.119,
      "duration": 5.041
    },
    {
      "lang": "en",
      "text": "is going to you know it takes to be to",
      "offset": 2440.079,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "be built right so you know the GPUs are",
      "offset": 2442.16,
      "duration": 3.439
    },
    {
      "lang": "en",
      "text": "going to get cheaper they're going to",
      "offset": 2444.48,
      "duration": 3.119
    },
    {
      "lang": "en",
      "text": "get smarter and yes they'll use less",
      "offset": 2445.599,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "energy but what happens on the flip side",
      "offset": 2447.599,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "is that adoption goes up what was the",
      "offset": 2449.28,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "first thing Amazon says they said we're",
      "offset": 2451.359,
      "duration": 2.961
    },
    {
      "lang": "en",
      "text": "going to you know be building more in",
      "offset": 2452.8,
      "duration": 3.279
    },
    {
      "lang": "en",
      "text": "terms of cloud computing and we need",
      "offset": 2454.32,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "more energy, right? Because a lot more",
      "offset": 2456.079,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "people will end up leveraging AI. So, I",
      "offset": 2458.88,
      "duration": 4.959
    },
    {
      "lang": "en",
      "text": "I don't know that I have a good like,",
      "offset": 2461.839,
      "duration": 4.721
    },
    {
      "lang": "en",
      "text": "hey, what do what do we do to",
      "offset": 2463.839,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "uh manage this challenge? I think it is",
      "offset": 2466.56,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "something though that needs to be really",
      "offset": 2468.24,
      "duration": 6.48
    },
    {
      "lang": "en",
      "text": "raised because at the end of the day, a",
      "offset": 2470.72,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "lot of people believe and I believe too",
      "offset": 2474.72,
      "duration": 3.599
    },
    {
      "lang": "en",
      "text": "that, you know, economies are going to",
      "offset": 2476.48,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "be driven by how how intelligent people",
      "offset": 2478.319,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "are at AI, right? How these countries",
      "offset": 2480.48,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "are at AI. if you don't have a policy or",
      "offset": 2482.079,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "view on how you're going to be",
      "offset": 2484.319,
      "duration": 4.641
    },
    {
      "lang": "en",
      "text": "leveraging it, it will, you know, it",
      "offset": 2485.76,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "will and is contributing to the, you",
      "offset": 2488.96,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "know, climate crisis we already have.",
      "offset": 2491.2,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "Yeah. Uh, I kind of agree with you on",
      "offset": 2493.119,
      "duration": 4.881
    },
    {
      "lang": "en",
      "text": "this. There's probably no easy solutions",
      "offset": 2495.359,
      "duration": 5.121
    },
    {
      "lang": "en",
      "text": "at all, but I do like the idea that",
      "offset": 2498,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "legislators um need to start thinking",
      "offset": 2500.48,
      "duration": 5.359
    },
    {
      "lang": "en",
      "text": "about this. And I guess any companies",
      "offset": 2502.96,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "that are using this also need to think",
      "offset": 2505.839,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "about what they're doing. Yeah. Yeah.",
      "offset": 2507.68,
      "duration": 2.96
    },
    {
      "lang": "en",
      "text": "And and some are, you know, I think some",
      "offset": 2509.119,
      "duration": 3.121
    },
    {
      "lang": "en",
      "text": "come, you know, some some have really",
      "offset": 2510.64,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "clearly stated kind of net zero",
      "offset": 2512.24,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "approaches. And so I think, you know,",
      "offset": 2514.48,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "it's especially in this day and age,",
      "offset": 2517.52,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "it's I think we're be hardressed to see",
      "offset": 2519.2,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "regulation being, at least here in the",
      "offset": 2520.96,
      "duration": 4.639
    },
    {
      "lang": "en",
      "text": "US, a a top priority. But I do think",
      "offset": 2522.72,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "the, you know, the notion of both",
      "offset": 2525.599,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "standards and, you know, talking about",
      "offset": 2527.119,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "it is going to be important because then",
      "offset": 2530.079,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "each company can choose to take their",
      "offset": 2531.52,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "own, you know, actions towards this. So",
      "offset": 2533.76,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "there was a lot of really here here's a",
      "offset": 2536.48,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "challenge I should say with not having",
      "offset": 2538.64,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "any policy or regulation is we saw the",
      "offset": 2540,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "leaps forward in green technology take",
      "offset": 2542.8,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "place when California set some really",
      "offset": 2544.8,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "important emission standards right and",
      "offset": 2547.28,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "then all of a sudden everybody's",
      "offset": 2549.28,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "motivated to think really intelligently",
      "offset": 2550.8,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "about green technology I think there is",
      "offset": 2552.8,
      "duration": 5.279
    },
    {
      "lang": "en",
      "text": "a role for for policy to be to uh to",
      "offset": 2555.04,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "play in this whether will happen you",
      "offset": 2558.079,
      "duration": 5.201
    },
    {
      "lang": "en",
      "text": "know in the next few years here pro",
      "offset": 2560.56,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "maybe not maybe not here in the US Um,",
      "offset": 2563.28,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "but I think it's a very important",
      "offset": 2565.52,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "consideration and we're seeing some",
      "offset": 2567.04,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "companies lead the way. They're really",
      "offset": 2568.64,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "challenging um to get net zero and",
      "offset": 2571.119,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "challenging their suppliers like us to",
      "offset": 2573.28,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "get net zero. Uh yeah, I like the idea",
      "offset": 2574.72,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "that uh just one part of the world needs",
      "offset": 2577.2,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "to come up with some regulations and",
      "offset": 2578.8,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "then it provides inspiration for the",
      "offset": 2580.4,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "other parts of the world. But yeah, uh",
      "offset": 2582.16,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "maybe this feels like a whole separate",
      "offset": 2584.16,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "episode. It probably is. So, uh yeah,",
      "offset": 2586.079,
      "duration": 4.961
    },
    {
      "lang": "en",
      "text": "the audience has to watch this space. Uh",
      "offset": 2588.96,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "we'll see what we can do. All right. So",
      "offset": 2591.04,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "uh just to wrap up, do you have any",
      "offset": 2592.8,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "final advice for companies who are",
      "offset": 2595.04,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "interested in doing data enrichment? One",
      "offset": 2596.8,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "of the things we haven't um discussed",
      "offset": 2599.2,
      "duration": 2.8
    },
    {
      "lang": "en",
      "text": "but I I think we've been discussing",
      "offset": 2600.72,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "components of it is this notion of",
      "offset": 2602,
      "duration": 5.359
    },
    {
      "lang": "en",
      "text": "responsible AI and responsible AI isn't",
      "offset": 2603.92,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "the same thing as like ethical AI. What",
      "offset": 2607.359,
      "duration": 3.281
    },
    {
      "lang": "en",
      "text": "it means is it's really have you built",
      "offset": 2609.2,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "the AI in a responsible way and it's",
      "offset": 2610.64,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "typically around four different pillars.",
      "offset": 2612.88,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "It's around data governance. So what",
      "offset": 2614.72,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "data are you using? Where did you get",
      "offset": 2617.04,
      "duration": 2.88
    },
    {
      "lang": "en",
      "text": "it? whether you have the right to use it",
      "offset": 2618.56,
      "duration": 3.039
    },
    {
      "lang": "en",
      "text": "or not all that's coming into question I",
      "offset": 2619.92,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "think um with everything going on right",
      "offset": 2621.599,
      "duration": 5.281
    },
    {
      "lang": "en",
      "text": "now but still do you have the right data",
      "offset": 2624.16,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "um do you have the right sort of privacy",
      "offset": 2626.88,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "and security do you have a way in which",
      "offset": 2628.72,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "you can evaluate your model how do you",
      "offset": 2630.48,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "evaluate it right some high-risk",
      "offset": 2632.88,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "applications require a different level",
      "offset": 2634.8,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "of scrutiny maybe some human uh insight",
      "offset": 2637.28,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "etc so lending systems safety",
      "offset": 2640.16,
      "duration": 5.439
    },
    {
      "lang": "en",
      "text": "applications you know etc defense you",
      "offset": 2642.72,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "know cyber security all those kinds of",
      "offset": 2645.599,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "things and so At the end of the day,",
      "offset": 2647.28,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "developers are the ones who build this.",
      "offset": 2649.92,
      "duration": 5.439
    },
    {
      "lang": "en",
      "text": "And so I'm definitely an advocate of",
      "offset": 2651.92,
      "duration": 5.679
    },
    {
      "lang": "en",
      "text": "making sure that those pillars of",
      "offset": 2655.359,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "responsible AI, which are really just",
      "offset": 2657.599,
      "duration": 3.441
    },
    {
      "lang": "en",
      "text": "development best practices are really",
      "offset": 2659.04,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "communicated because at the end of the",
      "offset": 2661.04,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "day, um it's the developers who's who",
      "offset": 2662.64,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "who's picking that model, who's building",
      "offset": 2664.8,
      "duration": 3.039
    },
    {
      "lang": "en",
      "text": "that model, that needs to be aware of",
      "offset": 2666.56,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "these practices so that you can really",
      "offset": 2667.839,
      "duration": 5.361
    },
    {
      "lang": "en",
      "text": "um sort of measure twice, cut once, if",
      "offset": 2670.56,
      "duration": 4.559
    },
    {
      "lang": "en",
      "text": "that makes sense. have a plan, have a",
      "offset": 2673.2,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "way to evaluate it, be able to do so",
      "offset": 2675.119,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "knowing that you're going to get to the",
      "offset": 2677.599,
      "duration": 2.801
    },
    {
      "lang": "en",
      "text": "right performant outcome. If you",
      "offset": 2678.8,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "leverage some of these best practices",
      "offset": 2680.4,
      "duration": 3.439
    },
    {
      "lang": "en",
      "text": "out there, you can make sure that you",
      "offset": 2681.92,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "know your your bot or whatever it is",
      "offset": 2683.839,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "you're building, you know, gets",
      "offset": 2685.68,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "redteamed, right, and doesn't say or do",
      "offset": 2687.68,
      "duration": 3.439
    },
    {
      "lang": "en",
      "text": "something inappropriate that there are",
      "offset": 2689.92,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "ways in which there you put some",
      "offset": 2691.119,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "appropriate best practices into your",
      "offset": 2692.96,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "development much like you would for",
      "offset": 2695.44,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "security, right? You don't want to leak",
      "offset": 2697.68,
      "duration": 3.679
    },
    {
      "lang": "en",
      "text": "your customers data. So, you're going to",
      "offset": 2699.76,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "build an architecture with security in",
      "offset": 2701.359,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "mind. I think of responsible um AI",
      "offset": 2702.88,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "development practices as the same thing.",
      "offset": 2705.2,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "I'd add one more thing I love that Wendy",
      "offset": 2707.04,
      "duration": 5.279
    },
    {
      "lang": "en",
      "text": "is um especially for potentially some of",
      "offset": 2709.52,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "your audience depending on how far along",
      "offset": 2712.319,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "they are in their AI journey is that",
      "offset": 2714.16,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "when you're thinking about this is do",
      "offset": 2716.24,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "some research or talk to some experts",
      "offset": 2717.92,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "like ourselves that doesn't have to just",
      "offset": 2719.52,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "be a plug for us but really there's",
      "offset": 2721.44,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "really good resources out there. There",
      "offset": 2723.76,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "are people in the industry um people",
      "offset": 2725.2,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "like ourselves who can help who have",
      "offset": 2726.96,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "seen this. Like we know what good looks",
      "offset": 2728.8,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "like. We've been there. We've done this",
      "offset": 2730.72,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "for for extremely large names named",
      "offset": 2732.72,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "companies and we've seen what helps them",
      "offset": 2735.44,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "drive success is that there's help out",
      "offset": 2738.16,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "there. You don't have to figure it all",
      "offset": 2740,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "out by yourself. Yeah. Uh certainly both",
      "offset": 2741.44,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "great ideas there. Uh I like the idea of",
      "offset": 2744.079,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "responsible AI. Uh you don't want to",
      "offset": 2746,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "expose yourself to business risks by",
      "offset": 2748.079,
      "duration": 4.481
    },
    {
      "lang": "en",
      "text": "doing something stupid. And again uh",
      "offset": 2750.079,
      "duration": 5.121
    },
    {
      "lang": "en",
      "text": "simply Duncan is like yeah you don't",
      "offset": 2752.56,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "want to do do something stupid. like",
      "offset": 2755.2,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "talk to an expert, have a think about",
      "offset": 2757.28,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "what you're doing before you just dive",
      "offset": 2758.96,
      "duration": 2.879
    },
    {
      "lang": "en",
      "text": "straight in there, which is a shame. I",
      "offset": 2760.4,
      "duration": 2.88
    },
    {
      "lang": "en",
      "text": "always hate planning. I always want to",
      "offset": 2761.839,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "dive in, but uh yeah, uh it's much more",
      "offset": 2763.28,
      "duration": 4.799
    },
    {
      "lang": "en",
      "text": "sensible to think first and then ask for",
      "offset": 2765.92,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "help if you need it. Uh so finally, uh I",
      "offset": 2768.079,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "always want recommendations for people",
      "offset": 2770.8,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "to follow. Uh so I'd love to know about",
      "offset": 2772.24,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "whose work you admire at the moment. Uh",
      "offset": 2774.64,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "who are you listening to? Um this has",
      "offset": 2776.8,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "nothing to do with AI, but I've been",
      "offset": 2778.72,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "listening to Michelle Obama a lot. So,",
      "offset": 2780.4,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "nothing to do with KI, but that's the",
      "offset": 2783.68,
      "duration": 2.96
    },
    {
      "lang": "en",
      "text": "first thing first thing that came to",
      "offset": 2785.28,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "mind. Um, go ahead, Doug. Okay. I",
      "offset": 2786.64,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "actually thought it was going to be a",
      "offset": 2789.52,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "K-pug recommendation. Yeah. I I mean, I",
      "offset": 2790.48,
      "duration": 4.639
    },
    {
      "lang": "en",
      "text": "haven't been following individuals as",
      "offset": 2793.52,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "much, but I've been following trends and",
      "offset": 2795.119,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "some of the things that I find really",
      "offset": 2796.96,
      "duration": 6.24
    },
    {
      "lang": "en",
      "text": "interesting um is the introduction of uh",
      "offset": 2798.96,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "let's call it more standard engineering",
      "offset": 2803.2,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "practices as it applies to LLM. So we",
      "offset": 2804.72,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "saw this with DeepSeek um as it came out",
      "offset": 2806.8,
      "duration": 4.559
    },
    {
      "lang": "en",
      "text": "where they took an approach of different",
      "offset": 2809.2,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "innovative not even necessarily super",
      "offset": 2811.359,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "innovative ways but instead of making",
      "offset": 2813.28,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "the the goal how do we make the biggest",
      "offset": 2815.359,
      "duration": 3.441
    },
    {
      "lang": "en",
      "text": "model how do we make it the most",
      "offset": 2817.359,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "efficient model and seeing different",
      "offset": 2818.8,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "ways to tackle that problem that's been",
      "offset": 2821.359,
      "duration": 4.881
    },
    {
      "lang": "en",
      "text": "super fascinating to me um as I nerd out",
      "offset": 2823.92,
      "duration": 3.679
    },
    {
      "lang": "en",
      "text": "in that space.",
      "offset": 2826.24,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "And I I have a serious answer actually.",
      "offset": 2827.599,
      "duration": 4.641
    },
    {
      "lang": "en",
      "text": "Uh I Michelle is the first one that came",
      "offset": 2830.24,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "to mind, but um Andreas Carpathy he does",
      "offset": 2832.24,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "a great set of series. I think anybody",
      "offset": 2835.76,
      "duration": 4.559
    },
    {
      "lang": "en",
      "text": "who is really trying to understand more",
      "offset": 2838.24,
      "duration": 4.879
    },
    {
      "lang": "en",
      "text": "about AI, the technical concepts of AI.",
      "offset": 2840.319,
      "duration": 5.601
    },
    {
      "lang": "en",
      "text": "Um he's I would subscribe to his YouTube",
      "offset": 2843.119,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "channel. It's excellent. Yeah. uh both",
      "offset": 2845.92,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "Michelle Obama and Andre Alpathy",
      "offset": 2847.839,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "definitely great speakers although on uh",
      "offset": 2850,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "very different topics and yeah uh there",
      "offset": 2851.76,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "are a lot of uh amazing foundation model",
      "offset": 2854,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "researchers uh speaking about their work",
      "offset": 2856.4,
      "duration": 3.439
    },
    {
      "lang": "en",
      "text": "as well and I do like the idea of uh",
      "offset": 2858.16,
      "duration": 3.439
    },
    {
      "lang": "en",
      "text": "making things uh more efficient saving",
      "offset": 2859.839,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "money but uh on that note uh I think we",
      "offset": 2861.599,
      "duration": 5.921
    },
    {
      "lang": "en",
      "text": "have to uh stop now uh so yeah thank you",
      "offset": 2864.24,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "both thanks Richie",
      "offset": 2867.52,
      "duration": 21.55
    },
    {
      "lang": "en",
      "text": "[Music]",
      "offset": 2869.12,
      "duration": 19.95
    }
  ],
  "cleanText": "Welcome to DataFramed.\nThis is Richie.\n\nThere are now many great AI models that perform well off the shelf, but for some business or scientific use cases, performance is still lacking.\nBehind every great model is a great data set.\nAnd if you want your computer vision model to reliably detect your product or you want your call center AI to reliably answer support questions that your customers care about, then you're going to have to provide your AI with your business data.\nToday we're looking at the process of collecting and enriching your data, then feeding it to your AI for better performance.\nI also want to know about the data annotation workers who are the hidden stars of the AI revolution.\nI have two guests for you from the data annotation and model evaluation company, Sama.\nWendy Gonzalez is steering the ship as CEO, having moved into the role from COO.\nShe joined Sama from a background as a product lead at an IoT startup and she's also spent time as a management consultant with stints at EY and Capgemini.\nIn 2023, Wendy made Women Tech Networks 100 executive women in tech to watch list.\nDuncan Curtis is senior VP of product and technology.\nHe's got 15 years experience as a product manager, having previously run Google Play games and also products at Zuks and Aptive.\nLet's find out how to make great data sets for your AI.\nLarge language models are really good at getting generic answers right.\nHowever, when it comes down to actually doing what we do in our day-to-day businesses, often requires much more specialized knowledge.\nSo, we've moved almost 70,000 people out of poverty since we have started this company.\nWhat we do is we have an impact hiring model where we hire on the basis of impact.\n\nHi there Wendy and Duncan.\nWelcome to the show.\nThank you.\nGlad to be here.\nBrilliant.\nSo there are a lot of really great foundation large language models.\nSo why do you need to use your own data rather than just an off-the-shelf model?\nLarge language models are really good at getting generic answers right.\nAnd so they've been trained on a very large corpus of data across the internet or a large portion of it.\nHowever, when it comes down to actually doing what we do in our day-to-day businesses, it often requires much more specialized knowledge.\nAnd so what we find is that while models are really great for things like writing an email that's a generic email, it might actually really struggle if you wanted to do something within a specific domain like referencing law or referencing, you know, HR policies or even better, what about referencing your own internal documents.\nSo if you wanted to write an email out to your employees, but oh wait, I need to make sure that it actually, you know, follows our policies.\nThat's not going to be as easy to do with a generic model.\nWe do see people doing something that's called distillation of models.\nSo often when you see large language models come out you hear like oh you know Chad GBT4.1 has just landed on Monday.\nBut they also release smaller versions.\nAnd the reason they release smaller versions is they take that big model and they eliminate certain parts of it to try to keep to get that model smaller but to try to retain as much of that bigger information.\nAnd the reason you want it smaller is because you want it to be faster.\nSo, when you're actually more real-time chat, but you also want it to be cheaper to run and be able to run more on cheaper hardware.\nSo, that's hope that answers your question.\nOkay.\nSo, that makes a lot of sense.\nIf you're doing something that's a little bit out of the ordinary, not a generic question in some sense, then that's when you're going to want to use your own data or get some domain specific data.\nMaybe we can dig into some of these ways making your models faster and cheaper because both those things are quite useful as well.\nUh so, yeah.\nUh we'll get into that later perhaps.\nUm all right so I would love some concrete examples.\nUh do you have any real examples of where a company's trained or they've made use of data enrichment to improve their own model and make things better?\nYeah, absolutely.\nSo a great example would be we were working with a company in the HR space and so one of the things they wanted to do was train a model to be able to understand what was in job applicants resumes.\nSo they had some matching that they wanted to do where they had let's call it I think it was somewhere in the like 180 sort of skills that they wanted to tie to people's resumes but in those regimes you call different skills a lot of things.\nSo let's say let's say executive presentations might be the the tag that they wanted to use but that in might appear in someone's resume as anything from presented to the board regularly present to you know my executive team it might be speaks at conferences and so what we would do in that case is enrich a set of rums with getting those different examples within rums and and aligning them with that taxonomy that that list that they had and then they can use that to train an AI or to to basically find new instances of that moving forward.\nAh okay.\nUh so this is one of those high-risk use cases.\nI know certainly under the EU AI act any kind of HR like AI use cases is considered high risk because there's a risk of discrimination happening there.\nSo by the way you've got to be really really sure that the AI is highly accurate.\nAnd it's not just highly accurate.\nI completely agree with you.\nIt's also not biased.\nI mean, we've seen things in the past where I think it was there was some very public ones where it turned out that AI had been trained on what previous good applicants looked like and it was extremely biased to people of color.\nAnd so it was quite unfortunate that the way that that model training was designed inherently picked up a set of bias there.\nAnd so one of the things that we do not just when we're enriching data but as we're going through that process is that we also work with our clients to show them the distribution of their data.\nSo you know in in something like a self-driving car case it might be as easy as saying hey yes you've got a million vehicles but you only got 200 motorcycles you really let's find some more motorcycles within your data or you can collect some more so that you can represent motorcycles.\nWell, now in the HR use case, it might be, hi, you don't have a good representation of gender.\nYou don't have a good representation of educational background.\nAre we biasing towards particular schools because we're seeing this as, you know, is your training data set up in that way?\nUm, so we can we help with that as well for our clients.\nYeah, certainly.\nEven just crunching some numbers on what are the distribution of the outputs, that's going to give you a lot of transparency on what's the model doing, are you being fair in general?\nUm if you're making your own model or at least modifying your own AI does that it sounds like it's quite an intensive process.\nSo I'm wondering is this just something for big businesses or can anyone do this?\nUh maybe Wendy can you talk me through which industries or business types are making use of this?\nYeah.\nSo I mean for a lot of enterprises they're leveraging these foundation models.\nIt doesn't make sense to build your own.\nYou know, billions of dollars, lots of GPUs, lots of cloud computing.\nIt makes no sense.\nThey're really advanced.\nYou can find a way to apply them to your own use cases and as Duncan said, do things like rag embeddings which allow you to train the model on, you know, your own proprietary data for the right application.\nSo, there's a lot that's happening there.\nBut then in some cases, your business, you know, it may be so core to your business.\nSo, some easy examples are self-driving cars.\nIt is core to the hardware in your vehicle, the cameras, the sensors, and the placement.\nSo, a lot of companies are building their own or, you know, they might be leveraging, for example, like Nvidia's platform, but they're still ultimately taking the time to build it because it's part of the hardware integration.\nSome cases, yep, companies are still building it or another example might be things like e-commerce, right?\nSo, if you're going online, your product catalog is key.\nThe ability to search for products and to do some of the data enrichment that Duncan had just mentioned so that your products are searchable and you can recommend things appropriately.\nThat's an another example to where it's so core to the business of actually selling the product that um even if you might be leveraging some models, a lot of companies are choosing to to make those investments themselves as well.\nI think a good example there would be say ThreadUp.\nUm so recently we were at a conference called Shop Talk and there was a great presentation by a company called Thread Up who um basically had allows secondhand clothes to be sold.\nSo their product catalog each item is one each item is a unique skew.\nYes, they do have categories but I think it was when was it Kendrick Lamar at the Super Bowl.\nSo it ended up with flared jeans and everyone was like oh my god this is amazing and a new trend again.\nBut they they're using AI in a really interesting way because they and their problem is different to what you were mentioning in really large businesses where they have a unique issue where each item is being uploaded in its custom and so looking at how they can match those and having an efficient system of data enrichment as well as AI to to help with that data enrichment as a first pass is really important to their um product and user experience straight out of the kit.\nOkay.\nSo those are quite wildly different use cases.\nUh certainly I can see how a self-driving car you don't want to be sending your video data to chat GBT and saying well should I turn now uh yeah it's going to be a terrible thing.\nUh so uh you want to build your own solution but uh the retail example also yeah I can see how you got loads of different products and you need to have I guess product descriptions for everything.\nYou got to have photos for everything and assistants there just managing or generating content.\nI'd like to know a bit more about what data enrichment involves because I guess in my mind it's like the sort of Amazon Turk type situations where you got a lot of people just staring at photos and writing descriptions of them.\nHow accurate is that?\nWell, data annotation.\nSo data annotation um and enrichment it's really about tagging basically or enhancing unstructured data.\nOkay, so it could be visual data, it could be text data, it's about adding additional attributes.\nAnd the reason why that's important is number one, you either are training a model to perform in some way.\nSo a self-driving car is pretty clear.\nYou need to recognize lanes.\nYou need to recognize traffic signs.\nYou need to recognize pedestrians and other vehicles to operate the to to do things like collision avoidance.\nIt also can be used to validate that your model's performing properly.\nOkay, so you you need to know what does good look like, how is your model performing against what the expectations are.\nAnd so that's really what data data annotation is about.\nAnd oftentimes in a number of cases, it's not just about capturing the right sort of class or the right descriptions.\nIt can be enriching that data.\nSo I think a good example of this just to kind of take the parallel from the retail example is think of like Spotify or think of like Apple Music, right?\nSo they had to basically build a genome of what is music and there are a lot of attributes, right?\nI mean, this is where I suddenly realize when we're talking about all the different descriptions of like, you know, K-punk, you know, I I wouldn't even know what K-punk was like 10 years, you know, like 2 years ago, probably as an example, but there there are so many different genres.\nAnd then you from the the song itself, the, you know, the the AI needs to say, &quot;Hey, where does it fit?&quot;\nAnd it's it's literally G.\nI mean, there may be like 50 or 100 different attributes that can make something be a K-punk versus a K metal versus a K-pop type of song, right?\nProduct cataloges run very similarly.\nDifferent products, lots of attributes.\nSo, when it comes to um being able to to search, you know, recommend um identify to allow the AI to really perform as as optimal as possible, you need to not only tag it, but often times you need to enrich it.\nOkay.\nYeah.\nSo, uh, it's not just writing descriptions.\nIt's about, I guess, feature engineering stuff on Yeah, certainly with music.\nOkay.\nUh, you've got the people who are in the band and I guess the instruments they're playing and there's probably some kind of chord progressions and tempos and, uh, yeah, this could very easily become a very complex modeling situation.\nJust have subtle differences between genres.\nAnd it's interesting because like when the reason you want to have this depth of attributes or genome as as Wendy was pointing out is because it allows that search relevance or that recommendation the the end use case to be so much more personalized.\nWhereas if you just said you know if you just started with oh it's music and it's K-punk and that's it and that's all you had about it.\nIt's you don't it makes it a lot harder for that next recommendation of a really great song to find its way to a listener or for a really great product that's going to fit a need for someone um or for products to be matched near near each other or shown together.\nIt um really powers a lot of that ROI I'm going to say for the user experience where getting good ads is like or good recommendations is such a better experience than getting just something random or something near what you were looking for.\nYeah.\nAnd bottom line, it increases, you know, cart sizes and purchases online.\nSo, it's core core part of it.\nAnd that's really where we typically see AI being implemented is if it's going to make a core differentiation in your product or it's going to help you save money.\nOh, absolutely.\nI have to say uh a lot of the streaming music websites do this incredibly well.\nBut for many retail websites, absolutely terrible.\nSo, the experience of searching something, you're like, well, I know what I want.\nI can't see it in the results.\nAnd so yeah, I can see this is incredibly important and a lot of shopping websites really need to take note.\nSo hopefully anyone in the audience working on a website.\nYep.\nBetter search is a good thing.\nSuppose you're interested in this.\nUm I guess to start you need to find yourself a data set.\nSo where does the data come from?\nUm if you decide you want to get some data to feed into your\n\n\nOwn model.\nWhat do you do?\nData can come from so many places.\nUm, so let's say, uh, if I was taking a retail example, a lot of that information is going to be already there.\nSo it's the product catalog of all the images and descriptions that your vendors have uploaded.\nAnd so you've now got access to that data, and you can enrich it from there.\nIf we're talking about something like self-driving cars, you need to actually have a fleet of vehicles.\nYou need to put cameras and LARS on them and drive them around and actually record data.\nBut there's also that's so that's for the raw data um collection.\nBut I think we should also touch a little bit on um what kind of mix of synthetic data can also be part of your AI solution.\nWhen we look at how models are being developed, especially even the large language models, we're now seeing synthetic data from the generation before being a large portion of the training data for the next generation.\nUm because as the data needs are exploding in terms of they're running out of the internet to continue to scrape, and so they're generating more more content, more specific content from, you know, if you take for example, uh, with llama 4 out, llama 3 actually produced a large portion of the training data for llama 4.\nAnd so you can see, and if I, if we go to self-driving cars, for example, being able to generate um using top-of-the-line game engines or custom, like if you think of, if you think of the movies and video games, the top-of-the-line ones we have today, are photo realistic.\nAnd so they're able to use those technologies to also simulate uh um more hours of driving and see how the vehicle um can react there.\nSame with your product catalog is that you might have, you might be going into a new category that you do not actually have information on.\nYou can actually create synthetic data from, you know, image generation as well as product catalog description.\nYou can actually build a syn synthetic data pipeline um in order to be able to have new training data, let's say ahead of a new category that you're going to have on your website.\nAnd so the funny thing about synthetic data though is that you have to be careful, like what we were talking about before, is taking inherent bias into your model.\nAnd so it's really important to have your synthetic data validated.\nWendy, do you want to talk a little bit about um some of the was there?\nYeah, I, I was, I was going to actually just touch on the the exact same thing that you, you can leverage a model to train a model, but that model training a model could carry forward biases from the previous model.\nSo, at the end of the day, you still have to know what good looks like, you still have to know how you evaluate your model, and even if you're leveraging something like synthetic data, is it in context?\nYou know, is it realistic?\nIs it achieving?\nSo, number one, you have to say, hey, what is I'm trying to build in terms of my data set?\nWhat's missing?\nWhat can synthetic data support?\nThen second is that synthetic data going to be of the quality that we expect it to be.\nSo what happens often times, especially in like image generation?\nYou might like have a phone, but maybe it's floating exactly one centimeter above the table, right?\nThere are these things that, you know, it is not perfect.\nUm, and at the end of the day, the quality of the data is what matters most.\nWhether it is captured or synthetic or generated by a model, you still need to know how do I evaluate it?\nIs it accurate?\nOkay, that makes a lot of sense.\nSo if there are cases where you don't have good real data or it's very expensive to collect, then yeah, uh, I think uh, that's going to be incredibly useful.\nI heard a case a while ago, it was from the US Air Force, where they were trying to train their drones to do something, and they said, well, we only ever fly drones during the day, so we don't have any data on how well they perform at night.\nUh, so they had to deep fake nighttime flying in order to generate a data set that they could then train on.\nUh, yeah, I, I like that idea.\nCertainly, I can see how if you're generating garbage quality data from a model, feeding that into another model, it's just got worse and worse and worse, and that's not going to benefit anyone.\nYeah, it's like a copy of a copy kind of a a scenario.\nAnd um we see it, uh, synthetic data has has has good good uses or great uses in edge cases.\nSo imagine like nobody wants to realtime capture, you know, a stroller in the street or an empty stroller or stroller with a baby in it, or I heard one actually from a from an auto company client where they're like, you wouldn't think of this, but sometimes hogs like drop out of the sky and get in front of vehicles.\nThat's probably not something you're ever going to catch.\nIt has happened before.\nUm, it's probably not something you're going to catch uh, you know, in any regular real life.\nSo, it's a great example of some edge cases where it's like, okay, synthetic data makes total sense.\nOkay, that feels like a very Texas scenario somehow.\nUh, yeah.\nUh, I can see how it's going be very hard to create that kind of real uh that data in real life.\nUh, but uh, yeah, you might need to deal with it at some point.\nSo, it's important to have a data set.\nSo, suppose you've got your data, uh, some of it synthetic, some of it's real.\nWhat next?\nUm, I guess you have to choose a model to enrich.\nYeah, there's some some really good benchmarks out there.\nUm, but one of the really nice things about where we're at today is that it's actually very easy to just try a model out.\nAnd so being able to pick the right model for your use case can be as simple as actually running through a bunch of tasks or of the the type you want and seeing what the performance of those base models are.\nYou know, for example, Claude is extremely good at language um writing emails and writing personalized responses.\nIt it's a really it it far outperforms others even ignoring the benchmarking.\nUm uh it's sorry even more so than the benchmarking would would uh would show for example.\nAnd so what it really comes down to is test out the existing models for your use case and see how it feels because at the end of the day this is a almost all of these come down to a customer experience.\nUm at for a lot a lot of these, and so being able to get those intangible human elements of that sounds right, that sounds better, that's not messing up in this way, also set up a uh before you begin, you should also set up how you want to assess these, and so if you're doing a like an image detection model and you wanted to start with something like YOLO off the shelf, great, you can also, you can start with your metrics being like, oh, okay, well, I care about, do I care more about accurately detecting everything all the time and I'm okay with detecting some things that are the wrong things, or is this case actually it's really more, it's okay if I miss some things, but I should only detect the thing that is the problem that I'm looking for, so you can set up those uh metrics for yourself before you uh begin your investigation.\nYeah, I, I like to just to tack on to that one thing I share often with people are kind of contemplating, well, which model should I use is models change all the time, okay?\n4.5 just came out, right?\nAnd there's going to be something that comes out in another two weeks and probably an open source version of it or an openweight version of it, I should say, it'll happen.\nUm, and uh, the one content though is model evaluation, you have to know what are you trying to achieve with your model, what are the right outputs that I'm expecting, what are the appropriate parameters, and then the, you know, the models are like widgets, they could come and go, and what we're seeing actually a lot more is that companies are looking for flexibility, they know that there may be a next better thing that's coming out, so how do I ensure that, you know, I have the appropriate sort of um, you know, forward and backwards compatibility and an ability to to swap something out if something better comes along, which it inevitably will.\nProbably already has today.\nYou know, they're coming out like every single day, literally.\nThat's useful to know that you need to bear in mind that you're probably going to uh swap out your model at some point, probably fairly regularly.\nBut there's so many models around, it's relatively easy to try different things.\nI guess the trick is just uh make sure you got something like some measure of how good it is, so if you swap it out, you're not going to make things worse accidentally.\nYou can have a way of measuring is this going to be better on whatever the use case is.\nYes.\nYes.\nEspecially as you know models get more uh because it's all about cost, right?\nSo certain models can be cheaper to run as the technology improves, that's going to be a constant evaluation, just like people think of like cloud optimization, you know, similar kind of concept is it's always going to be evaluated for for the ROI and the cost.\nOkay.\nYeah.\nAnd I guess here we're mostly thinking about the inference cost.\nUm, is that the primary expense here?\nYeah, gen, that'll be your primary, your primary cost there, which is as I was saying earlier, one of the reasons people choose smaller models, and for example, you might need a larger model, like, you know, you might be up in the several hundred billion parameters at the moment, uh, like with your use case, and then something like a deep seat comes along or, you know, two or three generations later, you can actually get away with a 10 billion parameter because it's more specific or it's more, you know, um, and so you could really drop your inference costs over time.\nI guess if you have more specific data, is that also going to allow you to use a smaller model compared to having a general purpose one?\nLike do you need a larger general purpose model compared to a smaller more targeted model to get the same accuracy?\nThat's a really good question.\nI think the size of model generally relates to the capability level, the general capabilities you need.\nSo if you just need it to kind of know how to how to talk and how to think about the world, okay, you can go smaller.\nAnd the other side of that is when you said is your data really specific, I would look at it more as is the data you have or can create or you know, as we talked about before, does it really encompass the the entirety of your problem?\nSo if I took took an HR example, um, is that maybe I'm doing that regime rime piece where I'm just matching key words to a taxonomy, but do I need my model to do more about understanding the the maybe the history of someone or I need it to understand all the different educational institutions in the world, is that really captured within the data set that I've got or how much am I relying on the LLM or the AI model to have that general understanding there.\nSo I would say the more complete your data, your data is for your problem, another way you can also go generally smaller.\nOkay.\nSo this sounds like it's be something a lot of people might fall over because there's very subtle differences in questions.\nWhat university did this person go to is very different from is this a good university?\nWas it a good university at this particular time?\nAt that time.\nYeah.\nI mean, wow.\nAnd it's something that you could create or or have that data available as part of the the models or what the model has access to.\nOr you could be like, hey, and do you want your model going and checking the internet every time that it's doing a, you know, a check here?\nThat inference cost can go much higher if you need to check each university, each resume that you're looking for um to go figure that out at the same time, which is just interesting to think about the cost.\nAbsolutely.\nOkay.\nUh, so I guess the last step is how do you combine all your own custom data with the LLM?\nSo I know there are a few techniques for this.\nI mean the simplest thing is just use retrieval augmented generation, RAG, and there are fine tuning options and a bunch of other techniques.\nSo when do you choose each of the different options to combine your data with the LLM or other AI?\nYeah.\nSo I mean with things more like a like with simpler models, like say if you were using a vision detection from like YOLO or something like that, it can be very cheap for you to actually add that data and do a retraining or a fine tuning of the model.\nBut when we're getting up into that LLM space is that it's fine-tuning is probably not the right term um as people think about it more from the sort of like traditional uh like CV vision models.\nIt's much more about how do you give the model the right context and the right access to the right data.\nSo more in that sort of rag kind of approach where you're like, okay, here's my document storage, and even for some use cases, it can even with the larger context windows we're seeing now, I'm we're actually seeing some clients that are able to incorporate the data that the model needs into the into the prompt at inference time, depending once again depending on how large the data set size is.\nSo you those are the two common ways that we've been seeing for smaller problems that that only require like a few documents worth for context versus ones where you're like, no, I've got millions of images that need to be or millions of documents that need to be included um and or or are regularly changing.\nThat's one of the other advantages of a of a rag system is not having a fixed like it's stopped at a point in time.\nYou can update the data sources as um as the world evolves and you can keep your model uh continuing to perform there.\nYeah, we we see, I mean, rag embeddings is definitely I think the predominant the predominant approach.\nI I just I say that because supervised fine-tuning for one models change all the time, right?\nSo as soon as you choose to fine-tune a model, it kind of limits your ability to transition to another model.\nThe second component is that it takes a decent amount of expertise, right?\nAnd a lot of these models are, you know, they're open weight or they're they're closed, right?\nYou you don't really know what's happening in the background to really understand those models and have the expertise to fine-tune it.\nIn addition to the fact that um it makes a little bit harder to swap out or you might be losing some sort of ROI in terms of being able to transition to another model.\nUm, we're seeing that rag and and prompts like Duncan was saying is really the most predominant way most companies are thinking about it now.\nSo, going back to your ThreadUp example where anytime someone uploads a new clothing item, you don't have to completely retune your model.\nSo, you say, &quot;Okay, I just want to add it to a data store and then that's done.&quot;\nYeah.\nJust pull it in.\nExactly.\nAll right.\nCool.\nSo um from that I guess the other big thing is how much can you just leave these models to just go and do\n\n\nSo, when do you need a human involved?\nSo, what can you automate and what can't you automate in these situations?\nI think automation is a really interesting topic.\nI think that automation should always be, you should always ask yourself the question, what can I automate and start with automation as your first place.\nWhat you then should be asking yourself is, where do I definitely need humans involved here?\nWhether that's on the data enrichment side, whether that's checking the synthetic data quality, whether it's also in an ongoing manner.\nSo, one of the things that we found, you kind of mentioned that, how much can you just let them go?\nAnd with the rate of change that we see in the world and the data sets for people is that having an ongoing model evaluation or validation in an ongoing nature is a really great way to be able to continue to keep your model performing at a very high rate.\nLet's take, say, Thread Up as an example.\nIf as fashion, maybe their models are performing extremely well now, but maybe they weren't actually that great at the...\nSorry, what were the type of jeans again?\nThey were the flare jeans.\nFlare jeans.\nMaybe flare jeans actually wasn't something their model was actually performing particularly well at, but it's become a really popular thing because of because of that Super Bowl halftime song.\nAnd so what you could detect on an ongoing basis is, hey, what are the most popular categories people are looking for, searching for, and are we doing well at that data?\nSo, having a set of humans who can actually, on a regular basis, plug into how your use case and how it's evolving and check that and see that the model's performing, and then being able to do something with that response, like, actually, it's not performing really well.\nOkay, well, let's make sure that we go look at some of the data for flare jeans and actually go and enrich that, and great, now the model's back up to performing.\nSo, we see it more as an ongoing process because once you've found that business value, that sort of like, hey, this is actually really valuable to customers.\nIt's, you know, increasing my cart size.\nIt's, you know, lowering cart abandonment, whatever the business value you're gaining there, you've got to ask yourself for each percentage of performance in that model, what's it going to cost me?\nIf am I willing to accept 5% less, 10% less, where 1% like, does each percent mean you like a million a year in difference or $10 million, depending on the scale of the company?\nAnd so then you can offset that with keeping, having that human model validation occurring.\nYeah, keeping, I mean, that's really the key is these AI models, they're experimental as well.\nNot only do they learn, you know, there are new edge cases, new data that comes up, like flare jeans or like whatever the, you know, the the the latest and greatest current trend or event is, but beyond that, it learns something from that.\nYou need to make sure it doesn't go off pieced.\nSo, model evaluation is really important because data is constantly changing, and you need to know, is it still performing as we expected it to perform?\nAnother example to think of, a simple one, is like the self-driving car.\nYou may have a car that works really, really well in, you know, Pacific Highway 101 here in California, but you take that, you put it into, you know, Rio de Janeiro, where you also have coastline and, and, you know, roads, and maybe it doesn't do so well, and plus, it doesn't really understand Portuguese or doesn't understand the types of the cars.\nSo, there are is going to be edge case data that's going to be important, and given that these technologies are global, like, that's kind of the trick.\nSo, like an agriculture example that is, you know, like wheat in Kenya looks different than wheat in Russia.\nYou can't just assume that the model that's been trained right is knows what the differences are.\nAnd that's the thing about these models is that, yes, they're trained on the entire corpus of the internet.\nBut does anybody believe the internet is either unbiased or has every single piece of data on it for every application?\nRight.\nSo, that's the other way to think of it.\nI'd also mention, Wendy, that we think about automation in the same way as well.\nWhile we're focusing on that human validation element, we actually, we have automation that's built into our processes as well.\nSo, if we were, if we take that Thread Up example, is that if we were doing data validation and saying, hey, do we have the right category for for the for this new product item, is that we're not just going to sit there and have someone go, okay, let me look at the entire list of 10,000 options for where for what category this could be.\nNo, we will introduce it.\nWe have an LLM at the beginning saying, hey, I think it's one of these three categories.\nAnd that allows us to capture that human insight in the most efficient way possible.\nAnd so that's how we really think about sort of human in the loop in automation.\nOkay.\nUh, that certainly makes a lot of sense.\nIf you've got severe consequences when the AI makes a mistake, then you're going to need to, well, you probably need to have both things.\nSo, you're going to need to have a software monitoring tool that says, okay, the AI has done something wrong.\nAnd then you're going to have to have humans in as well just to make a decision on what to do next.\nUh, verify that there really has been a problem with your AI.\nI'd like to know a bit about how you go about implementing these things.\nSo, suppose you say, okay, we need to have our own custom systems.\nWe're going to use our own data in an AI.\nUh, first of all, who tends to be in charge of these projects?\nIs it going to be what?\nChief technology officer, chief AI officer, chief data officer?\nUm, who tends to run this sort of thing?\nYeah, it generally comes from the top down in terms of how the need for the business to say, like, hey, we need to be further ahead in AI.\nIt's a very common thing that we're hearing, and I'm sure a lot of the audience are like, my boss or my board is telling me, like, why are you not using more AI?\nThat's generally where it initially comes from.\nBut in terms of those running the projects, it goes down the chain where you do, we do see a much more prevalent set of like a chief AI officer as a much more common title.\nNow, we're seeing that it then goes down to sort of like your directors of engineering or a director of product who may have a particular surface area or part of a product or service that they manage.\nAnd that's when the project starts becoming more real because you've actually got people who are, you know, partially, if not directly responsible for the P&L of a particular area, and they're like, great, okay, I know what I need to move from a business perspective.\nI have a target area because I know that, you know, let's say it was Thread Up, for example, it could be something where you've got, okay, well, I'm in the recommendations team, okay, well, I know that our recommendations are performing like this, and I needed to perform at a different level.\nOkay, now I can get in and start saying, well, let's, let's try to address this with AI.\nWhat kind of model, what kind of data are we going to need?\nOh, wait.\nI need human enrichment.\nUh, I should probably, you know, reach out to Sama.\nYeah.\nAnd and with the fact that make AI easier to adopt, we're seeing also a bit a bit more on the business side.\nSo, it's not unusual for a head of customer experience to say, hey, how am I going to integrate, you know, chatbot omni channel experience, right?\nSo, before you might experience reaching out.\nYeah, I think it's very true that stuff like this tends to start right at the top of the business.\nSo, yeah, there's always a CEO going, yes, let's have more AI, and then it has to filter down to all the different departments, and yeah, I guess a lot of different departments end up having to contribute in some way.\nI'd like to talk a little bit about Sama itself.\nUh, I know you have B Corp status.\nSo, uh, just for the international audience, uh, can you explain what is a B Corp and just tell us why did you choose this approach?\nUh, Wendy, do you want to take this one?\nYeah.\nYeah.\nSo, a B Corp stands for benefit corporation.\nSo, as we are a public benefit corporation, and it's basically a designation that states that a company has both a profit purpose, right?\nBut also a social or environmental purpose as well.\nOkay.\nSo, means that you can do, it's the double bottom line or the triple bottom line.\nB Corp and the B Corp certification group is basically the best globally known standard for how you evaluate companies who have purpose and profit.\nUm, and so we are B Corp, but they have a really rigorous evaluation process that is based off of the United Nations sustainable development goals, and um, in our case, we are really focused on workers and impact.\nSo, part of our our core social mission is to bring people from underserved communities into the digital economy by providing them not only training but full-time employment, not on the basis of just their, you know, their work experience or their resume, but on the basis of their impact, and then we provide the upskilling and training.\nSo, actually, that sounds pretty wonderful.\nI do like that you have a social mission.\nSo, uh, can you describe some of the positive impacts you've had so far?\nYeah, definitely, we're super proud of this.\nSo, we've moved almost 70,000 people out of poverty since we have started this company, and what we do is we have an impact hiring model where we hire on the basis of impact.\nSo, that means household incomes that fall below the World Bank poverty standard.\nReally, the key here is that there's so many talented people, lots of just incredibly talented people, but they lack the opportunity, and so Sama means equal in Sanskrit.\nWe are really just trying to level the playing field by providing job opportunities to people who would have huge barriers otherwise, but they're still really talented.\nSo, we open the door, but our great and talented workforce is the ones who walk through it.\nThat's very cool.\nUm, and do you want to describe some of the jobs that these people are doing?\nUh, yes.\nSo, we're doing a lot in the data annotation validation space, data insights, but I'll give a couple of examples.\nSo, we have people who are helping um, do annotation for self-driving cars.\nSo, that could be, you know, complex sensor fusion, 3D LAR and 2D data to help detect, you know, vulnerable road users or traffic signs.\nAnd it sounds fairly simple, but it's not.\nI, I would actually challenge anybody to try to run some of these.\nIt requires, you know, depth perception, like lots of, you know, complex taxonomy.\nIn other cases, we're doing validation.\nSo, an example that Duncan was using earlier is, uh, you are building, you know, you, you, you're, you have a retail application, you have images, but the images that were provided by your, you know, individual, you know, small business, don't include any descriptions, an LLM autogenerates the description, but it's written out of context or has weird grammar, or it's not exactly accurate, it's chartreuse instead of green, or, you know, examples like that, and so human loop might be there to help validate the the reasoning, the context, the accuracy.\nAnd then they're also doing things really intelligently.\nSo, it's not just about, um, okay, let's annotate this or annotate this edge case, but it could be the evaluation of the data set.\nUm, so Duncan's example of, hey, there are not enough motorcycles, or we've noticed that there's a really common failure point with your model.\nIt always fails when it sees, you know, a red, I don't know, vehicle.\nI'm making that up.\nBut the idea is that they're evaluating, understanding the data, then providing insights back to our clients on how they can improve the accuracy of their models.\nYeah.\nSo, I do feel like these are the unsung heroes of AI.\nUh, so because you got all these sort of rockstar AI researchers earning a fortune, but then actually in terms of model quality, just getting correctly annotated data in the background is incredibly important.\nUh, probably has an equal impact, I think.\nUh, absolutely.\nI mean, it is still true to this date.\nIt really is garbage in, garbage out.\nLike, data is king.\nYou have to make sure you're using the right data and that data is valid.\nThat's that's the entire goal behind the social mission is there's a lot of business value that's being created.\nWant to create a lot of employment at living wages along the way and let let a larger group of people participate in the effects of the digital economy.\nAll right.\nWonderful.\nUh, so actually, I have a tricky question, uh, because this is the one issue we tend to skirt around a lot when we talk about AI, since you're running a socially conscious company.\nI wanted to ask you about it.\nA lot of AI, particularly generative AI, is incredibly energy intensive.\nSo, there's this trade-off between do we go all in on AI and just kind of burn the world, or how do you deal with that?\nUm, do you want to talk me through how you think about these energy problems at Sama?\nYeah, it's really interesting.\nUm, we, we all, we also are actually part of the science space climate action.\nSo, we have a, we have a sustainability objective as well, and we're carbon neutral in all of our North American offices, and uh, we are working towards that with our locations in East Africa as well, um, and and tracking and measuring that too.\nIt is really interesting as you can see the largest tech companies, right, the hyperscalers are literally doing things like buying three mile island and building data centers in billions, and we got some pretty interesting data points that uh, you know, even the the average price of, you know, of utilities and energy is actually affected the average person in Ireland because there is so much energy that's being used because so many tech companies are based in that area.\nSo, I think it's an under discussed topic, um, that is something that should deserves more because at the end of the day, the more sort of commoditized and lower the cost the AI is going to, you know, it takes to be to be built, right?\nSo, you know, the GPUs are going to get cheaper, they're going to get smarter, and yes, they'll use less energy, but what happens on the flip side is that adoption goes up.\nWhat was the first thing Amazon says?\nThey said, we're going to, you know, be building more in terms of cloud computing, and we need more energy, right?\nBecause a lot more people will end up leveraging AI.\nSo, I, I don't know that I have a good, like, hey, what do, what do we do to manage this challenge?\nI think it is something though that needs to be really raised because at the end of the day, a lot of people believe, and I believe too, that, you know, economies are going to be driven by how how intelligent people\n\n\nAre at AI, right?\nHow these countries are at AI.\nIf you don't have a policy or view on how you're going to be leveraging it, it will, you know, it will and is contributing to the, you know, climate crisis we already have.\nYeah.\nUh, I kind of agree with you on this.\nThere's probably no easy solutions at all, but I do like the idea that legislators um need to start thinking about this.\nAnd I guess any companies that are using this also need to think about what they're doing.\nYeah.\nYeah.\nAnd and some are, you know, I think some come, you know, some some have really clearly stated kind of net zero approaches.\nAnd so I think, you know, it's especially in this day and age, it's I think we're be hardressed to see regulation being, at least here in the US, a a top priority.\nBut I do think the, you know, the notion of both standards and, you know, talking about it is going to be important because then each company can choose to take their own, you know, actions towards this.\nSo there was a lot of really here here's a challenge I should say with not having any policy or regulation is we saw the leaps forward in green technology take place when California set some really important emission standards right and then all of a sudden everybody's motivated to think really intelligently about green technology.\nI think there is a role for for policy to be to uh to play in this whether will happen you know in the next few years here pro maybe not maybe not here in the US.\nUm, but I think it's a very important consideration and we're seeing some companies lead the way.\nThey're really challenging um to get net zero and challenging their suppliers like us to get net zero.\nUh yeah, I like the idea that uh just one part of the world needs to come up with some regulations and then it provides inspiration for the other parts of the world.\nBut yeah, uh maybe this feels like a whole separate episode.\nIt probably is.\nSo, uh yeah, the audience has to watch this space.\nUh we'll see what we can do.\nAll right.\nSo uh just to wrap up, do you have any final advice for companies who are interested in doing data enrichment?\nOne of the things we haven't um discussed but I I think we've been discussing components of it is this notion of responsible AI and responsible AI isn't the same thing as like ethical AI.\nWhat it means is it's really have you built the AI in a responsible way and it's typically around four different pillars.\nIt's around data governance.\nSo what data are you using?\nWhere did you get it?\nWhether you have the right to use it or not all that's coming into question I think um with everything going on right now but still do you have the right data um do you have the right sort of privacy and security do you have a way in which you can evaluate your model how do you evaluate it right some high-risk applications require a different level of scrutiny maybe some human uh insight etc so lending systems safety applications you know etc defense you know cyber security all those kinds of things and so At the end of the day, developers are the ones who build this.\nAnd so I'm definitely an advocate of making sure that those pillars of responsible AI, which are really just development best practices are really communicated because at the end of the day, um it's the developers who's who who's picking that model, who's building that model, that needs to be aware of these practices so that you can really um sort of measure twice, cut once, if that makes sense.\nHave a plan, have a way to evaluate it, be able to do so knowing that you're going to get to the right performant outcome.\nIf you leverage some of these best practices out there, you can make sure that you know your your bot or whatever it is you're building, you know, gets redteamed, right, and doesn't say or do something inappropriate that there are ways in which there you put some appropriate best practices into your development much like you would for security, right?\nYou don't want to leak your customers data.\nSo, you're going to build an architecture with security in mind.\nI think of responsible um AI development practices as the same thing.\nI'd add one more thing I love that Wendy is um especially for potentially some of your audience depending on how far along they are in their AI journey is that when you're thinking about this is do some research or talk to some experts like ourselves that doesn't have to just be a plug for us but really there's really good resources out there.\nThere are people in the industry um people like ourselves who can help who have seen this.\nLike we know what good looks like.\nWe've been there.\nWe've done this for for extremely large names named companies and we've seen what helps them drive success is that there's help out there.\nYou don't have to figure it all out by yourself.\nYeah.\nUh certainly both great ideas there.\nUh I like the idea of responsible AI.\nUh you don't want to expose yourself to business risks by doing something stupid.\nAnd again uh simply Duncan is like yeah you don't want to do do something stupid.\nLike talk to an expert, have a think about what you're doing before you just dive straight in there, which is a shame.\nI always hate planning.\nI always want to dive in, but uh yeah, uh it's much more sensible to think first and then ask for help if you need it.\nUh so finally, uh I always want recommendations for people to follow.\nUh so I'd love to know about whose work you admire at the moment.\nUh who are you listening to?\nUm this has nothing to do with AI, but I've been listening to Michelle Obama a lot.\nSo, nothing to do with KI, but that's the first thing first thing that came to mind.\nUm, go ahead, Doug.\nOkay.\nI actually thought it was going to be a K-pug recommendation.\nYeah.\nI I mean, I haven't been following individuals as much, but I've been following trends and some of the things that I find really interesting um is the introduction of uh let's call it more standard engineering practices as it applies to LLM.\nSo we saw this with DeepSeek um as it came out where they took an approach of different innovative not even necessarily super innovative ways but instead of making the the goal how do we make the biggest model how do we make it the most efficient model and seeing different ways to tackle that problem that's been super fascinating to me um as I nerd out in that space.\nAnd I I have a serious answer actually.\nUh I Michelle is the first one that came to mind, but um Andreas Carpathy he does a great set of series.\nI think anybody who is really trying to understand more about AI, the technical concepts of AI.\nUm he's I would subscribe to his YouTube channel.\nIt's excellent.\nYeah.\nUh both Michelle Obama and Andre Alpathy definitely great speakers although on uh very different topics and yeah uh there are a lot of uh amazing foundation model researchers uh speaking about their work as well and I do like the idea of uh making things uh more efficient saving money but uh on that note uh I think we have to uh stop now uh so yeah thank you both thanks Richie\n[Music]\n",
  "dumpedAt": "2025-07-21T18:43:25.847Z"
}