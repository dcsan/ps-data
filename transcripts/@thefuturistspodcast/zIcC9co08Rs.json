{
  "episodeId": "zIcC9co08Rs",
  "channelSlug": "@thefuturistspodcast",
  "title": "The Futurists - EPS_301: Machine Forecasting with Dan Schwarz",
  "publishedAt": "2025-07-18T14:32:36.000Z",
  "rawLines": [
    {
      "lang": "en",
      "text": "This week on the futurists, Dan Schwarz.",
      "offset": 0.32,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "Forecasting the future of technology is",
      "offset": 3.52,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "unbelievably hard as I'm sure you know",
      "offset": 5.68,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "Robert better than most. Um so we said",
      "offset": 7.52,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "okay we need more like we need more",
      "offset": 9.92,
      "duration": 3.679
    },
    {
      "lang": "en",
      "text": "intelligence and of course the source of",
      "offset": 11.679,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "new intelligence is not throw more",
      "offset": 13.599,
      "duration": 4.001
    },
    {
      "lang": "en",
      "text": "humans at the problem. It's put some AI",
      "offset": 15.599,
      "duration": 5.001
    },
    {
      "lang": "en",
      "text": "on it. And that's where we are now.",
      "offset": 17.6,
      "duration": 7.36
    },
    {
      "lang": "en",
      "text": "[Music]",
      "offset": 20.6,
      "duration": 5.8
    },
    {
      "lang": "en",
      "text": "Hey there. Welcome back to the futurist.",
      "offset": 24.96,
      "duration": 4.559
    },
    {
      "lang": "en",
      "text": "I'm Rob Tersik and this week I am solo.",
      "offset": 26.4,
      "duration": 5.279
    },
    {
      "lang": "en",
      "text": "Uh Brett King was planning to join but",
      "offset": 29.519,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "at the last moment got pulled away. As",
      "offset": 31.679,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "you may know if you listen to the show",
      "offset": 33.92,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "frequently uh Brett's often on the road",
      "offset": 35.28,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "so the guy has a lot of demands on his",
      "offset": 37.28,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "time but he set me up with a great",
      "offset": 39.12,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "interview today. I'm going to be",
      "offset": 41.12,
      "duration": 2.48
    },
    {
      "lang": "en",
      "text": "speaking to someone who's thinking very",
      "offset": 42.16,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "deeply uh about the future and in",
      "offset": 43.6,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "particular the future of AI uh by",
      "offset": 45.6,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "evaluating the performance of various AI",
      "offset": 47.76,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "models and their business models as",
      "offset": 49.52,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "well. Um and among them many other",
      "offset": 51.12,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "things. Uh so let me give a warm",
      "offset": 52.8,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "introduction to Dan Schwarz. Dan,",
      "offset": 54.8,
      "duration": 4.239
    },
    {
      "lang": "en",
      "text": "welcome to the futurist. Thanks for",
      "offset": 57.76,
      "duration": 2.799
    },
    {
      "lang": "en",
      "text": "joining us today on the show.",
      "offset": 59.039,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "Thank you for having me, Robert.",
      "offset": 60.559,
      "duration": 3.361
    },
    {
      "lang": "en",
      "text": "Dan, uh tell us a little bit about",
      "offset": 62.239,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "Future Search. Uh it's a relatively new",
      "offset": 63.92,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "organization and I think probably a lot",
      "offset": 66.08,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "of folks are not familiar with it.",
      "offset": 67.68,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "Yeah, we are a seedstage startup. Uh",
      "offset": 69.92,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "we're a little bit less than two years",
      "offset": 71.84,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "old. Um we are predicting the future",
      "offset": 73.52,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "using AI and uh we got started shortly",
      "offset": 76.08,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "after GPD4 came out when we realized",
      "offset": 79.28,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "that this was now possible. Um, prior to",
      "offset": 81.2,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "future search, I was the CTO of",
      "offset": 83.439,
      "duration": 2.561
    },
    {
      "lang": "en",
      "text": "Metaculus, which is the, you know,",
      "offset": 84.64,
      "duration": 3.519
    },
    {
      "lang": "en",
      "text": "preeminent human forecasting platform.",
      "offset": 86,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "And for that, I built and ran the",
      "offset": 88.159,
      "duration": 3.121
    },
    {
      "lang": "en",
      "text": "prediction market that is currently",
      "offset": 90,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "running inside Google. So, I was very,",
      "offset": 91.28,
      "duration": 3.519
    },
    {
      "lang": "en",
      "text": "very interested in how we can predict",
      "offset": 93.28,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "the future. And up until two years ago,",
      "offset": 94.799,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "the answer was how do we get the best",
      "offset": 96.96,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "information out of human beings? And now",
      "offset": 98.479,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "the question is, how do we get the best",
      "offset": 100.799,
      "duration": 2.96
    },
    {
      "lang": "en",
      "text": "information out of AI? And that's what",
      "offset": 102.079,
      "duration": 3.121
    },
    {
      "lang": "en",
      "text": "future is doing.",
      "offset": 103.759,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "Very cool. And so, if uh folks go to the",
      "offset": 105.2,
      "duration": 5.199
    },
    {
      "lang": "en",
      "text": "website, it's futurarch.ai AI because",
      "offset": 107.68,
      "duration": 3.759
    },
    {
      "lang": "en",
      "text": "actually there's a couple different",
      "offset": 110.399,
      "duration": 2.561
    },
    {
      "lang": "en",
      "text": "things that turn up if you search it on",
      "offset": 111.439,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "Google. So it's important to put theai",
      "offset": 112.96,
      "duration": 3.119
    },
    {
      "lang": "en",
      "text": "at the end if you're going to go to that",
      "offset": 114.799,
      "duration": 3.521
    },
    {
      "lang": "en",
      "text": "site. Uh you'll find research reports",
      "offset": 116.079,
      "duration": 3.761
    },
    {
      "lang": "en",
      "text": "and some news and I was actually quite",
      "offset": 118.32,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "interested to see uh the information",
      "offset": 119.84,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "that you've been sharing on LinkedIn. Uh",
      "offset": 121.36,
      "duration": 4.719
    },
    {
      "lang": "en",
      "text": "folks if you find um if you find Dan on",
      "offset": 124,
      "duration": 3.759
    },
    {
      "lang": "en",
      "text": "LinkedIn then you'll be able to see some",
      "offset": 126.079,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "of his recent reports uh you know for",
      "offset": 127.759,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "instance about the business model of",
      "offset": 129.679,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "OpenAI and so on. I was surprised you",
      "offset": 130.879,
      "duration": 3.041
    },
    {
      "lang": "en",
      "text": "were able to get that information",
      "offset": 132.959,
      "duration": 2.401
    },
    {
      "lang": "en",
      "text": "because that's not readily available",
      "offset": 133.92,
      "duration": 3.679
    },
    {
      "lang": "en",
      "text": "even from uh news publications.",
      "offset": 135.36,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "That's right. And it was last summer",
      "offset": 137.599,
      "duration": 3.041
    },
    {
      "lang": "en",
      "text": "when we were the first to basically",
      "offset": 139.2,
      "duration": 2.88
    },
    {
      "lang": "en",
      "text": "figure out their business model like",
      "offset": 140.64,
      "duration": 2.959
    },
    {
      "lang": "en",
      "text": "where the revenue was coming from from",
      "offset": 142.08,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "Chad GBT consumer and enterprise and",
      "offset": 143.599,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "from the API uh when none of that",
      "offset": 145.28,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "information was public and the main way",
      "offset": 147.44,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "we were able to do that was using our",
      "offset": 149.28,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "forecasting techniques. Uh to be great",
      "offset": 150.56,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "at forecasting you have to work with",
      "offset": 152.56,
      "duration": 3.039
    },
    {
      "lang": "en",
      "text": "information you don't have because the",
      "offset": 154.08,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "future is fundamentally unknowable. So",
      "offset": 155.599,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "you have to kind of triangulate data",
      "offset": 157.76,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "sources, you have to estimate, you have",
      "offset": 159.68,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "to infer, you have to make probabilistic",
      "offset": 161.28,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "inferences. But if you get enough data",
      "offset": 163.2,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "and you have good enough judgment, you",
      "offset": 165.68,
      "duration": 3.199
    },
    {
      "lang": "en",
      "text": "can make pretty good probabilistic",
      "offset": 167.519,
      "duration": 3.281
    },
    {
      "lang": "en",
      "text": "inferences. And those projections that",
      "offset": 168.879,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "we made last summer about OpenAI held",
      "offset": 170.8,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "out very very well when more data came",
      "offset": 172.959,
      "duration": 3.521
    },
    {
      "lang": "en",
      "text": "in. That gives us more confidence that",
      "offset": 174.879,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "our methodology is working and hopefully",
      "offset": 176.48,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "gives our audience some and customers",
      "offset": 178.239,
      "duration": 2.961
    },
    {
      "lang": "en",
      "text": "some confidence when they look at our",
      "offset": 180,
      "duration": 2.879
    },
    {
      "lang": "en",
      "text": "analysis that we're more likely to be",
      "offset": 181.2,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "right than your average analyst or",
      "offset": 182.879,
      "duration": 2.881
    },
    {
      "lang": "en",
      "text": "reporter on the topic.",
      "offset": 184.48,
      "duration": 2.479
    },
    {
      "lang": "en",
      "text": "So that's really interesting. So that",
      "offset": 185.76,
      "duration": 2.32
    },
    {
      "lang": "en",
      "text": "report that you published, you didn't do",
      "offset": 186.959,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "that in cooperation with OpenAI. You",
      "offset": 188.08,
      "duration": 3.519
    },
    {
      "lang": "en",
      "text": "didn't get access to any inside",
      "offset": 190.239,
      "duration": 3.121
    },
    {
      "lang": "en",
      "text": "information at that company. you simply",
      "offset": 191.599,
      "duration": 4.481
    },
    {
      "lang": "en",
      "text": "had your AI system evaluate trends and",
      "offset": 193.36,
      "duration": 4.799
    },
    {
      "lang": "en",
      "text": "then make forecasts and predictions uh",
      "offset": 196.08,
      "duration": 3.519
    },
    {
      "lang": "en",
      "text": "based on that information",
      "offset": 198.159,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "with plenty of humans too. Um despite",
      "offset": 199.599,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "what I said before about AI being the",
      "offset": 201.599,
      "duration": 3.441
    },
    {
      "lang": "en",
      "text": "main place to mine for insights about",
      "offset": 203.519,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "the future, of course humans are still",
      "offset": 205.04,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "king, just not for that long. Um so you",
      "offset": 206.879,
      "duration": 5.041
    },
    {
      "lang": "en",
      "text": "know two years ago it was purely a human",
      "offset": 210,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "intelligence game. The last two years",
      "offset": 211.92,
      "duration": 4.239
    },
    {
      "lang": "en",
      "text": "it's been hybrid human AI intelligence",
      "offset": 213.84,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "and now we are starting to see the pure",
      "offset": 216.159,
      "duration": 4.241
    },
    {
      "lang": "en",
      "text": "AI intelligence part come to its its own",
      "offset": 218.159,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "element. Um, you know, I'm I'm a",
      "offset": 220.4,
      "duration": 4.479
    },
    {
      "lang": "en",
      "text": "longtime chess player and this is kind",
      "offset": 222.879,
      "duration": 3.201
    },
    {
      "lang": "en",
      "text": "of the main way that we think about the",
      "offset": 224.879,
      "duration": 2.881
    },
    {
      "lang": "en",
      "text": "relation between humans and AI. You",
      "offset": 226.08,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "know, many decades of just humans, then",
      "offset": 227.76,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "this period of time for about 10 or 20",
      "offset": 229.76,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "years where is humans and AI working",
      "offset": 232,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "together and then we got to the point",
      "offset": 233.68,
      "duration": 3.199
    },
    {
      "lang": "en",
      "text": "where it was only AI and humans have",
      "offset": 235.28,
      "duration": 2.879
    },
    {
      "lang": "en",
      "text": "basically nothing left to say about the",
      "offset": 236.879,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "game of chess. Uh, predicting the future",
      "offset": 238.159,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "is much much harder than playing chess.",
      "offset": 240.239,
      "duration": 3.441
    },
    {
      "lang": "en",
      "text": "Much much harder. Uh, but I think it",
      "offset": 242.08,
      "duration": 3.359
    },
    {
      "lang": "en",
      "text": "will follow that same shape. So, we'll",
      "offset": 243.68,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "be in this era where we have human AI",
      "offset": 245.439,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "pairing and then we'll be in the AI only",
      "offset": 247.28,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "world before too long. Well, that's",
      "offset": 249.12,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "quite interesting. You know, the there",
      "offset": 251.28,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "was research uh republished today by um",
      "offset": 252.4,
      "duration": 6.64
    },
    {
      "lang": "en",
      "text": "uh Gary Marcus who's a notable critic or",
      "offset": 256.16,
      "duration": 4.799
    },
    {
      "lang": "en",
      "text": "I should say critical thinker about AI.",
      "offset": 259.04,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "He's uh he's well known for debunking",
      "offset": 260.959,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "some of the more outrageous claims made",
      "offset": 262.72,
      "duration": 4.479
    },
    {
      "lang": "en",
      "text": "by open AI. And he published research",
      "offset": 265.04,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "today that said even the reasoning",
      "offset": 267.199,
      "duration": 4.881
    },
    {
      "lang": "en",
      "text": "models uh that that open AI has been",
      "offset": 269.36,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "promoting so heavily recently. Uh he",
      "offset": 272.08,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "said even those reasoning models are",
      "offset": 274.4,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "subject to deception. uh and he gave",
      "offset": 276.08,
      "duration": 4.559
    },
    {
      "lang": "en",
      "text": "some examples where uh they were citing",
      "offset": 278.32,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "known research uh sorry known",
      "offset": 280.639,
      "duration": 3.761
    },
    {
      "lang": "en",
      "text": "publications that are uh disinformation",
      "offset": 282.479,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "sites um particularly the Pravda network",
      "offset": 284.4,
      "duration": 6.079
    },
    {
      "lang": "en",
      "text": "in Russia uh where if you ask uh the",
      "offset": 287.199,
      "duration": 5.041
    },
    {
      "lang": "en",
      "text": "reasoning models the open AI reasoning",
      "offset": 290.479,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "models they will tell you all about this",
      "offset": 292.24,
      "duration": 3.519
    },
    {
      "lang": "en",
      "text": "Pravda network and it's well understood",
      "offset": 294.16,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "by the AI that this is a disinformation",
      "offset": 295.759,
      "duration": 3.281
    },
    {
      "lang": "en",
      "text": "network but then again if you ask other",
      "offset": 297.68,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "questions it starts to show up uh as uh",
      "offset": 299.04,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "as credible information and so it's easy",
      "offset": 301.759,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "to fool these systems today. Uh tell me",
      "offset": 304,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "a little bit about that because you made",
      "offset": 306.639,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "a prediction that someday um perhaps",
      "offset": 308.16,
      "duration": 4.479
    },
    {
      "lang": "en",
      "text": "soon uh machines will be reasoning",
      "offset": 310.32,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "better than humans and I would say that",
      "offset": 312.639,
      "duration": 2.961
    },
    {
      "lang": "en",
      "text": "Gary Marcus would probably differ with",
      "offset": 314.32,
      "duration": 2.56
    },
    {
      "lang": "en",
      "text": "you on that. So how about how do you",
      "offset": 315.6,
      "duration": 2.72
    },
    {
      "lang": "en",
      "text": "respond to that?",
      "offset": 316.88,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "Yeah. Uh I mean Gary is a smart guy u",
      "offset": 318.32,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "but I think he disagrees with myself and",
      "offset": 321.28,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "many other people who are uh more of a",
      "offset": 323.84,
      "duration": 3.199
    },
    {
      "lang": "en",
      "text": "believer not necessarily in the present",
      "offset": 325.6,
      "duration": 2.72
    },
    {
      "lang": "en",
      "text": "state of these models but in the",
      "offset": 327.039,
      "duration": 3.281
    },
    {
      "lang": "en",
      "text": "velocity and maybe even the acceleration",
      "offset": 328.32,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "um of their quality. Yeah, that question",
      "offset": 330.32,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "is very interesting. I don't think the",
      "offset": 332.56,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "research definitively answers this, but",
      "offset": 334.16,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "the best of my understanding is that a",
      "offset": 336.08,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "lot of the citing of incredible sources",
      "offset": 337.68,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "uh comes from post training. You know,",
      "offset": 340.4,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "for a while hallucinations were such a",
      "offset": 342.32,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "huge problem for using LLMs for almost",
      "offset": 344.24,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "anything that the the reward for not",
      "offset": 346.16,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "hallucinating but citing your evidence",
      "offset": 348.88,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "was extremely high. And so models got in",
      "offset": 350.88,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "a habit of citing whatever they could",
      "offset": 353.28,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "find. Um it's not just Pravda, by the",
      "offset": 354.56,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "way. You know, a lot of future search",
      "offset": 356.72,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "runs, we have to, you know, go and tune",
      "offset": 358.4,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "them because they will pull up things",
      "offset": 360.32,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "like market research reports that are",
      "offset": 362.4,
      "duration": 4.239
    },
    {
      "lang": "en",
      "text": "superficially credible, but any expert",
      "offset": 364.72,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "looking at them will tell that this is",
      "offset": 366.639,
      "duration": 2.641
    },
    {
      "lang": "en",
      "text": "just some intern who just put a bunch of",
      "offset": 367.84,
      "duration": 2.799
    },
    {
      "lang": "en",
      "text": "numbers into a spreadsheet. It's not",
      "offset": 369.28,
      "duration": 2.56
    },
    {
      "lang": "en",
      "text": "like credible research.",
      "offset": 370.639,
      "duration": 2.961
    },
    {
      "lang": "en",
      "text": "And are the AI capable of making that",
      "offset": 371.84,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "discernment or does that require human",
      "offset": 373.6,
      "duration": 2.56
    },
    {
      "lang": "en",
      "text": "intervention?",
      "offset": 375.28,
      "duration": 2.16
    },
    {
      "lang": "en",
      "text": "That's, you know, that's a tough",
      "offset": 376.16,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "problem. Um, it is somewhat capable.",
      "offset": 377.44,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "Like you said, if you just ask chat GPT,",
      "offset": 379.6,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "is Pravda a credible source? It will",
      "offset": 381.44,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "tell you it's not, but then it will go",
      "offset": 383.6,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "cite it. Exactly as you said, Robert.",
      "offset": 384.96,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "So, some of this is just kind of the",
      "offset": 386.8,
      "duration": 2.8
    },
    {
      "lang": "en",
      "text": "engineering of the intelligence of what",
      "offset": 388.08,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "is a credible source is there. You just",
      "offset": 389.6,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "have to elicit it out of the model. But",
      "offset": 391.28,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "part of it is that you just need to have",
      "offset": 393.28,
      "duration": 3.359
    },
    {
      "lang": "en",
      "text": "good epistemics for your reasoning more",
      "offset": 394.72,
      "duration": 2.88
    },
    {
      "lang": "en",
      "text": "generally. And it's not just",
      "offset": 396.639,
      "duration": 2.641
    },
    {
      "lang": "en",
      "text": "hallucinations and it's not just, you",
      "offset": 397.6,
      "duration": 3.439
    },
    {
      "lang": "en",
      "text": "know, using sources that are not",
      "offset": 399.28,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "credible. There's a million ways you can",
      "offset": 401.039,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "go wrong in your reasoning chains. And",
      "offset": 402.96,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "you know Gary Marcus is right that if",
      "offset": 405.039,
      "duration": 3.761
    },
    {
      "lang": "en",
      "text": "you want to get high quality research",
      "offset": 406.72,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "just asking chat GPT even with 03 or",
      "offset": 408.8,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "Grock 4 which came out yesterday or",
      "offset": 411.28,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "whatever you want is not that great but",
      "offset": 412.96,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "that's like going to one human you you",
      "offset": 415.36,
      "duration": 3.679
    },
    {
      "lang": "en",
      "text": "just meet on the street or a single",
      "offset": 417.6,
      "duration": 3.039
    },
    {
      "lang": "en",
      "text": "consultant you hire and saying just tell",
      "offset": 419.039,
      "duration": 2.961
    },
    {
      "lang": "en",
      "text": "me what's going to happen with open AI",
      "offset": 420.639,
      "duration": 2.56
    },
    {
      "lang": "en",
      "text": "and just believing everything they tell",
      "offset": 422,
      "duration": 3.199
    },
    {
      "lang": "en",
      "text": "you. That would be a crazy thing to do.",
      "offset": 423.199,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "U you know one of the things about",
      "offset": 425.199,
      "duration": 3.361
    },
    {
      "lang": "en",
      "text": "coming to forecasting from studying",
      "offset": 426.88,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "humans before doing it as AI is that",
      "offset": 428.56,
      "duration": 4.639
    },
    {
      "lang": "en",
      "text": "humans are incredibly bad at almost",
      "offset": 431.44,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "every forecasting task like they also",
      "offset": 433.199,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "hallucinate and make stuff up that is",
      "offset": 435.599,
      "duration": 2.88
    },
    {
      "lang": "en",
      "text": "not you know they just remember",
      "offset": 437.28,
      "duration": 2.8
    },
    {
      "lang": "en",
      "text": "something but it turns out to be fake",
      "offset": 438.479,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "they will also site bad sources that",
      "offset": 440.08,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "they shouldn't site they will make",
      "offset": 442.08,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "deductive errors they make inductive",
      "offset": 443.52,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "errors they will omit critical",
      "offset": 445.12,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "information uh and so the best way to",
      "offset": 446.72,
      "duration": 3.759
    },
    {
      "lang": "en",
      "text": "get information out of humans is to have",
      "offset": 448.96,
      "duration": 3.679
    },
    {
      "lang": "en",
      "text": "like really expert humans and to work",
      "offset": 450.479,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "with them for a long period of time and",
      "offset": 452.639,
      "duration": 2.96
    },
    {
      "lang": "en",
      "text": "to have them work in teams",
      "offset": 454.08,
      "duration": 4.239
    },
    {
      "lang": "en",
      "text": "And that still is fraught and still",
      "offset": 455.599,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "leads to error. So the idea that we just",
      "offset": 458.319,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "take an offtheshelf AI just ask it one",
      "offset": 459.759,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "thing and say ah it failed therefore AI",
      "offset": 461.759,
      "duration": 2.961
    },
    {
      "lang": "en",
      "text": "is not trustworthy. It's like have you",
      "offset": 463.36,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "talked to humans? Like humans are",
      "offset": 464.72,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "terrible at these tasks. Really it's",
      "offset": 466.4,
      "duration": 3.519
    },
    {
      "lang": "en",
      "text": "it's just a complicated engineering and",
      "offset": 468.16,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "orchestration problem to get good",
      "offset": 469.919,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "information at large from humans from AI",
      "offset": 471.44,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "or from humans working with AI.",
      "offset": 473.759,
      "duration": 4.481
    },
    {
      "lang": "en",
      "text": "It's I'm laughing because of course",
      "offset": 476.4,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "you're on a show called the futurists",
      "offset": 478.24,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "where we talk to forecasters and people",
      "offset": 480.16,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "who make bold predictions all the time",
      "offset": 482,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "and it's true and even here we have uh",
      "offset": 484.4,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "we have the challenge of screening out",
      "offset": 486.72,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "charlatans um people who make you know",
      "offset": 488.72,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "basically they they take a shot from the",
      "offset": 490.879,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "hip uh there is a style of of futurist",
      "offset": 492.639,
      "duration": 5.84
    },
    {
      "lang": "en",
      "text": "who uh I call them entertainment",
      "offset": 496.479,
      "duration": 4.881
    },
    {
      "lang": "en",
      "text": "futurists because they make the kinds of",
      "offset": 498.479,
      "duration": 4.881
    },
    {
      "lang": "en",
      "text": "forecasts that sound really plausible",
      "offset": 501.36,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "and they're super interesting scenarios",
      "offset": 503.36,
      "duration": 3.679
    },
    {
      "lang": "en",
      "text": "and they present it in such a credible",
      "offset": 505.36,
      "duration": 3.519
    },
    {
      "lang": "en",
      "text": "fashion because they speak boldly with",
      "offset": 507.039,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "confidence that uh they can persuade a",
      "offset": 508.879,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "lot of people that that may be may be",
      "offset": 511.039,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "true or that may be likely and sometimes",
      "offset": 512.399,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "I'm listening to these folks and I think",
      "offset": 515.039,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "to myself this guy's completely making",
      "offset": 516.479,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "it up like you know he has it's not",
      "offset": 519.279,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "based on anything credible or you're",
      "offset": 521.039,
      "duration": 3.441
    },
    {
      "lang": "en",
      "text": "right like you know superficial search",
      "offset": 522.959,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "across the web and pulling a pulling up",
      "offset": 524.48,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "a couple research reports and then using",
      "offset": 526.56,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "that to extrapolate some scenario. uh",
      "offset": 528.24,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "you know typically when we do scenario",
      "offset": 530.8,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "planning for organizations um we'll",
      "offset": 532.399,
      "duration": 3.761
    },
    {
      "lang": "en",
      "text": "present a range of scenarios weighted",
      "offset": 534.56,
      "duration": 2.959
    },
    {
      "lang": "en",
      "text": "probabilities about what we believe",
      "offset": 536.16,
      "duration": 3.679
    },
    {
      "lang": "en",
      "text": "might happen and our reasoning for that",
      "offset": 537.519,
      "duration": 4.241
    },
    {
      "lang": "en",
      "text": "and um and you know very often there's",
      "offset": 539.839,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "variability with each of those right so",
      "offset": 541.76,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "it's never really that certain it's very",
      "offset": 543.68,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "difficult uh as you said in the",
      "offset": 545.44,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "beginning the future doesn't exist uh",
      "offset": 546.88,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "it's not like a book that's been written",
      "offset": 549.12,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "and you're just guessing the next page",
      "offset": 550.48,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "it's a range of probabilities that's the",
      "offset": 552.88,
      "duration": 2.8
    },
    {
      "lang": "en",
      "text": "only you know all that exists is the",
      "offset": 554.48,
      "duration": 2.4
    },
    {
      "lang": "en",
      "text": "present moment and what we understand",
      "offset": 555.68,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "about the past and the rest of it is to",
      "offset": 556.88,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "um how do you present that information",
      "offset": 559.2,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "and how do your clients get value from",
      "offset": 562,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "it?",
      "offset": 564.72,
      "duration": 2.88
    },
    {
      "lang": "en",
      "text": "Yeah, it's a great question, Robert, and",
      "offset": 565.92,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "yeah, you as a futurist who have worked",
      "offset": 567.6,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "with other futurists, I think you",
      "offset": 569.36,
      "duration": 2.479
    },
    {
      "lang": "en",
      "text": "probably understand this better than I",
      "offset": 570.64,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "do. Um the I'll point you to an example.",
      "offset": 571.839,
      "duration": 6.161
    },
    {
      "lang": "en",
      "text": "Um we contributed some of the forecast",
      "offset": 575.92,
      "duration": 4.479
    },
    {
      "lang": "en",
      "text": "to the AI 2027 report that came out a",
      "offset": 578,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "couple months ago. Uh Robert, did you",
      "offset": 580.399,
      "duration": 2.401
    },
    {
      "lang": "en",
      "text": "read that one?",
      "offset": 582,
      "duration": 1.68
    },
    {
      "lang": "en",
      "text": "No, I didn't.",
      "offset": 582.8,
      "duration": 2.159
    },
    {
      "lang": "en",
      "text": "I'd encourage you and your audience to",
      "offset": 583.68,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "check out AI 2027. It is a very very",
      "offset": 584.959,
      "duration": 6.401
    },
    {
      "lang": "en",
      "text": "well-crafted scenario of how a hard AI",
      "offset": 588.32,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "takeoff could happen in the next couple",
      "offset": 591.36,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "of years. Um, and the answer to your",
      "offset": 592.72,
      "duration": 3.679
    },
    {
      "lang": "en",
      "text": "question, Robert, is that it does all of",
      "offset": 594.88,
      "duration": 3.519
    },
    {
      "lang": "en",
      "text": "it. So, we contributed the forecast,",
      "offset": 596.399,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "just kind of the hard-nosed quantitative",
      "offset": 598.399,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "modeling plus putting in judgment, you",
      "offset": 600.56,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "know, all the forecasting techniques we",
      "offset": 602.56,
      "duration": 2.64
    },
    {
      "lang": "en",
      "text": "have at our disposal to just get the",
      "offset": 603.76,
      "duration": 3.519
    },
    {
      "lang": "en",
      "text": "most accurate answer we can to when will",
      "offset": 605.2,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "certain milestones be reached with the",
      "offset": 607.279,
      "duration": 3.201
    },
    {
      "lang": "en",
      "text": "first one being when will AI be so good",
      "offset": 608.88,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "at coding that it massively speeds up",
      "offset": 610.48,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "the coding that happens in the frontier",
      "offset": 612.08,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "labs that are developing AI. And then",
      "offset": 613.6,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "there's a series of milestones that",
      "offset": 615.6,
      "duration": 2.4
    },
    {
      "lang": "en",
      "text": "happen after that.",
      "offset": 616.88,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "But if you read it, it is a it's two",
      "offset": 618,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "scenarios. It's very long. It's an hour",
      "offset": 620.16,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "or two to read. And there's kind of an",
      "offset": 622.56,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "accompanying graphic on the side that",
      "offset": 624,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "shows you the progress that is, you",
      "offset": 625.92,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "know, manifesting in society. It talks",
      "offset": 627.6,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "about the technology. It talks about the",
      "offset": 629.6,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "politics, talks about USChina",
      "offset": 631.04,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "relationships, it talks about the actual",
      "offset": 633.04,
      "duration": 3.359
    },
    {
      "lang": "en",
      "text": "development of the models and tries to",
      "offset": 634.959,
      "duration": 2.88
    },
    {
      "lang": "en",
      "text": "synthesize all of that into a coherent",
      "offset": 636.399,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "hole. Um, AI 2022 is very very",
      "offset": 637.839,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "ambitious. Uh, I loved it. Some people",
      "offset": 640.24,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "loved it. Uh, some people really didn't",
      "offset": 642,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "like. Uh even Vitalic Bddherin just",
      "offset": 643.76,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "actually made critique of it just",
      "offset": 645.76,
      "duration": 2.639
    },
    {
      "lang": "en",
      "text": "yesterday that I thought was really",
      "offset": 647.04,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "interesting. Um so I wouldn't claim to",
      "offset": 648.399,
      "duration": 4.481
    },
    {
      "lang": "en",
      "text": "have the best answer to how to turn",
      "offset": 650.88,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "information about the future into",
      "offset": 652.88,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "something persuasive. Uh I think there's",
      "offset": 654.32,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "many different audiences who want many",
      "offset": 656.8,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "different types of things. I think my",
      "offset": 658.48,
      "duration": 3.039
    },
    {
      "lang": "en",
      "text": "main claim is that we should try harder",
      "offset": 660,
      "duration": 2.88
    },
    {
      "lang": "en",
      "text": "like we should make better scenarios",
      "offset": 661.519,
      "duration": 3.121
    },
    {
      "lang": "en",
      "text": "like you said make them probabilistic",
      "offset": 662.88,
      "duration": 2.72
    },
    {
      "lang": "en",
      "text": "like we should back them with",
      "offset": 664.64,
      "duration": 2.4
    },
    {
      "lang": "en",
      "text": "quantitative models.",
      "offset": 665.6,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "Um and then from the you know the future",
      "offset": 667.04,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "search and metaculous perspective we",
      "offset": 668.8,
      "duration": 3.599
    },
    {
      "lang": "en",
      "text": "should trust people who have a better",
      "offset": 670.72,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "track record. Like if people go and say",
      "offset": 672.399,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "things and those things turn out to be",
      "offset": 674.8,
      "duration": 3.039
    },
    {
      "lang": "en",
      "text": "good, we should listen to them more. If",
      "offset": 676.079,
      "duration": 2.88
    },
    {
      "lang": "en",
      "text": "people go and say things and those",
      "offset": 677.839,
      "duration": 2.161
    },
    {
      "lang": "en",
      "text": "things turn out to be wrong, we should",
      "offset": 678.959,
      "duration": 2.481
    },
    {
      "lang": "en",
      "text": "listen to them less.",
      "offset": 680,
      "duration": 3.279
    },
    {
      "lang": "en",
      "text": "It's astounding to me in media how many",
      "offset": 681.44,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "pundits are wrong consistently and yet",
      "offset": 683.279,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "they're still they still appear on",
      "offset": 686,
      "duration": 3.519
    },
    {
      "lang": "en",
      "text": "television. It's almost like, you know,",
      "offset": 687.2,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "the the audiences for this information,",
      "offset": 689.519,
      "duration": 3.041
    },
    {
      "lang": "en",
      "text": "at least when it comes to like",
      "offset": 691.6,
      "duration": 2.239
    },
    {
      "lang": "en",
      "text": "broadcasting and mass media, the",
      "offset": 692.56,
      "duration": 2.8
    },
    {
      "lang": "en",
      "text": "audiences seem to prefer someone who",
      "offset": 693.839,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "tells them a familiar tale or the tale",
      "offset": 695.36,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "that they expect or an exciting tale",
      "offset": 697.92,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "rather than anything that's close to",
      "offset": 699.92,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "accurate. Uh and and there's no penalty.",
      "offset": 701.36,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "It seems there's no accountability for",
      "offset": 703.839,
      "duration": 2.881
    },
    {
      "lang": "en",
      "text": "people who are egregiously wrong again",
      "offset": 705.2,
      "duration": 2.8
    },
    {
      "lang": "en",
      "text": "and again and again on television where",
      "offset": 706.72,
      "duration": 2.559
    },
    {
      "lang": "en",
      "text": "it's recorded and you can show the",
      "offset": 708,
      "duration": 2.88
    },
    {
      "lang": "en",
      "text": "evidence that that they have been wrong",
      "offset": 709.279,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "consistently. Um I'm not going to name",
      "offset": 710.88,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "names right now, but there are plenty of",
      "offset": 713.2,
      "duration": 3.759
    },
    {
      "lang": "en",
      "text": "examples particularly in the in the",
      "offset": 715.12,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "markets and finance. Uh",
      "offset": 716.959,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "but it's not it's not necessarily a lost",
      "offset": 719.12,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "cause. I think the you know the Tetlock",
      "offset": 720.959,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "school of forecasting that is done in",
      "offset": 723.12,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "tournaments with resolutions and",
      "offset": 725.12,
      "duration": 3.519
    },
    {
      "lang": "en",
      "text": "probabilities and brier scores, it's",
      "offset": 726.8,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "only about 10 or 15 years old. I think",
      "offset": 728.639,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "it's still a little bit slow in getting",
      "offset": 730.639,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "adopted into the wider you know even the",
      "offset": 732.24,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "finance community which really they have",
      "offset": 734.24,
      "duration": 2.64
    },
    {
      "lang": "en",
      "text": "a lot of money on the line you think",
      "offset": 735.76,
      "duration": 2.4
    },
    {
      "lang": "en",
      "text": "they would take this more seriously and",
      "offset": 736.88,
      "duration": 2.56
    },
    {
      "lang": "en",
      "text": "they frequently don't",
      "offset": 738.16,
      "duration": 2.96
    },
    {
      "lang": "en",
      "text": "but is changing and I think AI is",
      "offset": 739.44,
      "duration": 2.959
    },
    {
      "lang": "en",
      "text": "actually accelerating that change",
      "offset": 741.12,
      "duration": 2.64
    },
    {
      "lang": "en",
      "text": "because AI makes things a lot more",
      "offset": 742.399,
      "duration": 3.521
    },
    {
      "lang": "en",
      "text": "transparent because when an AI gives you",
      "offset": 743.76,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "some information it comes with a big old",
      "offset": 745.92,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "rationale it comes with models you can",
      "offset": 747.839,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "read it you can ask follow-up questions",
      "offset": 749.44,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "you can get much more information about",
      "offset": 751.279,
      "duration": 3.521
    },
    {
      "lang": "en",
      "text": "what that AI did when you talk to humans",
      "offset": 752.56,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "the kind of human judgment that is",
      "offset": 754.8,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "behind these forecasts is often quite",
      "offset": 756.8,
      "duration": 3.599
    },
    {
      "lang": "en",
      "text": "messy and often the human themselves",
      "offset": 759.04,
      "duration": 2.88
    },
    {
      "lang": "en",
      "text": "won't know. They'll say, \"Well, I just",
      "offset": 760.399,
      "duration": 3.761
    },
    {
      "lang": "en",
      "text": "have a sense that Open AI is ahead.\" And",
      "offset": 761.92,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "they won't be able to really justify",
      "offset": 764.16,
      "duration": 2.16
    },
    {
      "lang": "en",
      "text": "that.",
      "offset": 765.6,
      "duration": 2.08
    },
    {
      "lang": "en",
      "text": "So AI is making everything more",
      "offset": 766.32,
      "duration": 2.639
    },
    {
      "lang": "en",
      "text": "transparent. It's giving reasoning",
      "offset": 767.68,
      "duration": 2.64
    },
    {
      "lang": "en",
      "text": "chains and numbers and models and",
      "offset": 768.959,
      "duration": 2.801
    },
    {
      "lang": "en",
      "text": "citations to all sorts of types of",
      "offset": 770.32,
      "duration": 3.199
    },
    {
      "lang": "en",
      "text": "things we didn't used to have. And so I",
      "offset": 771.76,
      "duration": 3.199
    },
    {
      "lang": "en",
      "text": "think the demand especially from the",
      "offset": 773.519,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "financial community for more rigor is is",
      "offset": 774.959,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "is accelerating. And I think for the",
      "offset": 777.279,
      "duration": 3.041
    },
    {
      "lang": "en",
      "text": "rest of the world, too.",
      "offset": 779.04,
      "duration": 2.64
    },
    {
      "lang": "en",
      "text": "In a way, Dan, that's one of the reasons",
      "offset": 780.32,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "why we started the show uh a long time",
      "offset": 781.68,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "ago when Brett and I got started here.",
      "offset": 783.92,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "We said, you know, the world needs more",
      "offset": 785.519,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "people who can think athletically about",
      "offset": 787.6,
      "duration": 4.239
    },
    {
      "lang": "en",
      "text": "the future, even if you're wrong. You",
      "offset": 789.839,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "know, I make fun of the people who uh",
      "offset": 791.839,
      "duration": 3.521
    },
    {
      "lang": "en",
      "text": "who make mistakes when they predict or",
      "offset": 793.44,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "prognosticate, but the fact is it's a",
      "offset": 795.36,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "good habit to be thinking about the",
      "offset": 797.68,
      "duration": 2.399
    },
    {
      "lang": "en",
      "text": "future. It's also a very good habit to",
      "offset": 798.8,
      "duration": 2.719
    },
    {
      "lang": "en",
      "text": "keep track of your forecast so that you",
      "offset": 800.079,
      "duration": 2.801
    },
    {
      "lang": "en",
      "text": "can see how frequently you're wrong",
      "offset": 801.519,
      "duration": 2.961
    },
    {
      "lang": "en",
      "text": "because a lot of people fall into that",
      "offset": 802.88,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "kind of cognitive bias where they they",
      "offset": 804.48,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "think that they're more frequently",
      "offset": 806.72,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "right. I would guess most people are are",
      "offset": 808,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "not correct in their forecasts more than",
      "offset": 809.92,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "half the time. Uh I feel happy if I'm",
      "offset": 812,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "for if my forecast are right 50% of the",
      "offset": 814.72,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "time I feel like I'm doing fantastically",
      "offset": 816.72,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "well relative to most people. Now you",
      "offset": 818.24,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "brought up Philip Tetllock and for the",
      "offset": 820.48,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "folks who are listening it's important",
      "offset": 822.24,
      "duration": 4.719
    },
    {
      "lang": "en",
      "text": "to know um about super forecasting. Uh",
      "offset": 823.76,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "Tetlock is a psychologist who developed",
      "offset": 826.959,
      "duration": 3.201
    },
    {
      "lang": "en",
      "text": "a methodology. First he became",
      "offset": 828.8,
      "duration": 2.88
    },
    {
      "lang": "en",
      "text": "interested in the ability of people to",
      "offset": 830.16,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "forecast and and why can some folks do",
      "offset": 831.68,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "it better than others and discovered",
      "offset": 834,
      "duration": 3.279
    },
    {
      "lang": "en",
      "text": "that some people suffer from cognitive",
      "offset": 835.68,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "biases that make it impossible for them",
      "offset": 837.279,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "to make a good forecast. And then he",
      "offset": 839.12,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "started to study those who were what he",
      "offset": 841.279,
      "duration": 2.721
    },
    {
      "lang": "en",
      "text": "calls super forecasters who are highly",
      "offset": 842.48,
      "duration": 3.039
    },
    {
      "lang": "en",
      "text": "accurate and began to kind of",
      "offset": 844,
      "duration": 3.279
    },
    {
      "lang": "en",
      "text": "extrapolate their habits. And one of the",
      "offset": 845.519,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "habits that he cites in the book super",
      "offset": 847.279,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "forecasting is um the ability to read",
      "offset": 849.44,
      "duration": 6.88
    },
    {
      "lang": "en",
      "text": "broadly across multiple sources. And the",
      "offset": 852.639,
      "duration": 6.481
    },
    {
      "lang": "en",
      "text": "converse of that is uh the people who",
      "offset": 856.32,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "only read in a certain bubble. We can a",
      "offset": 859.12,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "simple example would be uh the the left",
      "offset": 861.6,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "and the right in the political spectrum",
      "offset": 864.16,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "in in any democracy not just the United",
      "offset": 865.68,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "States. uh we're so polarized right now",
      "offset": 867.76,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "and we're so overloaded with information",
      "offset": 869.76,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "uh that we tend to see the same",
      "offset": 872.72,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "headlines. We seem to tend to see the",
      "offset": 874.8,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "same stories repeated again and again",
      "offset": 876.72,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "and again. So if you only graze on one",
      "offset": 878.16,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "side of the political divide or the",
      "offset": 880.8,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "other uh for your news information, then",
      "offset": 882.24,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "you're likely to start to form an",
      "offset": 884.639,
      "duration": 2.56
    },
    {
      "lang": "en",
      "text": "impression, a kind of consensus",
      "offset": 886,
      "duration": 2.639
    },
    {
      "lang": "en",
      "text": "impression that may have nothing to do",
      "offset": 887.199,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "with reality. And anyone who's in the",
      "offset": 888.639,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "United States right now, you know",
      "offset": 890.8,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "exactly what I'm talking about. Uh so",
      "offset": 892.8,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "unfortunately we tend to say well that's",
      "offset": 895.36,
      "duration": 2.8
    },
    {
      "lang": "en",
      "text": "a problem on the right or you know",
      "offset": 897.04,
      "duration": 2.08
    },
    {
      "lang": "en",
      "text": "people on the right will say that's a",
      "offset": 898.16,
      "duration": 2.64
    },
    {
      "lang": "en",
      "text": "problem on the left. The reality is that",
      "offset": 899.12,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "uh the the news media today in order to",
      "offset": 900.8,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "garner an audience and get attention has",
      "offset": 902.88,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "to come up with extreme scenarios and",
      "offset": 904.48,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "grab our headlines and clickbait. Uh and",
      "offset": 906,
      "duration": 4.639
    },
    {
      "lang": "en",
      "text": "so as a result it's all pretty extreme.",
      "offset": 908.32,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "Uh when often when you dig a little past",
      "offset": 910.639,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "the headlines the reality is not that",
      "offset": 912.399,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "extreme. Now this becomes problematic if",
      "offset": 914.56,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "that's shaping your view of the present",
      "offset": 916.959,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "because it's going to change the way you",
      "offset": 918.8,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "think about the future. So what Philip",
      "offset": 920.079,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "Tetlock would recommend is to",
      "offset": 922.32,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "aggressively investigate the views on",
      "offset": 924.48,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "the opposite side of the political fence",
      "offset": 926.88,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "or on any issue. It doesn't have to just",
      "offset": 928.8,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "be politics. Uh his point is that the",
      "offset": 930.48,
      "duration": 3.599
    },
    {
      "lang": "en",
      "text": "people who have that habit of reading",
      "offset": 932.72,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "broadly across the spectrum, they tend",
      "offset": 934.079,
      "duration": 4.801
    },
    {
      "lang": "en",
      "text": "to make highly accurate forecasts",
      "offset": 936.72,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "because they're getting they have a",
      "offset": 938.88,
      "duration": 3.519
    },
    {
      "lang": "en",
      "text": "richer information diet. Now in your",
      "offset": 940,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "work, Dan, I'm sure this is a factor",
      "offset": 942.399,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "when you're working with artificial",
      "offset": 944.32,
      "duration": 2.56
    },
    {
      "lang": "en",
      "text": "intelligence. It's probably the same",
      "offset": 945.519,
      "duration": 2.88
    },
    {
      "lang": "en",
      "text": "thing, right? Garbage in garbage out is",
      "offset": 946.88,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "a famous classic computer program. Uh we",
      "offset": 948.399,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "do see that the example we gave about",
      "offset": 951.6,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "Pravda network for example uh you can",
      "offset": 953.519,
      "duration": 5.041
    },
    {
      "lang": "en",
      "text": "fool an AI. Uh so one one approach is to",
      "offset": 955.68,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "use multiple AIs double check you know",
      "offset": 958.56,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "or take the results from one and feed it",
      "offset": 960.24,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "into another and see if you can get a",
      "offset": 962.16,
      "duration": 3.359
    },
    {
      "lang": "en",
      "text": "better check. Uh tell me about some of",
      "offset": 963.6,
      "duration": 4.239
    },
    {
      "lang": "en",
      "text": "the methodologies that you use to ensure",
      "offset": 965.519,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "that you're getting balanced information",
      "offset": 967.839,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "and credible sources so that your",
      "offset": 969.6,
      "duration": 3.599
    },
    {
      "lang": "en",
      "text": "forecasts are more likely to be",
      "offset": 971.839,
      "duration": 2.721
    },
    {
      "lang": "en",
      "text": "accurate.",
      "offset": 973.199,
      "duration": 4.481
    },
    {
      "lang": "en",
      "text": "Yeah. Um, and just to say that the fact",
      "offset": 974.56,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "that breadth of research is so important",
      "offset": 977.68,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "really gives you a signal that AI is",
      "offset": 980,
      "duration": 2.72
    },
    {
      "lang": "en",
      "text": "going to help you a lot here because",
      "offset": 981.519,
      "duration": 2.88
    },
    {
      "lang": "en",
      "text": "going deep with AI is very hard as",
      "offset": 982.72,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "anyone who's used Chat GPT knows. But",
      "offset": 984.399,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "going broad with AI is almost baked in.",
      "offset": 986.48,
      "duration": 3.279
    },
    {
      "lang": "en",
      "text": "Like it will definitely read more",
      "offset": 988.48,
      "duration": 2.64
    },
    {
      "lang": "en",
      "text": "articles than you could ever read and",
      "offset": 989.759,
      "duration": 2.64
    },
    {
      "lang": "en",
      "text": "figure out all of those angles that you",
      "offset": 991.12,
      "duration": 3.519
    },
    {
      "lang": "en",
      "text": "can never figure out. Its synthesis and",
      "offset": 992.399,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "its judgment and its, you know,",
      "offset": 994.639,
      "duration": 3.361
    },
    {
      "lang": "en",
      "text": "incredulousness. It's not clear that it",
      "offset": 996.24,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "has it's I mean I wouldn't say it's",
      "offset": 998,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "stronger than that. It is clearly below",
      "offset": 999.92,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "human intelligence and judgment. uh but",
      "offset": 1001.68,
      "duration": 3.599
    },
    {
      "lang": "en",
      "text": "it can definitely read more than you. So",
      "offset": 1003.92,
      "duration": 2.88
    },
    {
      "lang": "en",
      "text": "to the extent that that insight from",
      "offset": 1005.279,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "Tetlock holds up, which I think it does,",
      "offset": 1006.8,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "you immediately can see how incredibly",
      "offset": 1009.12,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "useful AI can be for forecasting even",
      "offset": 1010.88,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "though if you just ask it a forecasting",
      "offset": 1013.199,
      "duration": 2.88
    },
    {
      "lang": "en",
      "text": "question, it's going to do pretty badly",
      "offset": 1014.8,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "on its own. So the main technique that",
      "offset": 1016.079,
      "duration": 4.241
    },
    {
      "lang": "en",
      "text": "we use at future search is detecting",
      "offset": 1018.32,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "errors. So we put out a benchmark called",
      "offset": 1020.32,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "deep research bench. There's a lot of",
      "offset": 1022.32,
      "duration": 2.96
    },
    {
      "lang": "en",
      "text": "tools called deep research out there",
      "offset": 1023.92,
      "duration": 3.119
    },
    {
      "lang": "en",
      "text": "right now. Uh you know, Claude has one",
      "offset": 1025.28,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "called research, grock has one called",
      "offset": 1027.039,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "deep search. Uh and then open AAI and",
      "offset": 1028.72,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "Gemini have something called deep",
      "offset": 1031.12,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "research and it will do this. It will",
      "offset": 1032.4,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "read 50 100 articles on your question.",
      "offset": 1034.48,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "Even very technical, very difficult",
      "offset": 1036.799,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "questions like you want to know about",
      "offset": 1038.4,
      "duration": 3.439
    },
    {
      "lang": "en",
      "text": "troop movements in Ukraine or you want",
      "offset": 1040.079,
      "duration": 3.441
    },
    {
      "lang": "en",
      "text": "to know about a new drug's impact on the",
      "offset": 1041.839,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "human gut. Very very technical",
      "offset": 1043.52,
      "duration": 2.96
    },
    {
      "lang": "en",
      "text": "questions. It will just read everything",
      "offset": 1045.199,
      "duration": 3.521
    },
    {
      "lang": "en",
      "text": "for you and the question is how good is",
      "offset": 1046.48,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "its output on those tricky questions?",
      "offset": 1048.72,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "Nobody had built a benchmark of this",
      "offset": 1050.88,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "before. Nobody actually knew how well",
      "offset": 1052.32,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "these things were researching these",
      "offset": 1054,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "topics. So we decided look in order for",
      "offset": 1055.36,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "to make our systems better at this step",
      "offset": 1058,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "one is to be able to evaluate it and",
      "offset": 1059.6,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "once we did that we realized we should",
      "offset": 1061.36,
      "duration": 2.88
    },
    {
      "lang": "en",
      "text": "probably share this benchmark with other",
      "offset": 1062.88,
      "duration": 2.48
    },
    {
      "lang": "en",
      "text": "folks so they should know if they're",
      "offset": 1064.24,
      "duration": 2.88
    },
    {
      "lang": "en",
      "text": "going to go to chat GPT or Gemini or",
      "offset": 1065.36,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "claude or Grock 4 what to expect um you",
      "offset": 1067.12,
      "duration": 4.559
    },
    {
      "lang": "en",
      "text": "know the evals from just yesterday is",
      "offset": 1070.08,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "that Grock 4 does seem to be a better",
      "offset": 1071.679,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "LLM for this type of research even",
      "offset": 1073.36,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "though it just came out compared to 03",
      "offset": 1075.679,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "or Gemini 2.5 or Claude sonnet 4 and the",
      "offset": 1077.36,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "way that we verified that is just very",
      "offset": 1080.559,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "carefully working out the correct answer",
      "offset": 1082.08,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "to questions that require web research",
      "offset": 1083.679,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "So we have tasks like validating claims,",
      "offset": 1085.84,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "finding numbers, compiling data sets. We",
      "offset": 1087.919,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "use humans. We very very carefully work",
      "offset": 1090.32,
      "duration": 3.599
    },
    {
      "lang": "en",
      "text": "out what the correct answer is. And then",
      "offset": 1092.08,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "the other technique is we freeze the",
      "offset": 1093.919,
      "duration": 2.801
    },
    {
      "lang": "en",
      "text": "internet. So when you ask a question",
      "offset": 1095.28,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "that requires searching the internet,",
      "offset": 1096.72,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "the internet's changing all the time. So",
      "offset": 1098.72,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "if you ask it again tomorrow, how will",
      "offset": 1100.24,
      "duration": 2.64
    },
    {
      "lang": "en",
      "text": "you know? The information might have",
      "offset": 1101.76,
      "duration": 2.08
    },
    {
      "lang": "en",
      "text": "changed. There might be more",
      "offset": 1102.88,
      "duration": 2.32
    },
    {
      "lang": "en",
      "text": "information. Some information might have",
      "offset": 1103.84,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "been removed. So we freeze chunks of the",
      "offset": 1105.2,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "internet that are relevant for these",
      "offset": 1107.44,
      "duration": 2.96
    },
    {
      "lang": "en",
      "text": "questions to build like a proper test",
      "offset": 1108.72,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "environment. So if you ask them question",
      "offset": 1110.4,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "about the human gut or Ukraine troop",
      "offset": 1112.24,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "movements or whatever, we know what",
      "offset": 1114.96,
      "duration": 3.599
    },
    {
      "lang": "en",
      "text": "what's in there. So we know how good the",
      "offset": 1116.88,
      "duration": 2.799
    },
    {
      "lang": "en",
      "text": "researcher is. We're holding the",
      "offset": 1118.559,
      "duration": 2.401
    },
    {
      "lang": "en",
      "text": "internet constant. And the thing we're",
      "offset": 1119.679,
      "duration": 2.401
    },
    {
      "lang": "en",
      "text": "changing is the quality of the",
      "offset": 1120.96,
      "duration": 3.599
    },
    {
      "lang": "en",
      "text": "researcher. And this benchmark does show",
      "offset": 1122.08,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "that AI models are getting dramatically",
      "offset": 1124.559,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "better at this type of work, but they",
      "offset": 1126.32,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "are still clearly subhuman. A human",
      "offset": 1128.24,
      "duration": 3.439
    },
    {
      "lang": "en",
      "text": "carefully working out an answer to a",
      "offset": 1130.16,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "question like this who is skilled and",
      "offset": 1131.679,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "calibrated and patient will get a better",
      "offset": 1133.28,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "answer than any deep research tool",
      "offset": 1135.52,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "currently on the web. U but the gap is",
      "offset": 1137.28,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "closing.",
      "offset": 1139.52,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "That's quite a bold statement. Uh tell",
      "offset": 1141.36,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "me about that gap and tell me how long",
      "offset": 1143.36,
      "duration": 4.559
    },
    {
      "lang": "en",
      "text": "can humans uh take comfort in the fact",
      "offset": 1145.76,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "that we're able to outperform in this",
      "offset": 1147.919,
      "duration": 3.201
    },
    {
      "lang": "en",
      "text": "one domain.",
      "offset": 1149.76,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "Yeah, again it's tricky because humans",
      "offset": 1151.12,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "have such massive variation. So I'm",
      "offset": 1153.36,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "talking about like really great humans",
      "offset": 1155.36,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "and for me as a forecaster a great human",
      "offset": 1157.44,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "is someone who scores really well in",
      "offset": 1159.76,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "forecasting tournaments. Uh we work some",
      "offset": 1161.2,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "with some of the most calibrated, most",
      "offset": 1163.28,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "accurate forecasters on planet Earth and",
      "offset": 1164.88,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "we ask them to do this research and kind",
      "offset": 1166.96,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "of work out what the correct answer is.",
      "offset": 1168.88,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "We know they won't always get the right",
      "offset": 1170.32,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "answer, but they will always have good",
      "offset": 1172.24,
      "duration": 2.96
    },
    {
      "lang": "en",
      "text": "uncertainty. Like what they know, they",
      "offset": 1173.6,
      "duration": 2.72
    },
    {
      "lang": "en",
      "text": "know. What they don't know, they don't",
      "offset": 1175.2,
      "duration": 2.4
    },
    {
      "lang": "en",
      "text": "know. And they don't confuse those",
      "offset": 1176.32,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "things. And that is an incredibly rare",
      "offset": 1177.6,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "skill, as I'm sure you know. Um so by",
      "offset": 1179.52,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "working out those answers, we have a",
      "offset": 1182.48,
      "duration": 2.64
    },
    {
      "lang": "en",
      "text": "sense of what the frontier is. Of",
      "offset": 1183.76,
      "duration": 2.88
    },
    {
      "lang": "en",
      "text": "course, the typical human who's asked",
      "offset": 1185.12,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "some question about the human gut is",
      "offset": 1186.64,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "going to get it much worse than chat",
      "offset": 1188.48,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "GPT. The question is if you really care",
      "offset": 1189.84,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "and this is for something you know for",
      "offset": 1192.32,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "the investor community if you want to",
      "offset": 1193.76,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "make a bet on AI you really want to know",
      "offset": 1195.44,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "what you're talking about AI is very",
      "offset": 1197.679,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "very messy right now we're talking about",
      "offset": 1199.76,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "getting the quality of evidence that",
      "offset": 1201.84,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "would be useful for making million or",
      "offset": 1203.52,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "billion dollar decisions for there",
      "offset": 1205.12,
      "duration": 2.96
    },
    {
      "lang": "en",
      "text": "you're not you're not asking like what",
      "offset": 1206.88,
      "duration": 2.56
    },
    {
      "lang": "en",
      "text": "would the typical human do you're not",
      "offset": 1208.08,
      "duration": 2.719
    },
    {
      "lang": "en",
      "text": "asking like what would one prompt for",
      "offset": 1209.44,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "chat GPT do you're asking what is the",
      "offset": 1210.799,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "best possible answer to this question",
      "offset": 1213.2,
      "duration": 3.359
    },
    {
      "lang": "en",
      "text": "that I could get and that's you know",
      "offset": 1214.72,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "deep research is one attempt at that you",
      "offset": 1216.559,
      "duration": 3.761
    },
    {
      "lang": "en",
      "text": "know chat GPT's deep research mode in",
      "offset": 1218.559,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "Gemini's deep research mode, but there's",
      "offset": 1220.32,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "new ones. You know, the Gro 4 heavy has",
      "offset": 1222.24,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "its own claims about being more",
      "offset": 1224.24,
      "duration": 2.799
    },
    {
      "lang": "en",
      "text": "epistemically virtuous than other",
      "offset": 1225.6,
      "duration": 3.439
    },
    {
      "lang": "en",
      "text": "models. Do those things hold up under",
      "offset": 1227.039,
      "duration": 3.441
    },
    {
      "lang": "en",
      "text": "scrutiny? That's what the benchmark",
      "offset": 1229.039,
      "duration": 3.041
    },
    {
      "lang": "en",
      "text": "tells us. And then you get the sense of",
      "offset": 1230.48,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "what the frontier is. Now, I noticed on",
      "offset": 1232.08,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "your website that companies like OpenAI",
      "offset": 1234.48,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "and Amazon are customers. Uh so, and",
      "offset": 1236.4,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "Google, I think, as well. So, uh even",
      "offset": 1238.64,
      "duration": 2.96
    },
    {
      "lang": "en",
      "text": "though you're benchmarking these",
      "offset": 1240.559,
      "duration": 2.24
    },
    {
      "lang": "en",
      "text": "companies, and in some cases, what",
      "offset": 1241.6,
      "duration": 2.88
    },
    {
      "lang": "en",
      "text": "you're telling me right now is uh some",
      "offset": 1242.799,
      "duration": 3.041
    },
    {
      "lang": "en",
      "text": "of the models don't perform as well as",
      "offset": 1244.48,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "others, yet these companies are quite",
      "offset": 1245.84,
      "duration": 3.199
    },
    {
      "lang": "en",
      "text": "interested in getting your research. So",
      "offset": 1247.84,
      "duration": 3.199
    },
    {
      "lang": "en",
      "text": "are you creating a kind of like um I",
      "offset": 1249.039,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "don't know Neielson rating or billboard",
      "offset": 1251.039,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "top 10 chart for AI performance is that",
      "offset": 1252.88,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "is that kind of like an is it becoming",
      "offset": 1255.44,
      "duration": 3.359
    },
    {
      "lang": "en",
      "text": "an industry standard?",
      "offset": 1257.039,
      "duration": 3.201
    },
    {
      "lang": "en",
      "text": "Uh I would hope so. I think these",
      "offset": 1258.799,
      "duration": 2.801
    },
    {
      "lang": "en",
      "text": "benchmarks are quite important and",
      "offset": 1260.24,
      "duration": 2.64
    },
    {
      "lang": "en",
      "text": "future search is very happy to",
      "offset": 1261.6,
      "duration": 2.88
    },
    {
      "lang": "en",
      "text": "contribute deep research bench. Uh we",
      "offset": 1262.88,
      "duration": 3.039
    },
    {
      "lang": "en",
      "text": "have another benchmark on our site too.",
      "offset": 1264.48,
      "duration": 3.199
    },
    {
      "lang": "en",
      "text": "You can see that it's specifically about",
      "offset": 1265.919,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "forecasting using the same technique. Um",
      "offset": 1267.679,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "we call it past casting. Basically",
      "offset": 1270.08,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "freezing slices of the internet such",
      "offset": 1271.76,
      "duration": 2.96
    },
    {
      "lang": "en",
      "text": "that you can forecast from the",
      "offset": 1273.52,
      "duration": 2.639
    },
    {
      "lang": "en",
      "text": "perspective of the past and get the",
      "offset": 1274.72,
      "duration": 2.959
    },
    {
      "lang": "en",
      "text": "answer right away. It's a technique",
      "offset": 1276.159,
      "duration": 3.041
    },
    {
      "lang": "en",
      "text": "that's only available to AIS because",
      "offset": 1277.679,
      "duration": 3.201
    },
    {
      "lang": "en",
      "text": "once a human learns something, you can't",
      "offset": 1279.2,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "forecast it again. You just know the",
      "offset": 1280.88,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "answer. But AIs have training window cut",
      "offset": 1282.32,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "offs and you can restrict the",
      "offset": 1284.4,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "information they have access to and say",
      "offset": 1285.76,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "given these inputs, could you predict",
      "offset": 1287.6,
      "duration": 2.88
    },
    {
      "lang": "en",
      "text": "what will happen next? Like in real",
      "offset": 1288.96,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "world problems. Um, so yes, I think",
      "offset": 1290.48,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "these benchmarks are very important and",
      "offset": 1293.2,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "we're very happy to have the Frontier AI",
      "offset": 1294.64,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "labs be customers of ours. Uh, they're",
      "offset": 1296.64,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "sometimes by research on each other,",
      "offset": 1298.4,
      "duration": 2.8
    },
    {
      "lang": "en",
      "text": "which is, you know, kind of an",
      "offset": 1299.84,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "interesting use case for us. But",
      "offset": 1301.2,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "generally speaking, future search is",
      "offset": 1302.96,
      "duration": 2.959
    },
    {
      "lang": "en",
      "text": "about the software. It's not about the",
      "offset": 1304.32,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "benchmarks and it's not about the human",
      "offset": 1305.919,
      "duration": 2.481
    },
    {
      "lang": "en",
      "text": "intelligence. Other people have",
      "offset": 1307.36,
      "duration": 2.559
    },
    {
      "lang": "en",
      "text": "benchmarks. Plenty of other people have",
      "offset": 1308.4,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "human intelligence. It's the ability to",
      "offset": 1309.919,
      "duration": 4.481
    },
    {
      "lang": "en",
      "text": "train against those benchmarks and make",
      "offset": 1312.559,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "software that just makes better",
      "offset": 1314.4,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "epistemic decisions that is just less",
      "offset": 1315.919,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "likely to site Pravda and more likely to",
      "offset": 1317.76,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "have calibrated judgment in its output.",
      "offset": 1320.24,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "That's what is of the commercial value",
      "offset": 1322.48,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "that future search is going for. So,",
      "offset": 1324.24,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "we're very happy to sell this kind of AI",
      "offset": 1325.6,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "human hybrid research. We do just want",
      "offset": 1328.08,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "the best possible answer to questions",
      "offset": 1330.4,
      "duration": 3.279
    },
    {
      "lang": "en",
      "text": "and if that requires humans, we'll use",
      "offset": 1331.919,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "humans. But again, we're moving to a",
      "offset": 1333.679,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "world where AI is going to eclipse the",
      "offset": 1335.679,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "ability for humans to meaningfully add",
      "offset": 1337.36,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "judgment on these very very complicated",
      "offset": 1338.799,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "problems. And there it's the software",
      "offset": 1340.64,
      "duration": 3.519
    },
    {
      "lang": "en",
      "text": "that is our business.",
      "offset": 1342.559,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "Great. On that note, I'm going to take a",
      "offset": 1344.159,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "little break. Uh we'll be back in just a",
      "offset": 1345.919,
      "duration": 3.441
    },
    {
      "lang": "en",
      "text": "just a moment. Uh we have to have a word",
      "offset": 1348,
      "duration": 2.799
    },
    {
      "lang": "en",
      "text": "from our sponsors. You're listening to",
      "offset": 1349.36,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "the Futurist and our guest this week is",
      "offset": 1350.799,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "Dan Schwarz. We'll be right back after",
      "offset": 1352.48,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "this.",
      "offset": 1354.559,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "Hi, this is Rob Tursk from the Futurist",
      "offset": 1356.08,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "podcast which is part of the provoked",
      "offset": 1358.64,
      "duration": 3.519
    },
    {
      "lang": "en",
      "text": "media network. I'm excited to tell you",
      "offset": 1360.159,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "about some news. The Futurist is",
      "offset": 1362.159,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "expanding into the real world. We're",
      "offset": 1364,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "doing a live event in Dubai. Now, folks",
      "offset": 1365.919,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "who listen to the Futurist podcast,",
      "offset": 1368.64,
      "duration": 2.64
    },
    {
      "lang": "en",
      "text": "you're going to be familiar with the",
      "offset": 1370.32,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "fact that my co-host Brett King has been",
      "offset": 1371.28,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "working very hard in Dubai and other",
      "offset": 1373.76,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "parts of the Middle East for a long",
      "offset": 1375.679,
      "duration": 3.041
    },
    {
      "lang": "en",
      "text": "time. And for more than a year, he's",
      "offset": 1377.44,
      "duration": 2.56
    },
    {
      "lang": "en",
      "text": "been putting together this event. And",
      "offset": 1378.72,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "now, with the help and support of",
      "offset": 1380,
      "duration": 5.679
    },
    {
      "lang": "en",
      "text": "Mastercard and Emirates, MBD, and many",
      "offset": 1382.72,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "other partners, we are putting together",
      "offset": 1385.679,
      "duration": 4.641
    },
    {
      "lang": "en",
      "text": "the world's largest futurist meeting in",
      "offset": 1387.84,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "Dubai. It will take place at the",
      "offset": 1390.32,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "fabulous Jumariah Beach Hotel in Dubai",
      "offset": 1391.84,
      "duration": 5.92
    },
    {
      "lang": "en",
      "text": "and it'll be on the September 22nd and",
      "offset": 1395.12,
      "duration": 5.439
    },
    {
      "lang": "en",
      "text": "23rd this year. So just a few weeks from",
      "offset": 1397.76,
      "duration": 5.279
    },
    {
      "lang": "en",
      "text": "now. The speakers are going to include",
      "offset": 1400.559,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "some of the world's leading futurists",
      "offset": 1403.039,
      "duration": 4.481
    },
    {
      "lang": "en",
      "text": "and forecasters and future thinkers.",
      "offset": 1404.799,
      "duration": 4.961
    },
    {
      "lang": "en",
      "text": "People like Brian Cox and astronaut",
      "offset": 1407.52,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "Scott Kelly. Of course, Brett and I will",
      "offset": 1409.76,
      "duration": 2.799
    },
    {
      "lang": "en",
      "text": "be there to conduct interviews and",
      "offset": 1411.36,
      "duration": 2.88
    },
    {
      "lang": "en",
      "text": "introduce some of the other folks. We've",
      "offset": 1412.559,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "got speakers from around the world. And",
      "offset": 1414.24,
      "duration": 2.559
    },
    {
      "lang": "en",
      "text": "if you're interested in meeting",
      "offset": 1415.679,
      "duration": 3.281
    },
    {
      "lang": "en",
      "text": "futurists in person and participating an",
      "offset": 1416.799,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "event that that attracts the",
      "offset": 1418.96,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "future-minded, please join us on the",
      "offset": 1420.4,
      "duration": 5.279
    },
    {
      "lang": "en",
      "text": "22nd and 23rd of September, you can",
      "offset": 1422.96,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "learn more about it at",
      "offset": 1425.679,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "futuristevent.com.",
      "offset": 1426.96,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "That's futurists singularevent.com.",
      "offset": 1429.039,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "It's all one word, futurist",
      "offset": 1431.84,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "futuristevent.com",
      "offset": 1433.36,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "and that'll tell you all about the",
      "offset": 1435.28,
      "duration": 2.72
    },
    {
      "lang": "en",
      "text": "event. I sure hope to see you there in",
      "offset": 1436.4,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "Dubai on the 22nd and 23rd of September.",
      "offset": 1438,
      "duration": 5.84
    },
    {
      "lang": "en",
      "text": "Thanks. Hey there. Welcome back to the",
      "offset": 1441.6,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "futurist. I'm Rob Tersik and this week",
      "offset": 1443.84,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "I'm talking to Dan Schwarz who is the",
      "offset": 1445.36,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "found co-founder and CEO of",
      "offset": 1448.32,
      "duration": 4.479
    },
    {
      "lang": "en",
      "text": "futurearch.ai",
      "offset": 1450.88,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "and we've been having a lively",
      "offset": 1452.799,
      "duration": 3.201
    },
    {
      "lang": "en",
      "text": "conversation so far about forecasting",
      "offset": 1454.08,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "methodologies and and how they're",
      "offset": 1456,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "changing in the time of artificial",
      "offset": 1457.6,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "intelligence and I want to come back to",
      "offset": 1459.6,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "a question we you you touched on your",
      "offset": 1462,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "background at Metaculus. So before you",
      "offset": 1464.08,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "started this company uh you were at a",
      "offset": 1466.32,
      "duration": 3.359
    },
    {
      "lang": "en",
      "text": "company called Metaculus which is a",
      "offset": 1468.32,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "human forecasting organization. Can you",
      "offset": 1469.679,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "give me a contrast between that",
      "offset": 1472.159,
      "duration": 4.241
    },
    {
      "lang": "en",
      "text": "methodology, human forecasting, and then",
      "offset": 1473.84,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "what you're doing differently today with",
      "offset": 1476.4,
      "duration": 3.519
    },
    {
      "lang": "en",
      "text": "AI? And I realize some of this might be",
      "offset": 1478.24,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "a little bit redundant, so skip that",
      "offset": 1479.919,
      "duration": 3.281
    },
    {
      "lang": "en",
      "text": "part, but uh but the contrast is what",
      "offset": 1481.52,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "I'm interested in. Like what's new, uh",
      "offset": 1483.2,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "what's novel?",
      "offset": 1484.88,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "Absolutely. So even though I'm mostly",
      "offset": 1486.32,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "excited about the use of AI and",
      "offset": 1488,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "forecasting, I think the use of humans",
      "offset": 1489.52,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "in forecasting is still really poorly",
      "offset": 1491.2,
      "duration": 3.359
    },
    {
      "lang": "en",
      "text": "understood. And part of the reason that",
      "offset": 1492.96,
      "duration": 3.199
    },
    {
      "lang": "en",
      "text": "I as a technologist got interested in it",
      "offset": 1494.559,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "is because I saw how much better we",
      "offset": 1496.159,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "could be doing just with humans. Uh this",
      "offset": 1498.159,
      "duration": 4.241
    },
    {
      "lang": "en",
      "text": "is in 2019. You know, I was very",
      "offset": 1500.08,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "interested in forecasting in prediction",
      "offset": 1502.4,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "markets, not really in anything else,",
      "offset": 1504.88,
      "duration": 2.72
    },
    {
      "lang": "en",
      "text": "but just prediction markets. I thought",
      "offset": 1506.32,
      "duration": 2.4
    },
    {
      "lang": "en",
      "text": "prediction markets were totally",
      "offset": 1507.6,
      "duration": 2.8
    },
    {
      "lang": "en",
      "text": "fascinating. The idea that you could",
      "offset": 1508.72,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "take betting as the mechanism in order",
      "offset": 1510.4,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "to get accuracy out of humans. Um, I was",
      "offset": 1512.72,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "at Google at the time. I was actually",
      "offset": 1515.52,
      "duration": 2.96
    },
    {
      "lang": "en",
      "text": "working at Whimo on the self-driving",
      "offset": 1517.039,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "car. Uh, Google has a history of this.",
      "offset": 1518.48,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "In 2005, they released uh well not",
      "offset": 1520.88,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "released, they had an internal",
      "offset": 1523.6,
      "duration": 2.4
    },
    {
      "lang": "en",
      "text": "prediction market. It was called profit,",
      "offset": 1524.64,
      "duration": 3.039
    },
    {
      "lang": "en",
      "text": "but it was written about in the New York",
      "offset": 1526,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "Times and there was a Harvard Business",
      "offset": 1527.679,
      "duration": 3.041
    },
    {
      "lang": "en",
      "text": "School review of it. They called it",
      "offset": 1529.2,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "Google's lunchtime betting game. And",
      "offset": 1530.72,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "Google employees who in 2005 were very",
      "offset": 1533.039,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "sharp um would bet about things like how",
      "offset": 1535.44,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "many users will we have, how much",
      "offset": 1537.919,
      "duration": 2.561
    },
    {
      "lang": "en",
      "text": "revenue will we have, what will happen",
      "offset": 1539.12,
      "duration": 2.64
    },
    {
      "lang": "en",
      "text": "in this office, what will happen with",
      "offset": 1540.48,
      "duration": 2.4
    },
    {
      "lang": "en",
      "text": "our competitor",
      "offset": 1541.76,
      "duration": 2.96
    },
    {
      "lang": "en",
      "text": "and filter that information up to senior",
      "offset": 1542.88,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "management. Um the project ran for four",
      "offset": 1544.72,
      "duration": 5.199
    },
    {
      "lang": "en",
      "text": "or five years and was shut down. Um I've",
      "offset": 1547.44,
      "duration": 4.479
    },
    {
      "lang": "en",
      "text": "written a little bit about that and why",
      "offset": 1549.919,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "what worked about it and what didn't.",
      "offset": 1551.919,
      "duration": 3.521
    },
    {
      "lang": "en",
      "text": "But inside Google, reading about it and",
      "offset": 1553.679,
      "duration": 3.201
    },
    {
      "lang": "en",
      "text": "seeing all the internal documentation in",
      "offset": 1555.44,
      "duration": 3.359
    },
    {
      "lang": "en",
      "text": "the code, I was thinking, \"Wow, that",
      "offset": 1556.88,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "actually worked.\" Like building a",
      "offset": 1558.799,
      "duration": 3.281
    },
    {
      "lang": "en",
      "text": "betting market so that people could bet",
      "offset": 1560.48,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "on outcomes actually just gives better",
      "offset": 1562.08,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "information to managers. The managers",
      "offset": 1563.6,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "don't forecast by just kind of looking",
      "offset": 1565.6,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "at it and using their guts. They could",
      "offset": 1566.96,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "basically have a very sophisticated poll",
      "offset": 1568.88,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "of all the people working on the project",
      "offset": 1570.96,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "and use that to inform their decisions.",
      "offset": 1572.4,
      "duration": 5.279
    },
    {
      "lang": "en",
      "text": "And often surprisingly that kind of poll",
      "offset": 1574.64,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "if if you have a big enough sample size",
      "offset": 1577.679,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "or big enough number of participants",
      "offset": 1579.44,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "they're surprisingly accurate. You know",
      "offset": 1582.159,
      "duration": 3.041
    },
    {
      "lang": "en",
      "text": "they they come within one or two",
      "offset": 1583.84,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "percentage points of accuracy. Um even",
      "offset": 1585.2,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "though some of the individual answers",
      "offset": 1587.679,
      "duration": 5.281
    },
    {
      "lang": "en",
      "text": "might range quite far. Um do you think",
      "offset": 1589.279,
      "duration": 5.441
    },
    {
      "lang": "en",
      "text": "that's going to be improved upon or is",
      "offset": 1592.96,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "that going to be an input in the future?",
      "offset": 1594.72,
      "duration": 4.959
    },
    {
      "lang": "en",
      "text": "Yeah. So yeah. So I'll try to say a",
      "offset": 1596.799,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "little bit more about what that frontier",
      "offset": 1599.679,
      "duration": 3.521
    },
    {
      "lang": "en",
      "text": "is. you know how good a forecasting I",
      "offset": 1601.2,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "was able to achieve with the prediction",
      "offset": 1603.2,
      "duration": 2.719
    },
    {
      "lang": "en",
      "text": "market running at Google and then the",
      "offset": 1604.64,
      "duration": 2.96
    },
    {
      "lang": "en",
      "text": "forecasting platform at Metaculus which",
      "offset": 1605.919,
      "duration": 3.041
    },
    {
      "lang": "en",
      "text": "is public so you know it's even open",
      "offset": 1607.6,
      "duration": 2.72
    },
    {
      "lang": "en",
      "text": "source so you can go and look and see",
      "offset": 1608.96,
      "duration": 2.719
    },
    {
      "lang": "en",
      "text": "what is everybody forecasting what are",
      "offset": 1610.32,
      "duration": 2.8
    },
    {
      "lang": "en",
      "text": "the track records and accuracy scores",
      "offset": 1611.679,
      "duration": 2.961
    },
    {
      "lang": "en",
      "text": "it's a bit technical but all that",
      "offset": 1613.12,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "information is out there um and yeah the",
      "offset": 1614.64,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "reason I was so excited about it you",
      "offset": 1618,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "know I was just kind of the normal",
      "offset": 1620,
      "duration": 2.96
    },
    {
      "lang": "en",
      "text": "technologist the reason I got so excited",
      "offset": 1621.2,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "about it is because the accuracy scores",
      "offset": 1622.96,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "were just very high and this again this",
      "offset": 1624.32,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "is kind of the the Tetlock school you",
      "offset": 1626.64,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "know reading those papers and seeing",
      "offset": 1628.48,
      "duration": 2.96
    },
    {
      "lang": "en",
      "text": "what some of his super forecasters were",
      "offset": 1629.76,
      "duration": 2.72
    },
    {
      "lang": "en",
      "text": "able to do that you were talking about",
      "offset": 1631.44,
      "duration": 2.8
    },
    {
      "lang": "en",
      "text": "in the last segment, Robert. It's",
      "offset": 1632.48,
      "duration": 3.439
    },
    {
      "lang": "en",
      "text": "astounding. I think that most people's",
      "offset": 1634.24,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "view is that the future is just totally",
      "offset": 1635.919,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "unknowable. Like basically everything is",
      "offset": 1638.159,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "50/50. There's not really much you can",
      "offset": 1639.84,
      "duration": 3.199
    },
    {
      "lang": "en",
      "text": "say. You just have to wait and find out.",
      "offset": 1641.279,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "And Tedlock demonstrated that was far",
      "offset": 1643.039,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "from true. Like you can get really great",
      "offset": 1644.88,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "accuracy. Now very very few humans can",
      "offset": 1646.64,
      "duration": 3.279
    },
    {
      "lang": "en",
      "text": "do it and they have to do it in specific",
      "offset": 1648.72,
      "duration": 2.72
    },
    {
      "lang": "en",
      "text": "ways as you were discussing in the last",
      "offset": 1649.919,
      "duration": 3.281
    },
    {
      "lang": "en",
      "text": "segment, but it does work and those",
      "offset": 1651.44,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "accuracy scores are good. And then the",
      "offset": 1653.2,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "evidence from Google's internal",
      "offset": 1655.44,
      "duration": 2.8
    },
    {
      "lang": "en",
      "text": "prediction market was the same. you look",
      "offset": 1656.72,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "at that calibration chart when Google",
      "offset": 1658.24,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "employees betting with each other was",
      "offset": 1660.48,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "ended with a you know 35% chance of",
      "offset": 1662.48,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "something happening it tended to happen",
      "offset": 1664.48,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "35% of the time and that's just",
      "offset": 1666.08,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "astounding to me when I was looking at",
      "offset": 1668.32,
      "duration": 2.8
    },
    {
      "lang": "en",
      "text": "that data I could not believe that you",
      "offset": 1669.6,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "could actually do that",
      "offset": 1671.12,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "the the collective wisdom or the",
      "offset": 1672.72,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "collective forecasting capability of a",
      "offset": 1674.48,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "lot of human minds is quite powerful",
      "offset": 1676.559,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "obviously you know two heads are better",
      "offset": 1678.88,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "than one but in this case you're talking",
      "offset": 1680.88,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "about thousands of minds in a way it is",
      "offset": 1682.24,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "a kind of super intelligence or an",
      "offset": 1684.96,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "artificial artificial intelligence",
      "offset": 1687.36,
      "duration": 2.08
    },
    {
      "lang": "en",
      "text": "because you're harnessing the for the",
      "offset": 1688.24,
      "duration": 2.559
    },
    {
      "lang": "en",
      "text": "forecasting capability of a lot of",
      "offset": 1689.44,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "different individuals. So, it's not a",
      "offset": 1690.799,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "natural thing. Um, and you're going to",
      "offset": 1692.64,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "it would be likely or I think reasonable",
      "offset": 1695.12,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "to expect that to outperform an",
      "offset": 1696.88,
      "duration": 5.919
    },
    {
      "lang": "en",
      "text": "individual. Um, the uh",
      "offset": 1698.88,
      "duration": 6.24
    },
    {
      "lang": "en",
      "text": "yeah, the super super conversation I'm",
      "offset": 1702.799,
      "duration": 3.441
    },
    {
      "lang": "en",
      "text": "enjoying. I like the fact that you can",
      "offset": 1705.12,
      "duration": 2.559
    },
    {
      "lang": "en",
      "text": "root this all back in Tetlock because",
      "offset": 1706.24,
      "duration": 3.439
    },
    {
      "lang": "en",
      "text": "I'm a fan. I think more people should",
      "offset": 1707.679,
      "duration": 3.761
    },
    {
      "lang": "en",
      "text": "know about the the super forecasting",
      "offset": 1709.679,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "methodology. But one thing about Teloc",
      "offset": 1711.44,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "is that uh forecasters are his",
      "offset": 1713.36,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "forecasters are successful or you know",
      "offset": 1715.36,
      "duration": 5.039
    },
    {
      "lang": "en",
      "text": "expert in one domain and it's very rare",
      "offset": 1717.52,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "to find someone who can accurately",
      "offset": 1720.399,
      "duration": 4.241
    },
    {
      "lang": "en",
      "text": "forecast across multiple domains. Now",
      "offset": 1721.919,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "with artificial intelligence it seems to",
      "offset": 1724.64,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "me once the AI has been trained on how",
      "offset": 1726.32,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "to do fairly good reasoning and how to",
      "offset": 1729.36,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "you know kind of evaluate the sources so",
      "offset": 1731.76,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "it makes good decisions maybe there's",
      "offset": 1733.6,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "work to be done there still. uh but it",
      "offset": 1735.52,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "will be able to apply that broadly",
      "offset": 1737.52,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "across multiple domains not not limited",
      "offset": 1738.72,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "to a single domain. Is that something",
      "offset": 1740.88,
      "duration": 3.679
    },
    {
      "lang": "en",
      "text": "that you are observing? Is that was that",
      "offset": 1743.039,
      "duration": 2.88
    },
    {
      "lang": "en",
      "text": "one of the inspirations for starting",
      "offset": 1744.559,
      "duration": 2.72
    },
    {
      "lang": "en",
      "text": "future search?",
      "offset": 1745.919,
      "duration": 2.88
    },
    {
      "lang": "en",
      "text": "Yeah. So you know I was the CTO of",
      "offset": 1747.279,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "Metaculus. My co-founder uh Lawrence",
      "offset": 1748.799,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "Phillips was the head of AI there and we",
      "offset": 1750.88,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "were looking at these AI forecasts with",
      "offset": 1753.2,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "with the platform and trying to figure",
      "offset": 1755.2,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "out how to make them more accurate. We",
      "offset": 1756.96,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "were looking at really hard questions.",
      "offset": 1758.32,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "Uh the single most popular metaculous",
      "offset": 1760.48,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "question is about the arrival date of",
      "offset": 1762.72,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "AGI. um in the in the subsequent years",
      "offset": 1764.08,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "um that's become even more trendy. That",
      "offset": 1767.76,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "question was originally written you know",
      "offset": 1769.76,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "in 2017 or 2018. You know the platform",
      "offset": 1771.2,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "metacula started in 2015. It even",
      "offset": 1773.679,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "predates Tetlo's book super forecasters.",
      "offset": 1775.44,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "So people have been trying to use the",
      "offset": 1777.84,
      "duration": 3.439
    },
    {
      "lang": "en",
      "text": "collective human wisdom to answer this",
      "offset": 1779.52,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "question. What's going to happen with AI",
      "offset": 1781.279,
      "duration": 4.241
    },
    {
      "lang": "en",
      "text": "for years now? Um and we were not",
      "offset": 1782.88,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "satisfied. Lawrence and I were looking",
      "offset": 1785.52,
      "duration": 3.279
    },
    {
      "lang": "en",
      "text": "at those human forecasts that were being",
      "offset": 1787.12,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "aggregated, all the scoring methodology,",
      "offset": 1788.799,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "the the math behind it, the kind of",
      "offset": 1790.48,
      "duration": 2.96
    },
    {
      "lang": "en",
      "text": "forecast elicitation, the research",
      "offset": 1791.919,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "people were doing and we just became",
      "offset": 1793.44,
      "duration": 3.359
    },
    {
      "lang": "en",
      "text": "convinced that this could not be done",
      "offset": 1795.52,
      "duration": 2.96
    },
    {
      "lang": "en",
      "text": "without AI assistance. Like the the",
      "offset": 1796.799,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "human frontier was not good enough to",
      "offset": 1798.48,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "tell us what was going to happen in AI",
      "offset": 1800.64,
      "duration": 2.639
    },
    {
      "lang": "en",
      "text": "and that's what Lawrence and I really",
      "offset": 1802.08,
      "duration": 2.959
    },
    {
      "lang": "en",
      "text": "wanted to know. You know, we would get",
      "offset": 1803.279,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "hung up on these details. So something",
      "offset": 1805.039,
      "duration": 5.041
    },
    {
      "lang": "en",
      "text": "like uh when is GBD5 going to come out?",
      "offset": 1807.44,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "One of the things you might want to",
      "offset": 1810.08,
      "duration": 2.56
    },
    {
      "lang": "en",
      "text": "think about for when GBD5 is going to",
      "offset": 1811.12,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "come out is what's going on with China?",
      "offset": 1812.64,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "Because to what extent is open AI racing",
      "offset": 1814.64,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "now since we asked that question things",
      "offset": 1817.12,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "have changed a lot I think open AI is",
      "offset": 1818.799,
      "duration": 2.88
    },
    {
      "lang": "en",
      "text": "much more concerned about anthropic and",
      "offset": 1820.24,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "Google now than it is about you know by",
      "offset": 1821.679,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "do and 10 cent and deepseeek although I",
      "offset": 1823.84,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "don't know I mean it's quite complicated",
      "offset": 1825.919,
      "duration": 3.521
    },
    {
      "lang": "en",
      "text": "but the moment you ask that question the",
      "offset": 1827.52,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "moment that you think the US China",
      "offset": 1829.44,
      "duration": 2.88
    },
    {
      "lang": "en",
      "text": "relations is relevant you just open this",
      "offset": 1830.64,
      "duration": 3.519
    },
    {
      "lang": "en",
      "text": "whole Pandora's box of complexity that",
      "offset": 1832.32,
      "duration": 3.599
    },
    {
      "lang": "en",
      "text": "no human could grapple with you're",
      "offset": 1834.159,
      "duration": 3.281
    },
    {
      "lang": "en",
      "text": "suddenly looking at okay there's all",
      "offset": 1835.919,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "these export controls like which ones",
      "offset": 1837.44,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "are in effect which ones are actually",
      "offset": 1839.279,
      "duration": 3.361
    },
    {
      "lang": "en",
      "text": "useful if those semiconductors are",
      "offset": 1840.72,
      "duration": 3.199
    },
    {
      "lang": "en",
      "text": "actually restricted how much does that",
      "offset": 1842.64,
      "duration": 2.8
    },
    {
      "lang": "en",
      "text": "slow down their research.",
      "offset": 1843.919,
      "duration": 3.041
    },
    {
      "lang": "en",
      "text": "If the semiconductors are slowing down",
      "offset": 1845.44,
      "duration": 2.719
    },
    {
      "lang": "en",
      "text": "their research, how much of that is",
      "offset": 1846.96,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "known by the leadership of Open AI, are",
      "offset": 1848.159,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "they taking that into account and just",
      "offset": 1850.24,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "on and on and on and on and on. The idea",
      "offset": 1852,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "that a human could sit down just with a",
      "offset": 1854.08,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "pencil and paper and just kind of reason",
      "offset": 1855.76,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "through that. We we talk to our",
      "offset": 1857.2,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "forecasters and they would say, \"Look,",
      "offset": 1859.6,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "I've got a tiny angle on this. I've got",
      "offset": 1860.96,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "a little bit of an intuition.\" And we",
      "offset": 1862.88,
      "duration": 2.48
    },
    {
      "lang": "en",
      "text": "just kind of hope by having a thousand",
      "offset": 1864.24,
      "duration": 2.96
    },
    {
      "lang": "en",
      "text": "of them that the signal would come out.",
      "offset": 1865.36,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "But on the hardest questions, the the",
      "offset": 1867.2,
      "duration": 3.199
    },
    {
      "lang": "en",
      "text": "evidence suggests that the forecasts are",
      "offset": 1868.88,
      "duration": 2.96
    },
    {
      "lang": "en",
      "text": "much less accurate. forecasting the",
      "offset": 1870.399,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "future of technology is unbelievably",
      "offset": 1871.84,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "hard as I'm sure you know Robert better",
      "offset": 1874,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "than most. Um so we said okay we need",
      "offset": 1875.76,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "more like we need more intelligence and",
      "offset": 1878.24,
      "duration": 3.679
    },
    {
      "lang": "en",
      "text": "of course the source of new intelligence",
      "offset": 1880.32,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "is not throw more humans at the problem",
      "offset": 1881.919,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "it's put some AI on it and that's where",
      "offset": 1884.24,
      "duration": 2.88
    },
    {
      "lang": "en",
      "text": "we are now",
      "offset": 1886.159,
      "duration": 3.361
    },
    {
      "lang": "en",
      "text": "and but but it's not just a quantitative",
      "offset": 1887.12,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "change uh you know more AI versus more",
      "offset": 1889.52,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "throwing more humans at the problem. I",
      "offset": 1892,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "think what you're suggesting here is",
      "offset": 1894.24,
      "duration": 2.96
    },
    {
      "lang": "en",
      "text": "there's a qualitative change as well. um",
      "offset": 1895.36,
      "duration": 3.439
    },
    {
      "lang": "en",
      "text": "when you have a machine intelligence",
      "offset": 1897.2,
      "duration": 3.199
    },
    {
      "lang": "en",
      "text": "it's actually going to perform that",
      "offset": 1898.799,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "function in a way that humans would not",
      "offset": 1900.399,
      "duration": 4.241
    },
    {
      "lang": "en",
      "text": "even a collection of human minds could",
      "offset": 1902.48,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "not because human minds don't think that",
      "offset": 1904.64,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "way is that your observation and was",
      "offset": 1906.24,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "that the inspiration for starting your",
      "offset": 1908.48,
      "duration": 2.319
    },
    {
      "lang": "en",
      "text": "company",
      "offset": 1910,
      "duration": 3.679
    },
    {
      "lang": "en",
      "text": "absolutely um it was quite clear that",
      "offset": 1910.799,
      "duration": 5.281
    },
    {
      "lang": "en",
      "text": "talking to GPD4 even in the early GPD4",
      "offset": 1913.679,
      "duration": 4.641
    },
    {
      "lang": "en",
      "text": "days was like talking to a whole group",
      "offset": 1916.08,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "of people and if the core insight from",
      "offset": 1918.32,
      "duration": 4.479
    },
    {
      "lang": "en",
      "text": "forecasting is don't just do one person",
      "offset": 1920.399,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "do multiple people and also pick people",
      "offset": 1922.799,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "who are actually good at it GPD4 was",
      "offset": 1924.559,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "kind of like a hive mind. You know, when",
      "offset": 1926.799,
      "duration": 3.441
    },
    {
      "lang": "en",
      "text": "we were looking at it, it was kind of",
      "offset": 1928.88,
      "duration": 3.279
    },
    {
      "lang": "en",
      "text": "like talking to a thousand people. It",
      "offset": 1930.24,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "just knew absolutely everything. If you",
      "offset": 1932.159,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "could have one intelligence that has the",
      "offset": 1934.32,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "breadth of a thousand or even a million",
      "offset": 1936.24,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "humans. And you know that breadth of",
      "offset": 1938.159,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "knowledge is useful in forecasting.",
      "offset": 1940,
      "duration": 2.96
    },
    {
      "lang": "en",
      "text": "Well, then it's just obvious. You got to",
      "offset": 1941.519,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "try to see if GPD4 can forecast. But",
      "offset": 1942.96,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "again, we were not the only ones to run",
      "offset": 1945.2,
      "duration": 3.199
    },
    {
      "lang": "en",
      "text": "experiments to see how well GPD4 could",
      "offset": 1946.64,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "predict the future when it came out. And",
      "offset": 1948.399,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "the answer was it was terrible. Um and",
      "offset": 1950,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "so it became basically an engineering",
      "offset": 1952.159,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "and a research and an AI problem to say",
      "offset": 1953.76,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "look the the seed like the potential is",
      "offset": 1955.679,
      "duration": 4.561
    },
    {
      "lang": "en",
      "text": "clearly there as as we know from human",
      "offset": 1957.919,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "forecasting like it has the knowledge",
      "offset": 1960.24,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "and the ability to do the research that",
      "offset": 1962.24,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "could make superhuman forecasting",
      "offset": 1964.08,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "possible with an AI but somebody has to",
      "offset": 1965.6,
      "duration": 4.799
    },
    {
      "lang": "en",
      "text": "go build it and that's what we're doing.",
      "offset": 1967.76,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "Now in the beginning of the show you",
      "offset": 1970.399,
      "duration": 3.201
    },
    {
      "lang": "en",
      "text": "mentioned that there's a limited time",
      "offset": 1971.84,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "where humans will be able to outperform",
      "offset": 1973.6,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "AI and even at this stage uh taken on an",
      "offset": 1975.679,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "individual basis AI is going to",
      "offset": 1979.2,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "outperform just about anybody on most",
      "offset": 1980.799,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "tasks. We might still one or two of us",
      "offset": 1982.48,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "might still be able to outperform on a",
      "offset": 1984.96,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "particular set of tasks but broadly",
      "offset": 1986.48,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "speaking AI is already at a point where",
      "offset": 1988.88,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "it can outthink us and outperform us and",
      "offset": 1990.48,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "do so faster and more accurately uh than",
      "offset": 1993.2,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "we can do in most domains. But in the",
      "offset": 1995.6,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "beginning of the show, you said that",
      "offset": 1998.08,
      "duration": 2.719
    },
    {
      "lang": "en",
      "text": "that's coming to an end that at some",
      "offset": 1999.2,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "point in the near future, you forecast",
      "offset": 2000.799,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "or you believe that uh artificial",
      "offset": 2002.72,
      "duration": 3.439
    },
    {
      "lang": "en",
      "text": "intelligence will outperform all humans",
      "offset": 2004.559,
      "duration": 3.521
    },
    {
      "lang": "en",
      "text": "in all categories. Is am I am I",
      "offset": 2006.159,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "restating your assumption correctly or",
      "offset": 2008.08,
      "duration": 2.64
    },
    {
      "lang": "en",
      "text": "maybe I got it wrong?",
      "offset": 2009.84,
      "duration": 2.24
    },
    {
      "lang": "en",
      "text": "Well, I was making this the slightly",
      "offset": 2010.72,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "narrower claim that I think AI",
      "offset": 2012.08,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "unassisted will outperform human",
      "offset": 2014.08,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "forecasters pretty soon. Uh forecasting",
      "offset": 2016,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "is kind of like the most, you know,",
      "offset": 2018.399,
      "duration": 4.721
    },
    {
      "lang": "en",
      "text": "elite form of intelligence because to",
      "offset": 2021.2,
      "duration": 3.199
    },
    {
      "lang": "en",
      "text": "predict the future, you basically have",
      "offset": 2023.12,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "to model the entire world. If you're",
      "offset": 2024.399,
      "duration": 3.041
    },
    {
      "lang": "en",
      "text": "going to answer any forecasting",
      "offset": 2026.24,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "question, you have to understand science",
      "offset": 2027.44,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "and philosophy and culture and",
      "offset": 2029.36,
      "duration": 3.679
    },
    {
      "lang": "en",
      "text": "geopolitics and economics and everything",
      "offset": 2031.2,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "else. So when I say AI will outperform",
      "offset": 2033.039,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "humans in forecasting, I'm kind of",
      "offset": 2035.76,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "making the claim that AI will outperform",
      "offset": 2037.279,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "humans on everything.",
      "offset": 2038.96,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "But I am talking just about basically",
      "offset": 2040.559,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "making probabilistic statements about",
      "offset": 2042.24,
      "duration": 3.279
    },
    {
      "lang": "en",
      "text": "the future and then scoring them.",
      "offset": 2043.679,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "I I admire your constraint. Uh that's",
      "offset": 2045.519,
      "duration": 5.201
    },
    {
      "lang": "en",
      "text": "good because we've had many folks on the",
      "offset": 2048.159,
      "duration": 6.321
    },
    {
      "lang": "en",
      "text": "show who make very broad sweeping claims",
      "offset": 2050.72,
      "duration": 5.359
    },
    {
      "lang": "en",
      "text": "uh that I think are unsupportable. You",
      "offset": 2054.48,
      "duration": 2.56
    },
    {
      "lang": "en",
      "text": "know, they they're they're kind of",
      "offset": 2056.079,
      "duration": 2.56
    },
    {
      "lang": "en",
      "text": "extrapolating from what they know in one",
      "offset": 2057.04,
      "duration": 2.72
    },
    {
      "lang": "en",
      "text": "domain and they're saying, \"Well, that's",
      "offset": 2058.639,
      "duration": 2.881
    },
    {
      "lang": "en",
      "text": "going to happen across the board.\" And I",
      "offset": 2059.76,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "like to remind those folks that there",
      "offset": 2061.52,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "are many many things that humans do that",
      "offset": 2062.8,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "machines cannot do and will not do",
      "offset": 2064.56,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "anytime soon. Um you know, just consider",
      "offset": 2066.24,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "the people that build your house or",
      "offset": 2068.8,
      "duration": 2.879
    },
    {
      "lang": "en",
      "text": "repair your house or do the plumbing in",
      "offset": 2070,
      "duration": 3.359
    },
    {
      "lang": "en",
      "text": "your house or the electricity and so",
      "offset": 2071.679,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "forth. it there are a lot of tasks that",
      "offset": 2073.359,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "humans are quite capable of and frankly",
      "offset": 2075.599,
      "duration": 4.961
    },
    {
      "lang": "en",
      "text": "we're very good at uh and robots and and",
      "offset": 2077.76,
      "duration": 5.359
    },
    {
      "lang": "en",
      "text": "AI are not yet able to do those things",
      "offset": 2080.56,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "and it may be possible in the future but",
      "offset": 2083.119,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "even then it might not be economically",
      "offset": 2085.52,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "feasible to replace human workers uh for",
      "offset": 2086.96,
      "duration": 4.879
    },
    {
      "lang": "en",
      "text": "a lot of those tasks that",
      "offset": 2089.52,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "example there which is talking to people",
      "offset": 2091.839,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "one of the things that a great",
      "offset": 2093.919,
      "duration": 2.48
    },
    {
      "lang": "en",
      "text": "forecaster will do in order to make a",
      "offset": 2094.879,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "great forecast is go talk to people who",
      "offset": 2096.399,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "are subject matter experts or insiders",
      "offset": 2098.079,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "and see what they say you know chat GBT",
      "offset": 2099.839,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "can uh summon up an email client and",
      "offset": 2102,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "email a professor of microbiology and",
      "offset": 2104,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "ask them a question, but I don't think",
      "offset": 2106.079,
      "duration": 2.641
    },
    {
      "lang": "en",
      "text": "they're going to get a response. Whereas",
      "offset": 2107.2,
      "duration": 2.879
    },
    {
      "lang": "en",
      "text": "a human could reach out to them and have",
      "offset": 2108.72,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "a plausible chance of getting that. So,",
      "offset": 2110.079,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "the kind of the leg work of forecasting",
      "offset": 2111.76,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "is actually still solidly in the human",
      "offset": 2113.68,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "camp. And it's not clear how drawing",
      "offset": 2115.44,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "from other humans is going to be",
      "offset": 2117.76,
      "duration": 2.96
    },
    {
      "lang": "en",
      "text": "something that an AI system is going to",
      "offset": 2119.28,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "be able to do autonomously. So I very",
      "offset": 2120.72,
      "duration": 3.359
    },
    {
      "lang": "en",
      "text": "much agree like operating in the real",
      "offset": 2122.72,
      "duration": 3.119
    },
    {
      "lang": "en",
      "text": "world humans have many advantages and",
      "offset": 2124.079,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "we're not close to all of those",
      "offset": 2125.839,
      "duration": 2.961
    },
    {
      "lang": "en",
      "text": "advantages just going to zero across",
      "offset": 2127.119,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "every industry maybe in a long time",
      "offset": 2128.8,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "unless we have some sort of super",
      "offset": 2131.119,
      "duration": 3.761
    },
    {
      "lang": "en",
      "text": "intelligent explosion.",
      "offset": 2132.48,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "I think it's important for people to",
      "offset": 2134.88,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "hear that. Um we recently had a guest on",
      "offset": 2136.16,
      "duration": 6.24
    },
    {
      "lang": "en",
      "text": "who I disagreed with uh quite strongly",
      "offset": 2138.4,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "um because he made the very fil claim",
      "offset": 2142.4,
      "duration": 4.719
    },
    {
      "lang": "en",
      "text": "that within a couple of years um humans",
      "offset": 2144.4,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "won't I think he's to summarize probably",
      "offset": 2147.119,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "unfairly uh to summarize what he was",
      "offset": 2149.92,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "trying to say is that in a few years",
      "offset": 2151.599,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "machine intelligence will will be so",
      "offset": 2153.76,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "advanced that there'll be no work left",
      "offset": 2155.839,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "for humans. And again I'm probably being",
      "offset": 2158.32,
      "duration": 3.519
    },
    {
      "lang": "en",
      "text": "unfair. I don't know if he made that",
      "offset": 2160.24,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "exact claim, but you do hear that quite",
      "offset": 2161.839,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "often, right, in the in the tech trades",
      "offset": 2163.44,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "and in Silicon Valley, this kind of",
      "offset": 2165.44,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "euphoria uh about this moment in time",
      "offset": 2167.68,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "that seems to be just around the corner,",
      "offset": 2170.24,
      "duration": 3.119
    },
    {
      "lang": "en",
      "text": "but it's always just around the corner.",
      "offset": 2171.92,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "It never seems to get quite here. Um,",
      "offset": 2173.359,
      "duration": 6.161
    },
    {
      "lang": "en",
      "text": "and that at that time magically machines",
      "offset": 2176.4,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "will be about performance across the",
      "offset": 2179.52,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "board in every human function and",
      "offset": 2180.88,
      "duration": 4.239
    },
    {
      "lang": "en",
      "text": "therefore there'll be no jobs left for",
      "offset": 2182.64,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "humans. And I think that therefore uh",
      "offset": 2185.119,
      "duration": 5.601
    },
    {
      "lang": "en",
      "text": "part is a huge assumption that is",
      "offset": 2187.44,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "probably incorrect. Like in other words,",
      "offset": 2190.72,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "I don't lose any sleep about humans",
      "offset": 2192.64,
      "duration": 4.479
    },
    {
      "lang": "en",
      "text": "losing their jobs anytime soon. Um I",
      "offset": 2194.16,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "noticed that it's extremely hard to hire",
      "offset": 2197.119,
      "duration": 3.521
    },
    {
      "lang": "en",
      "text": "people right now in the United States.",
      "offset": 2199.04,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "We are very close to full employment.",
      "offset": 2200.64,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "There are a lot of unfilled jobs and",
      "offset": 2202.72,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "here we have the smartest minds in the",
      "offset": 2205.04,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "country in the technology industry and",
      "offset": 2206.48,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "they're speculating about the fact that",
      "offset": 2208.24,
      "duration": 2.64
    },
    {
      "lang": "en",
      "text": "there'll be no jobs for humans in the",
      "offset": 2209.52,
      "duration": 2.72
    },
    {
      "lang": "en",
      "text": "near future. I can't get those two",
      "offset": 2210.88,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "things to reconcile in my mind. Can you",
      "offset": 2212.24,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "share your perspectives on that lively",
      "offset": 2214.4,
      "duration": 2.719
    },
    {
      "lang": "en",
      "text": "topic?",
      "offset": 2216.16,
      "duration": 2.72
    },
    {
      "lang": "en",
      "text": "Yeah. Uh that's a great point and I I",
      "offset": 2217.119,
      "duration": 3.281
    },
    {
      "lang": "en",
      "text": "mostly agree with you Robert. I think I",
      "offset": 2218.88,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "I'll try to make the you know I guess",
      "offset": 2220.4,
      "duration": 3.439
    },
    {
      "lang": "en",
      "text": "what I would call the steelman case for",
      "offset": 2222.16,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "how that could actually happen. Uh but",
      "offset": 2223.839,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "you know one of the trueisms among the",
      "offset": 2226.16,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "forecasting community is if you just get",
      "offset": 2227.92,
      "duration": 2.88
    },
    {
      "lang": "en",
      "text": "a forecasting question you should just",
      "offset": 2229.52,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "say no like nothing ever happens like",
      "offset": 2230.8,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "almost any question you get this is even",
      "offset": 2232.72,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "shown in platforms the one that I built",
      "offset": 2234.56,
      "duration": 3.039
    },
    {
      "lang": "en",
      "text": "and ran at Google and on Metaculus like",
      "offset": 2235.92,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "70% of questions like will this happen",
      "offset": 2237.599,
      "duration": 5.281
    },
    {
      "lang": "en",
      "text": "by this date for any this answer is no.",
      "offset": 2239.52,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "Um, so I think having a kind of a status",
      "offset": 2242.88,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "quo prior is just a very healthy",
      "offset": 2244.88,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "epistemic disposition to have as a",
      "offset": 2246.72,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "forecaster. Um, you know, as a Silicon",
      "offset": 2248.4,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "Valley person, as a technologist, as",
      "offset": 2251.68,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "somebody working on AI and trying to",
      "offset": 2253.44,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "make it more capable. Uh, I am very",
      "offset": 2254.8,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "interested in these claims that we will",
      "offset": 2256.8,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "have an intelligence explosion or some",
      "offset": 2258.32,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "sort of superhuman thing that can do",
      "offset": 2259.92,
      "duration": 3.679
    },
    {
      "lang": "en",
      "text": "everything. This I only see one",
      "offset": 2261.44,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "plausible way under which that would",
      "offset": 2263.599,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "happen and that's in the AI 2027",
      "offset": 2265.52,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "scenario that I encourage your audience",
      "offset": 2267.839,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "to check out. it it's a very specific",
      "offset": 2269.52,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "path. Step one, AI gets very very good",
      "offset": 2271.68,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "at software engineering. Now, this is",
      "offset": 2274.72,
      "duration": 3.359
    },
    {
      "lang": "en",
      "text": "very plausible because AI is already",
      "offset": 2276.56,
      "duration": 2.96
    },
    {
      "lang": "en",
      "text": "pretty good at software engineering.",
      "offset": 2278.079,
      "duration": 2.881
    },
    {
      "lang": "en",
      "text": "Now, software engineering is only I",
      "offset": 2279.52,
      "duration": 2.88
    },
    {
      "lang": "en",
      "text": "don't know 1% of the economy. So, you",
      "offset": 2280.96,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "might say, what's the big deal? But most",
      "offset": 2282.4,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "of the development of AI at AI companies",
      "offset": 2284.72,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "is being done by software engineers. So,",
      "offset": 2286.8,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "if software engineering becomes 10 times",
      "offset": 2289.04,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "more productive or 10 times faster, then",
      "offset": 2291.2,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "the next iteration of the AI model",
      "offset": 2293.52,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "should be coming that much sooner. And",
      "offset": 2295.28,
      "duration": 2.799
    },
    {
      "lang": "en",
      "text": "there's a bit of a feedback loop there",
      "offset": 2296.72,
      "duration": 2.8
    },
    {
      "lang": "en",
      "text": "because as it gets smarter, it will be",
      "offset": 2298.079,
      "duration": 3.201
    },
    {
      "lang": "en",
      "text": "an even better software engineer. So",
      "offset": 2299.52,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "that's step one. Step two is having AI",
      "offset": 2301.28,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "good at doing AI research. Now, a lot of",
      "offset": 2303.92,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "AI research is software. You have to",
      "offset": 2306.4,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "write experiment code. You have to train",
      "offset": 2308.16,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "new models. You have to release them,",
      "offset": 2309.92,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "get feedback from humans. But a lot of",
      "offset": 2311.2,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "research is just research. It's just",
      "offset": 2313.52,
      "duration": 2.72
    },
    {
      "lang": "en",
      "text": "thinking about like what's the best",
      "offset": 2315.04,
      "duration": 2.72
    },
    {
      "lang": "en",
      "text": "algorithm? Like where am I going to get",
      "offset": 2316.24,
      "duration": 2.879
    },
    {
      "lang": "en",
      "text": "the best training data? Like what did",
      "offset": 2317.76,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "this experiment tell me? Right now AI is",
      "offset": 2319.119,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "not very good at these things. But as it",
      "offset": 2321.28,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "gets better at software, we're expecting",
      "offset": 2323.2,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "it to get better at research. Once it",
      "offset": 2324.64,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "gets better at research, again, there's",
      "offset": 2326.56,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "a positive feedback loop. The research",
      "offset": 2327.76,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "is done a little bit faster, so the next",
      "offset": 2330,
      "duration": 2.96
    },
    {
      "lang": "en",
      "text": "generation of the model comes out a",
      "offset": 2331.68,
      "duration": 2.56
    },
    {
      "lang": "en",
      "text": "little bit sooner, which makes it a",
      "offset": 2332.96,
      "duration": 2.96
    },
    {
      "lang": "en",
      "text": "little bit faster to do the next set of",
      "offset": 2334.24,
      "duration": 3.119
    },
    {
      "lang": "en",
      "text": "research to generate the next model,",
      "offset": 2335.92,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "etc., etc. Once you have a very very",
      "offset": 2337.359,
      "duration": 4.961
    },
    {
      "lang": "en",
      "text": "good AI researcher, then the further",
      "offset": 2340.24,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "claim is that this can be used to train",
      "offset": 2342.32,
      "duration": 2.88
    },
    {
      "lang": "en",
      "text": "an AI that is good at things that are",
      "offset": 2343.76,
      "duration": 3.359
    },
    {
      "lang": "en",
      "text": "not just done at AI companies. And this",
      "offset": 2345.2,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "would be doing law, doing medicine,",
      "offset": 2347.119,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "doing accounting, maybe even designing",
      "offset": 2348.8,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "robots to build your house for you, like",
      "offset": 2350.72,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "in your example of maybe the last form",
      "offset": 2352.24,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "of human labor. So that's basically a",
      "offset": 2354,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "story for which this could happen. It",
      "offset": 2356.72,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "requires three pretty strong assumptions",
      "offset": 2358.24,
      "duration": 3.359
    },
    {
      "lang": "en",
      "text": "that have to happen in sequence. So even",
      "offset": 2359.92,
      "duration": 3.679
    },
    {
      "lang": "en",
      "text": "if this story does unfold, you know, our",
      "offset": 2361.599,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "forecast in AI 2027 is that this even if",
      "offset": 2363.599,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "this happens would be something that",
      "offset": 2366.079,
      "duration": 2.881
    },
    {
      "lang": "en",
      "text": "would be at the earliest in mid the mid",
      "offset": 2367.2,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "2030s. Uh we were kind of the dissenting",
      "offset": 2368.96,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "view in AI 2027 which lays out the case",
      "offset": 2371.2,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "that in fact this could happen all at",
      "offset": 2373.359,
      "duration": 3.281
    },
    {
      "lang": "en",
      "text": "once. that first step of automating",
      "offset": 2374.8,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "software and then automating AI research",
      "offset": 2376.64,
      "duration": 2.959
    },
    {
      "lang": "en",
      "text": "and then automating everything else",
      "offset": 2378.32,
      "duration": 3.759
    },
    {
      "lang": "en",
      "text": "could happen in as short as a few years.",
      "offset": 2379.599,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "As forecasters, we couldn't rule out",
      "offset": 2382.079,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "rule that out like it might have a",
      "offset": 2383.52,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "realistic chance maybe a two or 5%",
      "offset": 2385.359,
      "duration": 3.521
    },
    {
      "lang": "en",
      "text": "chance of happening that",
      "offset": 2387.28,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "our median scenarios that it take takes",
      "offset": 2388.88,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "much longer. But if you agree with that",
      "offset": 2390.72,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "model in that premise, you can actually",
      "offset": 2392.16,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "see a path towards that very, you know,",
      "offset": 2394,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "grandiloquent future. Yeah. Again,",
      "offset": 2396.48,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "Robert, I think I mostly agree with you.",
      "offset": 2398.48,
      "duration": 3.359
    },
    {
      "lang": "en",
      "text": "I don't see that coming anytime soon.",
      "offset": 2400,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "Um, but it's not impossible and I",
      "offset": 2401.839,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "wouldn't reject it out of hand. Right.",
      "offset": 2403.44,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "So there uh I guess what I'm missing, my",
      "offset": 2405.52,
      "duration": 6.64
    },
    {
      "lang": "en",
      "text": "blind spot there is uh that notion of um",
      "offset": 2407.68,
      "duration": 7.28
    },
    {
      "lang": "en",
      "text": "the AI",
      "offset": 2412.16,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "increasing in its ability to produce",
      "offset": 2414.96,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "better AI, right? So the ability for it",
      "offset": 2416.96,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "to engineer a better version of itself.",
      "offset": 2419.04,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "I'm well familiar with the idea that um",
      "offset": 2421.119,
      "duration": 3.441
    },
    {
      "lang": "en",
      "text": "artificial intelligence is writing",
      "offset": 2423.119,
      "duration": 3.281
    },
    {
      "lang": "en",
      "text": "software. That's well understood right",
      "offset": 2424.56,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "now. But that second implication then",
      "offset": 2426.4,
      "duration": 3.439
    },
    {
      "lang": "en",
      "text": "that if it can write better software",
      "offset": 2428.56,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "then it can and can conduct better AI",
      "offset": 2429.839,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "research then it's going to start to",
      "offset": 2431.76,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "improve itself and it is true these",
      "offset": 2433.52,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "systems operate at very high speed and",
      "offset": 2435.68,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "so that result could happen uh much",
      "offset": 2438,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "quicker than someone like me a skeptic",
      "offset": 2440.72,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "like me might might predict or expect.",
      "offset": 2442.96,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "Uh if you don't mind I want to circle",
      "offset": 2446.48,
      "duration": 2.96
    },
    {
      "lang": "en",
      "text": "back to a thing we talked about a moment",
      "offset": 2447.92,
      "duration": 3.439
    },
    {
      "lang": "en",
      "text": "ago because uh it occurred to me when",
      "offset": 2449.44,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "you're speaking it but I didn't want to",
      "offset": 2451.359,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "interrupt you. Um I I live in Los",
      "offset": 2452.64,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "Angeles. I deal with a lot of people in",
      "offset": 2455.04,
      "duration": 2.799
    },
    {
      "lang": "en",
      "text": "the motion picture industry and the",
      "offset": 2456.24,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "media industry in general and of course",
      "offset": 2457.839,
      "duration": 3.121
    },
    {
      "lang": "en",
      "text": "as you know there's a lot of resistance",
      "offset": 2459.76,
      "duration": 2.96
    },
    {
      "lang": "en",
      "text": "there to AI for a whole bunch of",
      "offset": 2460.96,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "reasons. There's a kind of moral outrage",
      "offset": 2462.72,
      "duration": 4.639
    },
    {
      "lang": "en",
      "text": "right now that AIs have been trained on",
      "offset": 2464.56,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "the work of human beings really the you",
      "offset": 2467.359,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "know the literary and artistic output of",
      "offset": 2469.28,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "of of hundreds of people millions of",
      "offset": 2471.119,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "people uh has been uh has been used",
      "offset": 2473.44,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "without permission to train artificial",
      "offset": 2475.44,
      "duration": 3.679
    },
    {
      "lang": "en",
      "text": "intelligence. I'm going to leave that",
      "offset": 2477.76,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "issue aside right now um because what I",
      "offset": 2479.119,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "want to do is is make an observation",
      "offset": 2482.24,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "about it.",
      "offset": 2484.079,
      "duration": 3.201
    },
    {
      "lang": "en",
      "text": "The artists that I work with, uh, the",
      "offset": 2485.76,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "people in the entertainment industry who",
      "offset": 2487.28,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "embrace artificial intelligence, they",
      "offset": 2489.04,
      "duration": 2.96
    },
    {
      "lang": "en",
      "text": "have a slightly different perspective on",
      "offset": 2490.72,
      "duration": 2.399
    },
    {
      "lang": "en",
      "text": "that. I think is a meaningful",
      "offset": 2492,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "distinction here to to emphasize. And",
      "offset": 2493.119,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "that is when you work with artificial",
      "offset": 2495.04,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "intelligence, you are engaging with the",
      "offset": 2497.839,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "collective intelligence of humanity. In",
      "offset": 2499.52,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "other words, it it's not a replacement",
      "offset": 2502.079,
      "duration": 4.561
    },
    {
      "lang": "en",
      "text": "for humanity. It's a quick access to all",
      "offset": 2504.24,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "the knowledge and wisdom and insight",
      "offset": 2506.64,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "that humans have gathered over",
      "offset": 2508.4,
      "duration": 3.439
    },
    {
      "lang": "en",
      "text": "centuries. It's all there. You know,",
      "offset": 2510.24,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "it's been trained on everything. And um",
      "offset": 2511.839,
      "duration": 4.801
    },
    {
      "lang": "en",
      "text": "and as a result when you're working with",
      "offset": 2514.56,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "AI, you're kind of communing with the",
      "offset": 2516.64,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "general intelligence of humanity or the",
      "offset": 2518.88,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "let's say uh the wisdom of the elders is",
      "offset": 2521.2,
      "duration": 3.119
    },
    {
      "lang": "en",
      "text": "the way one of my friends put it. And I",
      "offset": 2522.96,
      "duration": 2.48
    },
    {
      "lang": "en",
      "text": "thought that was a nice way to think of",
      "offset": 2524.319,
      "duration": 2.641
    },
    {
      "lang": "en",
      "text": "it. Certainly that's a more artistic",
      "offset": 2525.44,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "interpretation. When I say that, what do",
      "offset": 2526.96,
      "duration": 2.96
    },
    {
      "lang": "en",
      "text": "you think about that? Is that true? Is",
      "offset": 2528.48,
      "duration": 3.119
    },
    {
      "lang": "en",
      "text": "this like basically just the next",
      "offset": 2529.92,
      "duration": 3.199
    },
    {
      "lang": "en",
      "text": "iteration of collective human",
      "offset": 2531.599,
      "duration": 2.72
    },
    {
      "lang": "en",
      "text": "intelligence?",
      "offset": 2533.119,
      "duration": 2.641
    },
    {
      "lang": "en",
      "text": "I absolutely agree with that. I think",
      "offset": 2534.319,
      "duration": 3.441
    },
    {
      "lang": "en",
      "text": "that's a a poignant insight and and",
      "offset": 2535.76,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "again I think it's really at the heart",
      "offset": 2537.76,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "of forecasting. Forecasting requires an",
      "offset": 2538.88,
      "duration": 5.439
    },
    {
      "lang": "en",
      "text": "incredible depth of knowledge. Um, and",
      "offset": 2541.92,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "that depth often comes through breadth.",
      "offset": 2544.319,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "You just have to read everything. You",
      "offset": 2546.56,
      "duration": 2.559
    },
    {
      "lang": "en",
      "text": "know, in forecasting tournaments, there",
      "offset": 2547.839,
      "duration": 2.321
    },
    {
      "lang": "en",
      "text": "would be some question about, you know,",
      "offset": 2549.119,
      "duration": 2.881
    },
    {
      "lang": "en",
      "text": "Russia, Ukraine or the Red Sea or Israel",
      "offset": 2550.16,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "or something. And the forecasters would",
      "offset": 2552,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "just go to the library and get a book on",
      "offset": 2553.68,
      "duration": 3.439
    },
    {
      "lang": "en",
      "text": "the history of the Israel Palestine",
      "offset": 2555.44,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "conflict and sit and read it for a",
      "offset": 2557.119,
      "duration": 2.561
    },
    {
      "lang": "en",
      "text": "couple of days and then they would come",
      "offset": 2558.64,
      "duration": 2.479
    },
    {
      "lang": "en",
      "text": "back and say, \"Okay, here's my take on",
      "offset": 2559.68,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "this.\" We don't need to do that anymore",
      "offset": 2561.119,
      "duration": 3.761
    },
    {
      "lang": "en",
      "text": "because all of that knowledge is in the",
      "offset": 2562.96,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "model. If you wanted to talk to",
      "offset": 2564.88,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "collective humanity, the wisdom of our",
      "offset": 2566.72,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "elders, it's right there on chat GPT",
      "offset": 2568.56,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "Gemini claude available for free 24",
      "offset": 2570.64,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "hours a day, it is a true forecasting",
      "offset": 2572.96,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "superpower. And that's why for me when",
      "offset": 2575.52,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "this AI revolution started, I looked to",
      "offset": 2577.119,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "my domain and said this is going to",
      "offset": 2579.599,
      "duration": 3.441
    },
    {
      "lang": "en",
      "text": "change. You know, if you're working on",
      "offset": 2581.2,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "say medicine and maybe it's a very open",
      "offset": 2583.04,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "question or or the music industry or",
      "offset": 2584.8,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "entertainment like to what role will AI",
      "offset": 2586.88,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "be making movies for us or recording",
      "offset": 2588.64,
      "duration": 3.679
    },
    {
      "lang": "en",
      "text": "music? I have no idea. like you could",
      "offset": 2590.56,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "have different takes on that or whether",
      "offset": 2592.319,
      "duration": 3.201
    },
    {
      "lang": "en",
      "text": "it's even ethical to do so like you said",
      "offset": 2593.92,
      "duration": 3.679
    },
    {
      "lang": "en",
      "text": "using all that copyrighted material. Um",
      "offset": 2595.52,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "in medicine it's far from clear how",
      "offset": 2597.599,
      "duration": 3.361
    },
    {
      "lang": "en",
      "text": "useful AI is going to be in diagnostics",
      "offset": 2599.28,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "or therapeutics but in forecasting this",
      "offset": 2600.96,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "ability to talk to collective humanity",
      "offset": 2603.68,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "and synthesize all basically compress",
      "offset": 2605.52,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "everything that humanity knows about say",
      "offset": 2607.92,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "China into something where you can just",
      "offset": 2609.68,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "get all of the information at your",
      "offset": 2611.44,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "fingertips that's clearly a superpower",
      "offset": 2612.72,
      "duration": 3.359
    },
    {
      "lang": "en",
      "text": "and so that meant that my field of",
      "offset": 2614.8,
      "duration": 2.72
    },
    {
      "lang": "en",
      "text": "forecasting was going to get disrupted",
      "offset": 2616.079,
      "duration": 2.801
    },
    {
      "lang": "en",
      "text": "and that meant it was time to go do it",
      "offset": 2617.52,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "with AI as a startup. So again, I can't",
      "offset": 2618.88,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "generalize necessarily to other domains,",
      "offset": 2621.28,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "but I think that's a very deep insight",
      "offset": 2623.2,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "and something that even now a couple",
      "offset": 2624.8,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "years into the chat GPT era, people are",
      "offset": 2626.72,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "still learning. Just about every",
      "offset": 2628.88,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "industry, certainly the media industries",
      "offset": 2631.04,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "I know so well are governed by this what",
      "offset": 2632.56,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "we call the iron triangle, which is um",
      "offset": 2634.72,
      "duration": 4.639
    },
    {
      "lang": "en",
      "text": "you know, your budget or money, time,",
      "offset": 2636.72,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "and quality. And within those three",
      "offset": 2639.359,
      "duration": 2.801
    },
    {
      "lang": "en",
      "text": "domains, you're going to try to",
      "offset": 2641.2,
      "duration": 2.96
    },
    {
      "lang": "en",
      "text": "optimize. And very often what happens is",
      "offset": 2642.16,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "you're on a timeline. So the budget the",
      "offset": 2644.16,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "timeline is set, the data is set. So",
      "offset": 2646.16,
      "duration": 3.439
    },
    {
      "lang": "en",
      "text": "you're kind of working against the",
      "offset": 2648.64,
      "duration": 2.56
    },
    {
      "lang": "en",
      "text": "clock. you don't have much flexibility",
      "offset": 2649.599,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "on timeline. Um, and budgets are usually",
      "offset": 2651.2,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "set. So, within the constraints of",
      "offset": 2654.079,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "budget and time, you opt for the best",
      "offset": 2656,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "quality you can achieve. And certainly",
      "offset": 2658.319,
      "duration": 3.441
    },
    {
      "lang": "en",
      "text": "that that would be a fair summary of",
      "offset": 2660.319,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "almost every media product that's out",
      "offset": 2661.76,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "there. Now, what we're observing when we",
      "offset": 2663.359,
      "duration": 5.281
    },
    {
      "lang": "en",
      "text": "work with AI uh, in the media business,",
      "offset": 2665.68,
      "duration": 4.639
    },
    {
      "lang": "en",
      "text": "what we're able to do is get results",
      "offset": 2668.64,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "much much faster. So, if we want a lot",
      "offset": 2670.319,
      "duration": 4.961
    },
    {
      "lang": "en",
      "text": "of ideas, we can generate thousands more",
      "offset": 2672.8,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "ideas much faster. So, what's happening",
      "offset": 2675.28,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "is we're able to extend time. you get",
      "offset": 2677.119,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "more time essentially or you get results",
      "offset": 2679.68,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "faster and you can take that gain in",
      "offset": 2681.599,
      "duration": 5.201
    },
    {
      "lang": "en",
      "text": "time and invest it in better quality.",
      "offset": 2684.24,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "And I think this is this observation is",
      "offset": 2686.8,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "a lot of people in Los Angeles are",
      "offset": 2689.76,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "missing this right now like that that is",
      "offset": 2691.2,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "a gigantic unlock for the creative",
      "offset": 2692.8,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "process. They tend to view AI as a",
      "offset": 2694.48,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "threat that's going to replace human",
      "offset": 2696.64,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "workers in the in the motion picture",
      "offset": 2698.24,
      "duration": 3.119
    },
    {
      "lang": "en",
      "text": "business. There's no doubt there will be",
      "offset": 2699.76,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "job loss because you'll be able to do",
      "offset": 2701.359,
      "duration": 3.281
    },
    {
      "lang": "en",
      "text": "more with fewer people. That's that's a",
      "offset": 2702.88,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "certainty like that will be one of the",
      "offset": 2704.64,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "promises of AI. Um but in a way that",
      "offset": 2706,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "helps you extend that other criteria or",
      "offset": 2708.8,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "that other constraint which is budget,",
      "offset": 2710.88,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "right? So fewer people means you can do",
      "offset": 2712.56,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "more with less money. Um those two",
      "offset": 2714.24,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "things can be reinvested in quality. And",
      "offset": 2716.96,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "so what I'm starting to see in in the",
      "offset": 2718.64,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "entertainment business, quality is going",
      "offset": 2720.48,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "to be more optionality and more uh more",
      "offset": 2721.76,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "aesthetic choices that the director or",
      "offset": 2724.16,
      "duration": 3.679
    },
    {
      "lang": "en",
      "text": "the creative person can make a decision",
      "offset": 2726.16,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "about. Um do you see that broadly? I",
      "offset": 2727.839,
      "duration": 4.721
    },
    {
      "lang": "en",
      "text": "mean I'm I'm thinking that in your line",
      "offset": 2730.96,
      "duration": 3.119
    },
    {
      "lang": "en",
      "text": "of work you're doing you're dealing with",
      "offset": 2732.56,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "something similar, right? So anytime a a",
      "offset": 2734.079,
      "duration": 3.441
    },
    {
      "lang": "en",
      "text": "an organization is asked to make a",
      "offset": 2736.24,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "forecast or a prediction, you do run",
      "offset": 2737.52,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "into the constraints of what you know",
      "offset": 2739.52,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "how much data is available, how many",
      "offset": 2740.96,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "research reports can we digest in a",
      "offset": 2742.64,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "short in a certain period of time. We",
      "offset": 2744.8,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "have to deliver the report in a timely",
      "offset": 2746.72,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "way because that has there's there's",
      "offset": 2748.72,
      "duration": 3.599
    },
    {
      "lang": "en",
      "text": "time value to the information we're",
      "offset": 2750.64,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "going to provide. Um and so those become",
      "offset": 2752.319,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "constraints that are going to dictate",
      "offset": 2755.04,
      "duration": 2.64
    },
    {
      "lang": "en",
      "text": "the quality that you can achieve within",
      "offset": 2756.24,
      "duration": 3.599
    },
    {
      "lang": "en",
      "text": "those two variables. Tell me a little",
      "offset": 2757.68,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "bit about how AI changes that that for",
      "offset": 2759.839,
      "duration": 4.641
    },
    {
      "lang": "en",
      "text": "you. Quality versus the quality of the",
      "offset": 2762.16,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "output versus time and budget.",
      "offset": 2764.48,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "Yeah, I mean I'll give you a specific",
      "offset": 2766.48,
      "duration": 3.359
    },
    {
      "lang": "en",
      "text": "example that might illuminate this. So,",
      "offset": 2768,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "one of the tasks that we have in deep",
      "offset": 2769.839,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "research bench is called find original",
      "offset": 2771.839,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "source. And what it does is it takes a",
      "offset": 2773.359,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "claim on the web and tries to track it",
      "offset": 2775.599,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "down to its original source. Now,",
      "offset": 2777.599,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "sometimes this is easy because if you're",
      "offset": 2779.44,
      "duration": 2.72
    },
    {
      "lang": "en",
      "text": "looking at, you know, mainstream",
      "offset": 2781.119,
      "duration": 2.561
    },
    {
      "lang": "en",
      "text": "high-quality reporting, when there's a",
      "offset": 2782.16,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "claim made, there's generally a link and",
      "offset": 2783.68,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "you follow the link and that will",
      "offset": 2785.52,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "generally be the primary source, but the",
      "offset": 2787.2,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "vast majority of the web is not the",
      "offset": 2789.44,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "reporting quality of the New York Times.",
      "offset": 2790.96,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "And so, people make claims all the time",
      "offset": 2792.72,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "that either don't have that link or link",
      "offset": 2794.16,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "to something that is itself a secondary",
      "offset": 2796,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "source or have the link but misstate the",
      "offset": 2797.68,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "claim that it was in that link. One",
      "offset": 2799.68,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "thing you can do with AI to kind of mess",
      "offset": 2802,
      "duration": 3.119
    },
    {
      "lang": "en",
      "text": "with this time constraints or the amount",
      "offset": 2803.599,
      "duration": 3.281
    },
    {
      "lang": "en",
      "text": "of money you put in. Imagine you take",
      "offset": 2805.119,
      "duration": 3.361
    },
    {
      "lang": "en",
      "text": "you've got three paragraphs of text that",
      "offset": 2806.88,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "are explaining a decision or a forecast,",
      "offset": 2808.48,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "go to every sentence and say what",
      "offset": 2810.88,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "assumptions or claims are implied in the",
      "offset": 2812.72,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "sentence. For every one of those, track",
      "offset": 2814.88,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "down the original source of that claim",
      "offset": 2816.8,
      "duration": 2.799
    },
    {
      "lang": "en",
      "text": "or assumption and then do this",
      "offset": 2818.24,
      "duration": 2.72
    },
    {
      "lang": "en",
      "text": "recursively. You know, if you find",
      "offset": 2819.599,
      "duration": 2.641
    },
    {
      "lang": "en",
      "text": "something somewhere on the web, where",
      "offset": 2820.96,
      "duration": 2.96
    },
    {
      "lang": "en",
      "text": "did that come from? Keep chasing it",
      "offset": 2822.24,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "down. You can spawn a very large number",
      "offset": 2823.92,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "of web research agents to go trace down",
      "offset": 2826.64,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "the original source and verify basically",
      "offset": 2828.64,
      "duration": 4.479
    },
    {
      "lang": "en",
      "text": "every single fact in a piece of writing",
      "offset": 2830.64,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "and you can do that for pennies on the",
      "offset": 2833.119,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "dollar. Now it might cost the AI system",
      "offset": 2834.96,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "many dollars or tens of dollars to do",
      "offset": 2836.8,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "this but humans would cost thousands or",
      "offset": 2838.56,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "tens of thousands of dollars to do this",
      "offset": 2841.44,
      "duration": 2.48
    },
    {
      "lang": "en",
      "text": "amount of work.",
      "offset": 2843.04,
      "duration": 2.48
    },
    {
      "lang": "en",
      "text": "Plus that cost is coming down as the",
      "offset": 2843.92,
      "duration": 3.439
    },
    {
      "lang": "en",
      "text": "cost of compute goes down. So in two",
      "offset": 2845.52,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "years it'll be a lot cheaper.",
      "offset": 2847.359,
      "duration": 3.521
    },
    {
      "lang": "en",
      "text": "Costa is coming down. uh but the quality",
      "offset": 2848.64,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "is going up and the quality matters and",
      "offset": 2850.88,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "so it can still I don't know we have",
      "offset": 2852.56,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "runs of future search that cost many",
      "offset": 2854,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "tens of dollars you know sometimes for",
      "offset": 2856,
      "duration": 2.8
    },
    {
      "lang": "en",
      "text": "example we will do something that",
      "offset": 2857.52,
      "duration": 2.64
    },
    {
      "lang": "en",
      "text": "requires looking at every single company",
      "offset": 2858.8,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "in the S&P 500 so we will have research",
      "offset": 2860.16,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "agents several of them for each company",
      "offset": 2862.96,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "in the S&P 500 that are all researching",
      "offset": 2864.8,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "something those costs can be measured in",
      "offset": 2867.04,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "hundreds or thousands of dollars again",
      "offset": 2869.76,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "still orders of magnitude cheaper than",
      "offset": 2871.92,
      "duration": 3.679
    },
    {
      "lang": "en",
      "text": "if humans were doing it but the main",
      "offset": 2873.68,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "thing is how do you productively use",
      "offset": 2875.599,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "that intelligence and the AI and its",
      "offset": 2877.599,
      "duration": 2.961
    },
    {
      "lang": "en",
      "text": "research capab capabilities to answer a",
      "offset": 2879.2,
      "duration": 3.119
    },
    {
      "lang": "en",
      "text": "question that you care about as a human.",
      "offset": 2880.56,
      "duration": 3.279
    },
    {
      "lang": "en",
      "text": "You would never say, \"Well, I'll go look",
      "offset": 2882.319,
      "duration": 3.121
    },
    {
      "lang": "en",
      "text": "and to see what the impact of tariffs is",
      "offset": 2883.839,
      "duration": 5.361
    },
    {
      "lang": "en",
      "text": "on every single company in the S&P 500",
      "offset": 2885.44,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "system.\" That's a great question to ask.",
      "offset": 2889.2,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "You can actually do that if you have the",
      "offset": 2891.2,
      "duration": 2.879
    },
    {
      "lang": "en",
      "text": "right infrastructure and the scale that",
      "offset": 2892.72,
      "duration": 2.72
    },
    {
      "lang": "en",
      "text": "future search has.",
      "offset": 2894.079,
      "duration": 3.201
    },
    {
      "lang": "en",
      "text": "So, I don't think I have a great answer",
      "offset": 2895.44,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "to the resolution of the iron triangle",
      "offset": 2897.28,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "other than to say it requires",
      "offset": 2899.839,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "creativity. Like AI, it is the",
      "offset": 2901.119,
      "duration": 4.561
    },
    {
      "lang": "en",
      "text": "collective wisdom of humans, but it is",
      "offset": 2903.44,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "its own different beast. It is kind of",
      "offset": 2905.68,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "an alien that that operates in different",
      "offset": 2907.28,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "ways and surprising ways and has",
      "offset": 2909.44,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "different trade-offs of quality and time",
      "offset": 2910.88,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "and money than humans. But if you're",
      "offset": 2912.72,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "smart about the way to kind of break",
      "offset": 2914.8,
      "duration": 3.519
    },
    {
      "lang": "en",
      "text": "down your problem, then you can deploy",
      "offset": 2916.24,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "these things at scale to do things that",
      "offset": 2918.319,
      "duration": 3.441
    },
    {
      "lang": "en",
      "text": "a human would never be able to do while",
      "offset": 2920.16,
      "duration": 3.199
    },
    {
      "lang": "en",
      "text": "still kind of leaving the core of it to",
      "offset": 2921.76,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "the human and get a massive quality",
      "offset": 2923.359,
      "duration": 3.281
    },
    {
      "lang": "en",
      "text": "improvement pretty cheaply.",
      "offset": 2925.2,
      "duration": 2.96
    },
    {
      "lang": "en",
      "text": "So you're you're what what I'm hearing",
      "offset": 2926.64,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "you describe is there's still a role for",
      "offset": 2928.16,
      "duration": 2.959
    },
    {
      "lang": "en",
      "text": "a human being there in terms of",
      "offset": 2929.76,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "directing the AI uh to do the useful",
      "offset": 2931.119,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "research. the the grunt work, the",
      "offset": 2933.44,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "research could certainly be done by the",
      "offset": 2935.2,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "machine. Um Dan, let me ask you a",
      "offset": 2936.48,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "related question because this is one of",
      "offset": 2939.44,
      "duration": 5.679
    },
    {
      "lang": "en",
      "text": "the areas where um human forecasting",
      "offset": 2941.2,
      "duration": 7.68
    },
    {
      "lang": "en",
      "text": "has failed uh kind of uh notoriously. Uh",
      "offset": 2945.119,
      "duration": 6.801
    },
    {
      "lang": "en",
      "text": "humans like to most humans like to think",
      "offset": 2948.88,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "that they can extrapolate from any",
      "offset": 2951.92,
      "duration": 2.8
    },
    {
      "lang": "en",
      "text": "trend. Now, we're not we're not always",
      "offset": 2953.52,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "as good as we think and also that's a",
      "offset": 2954.72,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "very dangerous thing to do because",
      "offset": 2956.96,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "trends never unfold in a in a linear",
      "offset": 2958.4,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "path uh the way we tend to assume. But",
      "offset": 2960.72,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "we like to think that we can say, okay,",
      "offset": 2962.96,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "you know, if if all else holds true, uh",
      "offset": 2964.4,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "this particular trend, I can kind of",
      "offset": 2966.96,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "predict the the trajectory of that",
      "offset": 2968.48,
      "duration": 3.359
    },
    {
      "lang": "en",
      "text": "trend.",
      "offset": 2970.24,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "Um but what we're notoriously bad at",
      "offset": 2971.839,
      "duration": 5.361
    },
    {
      "lang": "en",
      "text": "is answering the question, then what",
      "offset": 2975.44,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "happens? In other words, what are the",
      "offset": 2977.2,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "second and third order consequences of",
      "offset": 2978.88,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "of a very obvious trend that we all",
      "offset": 2981.44,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "think we can predict the future of? And",
      "offset": 2983.04,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "humans are terrible at this. I mean, we",
      "offset": 2985.359,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "see this in politics constantly. We see",
      "offset": 2986.64,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "this in geopolitics constantly uh where",
      "offset": 2988.559,
      "duration": 4.721
    },
    {
      "lang": "en",
      "text": "you know one nation or another makes a",
      "offset": 2991.2,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "move on the global chessboard and then",
      "offset": 2993.28,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "there's a series kind of cascade of",
      "offset": 2995.04,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "consequences that occur and you think to",
      "offset": 2997.359,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "yourself didn't they think about that",
      "offset": 2999.52,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "before they started bombing or before",
      "offset": 3001.04,
      "duration": 3.279
    },
    {
      "lang": "en",
      "text": "they did the invasion or whatever you",
      "offset": 3002.64,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "know egregious blunder was made. Um in",
      "offset": 3004.319,
      "duration": 5.841
    },
    {
      "lang": "en",
      "text": "some cases they don't care you know the",
      "offset": 3008,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "leaders of the country do not care",
      "offset": 3010.16,
      "duration": 2.159
    },
    {
      "lang": "en",
      "text": "because they just want to deal with this",
      "offset": 3011.28,
      "duration": 2.16
    },
    {
      "lang": "en",
      "text": "thing at hand and they're not worried",
      "offset": 3012.319,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "about the future consequences or they'll",
      "offset": 3013.44,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "figure they'll deal with them later. Um,",
      "offset": 3015.359,
      "duration": 5.121
    },
    {
      "lang": "en",
      "text": "but in some ways this creates so much",
      "offset": 3017.599,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "collateral damage, so much economic",
      "offset": 3020.48,
      "duration": 4.879
    },
    {
      "lang": "en",
      "text": "hardship that I often pine for that and",
      "offset": 3023.119,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "I think, gee, I wish that humans were",
      "offset": 3025.359,
      "duration": 2.881
    },
    {
      "lang": "en",
      "text": "better at thinking about long-term",
      "offset": 3026.8,
      "duration": 2.88
    },
    {
      "lang": "en",
      "text": "consequences because that would probably",
      "offset": 3028.24,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "cause us to think twice about making the",
      "offset": 3029.68,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "drastic move that we're tempted to make.",
      "offset": 3031.68,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "Do you think machine intelligence is",
      "offset": 3034.8,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "better at forecasting and anticipating",
      "offset": 3036.96,
      "duration": 5.119
    },
    {
      "lang": "en",
      "text": "second and third order consequences?",
      "offset": 3039.76,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "Uh, certainly not today. U, but of",
      "offset": 3042.079,
      "duration": 3.441
    },
    {
      "lang": "en",
      "text": "course that's the direction that we hope",
      "offset": 3044.24,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "it will go. Yeah, I think that that is",
      "offset": 3045.52,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "that is a great point and it's actually",
      "offset": 3047.28,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "one of the risks of AI is whenever",
      "offset": 3049.04,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "something looks like a time series",
      "offset": 3051.599,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "forecast. That stuff even before",
      "offset": 3053.2,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "language models was firmly in the",
      "offset": 3055.359,
      "duration": 3.361
    },
    {
      "lang": "en",
      "text": "territory of machine learning. There's",
      "offset": 3057.359,
      "duration": 2.96
    },
    {
      "lang": "en",
      "text": "all sorts of time series algorithms and",
      "offset": 3058.72,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "they're used a million times a day in",
      "offset": 3060.319,
      "duration": 3.201
    },
    {
      "lang": "en",
      "text": "many businesses generally for things",
      "offset": 3062.24,
      "duration": 2.96
    },
    {
      "lang": "en",
      "text": "like supply chain forecasting. Like I",
      "offset": 3063.52,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "need to know how many parts I'm going to",
      "offset": 3065.2,
      "duration": 2.96
    },
    {
      "lang": "en",
      "text": "have. I need to know how long they're",
      "offset": 3067.04,
      "duration": 2.319
    },
    {
      "lang": "en",
      "text": "going to be on the shelves. I need I",
      "offset": 3068.16,
      "duration": 2.24
    },
    {
      "lang": "en",
      "text": "need to know when they're going to go",
      "offset": 3069.359,
      "duration": 2.881
    },
    {
      "lang": "en",
      "text": "out the door. I need to plan for say",
      "offset": 3070.4,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "Christmas holiday shopping um and the",
      "offset": 3072.24,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "surge in demand there and make sure I've",
      "offset": 3074.48,
      "duration": 3.119
    },
    {
      "lang": "en",
      "text": "got enough inventory and you know enough",
      "offset": 3075.76,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "distribution. All of that stuff just",
      "offset": 3077.599,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "looks like taking a very dense set of",
      "offset": 3079.76,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "data that has a trend line and then",
      "offset": 3081.28,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "extrapolating it. And you say well the",
      "offset": 3082.96,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "last three Christmases we had a 40%",
      "offset": 3085.52,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "bump. So I predicted this Christmas will",
      "offset": 3087.44,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "have a 40% bump and that can be a very",
      "offset": 3089.28,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "good forecast. And you look at that",
      "offset": 3090.96,
      "duration": 3.359
    },
    {
      "lang": "en",
      "text": "methodology and it kind of gives you",
      "offset": 3093.04,
      "duration": 2.799
    },
    {
      "lang": "en",
      "text": "this false confidence that you can use",
      "offset": 3094.319,
      "duration": 2.8
    },
    {
      "lang": "en",
      "text": "that to figure out things that have",
      "offset": 3095.839,
      "duration": 3.121
    },
    {
      "lang": "en",
      "text": "these second or third order consequences",
      "offset": 3097.119,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "exactly as you're describing, Robert.",
      "offset": 3098.96,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "Um, one of the things I was interested",
      "offset": 3100.96,
      "duration": 2.879
    },
    {
      "lang": "en",
      "text": "in at Google with the prediction market",
      "offset": 3102.4,
      "duration": 2.719
    },
    {
      "lang": "en",
      "text": "I had was trying to see if we could",
      "offset": 3103.839,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "forecast basically the chip uh economy",
      "offset": 3105.119,
      "duration": 5.041
    },
    {
      "lang": "en",
      "text": "better. And this one was very much was",
      "offset": 3107.599,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "time series kind of supply chain",
      "offset": 3110.16,
      "duration": 3.199
    },
    {
      "lang": "en",
      "text": "forecasting. They did it the same way",
      "offset": 3111.68,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "that most other large companies do. And",
      "offset": 3113.359,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "they broke it into two different",
      "offset": 3115.92,
      "duration": 2.639
    },
    {
      "lang": "en",
      "text": "categories. They called it inorganic and",
      "offset": 3117.04,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "organic forecasting. The thing called",
      "offset": 3118.559,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "organic forecasting they said was time",
      "offset": 3120.48,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "series just like well what happened last",
      "offset": 3122.16,
      "duration": 3.679
    },
    {
      "lang": "en",
      "text": "year predict that will happen this year",
      "offset": 3123.68,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "add 20% because it's growing it's",
      "offset": 3125.839,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "probably right and then the thing called",
      "offset": 3127.76,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "inorganic forecasting was everything",
      "offset": 3129.599,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "else while I was there the big thing",
      "offset": 3131.839,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "that was in the inorganic forecasting",
      "offset": 3134,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "was co 19 there was a global pandemic",
      "offset": 3135.599,
      "duration": 5.041
    },
    {
      "lang": "en",
      "text": "that destroyed all the supply chains and",
      "offset": 3138.88,
      "duration": 3.199
    },
    {
      "lang": "en",
      "text": "nobody's chips were going into their",
      "offset": 3140.64,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "servers into their data centers on time",
      "offset": 3142.079,
      "duration": 4.641
    },
    {
      "lang": "en",
      "text": "every single model fell on its head and",
      "offset": 3144.48,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "died and became useless when that",
      "offset": 3146.72,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "happened and so they had pull in all the",
      "offset": 3148.4,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "humans and say, \"Well, okay, every model",
      "offset": 3150.16,
      "duration": 3.679
    },
    {
      "lang": "en",
      "text": "we have of our chip supply chain is",
      "offset": 3152.16,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "wrong. So, what should we actually do?\"",
      "offset": 3153.839,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "And the the ML basically got thrown out",
      "offset": 3155.68,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "and it was only up to the humans to kind",
      "offset": 3157.52,
      "duration": 3.599
    },
    {
      "lang": "en",
      "text": "of make those adjustments. I think one",
      "offset": 3159.2,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "of the big challenges is that synthesis",
      "offset": 3161.119,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "like the ML was useful in some ways. If",
      "offset": 3162.88,
      "duration": 4.479
    },
    {
      "lang": "en",
      "text": "you trust it too much when CO happens,",
      "offset": 3165.599,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "you you're completely out of luck, but",
      "offset": 3167.359,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "you can't just replace with an army of",
      "offset": 3169.119,
      "duration": 2.96
    },
    {
      "lang": "en",
      "text": "humans because most of the time it's not",
      "offset": 3170.559,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "CO. And so, these kind of, you know, as",
      "offset": 3172.079,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "Talib would say, the black swans or as",
      "offset": 3174.079,
      "duration": 2.801
    },
    {
      "lang": "en",
      "text": "you said, kind of the second order",
      "offset": 3175.76,
      "duration": 2.4
    },
    {
      "lang": "en",
      "text": "consequences. Yeah. I don't think",
      "offset": 3176.88,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "anybody has a good practice of adopting",
      "offset": 3178.16,
      "duration": 3.439
    },
    {
      "lang": "en",
      "text": "those into like a standardized",
      "offset": 3180.16,
      "duration": 2.959
    },
    {
      "lang": "en",
      "text": "forecasting process yet. I think that's",
      "offset": 3181.599,
      "duration": 3.361
    },
    {
      "lang": "en",
      "text": "still an uncert",
      "offset": 3183.119,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "we haven't maybe we haven't quite gotten",
      "offset": 3184.96,
      "duration": 3.359
    },
    {
      "lang": "en",
      "text": "there yet, but how would you approach",
      "offset": 3186.8,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "that? I mean, how would would you have",
      "offset": 3188.319,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "um would you do like a second run of",
      "offset": 3190.16,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "your forecast once you once you've got a",
      "offset": 3192.559,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "scenario or a range of scenarios",
      "offset": 3194.559,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "posited? Could you then apply like a",
      "offset": 3196.48,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "black a black swan filter to it and say,",
      "offset": 3198.96,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "\"Okay, now give me the now now",
      "offset": 3200.96,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "re-evaluate those outcomes and show me",
      "offset": 3203.119,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "some of the possible consequences.\"",
      "offset": 3205.359,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "Um do do you think that that's going to",
      "offset": 3207.599,
      "duration": 3.281
    },
    {
      "lang": "en",
      "text": "be something that we can possibly do?",
      "offset": 3209.599,
      "duration": 2.48
    },
    {
      "lang": "en",
      "text": "Because I mean honestly that would be an",
      "offset": 3210.88,
      "duration": 2.719
    },
    {
      "lang": "en",
      "text": "enormous unluck because I think this is",
      "offset": 3212.079,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "one of the big blind spots of humanity.",
      "offset": 3213.599,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "Absolutely. Um I I'm not confident. Um",
      "offset": 3216.319,
      "duration": 4.961
    },
    {
      "lang": "en",
      "text": "it's definitely doable. I have not seen",
      "offset": 3219.599,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "anybody do it well, but I basically",
      "offset": 3221.28,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "believe it's possible because again it",
      "offset": 3223.359,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "leads into the strengths of AIS. So if",
      "offset": 3225.119,
      "duration": 3.121
    },
    {
      "lang": "en",
      "text": "you've got your team of human",
      "offset": 3227.119,
      "duration": 2.48
    },
    {
      "lang": "en",
      "text": "forecasters, so like hey am I going to",
      "offset": 3228.24,
      "duration": 3.119
    },
    {
      "lang": "en",
      "text": "get all my Nvidia chips in my data",
      "offset": 3229.599,
      "duration": 3.441
    },
    {
      "lang": "en",
      "text": "center uh they can't think of",
      "offset": 3231.359,
      "duration": 3.121
    },
    {
      "lang": "en",
      "text": "everything. They could maybe think of",
      "offset": 3233.04,
      "duration": 3.279
    },
    {
      "lang": "en",
      "text": "four or five scenarios and work them out",
      "offset": 3234.48,
      "duration": 3.599
    },
    {
      "lang": "en",
      "text": "in detail and then that will be the end",
      "offset": 3236.319,
      "duration": 3.121
    },
    {
      "lang": "en",
      "text": "of the hours that they have to work on",
      "offset": 3238.079,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "the problem. If you have an AI system",
      "offset": 3239.44,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "that has the type of judgment necessary",
      "offset": 3241.76,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "to go through those scenarios, you can",
      "offset": 3243.76,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "consider a 100 scenarios or a thousand",
      "offset": 3245.2,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "scenarios. You could be doing in early",
      "offset": 3246.96,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "2020 what no human was doing which is",
      "offset": 3249.04,
      "duration": 3.519
    },
    {
      "lang": "en",
      "text": "forecasting with the impact of a",
      "offset": 3251.2,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "pandemic on your supply chain. Nobody",
      "offset": 3252.559,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "was thinking about that scenario until",
      "offset": 3255.119,
      "duration": 2.881
    },
    {
      "lang": "en",
      "text": "it happened. But",
      "offset": 3256.72,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "the funny thing about that is CO 19",
      "offset": 3258,
      "duration": 3.599
    },
    {
      "lang": "en",
      "text": "although you know it did come very",
      "offset": 3260,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "quickly uh we had forecasts of a global",
      "offset": 3261.599,
      "duration": 5.441
    },
    {
      "lang": "en",
      "text": "pandemic including a global pandemic",
      "offset": 3264.8,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "that involved corona viruses coming from",
      "offset": 3267.04,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "the Wuhan region. Right? This was not a",
      "offset": 3269.04,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "surprise to anyone that was working in",
      "offset": 3271.28,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "epidemiology. They had been forecasting",
      "offset": 3272.96,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "that for 20 years. Uh so it's kind of",
      "offset": 3275.119,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "funny to me that that never came into",
      "offset": 3277.44,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "the scenario planning for the supply",
      "offset": 3279.04,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "chain. It never folded into uh scenario",
      "offset": 3280.88,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "planning for national security or for",
      "offset": 3283.359,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "public health. Uh I actually take that",
      "offset": 3285.52,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "back because the good public health",
      "offset": 3287.359,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "organizations were quite aware of it.",
      "offset": 3289.2,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "They were sometimes styided in the",
      "offset": 3291.359,
      "duration": 3.521
    },
    {
      "lang": "en",
      "text": "response. Um but it's interesting right",
      "offset": 3292.88,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "there. That's an example of something",
      "offset": 3294.88,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "that was actually well predicted and",
      "offset": 3296.16,
      "duration": 3.679
    },
    {
      "lang": "en",
      "text": "well understood and the dynamics of it",
      "offset": 3297.92,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "spread were well understood in advance.",
      "offset": 3299.839,
      "duration": 3.441
    },
    {
      "lang": "en",
      "text": "I don't think everyone believed it. you",
      "offset": 3301.52,
      "duration": 2.88
    },
    {
      "lang": "en",
      "text": "know maybe it was a small number of",
      "offset": 3303.28,
      "duration": 2.72
    },
    {
      "lang": "en",
      "text": "people who understood it and uh they",
      "offset": 3304.4,
      "duration": 2.88
    },
    {
      "lang": "en",
      "text": "didn't have a platform to get the",
      "offset": 3306,
      "duration": 2.96
    },
    {
      "lang": "en",
      "text": "information out but it wouldn't be",
      "offset": 3307.28,
      "duration": 3.279
    },
    {
      "lang": "en",
      "text": "accurate to say that like no one knew",
      "offset": 3308.96,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "that there would be a co 19 pandemic",
      "offset": 3310.559,
      "duration": 5.601
    },
    {
      "lang": "en",
      "text": "when in fact uh you know a a coronavirus",
      "offset": 3312.8,
      "duration": 5.519
    },
    {
      "lang": "en",
      "text": "born uh pandemic coming from the Wuhan",
      "offset": 3316.16,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "region was something that many many many",
      "offset": 3318.319,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "people in epidemiology had been thinking",
      "offset": 3320.319,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "about for years and discussing uh it was",
      "offset": 3322.16,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "fairly well understood so here we have a",
      "offset": 3324.559,
      "duration": 3.361
    },
    {
      "lang": "en",
      "text": "different problem which is the Cassandra",
      "offset": 3326.24,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "problem which is that you can be you",
      "offset": 3327.92,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "know outside the temple and making",
      "offset": 3330,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "absolutely accurate forecast that nobody",
      "offset": 3332,
      "duration": 3.359
    },
    {
      "lang": "en",
      "text": "listens to because they're politically",
      "offset": 3333.92,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "uncomfortable or inconvenient. Do you",
      "offset": 3335.359,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "run into that in your line of work? I",
      "offset": 3337.839,
      "duration": 3.041
    },
    {
      "lang": "en",
      "text": "mean, are there forecasts that you make",
      "offset": 3339.359,
      "duration": 3.521
    },
    {
      "lang": "en",
      "text": "or where you you feel like, oh, 100%",
      "offset": 3340.88,
      "duration": 4.719
    },
    {
      "lang": "en",
      "text": "accurate forecast, a possibility, but it",
      "offset": 3342.88,
      "duration": 4.239
    },
    {
      "lang": "en",
      "text": "lands with a thud because it's not the",
      "offset": 3345.599,
      "duration": 2.881
    },
    {
      "lang": "en",
      "text": "answer people want to hear.",
      "offset": 3347.119,
      "duration": 2.801
    },
    {
      "lang": "en",
      "text": "Well, of course, timing is everything in",
      "offset": 3348.48,
      "duration": 3.119
    },
    {
      "lang": "en",
      "text": "forecasting and yes, uh, the",
      "offset": 3349.92,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "epidemiological community did predict",
      "offset": 3351.599,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "that there would be global pandemics",
      "offset": 3353.52,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "like the CO9 one, even as you say,",
      "offset": 3355.28,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "possibly with a corona virus",
      "offset": 3357.359,
      "duration": 3.521
    },
    {
      "lang": "en",
      "text": "specifically. Um but there were many",
      "offset": 3358.96,
      "duration": 3.359
    },
    {
      "lang": "en",
      "text": "other hypotheses of other types of",
      "offset": 3360.88,
      "duration": 2.64
    },
    {
      "lang": "en",
      "text": "viruses and it could have happened at",
      "offset": 3362.319,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "any time. Um one interesting detail is I",
      "offset": 3363.52,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "learned about COVID from Metaculus you",
      "offset": 3365.92,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "know years before I was the CTO there.",
      "offset": 3367.68,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "Uh that was you know a forecasting",
      "offset": 3369.76,
      "duration": 2.96
    },
    {
      "lang": "en",
      "text": "platform was actually one of the only",
      "offset": 3371.52,
      "duration": 2.48
    },
    {
      "lang": "en",
      "text": "places on the internet where people were",
      "offset": 3372.72,
      "duration": 2.56
    },
    {
      "lang": "en",
      "text": "actively engaged in trying to figure out",
      "offset": 3374,
      "duration": 2.88
    },
    {
      "lang": "en",
      "text": "what was going on with this weird virus",
      "offset": 3375.28,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "in China. This was like late January",
      "offset": 3376.88,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "early February 2020. Uh it kind of",
      "offset": 3378.88,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "seeped its way to the various parts of",
      "offset": 3381.04,
      "duration": 2.72
    },
    {
      "lang": "en",
      "text": "the internet like months before it",
      "offset": 3382.4,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "became a mainstream thing. Uh, but I was",
      "offset": 3383.76,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "able to actually cancel a trip to Hawaii",
      "offset": 3385.92,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "to go to a wedding because I saw stuff",
      "offset": 3387.52,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "on forecasting platforms that was not in",
      "offset": 3389.04,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "the news anywhere. None of my colleagues",
      "offset": 3390.64,
      "duration": 3.199
    },
    {
      "lang": "en",
      "text": "were talking about it at work. Like it",
      "offset": 3392.4,
      "duration": 2.56
    },
    {
      "lang": "en",
      "text": "was just a thing that the niche",
      "offset": 3393.839,
      "duration": 3.121
    },
    {
      "lang": "en",
      "text": "forecasting community had picked up on.",
      "offset": 3394.96,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "So timing is interesting because you",
      "offset": 3396.96,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "have to time the forecast, but also",
      "offset": 3398.24,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "things sometimes unfold slowly over time",
      "offset": 3400,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "and there was the whole period from late",
      "offset": 3402.24,
      "duration": 4.559
    },
    {
      "lang": "en",
      "text": "December of 2019 through midFebruary of",
      "offset": 3403.92,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "2020 where people who were quite savvy",
      "offset": 3406.799,
      "duration": 3.121
    },
    {
      "lang": "en",
      "text": "knew what was happening and the rest of",
      "offset": 3408.64,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "the world was totally oblivious. Um",
      "offset": 3409.92,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "yeah, I will say one more interesting",
      "offset": 3412.559,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "case for for pandemics is uh cyber",
      "offset": 3413.92,
      "duration": 4.639
    },
    {
      "lang": "en",
      "text": "attacks. This is something where every",
      "offset": 3416.48,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "professional in the cyber security",
      "offset": 3418.559,
      "duration": 3.361
    },
    {
      "lang": "en",
      "text": "community is worried that basically all",
      "offset": 3420.16,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "of our hospital systems, all of our",
      "offset": 3421.92,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "power transmission lines, like large",
      "offset": 3423.76,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "companies are completely and utterly",
      "offset": 3425.839,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "unready for like a very serious state",
      "offset": 3428,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "sponsored hack and have been trumpeting",
      "offset": 3430.079,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "this for many years. I my prediction is",
      "offset": 3432.64,
      "duration": 3.679
    },
    {
      "lang": "en",
      "text": "it's going to be like co is that they're",
      "offset": 3434.799,
      "duration": 3.201
    },
    {
      "lang": "en",
      "text": "going to turn out to be right like that",
      "offset": 3436.319,
      "duration": 2.881
    },
    {
      "lang": "en",
      "text": "is going to happen. There's going to be",
      "offset": 3438,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "an absolutely devastating cyber attack",
      "offset": 3439.2,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "maybe sometime in the next 5 to 10 years",
      "offset": 3441.28,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "that takes a whole country or a whole",
      "offset": 3443.52,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "hospital system or the financial system",
      "offset": 3445.76,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "or a tech company completely offline",
      "offset": 3447.76,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "causes billions or maybe even trillions",
      "offset": 3450.16,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "of dollar in damages. And all the people",
      "offset": 3452.16,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "who are professionals in that community",
      "offset": 3454.559,
      "duration": 2.8
    },
    {
      "lang": "en",
      "text": "said I've been telling you this is going",
      "offset": 3456,
      "duration": 2.64
    },
    {
      "lang": "en",
      "text": "to happen and telling you to prepare for",
      "offset": 3457.359,
      "duration": 2.96
    },
    {
      "lang": "en",
      "text": "this for decades and nobody listened.",
      "offset": 3458.64,
      "duration": 2.959
    },
    {
      "lang": "en",
      "text": "and all the people who could have done",
      "offset": 3460.319,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "something about it saying, \"Yeah, well,",
      "offset": 3461.599,
      "duration": 2.96
    },
    {
      "lang": "en",
      "text": "there were a lot of other things I was",
      "offset": 3463.359,
      "duration": 2.561
    },
    {
      "lang": "en",
      "text": "worried about. You didn't tell me when",
      "offset": 3464.559,
      "duration": 2.641
    },
    {
      "lang": "en",
      "text": "it was going to happen and it's very",
      "offset": 3465.92,
      "duration": 2.8
    },
    {
      "lang": "en",
      "text": "expensive to protect against that type",
      "offset": 3467.2,
      "duration": 2.08
    },
    {
      "lang": "en",
      "text": "of thing.\"",
      "offset": 3468.72,
      "duration": 0.96
    },
    {
      "lang": "en",
      "text": "That's right.",
      "offset": 3469.28,
      "duration": 1.68
    },
    {
      "lang": "en",
      "text": "So, I think the the moral of the story",
      "offset": 3469.68,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "here is like forecasting alone isn't",
      "offset": 3470.96,
      "duration": 3.119
    },
    {
      "lang": "en",
      "text": "enough because even if you have the",
      "offset": 3472.72,
      "duration": 2.96
    },
    {
      "lang": "en",
      "text": "forecast, what are you going to do about",
      "offset": 3474.079,
      "duration": 2.401
    },
    {
      "lang": "en",
      "text": "it?",
      "offset": 3475.68,
      "duration": 2.399
    },
    {
      "lang": "en",
      "text": "This is the challenge, right? You you",
      "offset": 3476.48,
      "duration": 3.599
    },
    {
      "lang": "en",
      "text": "can actually develop highly",
      "offset": 3478.079,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "sophisticated accurate forecasting and",
      "offset": 3480.079,
      "duration": 4.801
    },
    {
      "lang": "en",
      "text": "um still not be able to influence the",
      "offset": 3482.799,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "political debate or the economic",
      "offset": 3484.88,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "decision-m. Uh Dan, give me put on your",
      "offset": 3486.88,
      "duration": 4.719
    },
    {
      "lang": "en",
      "text": "forecasting hat for a moment as we come",
      "offset": 3489.92,
      "duration": 3.199
    },
    {
      "lang": "en",
      "text": "to the end of the show here and tell me",
      "offset": 3491.599,
      "duration": 2.801
    },
    {
      "lang": "en",
      "text": "what you think the world's going to look",
      "offset": 3493.119,
      "duration": 4.641
    },
    {
      "lang": "en",
      "text": "like in the next 10 or 20 years based on",
      "offset": 3494.4,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "what you're seeing this uh convergence",
      "offset": 3497.76,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "of technologies and the rapid iteration",
      "offset": 3499.44,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "and improvement and particularly in",
      "offset": 3501.44,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "machine intelligence and its ability to",
      "offset": 3503.839,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "do forecasting. What do you think the",
      "offset": 3506.24,
      "duration": 2.72
    },
    {
      "lang": "en",
      "text": "world's going to be like? Will we have",
      "offset": 3507.839,
      "duration": 3.041
    },
    {
      "lang": "en",
      "text": "much better uh perspectives on the",
      "offset": 3508.96,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "future as a society? Will this improve",
      "offset": 3510.88,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "our ability to collective decision make",
      "offset": 3513.04,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "or or not?",
      "offset": 3515.28,
      "duration": 3.039
    },
    {
      "lang": "en",
      "text": "I think it will. Um, obviously I'm",
      "offset": 3516.48,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "biased because I'm orienting my career",
      "offset": 3518.319,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "around it. Um, and you know, doing it as",
      "offset": 3520.16,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "a a startup, not as a think tank for a",
      "offset": 3522.559,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "research lab because I think this is a",
      "offset": 3524.48,
      "duration": 2.879
    },
    {
      "lang": "en",
      "text": "billion-dollar opportunity. So, of",
      "offset": 3525.839,
      "duration": 2.561
    },
    {
      "lang": "en",
      "text": "course, I'm biased. You know, the",
      "offset": 3527.359,
      "duration": 2.401
    },
    {
      "lang": "en",
      "text": "forecasters that we have at future",
      "offset": 3528.4,
      "duration": 2.88
    },
    {
      "lang": "en",
      "text": "search might give you a more calibrated",
      "offset": 3529.76,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "view than me as the CEO. Um, but yes, I",
      "offset": 3531.28,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "think forecasting is unbelievably",
      "offset": 3534.24,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "valuable and it has been proven out in",
      "offset": 3535.92,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "the literature and you absolutely can",
      "offset": 3537.44,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "use AI to make it much better, faster,",
      "offset": 3539.04,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "cheaper, ask all the questions you never",
      "offset": 3540.88,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "wanted. you you never never had humans",
      "offset": 3542.96,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "that you could answer ask to answer",
      "offset": 3545.04,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "those questions before. But it takes",
      "offset": 3546.72,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "time. So if you're asking me about the",
      "offset": 3549.44,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "2030s or 2040s, I would predict quite",
      "offset": 3551.119,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "strongly that we'll look back to this",
      "offset": 3553.52,
      "duration": 2.72
    },
    {
      "lang": "en",
      "text": "time and say, \"Wow, we were living in",
      "offset": 3554.799,
      "duration": 2.881
    },
    {
      "lang": "en",
      "text": "the dark ages.\" Like we knew how to",
      "offset": 3556.24,
      "duration": 2.879
    },
    {
      "lang": "en",
      "text": "predict things and we weren't doing it",
      "offset": 3557.68,
      "duration": 3.439
    },
    {
      "lang": "en",
      "text": "at all. People were just using their gut",
      "offset": 3559.119,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "to make all the decisions in government",
      "offset": 3561.119,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "and in business and academia. No one was",
      "offset": 3562.799,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "forecasting like which scientific paths",
      "offset": 3565.2,
      "duration": 2.96
    },
    {
      "lang": "en",
      "text": "would work better. Nobody was",
      "offset": 3566.96,
      "duration": 2.879
    },
    {
      "lang": "en",
      "text": "forecasting, you know, cyber attacks and",
      "offset": 3568.16,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "pandemics. People weren't forecasting",
      "offset": 3569.839,
      "duration": 3.361
    },
    {
      "lang": "en",
      "text": "the outcomes of mergers. They weren't",
      "offset": 3571.68,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "forecasting the outcomes of, you know,",
      "offset": 3573.2,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "bombing Iran or whatever is going on",
      "offset": 3574.72,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "right now with Israel, Iran. Everyone",
      "offset": 3576.24,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "was just using their gut and just",
      "offset": 3578.16,
      "duration": 3.439
    },
    {
      "lang": "en",
      "text": "guessing. And all of society was run",
      "offset": 3579.92,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "that way. And once we have better",
      "offset": 3581.599,
      "duration": 3.281
    },
    {
      "lang": "en",
      "text": "technology to do this, we'll never look",
      "offset": 3583.2,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "back. In the same way that the",
      "offset": 3584.88,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "scientific method has completely changed",
      "offset": 3586.24,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "something like medicine where medicine",
      "offset": 3588.4,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "was just kind of like doctors just did",
      "offset": 3590,
      "duration": 2.96
    },
    {
      "lang": "en",
      "text": "whatever they felt like. They didn't",
      "offset": 3591.44,
      "duration": 2.639
    },
    {
      "lang": "en",
      "text": "really have evidence behind anything",
      "offset": 3592.96,
      "duration": 2.96
    },
    {
      "lang": "en",
      "text": "they were doing. We lived that way for",
      "offset": 3594.079,
      "duration": 4.561
    },
    {
      "lang": "en",
      "text": "hundreds of years. And very recently",
      "offset": 3595.92,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "doctors now do stuff that is actually",
      "offset": 3598.64,
      "duration": 3.439
    },
    {
      "lang": "en",
      "text": "supported by the science. The science of",
      "offset": 3600.16,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "forecasting is turning online as well. I",
      "offset": 3602.079,
      "duration": 4.561
    },
    {
      "lang": "en",
      "text": "think heads of state CEOs once that",
      "offset": 3604.24,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "technology becomes available they will",
      "offset": 3606.64,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "use it. And I kind of understand why",
      "offset": 3608.48,
      "duration": 2.879
    },
    {
      "lang": "en",
      "text": "they don't use it today because it's not",
      "offset": 3609.76,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "very accessible. But I think we will",
      "offset": 3611.359,
      "duration": 3.521
    },
    {
      "lang": "en",
      "text": "look back on this as a total dark age",
      "offset": 3613.28,
      "duration": 2.799
    },
    {
      "lang": "en",
      "text": "for humanity where we were just",
      "offset": 3614.88,
      "duration": 2.959
    },
    {
      "lang": "en",
      "text": "blundering towards the future with",
      "offset": 3616.079,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "absolutely no plan, no foresight, no",
      "offset": 3617.839,
      "duration": 5.201
    },
    {
      "lang": "en",
      "text": "real idea what was going on. And we will",
      "offset": 3620.48,
      "duration": 4.639
    },
    {
      "lang": "en",
      "text": "think it was like a total crime that we",
      "offset": 3623.04,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "were operating this way.",
      "offset": 3625.119,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "Let's hope that the humans can evolve",
      "offset": 3627.119,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "the ability to listen to the forecast",
      "offset": 3629.28,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "and make intelligent decisions uh based",
      "offset": 3631.04,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "on that information. Yeah.",
      "offset": 3633.2,
      "duration": 2.8
    },
    {
      "lang": "en",
      "text": "Well, Dan, it's been a pleasure having",
      "offset": 3634.72,
      "duration": 2.56
    },
    {
      "lang": "en",
      "text": "you on the show today. I've enjoyed this",
      "offset": 3636,
      "duration": 3.359
    },
    {
      "lang": "en",
      "text": "conversation immensely. Where can people",
      "offset": 3637.28,
      "duration": 5.039
    },
    {
      "lang": "en",
      "text": "find out more information about you and",
      "offset": 3639.359,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "about future.ai?",
      "offset": 3642.319,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "Yeah. Well, it's at futurearch.ai. Um",
      "offset": 3644.079,
      "duration": 3.201
    },
    {
      "lang": "en",
      "text": "yeah, thank you Robert for having me.",
      "offset": 3646.079,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "It's been a great conversation. Yeah, I",
      "offset": 3647.28,
      "duration": 3.039
    },
    {
      "lang": "en",
      "text": "would encourage people if they want to",
      "offset": 3649.119,
      "duration": 2.561
    },
    {
      "lang": "en",
      "text": "see what's going on with the future of",
      "offset": 3650.319,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "AI itself and and how AI can help you",
      "offset": 3651.68,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "understand that future.ai. We've got",
      "offset": 3654,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "evals, we've got reports, um, and",
      "offset": 3656.16,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "software coming out soon.",
      "offset": 3658.079,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "Cool. Thanks for being on the show. And,",
      "offset": 3660.079,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "uh, folks who are listening, you've been",
      "offset": 3662.24,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "listening to Dan Schwarz, the CEO and",
      "offset": 3663.839,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "co-founder of futurearch.ai.",
      "offset": 3665.76,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "I'm Rob Turszik from the Futurists. And",
      "offset": 3668.079,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "every week, Brett King and I will bring",
      "offset": 3670,
      "duration": 2.96
    },
    {
      "lang": "en",
      "text": "you another person who's thinking about",
      "offset": 3671.599,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "and shaping the future. Um, we enjoy",
      "offset": 3672.96,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "this process so much and we're also",
      "offset": 3675.52,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "getting such a kick out of uh, the",
      "offset": 3678,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "messages and the comments that we get",
      "offset": 3680.16,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "back from people. Um, thank you. keep",
      "offset": 3681.44,
      "duration": 4.879
    },
    {
      "lang": "en",
      "text": "sending that information to us. Uh I",
      "offset": 3683.68,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "want to mention one thing that's",
      "offset": 3686.319,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "happening uh in September. I'm thrilled",
      "offset": 3687.44,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "to tell you that we'll be doing a live",
      "offset": 3689.599,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "event in Dubai. Uh Brett has been",
      "offset": 3691.2,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "working very hard to organize this event",
      "offset": 3693.44,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "with the sponsorship of Mastercard. We",
      "offset": 3695.119,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "will be bringing together some of the",
      "offset": 3697.52,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "world's best uh futurist forecasters and",
      "offset": 3698.799,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "future thinkers for a live event, a",
      "offset": 3700.88,
      "duration": 4.959
    },
    {
      "lang": "en",
      "text": "two-day event in Dubai at the famous",
      "offset": 3703.599,
      "duration": 4.561
    },
    {
      "lang": "en",
      "text": "Jariah Beach Hotel there. Very fabulous",
      "offset": 3705.839,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "place. If you're interested, you can",
      "offset": 3708.16,
      "duration": 2.639
    },
    {
      "lang": "en",
      "text": "learn more about that at",
      "offset": 3710,
      "duration": 2.48
    },
    {
      "lang": "en",
      "text": "futuristevent.com.",
      "offset": 3710.799,
      "duration": 3.201
    },
    {
      "lang": "en",
      "text": "and I'm looking forward to seeing you",
      "offset": 3712.48,
      "duration": 3.119
    },
    {
      "lang": "en",
      "text": "there in person if you can make it. And",
      "offset": 3714,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "if you can't, well, I'll see you in the",
      "offset": 3715.599,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "future on the Futurist podcast. Thanks,",
      "offset": 3717.04,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "Dan. Thanks for joining us.",
      "offset": 3719.359,
      "duration": 5.24
    },
    {
      "lang": "en",
      "text": "Thank you, Robert.",
      "offset": 3721.28,
      "duration": 3.319
    }
  ],
  "cleanText": "This week on The Futurists, Dan Schwarz.\n\nForecasting the future of technology is unbelievably hard as I'm sure you know Robert better than most. Um so we said, okay, we need more like we need more intelligence and of course the source of new intelligence is not throw more humans at the problem. It's put some AI on it. And that's where we are now.\n\n[Music]\n\nHey there. Welcome back to The Futurists. I'm Rob Tercek and this week I am solo. Uh Brett King was planning to join but at the last moment got pulled away. As you may know if you listen to the show frequently, uh Brett's often on the road, so the guy has a lot of demands on his time, but he set me up with a great interview today. I'm going to be speaking to someone who's thinking very deeply uh about the future and in particular the future of AI uh by evaluating the performance of various AI models and their business models as well. Um and among them many other things. Uh so let me give a warm introduction to Dan Schwarz. Dan, welcome to The Futurists. Thanks for joining us today on the show.\n\nThank you for having me, Robert.\n\nDan, uh tell us a little bit about FutureSearch. Uh it's a relatively new organization and I think probably a lot of folks are not familiar with it.\n\nYeah, we are a seed-stage startup. Uh we're a little bit less than two years old. Um we are predicting the future using AI and uh we got started shortly after GPD4 came out when we realized that this was now possible. Um, prior to FutureSearch, I was the CTO of Metaculus, which is the, you know, preeminent human forecasting platform. And for that, I built and ran the prediction market that is currently running inside Google. So, I was very, very interested in how we can predict the future. And up until two years ago, the answer was how do we get the best information out of human beings? And now the question is, how do we get the best information out of AI? And that's what FutureSearch is doing.\n\nVery cool. And so, if uh folks go to the website, it's FutureSearch.ai AI because actually there's a couple different things that turn up if you search it on Google. So it's important to put the .ai at the end if you're going to go to that site. Uh you'll find research reports and some news and I was actually quite interested to see uh the information that you've been sharing on LinkedIn. Uh folks, if you find um if you find Dan on LinkedIn, then you'll be able to see some of his recent reports uh you know for instance about the business model of OpenAI and so on. I was surprised you were able to get that information because that's not readily available even from uh news publications.\n\nThat's right. And it was last summer when we were the first to basically figure out their business model like where the revenue was coming from from Chad GBT consumer and enterprise and from the API uh when none of that information was public and the main way we were able to do that was using our forecasting techniques. Uh to be great at forecasting you have to work with information you don't have because the future is fundamentally unknowable. So you have to kind of triangulate data sources, you have to estimate, you have to infer, you have to make probabilistic inferences. But if you get enough data and you have good enough judgment, you can make pretty good probabilistic inferences. And those projections that we made last summer about OpenAI held out very, very well when more data came in. That gives us more confidence that our methodology is working and hopefully gives our audience some and customers some confidence when they look at our analysis that we're more likely to be right than your average analyst or reporter on the topic.\n\nSo that's really interesting. So that report that you published, you didn't do that in cooperation with OpenAI. You didn't get access to any inside information at that company. you simply had your AI system evaluate trends and then make forecasts and predictions uh based on that information.\n\nWith plenty of humans too. Um despite what I said before about AI being the main place to mine for insights about the future, of course humans are still king, just not for that long. Um so you know two years ago it was purely a human intelligence game. The last two years it's been hybrid human AI intelligence and now we are starting to see the pure AI intelligence part come to its its own element. Um, you know, I'm I'm a longtime chess player and this is kind of the main way that we think about the relation between humans and AI. You know, many decades of just humans, then this period of time for about 10 or 20 years where is humans and AI working together and then we got to the point where it was only AI and humans have basically nothing left to say about the game of chess. Uh, predicting the future is much, much harder than playing chess. Much, much harder. Uh, but I think it will follow that same shape. So, we'll be in this era where we have human AI pairing and then we'll be in the AI only world before too long. Well, that's quite interesting. You know, the there was research uh republished today by um uh Gary Marcus who's a notable critic or I should say critical thinker about AI. He's uh he's well known for debunking some of the more outrageous claims made by OpenAI. And he published research today that said even the reasoning models uh that that OpenAI has been promoting so heavily recently. Uh he said even those reasoning models are subject to deception. uh and he gave some examples where uh they were citing known research uh sorry known publications that are uh disinformation sites um particularly the Pravda network in Russia uh where if you ask uh the reasoning models the OpenAI reasoning models they will tell you all about this Pravda network and it's well understood by the AI that this is a disinformation network but then again if you ask other questions it starts to show up uh as uh as credible information and so it's easy to fool these systems today. Uh tell me a little bit about that because you made a prediction that someday um perhaps soon uh machines will be reasoning better than humans and I would say that Gary Marcus would probably differ with you on that. So how about how do you respond to that?\n\nYeah. Uh I mean Gary is a smart guy, but I think he disagrees with myself and many other people who are uh more of a believer not necessarily in the present state of these models but in the velocity and maybe even the acceleration um of their quality. Yeah, that question is very interesting. I don't think the research definitively answers this, but the best of my understanding is that a lot of the citing of incredible sources uh comes from post training. You know, for a while hallucinations were such a huge problem for using LLMs for almost anything that the the reward for not hallucinating but citing your evidence was extremely high. And so models got in a habit of citing whatever they could find. Um it's not just Pravda, by the way. You know, a lot of FutureSearch runs, we have to, you know, go and tune them because they will pull up things like market research reports that are superficially credible, but any expert looking at them will tell that this is just some intern who just put a bunch of numbers into a spreadsheet. It's not like credible research.\n\nAnd are the AI capable of making that discernment or does that require human intervention?\n\nThat's, you know, that's a tough problem. Um, it is somewhat capable. Like you said, if you just ask chat GPT, is Pravda a credible source? It will tell you it's not, but then it will go cite it. Exactly as you said, Robert. So, some of this is just kind of the engineering of the intelligence of what is a credible source is there. You just have to elicit it out of the model. But part of it is that you just need to have good epistemics for your reasoning more generally. And it's not just hallucinations and it's not just, you know, using sources that are not credible. There's a million ways you can go wrong in your reasoning chains. And you know Gary Marcus is right that if you want to get high quality research just asking chat GPT even with 03 or Grock 4 which came out yesterday or whatever you want is not that great but that's like going to one human you you just meet on the street or a single consultant you hire and saying just tell me what's going to happen with OpenAI and just believing everything they tell you. That would be a crazy thing to do.\n\nU you know one of the things about coming to forecasting from studying humans before doing it as AI is that humans are incredibly bad at almost every forecasting task like they also hallucinate and make stuff up that is not you know they just remember something but it turns out to be fake they will also site bad sources that they shouldn't site they will make deductive errors they make inductive errors they will omit critical information uh and so the best way to get information out of humans is to have like really expert humans and to work with them for a long period of time and to have them work in teams.\n\nAnd that still is fraught and still leads to error. So the idea that we just take an off-the-shelf AI just ask it one thing and say ah it failed therefore AI is not trustworthy. It's like have you talked to humans? Like humans are terrible at these tasks. Really it's it's just a complicated engineering and orchestration problem to get good information at large from humans from AI or from humans working with AI.\n\nIt's I'm laughing because of course you're on a show called The Futurists where we talk to forecasters and people who make bold predictions all the time and it's true and even here we have uh we have the challenge of screening out charlatans um people who make you know basically they they take a shot from the hip uh there is a style of of futurist who uh I call them entertainment futurists because they make the kinds of forecasts that sound really plausible and they're super interesting scenarios and they present it in such a credible fashion because they speak boldly with confidence that uh they can persuade a lot of people that that may be may be true or that may be likely and sometimes I'm listening to these folks and I think to myself this guy's completely making it up like you know he has it's not based on anything credible or you're right like you know superficial search across the web and pulling a pulling up a couple research reports and then using that to extrapolate some scenario. uh you know typically when we do scenario planning for organizations um we'll present a range of scenarios weighted probabilities about what we believe might happen and our reasoning for that and um and you know very often there's variability with each of those right so it's never really that certain it's very difficult uh as you said in the beginning the future doesn't exist uh it's not like a book that's been written and you're just guessing the next page it's a range of probabilities that's the only you know all that exists is the present moment and what we understand about the past and the rest of it is to um how do you present that information and how do your clients get value from it?\n\nYeah, it's a great question, Robert, and yeah, you as a futurist who have worked with other futurists, I think you probably understand this better than I do. Um the I'll point you to an example. Um we contributed some of the forecast to the AI 2027 report that came out a couple months ago. Uh Robert, did you read that one?\n\nNo, I didn't.\n\nI'd encourage you and your audience to check out AI 2027. It is a very, very well-crafted scenario of how a hard AI takeoff could happen in the next couple of years. Um, and the answer to your question, Robert, is that it does all of it. So, we contributed the forecast, just kind of the hard-nosed quantitative modeling plus putting in judgment, you know, all the forecasting techniques we have at our disposal to just get the most accurate answer we can to when will certain milestones be reached with the first one being when will AI be so good at coding that it massively speeds up the coding that happens in the frontier labs that are developing AI. And then there's a series of milestones that happen after that.\n\nBut if you read it, it is a it's two scenarios. It's very long. It's an hour or two to read. And there's kind of an accompanying graphic on the side that shows you the progress that is, you know, manifesting in society. It talks about the technology. It talks about the politics, talks about US-China relationships, it talks about the actual development of the models and tries to synthesize all of that into a coherent hole. Um, AI 2022 is very, very ambitious. Uh, I loved it. Some people loved it. Uh, some people really didn't like. Uh even Vitalic Bddherin just actually made critique of it just yesterday that I thought was really interesting. Um so I wouldn't claim to have the best answer to how to turn information about the future into something persuasive. Uh I think there's many different audiences who want many different types of things. I think my main claim is that we should try harder like we should make better scenarios like you said make them probabilistic like we should back them with quantitative models.\n\nUm and then from the you know the FutureSearch and Metaculous perspective we should trust people who have a better track record. Like if people go and say things and those things turn out to be good, we should listen to them more. If people go and say things and those things turn out to be wrong, we should listen to them less.\n\nIt's astounding to me in media how many pundits are wrong consistently and yet they're still they still appear on television. It's almost like, you know, the the audiences for this information, at least when it comes to like broadcasting and mass media, the audiences seem to prefer someone who tells them a familiar tale or the tale that they expect or an exciting tale rather than anything that's close to accurate. Uh and and there's no penalty. It seems there's no accountability for people who are egregiously wrong again and again and again on television where it's recorded and you can show the evidence that that they have been wrong consistently. Um I'm not going to name names right now, but there are plenty of examples particularly in the in the markets and finance.\n\nUh but it's not it's not necessarily a lost cause. I think the you know the Tetlock school of forecasting that is done in tournaments with resolutions and probabilities and brier scores, it's only about 10 or 15 years old. I think it's still a little bit slow in getting adopted into the wider you know even the finance community which really they have a lot of money on the line you think they would take this more seriously and they frequently don't.\n\nBut is changing and I think AI is actually accelerating that change because AI makes things a lot more transparent because when an AI gives you some information it comes with a big old rationale it comes with models you can read it you can ask follow-up questions you can get much more.\n\n\nInformation about what that AI did when you talk to humans, the kind of human judgment that is behind these forecasts is often quite messy, and often the human themselves won't know. They'll say, \"Well, I just have a sense that Open AI is ahead,\" and they won't be able to really justify that.\n\nSo AI is making everything more transparent. It's giving reasoning chains and numbers and models and citations to all sorts of types of things we didn't used to have. And so I think the demand, especially from the financial community, for more rigor is accelerating, and I think for the rest of the world, too.\n\nIn a way, Dan, that's one of the reasons why we started the show a long time ago when Brett and I got started here. We said, you know, the world needs more people who can think athletically about the future, even if you're wrong. You know, I make fun of the people who make mistakes when they predict or prognosticate, but the fact is it's a good habit to be thinking about the future. It's also a very good habit to keep track of your forecast so that you can see how frequently you're wrong because a lot of people fall into that kind of cognitive bias where they think that they're more frequently right. I would guess most people are not correct in their forecasts more than half the time. I feel happy if my forecast are right 50% of the time. I feel like I'm doing fantastically well relative to most people. Now you brought up Philip Tetlock, and for the folks who are listening, it's important to know about super forecasting. Tetlock is a psychologist who developed a methodology. First, he became interested in the ability of people to forecast and why can some folks do it better than others and discovered that some people suffer from cognitive biases that make it impossible for them to make a good forecast. And then he started to study those who were what he calls super forecasters who are highly accurate and began to kind of extrapolate their habits. And one of the habits that he cites in the book Superforecasting is the ability to read broadly across multiple sources. And the converse of that is the people who only read in a certain bubble. We can a simple example would be the left and the right in the political spectrum in any democracy, not just the United States. We're so polarized right now, and we're so overloaded with information that we tend to see the same headlines. We seem to tend to see the same stories repeated again and again and again. So if you only graze on one side of the political divide or the other for your news information, then you're likely to start to form an impression, a kind of consensus impression that may have nothing to do with reality. And anyone who's in the United States right now, you know exactly what I'm talking about. So unfortunately, we tend to say, well, that's a problem on the right, or you know, people on the right will say that's a problem on the left. The reality is that the news media today, in order to garner an audience and get attention, has to come up with extreme scenarios and grab our headlines and clickbait. And so as a result, it's all pretty extreme. When often when you dig a little past the headlines, the reality is not that extreme. Now this becomes problematic if that's shaping your view of the present because it's going to change the way you think about the future. So what Philip Tetlock would recommend is to aggressively investigate the views on the opposite side of the political fence or on any issue. It doesn't have to just be politics. His point is that the people who have that habit of reading broadly across the spectrum, they tend to make highly accurate forecasts because they're getting they have a richer information diet. Now in your work, Dan, I'm sure this is a factor when you're working with artificial intelligence. It's probably the same thing, right? Garbage in, garbage out is a famous classic computer program. We do see that the example we gave about Pravda network, for example, you can fool an AI. So one approach is to use multiple AIs, double check, you know, or take the results from one and feed it into another and see if you can get a better check. Tell me about some of the methodologies that you use to ensure that you're getting balanced information and credible sources so that your forecasts are more likely to be accurate.\n\nYeah. Um, and just to say that the fact that breadth of research is so important really gives you a signal that AI is going to help you a lot here because going deep with AI is very hard, as anyone who's used Chat GPT knows. But going broad with AI is almost baked in. Like it will definitely read more articles than you could ever read and figure out all of those angles that you can never figure out. Its synthesis and its judgment and its, you know, incredulousness. It's not clear that it has it's I mean I wouldn't say it's stronger than that. It is clearly below human intelligence and judgment. But it can definitely read more than you. So to the extent that that insight from Tetlock holds up, which I think it does, you immediately can see how incredibly useful AI can be for forecasting, even though if you just ask it a forecasting question, it's going to do pretty badly on its own. So the main technique that we use at FutureSearch is detecting errors. So we put out a benchmark called Deep Research Bench. There's a lot of tools called deep research out there right now. You know, Claude has one called Research, Grock has one called Deep Search. And then Open AAI and Gemini have something called Deep Research, and it will do this. It will read 50, 100 articles on your question. Even very technical, very difficult questions, like you want to know about troop movements in Ukraine or you want to know about a new drug's impact on the human gut. Very, very technical questions. It will just read everything for you, and the question is how good is its output on those tricky questions? Nobody had built a benchmark of this before. Nobody actually knew how well these things were researching these topics. So we decided, look, in order for to make our systems better at this, step one is to be able to evaluate it, and once we did that, we realized we should probably share this benchmark with other folks so they should know if they're going to go to chat GPT or Gemini or Claude or Grock 4 what to expect. Um, you know, the evals from just yesterday is that Grock 4 does seem to be a better LLM for this type of research, even though it just came out, compared to 03 or Gemini 2.5 or Claude Sonnet 4, and the way that we verified that is just very carefully working out the correct answer to questions that require web research. So we have tasks like validating claims, finding numbers, compiling data sets. We use humans. We very, very carefully work out what the correct answer is. And then the other technique is we freeze the internet. So when you ask a question that requires searching the internet, the internet's changing all the time. So if you ask it again tomorrow, how will you know? The information might have changed. There might be more information. Some information might have been removed. So we freeze chunks of the internet that are relevant for these questions to build like a proper test environment. So if you ask them a question about the human gut or Ukraine troop movements or whatever, we know what what's in there. So we know how good the researcher is. We're holding the internet constant. And the thing we're changing is the quality of the researcher. And this benchmark does show that AI models are getting dramatically better at this type of work, but they are still clearly subhuman. A human carefully working out an answer to a question like this who is skilled and calibrated and patient will get a better answer than any deep research tool currently on the web. But the gap is closing.\n\nThat's quite a bold statement. Tell me about that gap and tell me how long can humans take comfort in the fact that we're able to outperform in this one domain.\n\nYeah, again, it's tricky because humans have such massive variation. So I'm talking about like really great humans, and for me as a forecaster, a great human is someone who scores really well in forecasting tournaments. We work some with some of the most calibrated, most accurate forecasters on planet Earth, and we ask them to do this research and kind of work out what the correct answer is. We know they won't always get the right answer, but they will always have good uncertainty. Like what they know, they know. What they don't know, they don't know. And they don't confuse those things. And that is an incredibly rare skill, as I'm sure you know. Um, so by working out those answers, we have a sense of what the frontier is. Of course, the typical human who's asked some question about the human gut is going to get it much worse than chat GPT. The question is if you really care, and this is for something you know, for the investor community, if you want to make a bet on AI, you really want to know what you're talking about. AI is very, very messy right now. We're talking about getting the quality of evidence that would be useful for making million or billion dollar decisions. For there, you're not you're not asking like what would the typical human do, you're not asking like what would one prompt for chat GPT do, you're asking what is the best possible answer to this question that I could get, and that's you know, deep research is one attempt at that, you know, chat GPT's deep research mode in Gemini's deep research mode, but there's new ones. You know, the Gro 4 heavy has its own claims about being more epistemically virtuous than other models. Do those things hold up under scrutiny? That's what the benchmark tells us. And then you get the sense of what the frontier is. Now, I noticed on your website that companies like OpenAI and Amazon are customers. So, and Google, I think, as well. So, even though you're benchmarking these companies, and in some cases, what you're telling me right now is some of the models don't perform as well as others, yet these companies are quite interested in getting your research. So are you creating a kind of like um, I don't know, Neielson rating or billboard top 10 chart for AI performance? Is that is that kind of like an is it becoming an industry standard?\n\nUh, I would hope so. I think these benchmarks are quite important, and FutureSearch is very happy to contribute Deep Research Bench. We have another benchmark on our site, too. You can see that it's specifically about forecasting using the same technique. Um, we call it past casting. Basically, freezing slices of the internet such that you can forecast from the perspective of the past and get the answer right away. It's a technique that's only available to AIs because once a human learns something, you can't forecast it again. You just know the answer. But AIs have training window cut offs, and you can restrict the information they have access to and say, given these inputs, could you predict what will happen next? Like in real world problems. Um, so yes, I think these benchmarks are very important, and we're very happy to have the Frontier AI labs be customers of ours. Uh, they're sometimes by research on each other, which is, you know, kind of an interesting use case for us. But generally speaking, FutureSearch is about the software. It's not about the benchmarks, and it's not about the human intelligence. Other people have benchmarks. Plenty of other people have human intelligence. It's the ability to train against those benchmarks and make software that just makes better epistemic decisions that is just less likely to cite Pravda and more likely to have calibrated judgment in its output. That's what is of the commercial value that FutureSearch is going for. So, we're very happy to sell this kind of AI human hybrid research. We do just want the best possible answer to questions, and if that requires humans, we'll use humans. But again, we're moving to a world where AI is going to eclipse the ability for humans to meaningfully add judgment on these very, very complicated problems. And there it's the software that is our business.\n\nGreat. On that note, I'm going to take a little break. Uh, we'll be back in just a just a moment. Uh, we have to have a word from our sponsors. You're listening to The Futurist, and our guest this week is Dan Schwarz. We'll be right back after this.\n\nHi, this is Rob Tursk from the Futurist podcast, which is part of the Provoked Media Network. I'm excited to tell you about some news. The Futurist is expanding into the real world. We're doing a live event in Dubai. Now, folks who listen to the Futurist podcast, you're going to be familiar with the fact that my co-host Brett King has been working very hard in Dubai and other parts of the Middle East for a long time. And for more than a year, he's been putting together this event. And now, with the help and support of Mastercard and Emirates, MBD, and many other partners, we are putting together the world's largest futurist meeting in Dubai. It will take place at the fabulous Jumariah Beach Hotel in Dubai, and it'll be on the September 22nd and 23rd this year. So just a few weeks from now. The speakers are going to include some of the world's leading futurists and forecasters and future thinkers. People like Brian Cox and astronaut Scott Kelly. Of course, Brett and I will be there to conduct interviews and introduce some of the other folks. We've got speakers from around the world. And if you're interested in meeting futurists in person and participating an event that that attracts the future-minded, please join us on the 22nd and 23rd of September, you can learn more about it at futuristevent.com.\n\nThat's futuristevent.com. It's all one word, futuristevent.com, and that'll tell you all about the event. I sure hope to see you there in Dubai on the 22nd and 23rd of September. Thanks. Hey there. Welcome back to The Futurist. I'm Rob Tersik, and this week I'm talking to Dan Schwarz, who is the found co-founder and CEO of FutureSearch.ai, and we've been having a lively conversation so far about forecasting methodologies and and how they're changing in the time of artificial intelligence, and I want to come back to a question we you you touched on your background at Metaculus. So before you started this company, uh, you were at a company called Metaculus, which is a human forecasting organization. Can you give me a contrast between that methodology, human forecasting, and then what you're doing differently today with AI? And I realize some of this might be a little bit redundant, so skip that part, but uh, but the contrast is what I'm interested in. Like what's new, uh, what's novel?\n\nAbsolutely. So even though I'm mostly excited about the use of AI and forecasting,\n\n\nI think the use of humans in forecasting is still really poorly understood.\nAnd part of the reason that I, as a technologist, got interested in it is because I saw how much better we could be doing just with humans.\nUh, this is in 2019.\nYou know, I was very interested in forecasting in prediction markets, not really in anything else, but just prediction markets.\nI thought prediction markets were totally fascinating.\nThe idea that you could take betting as the mechanism in order to get accuracy out of humans.\nUm, I was at Google at the time.\nI was actually working at Whimo on the self-driving car.\nUh, Google has a history of this.\nIn 2005, they released, uh, well, not released, they had an internal prediction market.\nIt was called Profit, but it was written about in the New York Times, and there was a Harvard Business School review of it.\nThey called it Google's lunchtime betting game.\nAnd Google employees, who in 2005 were very sharp, um, would bet about things like how many users will we have, how much revenue will we have, what will happen in this office, what will happen with our competitor, and filter that information up to senior management.\nUm, the project ran for four or five years and was shut down.\nUm, I've written a little bit about that and why, what worked about it and what didn't.\nBut inside Google, reading about it and seeing all the internal documentation in the code, I was thinking, \"Wow, that actually worked.\"\nLike building a betting market so that people could bet on outcomes actually just gives better information to managers.\nThe managers don't forecast by just kind of looking at it and using their guts.\nThey could basically have a very sophisticated poll of all the people working on the project and use that to inform their decisions.\nAnd often, surprisingly, that kind of poll, if you have a big enough sample size or big enough number of participants, they're surprisingly accurate.\nYou know, they come within one or two percentage points of accuracy.\nUm, even though some of the individual answers might range quite far.\nUm, do you think that's going to be improved upon or is that going to be an input in the future?\nYeah.\nSo, yeah.\nSo I'll try to say a little bit more about what that frontier is.\nYou know, how good a forecasting I was able to achieve with the prediction market running at Google and then the forecasting platform at Metaculus, which is public, so you know, it's even open source, so you can go and look and see what is everybody forecasting, what are the track records and accuracy scores.\nIt's a bit technical, but all that information is out there.\nUm, and yeah, the reason I was so excited about it, you know, I was just kind of the normal technologist, the reason I got so excited about it is because the accuracy scores were just very high.\nAnd this again, this is kind of the Tetlock school, you know, reading those papers and seeing what some of his super forecasters were able to do that you were talking about in the last segment, Robert.\nIt's astounding.\nI think that most people's view is that the future is just totally unknowable.\nLike, basically everything is 50/50.\nThere's not really much you can say.\nYou just have to wait and find out.\nAnd Tedlock demonstrated that was far from true.\nLike, you can get really great accuracy.\nNow, very, very few humans can do it, and they have to do it in specific ways, as you were discussing in the last segment, but it does work, and those accuracy scores are good.\nAnd then the evidence from Google's internal prediction market was the same.\nYou look at that calibration chart when Google employees betting with each other was ended with a, you know, 35% chance of something happening, it tended to happen 35% of the time, and that's just astounding to me.\nWhen I was looking at that data, I could not believe that you could actually do that.\nThe collective wisdom or the collective forecasting capability of a lot of human minds is quite powerful.\nObviously, you know, two heads are better than one, but in this case, you're talking about thousands of minds.\nIn a way, it is a kind of super intelligence or an artificial artificial intelligence because you're harnessing the forecasting capability of a lot of different individuals.\nSo, it's not a natural thing.\nUm, and you're going to, it would be likely or I think reasonable to expect that to outperform an individual.\nUm, the uh, yeah, the super, super conversation I'm enjoying.\nI like the fact that you can root this all back in Tetlock because I'm a fan.\nI think more people should know about the super forecasting methodology.\nBut one thing about Teloc is that, uh, forecasters are, his forecasters are successful or, you know, expert in one domain, and it's very rare to find someone who can accurately forecast across multiple domains.\nNow, with artificial intelligence, it seems to me, once the AI has been trained on how to do fairly good reasoning and how to, you know, kind of evaluate the sources, so it makes good decisions, maybe there's work to be done there still, uh, but it will be able to apply that broadly across multiple domains, not, not limited to a single domain.\nIs that something that you are observing?\nIs that was that one of the inspirations for starting FutureSearch?\nYeah.\nSo, you know, I was the CTO of Metaculus.\nMy co-founder, uh, Lawrence Phillips, was the head of AI there, and we were looking at these AI forecasts with the platform and trying to figure out how to make them more accurate.\nWe were looking at really hard questions.\nUh, the single most popular Metaculus question is about the arrival date of AGI.\nUm, in the in the subsequent years, um, that's become even more trendy.\nThat question was originally written, you know, in 2017 or 2018.\nYou know, the platform Metaculus started in 2015.\nIt even predates Tetlo's book Superforecasters.\nSo people have been trying to use the collective human wisdom to answer this question.\nWhat's going to happen with AI for years now?\nUm, and we were not satisfied.\nLawrence and I were looking at those human forecasts that were being aggregated, all the scoring methodology, the math behind it, the kind of forecast elicitation, the research people were doing, and we just became convinced that this could not be done without AI assistance.\nLike, the human frontier was not good enough to tell us what was going to happen in AI, and that's what Lawrence and I really wanted to know.\nYou know, we would get hung up on these details.\nSo something like, uh, when is GBD5 going to come out?\nOne of the things you might want to think about for when GBD5 is going to come out is what's going on with China?\nBecause to what extent is OpenAI racing now?\nSince we asked that question, things have changed a lot.\nI think OpenAI is much more concerned about Anthropic and Google now than it is about, you know, by do and 10 cent and Deepseek, although I don't know, I mean, it's quite complicated, but the moment you ask that question, the moment that you think the US-China relations is relevant, you just open this whole Pandora's box of complexity that no human could grapple with.\nYou're suddenly looking at, okay, there's all these export controls, like which ones are in effect, which ones are actually useful?\nIf those semiconductors are actually restricted, how much does that slow down their research?\nIf the semiconductors are slowing down their research, how much of that is known by the leadership of OpenAI?\nAre they taking that into account?\nAnd just on and on and on and on and on.\nThe idea that a human could sit down just with a pencil and paper and just kind of reason through that.\nWe, we talk to our forecasters and they would say, \"Look, I've got a tiny angle on this.\nI've got a little bit of an intuition.\"\nAnd we just kind of hope by having a thousand of them that the signal would come out.\nBut on the hardest questions, the evidence suggests that the forecasts are much less accurate.\nForecasting the future of technology is unbelievably hard, as I'm sure you know, Robert, better than most.\nUm, so we said, okay, we need more, like, we need more intelligence, and of course, the source of new intelligence is not throw more humans at the problem, it's put some AI on it, and that's where we are now.\nAnd but, but it's not just a quantitative change, uh, you know, more AI versus more throwing more humans at the problem.\nI think what you're suggesting here is there's a qualitative change as well.\nUm, when you have a machine intelligence, it's actually going to perform that function in a way that humans would not, even a collection of human minds could not, because human minds don't think that way.\nIs that your observation, and was that the inspiration for starting your company?\nAbsolutely.\nUm, it was quite clear that talking to GPD4, even in the early GPD4 days, was like talking to a whole group of people.\nAnd if the core insight from forecasting is don't just do one person, do multiple people, and also pick people who are actually good at it, GPD4 was kind of like a hive mind.\nYou know, when we were looking at it, it was kind of like talking to a thousand people.\nIt just knew absolutely everything.\nIf you could have one intelligence that has the breadth of a thousand or even a million humans, and you know that breadth of knowledge is useful in forecasting, well, then it's just obvious.\nYou got to try to see if GPD4 can forecast.\nBut again, we were not the only ones to run experiments to see how well GPD4 could predict the future when it came out.\nAnd the answer was it was terrible.\nUm, and so it became basically an engineering and a research and an AI problem to say, look, the seed, like the potential is clearly there, as, as we know from human forecasting, like it has the knowledge and the ability to do the research that could make superhuman forecasting possible with an AI, but somebody has to go build it, and that's what we're doing.\nNow, in the beginning of the show, you mentioned that there's a limited time where humans will be able to outperform AI, and even at this stage, uh, taken on an individual basis, AI is going to outperform just about anybody on most tasks.\nWe might still, one or two of us might still be able to outperform on a particular set of tasks, but broadly speaking, AI is already at a point where it can outthink us and outperform us and do so faster and more accurately, uh, than we can do in most domains.\nBut in the beginning of the show, you said that that's coming to an end, that at some point in the near future, you forecast or you believe that, uh, artificial intelligence will outperform all humans in all categories.\nIs, am I, am I restating your assumption correctly, or maybe I got it wrong?\nWell, I was making this the slightly narrower claim that I think AI unassisted will outperform human forecasters pretty soon.\nUh, forecasting is kind of like the most, you know, elite form of intelligence because to predict the future, you basically have to model the entire world.\nIf you're going to answer any forecasting question, you have to understand science and philosophy and culture and geopolitics and economics and everything else.\nSo when I say AI will outperform humans in forecasting, I'm kind of making the claim that AI will outperform humans on everything.\nBut I am talking just about basically making probabilistic statements about the future and then scoring them.\nI, I admire your constraint.\nUh, that's good because we've had many folks on the show who make very broad sweeping claims, uh, that I think are unsupportable.\nYou know, they, they're, they're kind of extrapolating from what they know in one domain, and they're saying, \"Well, that's going to happen across the board.\"\nAnd I like to remind those folks that there are many, many things that humans do that machines cannot do and will not do anytime soon.\nUm, you know, just consider the people that build your house or repair your house or do the plumbing in your house or the electricity and so forth.\nIt, there are a lot of tasks that humans are quite capable of, and frankly, we're very good at, uh, and robots and and AI are not yet able to do those things, and it may be possible in the future, but even then, it might not be economically feasible to replace human workers, uh, for a lot of those tasks.\nThat example there, which is talking to people, one of the things that a great forecaster will do in order to make a great forecast is go talk to people who are subject matter experts or insiders and see what they say.\nYou know, chat GBT can, uh, summon up an email client and email a professor of microbiology and ask them a question, but I don't think they're going to get a response.\nWhereas a human could reach out to them and have a plausible chance of getting that.\nSo, the kind of the legwork of forecasting is actually still solidly in the human camp.\nAnd it's not clear how drawing from other humans is going to be something that an AI system is going to be able to do autonomously.\nSo I very much agree, like, operating in the real world, humans have many advantages, and we're not close to all of those advantages just going to zero across every industry, maybe in a long time, unless we have some sort of super intelligent explosion.\nI think it's important for people to hear that.\nUm, we recently had a guest on who I disagreed with, uh, quite strongly, um, because he made the very fil claim that within a couple of years, um, humans won't, I think he's to summarize, probably unfairly, uh, to summarize what he was trying to say is that in a few years, machine intelligence will, will be so advanced that there'll be no work left for humans.\nAnd again, I'm probably being unfair.\nI don't know if he made that exact claim, but you do hear that quite often, right, in the in the tech trades and in Silicon Valley, this kind of euphoria, uh, about this moment in time that seems to be just around the corner, but it's always just around the corner.\nIt never seems to get quite here.\nUm, and that at that time, magically, machines will be about performance across the board in every human function, and therefore there'll be no jobs left for humans.\nAnd I think that therefore, uh, part is a huge assumption that is probably incorrect.\nLike, in other words, I don't lose any sleep about humans losing their jobs anytime soon.\nUm, I noticed that it's extremely hard to hire people right now in the United States.\nWe are very close to full employment.\nThere are a lot of unfilled jobs, and here we have the smartest minds in the country in the technology industry, and they're speculating about the fact that there'll be no jobs for humans in the near future.\nI can't get those two things to reconcile in my mind.\nCan you share your perspectives on that lively topic?\nYeah.\nUh, that's a great point, and I, I mostly agree with you, Robert.\nI think I, I'll try to make the, you know, I guess what I would call the steelman case for how that could actually happen.\nUh, but you know, one of the trueisms among the forecasting community is if you just get a forecasting question, you should just say no, like, nothing ever happens, like, almost any question you get, this is even shown in platforms, the one that I built and ran at Google and on Metaculus, like 70% of questions, like, will this happen by this date?\nFor any, this answer is no.\nUm, so I think having a kind of a status quo prior is just a very healthy epistemic disposition to have as a forecaster.\nUm, you know, as a Silicon Valley person, as a technologist, as\n\n\nSomebody working on AI and trying to make it more capable.\nUh, I am very interested in these claims that we will have an intelligence explosion or some sort of superhuman thing that can do everything.\nThis, I only see one plausible way under which that would happen, and that's in the AI 2027 scenario that I encourage your audience to check out.\nIt's a very specific path.\nStep one, AI gets very, very good at software engineering.\nNow, this is very plausible because AI is already pretty good at software engineering.\nNow, software engineering is only, I don't know, 1% of the economy.\nSo, you might say, what's the big deal?\nBut most of the development of AI at AI companies is being done by software engineers.\nSo, if software engineering becomes 10 times more productive or 10 times faster, then the next iteration of the AI model should be coming that much sooner.\nAnd there's a bit of a feedback loop there because as it gets smarter, it will be an even better software engineer.\nSo that's step one.\nStep two is having AI good at doing AI research.\nNow, a lot of AI research is software.\nYou have to write experiment code.\nYou have to train new models.\nYou have to release them, get feedback from humans.\nBut a lot of research is just research.\nIt's just thinking about like what's the best algorithm?\nLike where am I going to get the best training data?\nLike what did this experiment tell me?\nRight now AI is not very good at these things.\nBut as it gets better at software, we're expecting it to get better at research.\nOnce it gets better at research, again, there's a positive feedback loop.\nThe research is done a little bit faster, so the next generation of the model comes out a little bit sooner, which makes it a little bit faster to do the next set of research to generate the next model, etc., etc.\nOnce you have a very, very good AI researcher, then the further claim is that this can be used to train an AI that is good at things that are not just done at AI companies.\nAnd this would be doing law, doing medicine, doing accounting, maybe even designing robots to build your house for you, like in your example of maybe the last form of human labor.\nSo that's basically a story for which this could happen.\nIt requires three pretty strong assumptions that have to happen in sequence.\nSo even if this story does unfold, you know, our forecast in AI 2027 is that this, even if this happens, would be something that would be at the earliest in mid the mid 2030s.\nUh, we were kind of the dissenting view in AI 2027, which lays out the case that in fact this could happen all at once.\nThat first step of automating software and then automating AI research and then automating everything else could happen in as short as a few years.\nAs forecasters, we couldn't rule that out, like it might have a realistic chance, maybe a two or 5% chance of happening, that our median scenarios that it takes much longer.\nBut if you agree with that model in that premise, you can actually see a path towards that very, you know, grandiloquent future.\nYeah.\nAgain, Robert, I think I mostly agree with you.\nI don't see that coming anytime soon.\nUm, but it's not impossible, and I wouldn't reject it out of hand.\nRight.\nSo there, uh, I guess what I'm missing, my blind spot there is, uh, that notion of, um, the AI increasing in its ability to produce better AI, right?\nSo the ability for it to engineer a better version of itself.\nI'm well familiar with the idea that, um, artificial intelligence is writing software.\nThat's well understood right now.\nBut that second implication then, that if it can write better software, then it can and can conduct better AI research, then it's going to start to improve itself, and it is true these systems operate at very high speed, and so that result could happen, uh, much quicker than someone like me, a skeptic like me, might predict or expect.\nUh, if you don't mind, I want to circle back to a thing we talked about a moment ago because, uh, it occurred to me when you're speaking it, but I didn't want to interrupt you.\nUm, I, I live in Los Angeles.\nI deal with a lot of people in the motion picture industry and the media industry in general, and of course, as you know, there's a lot of resistance there to AI for a whole bunch of reasons.\nThere's a kind of moral outrage right now that AIs have been trained on the work of human beings, really the, you know, the literary and artistic output of of of hundreds of people, millions of people, uh, has been, uh, has been used without permission to train artificial intelligence.\nI'm going to leave that issue aside right now, um, because what I want to do is is make an observation about it.\nThe artists that I work with, uh, the people in the entertainment industry who embrace artificial intelligence, they have a slightly different perspective on that.\nI think is a meaningful distinction here to to emphasize.\nAnd that is when you work with artificial intelligence, you are engaging with the collective intelligence of humanity.\nIn other words, it, it's not a replacement for humanity.\nIt's a quick access to all the knowledge and wisdom and insight that humans have gathered over centuries.\nIt's all there.\nYou know, it's been trained on everything.\nAnd, um, and as a result, when you're working with AI, you're kind of communing with the general intelligence of humanity or the, let's say, uh, the wisdom of the elders is the way one of my friends put it.\nAnd I thought that was a nice way to think of it.\nCertainly that's a more artistic interpretation.\nWhen I say that, what do you think about that?\nIs that true?\nIs this like basically just the next iteration of collective human intelligence?\nI absolutely agree with that.\nI think that's a poignant insight, and and again, I think it's really at the heart of forecasting.\nForecasting requires an incredible depth of knowledge.\nUm, and that depth often comes through breadth.\nYou just have to read everything.\nYou know, in forecasting tournaments, there would be some question about, you know, Russia, Ukraine or the Red Sea or Israel or something.\nAnd the forecasters would just go to the library and get a book on the history of the Israel Palestine conflict and sit and read it for a couple of days, and then they would come back and say, \"Okay, here's my take on this.\"\nWe don't need to do that anymore because all of that knowledge is in the model.\nIf you wanted to talk to collective humanity, the wisdom of our elders, it's right there on chat GPT, Gemini, Claude, available for free 24 hours a day, it is a true forecasting superpower.\nAnd that's why for me, when this AI revolution started, I looked to my domain and said this is going to change.\nYou know, if you're working on, say, medicine, and maybe it's a very open question, or or the music industry or entertainment, like to what role will AI be making movies for us or recording music?\nI have no idea.\nLike, you could have different takes on that or whether it's even ethical to do so, like you said, using all that copyrighted material.\nUm, in medicine, it's far from clear how useful AI is going to be in diagnostics or therapeutics, but in forecasting, this ability to talk to collective humanity and synthesize all, basically compress everything that humanity knows about, say, China into something where you can just get all of the information at your fingertips, that's clearly a superpower, and so that meant that my field of forecasting was going to get disrupted, and that meant it was time to go do it with AI as a startup.\nSo again, I can't generalize necessarily to other domains, but I think that's a very deep insight and something that even now, a couple years into the chat GPT era, people are still learning.\nJust about every industry, certainly the media industries I know so well, are governed by this what we call the iron triangle, which is, um, you know, your budget or money, time, and quality.\nAnd within those three domains, you're going to try to optimize.\nAnd very often what happens is you're on a timeline.\nSo the budget, the timeline is set, the data is set.\nSo you're kind of working against the clock.\nYou don't have much flexibility on timeline.\nUm, and budgets are usually set.\nSo, within the constraints of budget and time, you opt for the best quality you can achieve.\nAnd certainly that that would be a fair summary of almost every media product that's out there.\nNow, what we're observing when we work with AI, uh, in the media business, what we're able to do is get results much, much faster.\nSo, if we want a lot of ideas, we can generate thousands more ideas much faster.\nSo, what's happening is we're able to extend time.\nYou get more time essentially, or you get results faster, and you can take that gain in time and invest it in better quality.\nAnd I think this is this observation is a lot of people in Los Angeles are missing this right now, like that that is a gigantic unlock for the creative process.\nThey tend to view AI as a threat that's going to replace human workers in the in the motion picture business.\nThere's no doubt there will be job loss because you'll be able to do more with fewer people.\nThat's that's a certainty, like that will be one of the promises of AI.\nUm, but in a way that helps you extend that other criteria or that other constraint, which is budget, right?\nSo fewer people means you can do more with less money.\nUm, those two things can be reinvested in quality.\nAnd so what I'm starting to see in in the entertainment business, quality is going to be more optionality and more, uh, more aesthetic choices that the director or the creative person can make a decision about.\nUm, do you see that broadly?\nI mean, I'm I'm thinking that in your line of work you're doing, you're dealing with something similar, right?\nSo anytime a an organization is asked to make a forecast or a prediction, you do run into the constraints of what you know, how much data is available, how many research reports can we digest in a short in a certain period of time.\nWe have to deliver the report in a timely way because that has there's there's time value to the information we're going to provide.\nUm, and so those become constraints that are going to dictate the quality that you can achieve within those two variables.\nTell me a little bit about how AI changes that that for you.\nQuality versus the quality of the output versus time and budget.\nYeah, I mean, I'll give you a specific example that might illuminate this.\nSo, one of the tasks that we have in deep research bench is called find original source.\nAnd what it does is it takes a claim on the web and tries to track it down to its original source.\nNow, sometimes this is easy because if you're looking at, you know, mainstream high-quality reporting, when there's a claim made, there's generally a link and you follow the link and that will generally be the primary source, but the vast majority of the web is not the reporting quality of the New York Times.\nAnd so, people make claims all the time that either don't have that link or link to something that is itself a secondary source or have the link but misstate the claim that it was in that link.\nOne thing you can do with AI to kind of mess with this time constraints or the amount of money you put in.\nImagine you take you've got three paragraphs of text that are explaining a decision or a forecast, go to every sentence and say what assumptions or claims are implied in the sentence.\nFor every one of those, track down the original source of that claim or assumption and then do this recursively.\nYou know, if you find something somewhere on the web, where did that come from?\nKeep chasing it down.\nYou can spawn a very large number of web research agents to go trace down the original source and verify basically every single fact in a piece of writing, and you can do that for pennies on the dollar.\nNow it might cost the AI system many dollars or tens of dollars to do this, but humans would cost thousands or tens of thousands of dollars to do this amount of work.\nPlus that cost is coming down as the cost of compute goes down.\nSo in two years it'll be a lot cheaper.\nCosta is coming down, uh, but the quality is going up, and the quality matters, and so it can still, I don't know, we have runs of future search that cost many tens of dollars, you know, sometimes, for example, we will do something that requires looking at every single company in the S&P 500, so we will have research agents, several of them for each company in the S&P 500 that are all researching something.\nThose costs can be measured in hundreds or thousands of dollars, again, still orders of magnitude cheaper than if humans were doing it, but the main thing is how do you productively use that intelligence and the AI and its research capab capabilities to answer a question that you care about as a human.\nYou would never say, \"Well, I'll go look and to see what the impact of tariffs is on every single company in the S&P 500 system.\"\nThat's a great question to ask.\nYou can actually do that if you have the right infrastructure and the scale that future search has.\nSo, I don't think I have a great answer to the resolution of the iron triangle other than to say it requires creativity.\nLike AI, it is the collective wisdom of humans, but it is its own different beast.\nIt is kind of an alien that that operates in different ways and surprising ways and has different trade-offs of quality and time and money than humans.\nBut if you're smart about the way to kind of break down your problem, then you can deploy these things at scale to do things that a human would never be able to do while still kind of leaving the core of it to the human and get a massive quality improvement pretty cheaply.\nSo you're you're what what I'm hearing you describe is there's still a role for a human being there in terms of directing the AI, uh, to do the useful research.\nThe the grunt work, the research could certainly be done by the machine.\nUm, Dan, let me ask you a related question because this is one of the areas where, um, human forecasting has failed, uh, kind of, uh, notoriously.\nUh, humans like to, most humans like to think that they can extrapolate from any trend.\nNow, we're not, we're not always as good as we think, and also that's a very dangerous thing to do because trends never unfold in a in a linear path, uh, the way we tend to assume.\nBut we like to think that we can say, okay, you know, if if all else holds true, uh, this particular trend, I can kind of predict the the trajectory of that trend.\nUm, but what we're notoriously bad at is answering the question, then what happens?\nIn other words, what are the second and third order consequences of of a very obvious trend that we all think we can predict the future of?\nAnd humans are terrible at this.\nI mean, we see this in politics constantly.\nWe see this in geopolitics constantly, uh, where, you know, one nation or another makes a move on the global chessboard, and then there's a series kind of cascade of consequences that occur, and you think to yourself, didn't they think about that before they started bombing or before they did the invasion or whatever, you know, egregious blunder was made.\nUm, in some cases, they don't.\n\n\nDo you know the leaders of the country do not care because they just want to deal with this thing at hand, and they're not worried about the future consequences, or they'll figure they'll deal with them later.\nUm, but in some ways, this creates so much collateral damage, so much economic hardship that I often pine for that, and I think, gee, I wish that humans were better at thinking about long-term consequences because that would probably cause us to think twice about making the drastic move that we're tempted to make.\nDo you think machine intelligence is better at forecasting and anticipating second and third-order consequences?\nUh, certainly not today.\nUh, but of course, that's the direction that we hope it will go.\nYeah, I think that that is a great point, and it's actually one of the risks of AI is whenever something looks like a time series forecast.\nThat stuff, even before language models, was firmly in the territory of machine learning.\nThere's all sorts of time series algorithms, and they're used a million times a day in many businesses, generally for things like supply chain forecasting.\nLike I need to know how many parts I'm going to have.\nI need to know how long they're going to be on the shelves.\nI need, I need to know when they're going to go out the door.\nI need to plan for, say, Christmas holiday shopping, um, and the surge in demand there and make sure I've got enough inventory and you know, enough distribution.\nAll of that stuff just looks like taking a very dense set of data that has a trend line and then extrapolating it.\nAnd you say, well, the last three Christmases we had a 40% bump.\nSo I predicted this Christmas will have a 40% bump, and that can be a very good forecast.\nAnd you look at that methodology, and it kind of gives you this false confidence that you can use that to figure out things that have these second or third-order consequences exactly as you're describing, Robert.\nUm, one of the things I was interested in at Google with the prediction market I had was trying to see if we could forecast basically the chip uh economy better.\nAnd this one was very much was time series kind of supply chain forecasting.\nThey did it the same way that most other large companies do.\nAnd they broke it into two different categories.\nThey called it inorganic and organic forecasting.\nThe thing called organic forecasting, they said, was time series, just like, well, what happened last year, predict that will happen this year, add 20% because it's growing, it's probably right.\nAnd then the thing called inorganic forecasting was everything else.\nWhile I was there, the big thing that was in the inorganic forecasting was COVID-19.\nThere was a global pandemic that destroyed all the supply chains, and nobody's chips were going into their servers, into their data centers on time.\nEvery single model fell on its head and died and became useless when that happened.\nAnd so they had to pull in all the humans and say, \"Well, okay, every model we have of our chip supply chain is wrong.\nSo, what should we actually do?\"\nAnd the ML basically got thrown out, and it was only up to the humans to kind of make those adjustments.\nI think one of the big challenges is that synthesis, like the ML was useful in some ways.\nIf you trust it too much when COVID happens, you're completely out of luck, but you can't just replace with an army of humans because most of the time it's not COVID.\nAnd so, these kind of, you know, as Taleb would say, the black swans, or as you said, kind of the second-order consequences.\nYeah.\nI don't think anybody has a good practice of adopting those into like a standardized forecasting process yet.\nI think that's still an uncert.\nWe haven't maybe we haven't quite gotten there yet, but how would you approach that?\nI mean, how would, would you have, um, would you do like a second run of your forecast once you, once you've got a scenario or a range of scenarios posited?\nCould you then apply like a black, a black swan filter to it and say, \"Okay, now give me the, now, now re-evaluate those outcomes and show me some of the possible consequences.\"\nUm, do, do you think that that's going to be something that we can possibly do?\nBecause I mean, honestly, that would be an enormous unluck because I think this is one of the big blind spots of humanity.\nAbsolutely.\nUm, I, I'm not confident.\nUm, it's definitely doable.\nI have not seen anybody do it well, but I basically believe it's possible because again, it leads into the strengths of AI.\nSo if you've got your team of human forecasters, so like, hey, am I going to get all my Nvidia chips in my data center, uh, they can't think of everything.\nThey could maybe think of four or five scenarios and work them out in detail, and then that will be the end of the hours that they have to work on the problem.\nIf you have an AI system that has the type of judgment necessary to go through those scenarios, you can consider a 100 scenarios or a thousand scenarios.\nYou could be doing in early 2020 what no human was doing, which is forecasting with the impact of a pandemic on your supply chain.\nNobody was thinking about that scenario until it happened.\nBut the funny thing about that is COVID-19, although you know it did come very quickly, uh, we had forecasts of a global pandemic, including a global pandemic that involved coronaviruses coming from the Wuhan region.\nRight?\nThis was not a surprise to anyone that was working in epidemiology.\nThey had been forecasting that for 20 years.\nUh, so it's kind of funny to me that that never came into the scenario planning for the supply chain.\nIt never folded into uh, scenario planning for national security or for public health.\nUh, I actually take that back because the good public health organizations were quite aware of it.\nThey were sometimes styided in the response.\nUm, but it's interesting right there.\nThat's an example of something that was actually well predicted and well understood, and the dynamics of it spread were well understood in advance.\nI don't think everyone believed it.\nYou know, maybe it was a small number of people who understood it, and uh, they didn't have a platform to get the information out, but it wouldn't be accurate to say that like no one knew that there would be a COVID-19 pandemic when in fact, uh, you know, a coronavirus born uh, pandemic coming from the Wuhan region was something that many, many, many people in epidemiology had been thinking about for years and discussing, uh, it was fairly well understood.\nSo here we have a different problem, which is the Cassandra problem, which is that you can be, you know, outside the temple and making absolutely accurate forecast that nobody listens to because they're politically uncomfortable or inconvenient.\nDo you run into that in your line of work?\nI mean, are there forecasts that you make or where you, you feel like, oh, 100% accurate forecast, a possibility, but it lands with a thud because it's not the answer people want to hear.\nWell, of course, timing is everything in forecasting, and yes, uh, the epidemiological community did predict that there would be global pandemics like the COVID-19 one, even as you say, possibly with a coronavirus specifically.\nUm, but there were many other hypotheses of other types of viruses, and it could have happened at any time.\nUm, one interesting detail is I learned about COVID from Metaculus, you know, years before I was the CTO there.\nUh, that was, you know, a forecasting platform was actually one of the only places on the internet where people were actively engaged in trying to figure out what was going on with this weird virus in China.\nThis was like late January, early February 2020.\nUh, it kind of seeped its way to the various parts of the internet like months before it became a mainstream thing.\nUh, but I was able to actually cancel a trip to Hawaii to go to a wedding because I saw stuff on forecasting platforms that was not in the news anywhere.\nNone of my colleagues were talking about it at work.\nLike it was just a thing that the niche forecasting community had picked up on.\nSo timing is interesting because you have to time the forecast, but also things sometimes unfold slowly over time, and there was the whole period from late December of 2019 through mid-February of 2020 where people who were quite savvy knew what was happening, and the rest of the world was totally oblivious.\nUm, yeah, I will say one more interesting case for for pandemics is uh, cyber attacks.\nThis is something where every professional in the cyber security community is worried that basically all of our hospital systems, all of our power transmission lines, like large companies are completely and utterly unready for like a very serious state-sponsored hack and have been trumpeting this for many years.\nI, my prediction is it's going to be like COVID is that they're going to turn out to be right, like that is going to happen.\nThere's going to be an absolutely devastating cyber attack maybe sometime in the next 5 to 10 years that takes a whole country or a whole hospital system or the financial system or a tech company completely offline, causes billions or maybe even trillions of dollars in damages.\nAnd all the people who are professionals in that community said, \"I've been telling you this is going to happen and telling you to prepare for this for decades,\" and nobody listened.\nAnd all the people who could have done something about it saying, \"Yeah, well, there were a lot of other things I was worried about.\nYou didn't tell me when it was going to happen, and it's very expensive to protect against that type of thing.\"\nThat's right.\nSo, I think the the moral of the story here is like forecasting alone isn't enough because even if you have the forecast, what are you going to do about it?\nThis is the challenge, right?\nYou you can actually develop highly sophisticated, accurate forecasting and um, still not be able to influence the political debate or the economic decision-m.\nUh, Dan, give me, put on your forecasting hat for a moment as we come to the end of the show here and tell me what you think the world's going to look like in the next 10 or 20 years based on what you're seeing this uh, convergence of technologies and the rapid iteration and improvement and particularly in machine intelligence and its ability to do forecasting.\nWhat do you think the world's going to be like?\nWill we have much better uh, perspectives on the future as a society?\nWill this improve our ability to collective decision make or or not?\nI think it will.\nUm, obviously I'm biased because I'm orienting my career around it.\nUm, and you know, doing it as a a startup, not as a think tank for a research lab because I think this is a billion-dollar opportunity.\nSo, of course, I'm biased.\nYou know, the forecasters that we have at FutureSearch might give you a more calibrated view than me as the CEO.\nUm, but yes, I think forecasting is unbelievably valuable, and it has been proven out in the literature, and you absolutely can use AI to make it much better, faster, cheaper, ask all the questions you never wanted.\nYou, you never, never had humans that you could answer, ask to answer those questions before.\nBut it takes time.\nSo if you're asking me about the 2030s or 2040s, I would predict quite strongly that we'll look back to this time and say, \"Wow, we were living in the dark ages.\"\nLike we knew how to predict things, and we weren't doing it at all.\nPeople were just using their gut to make all the decisions in government and in business and academia.\nNo one was forecasting like which scientific paths would work better.\nNobody was forecasting, you know, cyber attacks and pandemics.\nPeople weren't forecasting the outcomes of mergers.\nThey weren't forecasting the outcomes of, you know, bombing Iran or whatever is going on right now with Israel, Iran.\nEveryone was just using their gut and just guessing.\nAnd all of society was run that way.\nAnd once we have better technology to do this, we'll never look back.\nIn the same way that the scientific method has completely changed something like medicine where medicine was just kind of like doctors just did whatever they felt like.\nThey didn't really have evidence behind anything they were doing.\nWe lived that way for hundreds of years.\nAnd very recently, doctors now do stuff that is actually supported by the science.\nThe science of forecasting is turning online as well.\nI think heads of state, CEOs, once that technology becomes available, they will use it.\nAnd I kind of understand why they don't use it today because it's not very accessible.\nBut I think we will look back on this as a total dark age for humanity where we were just blundering towards the future with absolutely no plan, no foresight, no real idea what was going on.\nAnd we will think it was like a total crime that we were operating this way.\nLet's hope that the humans can evolve the ability to listen to the forecast and make intelligent decisions uh, based on that information.\nYeah.\nWell, Dan, it's been a pleasure having you on the show today.\nI've enjoyed this conversation immensely.\nWhere can people find out more information about you and about FutureSearch.ai?\nYeah.\nWell, it's at FutureSearch.ai.\nUm, yeah, thank you, Robert, for having me.\nIt's been a great conversation.\nYeah, I would encourage people if they want to see what's going on with the future of AI itself and and how AI can help you understand that, FutureSearch.ai.\nWe've got evals, we've got reports, um, and software coming out soon.\nCool.\nThanks for being on the show.\nAnd, uh, folks who are listening, you've been listening to Dan Schwarz, the CEO and co-founder of FutureSearch.ai.\nI'm Rob Tercek from The Futurists.\nAnd every week, Brett King and I will bring you another person who's thinking about and shaping the future.\nUm, we enjoy this process so much, and we're also getting such a kick out of uh, the messages and the comments that we get back from people.\nUm, thank you.\nKeep sending that information to us.\nUh, I want to mention one thing that's happening uh, in September.\nI'm thrilled to tell you that we'll be doing a live event in Dubai.\nUh, Brett has been working very hard to organize this event with the sponsorship of Mastercard.\nWe will be bringing together some of the world's best uh, futurist forecasters and future thinkers for a live event, a two-day event in Dubai at the famous Jumeirah Beach Hotel there.\nVery fabulous place.\nIf you're interested, you can learn more about that at futuristevent.com.\nAnd I'm looking forward to seeing you there in person if you can make it.\nAnd if you can't, well, I'll see you in the future on the Futurist podcast.\nThanks, Dan.\nThanks for joining us.\nThank you, Robert.\n",
  "dumpedAt": "2025-07-21T18:43:26.477Z"
}