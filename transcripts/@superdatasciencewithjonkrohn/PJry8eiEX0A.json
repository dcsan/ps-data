{
  "episodeId": "PJry8eiEX0A",
  "channelSlug": "@superdatasciencewithjonkrohn",
  "title": "901: Automating Legal Work with Data-Centric ML (feat. Lilith Bat-Leah)",
  "publishedAt": "2025-07-01T11:00:48.000Z",
  "rawLines": [
    {
      "lang": "en",
      "text": "Tell us why you prefer going in ranges,",
      "offset": 0.16,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "why you prefer providing information in",
      "offset": 2.639,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "ranges as opposed to point estimates.\n I",
      "offset": 5.04,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "mean, we are dealing with uncertainties,",
      "offset": 7.839,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "right? You shouldn't assume that a point",
      "offset": 9.84,
      "duration": 4.879
    },
    {
      "lang": "en",
      "text": "estimate is truly representative of the",
      "offset": 11.519,
      "duration": 4.481
    },
    {
      "lang": "en",
      "text": "parameter that you're trying to",
      "offset": 14.719,
      "duration": 3.441
    },
    {
      "lang": "en",
      "text": "estimate. A point estimate without",
      "offset": 16,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "sample size, without confidence",
      "offset": 18.16,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "intervals, is basically lying with",
      "offset": 19.92,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "statistics. You have no idea what what",
      "offset": 21.76,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "the actual claim is there. If you don't",
      "offset": 23.84,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "understand statistics, I don't think",
      "offset": 26.56,
      "duration": 4.799
    },
    {
      "lang": "en",
      "text": "you're able to properly evaluate the",
      "offset": 28.72,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "performance of the models that you're",
      "offset": 31.359,
      "duration": 4.001
    },
    {
      "lang": "en",
      "text": "building. I think especially in this era",
      "offset": 33.04,
      "duration": 5.679
    },
    {
      "lang": "en",
      "text": "of blackbox models, it's so important to",
      "offset": 35.36,
      "duration": 6.4
    },
    {
      "lang": "en",
      "text": "be able to to actually evaluate the",
      "offset": 38.719,
      "duration": 6.311
    },
    {
      "lang": "en",
      "text": "performance of them.",
      "offset": 41.76,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "[Music]",
      "offset": 45.03,
      "duration": 4.09
    },
    {
      "lang": "en",
      "text": "Lilith, welcome to the Super Data",
      "offset": 46.96,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "Science podcast. I'm delighted to",
      "offset": 49.12,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "finally get you on the show. I was",
      "offset": 50.8,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "talking about it with you for a while",
      "offset": 52.64,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "and now it's finally happening. Where",
      "offset": 55.84,
      "duration": 3.359
    },
    {
      "lang": "en",
      "text": "are you calling in from today?\n Thank you",
      "offset": 57.28,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "so much for having me. I am in New York",
      "offset": 59.199,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "City.\n Likewise. Exactly. Both in",
      "offset": 61.52,
      "duration": 6.4
    },
    {
      "lang": "en",
      "text": "Manhattan. Uh though recording remotely",
      "offset": 65.199,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "anyway,",
      "offset": 67.92,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "it does make things easier. Uh there's a",
      "offset": 69.52,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "lot less setup involved if I just do",
      "offset": 71.6,
      "duration": 2.879
    },
    {
      "lang": "en",
      "text": "remote recording sessions. For people",
      "offset": 73.2,
      "duration": 2.88
    },
    {
      "lang": "en",
      "text": "who are wondering at home why I",
      "offset": 74.479,
      "duration": 3.761
    },
    {
      "lang": "en",
      "text": "sometimes do New York episodes uh",
      "offset": 76.08,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "remotely with guests. Uh though I guess",
      "offset": 78.24,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "also I could be traveling. I don't know",
      "offset": 80.56,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "it just makes the logistics easier uh to",
      "offset": 81.92,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "do things remote and yeah so we actually",
      "offset": 83.92,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "met after the open data science",
      "offset": 86.88,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "conference east in Boston a year ago.",
      "offset": 89.2,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "Was it a year ago or two years ago? Just",
      "offset": 92.32,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "a year.\n I think it was just a year ago.",
      "offset": 93.84,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "Just a year. And so we were on the train",
      "offset": 95.92,
      "duration": 7.28
    },
    {
      "lang": "en",
      "text": "back. So the uh the Excella the uh",
      "offset": 98.4,
      "duration": 7.52
    },
    {
      "lang": "en",
      "text": "supposed express train that is available",
      "offset": 103.2,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "only in this kind of northeast corridor",
      "offset": 105.92,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "of the US and it isn't that fast. to",
      "offset": 107.84,
      "duration": 4.239
    },
    {
      "lang": "en",
      "text": "people who have been on express trains",
      "offset": 110.56,
      "duration": 4.239
    },
    {
      "lang": "en",
      "text": "in Europe or Asia,",
      "offset": 112.079,
      "duration": 5.281
    },
    {
      "lang": "en",
      "text": "you'll be like, &quot;This isn't a very fast",
      "offset": 114.799,
      "duration": 5.201
    },
    {
      "lang": "en",
      "text": "train.&quot; Um, but it is a really nice ride",
      "offset": 117.36,
      "duration": 5.84
    },
    {
      "lang": "en",
      "text": "from New York to Boston or vice versa.",
      "offset": 120,
      "duration": 6.32
    },
    {
      "lang": "en",
      "text": "And um, yeah, the only kind of nice",
      "offset": 123.2,
      "duration": 5.919
    },
    {
      "lang": "en",
      "text": "train ride uh that you can that you can",
      "offset": 126.32,
      "duration": 4.639
    },
    {
      "lang": "en",
      "text": "have in North or at least in the US.",
      "offset": 129.119,
      "duration": 2.961
    },
    {
      "lang": "en",
      "text": "Canada does actually have some nice",
      "offset": 130.959,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "trains, too. And uh I was sitting you",
      "offset": 132.08,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "know trying to mind my own business but",
      "offset": 134.959,
      "duration": 6.801
    },
    {
      "lang": "en",
      "text": "behind me you were sitting and you were",
      "offset": 137.36,
      "duration": 7.2
    },
    {
      "lang": "en",
      "text": "going into uh a lot of technical detail",
      "offset": 141.76,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "and explaining technical data science",
      "offset": 144.56,
      "duration": 6.48
    },
    {
      "lang": "en",
      "text": "concepts very clearly succinctly in a",
      "offset": 147.28,
      "duration": 6.08
    },
    {
      "lang": "en",
      "text": "really enjoyable way to whomever you",
      "offset": 151.04,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "were sitting with. And after like an",
      "offset": 153.36,
      "duration": 4.239
    },
    {
      "lang": "en",
      "text": "hour of listening to that I popped",
      "offset": 155.84,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "around in my seat because I had to find",
      "offset": 157.599,
      "duration": 3.761
    },
    {
      "lang": "en",
      "text": "out who this person was and it was you.",
      "offset": 159.12,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "Thank you. Yeah. And you can give uh all",
      "offset": 161.36,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "of that credit to the judges and",
      "offset": 163.36,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "attorneys that I've",
      "offset": 165.92,
      "duration": 5.84
    },
    {
      "lang": "en",
      "text": "technical concept over the years.\n Yes.",
      "offset": 168.72,
      "duration": 6.48
    },
    {
      "lang": "en",
      "text": "And so we are going to have a a legal",
      "offset": 171.76,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "episode here. Um but I think this will",
      "offset": 175.2,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "be interesting for anyone because uh you",
      "offset": 177.12,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "know we I think it's great to dig into",
      "offset": 179.519,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "different domains and whether you know",
      "offset": 181.68,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "you do work in legal or legal tech",
      "offset": 184.959,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "yourself. There's lots of concepts that",
      "offset": 187.12,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "we'll be describing that could be",
      "offset": 190.159,
      "duration": 3.521
    },
    {
      "lang": "en",
      "text": "transferable, you know, so you might",
      "offset": 191.76,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "think of an analogous kind of thing that",
      "offset": 193.68,
      "duration": 5.279
    },
    {
      "lang": "en",
      "text": "you could be doing in your own industry.",
      "offset": 195.92,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "Um, and so yeah, so let's start off with",
      "offset": 198.959,
      "duration": 5.041
    },
    {
      "lang": "en",
      "text": "that. So you are the senior director of",
      "offset": 201.12,
      "duration": 6.32
    },
    {
      "lang": "en",
      "text": "the AI labs for a company called Epic,",
      "offset": 204,
      "duration": 4.959
    },
    {
      "lang": "en",
      "text": "EPIQ,",
      "offset": 207.44,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "which is a legal which is a leading",
      "offset": 208.959,
      "duration": 3.761
    },
    {
      "lang": "en",
      "text": "legal tech company. They're a pretty big",
      "offset": 210.72,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "one. Uh, there's thousands of employees,",
      "offset": 212.72,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "I think. I I looked into this. Yeah, I",
      "offset": 215.68,
      "duration": 4.639
    },
    {
      "lang": "en",
      "text": "think we're over 6,000 right now,\n right?",
      "offset": 217.84,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "Over 6,000 employees. So, it's a big",
      "offset": 220.319,
      "duration": 4.241
    },
    {
      "lang": "en",
      "text": "legal tech company. Earlier this year,",
      "offset": 222,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "Epic launched something called the Epic",
      "offset": 224.56,
      "duration": 5.759
    },
    {
      "lang": "en",
      "text": "AI Discovery Assistant, which claims to",
      "offset": 227.28,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "automate more than 80% of traditional",
      "offset": 230.319,
      "duration": 5.761
    },
    {
      "lang": "en",
      "text": "eiscocovery processes, and completes",
      "offset": 233.04,
      "duration": 5.199
    },
    {
      "lang": "en",
      "text": "reviews up to 90% faster than something",
      "offset": 236.08,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "called TAR, technology assisted review,",
      "offset": 238.239,
      "duration": 5.601
    },
    {
      "lang": "en",
      "text": "or linear review, which I'm guessing is",
      "offset": 241.04,
      "duration": 5.279
    },
    {
      "lang": "en",
      "text": "like a human reading every word on a",
      "offset": 243.84,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "page linearly.",
      "offset": 246.319,
      "duration": 5.521
    },
    {
      "lang": "en",
      "text": "So, uh, we've got a bunch of legal tech",
      "offset": 248.56,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "jargon here now that, uh, I don't I'm",
      "offset": 251.84,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "not really familiar with. So, tell us",
      "offset": 254.56,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "about linear reviews, tar, and",
      "offset": 255.68,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "eiscocovery. Tell us about those firms",
      "offset": 258.32,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "about those terms, and then we can get",
      "offset": 260.16,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "into how, uh, AI can make life easier.",
      "offset": 262,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "Yeah, and I'll qualify one of those",
      "offset": 264.72,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "claims a little bit. It's it's um,",
      "offset": 267.12,
      "duration": 6.48
    },
    {
      "lang": "en",
      "text": "better than traditional TAR. Uh so I",
      "offset": 269.52,
      "duration": 6.399
    },
    {
      "lang": "en",
      "text": "would say that the the software that we",
      "offset": 273.6,
      "duration": 5.92
    },
    {
      "lang": "en",
      "text": "offer does support TAR workflows. Um and",
      "offset": 275.919,
      "duration": 5.441
    },
    {
      "lang": "en",
      "text": "to actually describe what that is, it",
      "offset": 279.52,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "stands for technology assisted review",
      "offset": 281.36,
      "duration": 5.92
    },
    {
      "lang": "en",
      "text": "and it basically um basically describes",
      "offset": 283.84,
      "duration": 5.84
    },
    {
      "lang": "en",
      "text": "a process whereby you use machine",
      "offset": 287.28,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "learning to",
      "offset": 289.68,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "um classify documents as relevant to a",
      "offset": 291.6,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "litigation or not relevant to a",
      "offset": 294.24,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "litigation.\n And a litigation is just",
      "offset": 295.84,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "somebody suing someone else, I guess.",
      "offset": 298.56,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "Yeah. Yeah. So, the way I explain",
      "offset": 300.4,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "discovery for for people outside of the",
      "offset": 302.479,
      "duration": 4.961
    },
    {
      "lang": "en",
      "text": "legal industry is uh basically anytime",
      "offset": 304.8,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "two companies sue each other, they have",
      "offset": 307.44,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "to exchange anything and everything that",
      "offset": 309.68,
      "duration": 4.799
    },
    {
      "lang": "en",
      "text": "might be considered evidence in the",
      "offset": 312,
      "duration": 6.16
    },
    {
      "lang": "en",
      "text": "case. Um, so what this ends up looking",
      "offset": 314.479,
      "duration": 6.56
    },
    {
      "lang": "en",
      "text": "like is is piles and piles, maybe",
      "offset": 318.16,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "hundreds of thousands, even millions of",
      "offset": 321.039,
      "duration": 5.761
    },
    {
      "lang": "en",
      "text": "documents, emails, word docs, excels,",
      "offset": 323.84,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "tweets, text messages, anything and",
      "offset": 326.8,
      "duration": 4.959
    },
    {
      "lang": "en",
      "text": "everything. tons of unstructured data",
      "offset": 329.44,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "that might be relevant to the litigation",
      "offset": 331.759,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "and then attorneys have to go through",
      "offset": 334.88,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "all of that and determine what is going",
      "offset": 336.479,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "to be produced to the other side, what",
      "offset": 338.88,
      "duration": 3.759
    },
    {
      "lang": "en",
      "text": "they're legally obligated to produce to",
      "offset": 340.88,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "the other side because it might be",
      "offset": 342.639,
      "duration": 4.241
    },
    {
      "lang": "en",
      "text": "evidence. Um, so that is eiscocovery in",
      "offset": 344.4,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "a nutshell.\n What what makes it",
      "offset": 346.88,
      "duration": 3.599
    },
    {
      "lang": "en",
      "text": "eiscocovery?",
      "offset": 348.96,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "So way back when and you might be",
      "offset": 350.479,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "familiar with those TV shows where the",
      "offset": 352.4,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "lawyers have the boxes of documents.",
      "offset": 354.479,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "That's traditional discovery.",
      "offset": 356.96,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "But now all of the business records all",
      "offset": 359.759,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "the data as it was maintained in the",
      "offset": 362.32,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "ordinary course of business is",
      "offset": 364.08,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "electronic. So um in the early as around",
      "offset": 366,
      "duration": 7.36
    },
    {
      "lang": "en",
      "text": "then I think uh we started calling it",
      "offset": 370.08,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "eiscocovery rather than than discovery",
      "offset": 373.36,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "but now pretty much all of document",
      "offset": 375.84,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "discovery is is eiscocovery for the most",
      "offset": 378.96,
      "duration": 6.799
    },
    {
      "lang": "en",
      "text": "part exceptions where uh some you know",
      "offset": 381.44,
      "duration": 6.16
    },
    {
      "lang": "en",
      "text": "asbestos case where you have to go back",
      "offset": 385.759,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "to the to the paper documents and scan",
      "offset": 387.6,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "them in and then and then review them.",
      "offset": 389.919,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "This kind of reminds me of uh yeah,",
      "offset": 393.28,
      "duration": 6.639
    },
    {
      "lang": "en",
      "text": "watching those old TV shows and uh and",
      "offset": 395.919,
      "duration": 5.84
    },
    {
      "lang": "en",
      "text": "you'd see like it seems like it's a",
      "offset": 399.919,
      "duration": 3.761
    },
    {
      "lang": "en",
      "text": "deliberate strategy to flood your",
      "offset": 401.759,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "opponent with like as many documents as",
      "offset": 403.68,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "possible to bog them down and increase",
      "offset": 405.68,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "their fees, that kind of thing.\n Yeah.",
      "offset": 407.52,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "Yeah. So, so that's considered a bad",
      "offset": 410,
      "duration": 5.84
    },
    {
      "lang": "en",
      "text": "faith approach these days if if you try",
      "offset": 412.8,
      "duration": 6.08
    },
    {
      "lang": "en",
      "text": "to just overwhelm your opposing council",
      "offset": 415.84,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "with with documents that aren't actually",
      "offset": 418.88,
      "duration": 5.84
    },
    {
      "lang": "en",
      "text": "responsive to their their RFPs. Um, and",
      "offset": 421.28,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "that's where precision matters a lot if",
      "offset": 424.72,
      "duration": 3.599
    },
    {
      "lang": "en",
      "text": "you're using a certain version of",
      "offset": 426.72,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "technology assisted review. So, yeah. So",
      "offset": 428.319,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "now that we have all these great machine",
      "offset": 430.639,
      "duration": 4.241
    },
    {
      "lang": "en",
      "text": "learning tools for eiscocovery,",
      "offset": 432,
      "duration": 5.84
    },
    {
      "lang": "en",
      "text": "uh it's much easier for opposing council",
      "offset": 434.88,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "to uncover the needles in a hay stack",
      "offset": 437.84,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "that they might be looking for and and",
      "offset": 439.68,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "pinpoint the evidence that really",
      "offset": 441.919,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "matters to them.\n Nice. Very cool. So now",
      "offset": 443.44,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "I think we have an understanding of kind",
      "offset": 445.599,
      "duration": 4.641
    },
    {
      "lang": "en",
      "text": "of the territory. So tell us about Epic",
      "offset": 446.96,
      "duration": 7.04
    },
    {
      "lang": "en",
      "text": "AI's discovery or Epic's AI discovery",
      "offset": 450.24,
      "duration": 7.679
    },
    {
      "lang": "en",
      "text": "assistant. Tell us uh about Yeah. how",
      "offset": 454,
      "duration": 6.479
    },
    {
      "lang": "en",
      "text": "that's different and how it accelerates",
      "offset": 457.919,
      "duration": 4.641
    },
    {
      "lang": "en",
      "text": "again this uh yeah the the claim that",
      "offset": 460.479,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "you qualified appropriately. Uh but that",
      "offset": 462.56,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "we get this like 80%",
      "offset": 465.759,
      "duration": 5.201
    },
    {
      "lang": "en",
      "text": "um you know it automates 80% of uh",
      "offset": 468,
      "duration": 5.759
    },
    {
      "lang": "en",
      "text": "discovery and uh completes reviews up to",
      "offset": 470.96,
      "duration": 7.04
    },
    {
      "lang": "en",
      "text": "90% faster than uh yeah than than kind",
      "offset": 473.759,
      "duration": 6.641
    },
    {
      "lang": "en",
      "text": "of linear review other approaches. So",
      "offset": 478,
      "duration": 6.56
    },
    {
      "lang": "en",
      "text": "traditional TAR technology um basically",
      "offset": 480.4,
      "duration": 6.4
    },
    {
      "lang": "en",
      "text": "it's a it's a classifier with active",
      "offset": 484.56,
      "duration": 5.039
    },
    {
      "lang": "en",
      "text": "learning and depending on the prevalence",
      "offset": 486.8,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "of documents that you actually care",
      "offset": 489.599,
      "duration": 4.641
    },
    {
      "lang": "en",
      "text": "about in your overall population uh",
      "offset": 491.52,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "you'll you'll use one of two different",
      "offset": 494.24,
      "duration": 4.799
    },
    {
      "lang": "en",
      "text": "active learning workflows. Um and before",
      "offset": 496,
      "duration": 6.479
    },
    {
      "lang": "en",
      "text": "I keep going can I assume that your",
      "offset": 499.039,
      "duration": 5.201
    },
    {
      "lang": "en",
      "text": "audience will be familiar with active",
      "offset": 502.479,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "learning?\n I would love to hear a bit",
      "offset": 504.24,
      "duration": 4.799
    },
    {
      "lang": "en",
      "text": "more about it.\n Excellent. Um so active",
      "offset": 506.16,
      "duration": 5.92
    },
    {
      "lang": "en",
      "text": "learning is just a way to select data in",
      "offset": 509.039,
      "duration": 7.201
    },
    {
      "lang": "en",
      "text": "a more efficient way for for um for",
      "offset": 512.08,
      "duration": 6.72
    },
    {
      "lang": "en",
      "text": "training your classifier. And there are",
      "offset": 516.24,
      "duration": 4.719
    },
    {
      "lang": "en",
      "text": "generally two",
      "offset": 518.8,
      "duration": 7.039
    },
    {
      "lang": "en",
      "text": "popular approaches to it in in uh",
      "offset": 520.959,
      "duration": 7.601
    },
    {
      "lang": "en",
      "text": "eiscocovery. So if you have really low",
      "offset": 525.839,
      "duration": 4.641
    },
    {
      "lang": "en",
      "text": "prevalence, you're probably better off",
      "offset": 528.56,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "using relevance feedback. So, you're",
      "offset": 530.48,
      "duration": 6.72
    },
    {
      "lang": "en",
      "text": "going to uh have human annotators label",
      "offset": 533.44,
      "duration": 7.12
    },
    {
      "lang": "en",
      "text": "the documents that are already most",
      "offset": 537.2,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "likely to be considered relevant by the",
      "offset": 540.56,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "the model. So, you're going to um use",
      "offset": 542.8,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "that and then you're going to",
      "offset": 545.2,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "iteratively retrain the model several",
      "offset": 546.32,
      "duration": 5.199
    },
    {
      "lang": "en",
      "text": "times in order to improve performance.",
      "offset": 549.12,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "And that's in a low prevalence",
      "offset": 551.519,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "situation. If you have more balanced",
      "offset": 553.279,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "classes, um that is an a more equal",
      "offset": 555.519,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "proportion of relevant and irrelevant",
      "offset": 559.279,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "documents, uh then you're going to want",
      "offset": 561.279,
      "duration": 5.361
    },
    {
      "lang": "en",
      "text": "to use uncertainty sampling where you're",
      "offset": 564.399,
      "duration": 4.961
    },
    {
      "lang": "en",
      "text": "you're looking at the entropy of each",
      "offset": 566.64,
      "duration": 7.04
    },
    {
      "lang": "en",
      "text": "data point and um and having human",
      "offset": 569.36,
      "duration": 6.479
    },
    {
      "lang": "en",
      "text": "annotators label the documents that the",
      "offset": 573.68,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "model is most unsure about uh in order",
      "offset": 575.839,
      "duration": 4.881
    },
    {
      "lang": "en",
      "text": "to improve performance. So those are",
      "offset": 578.72,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "those are the two flavors of active",
      "offset": 580.72,
      "duration": 2.96
    },
    {
      "lang": "en",
      "text": "learning that you tend to use in the",
      "offset": 582.24,
      "duration": 3.599
    },
    {
      "lang": "en",
      "text": "space.\n Very cool. That's exactly the",
      "offset": 583.68,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "kind of clear technical explanation uh",
      "offset": 585.839,
      "duration": 4.801
    },
    {
      "lang": "en",
      "text": "that I heard on that train ride. Uh",
      "offset": 588.72,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "fantastic. Thanks, Lilith. Um yeah, so",
      "offset": 590.64,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "we kind of took a little bit of an",
      "offset": 593.68,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "excursion to talk about active learning.",
      "offset": 595.2,
      "duration": 4.639
    },
    {
      "lang": "en",
      "text": "Uh but yeah, you were filling us in on",
      "offset": 597.6,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "uh Epics's AI discovery assistant. Yeah,",
      "offset": 599.839,
      "duration": 4.881
    },
    {
      "lang": "en",
      "text": "and I really should I should be I am",
      "offset": 602.56,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "very excited to talk about Epic tools.",
      "offset": 604.72,
      "duration": 4.559
    },
    {
      "lang": "en",
      "text": "But again with with traditional tar it's",
      "offset": 606.72,
      "duration": 4.239
    },
    {
      "lang": "en",
      "text": "basically traditional long text",
      "offset": 609.279,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "classification. Anything from a random",
      "offset": 610.959,
      "duration": 6.401
    },
    {
      "lang": "en",
      "text": "forest algorithm to an SPM to uh",
      "offset": 613.839,
      "duration": 6.321
    },
    {
      "lang": "en",
      "text": "logistic regression is pretty popular.",
      "offset": 617.36,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "Um you can use any of these these",
      "offset": 620.16,
      "duration": 5.119
    },
    {
      "lang": "en",
      "text": "algorithms or some ensemble learning and",
      "offset": 622.16,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "and arrive at your classifications along",
      "offset": 625.279,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "with that active learning component of",
      "offset": 627.68,
      "duration": 5.839
    },
    {
      "lang": "en",
      "text": "things. Um, what's very cool about Epic",
      "offset": 630.079,
      "duration": 6.561
    },
    {
      "lang": "en",
      "text": "AI Discovery Assistant is that it uses",
      "offset": 633.519,
      "duration": 6.081
    },
    {
      "lang": "en",
      "text": "more traditional methods for for long",
      "offset": 636.64,
      "duration": 5.199
    },
    {
      "lang": "en",
      "text": "text classification, but it also",
      "offset": 639.6,
      "duration": 6.479
    },
    {
      "lang": "en",
      "text": "leverages LLMs. Both your human language",
      "offset": 641.839,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "instructions",
      "offset": 646.079,
      "duration": 4.481
    },
    {
      "lang": "en",
      "text": "uh and your labeled examples are going",
      "offset": 647.839,
      "duration": 5.921
    },
    {
      "lang": "en",
      "text": "to go into training the best classifier",
      "offset": 650.56,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "possible. So, um, so it takes input from",
      "offset": 653.76,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "both example data and from natural",
      "offset": 656,
      "duration": 5.279
    },
    {
      "lang": "en",
      "text": "language instruction. So you need a",
      "offset": 658.88,
      "duration": 5.199
    },
    {
      "lang": "en",
      "text": "classifier for basically every case, a",
      "offset": 661.279,
      "duration": 5.281
    },
    {
      "lang": "en",
      "text": "separate classifier,\n sometimes many many",
      "offset": 664.079,
      "duration": 4.481
    },
    {
      "lang": "en",
      "text": "classifiers in one case. It depends on",
      "offset": 666.56,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "how many different things they they care",
      "offset": 668.56,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "about classifying. So generally you'll",
      "offset": 670.56,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "always have a responsiveness assuming",
      "offset": 672.959,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "that it's in preparation for a",
      "offset": 674.959,
      "duration": 4.641
    },
    {
      "lang": "en",
      "text": "production to opposing. You'll always",
      "offset": 677.36,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "have what's called a responsiveness",
      "offset": 679.6,
      "duration": 4.239
    },
    {
      "lang": "en",
      "text": "model. Basically a relevance model. Is",
      "offset": 681.6,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "it relevant to any of the issues in the",
      "offset": 683.839,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "case? Um but then you might also have",
      "offset": 685.68,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "classifiers for things like privilege uh",
      "offset": 688.079,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "whether the document is protected by",
      "offset": 690.8,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "attorney client privilege and therefore",
      "offset": 693.279,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "um it's not mandatory to disclose it. Uh",
      "offset": 695.76,
      "duration": 6.48
    },
    {
      "lang": "en",
      "text": "and then confidentiality potentially and",
      "offset": 699.279,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "then all sorts of issues that the",
      "offset": 702.24,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "attorneys working on the case might care",
      "offset": 704.079,
      "duration": 3.361
    },
    {
      "lang": "en",
      "text": "about.",
      "offset": 706.24,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "So, does this mean that big law firms",
      "offset": 707.44,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "typically have data scientists on hand",
      "offset": 709.68,
      "duration": 6.399
    },
    {
      "lang": "en",
      "text": "or do they rely completely on tools like",
      "offset": 712.32,
      "duration": 7.519
    },
    {
      "lang": "en",
      "text": "Epic AI Discovery Assistant to allow",
      "offset": 716.079,
      "duration": 5.681
    },
    {
      "lang": "en",
      "text": "this kind of these classifiers to be",
      "offset": 719.839,
      "duration": 4.481
    },
    {
      "lang": "en",
      "text": "trained in a in a fully automated way",
      "offset": 721.76,
      "duration": 5.759
    },
    {
      "lang": "en",
      "text": "without some kind of you know technical",
      "offset": 724.32,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "expertise like a data scientist being",
      "offset": 727.519,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "involved.\n Yeah, they mostly rely on",
      "offset": 729.12,
      "duration": 6.399
    },
    {
      "lang": "en",
      "text": "these tools. So very few law firms have",
      "offset": 731.519,
      "duration": 7.361
    },
    {
      "lang": "en",
      "text": "maybe that's changing but um I would say",
      "offset": 735.519,
      "duration": 5.361
    },
    {
      "lang": "en",
      "text": "very few law firms have data scientists",
      "offset": 738.88,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "who are involved in the discovery",
      "offset": 740.88,
      "duration": 6.639
    },
    {
      "lang": "en",
      "text": "component of of um of the practice. So",
      "offset": 742.72,
      "duration": 7.04
    },
    {
      "lang": "en",
      "text": "yeah so they do rely on these tools.",
      "offset": 747.519,
      "duration": 5.841
    },
    {
      "lang": "en",
      "text": "With that said, it it you do need to",
      "offset": 749.76,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "have some expertise, some domain",
      "offset": 753.36,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "expertise and some familiarity with",
      "offset": 755.2,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "basic evaluation metrics in order to",
      "offset": 757.519,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "make sure that you're using the tool in",
      "offset": 760.72,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "a defensible manner. Um, and we are",
      "offset": 762.639,
      "duration": 5.681
    },
    {
      "lang": "en",
      "text": "trying to build in as much of that as",
      "offset": 765.92,
      "duration": 4.479
    },
    {
      "lang": "en",
      "text": "possible. Build in the expertise, build",
      "offset": 768.32,
      "duration": 4.639
    },
    {
      "lang": "en",
      "text": "in all the all the metrics and and",
      "offset": 770.399,
      "duration": 5.521
    },
    {
      "lang": "en",
      "text": "intuitive explanations of them. Um, but",
      "offset": 772.959,
      "duration": 4.961
    },
    {
      "lang": "en",
      "text": "I would say at this point it's still",
      "offset": 775.92,
      "duration": 5.359
    },
    {
      "lang": "en",
      "text": "ideal to have that domain expertise um,",
      "offset": 777.92,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "and a little bit of familiarity with",
      "offset": 781.279,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "evaluation metrics.\n Gotcha. So perhaps",
      "offset": 783.04,
      "duration": 7.359
    },
    {
      "lang": "en",
      "text": "uh, a law firm might work with Epic not",
      "offset": 786.399,
      "duration": 6.721
    },
    {
      "lang": "en",
      "text": "only to get access to a tool but also to",
      "offset": 790.399,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "leverage expertise from people like",
      "offset": 793.12,
      "duration": 4.719
    },
    {
      "lang": "en",
      "text": "yourself.\n Exactly. Yeah. Yeah. We have",
      "offset": 794.639,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "an amazing team that helps clients with",
      "offset": 797.839,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "uh with specific matters and helps them",
      "offset": 800.639,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "achieve whatever it is they're looking",
      "offset": 802.959,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "to achieve for that particular case. And",
      "offset": 804.32,
      "duration": 6.16
    },
    {
      "lang": "en",
      "text": "that can entail uh building dozens of",
      "offset": 807.519,
      "duration": 6.641
    },
    {
      "lang": "en",
      "text": "models for for one single case.",
      "offset": 810.48,
      "duration": 6.4
    },
    {
      "lang": "en",
      "text": "When the stakes are so high as as you",
      "offset": 814.16,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "know big law firms when you're talking",
      "offset": 816.88,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "about hundreds of thousands or millions",
      "offset": 818.48,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "of documents obviously these are going",
      "offset": 819.92,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "to end up being very expensive cases.",
      "offset": 822,
      "duration": 5.519
    },
    {
      "lang": "en",
      "text": "you know, you're talking I at least",
      "offset": 824,
      "duration": 5.92
    },
    {
      "lang": "en",
      "text": "millions of dollars and there's probably",
      "offset": 827.519,
      "duration": 4.641
    },
    {
      "lang": "en",
      "text": "very often in these kinds of litigation",
      "offset": 829.92,
      "duration": 4.719
    },
    {
      "lang": "en",
      "text": "situations tens hundreds of millions of",
      "offset": 832.16,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "dollars, billions of dollars on the line",
      "offset": 834.639,
      "duration": 6.161
    },
    {
      "lang": "en",
      "text": "one way or another um for the uh the",
      "offset": 836.72,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "defendant or the plaintiff. Does that is",
      "offset": 840.8,
      "duration": 2.56
    },
    {
      "lang": "en",
      "text": "that does that happen in litigation? Do",
      "offset": 842.16,
      "duration": 2.479
    },
    {
      "lang": "en",
      "text": "you have a defendant and a plaintiff in",
      "offset": 843.36,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "litigation?\n Yeah. Okay.",
      "offset": 844.639,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "Um,",
      "offset": 847.04,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "and so in in that kind of situation, the",
      "offset": 848.639,
      "duration": 5.841
    },
    {
      "lang": "en",
      "text": "stakes are very high. So how do you",
      "offset": 852.72,
      "duration": 4.559
    },
    {
      "lang": "en",
      "text": "balance speed and automation, which are",
      "offset": 854.48,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "so important, with the legal field's",
      "offset": 857.279,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "high standards for defensibility, a word",
      "offset": 860.16,
      "duration": 5.359
    },
    {
      "lang": "en",
      "text": "you just used, and due diligence?\n Those",
      "offset": 862.399,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "are great questions. So um so one of the",
      "offset": 865.519,
      "duration": 5.841
    },
    {
      "lang": "en",
      "text": "fun things about working in the legal",
      "offset": 868.399,
      "duration": 4.961
    },
    {
      "lang": "en",
      "text": "industry is that these standard",
      "offset": 871.36,
      "duration": 4.479
    },
    {
      "lang": "en",
      "text": "evaluation metrics recall and precision",
      "offset": 873.36,
      "duration": 6.479
    },
    {
      "lang": "en",
      "text": "generally um get negotiated sometimes",
      "offset": 875.839,
      "duration": 6.8
    },
    {
      "lang": "en",
      "text": "get negotiated with opposing council um",
      "offset": 879.839,
      "duration": 5.521
    },
    {
      "lang": "en",
      "text": "or some governmental body. So it's a one",
      "offset": 882.639,
      "duration": 4.961
    },
    {
      "lang": "en",
      "text": "time where your evaluation metrics and",
      "offset": 885.36,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "being rigorous in your evaluation",
      "offset": 887.6,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "processes",
      "offset": 889.92,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "reasonably rigorous in your evaluation",
      "offset": 891.519,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "processes really really matter. Right?",
      "offset": 893.68,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "you get to argue about the margin of",
      "offset": 895.519,
      "duration": 4.481
    },
    {
      "lang": "en",
      "text": "error and all sorts of things like that.",
      "offset": 897.519,
      "duration": 4.481
    },
    {
      "lang": "en",
      "text": "Um, and you have to, as a data",
      "offset": 900,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "scientist, you do have to be able to",
      "offset": 902,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "explain what that really means and what",
      "offset": 903.6,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "the consequences of it might mean uh to",
      "offset": 906.079,
      "duration": 6.241
    },
    {
      "lang": "en",
      "text": "to attorneys and sometimes judges.",
      "offset": 909.12,
      "duration": 5.519
    },
    {
      "lang": "en",
      "text": "Um, but it it is every case is a little",
      "offset": 912.32,
      "duration": 6.48
    },
    {
      "lang": "en",
      "text": "bit different. um defensibility boils",
      "offset": 914.639,
      "duration": 7.281
    },
    {
      "lang": "en",
      "text": "down to what that particular attorney is",
      "offset": 918.8,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "comfortable defending and there are",
      "offset": 921.92,
      "duration": 5.84
    },
    {
      "lang": "en",
      "text": "proportionality considerations and and",
      "offset": 924.56,
      "duration": 5.839
    },
    {
      "lang": "en",
      "text": "you know undue burden considerations",
      "offset": 927.76,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "that go into it. So, for example, if you",
      "offset": 930.399,
      "duration": 5.201
    },
    {
      "lang": "en",
      "text": "have a really really low prevalence",
      "offset": 932.88,
      "duration": 7.04
    },
    {
      "lang": "en",
      "text": "um uh you know, relevance tag, right? If",
      "offset": 935.6,
      "duration": 6.88
    },
    {
      "lang": "en",
      "text": "you're if you're looking for a subset of",
      "offset": 939.92,
      "duration": 6.88
    },
    {
      "lang": "en",
      "text": "the documents that's really rare, um",
      "offset": 942.48,
      "duration": 6.64
    },
    {
      "lang": "en",
      "text": "just sampling enough documents in order",
      "offset": 946.8,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "to be able to evaluate it could become",
      "offset": 949.12,
      "duration": 6.56
    },
    {
      "lang": "en",
      "text": "overly burdensome potentially. And then",
      "offset": 952.56,
      "duration": 5.839
    },
    {
      "lang": "en",
      "text": "we have this metric that I've never come",
      "offset": 955.68,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "across outside of eiscocovery. we call",
      "offset": 958.399,
      "duration": 5.921
    },
    {
      "lang": "en",
      "text": "it illusion where we're just sampling",
      "offset": 961.04,
      "duration": 7.359
    },
    {
      "lang": "en",
      "text": "the subset of documents uh predicted not",
      "offset": 964.32,
      "duration": 5.92
    },
    {
      "lang": "en",
      "text": "relevant and we have the human ground",
      "offset": 968.399,
      "duration": 3.521
    },
    {
      "lang": "en",
      "text": "truth labels for all the relevant",
      "offset": 970.24,
      "duration": 6.159
    },
    {
      "lang": "en",
      "text": "documents. So from um from those two",
      "offset": 971.92,
      "duration": 7.12
    },
    {
      "lang": "en",
      "text": "metrics we can then estimate an interval",
      "offset": 976.399,
      "duration": 5.601
    },
    {
      "lang": "en",
      "text": "for recall and that's an interesting",
      "offset": 979.04,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "case and and the defensibility around",
      "offset": 982,
      "duration": 5.839
    },
    {
      "lang": "en",
      "text": "that is debated. Um, I I'm a proponent",
      "offset": 984,
      "duration": 6.56
    },
    {
      "lang": "en",
      "text": "of it because we don't use any of these",
      "offset": 987.839,
      "duration": 5.041
    },
    {
      "lang": "en",
      "text": "metrics to evaluate what we call linear",
      "offset": 990.56,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "review, which is just humans with eyes",
      "offset": 992.88,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "on everything. Um, and if we're just",
      "offset": 995.12,
      "duration": 4.959
    },
    {
      "lang": "en",
      "text": "going to assume that that is the gold",
      "offset": 998.24,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "standard, that all of those labels are",
      "offset": 1000.079,
      "duration": 4.801
    },
    {
      "lang": "en",
      "text": "in fact correct, which we kind of know",
      "offset": 1001.92,
      "duration": 6.159
    },
    {
      "lang": "en",
      "text": "they probably aren't,",
      "offset": 1004.88,
      "duration": 7.6
    },
    {
      "lang": "en",
      "text": "um, then why should we hold uh, machine",
      "offset": 1008.079,
      "duration": 6.32
    },
    {
      "lang": "en",
      "text": "learning workflows to a higher standard,",
      "offset": 1012.48,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "right? we should be able to accept that",
      "offset": 1014.399,
      "duration": 6.401
    },
    {
      "lang": "en",
      "text": "those that those uh labels are are the",
      "offset": 1016.24,
      "duration": 8.16
    },
    {
      "lang": "en",
      "text": "gold standard. Um so yeah, lots of",
      "offset": 1020.8,
      "duration": 5.519
    },
    {
      "lang": "en",
      "text": "interesting lots of interesting areas of",
      "offset": 1024.4,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "of debate, lots of different angles. And",
      "offset": 1026.319,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "again, it just depends on the case and",
      "offset": 1028.559,
      "duration": 6.24
    },
    {
      "lang": "en",
      "text": "and who's requesting what and how",
      "offset": 1030.959,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "ownorous it's going to be for the",
      "offset": 1034.799,
      "duration": 4.481
    },
    {
      "lang": "en",
      "text": "producing party to uh to appease",
      "offset": 1036.319,
      "duration": 6.961
    },
    {
      "lang": "en",
      "text": "opposing. Um, and and all of that goes",
      "offset": 1039.28,
      "duration": 6.639
    },
    {
      "lang": "en",
      "text": "into a defensible quote unquote",
      "offset": 1043.28,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "defensible workflow.",
      "offset": 1045.919,
      "duration": 4.721
    },
    {
      "lang": "en",
      "text": "This episode of Super Data Science is",
      "offset": 1048.96,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "brought to you by the Dell AI Factory",
      "offset": 1050.64,
      "duration": 5.039
    },
    {
      "lang": "en",
      "text": "with Nvidia, helping you fasttrack your",
      "offset": 1053.2,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "AI adoption from the desktop to the data",
      "offset": 1055.679,
      "duration": 5.041
    },
    {
      "lang": "en",
      "text": "center. The Dell AI factory with NVIDIA",
      "offset": 1058.16,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "provides a simple development launchpad",
      "offset": 1060.72,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "that allows you to perform local",
      "offset": 1062.48,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "prototyping in a safe and secure",
      "offset": 1064.32,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "environment. Next, develop and prepare",
      "offset": 1066.08,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "to scale by rapidly building AI and data",
      "offset": 1068.96,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "workflows with containerbased",
      "offset": 1071.44,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "microservices. And then deploy and",
      "offset": 1072.72,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "optimize in the enterprise with a",
      "offset": 1075.76,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "scalable infrastructure framework. Visit",
      "offset": 1077.52,
      "duration": 5.279
    },
    {
      "lang": "en",
      "text": "ww.dell.com/supdatience",
      "offset": 1080.24,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "to learn more. That's",
      "offset": 1082.799,
      "duration": 3.961
    },
    {
      "lang": "en",
      "text": "dell.com/supdatience.",
      "offset": 1083.76,
      "duration": 3
    },
    {
      "lang": "en",
      "text": "All right. Right. Let's talk a little",
      "offset": 1087.36,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "bit more about this illusion uh term",
      "offset": 1088.64,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "that seems to be unique to legal tech.",
      "offset": 1091.36,
      "duration": 6.319
    },
    {
      "lang": "en",
      "text": "Um, so, uh, for for our listeners, uh,",
      "offset": 1094.08,
      "duration": 6.88
    },
    {
      "lang": "en",
      "text": "it's not an illusion like a magic trick",
      "offset": 1097.679,
      "duration": 7.921
    },
    {
      "lang": "en",
      "text": "with an I. It's like elude. E L U D E.",
      "offset": 1100.96,
      "duration": 9.599
    },
    {
      "lang": "en",
      "text": "Uh, illusion. E L U S I O N. Uh, so it's",
      "offset": 1105.6,
      "duration": 7.68
    },
    {
      "lang": "en",
      "text": "like, so it's like kind of like this",
      "offset": 1110.559,
      "duration": 5.201
    },
    {
      "lang": "en",
      "text": "idea of like deception um or like",
      "offset": 1113.28,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "avoiding detection, I suppose, because",
      "offset": 1115.76,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "it's not like deliberate deception.",
      "offset": 1117.6,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "Yeah. Those are the documents that have",
      "offset": 1119.679,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "eluded you. So yeah.\n Right. Exactly. And",
      "offset": 1121.679,
      "duration": 6.401
    },
    {
      "lang": "en",
      "text": "so then why is that different from you",
      "offset": 1124.799,
      "duration": 6.081
    },
    {
      "lang": "en",
      "text": "know from a machine learning metric that",
      "offset": 1128.08,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "would be equivalent like um so that",
      "offset": 1130.88,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "would be a and I always I often like",
      "offset": 1133.12,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "getting um like a little 2 by 2 table in",
      "offset": 1135.2,
      "duration": 2.96
    },
    {
      "lang": "en",
      "text": "front of me to make sure I'm not",
      "offset": 1137.28,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "butchering this but that would be a uh",
      "offset": 1138.16,
      "duration": 6.32
    },
    {
      "lang": "en",
      "text": "false negative.",
      "offset": 1141.6,
      "duration": 6.56
    },
    {
      "lang": "en",
      "text": "Um correct. Yes. Yes. false negative out",
      "offset": 1144.48,
      "duration": 7.68
    },
    {
      "lang": "en",
      "text": "of false negatives and um and true",
      "offset": 1148.16,
      "duration": 6.16
    },
    {
      "lang": "en",
      "text": "negatives. Exactly.\n Right. We actually",
      "offset": 1152.16,
      "duration": 5.84
    },
    {
      "lang": "en",
      "text": "candidly for our listeners, I just took",
      "offset": 1154.32,
      "duration": 6.08
    },
    {
      "lang": "en",
      "text": "uh I just took a second to do some",
      "offset": 1158,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "research and and pull out that it seems",
      "offset": 1160.4,
      "duration": 6.399
    },
    {
      "lang": "en",
      "text": "like kind of a generic term for this uh",
      "offset": 1163.6,
      "duration": 7.199
    },
    {
      "lang": "en",
      "text": "for illusion. So, uh, false negatives",
      "offset": 1166.799,
      "duration": 5.841
    },
    {
      "lang": "en",
      "text": "divided by false negatives and true",
      "offset": 1170.799,
      "duration": 4.961
    },
    {
      "lang": "en",
      "text": "negatives, uh, can be called, uh, false",
      "offset": 1172.64,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "omission rate in machine learning in",
      "offset": 1175.76,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "general. But I guess that's kind of a",
      "offset": 1177.6,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "it's a bit of a mouthful. Illusion",
      "offset": 1179.52,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "sounds nicer. It sounds like it's such a",
      "offset": 1182,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "it's a simple word. Uh, I like it a lot.",
      "offset": 1184.16,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "And I don't know who to credit who to",
      "offset": 1187.36,
      "duration": 6.16
    },
    {
      "lang": "en",
      "text": "credit with that term. Um, uh, it it did",
      "offset": 1189.84,
      "duration": 7.92
    },
    {
      "lang": "en",
      "text": "kind of pop out of nowhere. Um, so yeah.",
      "offset": 1193.52,
      "duration": 7.2
    },
    {
      "lang": "en",
      "text": "So, I I wish I could tell you more, but",
      "offset": 1197.76,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "I did figure out how to get an interval",
      "offset": 1200.72,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "for recall based on the illusion rate.",
      "offset": 1203.2,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "Right? The problem with the illusion",
      "offset": 1205.2,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "rate, and it's a very legitimate",
      "offset": 1206.72,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "problem, is that people will take an",
      "offset": 1209.039,
      "duration": 6.961
    },
    {
      "lang": "en",
      "text": "illusion sample um and just decide that,",
      "offset": 1211.84,
      "duration": 6.8
    },
    {
      "lang": "en",
      "text": "hey, yeah, it's low, that's good,",
      "offset": 1216,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "without thinking about the starting",
      "offset": 1218.64,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "prevalence. Right? So if you started",
      "offset": 1221.28,
      "duration": 5.519
    },
    {
      "lang": "en",
      "text": "with um so right people will say oh if",
      "offset": 1224.4,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "if the illusion is under 5% then it's",
      "offset": 1226.799,
      "duration": 8.081
    },
    {
      "lang": "en",
      "text": "good but that's not good if your if your",
      "offset": 1230,
      "duration": 7.679
    },
    {
      "lang": "en",
      "text": "prevalence was under 5% to begin with",
      "offset": 1234.88,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "right then that doesn't tell you",
      "offset": 1237.679,
      "duration": 5.601
    },
    {
      "lang": "en",
      "text": "anything um so with this standard",
      "offset": 1239.52,
      "duration": 6.639
    },
    {
      "lang": "en",
      "text": "workflow so there now I can talk about I",
      "offset": 1243.28,
      "duration": 6.32
    },
    {
      "lang": "en",
      "text": "hate these terms but there's tar 1.0 and",
      "offset": 1246.159,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "tar 2.0",
      "offset": 1249.6,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "And um they basically are heruristics",
      "offset": 1251.679,
      "duration": 4.561
    },
    {
      "lang": "en",
      "text": "for different workflows. And there's",
      "offset": 1254.64,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "different permutations, right? There's",
      "offset": 1256.24,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "different ways of of getting to whatever",
      "offset": 1258,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "model you're using to serve up documents",
      "offset": 1260.88,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "uh and different stopping points for for",
      "offset": 1263.76,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "training. But at the end of the day, it",
      "offset": 1266.32,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "boils down to tar one being a workflow",
      "offset": 1268.24,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "where you produce documents that have",
      "offset": 1271.36,
      "duration": 6.319
    },
    {
      "lang": "en",
      "text": "only been classified by your classifier",
      "offset": 1273.84,
      "duration": 8.319
    },
    {
      "lang": "en",
      "text": "uh and not necessarily been looked at by",
      "offset": 1277.679,
      "duration": 8.721
    },
    {
      "lang": "en",
      "text": "human attorneys. Whereas TAR 2.0",
      "offset": 1282.159,
      "duration": 7.441
    },
    {
      "lang": "en",
      "text": "um huristically describes a workflow",
      "offset": 1286.4,
      "duration": 6.159
    },
    {
      "lang": "en",
      "text": "where you're looking at every predicted",
      "offset": 1289.6,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "relevant document before it goes out the",
      "offset": 1292.559,
      "duration": 6.081
    },
    {
      "lang": "en",
      "text": "door. Um so in this tar 2 workflow in",
      "offset": 1294.72,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "this workflow where you are having",
      "offset": 1298.64,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "humans actually annotate every predicted",
      "offset": 1300.4,
      "duration": 6.399
    },
    {
      "lang": "en",
      "text": "relevant document um then again now you",
      "offset": 1303.44,
      "duration": 6.719
    },
    {
      "lang": "en",
      "text": "have that known quantity you you do know",
      "offset": 1306.799,
      "duration": 5.841
    },
    {
      "lang": "en",
      "text": "how many actual relevant documents there",
      "offset": 1310.159,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "were you don't have to estimate that",
      "offset": 1312.64,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "from a recall precision uh curve or",
      "offset": 1314.08,
      "duration": 6.959
    },
    {
      "lang": "en",
      "text": "confusion matrix um and then you can",
      "offset": 1316.96,
      "duration": 6.64
    },
    {
      "lang": "en",
      "text": "estimate what the interval for recall is",
      "offset": 1321.039,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "based on the interval",
      "offset": 1323.6,
      "duration": 4.559
    },
    {
      "lang": "en",
      "text": "for illusion. And you hear me go on and",
      "offset": 1325.44,
      "duration": 5.84
    },
    {
      "lang": "en",
      "text": "on about intervals. I am obsessive about",
      "offset": 1328.159,
      "duration": 6.241
    },
    {
      "lang": "en",
      "text": "focusing on confidence interval and not",
      "offset": 1331.28,
      "duration": 5.759
    },
    {
      "lang": "en",
      "text": "point estimate.\n Exactly. I actually had",
      "offset": 1334.4,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "some questions for you later on in the",
      "offset": 1337.039,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "episode about that, but we might as well",
      "offset": 1339.12,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "get into it right now. Why? Why do I",
      "offset": 1340.559,
      "duration": 6.561
    },
    {
      "lang": "en",
      "text": "mean I can I can guess, but please tell",
      "offset": 1343.039,
      "duration": 6.64
    },
    {
      "lang": "en",
      "text": "us why you prefer going in ranges. why",
      "offset": 1347.12,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "you prefer providing information in",
      "offset": 1349.679,
      "duration": 5.201
    },
    {
      "lang": "en",
      "text": "ranges as opposed to point estimates.",
      "offset": 1351.84,
      "duration": 7.12
    },
    {
      "lang": "en",
      "text": "Yeah. So the short answer is that the",
      "offset": 1354.88,
      "duration": 6.32
    },
    {
      "lang": "en",
      "text": "coolest thing about statistics is that",
      "offset": 1358.96,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "you get to measure your uncertainty.",
      "offset": 1361.2,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "So why wouldn't you why wouldn't you do",
      "offset": 1363.84,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "that? Why wouldn't you measure your",
      "offset": 1366.24,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "uncertainty? Um but the more more",
      "offset": 1367.6,
      "duration": 6.559
    },
    {
      "lang": "en",
      "text": "serious answer is that um I mean we are",
      "offset": 1370.32,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "dealing with uncertainties, right? you",
      "offset": 1374.159,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "shouldn't assume that a point estimate",
      "offset": 1376,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "is truly representative of the parameter",
      "offset": 1377.76,
      "duration": 6.32
    },
    {
      "lang": "en",
      "text": "that you're trying to estimate. Um, you",
      "offset": 1380.88,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "really should think about those those",
      "offset": 1384.08,
      "duration": 4.719
    },
    {
      "lang": "en",
      "text": "confidence intervals because then you",
      "offset": 1386.48,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "can feel pretty good about knowing that",
      "offset": 1388.799,
      "duration": 3.521
    },
    {
      "lang": "en",
      "text": "it's going to be somewhere within that",
      "offset": 1390.72,
      "duration": 6.48
    },
    {
      "lang": "en",
      "text": "range. Um, and and you're taking account",
      "offset": 1392.32,
      "duration": 6.8
    },
    {
      "lang": "en",
      "text": "you're taking the uncertainty into",
      "offset": 1397.2,
      "duration": 6.4
    },
    {
      "lang": "en",
      "text": "account. Um, right? So it's easy to to",
      "offset": 1399.12,
      "duration": 6.16
    },
    {
      "lang": "en",
      "text": "fixate on a point estimate, but I've",
      "offset": 1403.6,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "said before that uh a point estimate",
      "offset": 1405.28,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "without sample size, without confidence",
      "offset": 1408.08,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "intervals is basically lying with",
      "offset": 1410.4,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "statistics. You have no idea what what",
      "offset": 1412.24,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "the actual claim is there,\n right? And so",
      "offset": 1414.32,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "how do people who aren't trained in",
      "offset": 1416.96,
      "duration": 5.199
    },
    {
      "lang": "en",
      "text": "statistics react uh when you provide",
      "offset": 1419.44,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "them with confidence intervals as",
      "offset": 1422.159,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "opposed to point estimates? Do you ever",
      "offset": 1423.84,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "get kind of a you know confusion or",
      "offset": 1426,
      "duration": 4.799
    },
    {
      "lang": "en",
      "text": "backlash on that?",
      "offset": 1429.12,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "Yeah. Yeah. Um, so it depends on who I'm",
      "offset": 1430.799,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "working with. If it's, you know, if it's",
      "offset": 1434.88,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "an attorney or a judge, I try to just",
      "offset": 1436.799,
      "duration": 6.401
    },
    {
      "lang": "en",
      "text": "demonstrate. I have like a, um, even",
      "offset": 1439.76,
      "duration": 5.279
    },
    {
      "lang": "en",
      "text": "just like a quick calculator in Excel,",
      "offset": 1443.2,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "I'll show them how, you know, varying",
      "offset": 1445.039,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "certain things affects those estimates",
      "offset": 1447.44,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "and try to give them an intuitive",
      "offset": 1449.679,
      "duration": 4.801
    },
    {
      "lang": "en",
      "text": "understanding of it. If it's if it's a",
      "offset": 1451.2,
      "duration": 6.079
    },
    {
      "lang": "en",
      "text": "consultant um and I'm trying to give",
      "offset": 1454.48,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "them a more intuitive understanding of",
      "offset": 1457.279,
      "duration": 6.801
    },
    {
      "lang": "en",
      "text": "it, I'll have them I'll have them",
      "offset": 1458.96,
      "duration": 7.68
    },
    {
      "lang": "en",
      "text": "randomly sample half of the documents in",
      "offset": 1464.08,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "a certain population and label them",
      "offset": 1466.64,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "something like documents I care about.",
      "offset": 1469.84,
      "duration": 4.719
    },
    {
      "lang": "en",
      "text": "And then I have them sample with 90%",
      "offset": 1472.08,
      "duration": 6.079
    },
    {
      "lang": "en",
      "text": "confidence uh at least 10 times so that",
      "offset": 1474.559,
      "duration": 7.841
    },
    {
      "lang": "en",
      "text": "they can see that hey on average one out",
      "offset": 1478.159,
      "duration": 8.801
    },
    {
      "lang": "en",
      "text": "of 10 times the actual um the point",
      "offset": 1482.4,
      "duration": 6.72
    },
    {
      "lang": "en",
      "text": "estimate that I'm estimating from this",
      "offset": 1486.96,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "sample is not within the range that I've",
      "offset": 1489.12,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "estimated. Right? And I think that",
      "offset": 1492.4,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "builds up an intuitive understanding of",
      "offset": 1494.48,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "of confidence intervals.\n Yes. Yes. Yes.",
      "offset": 1496.799,
      "duration": 5.441
    },
    {
      "lang": "en",
      "text": "the old law of large numbers. Uh",
      "offset": 1499.52,
      "duration": 5.279
    },
    {
      "lang": "en",
      "text": "sounding familiar here.",
      "offset": 1502.24,
      "duration": 6.559
    },
    {
      "lang": "en",
      "text": "Uh and uh I do I will eventually create",
      "offset": 1504.799,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "uh YouTube content on these concepts if",
      "offset": 1508.799,
      "duration": 3.201
    },
    {
      "lang": "en",
      "text": "I haven't already. I can't remember",
      "offset": 1510.799,
      "duration": 2.721
    },
    {
      "lang": "en",
      "text": "where I am. And I've been creating this",
      "offset": 1512,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "like",
      "offset": 1513.52,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "uh ma this mathematical foundations",
      "offset": 1515.2,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "content uh and I was really good about",
      "offset": 1518,
      "duration": 3.679
    },
    {
      "lang": "en",
      "text": "putting it on YouTube for a couple of",
      "offset": 1520.32,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "years up until three years ago. And I",
      "offset": 1521.679,
      "duration": 4.721
    },
    {
      "lang": "en",
      "text": "know that somewhere in there I do have a",
      "offset": 1524.96,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "law a law of large numbers video, but I",
      "offset": 1526.4,
      "duration": 3.759
    },
    {
      "lang": "en",
      "text": "think I might not have released it yet.",
      "offset": 1528.799,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "So that it is coming eventually someday.",
      "offset": 1530.159,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "Um nice. In the meantime, uh people can",
      "offset": 1532.799,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "look it up, but it's basically it's",
      "offset": 1536.159,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "like, you know, the more data that you",
      "offset": 1537.919,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "sample um the tighter your ranges will",
      "offset": 1539.84,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "tend to be, your estimates will tend to",
      "offset": 1543.679,
      "duration": 4.721
    },
    {
      "lang": "en",
      "text": "be. you you you begin to get uh a better",
      "offset": 1544.96,
      "duration": 7.12
    },
    {
      "lang": "en",
      "text": "picture of reality um without having to",
      "offset": 1548.4,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "look at every single data point.\n That's",
      "offset": 1552.08,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "right. And I was actually just showing",
      "offset": 1554.4,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "colleagues today that um when your",
      "offset": 1556.48,
      "duration": 5.92
    },
    {
      "lang": "en",
      "text": "sample is large enough, the intervals",
      "offset": 1559.84,
      "duration": 6.959
    },
    {
      "lang": "en",
      "text": "for 95% confidence level versus 99%",
      "offset": 1562.4,
      "duration": 6.24
    },
    {
      "lang": "en",
      "text": "confidence level tend to converge.",
      "offset": 1566.799,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "Right? So, um, once your your sample is",
      "offset": 1568.64,
      "duration": 5.279
    },
    {
      "lang": "en",
      "text": "sufficiently large, it doesn't really",
      "offset": 1572.159,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "matter whether you're estimating",
      "offset": 1573.919,
      "duration": 5.601
    },
    {
      "lang": "en",
      "text": "something at 95 or 99% confidence.",
      "offset": 1575.84,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "Right. Right. Right. That makes a lot of",
      "offset": 1579.52,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "sense. Nice. All right. So, we've now",
      "offset": 1580.96,
      "duration": 6.719
    },
    {
      "lang": "en",
      "text": "learned a lot about law, about legal",
      "offset": 1583.52,
      "duration": 7.12
    },
    {
      "lang": "en",
      "text": "tech. Uh, have we gotten into yet? Yeah,",
      "offset": 1587.679,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "I guess we have. 've gotten into the",
      "offset": 1590.64,
      "duration": 2.88
    },
    {
      "lang": "en",
      "text": "Epic AI discovery assistant as well",
      "offset": 1591.84,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "because that you explained, you know, it",
      "offset": 1593.52,
      "duration": 3.519
    },
    {
      "lang": "en",
      "text": "had it had things built into it like",
      "offset": 1595.36,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "retriever augmented generation um that",
      "offset": 1597.039,
      "duration": 4.721
    },
    {
      "lang": "en",
      "text": "allowed it to outperform technology",
      "offset": 1599.44,
      "duration": 6.239
    },
    {
      "lang": "en",
      "text": "assistant review 1.0 or 2.0\n traditional",
      "offset": 1601.76,
      "duration": 7.68
    },
    {
      "lang": "en",
      "text": "techn workflow terms uh than than",
      "offset": 1605.679,
      "duration": 6.401
    },
    {
      "lang": "en",
      "text": "technical terms. Um, so I hate the terms",
      "offset": 1609.44,
      "duration": 5.359
    },
    {
      "lang": "en",
      "text": "because they confuse people so much, but",
      "offset": 1612.08,
      "duration": 6.4
    },
    {
      "lang": "en",
      "text": "uh but it's it's been what the industry",
      "offset": 1614.799,
      "duration": 5.681
    },
    {
      "lang": "en",
      "text": "has been using for for quite a while",
      "offset": 1618.48,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "now.\n Nice. All right. And so the topic",
      "offset": 1620.48,
      "duration": 5.92
    },
    {
      "lang": "en",
      "text": "that I actually thought might be the",
      "offset": 1624.48,
      "duration": 3.199
    },
    {
      "lang": "en",
      "text": "topic that we talked about the entire",
      "offset": 1626.4,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "episode, but it ended up being that",
      "offset": 1627.679,
      "duration": 3.281
    },
    {
      "lang": "en",
      "text": "there were so many interesting things to",
      "offset": 1629.52,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "go into around legal tech AI that I",
      "offset": 1630.96,
      "duration": 4.719
    },
    {
      "lang": "en",
      "text": "wanted to have the conversation that we",
      "offset": 1634.48,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "just had. But the actual the the impetus",
      "offset": 1635.679,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "uh for having an episode when we talked",
      "offset": 1639.36,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "about it on the train already a year ago",
      "offset": 1641.279,
      "duration": 4.481
    },
    {
      "lang": "en",
      "text": "was this idea of datacentric machine",
      "offset": 1643.279,
      "duration": 5.041
    },
    {
      "lang": "en",
      "text": "learning. And so this is now a topic",
      "offset": 1645.76,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "that is you know it's not this isn't",
      "offset": 1648.32,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "just like oh there's some analogies here",
      "offset": 1650,
      "duration": 3.679
    },
    {
      "lang": "en",
      "text": "that might be relevant to your industry.",
      "offset": 1652,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "Datacentric ML is relevant to every",
      "offset": 1653.679,
      "duration": 5.041
    },
    {
      "lang": "en",
      "text": "listener anybody who's working with",
      "offset": 1656.48,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "data. Um this is relevant. And so tell",
      "offset": 1658.72,
      "duration": 5.92
    },
    {
      "lang": "en",
      "text": "us about datacentric machine learning",
      "offset": 1662,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "research, DMLR.",
      "offset": 1664.64,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "And um and my understanding is that you",
      "offset": 1666.96,
      "duration": 9.12
    },
    {
      "lang": "en",
      "text": "fell into DMLR as as a result of how how",
      "offset": 1670.08,
      "duration": 9.76
    },
    {
      "lang": "en",
      "text": "messy the data are in the legal space.",
      "offset": 1676.08,
      "duration": 7.68
    },
    {
      "lang": "en",
      "text": "Yeah, that's right. So um in my first",
      "offset": 1679.84,
      "duration": 7.36
    },
    {
      "lang": "en",
      "text": "R&amp;D role, I was really focused on on",
      "offset": 1683.76,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "algorithms and on finding the best",
      "offset": 1687.2,
      "duration": 4.479
    },
    {
      "lang": "en",
      "text": "classification algorithms",
      "offset": 1689.44,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "uh for for these classification tasks",
      "offset": 1691.679,
      "duration": 4.561
    },
    {
      "lang": "en",
      "text": "that we've discussed. Um, at a certain",
      "offset": 1693.76,
      "duration": 5.919
    },
    {
      "lang": "en",
      "text": "point I realized that the label data I",
      "offset": 1696.24,
      "duration": 6.88
    },
    {
      "lang": "en",
      "text": "was working with was so noisy, just had",
      "offset": 1699.679,
      "duration": 6.88
    },
    {
      "lang": "en",
      "text": "so many uh mislabeled",
      "offset": 1703.12,
      "duration": 7.6
    },
    {
      "lang": "en",
      "text": "instances and and all of that um that it",
      "offset": 1706.559,
      "duration": 7.84
    },
    {
      "lang": "en",
      "text": "really curtailed my ability to evaluate",
      "offset": 1710.72,
      "duration": 7.36
    },
    {
      "lang": "en",
      "text": "the performance of of the of the",
      "offset": 1714.399,
      "duration": 6.961
    },
    {
      "lang": "en",
      "text": "algorithm um just because I couldn't",
      "offset": 1718.08,
      "duration": 7.599
    },
    {
      "lang": "en",
      "text": "necessarily trust my data. Uh so that",
      "offset": 1721.36,
      "duration": 8.72
    },
    {
      "lang": "en",
      "text": "led me to be very interested in what",
      "offset": 1725.679,
      "duration": 8.321
    },
    {
      "lang": "en",
      "text": "Andrew Ing coined datacentric AI. Um and",
      "offset": 1730.08,
      "duration": 6.88
    },
    {
      "lang": "en",
      "text": "I ended up getting involved with a",
      "offset": 1734,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "working group at ML Commons called data",
      "offset": 1736.96,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "perf. Uh where we were looking to",
      "offset": 1739.52,
      "duration": 4.879
    },
    {
      "lang": "en",
      "text": "benchmark datacentric machine learning.",
      "offset": 1741.84,
      "duration": 6.64
    },
    {
      "lang": "en",
      "text": "Um that ended up leading to a few",
      "offset": 1744.399,
      "duration": 6.081
    },
    {
      "lang": "en",
      "text": "different workshops that we've organized",
      "offset": 1748.48,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "at Icleair and ICML.",
      "offset": 1750.48,
      "duration": 5.919
    },
    {
      "lang": "en",
      "text": "Um data proof also became a Nurup's",
      "offset": 1753.6,
      "duration": 7.6
    },
    {
      "lang": "en",
      "text": "paper. Um and uh",
      "offset": 1756.399,
      "duration": 7.201
    },
    {
      "lang": "en",
      "text": "yeah basically it turned into a whole",
      "offset": 1761.2,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "community. So now there's a DMLR",
      "offset": 1763.6,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "journal, there are the DMLR workshops at",
      "offset": 1765.36,
      "duration": 4.799
    },
    {
      "lang": "en",
      "text": "these conferences and then data proerf",
      "offset": 1767.84,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "morphed into the datacentric machine",
      "offset": 1770.159,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "learning research working group with ML",
      "offset": 1771.76,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "common. So we have a lot of different",
      "offset": 1774.559,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "things going on. We're working in",
      "offset": 1776.159,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "partnership with common crawl, the",
      "offset": 1778.48,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "foundation that curates the data sets",
      "offset": 1781.039,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "that most LLMs have been trained on. Um",
      "offset": 1783.36,
      "duration": 6.96
    },
    {
      "lang": "en",
      "text": "we're we're partnering with them on a on",
      "offset": 1786.799,
      "duration": 7.12
    },
    {
      "lang": "en",
      "text": "a challenge that will result in a low",
      "offset": 1790.32,
      "duration": 7.359
    },
    {
      "lang": "en",
      "text": "resource language data set that that",
      "offset": 1793.919,
      "duration": 5.681
    },
    {
      "lang": "en",
      "text": "will be publicly available. So if you're",
      "offset": 1797.679,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "interested in joining the working group,",
      "offset": 1799.6,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "please do get involved. Uh again, it's",
      "offset": 1802,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "with ML Commons. Um you can go to that",
      "offset": 1803.919,
      "duration": 7.36
    },
    {
      "lang": "en",
      "text": "site and and sign up working group.",
      "offset": 1807.2,
      "duration": 6.079
    },
    {
      "lang": "en",
      "text": "This episode is sponsored by Adverity,",
      "offset": 1811.279,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "an integrated data platform for",
      "offset": 1813.279,
      "duration": 3.201
    },
    {
      "lang": "en",
      "text": "connecting, managing, and using your",
      "offset": 1814.88,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "data at scale. Imagine being able to ask",
      "offset": 1816.48,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "your data a question just like you would",
      "offset": 1818.72,
      "duration": 3.439
    },
    {
      "lang": "en",
      "text": "a colleague and getting an answer",
      "offset": 1820.559,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "instantly. No more digging through",
      "offset": 1822.159,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "dashboards, waiting on reports, or",
      "offset": 1824.159,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "dealing with complex BI tools. Just the",
      "offset": 1825.679,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "insights you need right when you need",
      "offset": 1827.919,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "them. With Adver's AI powered data",
      "offset": 1829.6,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "conversations, marketers will finally",
      "offset": 1831.679,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "talk to their data in plain English. Get",
      "offset": 1833.919,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "instant answers, make smarter decisions,",
      "offset": 1836.159,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "collaborate more easily, and cut",
      "offset": 1838.399,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "reporting time in half. What questions",
      "offset": 1840,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "will you ask? To learn more, check out",
      "offset": 1842,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "the show notes or visit",
      "offset": 1844.48,
      "duration": 3.679
    },
    {
      "lang": "en",
      "text": "www.adverity.com.",
      "offset": 1845.52,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "That's advi",
      "offset": 1848.159,
      "duration": 5.081
    },
    {
      "lang": "en",
      "text": "ty.com.",
      "offset": 1850.24,
      "duration": 3
    },
    {
      "lang": "en",
      "text": "We'll be sure to have a link to ML",
      "offset": 1854.08,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "Commons in the show notes. And so when",
      "offset": 1857.12,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "you say a low resource language, this",
      "offset": 1859.52,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "is, you know, languages that for which",
      "offset": 1861.36,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "there are not many data available",
      "offset": 1863.52,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "online. Uh they could be, you know,",
      "offset": 1865.679,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "rarely spoken languages or for whatever",
      "offset": 1867.919,
      "duration": 4.801
    },
    {
      "lang": "en",
      "text": "reason, languages that even even if",
      "offset": 1870,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "they're spoken relatively commonly, they",
      "offset": 1872.72,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "aren't represented on the internet.",
      "offset": 1874.48,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "Exactly. Exactly.\n Nice. That sounds",
      "offset": 1876.559,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "really cool. And so those acronyms that",
      "offset": 1879.12,
      "duration": 3.039
    },
    {
      "lang": "en",
      "text": "you were that you were saying there",
      "offset": 1880.88,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "earlier where this DMLR initiative was",
      "offset": 1882.159,
      "duration": 4.561
    },
    {
      "lang": "en",
      "text": "getting traction. So uh conferences like",
      "offset": 1884.48,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "Iclear, ICML, NURIPS, these are the",
      "offset": 1886.72,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "biggest conferences that there are,",
      "offset": 1889.6,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "academic conferences that there are and",
      "offset": 1891.76,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "so really cool that you get such an",
      "offset": 1894,
      "duration": 2.72
    },
    {
      "lang": "en",
      "text": "impact there. And it's also interesting",
      "offset": 1895.36,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "to hear the the connection to Andrew Ing",
      "offset": 1896.72,
      "duration": 7.04
    },
    {
      "lang": "en",
      "text": "there. Um because he so he I have in my",
      "offset": 1899.76,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "notes here somewhere. I'm kind of",
      "offset": 1903.76,
      "duration": 3.759
    },
    {
      "lang": "en",
      "text": "scrolling around in here. Yeah. So uh at",
      "offset": 1905.44,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "the inaugural DMLR workshop, Andrew Ing",
      "offset": 1907.519,
      "duration": 6.4
    },
    {
      "lang": "en",
      "text": "was the keynote.\n Yes. Yes. Exactly. and",
      "offset": 1911.2,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "he was involved with data perf as well.",
      "offset": 1913.919,
      "duration": 4.801
    },
    {
      "lang": "en",
      "text": "He's on that data perf.",
      "offset": 1915.76,
      "duration": 5.519
    },
    {
      "lang": "en",
      "text": "Okay. So, I'm I'm I'm now very clear on",
      "offset": 1918.72,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "the importance of DMLR and the traction",
      "offset": 1921.279,
      "duration": 4.561
    },
    {
      "lang": "en",
      "text": "it's getting and big wigs like Andrew",
      "offset": 1923.84,
      "duration": 4.719
    },
    {
      "lang": "en",
      "text": "Ing being involved. Probably most of our",
      "offset": 1925.84,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "listeners know who Andrew Ing is. He's",
      "offset": 1928.559,
      "duration": 3.761
    },
    {
      "lang": "en",
      "text": "one of the biggest names in data science",
      "offset": 1930.72,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "period. And if uh if you aren't already",
      "offset": 1932.32,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "familiar with him, we he was on our show",
      "offset": 1935.2,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "in December. So episode 841 you can go",
      "offset": 1937.2,
      "duration": 5.839
    },
    {
      "lang": "en",
      "text": "back to we'll have a link to that in the",
      "offset": 1940.64,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "show notes as well. Um so yeah so now I",
      "offset": 1943.039,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "have a clear understanding of you know",
      "offset": 1946.32,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "datacentric machine learning being very",
      "offset": 1948.799,
      "duration": 4.641
    },
    {
      "lang": "en",
      "text": "important gaining traction but uh our",
      "offset": 1950.72,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "listeners still might not have a great",
      "offset": 1953.44,
      "duration": 5.359
    },
    {
      "lang": "en",
      "text": "understanding of what it is.\n Yeah. Yeah.",
      "offset": 1955.36,
      "duration": 6.48
    },
    {
      "lang": "en",
      "text": "So um the best way I can explain it is",
      "offset": 1958.799,
      "duration": 5.841
    },
    {
      "lang": "en",
      "text": "that in traditional",
      "offset": 1961.84,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "machine learning paradigms you're",
      "offset": 1964.64,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "iterating on the model. you're iterating",
      "offset": 1966.48,
      "duration": 7.439
    },
    {
      "lang": "en",
      "text": "on the model architecture, on the um on",
      "offset": 1968.559,
      "duration": 8.161
    },
    {
      "lang": "en",
      "text": "the learning algorithm, all of those",
      "offset": 1973.919,
      "duration": 4.801
    },
    {
      "lang": "en",
      "text": "sorts of pieces. And that's where you're",
      "offset": 1976.72,
      "duration": 4.959
    },
    {
      "lang": "en",
      "text": "really focused on on improving",
      "offset": 1978.72,
      "duration": 4.799
    },
    {
      "lang": "en",
      "text": "performance is by iterating on the",
      "offset": 1981.679,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "model. With datacentric machine",
      "offset": 1983.519,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "learning, you're iterating on the data.",
      "offset": 1985.84,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "So, you're holding the model fixed and",
      "offset": 1988.159,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "you're improving the data. You're",
      "offset": 1989.919,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "systematically engineering better data.",
      "offset": 1991.679,
      "duration": 4.801
    },
    {
      "lang": "en",
      "text": "And then there are all these different",
      "offset": 1995.039,
      "duration": 3.281
    },
    {
      "lang": "en",
      "text": "questions, right? So there's the the",
      "offset": 1996.48,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "question of whether to aggregate labels",
      "offset": 1998.32,
      "duration": 5.839
    },
    {
      "lang": "en",
      "text": "or not. Um there's a really interesting",
      "offset": 2000.24,
      "duration": 7.2
    },
    {
      "lang": "en",
      "text": "paper Dory me that looked at waiting",
      "offset": 2004.159,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "different domains of the pile to get the",
      "offset": 2007.44,
      "duration": 6.719
    },
    {
      "lang": "en",
      "text": "best um LLM pre-training performance. Um",
      "offset": 2009.679,
      "duration": 6.641
    },
    {
      "lang": "en",
      "text": "so there's yeah it can it can go lots of",
      "offset": 2014.159,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "different ways. There's there's another",
      "offset": 2016.32,
      "duration": 3.199
    },
    {
      "lang": "en",
      "text": "paper I'm thinking of I can't remember",
      "offset": 2018,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "the name but they looked at selecting",
      "offset": 2019.519,
      "duration": 4.561
    },
    {
      "lang": "en",
      "text": "the best data points for training a",
      "offset": 2021.76,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "model a priori. So not even active",
      "offset": 2024.08,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "learning where you're starting with the",
      "offset": 2026.72,
      "duration": 4.799
    },
    {
      "lang": "en",
      "text": "results of the model to determine which",
      "offset": 2028.88,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "um additional data points you should",
      "offset": 2031.519,
      "duration": 6.561
    },
    {
      "lang": "en",
      "text": "have labeled but um but just with a with",
      "offset": 2033.039,
      "duration": 8.88
    },
    {
      "lang": "en",
      "text": "a data set from scratch using linear",
      "offset": 2038.08,
      "duration": 6.8
    },
    {
      "lang": "en",
      "text": "algebra to figure out which uh which",
      "offset": 2041.919,
      "duration": 5.681
    },
    {
      "lang": "en",
      "text": "data points are worth labeling.\n Right.",
      "offset": 2044.88,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "Right. Right. Right. So the idea here is",
      "offset": 2047.6,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "that um and so I I think this this this",
      "offset": 2049.28,
      "duration": 6.48
    },
    {
      "lang": "en",
      "text": "uh contrast with the idea of what we",
      "offset": 2053.28,
      "duration": 4.799
    },
    {
      "lang": "en",
      "text": "mostly end up doing as data scientists,",
      "offset": 2055.76,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "as machine learning engineers, as AI",
      "offset": 2058.079,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "engineers, where we're trying to change",
      "offset": 2060,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "our model weights in order to get the",
      "offset": 2062.48,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "best result for whatever situation we're",
      "offset": 2064.96,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "in. With datacentric machine learning,",
      "offset": 2066.639,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "the idea is that you could actually",
      "offset": 2069.04,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "potentially keep your model weights the",
      "offset": 2071.599,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "same and you make adjustments to the",
      "offset": 2073.119,
      "duration": 5.201
    },
    {
      "lang": "en",
      "text": "data themselves. uh in terms of how much",
      "offset": 2076,
      "duration": 3.599
    },
    {
      "lang": "en",
      "text": "you have or the composition of those",
      "offset": 2078.32,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "data or how you sample from the data. Um",
      "offset": 2079.599,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "and so basically you're you're concerned",
      "offset": 2082.399,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "you're focused on data. They become",
      "offset": 2084.879,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "central uh to the way that you develop",
      "offset": 2087.599,
      "duration": 5.601
    },
    {
      "lang": "en",
      "text": "your machine learning uh models and",
      "offset": 2090.879,
      "duration": 5.121
    },
    {
      "lang": "en",
      "text": "ultimately provide results.\n Yeah, that",
      "offset": 2093.2,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "is a a much better way of explaining it",
      "offset": 2096,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "than\n I doubt it's better. I doubt it's",
      "offset": 2098.48,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "better. It's just different because you",
      "offset": 2100.56,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "explained it very very well indeed.",
      "offset": 2101.92,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "Uh you are you are seriously you are",
      "offset": 2104.64,
      "duration": 5.439
    },
    {
      "lang": "en",
      "text": "gifted at explaining this stuff. Um",
      "offset": 2107.28,
      "duration": 7.36
    },
    {
      "lang": "en",
      "text": "nice. So um in a paper written by the by",
      "offset": 2110.079,
      "duration": 8.081
    },
    {
      "lang": "en",
      "text": "the DMLR community members and uh so",
      "offset": 2114.64,
      "duration": 6.959
    },
    {
      "lang": "en",
      "text": "it's it's a paper called DMLR colon",
      "offset": 2118.16,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "datacentric machine learning research",
      "offset": 2121.599,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "past present and future. I'll have a",
      "offset": 2123.44,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "link to that paper in the show notes.",
      "offset": 2125.839,
      "duration": 4.561
    },
    {
      "lang": "en",
      "text": "And I think you were a co-author on this",
      "offset": 2128.48,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "paper. Am I right? Yes, you are. you are",
      "offset": 2130.4,
      "duration": 3.439
    },
    {
      "lang": "en",
      "text": "in fact you're the third author on this",
      "offset": 2132.32,
      "duration": 5.84
    },
    {
      "lang": "en",
      "text": "paper amongst a couple dozen uh and in",
      "offset": 2133.839,
      "duration": 6.881
    },
    {
      "lang": "en",
      "text": "that paper uh it quotes that everyone",
      "offset": 2138.16,
      "duration": 6.16
    },
    {
      "lang": "en",
      "text": "wants to do the model work not the data",
      "offset": 2140.72,
      "duration": 6.399
    },
    {
      "lang": "en",
      "text": "work um so what mindset shifts or",
      "offset": 2144.32,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "incentives do you think are necessary to",
      "offset": 2147.119,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "elevate the perceived value of",
      "offset": 2148.72,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "datacentric contributions in the ML",
      "offset": 2151.44,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "community and uh yeah yeah so that's",
      "offset": 2153.44,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "that's that's more than enough questions",
      "offset": 2156.48,
      "duration": 5.92
    },
    {
      "lang": "en",
      "text": "yeah that's a great question so Um, so",
      "offset": 2158.56,
      "duration": 6.559
    },
    {
      "lang": "en",
      "text": "one of the major challenges when when",
      "offset": 2162.4,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "DMLR was getting off the ground was that",
      "offset": 2165.119,
      "duration": 7.601
    },
    {
      "lang": "en",
      "text": "there were no um really prestigious",
      "offset": 2168,
      "duration": 8.16
    },
    {
      "lang": "en",
      "text": "archival venues for this kind of work,",
      "offset": 2172.72,
      "duration": 6.399
    },
    {
      "lang": "en",
      "text": "right? So um so that's starting to be",
      "offset": 2176.16,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "addressed with the data sets and",
      "offset": 2179.119,
      "duration": 4.801
    },
    {
      "lang": "en",
      "text": "benchmarks track at NURIPS. Uh, and then",
      "offset": 2181.04,
      "duration": 4.799
    },
    {
      "lang": "en",
      "text": "launching the DMLR journal, which by the",
      "offset": 2183.92,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "way is it's the newest sibling journal",
      "offset": 2185.839,
      "duration": 4.801
    },
    {
      "lang": "en",
      "text": "to the JMLR journal, which uh which has",
      "offset": 2187.52,
      "duration": 8.64
    },
    {
      "lang": "en",
      "text": "some yeah uh street cred, but um yeah,",
      "offset": 2190.64,
      "duration": 9.12
    },
    {
      "lang": "en",
      "text": "so so finding or establishing",
      "offset": 2196.16,
      "duration": 7.12
    },
    {
      "lang": "en",
      "text": "uh these high impact prestigious",
      "offset": 2199.76,
      "duration": 5.599
    },
    {
      "lang": "en",
      "text": "venues for publishing this kind of work,",
      "offset": 2203.28,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "I think that goes a long way toward",
      "offset": 2205.359,
      "duration": 4.961
    },
    {
      "lang": "en",
      "text": "encouraging more of the of the",
      "offset": 2208.24,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "datacentric work. uh but we still have a",
      "offset": 2210.32,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "long way to go right I mean it is true I",
      "offset": 2212.8,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "think right 80% of of most data science",
      "offset": 2215.28,
      "duration": 5.839
    },
    {
      "lang": "en",
      "text": "projects are way more about data",
      "offset": 2218.48,
      "duration": 5.119
    },
    {
      "lang": "en",
      "text": "cleaning and data engineering and all of",
      "offset": 2221.119,
      "duration": 5.281
    },
    {
      "lang": "en",
      "text": "that but we really focus on that 20%",
      "offset": 2223.599,
      "duration": 6.081
    },
    {
      "lang": "en",
      "text": "that's iterating on the models um but we",
      "offset": 2226.4,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "don't look at that as a as a fun",
      "offset": 2229.68,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "exciting part so I think we do need to",
      "offset": 2231.44,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "just bring our engineering mindsets how",
      "offset": 2233.2,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "can we systematically improve data how",
      "offset": 2235.839,
      "duration": 6.481
    },
    {
      "lang": "en",
      "text": "can it be a task that goes beyond just",
      "offset": 2238.88,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "uh",
      "offset": 2242.32,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "annotating, finding better ways to",
      "offset": 2244.24,
      "duration": 5.359
    },
    {
      "lang": "en",
      "text": "annotate the data. Um",
      "offset": 2246.56,
      "duration": 4.799
    },
    {
      "lang": "en",
      "text": "all of those things have to happen for",
      "offset": 2249.599,
      "duration": 4.801
    },
    {
      "lang": "en",
      "text": "for it to I think gain even more",
      "offset": 2251.359,
      "duration": 5.521
    },
    {
      "lang": "en",
      "text": "traction than it has. Yeah, it is once",
      "offset": 2254.4,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "you put it in that kind of stark term",
      "offset": 2256.88,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "like we've probably had a hundred guests",
      "offset": 2258.48,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "on the podcast confirm that kind of like",
      "offset": 2260.8,
      "duration": 6.24
    },
    {
      "lang": "en",
      "text": "8020 around 80% of a realworld data",
      "offset": 2262.88,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "science project is spent on data",
      "offset": 2267.04,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "cleaning and 20% is actually on model",
      "offset": 2268.4,
      "duration": 5.439
    },
    {
      "lang": "en",
      "text": "building and it's so interesting that",
      "offset": 2271.119,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "when you think about that ratio",
      "offset": 2273.839,
      "duration": 6.081
    },
    {
      "lang": "en",
      "text": "how little there is on on that 80 how",
      "offset": 2277.119,
      "duration": 5.201
    },
    {
      "lang": "en",
      "text": "little there is published on that 80%.",
      "offset": 2279.92,
      "duration": 5.439
    },
    {
      "lang": "en",
      "text": "It should be most DMLR should be most of",
      "offset": 2282.32,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "it.\n Right. Right. Well, I agree with you",
      "offset": 2285.359,
      "duration": 4.801
    },
    {
      "lang": "en",
      "text": "on that one.\n I I guess what ends up",
      "offset": 2287.76,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "happening is I'm This is me just",
      "offset": 2290.16,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "completely riffing and I'd love to hear",
      "offset": 2292.16,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "what you think about this, but I guess",
      "offset": 2294,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "what ends up happening perhaps is that",
      "offset": 2295.28,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "people might feel when they're doing",
      "offset": 2298.72,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "that work that the problems that they're",
      "offset": 2300.64,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "encountering are unique to their",
      "offset": 2302.48,
      "duration": 5.92
    },
    {
      "lang": "en",
      "text": "particular data set. they don't maybe",
      "offset": 2305.52,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "maybe ideas don't come to mind for them",
      "offset": 2308.4,
      "duration": 5.439
    },
    {
      "lang": "en",
      "text": "that generalize well across uh many",
      "offset": 2310.72,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "domains or even within you know their",
      "offset": 2313.839,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "subject matter uh that that they're",
      "offset": 2315.52,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "expert in. So yeah, what do you think",
      "offset": 2318,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "about that? What are some of the what",
      "offset": 2321.2,
      "duration": 4.879
    },
    {
      "lang": "en",
      "text": "are some of the big trends or big themes",
      "offset": 2322.88,
      "duration": 7.68
    },
    {
      "lang": "en",
      "text": "that you see in DMLR that um yeah kind",
      "offset": 2326.079,
      "duration": 7.121
    },
    {
      "lang": "en",
      "text": "of apply broadly into a large range of",
      "offset": 2330.56,
      "duration": 6.08
    },
    {
      "lang": "en",
      "text": "circumstances?\n Yeah. So I'll go back to",
      "offset": 2333.2,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "data perf right because we we were",
      "offset": 2336.64,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "aiming to establish this benchmark suite",
      "offset": 2338.88,
      "duration": 6.239
    },
    {
      "lang": "en",
      "text": "benchmarks pushed model centric machine",
      "offset": 2341.68,
      "duration": 6.56
    },
    {
      "lang": "en",
      "text": "learning uh pretty far. So we were",
      "offset": 2345.119,
      "duration": 6.24
    },
    {
      "lang": "en",
      "text": "hoping that we could push datacentric ML",
      "offset": 2348.24,
      "duration": 5.359
    },
    {
      "lang": "en",
      "text": "further along by establishing benchmarks",
      "offset": 2351.359,
      "duration": 6.561
    },
    {
      "lang": "en",
      "text": "there. To be honest we have uh I don't",
      "offset": 2353.599,
      "duration": 6.24
    },
    {
      "lang": "en",
      "text": "know how I don't know how far we really",
      "offset": 2357.92,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "made it but it was it was an interesting",
      "offset": 2359.839,
      "duration": 5.041
    },
    {
      "lang": "en",
      "text": "endeavor. uh and we focused on a few",
      "offset": 2361.839,
      "duration": 6.881
    },
    {
      "lang": "en",
      "text": "different types of tasks. So one was",
      "offset": 2364.88,
      "duration": 6.64
    },
    {
      "lang": "en",
      "text": "data selection. So from a very large",
      "offset": 2368.72,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "pool of data, how do you select the",
      "offset": 2371.52,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "subset of data to train the highest",
      "offset": 2373.76,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "performing model? Uh and we did that in",
      "offset": 2376.32,
      "duration": 6.4
    },
    {
      "lang": "en",
      "text": "both the speech and the vision domains.",
      "offset": 2379.28,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "Um so that was one that was one",
      "offset": 2382.72,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "challenge uh and benchmark. Then we had",
      "offset": 2384.72,
      "duration": 6.639
    },
    {
      "lang": "en",
      "text": "a data debugging challenge where um",
      "offset": 2388,
      "duration": 7.839
    },
    {
      "lang": "en",
      "text": "where participants were um",
      "offset": 2391.359,
      "duration": 8.48
    },
    {
      "lang": "en",
      "text": "encouraged to find the mislabeled",
      "offset": 2395.839,
      "duration": 6.721
    },
    {
      "lang": "en",
      "text": "data points, the mislabeled instances in",
      "offset": 2399.839,
      "duration": 6.401
    },
    {
      "lang": "en",
      "text": "a in a data set and you know correct the",
      "offset": 2402.56,
      "duration": 6.48
    },
    {
      "lang": "en",
      "text": "labels or exclude them from training. Um",
      "offset": 2406.24,
      "duration": 6.32
    },
    {
      "lang": "en",
      "text": "so I think that has pretty broad broad",
      "offset": 2409.04,
      "duration": 6.4
    },
    {
      "lang": "en",
      "text": "application right anytime you're doing",
      "offset": 2412.56,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "supervised learning if you have if you",
      "offset": 2415.44,
      "duration": 6.639
    },
    {
      "lang": "en",
      "text": "have um mislabeled data then then that's",
      "offset": 2418,
      "duration": 6.48
    },
    {
      "lang": "en",
      "text": "going to be pretty practical. Uh and",
      "offset": 2422.079,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "then we also did a data valuation",
      "offset": 2424.48,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "challenge. So, how do you how do you",
      "offset": 2427.119,
      "duration": 7.441
    },
    {
      "lang": "en",
      "text": "value each piece of data, right? Not not",
      "offset": 2430.16,
      "duration": 7.919
    },
    {
      "lang": "en",
      "text": "or yeah, not all",
      "offset": 2434.56,
      "duration": 6.24
    },
    {
      "lang": "en",
      "text": "data are equal when you're training a",
      "offset": 2438.079,
      "duration": 6.081
    },
    {
      "lang": "en",
      "text": "model. Some have much more impact than",
      "offset": 2440.8,
      "duration": 7.92
    },
    {
      "lang": "en",
      "text": "others, right? Um, so we so we looked at",
      "offset": 2444.16,
      "duration": 6.88
    },
    {
      "lang": "en",
      "text": "that and that's a whole really",
      "offset": 2448.72,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "interesting",
      "offset": 2451.04,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "area of datacentric machine learning",
      "offset": 2452.8,
      "duration": 5.039
    },
    {
      "lang": "en",
      "text": "research that I didn't know anything",
      "offset": 2456,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "about until I joined DMLR. Uh, but yeah,",
      "offset": 2457.839,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "but there are all these different ways",
      "offset": 2460.96,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "to to estimate the value of certain data",
      "offset": 2462.24,
      "duration": 6.96
    },
    {
      "lang": "en",
      "text": "points. Um, and that might become",
      "offset": 2465.52,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "increasingly important as we try to",
      "offset": 2469.2,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "figure out how to compensate people for",
      "offset": 2471.04,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "all the data that we're using to train",
      "offset": 2472.88,
      "duration": 6.16
    },
    {
      "lang": "en",
      "text": "all these all these models. Um, and then",
      "offset": 2475.28,
      "duration": 7.2
    },
    {
      "lang": "en",
      "text": "we had a red teaming challenge called",
      "offset": 2479.04,
      "duration": 8.52
    },
    {
      "lang": "en",
      "text": "adversarial nibbler where",
      "offset": 2482.48,
      "duration": 5.08
    },
    {
      "lang": "en",
      "text": "you know the reference.\n Uh, is it",
      "offset": 2488.72,
      "duration": 6.32
    },
    {
      "lang": "en",
      "text": "Futurama?\n Yeah. Yeah. Yeah.\n That's",
      "offset": 2491.68,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "funny. I didn't actually think that",
      "offset": 2495.04,
      "duration": 2.72
    },
    {
      "lang": "en",
      "text": "there would be a reference until you",
      "offset": 2496.48,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "asked for one, but yeah, fortunately, I",
      "offset": 2497.76,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "have seen quite a few episodes of",
      "offset": 2500.72,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "Futurama.\n Cool. Well, I did not come up",
      "offset": 2502,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "with the name. I can't take credit",
      "offset": 2504.16,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "there, but um but yeah, but the main",
      "offset": 2505.44,
      "duration": 5.919
    },
    {
      "lang": "en",
      "text": "objective of that challenge was to find",
      "offset": 2508.079,
      "duration": 6.961
    },
    {
      "lang": "en",
      "text": "benign sounding prompts that generated",
      "offset": 2511.359,
      "duration": 6.641
    },
    {
      "lang": "en",
      "text": "unsafe images. So for example, a child",
      "offset": 2515.04,
      "duration": 7.76
    },
    {
      "lang": "en",
      "text": "sleeping in red paint sounds benign um",
      "offset": 2518,
      "duration": 7.04
    },
    {
      "lang": "en",
      "text": "but generates an image that looks",
      "offset": 2522.8,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "horrific, right? So um so the challenge",
      "offset": 2525.04,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "was all about finding these pairs, these",
      "offset": 2527.44,
      "duration": 6.8
    },
    {
      "lang": "en",
      "text": "text image pairs um for use in in then",
      "offset": 2529.92,
      "duration": 6.32
    },
    {
      "lang": "en",
      "text": "helping to make these models more robust",
      "offset": 2534.24,
      "duration": 4.879
    },
    {
      "lang": "en",
      "text": "and and all of that.\n Wow, what a visual.",
      "offset": 2536.24,
      "duration": 6.8
    },
    {
      "lang": "en",
      "text": "A child sleeping in red paint.",
      "offset": 2539.119,
      "duration": 6.801
    },
    {
      "lang": "en",
      "text": "Yeah, that is interesting. and just a",
      "offset": 2543.04,
      "duration": 4.799
    },
    {
      "lang": "en",
      "text": "little red paint puddle that just",
      "offset": 2545.92,
      "duration": 6.399
    },
    {
      "lang": "en",
      "text": "happens to be on the floor. Um",
      "offset": 2547.839,
      "duration": 7.28
    },
    {
      "lang": "en",
      "text": "um so yeah, so there's so I've I'll have",
      "offset": 2552.319,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "links in the show notes to dataperf.org",
      "offset": 2555.119,
      "duration": 5.281
    },
    {
      "lang": "en",
      "text": "which I'm guessing stands for data",
      "offset": 2558.079,
      "duration": 5.681
    },
    {
      "lang": "en",
      "text": "perfect maybe\n data performance\n data",
      "offset": 2560.4,
      "duration": 7.84
    },
    {
      "lang": "en",
      "text": "performance ah of course\n but uh but that",
      "offset": 2563.76,
      "duration": 7.68
    },
    {
      "lang": "en",
      "text": "site is super outdated just mlcoms and",
      "offset": 2568.24,
      "duration": 5.359
    },
    {
      "lang": "en",
      "text": "then dabbench.org org is the platform",
      "offset": 2571.44,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "where we host all of these challenges",
      "offset": 2573.599,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "and that's that's\n DAB that's like",
      "offset": 2575.28,
      "duration": 5.839
    },
    {
      "lang": "en",
      "text": "dynamic bench.\n Yeah. Yeah. So that's um",
      "offset": 2577.76,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "a platform that we've used to facilitate",
      "offset": 2581.119,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "a lot of these datacentric challenges",
      "offset": 2583.28,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "and that's still maintained by ML",
      "offset": 2585.28,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "comments and um and if you're interested",
      "offset": 2587.28,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "in that that same DMLR working group",
      "offset": 2589.52,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "that I mentioned before uh we we",
      "offset": 2591.599,
      "duration": 6.161
    },
    {
      "lang": "en",
      "text": "maintain Dynabench and and uh continue",
      "offset": 2594.56,
      "duration": 7.12
    },
    {
      "lang": "en",
      "text": "to host challenges on DAB.\n Nice. Um and",
      "offset": 2597.76,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "yeah so and then I'll also have a link",
      "offset": 2601.68,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "to your paper another so I already",
      "offset": 2603.2,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "mentioned the DMLR past present and",
      "offset": 2606,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "future paper we'll also have a link in",
      "offset": 2608.64,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "the show notes to your data PF paper uh",
      "offset": 2611.04,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "which is on benchmarks for datacentric",
      "offset": 2613.44,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "AI development and that one uh you're",
      "offset": 2615.119,
      "duration": 5.041
    },
    {
      "lang": "en",
      "text": "just a couple commas away from Andrew",
      "offset": 2618.56,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "Ang in the uh in the authors of that",
      "offset": 2620.16,
      "duration": 6.08
    },
    {
      "lang": "en",
      "text": "paper there um cool so those are",
      "offset": 2623.28,
      "duration": 5.039
    },
    {
      "lang": "en",
      "text": "resources that people can dig into",
      "offset": 2626.24,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "deeply if they have more interest in",
      "offset": 2628.319,
      "duration": 4.641
    },
    {
      "lang": "en",
      "text": "datacentric machine learning which",
      "offset": 2631.44,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "probably all of us should given that",
      "offset": 2632.96,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "80%.\n There is probably a lot of value to",
      "offset": 2634.8,
      "duration": 6.799
    },
    {
      "lang": "en",
      "text": "people sharing domain specific solutions",
      "offset": 2638.4,
      "duration": 5.919
    },
    {
      "lang": "en",
      "text": "because it might inspire people to find",
      "offset": 2641.599,
      "duration": 4.881
    },
    {
      "lang": "en",
      "text": "some new domain specific solution for",
      "offset": 2644.319,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "their domain. Um, and one of the things",
      "offset": 2646.48,
      "duration": 5.839
    },
    {
      "lang": "en",
      "text": "actually we're one of the future",
      "offset": 2649.839,
      "duration": 4.881
    },
    {
      "lang": "en",
      "text": "workshops we're considering is an",
      "offset": 2652.319,
      "duration": 4.881
    },
    {
      "lang": "en",
      "text": "applications research focused DMLR",
      "offset": 2654.72,
      "duration": 6.08
    },
    {
      "lang": "en",
      "text": "workshop because oftentimes",
      "offset": 2657.2,
      "duration": 7.04
    },
    {
      "lang": "en",
      "text": "uh at these academic conferences",
      "offset": 2660.8,
      "duration": 6.08
    },
    {
      "lang": "en",
      "text": "applications research gets looked down",
      "offset": 2664.24,
      "duration": 5.92
    },
    {
      "lang": "en",
      "text": "on a little bit. Uh, and we do think",
      "offset": 2666.88,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "that there's more more need to ground",
      "offset": 2670.16,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "everything in really practical use",
      "offset": 2672.48,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "cases. And we're sure that there's going",
      "offset": 2674.56,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "to be a lot of really interesting",
      "offset": 2676.72,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "research that is domain specific that",
      "offset": 2678.4,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "different people can can learn from. So",
      "offset": 2680.88,
      "duration": 4.479
    },
    {
      "lang": "en",
      "text": "that is um something that we're we're",
      "offset": 2683.2,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "hoping to undertake in the future.\n Very",
      "offset": 2685.359,
      "duration": 7.281
    },
    {
      "lang": "en",
      "text": "nice. And yeah, uh, not only would it be",
      "offset": 2688.96,
      "duration": 5.359
    },
    {
      "lang": "en",
      "text": "great for people to be publishing more",
      "offset": 2692.64,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "on the kinds of situations that they get",
      "offset": 2694.319,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "to with their specific domain, much in",
      "offset": 2696.56,
      "duration": 3.519
    },
    {
      "lang": "en",
      "text": "the same way that us at the beginning of",
      "offset": 2698.64,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "this episode talking about legal tech,",
      "offset": 2700.079,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "AI applications, uh, you know, people",
      "offset": 2702.72,
      "duration": 4.879
    },
    {
      "lang": "en",
      "text": "can have, uh, analogous ideas come up",
      "offset": 2705.359,
      "duration": 7.041
    },
    {
      "lang": "en",
      "text": "for their industry. And not only that um",
      "offset": 2707.599,
      "duration": 8.881
    },
    {
      "lang": "en",
      "text": "but um you could end up having I I I",
      "offset": 2712.4,
      "duration": 6.719
    },
    {
      "lang": "en",
      "text": "totally see the idea of of how",
      "offset": 2716.48,
      "duration": 5.599
    },
    {
      "lang": "en",
      "text": "benchmarks and competition have led us",
      "offset": 2719.119,
      "duration": 5.761
    },
    {
      "lang": "en",
      "text": "to having such a model ccentric approach",
      "offset": 2722.079,
      "duration": 4.961
    },
    {
      "lang": "en",
      "text": "to machine learning. And so things like",
      "offset": 2724.88,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "dataf where you have benchmarks where",
      "offset": 2727.04,
      "duration": 4.559
    },
    {
      "lang": "en",
      "text": "you have competitions and people can be",
      "offset": 2729.52,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "trying to to get the best results how",
      "offset": 2731.599,
      "duration": 5.281
    },
    {
      "lang": "en",
      "text": "that can drive more and more datacentric",
      "offset": 2733.92,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "ML adoption. It's a brilliant",
      "offset": 2736.88,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "initiative.\n Yeah. And at the same time,",
      "offset": 2738.72,
      "duration": 4.879
    },
    {
      "lang": "en",
      "text": "I think I think we can be critical of it",
      "offset": 2741.04,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "too because there is the critique that",
      "offset": 2743.599,
      "duration": 6.72
    },
    {
      "lang": "en",
      "text": "uh the intense focus on benchmark",
      "offset": 2747.04,
      "duration": 4.799
    },
    {
      "lang": "en",
      "text": "performance",
      "offset": 2750.319,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "doesn't necessarily translate to real",
      "offset": 2751.839,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "world impact in the way that we would",
      "offset": 2754,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "expect. So there's definitely a a",
      "offset": 2755.599,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "balance to be found there.\n Nicely said",
      "offset": 2758.4,
      "duration": 5.199
    },
    {
      "lang": "en",
      "text": "as you have done throughout the episode.",
      "offset": 2761.359,
      "duration": 6.561
    },
    {
      "lang": "en",
      "text": "Uh all right. Um, so",
      "offset": 2763.599,
      "duration": 7.121
    },
    {
      "lang": "en",
      "text": "before I let you go there, you know, we",
      "offset": 2767.92,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "we we've gone through kind of the most",
      "offset": 2770.72,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "exciting technical things that you're",
      "offset": 2772.48,
      "duration": 4.639
    },
    {
      "lang": "en",
      "text": "working on today, but you have an",
      "offset": 2774.88,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "interesting background that I'd like to",
      "offset": 2777.119,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "ask you at least one question about to",
      "offset": 2778.48,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "kind of get into. So just going over",
      "offset": 2780.8,
      "duration": 6.48
    },
    {
      "lang": "en",
      "text": "your LinkedIn profile, it looks like you",
      "offset": 2783.52,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "had a pretty interesting journey where",
      "offset": 2787.28,
      "duration": 2.88
    },
    {
      "lang": "en",
      "text": "there was actually there was a point",
      "offset": 2788.64,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "where you were an administrative",
      "offset": 2790.16,
      "duration": 2.88
    },
    {
      "lang": "en",
      "text": "assistant at the beginning of your",
      "offset": 2791.68,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "career and it looks like you kind of",
      "offset": 2793.04,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "grew through legal roles, you know,",
      "offset": 2795.44,
      "duration": 6.08
    },
    {
      "lang": "en",
      "text": "increasing seniority within legal firms",
      "offset": 2798.72,
      "duration": 6.96
    },
    {
      "lang": "en",
      "text": "and then uh yeah got you know got into",
      "offset": 2801.52,
      "duration": 6.319
    },
    {
      "lang": "en",
      "text": "data science as well and now you are a",
      "offset": 2805.68,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "data science leader. Um so you know I",
      "offset": 2807.839,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "think this is an interesting journey and",
      "offset": 2810.4,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "I'd love to hear just a bit about what",
      "offset": 2812.16,
      "duration": 6.72
    },
    {
      "lang": "en",
      "text": "happened.\n Yeah. Yeah. So I I fell into",
      "offset": 2814.48,
      "duration": 6.8
    },
    {
      "lang": "en",
      "text": "eiscocovery as an admin assistant",
      "offset": 2818.88,
      "duration": 4.239
    },
    {
      "lang": "en",
      "text": "basically as a temp receptionist",
      "offset": 2821.28,
      "duration": 6.24
    },
    {
      "lang": "en",
      "text": "actually. Um and uh and that was how I",
      "offset": 2823.119,
      "duration": 6.081
    },
    {
      "lang": "en",
      "text": "started my career. I was still finishing",
      "offset": 2827.52,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "my undergrad at the time. Uh and then at",
      "offset": 2829.2,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "the same time that I was getting really",
      "offset": 2831.92,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "familiar with eiscocovery and developing",
      "offset": 2834.48,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "my domain expertise there, I fell in",
      "offset": 2836.24,
      "duration": 7.04
    },
    {
      "lang": "en",
      "text": "love with statistics. So I I took my",
      "offset": 2839.2,
      "duration": 7.6
    },
    {
      "lang": "en",
      "text": "first stats course and I got an A in it.",
      "offset": 2843.28,
      "duration": 7.12
    },
    {
      "lang": "en",
      "text": "And um and I I didn't feel like I",
      "offset": 2846.8,
      "duration": 6.72
    },
    {
      "lang": "en",
      "text": "understood how or why I got an A because",
      "offset": 2850.4,
      "duration": 6.08
    },
    {
      "lang": "en",
      "text": "I I didn't understand I mean I could",
      "offset": 2853.52,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "calculate the correct answers but I",
      "offset": 2856.48,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "didn't have this intuitive understanding",
      "offset": 2858.64,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "for why they were the correct answers.",
      "offset": 2860.72,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "So I figured okay let me take more stats",
      "offset": 2863.52,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "courses. And I I took all the ones that",
      "offset": 2866.16,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "made sense for me at the time. I took",
      "offset": 2868.24,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "econometrics, psychometrics,",
      "offset": 2870,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "uh various finance courses with",
      "offset": 2872.4,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "portfolio theory. That's where I learned",
      "offset": 2874.319,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "PCA.",
      "offset": 2876,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "Um, yeah. So, I I took all these applied",
      "offset": 2877.839,
      "duration": 5.841
    },
    {
      "lang": "en",
      "text": "stats courses and I kept getting A's,",
      "offset": 2880.8,
      "duration": 7.279
    },
    {
      "lang": "en",
      "text": "but after each one, I had no idea how I",
      "offset": 2883.68,
      "duration": 6.96
    },
    {
      "lang": "en",
      "text": "was deserving of an A when I when I",
      "offset": 2888.079,
      "duration": 4.801
    },
    {
      "lang": "en",
      "text": "still felt like I didn't understand the",
      "offset": 2890.64,
      "duration": 6.719
    },
    {
      "lang": "en",
      "text": "material at all. Um, so finally I I",
      "offset": 2892.88,
      "duration": 8.4
    },
    {
      "lang": "en",
      "text": "asked a um I asked the chair of the",
      "offset": 2897.359,
      "duration": 6.48
    },
    {
      "lang": "en",
      "text": "statistics department at Northwestern if",
      "offset": 2901.28,
      "duration": 4.559
    },
    {
      "lang": "en",
      "text": "I could take his probability and",
      "offset": 2903.839,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "stochcastic processes course without any",
      "offset": 2905.839,
      "duration": 4.801
    },
    {
      "lang": "en",
      "text": "of the prerequisites, right? And I and I",
      "offset": 2907.92,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "wrote him uh you know saying, &quot;Okay, I",
      "offset": 2910.64,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "know this is going to sound crazy, but",
      "offset": 2913.28,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "here's why I think I can do it.&quot; H and",
      "offset": 2914.8,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "I'll never forget his reply. He wrote,",
      "offset": 2917.119,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "&quot;Dear Lilith, anything is possible, but",
      "offset": 2919.28,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "of course, I would have serious",
      "offset": 2922.079,
      "duration": 2.961
    },
    {
      "lang": "en",
      "text": "reservations about letting you enroll",
      "offset": 2923.28,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "without any of the prerequisites at all.",
      "offset": 2925.04,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "Write me back in a year. Let's see if",
      "offset": 2927.28,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "you really have picked up calculus",
      "offset": 2928.96,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "before I consider this seriously.&quot; So, I",
      "offset": 2930.64,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "did. I crammed. I crammed for a year. I,",
      "offset": 2933.28,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "you know, used MIT Open Courseware and",
      "offset": 2936.4,
      "duration": 5.199
    },
    {
      "lang": "en",
      "text": "Con Academy and everything out there to",
      "offset": 2939.28,
      "duration": 6.24
    },
    {
      "lang": "en",
      "text": "just learn calculus on my own. Um, a",
      "offset": 2941.599,
      "duration": 6.48
    },
    {
      "lang": "en",
      "text": "little bit of linear algebra. And then I",
      "offset": 2945.52,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "came back to him and I said, &quot;Okay,",
      "offset": 2948.079,
      "duration": 2.961
    },
    {
      "lang": "en",
      "text": "well, I didn't get as far as I as I",
      "offset": 2949.28,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "wanted to, uh, but",
      "offset": 2951.04,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "um,",
      "offset": 2954.24,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "I I you know, I think I I still want to",
      "offset": 2955.92,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "take your course.&quot; So, he said, &quot;Go",
      "offset": 2958.48,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "ahead.&quot; He sent me the textbook. It was",
      "offset": 2960.319,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "a PDF. It was the first real math",
      "offset": 2962.319,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "textbook I'd ever come across. It was",
      "offset": 2964.48,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "just uh no images or anything. Just",
      "offset": 2966.48,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "coding problems. That's how I learned",
      "offset": 2969.92,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "how to code, right? Um, and uh, and and",
      "offset": 2971.44,
      "duration": 7.36
    },
    {
      "lang": "en",
      "text": "math problems. and I crammed and I got",
      "offset": 2974.96,
      "duration": 6.399
    },
    {
      "lang": "en",
      "text": "an A on the finals. So, and then I",
      "offset": 2978.8,
      "duration": 4.559
    },
    {
      "lang": "en",
      "text": "finally felt like I understood",
      "offset": 2981.359,
      "duration": 4.641
    },
    {
      "lang": "en",
      "text": "statistics. Uh, and then since then it's",
      "offset": 2983.359,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "just been a lot of self-education and",
      "offset": 2986,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "diving really deep into all the",
      "offset": 2988.559,
      "duration": 3.121
    },
    {
      "lang": "en",
      "text": "different flavors of confidence",
      "offset": 2990.319,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "intervals you can you can use. Uh,",
      "offset": 2991.68,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "really understanding, right, what",
      "offset": 2994.319,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "probability coverage means from from",
      "offset": 2995.839,
      "duration": 5.201
    },
    {
      "lang": "en",
      "text": "that angle and just nerding out on the",
      "offset": 2998.4,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "stuff I find most interesting.\n Very",
      "offset": 3001.04,
      "duration": 4.559
    },
    {
      "lang": "en",
      "text": "interesting indeed. That was an even",
      "offset": 3003.52,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "more exciting story than I was",
      "offset": 3005.599,
      "duration": 3.281
    },
    {
      "lang": "en",
      "text": "anticipating. And it does it's",
      "offset": 3006.96,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "interesting that I mentioned cuz I had I",
      "offset": 3008.88,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "don't talk about that often anymore in",
      "offset": 3011.04,
      "duration": 2.16
    },
    {
      "lang": "en",
      "text": "my machine learning foundations",
      "offset": 3012.16,
      "duration": 2.959
    },
    {
      "lang": "en",
      "text": "curriculum, but it's covering a lot of",
      "offset": 3013.2,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "those subjects. Linear algebra,",
      "offset": 3015.119,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "calculus, probability theory, and",
      "offset": 3016.4,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "statistics",
      "offset": 3018.96,
      "duration": 4.879
    },
    {
      "lang": "en",
      "text": "and we go in that order. Um so that",
      "offset": 3020.64,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "hopefully by the time we get to the",
      "offset": 3023.839,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "statistics part uh you know you're able",
      "offset": 3025.2,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "to to to understand based on the the",
      "offset": 3027.839,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "fundamental building blocks underlying",
      "offset": 3030.48,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "it what's going on as opposed to just",
      "offset": 3031.92,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "being able to get an A by you know",
      "offset": 3034.48,
      "duration": 5.119
    },
    {
      "lang": "en",
      "text": "following the examples. Um not by wrote",
      "offset": 3036.96,
      "duration": 6.08
    },
    {
      "lang": "en",
      "text": "that's not exactly it but uh by kind of",
      "offset": 3039.599,
      "duration": 5.921
    },
    {
      "lang": "en",
      "text": "uh I guess by being able to apply the",
      "offset": 3043.04,
      "duration": 5.279
    },
    {
      "lang": "en",
      "text": "abstractions as opposed to you know",
      "offset": 3045.52,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "understand the underlying fundamentals.",
      "offset": 3048.319,
      "duration": 5.441
    },
    {
      "lang": "en",
      "text": "Um, and it is kind of interesting like I",
      "offset": 3050.96,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "guess I also you were very excited you",
      "offset": 3053.76,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "know you said I fell in love with",
      "offset": 3056.64,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "statistics and it's interesting because",
      "offset": 3057.839,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "I you know in a machine learning",
      "offset": 3059.68,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "foundation's curriculum I don't really",
      "offset": 3061.92,
      "duration": 5.439
    },
    {
      "lang": "en",
      "text": "need to include statistics. It's not",
      "offset": 3064.72,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "like some many people would argue it's",
      "offset": 3067.359,
      "duration": 5.521
    },
    {
      "lang": "en",
      "text": "not essential, but I also love",
      "offset": 3070,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "statistics and it ends up being useful",
      "offset": 3072.88,
      "duration": 4.959
    },
    {
      "lang": "en",
      "text": "in so many ways, particularly around",
      "offset": 3075.52,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "exactly what you described earlier in",
      "offset": 3077.839,
      "duration": 5.121
    },
    {
      "lang": "en",
      "text": "this episode around being able to um",
      "offset": 3079.359,
      "duration": 6.641
    },
    {
      "lang": "en",
      "text": "think of results that we have as being",
      "offset": 3082.96,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "over a range as opposed, you know, as as",
      "offset": 3086,
      "duration": 4.559
    },
    {
      "lang": "en",
      "text": "having a confidence interval as opposed",
      "offset": 3088.72,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "to being a point estimate. And it's",
      "offset": 3090.559,
      "duration": 3.121
    },
    {
      "lang": "en",
      "text": "through statistics that I feel like I",
      "offset": 3092.48,
      "duration": 2.4
    },
    {
      "lang": "en",
      "text": "have a really good understanding of what",
      "offset": 3093.68,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "those confidence intervals are.\n Yeah.",
      "offset": 3094.88,
      "duration": 4.719
    },
    {
      "lang": "en",
      "text": "And I think you're not if you don't",
      "offset": 3097.04,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "understand statistics, I don't think",
      "offset": 3099.599,
      "duration": 4.801
    },
    {
      "lang": "en",
      "text": "you're able to properly evaluate the",
      "offset": 3101.76,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "performance of the models that you're",
      "offset": 3104.4,
      "duration": 2.88
    },
    {
      "lang": "en",
      "text": "building. So you might be able to build",
      "offset": 3106.079,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "the model without statistics, but I",
      "offset": 3107.28,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "think especially in this era of blackbox",
      "offset": 3109.839,
      "duration": 6.321
    },
    {
      "lang": "en",
      "text": "models, it's so important to be able to",
      "offset": 3112.88,
      "duration": 5.92
    },
    {
      "lang": "en",
      "text": "to actually evaluate the performance of",
      "offset": 3116.16,
      "duration": 4.959
    },
    {
      "lang": "en",
      "text": "them. And that is exactly that ended up",
      "offset": 3118.8,
      "duration": 4.559
    },
    {
      "lang": "en",
      "text": "being the focus like when I I would try",
      "offset": 3121.119,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "to come up with relevant examples during",
      "offset": 3123.359,
      "duration": 4.641
    },
    {
      "lang": "en",
      "text": "the statistics section. Uh and a lot of",
      "offset": 3125.2,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "the time it was in exactly what you're",
      "offset": 3128,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "describing about evaluating different",
      "offset": 3129.68,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "models and being able to you know not",
      "offset": 3131.28,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "just you know run a model once a",
      "offset": 3133.2,
      "duration": 7.04
    },
    {
      "lang": "en",
      "text": "stochastic model once uh one way and a",
      "offset": 3136.72,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "second time another way and be like well",
      "offset": 3140.24,
      "duration": 3.359
    },
    {
      "lang": "en",
      "text": "I'm done. It did better the second time",
      "offset": 3142,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "and therefore the second model is",
      "offset": 3143.599,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "better. like you should be running that",
      "offset": 3145.2,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "model a bunch of times in both the A",
      "offset": 3147.28,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "case and the B case. Uh get a",
      "offset": 3150.48,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "distribution of results uh and be",
      "offset": 3152.72,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "comparing those and then if you have a",
      "offset": 3155.68,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "statistically significant result um and",
      "offset": 3157.68,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "that is actually something uh",
      "offset": 3161.04,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "statistical significance came up in our",
      "offset": 3162.64,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "research of you. So Serge Msiz our",
      "offset": 3164.4,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "researcher pulled up some quotes from",
      "offset": 3166,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "you around how uh how awful it you know",
      "offset": 3167.76,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "these kinds of ideas of a 95% confidence",
      "offset": 3170.48,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "interval having that as law. Uh I don't",
      "offset": 3172.48,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "know if you want to go into that at all,",
      "offset": 3174.559,
      "duration": 5.201
    },
    {
      "lang": "en",
      "text": "that kind of perspective.\n Sure. Sure. Um",
      "offset": 3175.92,
      "duration": 6.399
    },
    {
      "lang": "en",
      "text": "you mean just being fixated on it being",
      "offset": 3179.76,
      "duration": 5.599
    },
    {
      "lang": "en",
      "text": "a 95% confidence?\n Yeah. like if an alpha",
      "offset": 3182.319,
      "duration": 6.721
    },
    {
      "lang": "en",
      "text": "of 0.5 being the significance threshold",
      "offset": 3185.359,
      "duration": 5.361
    },
    {
      "lang": "en",
      "text": "you know kind of arbitrarily from the",
      "offset": 3189.04,
      "duration": 4.559
    },
    {
      "lang": "en",
      "text": "early 20th century uh which particularly",
      "offset": 3190.72,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "today when we have very large data sets",
      "offset": 3193.599,
      "duration": 4.881
    },
    {
      "lang": "en",
      "text": "you know when we had data sets when when",
      "offset": 3196.72,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "our sample sizes were eight 16 uh in",
      "offset": 3198.48,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "each group that kind of that arbitrary",
      "offset": 3202,
      "duration": 7.76
    },
    {
      "lang": "en",
      "text": "confidence threshold um of of uh and you",
      "offset": 3204.48,
      "duration": 6.56
    },
    {
      "lang": "en",
      "text": "can correct me if I don't say this",
      "offset": 3209.76,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "exactly right I'll do my best here but",
      "offset": 3211.04,
      "duration": 6.64
    },
    {
      "lang": "en",
      "text": "it's You know that if you if you ran the",
      "offset": 3213.28,
      "duration": 6.16
    },
    {
      "lang": "en",
      "text": "experiment",
      "offset": 3217.68,
      "duration": 6.24
    },
    {
      "lang": "en",
      "text": "uh 20 times, you would anticipate with a",
      "offset": 3219.44,
      "duration": 6.24
    },
    {
      "lang": "en",
      "text": "0.5",
      "offset": 3223.92,
      "duration": 5.679
    },
    {
      "lang": "en",
      "text": "uh uh alpha that one of those 20 times",
      "offset": 3225.68,
      "duration": 6.24
    },
    {
      "lang": "en",
      "text": "you would get a significant result by",
      "offset": 3229.599,
      "duration": 5.841
    },
    {
      "lang": "en",
      "text": "chance alone. And and this is like a",
      "offset": 3231.92,
      "duration": 5.919
    },
    {
      "lang": "en",
      "text": "century old idea",
      "offset": 3235.44,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "um from the kind of the age of Fischer",
      "offset": 3237.839,
      "duration": 7.52
    },
    {
      "lang": "en",
      "text": "and Pearson in statistics. Um and uh and",
      "offset": 3240.16,
      "duration": 7.12
    },
    {
      "lang": "en",
      "text": "and the idea and and so the idea there",
      "offset": 3245.359,
      "duration": 3.361
    },
    {
      "lang": "en",
      "text": "is that like you're you you'll kind of",
      "offset": 3247.28,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "accept that you're that you know you",
      "offset": 3248.72,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "you'll end up getting a significant",
      "offset": 3251.52,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "result by chance alone one out of 20",
      "offset": 3253.119,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "times and that's kind of tolerable. Uh",
      "offset": 3255.28,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "but it is completely arbitrary and then",
      "offset": 3257.28,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "today when you have thousands or",
      "offset": 3258.8,
      "duration": 6.64
    },
    {
      "lang": "en",
      "text": "millions or billions of samples um",
      "offset": 3261.76,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "you're going to get a significant result",
      "offset": 3265.44,
      "duration": 2.639
    },
    {
      "lang": "en",
      "text": "every single time at that at that kind",
      "offset": 3266.72,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "of threshold.\n Yeah. Yeah. Um, so the way",
      "offset": 3268.079,
      "duration": 4.561
    },
    {
      "lang": "en",
      "text": "that I've described it, and it is one of",
      "offset": 3270.8,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "those things that's really hard to",
      "offset": 3272.64,
      "duration": 4.479
    },
    {
      "lang": "en",
      "text": "explain in plain English, uh, but with",
      "offset": 3274.4,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "with a confidence interval, it's if you",
      "offset": 3277.119,
      "duration": 5.041
    },
    {
      "lang": "en",
      "text": "sampled this population an infinite",
      "offset": 3279.68,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "number of times,",
      "offset": 3282.16,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "you would expect that one out of 20",
      "offset": 3284.24,
      "duration": 4.879
    },
    {
      "lang": "en",
      "text": "times, the point estimate that you",
      "offset": 3286.559,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "arrive at through your sample is not",
      "offset": 3289.119,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "going to be within the estimated",
      "offset": 3292.079,
      "duration": 6.081
    },
    {
      "lang": "en",
      "text": "interval with a with if your",
      "offset": 3294.079,
      "duration": 8.401
    },
    {
      "lang": "en",
      "text": "uh confidence level is 95%. Um",
      "offset": 3298.16,
      "duration": 8.08
    },
    {
      "lang": "en",
      "text": "so yeah so like I mentioned earlier",
      "offset": 3302.48,
      "duration": 7.92
    },
    {
      "lang": "en",
      "text": "whether it's 95% or 99% confidence at a",
      "offset": 3306.24,
      "duration": 6.56
    },
    {
      "lang": "en",
      "text": "certain point those converge right the",
      "offset": 3310.4,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "intervals the intervals for those will",
      "offset": 3312.8,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "converge if you have a sufficiently",
      "offset": 3314.96,
      "duration": 5.599
    },
    {
      "lang": "en",
      "text": "large sample size but by that I mean a",
      "offset": 3316.72,
      "duration": 6.16
    },
    {
      "lang": "en",
      "text": "huge sample size right like you need to",
      "offset": 3320.559,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "be in the millions for them to really",
      "offset": 3322.88,
      "duration": 5.679
    },
    {
      "lang": "en",
      "text": "start to to converge and otherwise it's",
      "offset": 3326.319,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "just um you know smaller smaller",
      "offset": 3328.559,
      "duration": 4.641
    },
    {
      "lang": "en",
      "text": "differences between the the intervals as",
      "offset": 3331.119,
      "duration": 6.881
    },
    {
      "lang": "en",
      "text": "you increase your sample size. Um",
      "offset": 3333.2,
      "duration": 7.119
    },
    {
      "lang": "en",
      "text": "but if your sample size is very small,",
      "offset": 3338,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "if your sample size is as you mentioned,",
      "offset": 3340.319,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "you know, eight or 10, then there's",
      "offset": 3342.88,
      "duration": 4.719
    },
    {
      "lang": "en",
      "text": "actually a a pretty huge difference",
      "offset": 3345.599,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "between the interval that you get using",
      "offset": 3347.599,
      "duration": 6.401
    },
    {
      "lang": "en",
      "text": "95% confidence and 99% confidence. And",
      "offset": 3350.079,
      "duration": 6.881
    },
    {
      "lang": "en",
      "text": "sometimes I think people just I think",
      "offset": 3354,
      "duration": 4.559
    },
    {
      "lang": "en",
      "text": "people just need to think about the",
      "offset": 3356.96,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "question that they're trying to answer.",
      "offset": 3358.559,
      "duration": 6.161
    },
    {
      "lang": "en",
      "text": "So how important is it for me to",
      "offset": 3360.88,
      "duration": 6.8
    },
    {
      "lang": "en",
      "text": "be right about my interval?",
      "offset": 3364.72,
      "duration": 6.16
    },
    {
      "lang": "en",
      "text": "Right? Like it's a h",
      "offset": 3367.68,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "so you're basically trying to answer the",
      "offset": 3370.88,
      "duration": 5.679
    },
    {
      "lang": "en",
      "text": "the question how likely is it that my",
      "offset": 3372.96,
      "duration": 5.599
    },
    {
      "lang": "en",
      "text": "inference is correct? Right? And if you",
      "offset": 3376.559,
      "duration": 6.161
    },
    {
      "lang": "en",
      "text": "have if your inference is is",
      "offset": 3378.559,
      "duration": 7.441
    },
    {
      "lang": "en",
      "text": "conservative, I you have that larger",
      "offset": 3382.72,
      "duration": 6.56
    },
    {
      "lang": "en",
      "text": "interval, then you have you're in a",
      "offset": 3386,
      "duration": 5.839
    },
    {
      "lang": "en",
      "text": "better place to be correct more often,",
      "offset": 3389.28,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "right? Even though your your uncertainty",
      "offset": 3391.839,
      "duration": 4.561
    },
    {
      "lang": "en",
      "text": "is wider, your uncertainty your interval",
      "offset": 3394,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "is wider,",
      "offset": 3396.4,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "um",
      "offset": 3398.16,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "you're still going to be correct about",
      "offset": 3400,
      "duration": 5.359
    },
    {
      "lang": "en",
      "text": "it being in that interval. Whereas if",
      "offset": 3401.76,
      "duration": 5.839
    },
    {
      "lang": "en",
      "text": "you're really focused on that 95%",
      "offset": 3405.359,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "confidence level and you have this",
      "offset": 3407.599,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "really small sample size, then yeah,",
      "offset": 3408.96,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "you're just taking the the you know,",
      "offset": 3411.92,
      "duration": 5.199
    },
    {
      "lang": "en",
      "text": "you're at a higher risk of just",
      "offset": 3414.72,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "estimating something wrong, inferring",
      "offset": 3417.119,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "something wrong from your from your um",
      "offset": 3419.119,
      "duration": 6.161
    },
    {
      "lang": "en",
      "text": "statistic, right? I don't know if I",
      "offset": 3423.119,
      "duration": 4.881
    },
    {
      "lang": "en",
      "text": "don't know if that made sense, but\n that",
      "offset": 3425.28,
      "duration": 5.039
    },
    {
      "lang": "en",
      "text": "was pretty good. It is tricky and uh",
      "offset": 3428,
      "duration": 5.599
    },
    {
      "lang": "en",
      "text": "yeah, I followed along there. Um nice.",
      "offset": 3430.319,
      "duration": 4.881
    },
    {
      "lang": "en",
      "text": "All right. So, this has been a",
      "offset": 3433.599,
      "duration": 3.281
    },
    {
      "lang": "en",
      "text": "fascinating conversation. I knew it",
      "offset": 3435.2,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "would be. Uh, you did not disappoint.",
      "offset": 3436.88,
      "duration": 7.439
    },
    {
      "lang": "en",
      "text": "Um, for people who want to follow you uh",
      "offset": 3439.28,
      "duration": 6.72
    },
    {
      "lang": "en",
      "text": "after the episode and get more of your",
      "offset": 3444.319,
      "duration": 3.441
    },
    {
      "lang": "en",
      "text": "insights, how should they do that?",
      "offset": 3446,
      "duration": 4.799
    },
    {
      "lang": "en",
      "text": "LinkedIn is the best place for me.\n Nice.",
      "offset": 3447.76,
      "duration": 5.359
    },
    {
      "lang": "en",
      "text": "as it is for most guests these days.",
      "offset": 3450.799,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "I've actually I don't know if I've said",
      "offset": 3453.119,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "this explicitly uh on air before, but",
      "offset": 3454.4,
      "duration": 6.159
    },
    {
      "lang": "en",
      "text": "I've actually I've stopped tweeting.",
      "offset": 3457.04,
      "duration": 8.079
    },
    {
      "lang": "en",
      "text": "Uh and I don't really check uh X anymore",
      "offset": 3460.559,
      "duration": 8.081
    },
    {
      "lang": "en",
      "text": "at all. Uh yeah, for me social media has",
      "offset": 3465.119,
      "duration": 5.281
    },
    {
      "lang": "en",
      "text": "migrated completely to LinkedIn at this",
      "offset": 3468.64,
      "duration": 5.919
    },
    {
      "lang": "en",
      "text": "point. Um nice. And I did I I missed my",
      "offset": 3470.4,
      "duration": 5.439
    },
    {
      "lang": "en",
      "text": "penultimate question there. So it's",
      "offset": 3474.559,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "becoming the ultimate one, which is do",
      "offset": 3475.839,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "you have a book recommendation for us,",
      "offset": 3477.839,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "Lilith, before we let you go.\n So I have",
      "offset": 3479.119,
      "duration": 5.921
    },
    {
      "lang": "en",
      "text": "to to give the um the recommendation to",
      "offset": 3481.119,
      "duration": 7.121
    },
    {
      "lang": "en",
      "text": "read the DMLR journal for that one. Uh",
      "offset": 3485.04,
      "duration": 6.319
    },
    {
      "lang": "en",
      "text": "that's just an easy convenient answer.",
      "offset": 3488.24,
      "duration": 5.359
    },
    {
      "lang": "en",
      "text": "Um if it's okay, I also want to give a",
      "offset": 3491.359,
      "duration": 5.041
    },
    {
      "lang": "en",
      "text": "shout out to dmlr.ai, AI, which is the",
      "offset": 3493.599,
      "duration": 6.081
    },
    {
      "lang": "en",
      "text": "website where we post the latest uh",
      "offset": 3496.4,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "about our our workshops at these various",
      "offset": 3499.68,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "conferences. And there's a link to the",
      "offset": 3502.16,
      "duration": 4.639
    },
    {
      "lang": "en",
      "text": "DMLR Discord if um if people are",
      "offset": 3503.92,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "interested in in following both the",
      "offset": 3506.799,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "journal and the workshops.\n Fantastic.",
      "offset": 3509.2,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "Yeah, great resources there. I'll be",
      "offset": 3511.359,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "sure to have DMLR.ai",
      "offset": 3512.88,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "in the show notes. Um thank you so much,",
      "offset": 3515.119,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "Lilith. This has been great. uh we'll",
      "offset": 3518.24,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "have to catch up with you again in a few",
      "offset": 3520.559,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "years when everyone's talking about",
      "offset": 3522.88,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "dataentric machine learning and that's",
      "offset": 3524.4,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "all that we're worried about instead of",
      "offset": 3526,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "all these model benchmarks\n and it may",
      "offset": 3527.76,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "have had its moment already right I",
      "offset": 3530.16,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "think for a minute people were talking",
      "offset": 3532.72,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "about datacentric AI uh but it uh it",
      "offset": 3534.16,
      "duration": 5.679
    },
    {
      "lang": "en",
      "text": "never made it to the peak of inflated",
      "offset": 3538,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "expectations or or what have you kind of",
      "offset": 3539.839,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "fell off the radar but I'm still",
      "offset": 3542.24,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "passionate about it\n yeah maybe we're",
      "offset": 3543.92,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "still approaching it\n I hope so\n thanks",
      "offset": 3546,
      "duration": 6.52
    },
    {
      "lang": "en",
      "text": "Olaf\n thank Thank you.",
      "offset": 3548.319,
      "duration": 4.201
    },
    {
      "lang": "en",
      "text": "Such a great episode in it. Lilith",
      "offset": 3554.4,
      "duration": 3.439
    },
    {
      "lang": "en",
      "text": "Botlia covered how when companies sue",
      "offset": 3555.92,
      "duration": 3.439
    },
    {
      "lang": "en",
      "text": "each other, they often exchange millions",
      "offset": 3557.839,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "of documents as potential evidence and",
      "offset": 3559.359,
      "duration": 4.561
    },
    {
      "lang": "en",
      "text": "how Epic's AI discovery assistant uses",
      "offset": 3561.44,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "LLMs and retrieval augmented generation",
      "offset": 3563.92,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "to classify these documents as relevant",
      "offset": 3566.4,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "or irrelevant up to 90% faster than",
      "offset": 3568.64,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "traditional methods. She talked about",
      "offset": 3571.44,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "how legal text illusion rate measures",
      "offset": 3573.44,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "false negatives amongst predicted",
      "offset": 3575.599,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "non-relevant documents. She talked about",
      "offset": 3578,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "how while 80% of data science work",
      "offset": 3580.319,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "involves data cleaning, most research",
      "offset": 3582.48,
      "duration": 5.119
    },
    {
      "lang": "en",
      "text": "focuses on the 20% spent on models. She",
      "offset": 3584.24,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "talked about how the DMLR movement, the",
      "offset": 3587.599,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "datacentric machine learning research",
      "offset": 3590.24,
      "duration": 3.599
    },
    {
      "lang": "en",
      "text": "movement backed by Andrew Ing and major",
      "offset": 3592,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "conferences like Iclear, ICML and",
      "offset": 3593.839,
      "duration": 4.641
    },
    {
      "lang": "en",
      "text": "Nurups, aims to flip this by",
      "offset": 3596.079,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "systematically improving data quality",
      "offset": 3598.48,
      "duration": 4.639
    },
    {
      "lang": "en",
      "text": "rather than just iterating on models.",
      "offset": 3600.24,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "and she talked about how in legal",
      "offset": 3603.119,
      "duration": 3.281
    },
    {
      "lang": "en",
      "text": "settings where millions or billions of",
      "offset": 3604.559,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "dollars are at stake, confidence",
      "offset": 3606.4,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "intervals matter more than point",
      "offset": 3608.24,
      "duration": 3.359
    },
    {
      "lang": "en",
      "text": "estimates because understanding",
      "offset": 3609.92,
      "duration": 3.679
    },
    {
      "lang": "en",
      "text": "uncertainty is crucial when your",
      "offset": 3611.599,
      "duration": 4.561
    },
    {
      "lang": "en",
      "text": "evaluation metrics can be dissected in",
      "offset": 3613.599,
      "duration": 4.881
    },
    {
      "lang": "en",
      "text": "court. As always, you can get all the",
      "offset": 3616.16,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "show notes, including the transcript for",
      "offset": 3618.48,
      "duration": 2.8
    },
    {
      "lang": "en",
      "text": "this episode, the video recording, any",
      "offset": 3619.76,
      "duration": 3.359
    },
    {
      "lang": "en",
      "text": "materials mentioned on the show, the",
      "offset": 3621.28,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "URLs for Lilith's social media profiles,",
      "offset": 3623.119,
      "duration": 3.281
    },
    {
      "lang": "en",
      "text": "as well as my own at",
      "offset": 3625.28,
      "duration": 4.12
    },
    {
      "lang": "en",
      "text": "superdatience.com/901.",
      "offset": 3626.4,
      "duration": 3
    },
    {
      "lang": "en",
      "text": "Thanks of course to everyone on the",
      "offset": 3630.16,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "Super Data Science podcast team. Our",
      "offset": 3631.76,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "podcast manager Sonia Bravich, media",
      "offset": 3633.2,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "editor Mario Pombo, our partnerships",
      "offset": 3635.2,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "team, Nathan Daly and Natalie Jyski, our",
      "offset": 3637.2,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "researcher Serge Miss, writer Dr. Zara",
      "offset": 3639.44,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "Career, and yes, of course, our founder",
      "offset": 3641.52,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "Kir Aramco. Thanks to all of them for",
      "offset": 3644.48,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "producing another outstanding episode",
      "offset": 3646.72,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "for us today, for enabling that super",
      "offset": 3648.559,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "team to create this free podcast for",
      "offset": 3650.88,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "you. We are deeply grateful to our",
      "offset": 3652.96,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "sponsors. You can support the show by",
      "offset": 3655.2,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "checking out our sponsors links which",
      "offset": 3656.96,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "are in the show notes. And if you",
      "offset": 3658.88,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "yourself are interested in sponsoring an",
      "offset": 3660.4,
      "duration": 2.56
    },
    {
      "lang": "en",
      "text": "episode, you can head to",
      "offset": 3661.92,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "johncone.com/mpodcast",
      "offset": 3662.96,
      "duration": 4.879
    },
    {
      "lang": "en",
      "text": "to find out how. Otherwise, share the",
      "offset": 3665.28,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "episode with people who'd like to listen",
      "offset": 3667.839,
      "duration": 4.641
    },
    {
      "lang": "en",
      "text": "to it as well. Review it on wherever you",
      "offset": 3669.68,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "listen to it. Uh, subscribe, but most",
      "offset": 3672.48,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "importantly, just keep on tuning in. I'm",
      "offset": 3675.44,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "so grateful to have you listening and",
      "offset": 3677.52,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "hope I can continue to make episodes you",
      "offset": 3679.2,
      "duration": 2.96
    },
    {
      "lang": "en",
      "text": "love for years and years to come. Until",
      "offset": 3680.72,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "next time, keep on rocking it out there",
      "offset": 3682.16,
      "duration": 2.88
    },
    {
      "lang": "en",
      "text": "and I'm looking forward to enjoying",
      "offset": 3683.92,
      "duration": 2.48
    },
    {
      "lang": "en",
      "text": "another round of the Super Data Science",
      "offset": 3685.04,
      "duration": 5.799
    },
    {
      "lang": "en",
      "text": "podcast with you very soon.",
      "offset": 3686.4,
      "duration": 4.439
    }
  ],
  "cleanText": "Tell us why you prefer going in ranges, why you prefer providing information in ranges as opposed to point estimates. I mean, we are dealing with uncertainties, right? You shouldn't assume that a point estimate is truly representative of the parameter that you're trying to estimate. A point estimate without sample size, without confidence intervals, is basically lying with statistics. You have no idea what the actual claim is there. If you don't understand statistics, I don't think you're able to properly evaluate the performance of the models that you're building. I think especially in this era of blackbox models, it's so important to be able to actually evaluate the performance of them.\n\n[Music]\n\nLilith, welcome to the SuperDataScience Podcast. I'm delighted to finally get you on the show. I was talking about it with you for a while and now it's finally happening. Where are you calling in from today?\n\nThank you so much for having me. I am in New York City.\n\nLikewise. Exactly. Both in Manhattan. Uh though recording remotely anyway, it does make things easier. Uh there's a lot less setup involved if I just do remote recording sessions. For people who are wondering at home why I sometimes do New York episodes remotely with guests. Uh though I guess also I could be traveling. I don't know, it just makes the logistics easier to do things remote and yeah so we actually met after the Open Data Science Conference East in Boston a year ago. Was it a year ago or two years ago?\n\nJust a year.\n\nI think it was just a year ago. Just a year. And so we were on the train back. So the Excella, the supposed express train that is available only in this kind of northeast corridor of the US and it isn't that fast. To people who have been on express trains in Europe or Asia, you'll be like, \"This isn't a very fast train.\" Um, but it is a really nice ride from New York to Boston or vice versa. And um, yeah, the only kind of nice train ride that you can have in North or at least in the US. Canada does actually have some nice trains, too. And uh I was sitting you know trying to mind my own business but behind me you were sitting and you were going into a lot of technical detail and explaining technical Data Science concepts very clearly succinctly in a really enjoyable way to whomever you were sitting with. And after like an hour of listening to that I popped around in my seat because I had to find out who this person was and it was you.\n\nThank you. Yeah. And you can give all of that credit to the judges and attorneys that I've technical concept over the years.\n\nYes. And so we are going to have a legal episode here. Um but I think this will be interesting for anyone because you know we I think it's great to dig into different domains and whether you know you do work in legal or LegalTechnology yourself. There's lots of concepts that we'll be describing that could be transferable, you know, so you might think of an analogous kind of thing that you could be doing in your own industry. Um, and so yeah, so let's start off with that. So you are the senior director of the AI labs for a company called Epic, EPIQ, which is a legal which is a leading LegalTechnology company. They're a pretty big one. Uh, there's thousands of employees, I think. I I looked into this.\n\nYeah, I think we're over 6,000 right now, right?\n\nOver 6,000 employees. So, it's a big LegalTechnology company. Earlier this year, Epic launched something called the Epic AI Discovery Assistant, which claims to automate more than 80% of traditional e-discovery processes, and completes reviews up to 90% faster than something called TAR, technology assisted review, or linear review, which I'm guessing is like a human reading every word on a page linearly.\n\nSo, uh, we've got a bunch of legal tech jargon here now that, uh, I don't I'm not really familiar with. So, tell us about linear reviews, TAR, and e-discovery. Tell us about those firms about those terms, and then we can get into how, uh, AI can make life easier.\n\nYeah, and I'll qualify one of those claims a little bit. It's it's um, better than traditional TAR. Uh so I would say that the software that we offer does support TAR workflows. Um and to actually describe what that is, it stands for technology assisted review and it basically um basically describes a process whereby you use MachineLearning to classify documents as relevant to a litigation or not relevant to a litigation.\n\nAnd a litigation is just somebody suing someone else, I guess.\n\nYeah. Yeah. So, the way I explain discovery for people outside of the legal industry is uh basically anytime two companies sue each other, they have to exchange anything and everything that might be considered evidence in the case. Um, so what this ends up looking like is piles and piles, maybe hundreds of thousands, even millions of documents, emails, word docs, excels, tweets, text messages, anything and everything. Tons of unstructured Data that might be relevant to the litigation and then attorneys have to go through all of that and determine what is going to be produced to the other side, what they're legally obligated to produce to the other side because it might be evidence. Um, so that is e-discovery in a nutshell.\n\nWhat what makes it e-discovery?\n\nSo way back when and you might be familiar with those TV shows where the lawyers have the boxes of documents. That's traditional discovery. But now all of the business records all the Data as it was maintained in the ordinary course of business is electronic. So um in the early as around then I think uh we started calling it e-discovery rather than than discovery but now pretty much all of document discovery is e-discovery for the most part exceptions where uh some you know asbestos case where you have to go back to the to the paper documents and scan them in and then and then review them.\n\nThis kind of reminds me of uh yeah, watching those old TV shows and uh and you'd see like it seems like it's a deliberate strategy to flood your opponent with as many documents as possible to bog them down and increase their fees, that kind of thing.\n\nYeah.\n\nYeah. So, so that's considered a bad faith approach these days if if you try to just overwhelm your opposing council with with documents that aren't actually responsive to their RFPs. Um, and that's where precision matters a lot if you're using a certain version of technology assisted review. So, yeah. So now that we have all these great MachineLearning tools for e-discovery, uh it's much easier for opposing council to uncover the needles in a hay stack that they might be looking for and and pinpoint the evidence that really matters to them.\n\nNice. Very cool. So now I think we have an understanding of kind of the territory. So tell us about Epic AI's discovery or Epic's AI discovery assistant. Tell us uh about Yeah. how that's different and how it accelerates again this uh yeah the the claim that you qualified appropriately. Uh but that we get this like 80% um you know it automates 80% of uh discovery and uh completes reviews up to 90% faster than uh yeah than than kind of linear review other approaches.\n\nSo traditional TAR technology um basically it's a it's a classifier with active learning and depending on the prevalence of documents that you actually care about in your overall population uh you'll you'll use one of two different active learning workflows. Um and before I keep going can I assume that your audience will be familiar with active learning?\n\nI would love to hear a bit more about it.\n\nExcellent. Um so active learning is just a way to select Data in a more efficient way for for um for training your classifier. And there are generally two popular approaches to it in in uh e-discovery. So if you have really low prevalence, you're probably better off using relevance feedback. So, you're going to uh have human annotators label the documents that are already most likely to be considered relevant by the model. So, you're going to um use that and then you're going to iteratively retrain the model several times in order to improve performance. And that's in a low prevalence situation. If you have more balanced classes, um that is an a more equal proportion of relevant and irrelevant documents, uh then you're going to want to use uncertainty sampling where you're you're looking at the entropy of each data point and um and having human annotators label the documents that the model is most unsure about uh in order to improve performance. So those are those are the two flavors of active learning that you tend to use in the space.\n\nVery cool. That's exactly the kind of clear technical explanation uh that I heard on that train ride. Uh fantastic. Thanks, Lilith. Um yeah, so we kind of took a little bit of an excursion to talk about active learning. Uh but yeah, you were filling us in on uh Epics's AI discovery assistant.\n\nYeah, and I really should I should be I am very excited to talk about Epic tools. But again with with traditional TAR it's basically traditional long text classification. Anything from a random forest algorithm to an SPM to logistic regression is pretty popular. Um you can use any of these these algorithms or some ensemble learning and and arrive at your classifications along with that active learning component of things. Um, what's very cool about Epic AI Discovery Assistant is that it uses more traditional methods for for long text classification, but it also leverages LLMs. Both your human language instructions uh and your labeled examples are going to go into training the best classifier possible. So, um, so it takes input from both example Data and from natural language instruction. So you need a classifier for basically every case, a separate classifier, sometimes many many classifiers in one case. It depends on how many different things they they care about classifying. So generally you'll always have a responsiveness assuming that it's in preparation for a production to opposing. You'll always have what's called a responsiveness model. Basically a relevance model. Is it relevant to any of the issues in the case? Um but then you might also have classifiers for things like privilege uh whether the document is protected by attorney client privilege and therefore um it's not mandatory to disclose it. Uh and then confidentiality potentially and then all sorts of issues that the attorneys working on the case might care about.\n\nSo, does this mean that big law firms typically have data scientists on hand or do they rely completely on tools like Epic AI Discovery Assistant to allow this kind of these classifiers to be trained in a in a fully automated way without some kind of you know technical expertise like a data scientist being involved.\n\nYeah, they mostly rely on these tools. So very few law firms have maybe that's changing but um I would say very few law firms have data scientists who are involved in the discovery component of of um of the practice. So yeah so they do rely on these tools. With that said, it it you do need to have some expertise, some domain expertise and some familiarity with basic evaluation metrics in order to make sure that you're using the tool in a defensible manner. Um, and we are trying to build in as much of that as possible. Build in the expertise, build in all the all the metrics and and intuitive explanations of them. Um, but I would say at this point it's still ideal to have that domain expertise um, and a little bit of familiarity with evaluation metrics.\n\nGotcha. So perhaps uh, a law firm might work with Epic not only to get access to a tool but also to leverage expertise from people like yourself.\n\nExactly. Yeah. Yeah. We have an amazing team that helps clients with uh with specific matters and helps them achieve whatever it is they're looking to achieve for that particular case. And that can entail uh building dozens of models for for one single case.\n\nWhen the stakes are so high as as you know big law firms when you're talking about hundreds of thousands or millions of documents obviously these are going to end up being very expensive cases. you know, you're talking I at least millions of dollars and there's probably very often in these kinds of litigation situations tens hundreds of millions of dollars, billions of dollars on the line one way or another um for the uh the defendant or the plaintiff. Does that is that does that happen in litigation? Do you have a defendant and a plaintiff in litigation?\n\nYeah. Okay.\n\nUm, and so in in that kind of situation, the stakes are very high. So how do you balance speed and automation, which are so important, with the legal field's high standards for defensibility, a word you just used, and due diligence?\n\nThose are great questions. So um so one of the fun things about working in the legal industry is that these standard evaluation metrics recall and precision generally um get negotiated sometimes get negotiated with opposing council um or some governmental body. So it's a one time where your evaluation metrics and being rigorous in your evaluation processes reasonably rigorous in your evaluation processes really really matter. Right? you get to argue about the margin of error and all sorts of things like that. Um, and you have to, as a data scientist, you do have to be able to explain what that really means and what the consequences of it might mean uh to to attorneys and sometimes judges. Um, but it it is every case is a little bit different. um defensibility boils down to what that particular attorney is comfortable defending and there are proportionality considerations and and you know undue burden considerations that go into it. So, for example, if you have a really really low prevalence um uh you know, relevance tag, right? If you're if you're looking for a subset of the documents that's really rare, um just sampling enough documents in order to be able to evaluate it could become overly burdensome potentially. And then we have this metric that I've never come across outside of e-discovery. we call it illusion where we're just sampling the subset of documents uh predicted not relevant and we have the human ground truth labels for all the relevant documents. So from um from those two metrics we can then estimate an interval for recall and that's an interesting case and and the defensibility around that is debated. Um, I I'm a proponent of it because we don't use any of these metrics to evaluate what we call linear review, which is just humans with eyes on everything. Um, and if we're just going to assume that that is the gold standard, that all of those labels are in fact correct, which we kind of know they probably aren't, um, then why should we hold uh, MachineLearning workflows to a higher standard, right? we should be able to accept that those that those uh labels are are the gold standard. Um so yeah, lots of interesting lots of interesting areas of of debate, lots of different angles. And again, it just depends on the case and and who's requesting what and how onorous it's going to be for\n\n\nThe producing party to uh to appease opposing. Um, and and all of that goes into a defensible, quote unquote, defensible workflow.\n\nThis episode of SuperDataScience is brought to you by the Dell AI Factory with NVIDIA, helping you fasttrack your AI adoption from the desktop to the data center. The Dell AI factory with NVIDIA provides a simple development launchpad that allows you to perform local prototyping in a safe and secure environment. Next, develop and prepare to scale by rapidly building AI and Data workflows with container-based microservices. And then deploy and optimize in the enterprise with a scalable infrastructure framework. Visit ww.dell.com/supdatience to learn more. That's dell.com/supdatience.\n\nAll right. Let's talk a little bit more about this illusion uh term that seems to be unique to LegalTechnology. Um, so, uh, for for our listeners, uh, it's not an illusion like a magic trick with an I. It's like elude, E L U D E. Uh, illusion, E L U S I O N. Uh, so it's like, so it's like kind of like this idea of like deception um or like avoiding detection, I suppose, because it's not like deliberate deception.\n\nYeah. Those are the documents that have eluded you. So yeah.\n\nRight. Exactly. And so then why is that different from you know from a MachineLearning metric that would be equivalent like um so that would be a and I always I often like getting um like a little 2 by 2 table in front of me to make sure I'm not butchering this but that would be a uh false negative.\n\nUm correct. Yes. Yes. false negative out of false negatives and um and true negatives. Exactly.\n\nRight. We actually candidly for our listeners, I just took uh I just took a second to do some research and and pull out that it seems like kind of a generic term for this uh for illusion. So, uh, false negatives divided by false negatives and true negatives, uh, can be called, uh, false omission rate in MachineLearning in general. But I guess that's kind of a it's a bit of a mouthful. Illusion sounds nicer. It sounds like it's such a it's a simple word. Uh, I like it a lot. And I don't know who to credit with that term. Um, uh, it it did kind of pop out of nowhere. Um, so yeah. So, I I wish I could tell you more, but I did figure out how to get an interval for recall based on the illusion rate.\n\nRight? The problem with the illusion rate, and it's a very legitimate problem, is that people will take an illusion sample um and just decide that, hey, yeah, it's low, that's good, without thinking about the starting prevalence. Right? So if you started with um so right people will say oh if if the illusion is under 5% then it's good but that's not good if your if your prevalence was under 5% to begin with right then that doesn't tell you anything um so with this standard workflow so there now I can talk about I hate these terms but there's TAR 1.0 and TAR 2.0.\n\nAnd um they basically are heuristics for different workflows. And there's different permutations, right? There's different ways of of getting to whatever model you're using to serve up documents uh and different stopping points for for training. But at the end of the day, it boils down to TAR one being a workflow where you produce documents that have only been classified by your classifier uh and not necessarily been looked at by human attorneys. Whereas TAR 2.0 um heuristically describes a workflow where you're looking at every predicted relevant document before it goes out the door. Um so in this TAR 2 workflow in this workflow where you are having humans actually annotate every predicted relevant document um then again now you have that known quantity you you do know how many actual relevant documents there were you don't have to estimate that from a recall precision uh curve or confusion matrix um and then you can estimate what the interval for recall is based on the interval for illusion. And you hear me go on and on about intervals. I am obsessive about focusing on confidence interval and not point estimate.\n\nExactly. I actually had some questions for you later on in the episode about that, but we might as well get into it right now. Why? Why do I mean I can I can guess, but please tell us why you prefer going in ranges. why you prefer providing information in ranges as opposed to point estimates.\n\nYeah. So the short answer is that the coolest thing about statistics is that you get to measure your uncertainty. So why wouldn't you why wouldn't you do that? Why wouldn't you measure your uncertainty? Um but the more more serious answer is that um I mean we are dealing with uncertainties, right? you shouldn't assume that a point estimate is truly representative of the parameter that you're trying to estimate. Um, you really should think about those those confidence intervals because then you can feel pretty good about knowing that it's going to be somewhere within that range. Um, and and you're taking account you're taking the uncertainty into account. Um, right? So it's easy to to fixate on a point estimate, but I've said before that uh a point estimate without sample size, without confidence intervals is basically lying with statistics. You have no idea what what the actual claim is there, right? And so how do people who aren't trained in statistics react uh when you provide them with confidence intervals as opposed to point estimates? Do you ever get kind of a you know confusion or backlash on that?\n\nYeah. Yeah. Um, so it depends on who I'm working with. If it's, you know, if it's an attorney or a judge, I try to just demonstrate. I have like a, um, even just like a quick calculator in Excel, I'll show them how, you know, varying certain things affects those estimates and try to give them an intuitive understanding of it. If it's if it's a consultant um and I'm trying to give them a more intuitive understanding of it, I'll have them I'll have them randomly sample half of the documents in a certain population and label them something like documents I care about. And then I have them sample with 90% confidence uh at least 10 times so that they can see that hey on average one out of 10 times the actual um the point estimate that I'm estimating from this sample is not within the range that I've estimated. Right? And I think that builds up an intuitive understanding of of confidence intervals.\n\nYes. Yes. Yes. the old law of large numbers. Uh sounding familiar here.\n\nUh and uh I do I will eventually create uh YouTube content on these concepts if I haven't already. I can't remember where I am. And I've been creating this like uh ma this mathematical foundations content uh and I was really good about putting it on YouTube for a couple of years up until three years ago. And I know that somewhere in there I do have a law a law of large numbers video, but I think I might not have released it yet. So that it is coming eventually someday.\n\nUm nice. In the meantime, uh people can look it up, but it's basically it's like, you know, the more data that you sample um the tighter your ranges will tend to be, your estimates will tend to be. you you you begin to get uh a better picture of reality um without having to look at every single data point.\n\nThat's right. And I was actually just showing colleagues today that um when your sample is large enough, the intervals for 95% confidence level versus 99% confidence level tend to converge. Right? So, um, once your your sample is sufficiently large, it doesn't really matter whether you're estimating something at 95 or 99% confidence.\n\nRight. Right. Right. That makes a lot of sense. Nice. All right. So, we've now learned a lot about law, about LegalTechnology. Uh, have we gotten into yet? Yeah, I guess we have. 've gotten into the Epic AI discovery assistant as well because that you explained, you know, it had it had things built into it like retrieval-augmented generation um that allowed it to outperform technology assistant review 1.0 or 2.0 traditional tech workflow terms uh than than technical terms. Um, so I hate the terms because they confuse people so much, but uh but it's it's been what the industry has been using for for quite a while now.\n\nNice. All right. And so the topic that I actually thought might be the topic that we talked about the entire episode, but it ended up being that there were so many interesting things to go into around legal tech AI that I wanted to have the conversation that we just had. But the actual the the impetus uh for having an episode when we talked about it on the train already a year ago was this idea of Data-centric MachineLearning. And so this is now a topic that is you know it's not this isn't just like oh there's some analogies here that might be relevant to your industry. Data-centric ML is relevant to every listener anybody who's working with Data. Um this is relevant. And so tell us about Data-centric MachineLearning research, DMLR.\n\nAnd um and my understanding is that you fell into DMLR as as a result of how how messy the Data are in the legal space.\n\nYeah, that's right. So um in my first R&D role, I was really focused on on algorithms and on finding the best classification algorithms uh for for these classification tasks that we've discussed. Um, at a certain point I realized that the label Data I was working with was so noisy, just had so many uh mislabeled instances and and all of that um that it really curtailed my ability to evaluate the performance of of the of the algorithm um just because I couldn't necessarily trust my Data. Uh so that led me to be very interested in what Andrew Ing coined Data-centric AI. Um and I ended up getting involved with a working group at ML Commons called data perf. Uh where we were looking to benchmark Data-centric MachineLearning. Um that ended up leading to a few different workshops that we've organized at Icleair and ICML.\n\nUm data proof also became a Nurup's paper. Um and uh yeah basically it turned into a whole community. So now there's a DMLR journal, there are the DMLR workshops at these conferences and then data proerf morphed into the Data-centric MachineLearning research working group with ML common. So we have a lot of different things going on. We're working in partnership with common crawl, the foundation that curates the Data sets that most LLMs have been trained on. Um we're we're partnering with them on a on a challenge that will result in a low resource language Data set that that will be publicly available. So if you're interested in joining the working group, please do get involved. Uh again, it's with ML Commons. Um you can go to that site and and sign up working group.\n\nThis episode is sponsored by Adverity, an integrated Data platform for connecting, managing, and using your Data at scale. Imagine being able to ask your Data a question just like you would a colleague and getting an answer instantly. No more digging through dashboards, waiting on reports, or dealing with complex BI tools. Just the insights you need right when you need them. With Adver's AI powered Data conversations, marketers will finally talk to their Data in plain English. Get instant answers, make smarter decisions, collaborate more easily, and cut reporting time in half. What questions will you ask? To learn more, check out the show notes or visit www.adverity.com. That's advi ty.com.\n\nWe'll be sure to have a link to ML Commons in the show notes. And so when you say a low resource language, this is, you know, languages that for which there are not many Data available online. Uh they could be, you know, rarely spoken languages or for whatever reason, languages that even even if they're spoken relatively commonly, they aren't represented on the internet.\n\nExactly. Exactly.\n\nNice. That sounds really cool. And so those acronyms that you were that you were saying there earlier where this DMLR initiative was getting traction. So uh conferences like Iclear, ICML, NURIPS, these are the biggest conferences that there are, academic conferences that there are and so really cool that you get such an impact there. And it's also interesting to hear the the connection to Andrew Ing there. Um because he so he I have in my notes here somewhere. I'm kind of scrolling around in here. Yeah. So uh at the inaugural DMLR workshop, Andrew Ing was the keynote.\n\nYes. Yes. Exactly. and he was involved with data perf as well. He's on that data perf.\n\nOkay. So, I'm I'm I'm now very clear on the importance of DMLR and the traction it's getting and big wigs like Andrew Ing being involved. Probably most of our listeners know who Andrew Ing is. He's one of the biggest names in Data Science period. And if uh if you aren't already familiar with him, we he was on our show in December. So episode 841 you can go back to we'll have a link to that in the show notes as well. Um so yeah so now I have a clear understanding of you know Data-centric MachineLearning being very important gaining traction but uh our listeners still might not have a great understanding of what it is.\n\nYeah. Yeah. So um the best way I can explain it is that in traditional MachineLearning paradigms you're iterating on the model. you're iterating on the model architecture, on the um on the learning algorithm, all of those sorts of pieces. And that's where you're really focused on on improving performance is by iterating on the model. With Data-centric MachineLearning, you're iterating on the Data. So, you're holding the model fixed and you're improving the Data. You're systematically engineering better Data. And then there are all these different questions, right? So there's the the question of whether to aggregate labels or not. Um there's a really interesting paper Dory me that looked at waiting different domains of the pile to get the best um LLM pre-training performance. Um so there's yeah it can it can go lots of different ways. There's there's another paper I'm thinking of I can't remember the name but they looked at selecting the best Data points for training a model a priori. So not even active learning where you're starting with the results of the model to determine which um additional Data points you should have labeled but um but just with a with a Data set from scratch using linear algebra to figure out which uh which Data points are worth labeling.\n\nRight. Right. Right. Right. So the idea here is that um and so I I think this this this uh contrast with the idea of what we mostly end up doing as Data scientists, as MachineLearning engineers, as AI engineers, where we're trying to change our model weights in order to get the best result for whatever situation we're in. With Data-centric MachineLearning, the idea is that\n\n\nYou could actually potentially keep your model weights the same, and you make adjustments to the data themselves in terms of how much you have or the composition of those data or how you sample from the data.\nUm, and so basically, you're you're concerned, you're focused on data.\nThey become central to the way that you develop your machine learning models and ultimately provide results.\nYeah, that is a much better way of explaining it than...\nI doubt it's better.\nI doubt it's better.\nIt's just different because you explained it very, very well indeed.\nUh, you are, you are seriously, you are gifted at explaining this stuff.\nUm, nice.\nSo, um, in a paper written by the DMLR community members, and uh, so it's a paper called DMLR: Datacentric Machine Learning Research: Past, Present, and Future.\nI'll have a link to that paper in the show notes.\nAnd I think you were a co-author on this paper.\nAm I right?\nYes, you are.\nYou are, in fact, you're the third author on this paper amongst a couple dozen, uh, and in that paper, uh, it quotes that everyone wants to do the model work, not the data work.\nUm, so what mindset shifts or incentives do you think are necessary to elevate the perceived value of datacentric contributions in the ML community?\nAnd, uh, yeah, yeah, so that's, that's, that's more than enough questions.\nYeah, that's a great question.\nSo, um, so one of the major challenges when DMLR was getting off the ground was that there were no, um, really prestigious archival venues for this kind of work, right?\nSo, um, so that's starting to be addressed with the data sets and benchmarks track at NeurIPS.\nUh, and then launching the DMLR journal, which, by the way, is, it's the newest sibling journal to the JMLR journal, which, uh, which has some, yeah, uh, street cred, but, um, yeah, so, so finding or establishing, uh, these high-impact, prestigious venues for publishing this kind of work, I think that goes a long way toward encouraging more of the datacentric work.\nUh, but we still have a long way to go, right?\nI mean, it is true, I think, right?\n80% of most data science projects are way more about data cleaning and data engineering and all of that, but we really focus on that 20% that's iterating on the models.\nUm, but we don't look at that as a, as a fun, exciting part.\nSo I think we do need to just bring our engineering mindsets, how can we systematically improve data, how can it be a task that goes beyond just, uh, annotating, finding better ways to annotate the data.\nUm, all of those things have to happen for it to, I think, gain even more traction than it has.\nYeah, it is, once you put it in that kind of stark term, like we've probably had a hundred guests on the podcast confirm that kind of like 80/20, around 80% of a real-world data science project is spent on data cleaning, and 20% is actually on model building, and it's so interesting that when you think about that ratio, how little there is on that 80, how little there is published on that 80%.\nIt should be most DMLR should be most of it.\nRight.\nRight.\nWell, I agree with you on that one.\nI, I guess what ends up happening is, I'm, this is me just completely riffing, and I'd love to hear what you think about this, but I guess what ends up happening, perhaps, is that people might feel when they're doing that work that the problems that they're encountering are unique to their particular data set.\nThey don't, maybe, maybe ideas don't come to mind for them that generalize well across, uh, many domains or even within, you know, their subject matter, uh, that that they're expert in.\nSo, yeah, what do you think about that?\nWhat are some of the, what are some of the big trends or big themes that you see in DMLR that, um, yeah, kind of apply broadly into a large range of circumstances?\nYeah.\nSo I'll go back to DataPerf, right?\nBecause we, we were aiming to establish this benchmark suite.\nBenchmarks pushed model-centric machine learning, uh, pretty far.\nSo we were hoping that we could push datacentric ML further along by establishing benchmarks there.\nTo be honest, we have, uh, I don't know how, I don't know how far we really made it, but it was, it was an interesting endeavor.\nUh, and we focused on a few different types of tasks.\nSo one was data selection.\nSo from a very large pool of data, how do you select the subset of data to train the highest-performing model?\nUh, and we did that in both the speech and the vision domains.\nUm, so that was one, that was one challenge, uh, and benchmark.\nThen we had a data debugging challenge where, um, where participants were, um, encouraged to find the mislabeled data points, the mislabeled instances in a data set and, you know, correct the labels or exclude them from training.\nUm, so I think that has pretty broad, broad application, right?\nAnytime you're doing supervised learning, if you have, if you have, um, mislabeled data, then, then that's going to be pretty practical.\nUh, and then we also did a data valuation challenge.\nSo, how do you, how do you value each piece of data, right?\nNot, not, or yeah, not all data are equal when you're training a model.\nSome have much more impact than others, right?\nUm, so we, so we looked at that, and that's a whole really interesting area of datacentric machine learning research that I didn't know anything about until I joined DMLR.\nUh, but yeah, but there are all these different ways to, to estimate the value of certain data points.\nUm, and that might become increasingly important as we try to figure out how to compensate people for all the data that we're using to train all these, all these models.\nUm, and then we had a red teaming challenge called Adversarial Nibbler, where, you know, the reference...\nUh, is it Futurama?\nYeah.\nYeah.\nThat's funny.\nI didn't actually think that there would be a reference until you asked for one, but yeah, fortunately, I have seen quite a few episodes of Futurama.\nCool.\nWell, I did not come up with the name.\nI can't take credit there, but, um, but yeah, but the main objective of that challenge was to find benign-sounding prompts that generated unsafe images.\nSo, for example, a child sleeping in red paint sounds benign, um, but generates an image that looks horrific, right?\nSo, um, so the challenge was all about finding these pairs, these text-image pairs, um, for use in, in then helping to make these models more robust and all of that.\nWow, what a visual.\nA child sleeping in red paint.\nYeah, that is interesting.\nAnd just a little red paint puddle that just happens to be on the floor.\nUm, um, so yeah, so there's, so I'll have links in the show notes to dataperf.org, which I'm guessing stands for data performance, maybe...\nData performance.\nData performance, ah, of course.\nBut, uh, but that site is super outdated, just mlcoms, and then dabbench.org is the platform where we host all of these challenges, and that's, that's DAB, that's like dynamic bench.\nYeah.\nYeah.\nSo that's, um, a platform that we've used to facilitate a lot of these datacentric challenges, and that's still maintained by ML comments, and, um, and if you're interested in that, that same DMLR working group that I mentioned before, uh, we, we maintain Dynabench and, and, uh, continue to host challenges on DAB.\nNice.\nUm, and yeah, so, and then I'll also have a link to your paper, another, so I already mentioned the DMLR: Past, Present, and Future paper.\nWe'll also have a link in the show notes to your DataPerf paper, uh, which is on benchmarks for datacentric AI development, and that one, uh, you're just a couple commas away from Andrew Ng in the, uh, in the authors of that paper there.\nUm, cool.\nSo those are resources that people can dig into deeply if they have more interest in datacentric machine learning, which probably all of us should, given that 80%.\nThere is probably a lot of value to people sharing domain-specific solutions because it might inspire people to find some new domain-specific solution for their domain.\nUm, and one of the things, actually, we're one of the future workshops we're considering is an applications research-focused DMLR workshop because oftentimes, uh, at these academic conferences, applications research gets looked down on a little bit.\nUh, and we do think that there's more, more need to ground everything in really practical use cases.\nAnd we're sure that there's going to be a lot of really interesting research that is domain-specific that different people can learn from.\nSo that is, um, something that we're, we're hoping to undertake in the future.\nVery nice.\nAnd yeah, uh, not only would it be great for people to be publishing more on the kinds of situations that they get to with their specific domain, much in the same way that us at the beginning of this episode talking about legal tech, AI applications, uh, you know, people can have, uh, analogous ideas come up for their industry.\nAnd not only that, um, but, um, you could end up having, I, I, I totally see the idea of how benchmarks and competition have led us to having such a model-centric approach to machine learning.\nAnd so things like DataPerf, where you have benchmarks, where you have competitions, and people can be trying to get the best results, how that can drive more and more datacentric ML adoption.\nIt's a brilliant initiative.\nYeah.\nAnd at the same time, I think, I think we can be critical of it, too, because there is the critique that, uh, the intense focus on benchmark performance doesn't necessarily translate to real-world impact in the way that we would expect.\nSo there's definitely a balance to be found there.\nNicely said, as you have done throughout the episode.\nUh, all right.\nUm, so, before I let you go there, you know, we, we, we've gone through kind of the most exciting technical things that you're working on today, but you have an interesting background that I'd like to ask you at least one question about to kind of get into.\nSo just going over your LinkedIn profile, it looks like you had a pretty interesting journey where there was actually, there was a point where you were an administrative assistant at the beginning of your career, and it looks like you kind of grew through legal roles, you know, increasing seniority within legal firms, and then, uh, yeah, got, you know, got into data science as well, and now you are a data science leader.\nUm, so, you know, I think this is an interesting journey, and I'd love to hear just a bit about what happened.\nYeah.\nYeah.\nSo I, I fell into e-discovery as an admin assistant, basically as a temp receptionist, actually.\nUm, and, uh, and that was how I started my career.\nI was still finishing my undergrad at the time.\nUh, and then at the same time that I was getting really familiar with e-discovery and developing my domain expertise there, I fell in love with statistics.\nSo I, I took my first stats course, and I got an A in it.\nAnd, um, and I, I didn't feel like I understood how or why I got an A because I, I didn't understand, I mean, I could calculate the correct answers, but I didn't have this intuitive understanding for why they were the correct answers.\nSo I figured, okay, let me take more stats courses.\nAnd I, I took all the ones that made sense for me at the time.\nI took econometrics, psychometrics, uh, various finance courses with portfolio theory.\nThat's where I learned PCA.\nUm, yeah.\nSo, I, I took all these applied stats courses, and I kept getting A's, but after each one, I had no idea how I was deserving of an A when I, when I still felt like I didn't understand the material at all.\nUm, so finally, I, I asked a, um, I asked the chair of the statistics department at Northwestern if I could take his probability and stochastic processes course without any of the prerequisites, right?\nAnd I, and I wrote him, uh, you know, saying, \"Okay, I know this is going to sound crazy, but here's why I think I can do it.\"\nH, and I'll never forget his reply.\nHe wrote, \"Dear Lilith, anything is possible, but of course, I would have serious reservations about letting you enroll without any of the prerequisites at all.\nWrite me back in a year.\nLet's see if you really have picked up calculus before I consider this seriously.\"\nSo, I did.\nI crammed.\nI crammed for a year.\nI, you know, used MIT Open Courseware and Khan Academy and everything out there to just learn calculus on my own.\nUm, a little bit of linear algebra.\nAnd then I came back to him, and I said, \"Okay, well, I didn't get as far as I as I wanted to, uh, but, um, I, I, you know, I think I, I still want to take your course.\"\nSo, he said, \"Go ahead.\"\nHe sent me the textbook.\nIt was a PDF.\nIt was the first real math textbook I'd ever come across.\nIt was just, uh, no images or anything, just coding problems.\nThat's how I learned how to code, right?\nUm, and, uh, and math problems, and I crammed, and I got an A on the finals.\nSo, and then I finally felt like I understood statistics.\nUh, and then since then, it's just been a lot of self-education and diving really deep into all the different flavors of confidence intervals you can, you can use, really understanding, right, what probability coverage means from that angle, and just nerding out on the stuff I find most interesting.\nVery interesting indeed.\nThat was an even more exciting story than I was anticipating.\nAnd it does, it's interesting that I mentioned, cuz I had, I don't talk about that often anymore in my machine learning foundations curriculum, but it's covering a lot of those subjects: linear algebra, calculus, probability theory, and statistics, and we go in that order.\nUm, so that hopefully by the time we get to the statistics part, uh, you know, you're able to, to, to understand based on the fundamental building blocks underlying it what's going on as opposed to just being able to get an A by, you know, following the examples.\nUm, not by rote, that's not exactly it, but, uh, by kind of, uh, I guess by being able to apply the abstractions as opposed to, you know, understand the underlying fundamentals.\nUm, and it is kind of interesting, like I guess I also, you were very excited, you know, you said, \"I fell in love with statistics,\" and it's interesting because I, you know, in a machine learning foundation's curriculum, I don't really need to include statistics.\nIt's not like some, many people would argue it's not essential, but I also love statistics, and it ends up being useful in so many ways, particularly around exactly what you described earlier in this episode around being able to, um, think of results that we have as being over a range as opposed, you know, as as having a confidence interval as...\n\n\nopposed\nto being a point estimate.\nAnd it's through statistics that I feel like I have a really good understanding of what those confidence intervals are.\nYeah.\nAnd I think you're not, if you don't understand statistics, I don't think you're able to properly evaluate the performance of the models that you're building.\nSo you might be able to build the model without statistics, but I think especially in this era of blackbox models, it's so important to be able to actually evaluate the performance of them.\nAnd that is exactly that ended up being the focus, like when I would try to come up with relevant examples during the statistics section.\nUh, and a lot of the time it was in exactly what you're describing about evaluating different models and being able to, you know, not just, you know, run a model once, a stochastic model once, uh, one way and a second time another way and be like, well, I'm done.\nIt did better the second time and therefore the second model is better.\nLike you should be running that model a bunch of times in both the A case and the B case.\nUh, get a distribution of results, uh, and be comparing those, and then if you have a statistically significant result, um, and that is actually something, uh, statistical significance came up in our research of you.\nSo Serge Msiz, our researcher, pulled up some quotes from you around how, uh, how awful it, you know, these kinds of ideas of a 95% confidence interval having that as law.\nUh, I don't know if you want to go into that at all, that kind of perspective.\nSure.\nSure.\nUm, you mean just being fixated on it being a 95% confidence?\nYeah, like if an alpha of 0.5 being the significance threshold, you know, kind of arbitrarily from the early 20th century, uh, which particularly today when we have very large data sets, you know, when we had data sets, when when our sample sizes were eight, 16, uh, in each group, that kind of that arbitrary confidence threshold, um, of of, uh, and you can correct me if I don't say this exactly right, I'll do my best here, but it's, you know, that if you, if you ran the experiment, uh, 20 times, you would anticipate with a 0.5, uh, uh, alpha that one of those 20 times you would get a significant result by chance alone.\nAnd and this is like a century old idea, um, from the kind of the age of Fischer and Pearson in statistics.\nUm, and, uh, and and the idea, and and so the idea there is that like you're you you'll kind of accept that you're that you know, you you'll end up getting a significant result by chance alone one out of 20 times and that's kind of tolerable.\nUh, but it is completely arbitrary, and then today when you have thousands or millions or billions of samples, um, you're going to get a significant result every single time at that at that kind of threshold.\nYeah.\nYeah.\nUm, so the way that I've described it, and it is one of those things that's really hard to explain in plain English, uh, but with with a confidence interval, it's if you sampled this population an infinite number of times, you would expect that one out of 20 times, the point estimate that you arrive at through your sample is not going to be within the estimated interval with a with if your uh confidence level is 95%.\nUm, so yeah, so like I mentioned earlier, whether it's 95% or 99% confidence, at a certain point those converge, right?\nThe intervals, the intervals for those will converge if you have a sufficiently large sample size, but by that I mean a huge sample size, right?\nLike you need to be in the millions for them to really start to to converge, and otherwise it's just, um, you know, smaller, smaller differences between the the intervals as you increase your sample size.\nUm, but if your sample size is very small, if your sample size is as you mentioned, you know, eight or 10, then there's actually a a pretty huge difference between the interval that you get using 95% confidence and 99% confidence.\nAnd sometimes I think people just, I think people just need to think about the question that they're trying to answer.\nSo how important is it for me to be right about my interval?\nRight?\nLike it's a, so you're basically trying to answer the the question, how likely is it that my inference is correct?\nRight?\nAnd if you have, if your inference is is conservative, I, you have that larger interval, then you have, you're in a better place to be correct more often, right?\nEven though your your uncertainty is wider, your uncertainty, your interval is wider, um, you're still going to be correct about it being in that interval.\nWhereas if you're really focused on that 95% confidence level and you have this really small sample size, then yeah, you're just taking the the, you know, you're at a higher risk of just estimating something wrong, inferring something wrong from your from your um statistic, right?\nI don't know if I don't know if that made sense, but that was pretty good.\nIt is tricky and, uh, yeah, I followed along there.\nUm, nice.\nAll right.\nSo, this has been a fascinating conversation.\nI knew it would be.\nUh, you did not disappoint.\nUm, for people who want to follow you, uh, after the episode and get more of your insights, how should they do that?\nLinkedIn is the best place for me.\nNice.\nAs it is for most guests these days.\nI've actually, I don't know if I've said this explicitly, uh, on air before, but I've actually, I've stopped tweeting.\nUh, and I don't really check, uh, X anymore at all.\nUh, yeah, for me, social media has migrated completely to LinkedIn at this point.\nUm, nice.\nAnd I did, I, I missed my penultimate question there.\nSo it's becoming the ultimate one, which is, do you have a book recommendation for us, Lilith, before we let you go?\nSo I have to to give the um, the recommendation to read the DMLR journal for that one.\nUh, that's just an easy, convenient answer.\nUm, if it's okay, I also want to give a shout out to dmlr.ai, which is the website where we post the latest, uh, about our our workshops at these various conferences.\nAnd there's a link to the DMLR Discord if, um, if people are interested in in following both the journal and the workshops.\nFantastic.\nYeah, great resources there.\nI'll be sure to have DMLR.ai in the show notes.\nUm, thank you so much, Lilith.\nThis has been great.\nUh, we'll have to catch up with you again in a few years when everyone's talking about data-centric machine learning and that's all that we're worried about instead of all these model benchmarks.\nAnd it may have had its moment already, right?\nI think for a minute people were talking about datacentric AI, uh, but it, uh, it never made it to the peak of inflated expectations or or what have you, kind of fell off the radar, but I'm still passionate about it.\nYeah, maybe we're still approaching it.\nI hope so.\nThanks.\nOlaf.\nThank you.\nSuch a great episode in it.\nLilith Bat-Leah covered how when companies sue each other, they often exchange millions of documents as potential evidence and how Epic's AI discovery assistant uses LLMs and retrieval augmented generation to classify these documents as relevant or irrelevant up to 90% faster than traditional methods.\nShe talked about how legal text illusion rate measures false negatives amongst predicted non-relevant documents.\nShe talked about how while 80% of data science work involves data cleaning, most research focuses on the 20% spent on models.\nShe talked about how the DMLR movement, the datacentric machine learning research movement backed by Andrew Ing and major conferences like Iclear, ICML and Nurups, aims to flip this by systematically improving data quality rather than just iterating on models.\nAnd she talked about how in legal settings where millions or billions of dollars are at stake, confidence intervals matter more than point estimates because understanding uncertainty is crucial when your evaluation metrics can be dissected in court.\nAs always, you can get all the show notes, including the transcript for this episode, the video recording, any materials mentioned on the show, the URLs for Lilith's social media profiles, as well as my own at superdatience.com/901.\nThanks of course to everyone on the Super Data Science podcast team.\nOur podcast manager Sonia Bravich, media editor Mario Pombo, our partnerships team, Nathan Daly and Natalie Jyski, our researcher Serge Miss, writer Dr. Zara Career, and yes, of course, our founder Kir Aramco.\nThanks to all of them for producing another outstanding episode for us today, for enabling that super team to create this free podcast for you.\nWe are deeply grateful to our sponsors.\nYou can support the show by checking out our sponsors links which are in the show notes.\nAnd if you yourself are interested in sponsoring an episode, you can head to johncone.com/mpodcast to find out how.\nOtherwise, share the episode with people who'd like to listen to it as well.\nReview it on wherever you listen to it.\nUh, subscribe, but most importantly, just keep on tuning in.\nI'm so grateful to have you listening and hope I can continue to make episodes you love for years and years to come.\nUntil next time, keep on rocking it out there and I'm looking forward to enjoying another round of the Super Data Science podcast with you very soon.\n",
  "dumpedAt": "2025-07-21T18:43:25.660Z"
}