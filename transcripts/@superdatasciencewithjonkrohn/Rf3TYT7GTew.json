{
  "episodeId": "Rf3TYT7GTew",
  "channelSlug": "@superdatasciencewithjonkrohn",
  "title": "881: Beyond GPUs: The Power of Custom AI Accelerators â€” with Emily Webber",
  "publishedAt": "2025-04-22T11:00:47.000Z",
  "rawLines": [
    {
      "lang": "en",
      "text": "why did you go from software to hardware",
      "offset": 0.16,
      "duration": 5.84
    },
    {
      "lang": "en",
      "text": "in the AI space i became convinced that",
      "offset": 3.28,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "obviously foundation models were the",
      "offset": 6,
      "duration": 6.32
    },
    {
      "lang": "en",
      "text": "future of of AI um but I also saw",
      "offset": 8.16,
      "duration": 7.439
    },
    {
      "lang": "en",
      "text": "increasingly how infrastructure was just",
      "offset": 12.32,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "the make or break like really everything",
      "offset": 15.599,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "came down to from a customer perspective",
      "offset": 18.32,
      "duration": 5.119
    },
    {
      "lang": "en",
      "text": "how many you know accelerators can I get",
      "offset": 21.119,
      "duration": 4.481
    },
    {
      "lang": "en",
      "text": "what is the size of those accelerators",
      "offset": 23.439,
      "duration": 4.641
    },
    {
      "lang": "en",
      "text": "how healthy are they and how efficiently",
      "offset": 25.6,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "can I train and host my models on top of",
      "offset": 28.08,
      "duration": 6.4
    },
    {
      "lang": "en",
      "text": "that reinventing many of the foundations",
      "offset": 30.32,
      "duration": 7.759
    },
    {
      "lang": "en",
      "text": "of the ML technology stack as a whole uh",
      "offset": 34.48,
      "duration": 6.56
    },
    {
      "lang": "en",
      "text": "on the cloud is just the absolute",
      "offset": 38.079,
      "duration": 5.041
    },
    {
      "lang": "en",
      "text": "biggest draw fundamentally we work with",
      "offset": 41.04,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "customers you get to be a part of the",
      "offset": 43.12,
      "duration": 5.15
    },
    {
      "lang": "en",
      "text": "whole life cycle",
      "offset": 45.04,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "[Music]",
      "offset": 48.27,
      "duration": 3.25
    },
    {
      "lang": "en",
      "text": "emily welcome to the Super Data Science",
      "offset": 49.92,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "podcast i'm so excited to have you on",
      "offset": 51.52,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "the show where are you calling in from",
      "offset": 53.36,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "today hi John i'm excited to be here i'm",
      "offset": 54.96,
      "duration": 6.8
    },
    {
      "lang": "en",
      "text": "calling in from Washington DC nice uh",
      "offset": 57.6,
      "duration": 6.199
    },
    {
      "lang": "en",
      "text": "it's uh interesting",
      "offset": 61.76,
      "duration": 5.92
    },
    {
      "lang": "en",
      "text": "times in that part of the world uh lots",
      "offset": 63.799,
      "duration": 5.401
    },
    {
      "lang": "en",
      "text": "of things happening but we're not here",
      "offset": 67.68,
      "duration": 2.96
    },
    {
      "lang": "en",
      "text": "we've never been a political show we",
      "offset": 69.2,
      "duration": 5.599
    },
    {
      "lang": "en",
      "text": "won't get into it um I uh at the time of",
      "offset": 70.64,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "recording I'm excited i'm looking",
      "offset": 74.799,
      "duration": 5.041
    },
    {
      "lang": "en",
      "text": "forward to uh being at the data and AI",
      "offset": 76.64,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "summit in Richmond Virginia which is not",
      "offset": 79.84,
      "duration": 4.639
    },
    {
      "lang": "en",
      "text": "crazy far from DC or at least Virginia",
      "offset": 81.6,
      "duration": 7.04
    },
    {
      "lang": "en",
      "text": "isn't and uh that part of the world uh",
      "offset": 84.479,
      "duration": 7.041
    },
    {
      "lang": "en",
      "text": "you know Virginia near DC i've always",
      "offset": 88.64,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "really enjoyed everything about it um",
      "offset": 91.52,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "except the traffic",
      "offset": 93.68,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "yeah no the the traffic is tough",
      "offset": 96.4,
      "duration": 3.679
    },
    {
      "lang": "en",
      "text": "actually this time of year it's lovely",
      "offset": 98.4,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "because the cherry blossoms are just",
      "offset": 100.079,
      "duration": 5.201
    },
    {
      "lang": "en",
      "text": "beginning to bloom so peak season for",
      "offset": 102.56,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "cherry blossoms is coming up at the end",
      "offset": 105.28,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "of March um but one of the primary",
      "offset": 107.6,
      "duration": 5.519
    },
    {
      "lang": "en",
      "text": "reasons I'm in DC is because it's the",
      "offset": 110.72,
      "duration": 6.2
    },
    {
      "lang": "en",
      "text": "HQ2 area for Amazon so it's our second",
      "offset": 113.119,
      "duration": 6.64
    },
    {
      "lang": "en",
      "text": "headquarters um you remember a number of",
      "offset": 116.92,
      "duration": 5.159
    },
    {
      "lang": "en",
      "text": "years ago we we did this sort of head",
      "offset": 119.759,
      "duration": 6.161
    },
    {
      "lang": "en",
      "text": "HQ2 search and uh Crystal City Virginia",
      "offset": 122.079,
      "duration": 7.04
    },
    {
      "lang": "en",
      "text": "was was awarded HQ2 uh and so I moved",
      "offset": 125.92,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "out here a number of years ago uh to be",
      "offset": 129.119,
      "duration": 4.881
    },
    {
      "lang": "en",
      "text": "a part of all of the activities and and",
      "offset": 131.36,
      "duration": 4.239
    },
    {
      "lang": "en",
      "text": "everything that's going on there that's",
      "offset": 134,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "very cool now that also it reminds me",
      "offset": 135.599,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "though wasn't it initially supposed to",
      "offset": 138.16,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "be Manhattan it was supposed to be New",
      "offset": 140.239,
      "duration": 3.761
    },
    {
      "lang": "en",
      "text": "York City and then there was like an",
      "offset": 141.92,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "uprising against it and so they had to",
      "offset": 144,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "they had to pick somewhere else cuz it",
      "offset": 145.84,
      "duration": 2.88
    },
    {
      "lang": "en",
      "text": "was like there was this concern I can't",
      "offset": 147.12,
      "duration": 3
    },
    {
      "lang": "en",
      "text": "remember exactly but that like it would",
      "offset": 148.72,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "change too much like too fast like this",
      "offset": 150.12,
      "duration": 4.92
    },
    {
      "lang": "en",
      "text": "huge influx of people into an already",
      "offset": 153.44,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "busy place or something like that yeah",
      "offset": 155.04,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "no there were there were a lot of great",
      "offset": 157.28,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "cities obviously a lot of great choices",
      "offset": 159.2,
      "duration": 5.759
    },
    {
      "lang": "en",
      "text": "i I think the original uh spec was was",
      "offset": 161.2,
      "duration": 6.399
    },
    {
      "lang": "en",
      "text": "spread across three cities i think when",
      "offset": 164.959,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "they first announced it it was like New",
      "offset": 167.599,
      "duration": 6.241
    },
    {
      "lang": "en",
      "text": "York DC and then I want to say somewhere",
      "offset": 169.28,
      "duration": 7.679
    },
    {
      "lang": "en",
      "text": "in Tennessee if I'm not mistaken uh and",
      "offset": 173.84,
      "duration": 5.039
    },
    {
      "lang": "en",
      "text": "then that's that sort of boiled down",
      "offset": 176.959,
      "duration": 6.161
    },
    {
      "lang": "en",
      "text": "into uh definitely the DC area and um",
      "offset": 178.879,
      "duration": 7.44
    },
    {
      "lang": "en",
      "text": "some other places as well but yeah not",
      "offset": 183.12,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "primarily DC nice well I'm glad it's",
      "offset": 186.319,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "working out there it sounds like a great",
      "offset": 188.56,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "environment to work in certainly AWS is",
      "offset": 190.72,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "doing a lot of exciting things i thought",
      "offset": 193.28,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "that we might start we almost never",
      "offset": 196.08,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "start with going with with somebody's",
      "offset": 198.64,
      "duration": 4.879
    },
    {
      "lang": "en",
      "text": "career path but in your case we're going",
      "offset": 201.04,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "to do that because you have a unique",
      "offset": 203.519,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "career trajectory that I think provides",
      "offset": 205.92,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "some good context for the rest of the",
      "offset": 207.84,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "episode so you started with a degree in",
      "offset": 209.12,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "international finance and now you've",
      "offset": 211.28,
      "duration": 4.239
    },
    {
      "lang": "en",
      "text": "been a hands-on practitioner at Amazon",
      "offset": 213.76,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "for some time uh working on AI and",
      "offset": 215.519,
      "duration": 5.201
    },
    {
      "lang": "en",
      "text": "machine learning so tell us about that",
      "offset": 218.56,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "transition to what you're doing today",
      "offset": 220.72,
      "duration": 6.48
    },
    {
      "lang": "en",
      "text": "your your draw to a IML yeah totally so",
      "offset": 222.959,
      "duration": 6.881
    },
    {
      "lang": "en",
      "text": "I would say I got into computer science",
      "offset": 227.2,
      "duration": 6.16
    },
    {
      "lang": "en",
      "text": "a little bit later um definitely I uh",
      "offset": 229.84,
      "duration": 6.08
    },
    {
      "lang": "en",
      "text": "lived in Arizona actually is is where I",
      "offset": 233.36,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "got that degree from a school called",
      "offset": 235.92,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "Prescuit College um and I studied uh",
      "offset": 237.2,
      "duration": 6.239
    },
    {
      "lang": "en",
      "text": "definitely finance um I was actually",
      "offset": 241.12,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "interested in Buddhism as well so I",
      "offset": 243.439,
      "duration": 5.921
    },
    {
      "lang": "en",
      "text": "lived at a retreat center uh for many",
      "offset": 245.92,
      "duration": 7.36
    },
    {
      "lang": "en",
      "text": "years and studied um yeah studied",
      "offset": 249.36,
      "duration": 7.2
    },
    {
      "lang": "en",
      "text": "meditation and all sorts of things you",
      "offset": 253.28,
      "duration": 8
    },
    {
      "lang": "en",
      "text": "do seem super zen super empathetic our",
      "offset": 256.56,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "listeners wouldn't know this but we were",
      "offset": 261.28,
      "duration": 2.72
    },
    {
      "lang": "en",
      "text": "talking for a while before starting",
      "offset": 262.56,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "recording and I was like &quot;Wow Emily is",
      "offset": 264,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "just like such an engaging Yeah",
      "offset": 266.479,
      "duration": 4.961
    },
    {
      "lang": "en",
      "text": "empathetic person.&quot; And I don't know so",
      "offset": 268.8,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "all that time in the monastery I think",
      "offset": 271.44,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "paid off yes i I find myself coming back",
      "offset": 272.72,
      "duration": 6.64
    },
    {
      "lang": "en",
      "text": "to this grounding many times actually",
      "offset": 276.08,
      "duration": 5.679
    },
    {
      "lang": "en",
      "text": "because when we're in computer science",
      "offset": 279.36,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "right when we're trying to solve an",
      "offset": 281.759,
      "duration": 3.521
    },
    {
      "lang": "en",
      "text": "algorithmic problem trying to solve a",
      "offset": 283.12,
      "duration": 4.639
    },
    {
      "lang": "en",
      "text": "compute problem a development problem",
      "offset": 285.28,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "you know many times um what we really",
      "offset": 287.759,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "need is focus actually we need the",
      "offset": 290.56,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "ability to just bring our mind back to",
      "offset": 292.639,
      "duration": 6.641
    },
    {
      "lang": "en",
      "text": "what the goal is what the details are",
      "offset": 296,
      "duration": 6.4
    },
    {
      "lang": "en",
      "text": "what the challenge is and not be",
      "offset": 299.28,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "overwhelmed by you know getting too",
      "offset": 302.4,
      "duration": 5.359
    },
    {
      "lang": "en",
      "text": "fixated on something or being afraid of",
      "offset": 305.28,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "something and so just developing this",
      "offset": 307.759,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "sort of mental ability to like calmly",
      "offset": 310.08,
      "duration": 7.28
    },
    {
      "lang": "en",
      "text": "abide and calmly you know focus um has",
      "offset": 313.199,
      "duration": 6.641
    },
    {
      "lang": "en",
      "text": "honestly been really helpful uh in my",
      "offset": 317.36,
      "duration": 6.16
    },
    {
      "lang": "en",
      "text": "computer science you know degree um so I",
      "offset": 319.84,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "studied at the University of Chicago",
      "offset": 323.52,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "after that and did a joint degree that",
      "offset": 325.6,
      "duration": 6.8
    },
    {
      "lang": "en",
      "text": "was um a master's of public policy with",
      "offset": 328.32,
      "duration": 6.8
    },
    {
      "lang": "en",
      "text": "uh computational analysis actually so",
      "offset": 332.4,
      "duration": 5.359
    },
    {
      "lang": "en",
      "text": "studying like public policy projects",
      "offset": 335.12,
      "duration": 5.359
    },
    {
      "lang": "en",
      "text": "through the lens of computer science uh",
      "offset": 337.759,
      "duration": 5.521
    },
    {
      "lang": "en",
      "text": "and so that was where I uh developed a",
      "offset": 340.479,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "love of data science um I interned at",
      "offset": 343.28,
      "duration": 4.639
    },
    {
      "lang": "en",
      "text": "what's called the data science for",
      "offset": 346.479,
      "duration": 5.041
    },
    {
      "lang": "en",
      "text": "summergood social fellowship um where we",
      "offset": 347.919,
      "duration": 6.481
    },
    {
      "lang": "en",
      "text": "analyzed uh public policy problems and",
      "offset": 351.52,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "worked with organizations who you know",
      "offset": 354.4,
      "duration": 6.639
    },
    {
      "lang": "en",
      "text": "were nonprofits or NOS's uh analyzed",
      "offset": 357.52,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "their data science and then you know",
      "offset": 361.039,
      "duration": 4.241
    },
    {
      "lang": "en",
      "text": "delivered projects to them and so that's",
      "offset": 362.88,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "sort of where I got you know very",
      "offset": 365.28,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "interested obviously in technology",
      "offset": 367.12,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "technology development uh and trying to",
      "offset": 369.28,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "make a positive impact in the world and",
      "offset": 372,
      "duration": 6.639
    },
    {
      "lang": "en",
      "text": "that has led me to AWS very nice and",
      "offset": 374.72,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "yeah you've worked extensively ly with",
      "offset": 378.639,
      "duration": 4.241
    },
    {
      "lang": "en",
      "text": "SageMaker which a lot of our data",
      "offset": 380.24,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "science listeners would be familiar with",
      "offset": 382.88,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "uh maybe you can give because you do a",
      "offset": 384.88,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "even better job than I could at",
      "offset": 386.8,
      "duration": 2.64
    },
    {
      "lang": "en",
      "text": "explaining what SageMaker is so you can",
      "offset": 388.08,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "let us know about SageMaker and other",
      "offset": 389.44,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "AWS AI services that you've worked with",
      "offset": 391.28,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "but now you're working on the Tranium",
      "offset": 394,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "and Inferentia team so it's hardware",
      "offset": 396.16,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "compute hardware that you would use",
      "offset": 398.4,
      "duration": 5.919
    },
    {
      "lang": "en",
      "text": "instead of a GPU you'd use a tranium or",
      "offset": 401.6,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "inferentia chip uh to be doing a lot of",
      "offset": 404.319,
      "duration": 4.641
    },
    {
      "lang": "en",
      "text": "the heavy lifting in training in the",
      "offset": 406.96,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "case of Tranium or at inference time",
      "offset": 408.96,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "with the inferentia chip and uh yeah so",
      "offset": 411.36,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "fill us in on SageMaker other AWS AI",
      "offset": 413.68,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "services that you worked on in the past",
      "offset": 416.72,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "and why hardware tranium inferentia took",
      "offset": 417.84,
      "duration": 6.24
    },
    {
      "lang": "en",
      "text": "your fancy recently yeah absolutely so I",
      "offset": 420.8,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "joined Amazon actually as one of our",
      "offset": 424.08,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "first SageMaker solution architect",
      "offset": 426.56,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "essays so I you know got to work with",
      "offset": 428.479,
      "duration": 5.361
    },
    {
      "lang": "en",
      "text": "some of our earliest customers in the",
      "offset": 432.16,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "SageMaker days and figure out what's an",
      "offset": 433.84,
      "duration": 6.479
    },
    {
      "lang": "en",
      "text": "essay cool so what is an essay so a",
      "offset": 436.56,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "solutions architect at AWS fundamentally",
      "offset": 440.319,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "we work with customers so that means",
      "offset": 442.56,
      "duration": 6.4
    },
    {
      "lang": "en",
      "text": "your uh your sort of your fingers are",
      "offset": 445.759,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "like on the heartbeat they're on the",
      "offset": 448.96,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "pulse of the business they're on the",
      "offset": 451.199,
      "duration": 4.481
    },
    {
      "lang": "en",
      "text": "pulse of the service because you're",
      "offset": 453.28,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "explaining what the service does to",
      "offset": 455.68,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "customers every day you're in the weeds",
      "offset": 457.599,
      "duration": 5.761
    },
    {
      "lang": "en",
      "text": "with developers with you know data",
      "offset": 460.56,
      "duration": 6.16
    },
    {
      "lang": "en",
      "text": "scientists um leadership on both a",
      "offset": 463.36,
      "duration": 5.839
    },
    {
      "lang": "en",
      "text": "customer and the service team about what",
      "offset": 466.72,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "feature A is doing how well it's doing",
      "offset": 469.199,
      "duration": 5.201
    },
    {
      "lang": "en",
      "text": "and what it needs to do in the future so",
      "offset": 472.08,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "I love being a solutions architect",
      "offset": 474.4,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "always profoundly enjoyed this as a role",
      "offset": 476.479,
      "duration": 5.681
    },
    {
      "lang": "en",
      "text": "because you have visibility into the",
      "offset": 478.96,
      "duration": 5.84
    },
    {
      "lang": "en",
      "text": "whole picture you you get to be a part",
      "offset": 482.16,
      "duration": 5.84
    },
    {
      "lang": "en",
      "text": "of the whole life cycle and so I was one",
      "offset": 484.8,
      "duration": 6.239
    },
    {
      "lang": "en",
      "text": "of our first uh um I was one of our",
      "offset": 488,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "first solution architects for SageMaker",
      "offset": 491.039,
      "duration": 6.28
    },
    {
      "lang": "en",
      "text": "so SageMaker is a managed ML",
      "offset": 494,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "infrastructure at AWS essentially you",
      "offset": 497.319,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "can use SageMaker to spin up a notebook",
      "offset": 500,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "server use SageMaker to spin up what we",
      "offset": 502.919,
      "duration": 4.921
    },
    {
      "lang": "en",
      "text": "call training jobs which is where you're",
      "offset": 505.52,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "training your model in the context of a",
      "offset": 507.84,
      "duration": 5.92
    },
    {
      "lang": "en",
      "text": "job uh use SageMaker to spin up uh ML",
      "offset": 509.919,
      "duration": 6.881
    },
    {
      "lang": "en",
      "text": "hosting infrastructure we have uh",
      "offset": 513.76,
      "duration": 5.199
    },
    {
      "lang": "en",
      "text": "prepackaged models that are available in",
      "offset": 516.8,
      "duration": 4.239
    },
    {
      "lang": "en",
      "text": "SageMaker that you can pull down for",
      "offset": 518.959,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "training and hosting and we have a",
      "offset": 521.039,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "really cool development environment so",
      "offset": 523.12,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "SageMaker Studio and the Unified Studio",
      "offset": 525.44,
      "duration": 6.079
    },
    {
      "lang": "en",
      "text": "that lets a data scientist um so",
      "offset": 528.64,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "actually what it does is it decouples",
      "offset": 531.519,
      "duration": 5.401
    },
    {
      "lang": "en",
      "text": "the UI that's hosting your development",
      "offset": 534,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "environment from all of the compute",
      "offset": 536.92,
      "duration": 4.68
    },
    {
      "lang": "en",
      "text": "that's like running your notebook and",
      "offset": 539.44,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "running your analytics job and we",
      "offset": 541.6,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "package it up really really nicely so",
      "offset": 543.68,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "SageMaker Studio is a great like data",
      "offset": 546.56,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "science workbench for example where an",
      "offset": 549.12,
      "duration": 4.719
    },
    {
      "lang": "en",
      "text": "enterprise data science team can just",
      "offset": 551.36,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "get onboarded have all the tools that",
      "offset": 553.839,
      "duration": 5.841
    },
    {
      "lang": "en",
      "text": "they need to go analyze some data and",
      "offset": 555.92,
      "duration": 7.52
    },
    {
      "lang": "en",
      "text": "train some models very nice yeah and uh",
      "offset": 559.68,
      "duration": 6.08
    },
    {
      "lang": "en",
      "text": "yeah so then what was the what was the",
      "offset": 563.44,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "transition like why did why did you go",
      "offset": 565.76,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "from software to hardware in the AI",
      "offset": 567.839,
      "duration": 6.401
    },
    {
      "lang": "en",
      "text": "space yeah absolutely so through many",
      "offset": 570.8,
      "duration": 7.84
    },
    {
      "lang": "en",
      "text": "years on SageMaker uh like many people",
      "offset": 574.24,
      "duration": 7.36
    },
    {
      "lang": "en",
      "text": "um I saw how important foundation models",
      "offset": 578.64,
      "duration": 6.04
    },
    {
      "lang": "en",
      "text": "were it was obvious that customers were",
      "offset": 581.6,
      "duration": 6.16
    },
    {
      "lang": "en",
      "text": "increasingly going to foundation models",
      "offset": 584.68,
      "duration": 5.88
    },
    {
      "lang": "en",
      "text": "um for you know their ability to unlock",
      "offset": 587.76,
      "duration": 5.519
    },
    {
      "lang": "en",
      "text": "a variety of use cases but also the size",
      "offset": 590.56,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "of the models just kept getting larger",
      "offset": 593.279,
      "duration": 4.961
    },
    {
      "lang": "en",
      "text": "and larger and they were just consuming",
      "offset": 595.76,
      "duration": 7.36
    },
    {
      "lang": "en",
      "text": "so many resources and so I um set up",
      "offset": 598.24,
      "duration": 6.8
    },
    {
      "lang": "en",
      "text": "many of our distributed training",
      "offset": 603.12,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "capabilities so we were running",
      "offset": 605.04,
      "duration": 3.359
    },
    {
      "lang": "en",
      "text": "distributed training workshops with",
      "offset": 606.64,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "customers uh we were doing uh",
      "offset": 608.399,
      "duration": 5.041
    },
    {
      "lang": "en",
      "text": "accelerator health checks we were",
      "offset": 611.12,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "developing managed clusters and that led",
      "offset": 613.44,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "to a service called SageMaker Hyper Pod",
      "offset": 615.92,
      "duration": 6.12
    },
    {
      "lang": "en",
      "text": "um which is a fully",
      "offset": 618.88,
      "duration": 6.399
    },
    {
      "lang": "en",
      "text": "managed parallel environment to",
      "offset": 622.04,
      "duration": 5.72
    },
    {
      "lang": "en",
      "text": "establish clusters essentially so when",
      "offset": 625.279,
      "duration": 6.641
    },
    {
      "lang": "en",
      "text": "you want to train uh and host uh large",
      "offset": 627.76,
      "duration": 5.92
    },
    {
      "lang": "en",
      "text": "uh language models and large foundation",
      "offset": 631.92,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "models on AWS SageMaker Hyperpod is a",
      "offset": 633.68,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "really easy way to have a managed slurm",
      "offset": 636.72,
      "duration": 6.239
    },
    {
      "lang": "en",
      "text": "environment that you can hop into and",
      "offset": 638.88,
      "duration": 7.12
    },
    {
      "lang": "en",
      "text": "take advantage of optimized libraries",
      "offset": 642.959,
      "duration": 6.32
    },
    {
      "lang": "en",
      "text": "and have a variety of health checks and",
      "offset": 646,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "cluster management tools already",
      "offset": 649.279,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "available for you without needing to",
      "offset": 651.6,
      "duration": 5.919
    },
    {
      "lang": "en",
      "text": "develop that and so through this journey",
      "offset": 653.36,
      "duration": 6.479
    },
    {
      "lang": "en",
      "text": "um I became convinced that obviously",
      "offset": 657.519,
      "duration": 5.281
    },
    {
      "lang": "en",
      "text": "foundation models were the future of of",
      "offset": 659.839,
      "duration": 7.521
    },
    {
      "lang": "en",
      "text": "AI um but I also saw increasingly how",
      "offset": 662.8,
      "duration": 6.88
    },
    {
      "lang": "en",
      "text": "infrastructure was just the make or",
      "offset": 667.36,
      "duration": 4.719
    },
    {
      "lang": "en",
      "text": "break like really everything came down",
      "offset": 669.68,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "to from a customer perspective how many",
      "offset": 672.079,
      "duration": 5.041
    },
    {
      "lang": "en",
      "text": "you know accelerators can I get what is",
      "offset": 675.04,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "the size of those accelerators how",
      "offset": 677.12,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "healthy are they and how efficiently can",
      "offset": 679.04,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "I train and host my models on top of",
      "offset": 681.519,
      "duration": 6.161
    },
    {
      "lang": "en",
      "text": "that once I realized that that was the",
      "offset": 683.6,
      "duration": 6.76
    },
    {
      "lang": "en",
      "text": "game that that was the primary focus for",
      "offset": 687.68,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "customers I just wanted to dive in",
      "offset": 690.36,
      "duration": 5.159
    },
    {
      "lang": "en",
      "text": "figure out what does it take to actually",
      "offset": 693.36,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "develop a new accelerator uh how do you",
      "offset": 695.519,
      "duration": 5.281
    },
    {
      "lang": "en",
      "text": "develop a software stack on top of that",
      "offset": 698.16,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "and then how do you expose that through",
      "offset": 700.8,
      "duration": 5.039
    },
    {
      "lang": "en",
      "text": "the rest of the cloud so fundamentally I",
      "offset": 703.12,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "love the business opportunity uh it's",
      "offset": 705.839,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "just really exciting to think about",
      "offset": 708.88,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "obviously developing new accelerators",
      "offset": 711.279,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "and bringing those to customers but also",
      "offset": 713.36,
      "duration": 4.479
    },
    {
      "lang": "en",
      "text": "the technical problems are just so",
      "offset": 715.519,
      "duration": 4.721
    },
    {
      "lang": "en",
      "text": "interesting like it is absolutely a joy",
      "offset": 717.839,
      "duration": 5.201
    },
    {
      "lang": "en",
      "text": "to sit down and think about okay how do",
      "offset": 720.24,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "I write a kernel for this algorithm how",
      "offset": 723.04,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "do we design like communication",
      "offset": 725.6,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "collectives for this whole host of",
      "offset": 727.68,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "workloads like reinventing many of the",
      "offset": 729.519,
      "duration": 6.641
    },
    {
      "lang": "en",
      "text": "foundations of the ML technology stack",
      "offset": 733.36,
      "duration": 6.8
    },
    {
      "lang": "en",
      "text": "as a whole uh on the cloud is just the",
      "offset": 736.16,
      "duration": 6.799
    },
    {
      "lang": "en",
      "text": "absolute biggest draw in my mind wow",
      "offset": 740.16,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "yeah you are your genuine excitement for",
      "offset": 742.959,
      "duration": 5.761
    },
    {
      "lang": "en",
      "text": "it uh really shines through absolutely",
      "offset": 745.44,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "so uh you've said the word accelerate a",
      "offset": 748.72,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "few times i I just want to disambiguate",
      "offset": 750.88,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "that is so earlier when I said you would",
      "offset": 752.72,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "use a tranium or inferentia chip in lie",
      "offset": 755.36,
      "duration": 7.36
    },
    {
      "lang": "en",
      "text": "of a GPU that term accelerator would",
      "offset": 758.72,
      "duration": 6.48
    },
    {
      "lang": "en",
      "text": "apply to like it's it's the broader",
      "offset": 762.72,
      "duration": 4.44
    },
    {
      "lang": "en",
      "text": "umbrella that includes tranium",
      "offset": 765.2,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "inferentia and GPUs these are all",
      "offset": 767.16,
      "duration": 4.44
    },
    {
      "lang": "en",
      "text": "different kinds of hardware accelerators",
      "offset": 769.36,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "specialized in the case of trainium and",
      "offset": 771.6,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "inferentia specifically for neural",
      "offset": 773.519,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "networks for deep learning models like",
      "offset": 775.76,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "the like the large language models that",
      "offset": 777.839,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "have uh taken the world by storm and",
      "offset": 780.32,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "that got you the foundation models that",
      "offset": 781.92,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "got you excited about moving into this",
      "offset": 783.36,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "space and it is it's hardware driven",
      "offset": 785.76,
      "duration": 3.759
    },
    {
      "lang": "en",
      "text": "such an interesting phenomenon to watch",
      "offset": 787.519,
      "duration": 4.961
    },
    {
      "lang": "en",
      "text": "from a distance where the scientific",
      "offset": 789.519,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "advances the kind of new ideas in terms",
      "offset": 792.48,
      "duration": 6.28
    },
    {
      "lang": "en",
      "text": "of how should we model they're not",
      "offset": 795.279,
      "duration": 5.921
    },
    {
      "lang": "en",
      "text": "necessarily super fast moving like the",
      "offset": 798.76,
      "duration": 5.319
    },
    {
      "lang": "en",
      "text": "transformer idea many years later is",
      "offset": 801.2,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "still the dominant paradigm and at some",
      "offset": 804.079,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "point that may be replaced and that",
      "offset": 806.16,
      "duration": 4.239
    },
    {
      "lang": "en",
      "text": "builds upon deep learning which is seems",
      "offset": 807.839,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "like an even more entrenched paradigm",
      "offset": 810.399,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "that will be difficult to shake um maybe",
      "offset": 812.16,
      "duration": 4.239
    },
    {
      "lang": "en",
      "text": "a nice thing when you're designing",
      "offset": 814.8,
      "duration": 3.039
    },
    {
      "lang": "en",
      "text": "accelerators because it means you have",
      "offset": 816.399,
      "duration": 3.521
    },
    {
      "lang": "en",
      "text": "some kind of like linear algebra some",
      "offset": 817.839,
      "duration": 3.361
    },
    {
      "lang": "en",
      "text": "kinds of matrix multiplication",
      "offset": 819.92,
      "duration": 2.719
    },
    {
      "lang": "en",
      "text": "operations that you can be like we're",
      "offset": 821.2,
      "duration": 2.639
    },
    {
      "lang": "en",
      "text": "probably still going to be doing that in",
      "offset": 822.639,
      "duration": 2.361
    },
    {
      "lang": "en",
      "text": "5",
      "offset": 823.839,
      "duration": 4.641
    },
    {
      "lang": "en",
      "text": "years um but uh yeah it sounds like a",
      "offset": 825,
      "duration": 5.16
    },
    {
      "lang": "en",
      "text": "really exciting uh space to be working",
      "offset": 828.48,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "in there's a term that you mentioned as",
      "offset": 830.16,
      "duration": 4.479
    },
    {
      "lang": "en",
      "text": "as you were describing uh what excites",
      "offset": 832.56,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "you most about your work that I've got",
      "offset": 834.639,
      "duration": 3.361
    },
    {
      "lang": "en",
      "text": "to admit I don't understand very well",
      "offset": 836.639,
      "duration": 2.64
    },
    {
      "lang": "en",
      "text": "and so I bet a lot of our audience",
      "offset": 838,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "doesn't as well which is this idea of a",
      "offset": 839.279,
      "duration": 4.641
    },
    {
      "lang": "en",
      "text": "kernel so when you talk about an",
      "offset": 841.92,
      "duration": 6.159
    },
    {
      "lang": "en",
      "text": "algorithm kernel what does that mean",
      "offset": 843.92,
      "duration": 8.32
    },
    {
      "lang": "en",
      "text": "absolutely so fundamentally a kernel is",
      "offset": 848.079,
      "duration": 9.361
    },
    {
      "lang": "en",
      "text": "a function that's defined by the user",
      "offset": 852.24,
      "duration": 7.52
    },
    {
      "lang": "en",
      "text": "and when you're thinking about",
      "offset": 857.44,
      "duration": 5.519
    },
    {
      "lang": "en",
      "text": "programming up at the Python level we",
      "offset": 859.76,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "don't really think about that way",
      "offset": 862.959,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "everything we define is userdefined so",
      "offset": 864.56,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "we're like what gives everything I write",
      "offset": 866.56,
      "duration": 4.519
    },
    {
      "lang": "en",
      "text": "is a userdefined function",
      "offset": 868.56,
      "duration": 6.079
    },
    {
      "lang": "en",
      "text": "this thinking breaks down the further",
      "offset": 871.079,
      "duration": 7
    },
    {
      "lang": "en",
      "text": "down the compute stack you go so if you",
      "offset": 874.639,
      "duration": 5.601
    },
    {
      "lang": "en",
      "text": "want to run a program on trainium and",
      "offset": 878.079,
      "duration": 5.041
    },
    {
      "lang": "en",
      "text": "inferencia for example the way that",
      "offset": 880.24,
      "duration": 5.48
    },
    {
      "lang": "en",
      "text": "happens is you write your program in",
      "offset": 883.12,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "Python you write your program in PyTorch",
      "offset": 885.72,
      "duration": 7.16
    },
    {
      "lang": "en",
      "text": "and then you're going to compile that",
      "offset": 889.12,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "through something that's called PyTorch",
      "offset": 892.88,
      "duration": 4.959
    },
    {
      "lang": "en",
      "text": "XLA so accelerated linear algebra what",
      "offset": 894.8,
      "duration": 5.92
    },
    {
      "lang": "en",
      "text": "PyTorch XLA is going to do it's going to",
      "offset": 897.839,
      "duration": 6.641
    },
    {
      "lang": "en",
      "text": "take the model that you defined and it's",
      "offset": 900.72,
      "duration": 7.359
    },
    {
      "lang": "en",
      "text": "going to represent that as a graph",
      "offset": 904.48,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "essentially so the structure of your",
      "offset": 908.079,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "model is represented as a graph we call",
      "offset": 909.76,
      "duration": 6.4
    },
    {
      "lang": "en",
      "text": "that graph an HLO highle operations so",
      "offset": 912.399,
      "duration": 7.12
    },
    {
      "lang": "en",
      "text": "you get this HLO graph and then",
      "offset": 916.16,
      "duration": 6.4
    },
    {
      "lang": "en",
      "text": "essentially we do a handshake between",
      "offset": 919.519,
      "duration": 7.521
    },
    {
      "lang": "en",
      "text": "that HLO graph that's generated from XLA",
      "offset": 922.56,
      "duration": 7.56
    },
    {
      "lang": "en",
      "text": "and we feed that into the top of our",
      "offset": 927.04,
      "duration": 7.239
    },
    {
      "lang": "en",
      "text": "compiler and so we maintain a compiler",
      "offset": 930.12,
      "duration": 9.079
    },
    {
      "lang": "en",
      "text": "that takes the graph that you produced",
      "offset": 934.279,
      "duration": 8.521
    },
    {
      "lang": "en",
      "text": "from PyTorch and from PyTorch XLA and we",
      "offset": 939.199,
      "duration": 6.721
    },
    {
      "lang": "en",
      "text": "convert that through a variety iety of",
      "offset": 942.8,
      "duration": 6.159
    },
    {
      "lang": "en",
      "text": "algorithms and processes to ultimately",
      "offset": 945.92,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "generate the instruction set that",
      "offset": 948.959,
      "duration": 5.481
    },
    {
      "lang": "en",
      "text": "actually gets executed on the hardware",
      "offset": 951.6,
      "duration": 6.64
    },
    {
      "lang": "en",
      "text": "directly so what's a kernel a kernel is",
      "offset": 954.44,
      "duration": 8.44
    },
    {
      "lang": "en",
      "text": "where you override the compiler and you",
      "offset": 958.24,
      "duration": 8.599
    },
    {
      "lang": "en",
      "text": "get to define the operations on the chip",
      "offset": 962.88,
      "duration": 7.28
    },
    {
      "lang": "en",
      "text": "yourself using our kernel library and",
      "offset": 966.839,
      "duration": 6.041
    },
    {
      "lang": "en",
      "text": "our kernel library is called Nikki the",
      "offset": 970.16,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "neuron kernel interface so fundamentally",
      "offset": 972.88,
      "duration": 6.879
    },
    {
      "lang": "en",
      "text": "a kernel is a function that's defined by",
      "offset": 975.6,
      "duration": 7.679
    },
    {
      "lang": "en",
      "text": "the user and not as generated through",
      "offset": 979.759,
      "duration": 6.32
    },
    {
      "lang": "en",
      "text": "the compiler now there's a huge variety",
      "offset": 983.279,
      "duration": 6.081
    },
    {
      "lang": "en",
      "text": "of um sizes of kernels right so you can",
      "offset": 986.079,
      "duration": 6.88
    },
    {
      "lang": "en",
      "text": "have a kernel that's really just a hello",
      "offset": 989.36,
      "duration": 6.32
    },
    {
      "lang": "en",
      "text": "world function where it's like hey I did",
      "offset": 992.959,
      "duration": 5.201
    },
    {
      "lang": "en",
      "text": "a matal or I did like tensor ad right",
      "offset": 995.68,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "and that's like to get the software",
      "offset": 998.16,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "working and make sure you have the",
      "offset": 999.92,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "environment you know ready um but then",
      "offset": 1001.44,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "what most people will do is build on top",
      "offset": 1003.92,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "of that to define a full operation so",
      "offset": 1006,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "you'll define like a full forward pass",
      "offset": 1009.12,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "for your model or a full backward pass",
      "offset": 1011.36,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "or even just a part of it like maybe",
      "offset": 1013.519,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "just the MLP you know up projection or",
      "offset": 1015.6,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "down projection and then what you're",
      "offset": 1018.639,
      "duration": 4.241
    },
    {
      "lang": "en",
      "text": "doing is you're studying the compute",
      "offset": 1020.88,
      "duration": 4.799
    },
    {
      "lang": "en",
      "text": "optimization of that kernel like you",
      "offset": 1022.88,
      "duration": 4.559
    },
    {
      "lang": "en",
      "text": "want to look at the data movement you",
      "offset": 1025.679,
      "duration": 4.481
    },
    {
      "lang": "en",
      "text": "want to look at the you know utilization",
      "offset": 1027.439,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "you want to look at your memory",
      "offset": 1030.16,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "utilization your compute utilization and",
      "offset": 1031.919,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "so I know you've had Ron on the session",
      "offset": 1034.16,
      "duration": 4.639
    },
    {
      "lang": "en",
      "text": "in the past and so like everything Ron",
      "offset": 1036.24,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "you know teaches us and teaches the",
      "offset": 1038.799,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "world about like compute optimization we",
      "offset": 1040.64,
      "duration": 6.48
    },
    {
      "lang": "en",
      "text": "try to apply that when we're developing",
      "offset": 1043.679,
      "duration": 7.041
    },
    {
      "lang": "en",
      "text": "our kernels so we study like the compute",
      "offset": 1047.12,
      "duration": 6.24
    },
    {
      "lang": "en",
      "text": "requirements of a workload and we try to",
      "offset": 1050.72,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "improve it like that is the heart of of",
      "offset": 1053.36,
      "duration": 6.64
    },
    {
      "lang": "en",
      "text": "writing a kernel and implementing this",
      "offset": 1056.32,
      "duration": 6.56
    },
    {
      "lang": "en",
      "text": "algorithm that you have that's trying to",
      "offset": 1060,
      "duration": 4.799
    },
    {
      "lang": "en",
      "text": "improve something for large language",
      "offset": 1062.88,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "models we implement that as a kernel in",
      "offset": 1064.799,
      "duration": 7.281
    },
    {
      "lang": "en",
      "text": "order to improve the performance for it",
      "offset": 1068.08,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "excited to announce my friends that the",
      "offset": 1072.08,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "10th annual ODSC East the Open Data",
      "offset": 1073.76,
      "duration": 5.279
    },
    {
      "lang": "en",
      "text": "Science Conference East the one",
      "offset": 1076.88,
      "duration": 3.88
    },
    {
      "lang": "en",
      "text": "conference you don't want to miss in",
      "offset": 1079.039,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "2025 is returning to Boston from May",
      "offset": 1080.76,
      "duration": 5.159
    },
    {
      "lang": "en",
      "text": "13th to 15th and I'll be there leading a",
      "offset": 1083.44,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "4-hour hands-on workshop on designing",
      "offset": 1085.919,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "and deploying AI agents in Python odsc",
      "offset": 1088.16,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "East is 3 days packed with hands-on",
      "offset": 1091.679,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "sessions and deep dives into cutting",
      "offset": 1093.6,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "edge AI topics all taught by worldclass",
      "offset": 1095.039,
      "duration": 4.961
    },
    {
      "lang": "en",
      "text": "AI experts plus there are many great",
      "offset": 1097.52,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "networking opportunities odsc East is",
      "offset": 1100,
      "duration": 3.679
    },
    {
      "lang": "en",
      "text": "seriously my favorite conference in the",
      "offset": 1102.24,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "world no matter your skill level ODSC",
      "offset": 1103.679,
      "duration": 3.761
    },
    {
      "lang": "en",
      "text": "East will help you gain the AI expertise",
      "offset": 1105.44,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "to take your career to the next level",
      "offset": 1107.44,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "don't miss online special discount ends",
      "offset": 1109.12,
      "duration": 5.84
    },
    {
      "lang": "en",
      "text": "soon learn more at",
      "offset": 1111.52,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "odsc.com/boston an excellent explanation",
      "offset": 1116.52,
      "duration": 4.68
    },
    {
      "lang": "en",
      "text": "you are an outstanding teacher and we",
      "offset": 1118.88,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "will actually get later get to later in",
      "offset": 1121.2,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "this episode uh some of the educational",
      "offset": 1123.6,
      "duration": 2.8
    },
    {
      "lang": "en",
      "text": "stuff that you've been doing you're kind",
      "offset": 1125.28,
      "duration": 2.84
    },
    {
      "lang": "en",
      "text": "of an inspiration there but you're",
      "offset": 1126.4,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "naturally such an amazing explainer that",
      "offset": 1128.12,
      "duration": 4.6
    },
    {
      "lang": "en",
      "text": "was like 99th percentile of expl",
      "offset": 1130.32,
      "duration": 4.239
    },
    {
      "lang": "en",
      "text": "explanations of technical concepts that",
      "offset": 1132.72,
      "duration": 2.959
    },
    {
      "lang": "en",
      "text": "I've ever heard so thank you for that",
      "offset": 1134.559,
      "duration": 2.961
    },
    {
      "lang": "en",
      "text": "introduction to kernels and if people",
      "offset": 1135.679,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "are interested in that Ron Diamont",
      "offset": 1137.52,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "episode it's number 691 of this podcast",
      "offset": 1139.28,
      "duration": 5.759
    },
    {
      "lang": "en",
      "text": "also an amazing explainer of technical",
      "offset": 1142.72,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "concepts so if you want to understand a",
      "offset": 1145.039,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "lot in that episode we talked a ton",
      "offset": 1146.88,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "about designing accelerators",
      "offset": 1148.96,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "um and I learned so much in that episode",
      "offset": 1151.52,
      "duration": 7.12
    },
    {
      "lang": "en",
      "text": "it was amazing in fact Ron is such a",
      "offset": 1154,
      "duration": 8.08
    },
    {
      "lang": "en",
      "text": "luminary in this space um that at",
      "offset": 1158.64,
      "duration": 5.48
    },
    {
      "lang": "en",
      "text": "Nurip's neural information processing",
      "offset": 1162.08,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "systems arguably the most prestigious um",
      "offset": 1164.12,
      "duration": 6.04
    },
    {
      "lang": "en",
      "text": "academic AI conference in the world I",
      "offset": 1168.08,
      "duration": 4.719
    },
    {
      "lang": "en",
      "text": "was I was there in Vancouver in December",
      "offset": 1170.16,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "and I I met somebody new at like at",
      "offset": 1172.799,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "lunch or at dinner or something i can't",
      "offset": 1175.28,
      "duration": 2.8
    },
    {
      "lang": "en",
      "text": "remember exactly the context but they",
      "offset": 1176.48,
      "duration": 3.199
    },
    {
      "lang": "en",
      "text": "worked on training him in Frenchi chips",
      "offset": 1178.08,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "and it said &quot;Oh we had someone from the",
      "offset": 1179.679,
      "duration": 3.961
    },
    {
      "lang": "en",
      "text": "show.&quot; He was like &quot;Was it",
      "offset": 1181.6,
      "duration": 7.439
    },
    {
      "lang": "en",
      "text": "Ron?&quot; Uh so yes absolutely he's he's an",
      "offset": 1183.64,
      "duration": 9.399
    },
    {
      "lang": "en",
      "text": "iconic person in this space um yeah so",
      "offset": 1189.039,
      "duration": 6.561
    },
    {
      "lang": "en",
      "text": "fantastic there there there was a lot uh",
      "offset": 1193.039,
      "duration": 5.441
    },
    {
      "lang": "en",
      "text": "in there uh that some people might might",
      "offset": 1195.6,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "want to go back over uh to learn again",
      "offset": 1198.48,
      "duration": 4.559
    },
    {
      "lang": "en",
      "text": "about kernels uh there was one term in",
      "offset": 1201.12,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "there uh that I that I might define",
      "offset": 1203.039,
      "duration": 6.081
    },
    {
      "lang": "en",
      "text": "quickly for the audience so you said MLP",
      "offset": 1206.48,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "uh kind of casually in there is you know",
      "offset": 1209.12,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "one of the things that you could be",
      "offset": 1211.84,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "implementing in a kernel um and uh so",
      "offset": 1213.12,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "multi-layer perceptron I'm guessing is",
      "offset": 1216.88,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "what what that is there yeah and so kind",
      "offset": 1218.88,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "of like a one of the fundamental",
      "offset": 1221.12,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "building blocks it's it's like when",
      "offset": 1224,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "you're thinking about building a deep",
      "offset": 1226,
      "duration": 3.039
    },
    {
      "lang": "en",
      "text": "learning network a multi-layer",
      "offset": 1227.28,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "perceptron is kind of like a it was an",
      "offset": 1229.039,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "early deep learning network but then you",
      "offset": 1231.12,
      "duration": 2.64
    },
    {
      "lang": "en",
      "text": "can also think about it now as something",
      "offset": 1232.559,
      "duration": 2.961
    },
    {
      "lang": "en",
      "text": "that you can scale up into a bigger",
      "offset": 1233.76,
      "duration": 5.039
    },
    {
      "lang": "en",
      "text": "architecture yes and it's it's really",
      "offset": 1235.52,
      "duration": 7.36
    },
    {
      "lang": "en",
      "text": "interesting to think about how we",
      "offset": 1238.799,
      "duration": 7.441
    },
    {
      "lang": "en",
      "text": "represent data for kernels actually so",
      "offset": 1242.88,
      "duration": 6.159
    },
    {
      "lang": "en",
      "text": "the MLP itself right when you're",
      "offset": 1246.24,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "designing say like a baby MLP or a tiny",
      "offset": 1249.039,
      "duration": 6.88
    },
    {
      "lang": "en",
      "text": "MLP in PyTorch it's crazy easy to do",
      "offset": 1252,
      "duration": 7.6
    },
    {
      "lang": "en",
      "text": "that right it's so easy to just define",
      "offset": 1255.919,
      "duration": 6.481
    },
    {
      "lang": "en",
      "text": "your tensor define the operations you",
      "offset": 1259.6,
      "duration": 5.199
    },
    {
      "lang": "en",
      "text": "want to do and call it and in from the",
      "offset": 1262.4,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "PyTorch perspective that's it your job",
      "offset": 1264.799,
      "duration": 6.161
    },
    {
      "lang": "en",
      "text": "is done you've you've created an MLP um",
      "offset": 1266.88,
      "duration": 6.4
    },
    {
      "lang": "en",
      "text": "but it becomes so interesting when you",
      "offset": 1270.96,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "think about the size of that like when",
      "offset": 1273.28,
      "duration": 4.639
    },
    {
      "lang": "en",
      "text": "you want to scale it up um when you want",
      "offset": 1275.44,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "to shrink it but also when you want to",
      "offset": 1277.919,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "actually process it when you want to run",
      "offset": 1280.64,
      "duration": 5.84
    },
    {
      "lang": "en",
      "text": "the computations on that to execute the",
      "offset": 1283.919,
      "duration": 5.041
    },
    {
      "lang": "en",
      "text": "operations you've defined and it it",
      "offset": 1286.48,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "quickly becomes very challenging to do",
      "offset": 1288.96,
      "duration": 6.16
    },
    {
      "lang": "en",
      "text": "actually um and so when we're defining",
      "offset": 1291.76,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "our kernels and when we're defining our",
      "offset": 1295.12,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "our programs in Tranium um part of what",
      "offset": 1297.12,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "we want to do is think about how we're",
      "offset": 1300.08,
      "duration": 3.8
    },
    {
      "lang": "en",
      "text": "representing the data how we're",
      "offset": 1302.08,
      "duration": 4.52
    },
    {
      "lang": "en",
      "text": "structuring the data from the PyTorch",
      "offset": 1303.88,
      "duration": 5.159
    },
    {
      "lang": "en",
      "text": "perspective and then actually the the",
      "offset": 1306.6,
      "duration": 7.64
    },
    {
      "lang": "en",
      "text": "trick the game is to try to optimize the",
      "offset": 1309.039,
      "duration": 7.921
    },
    {
      "lang": "en",
      "text": "data representation and optimize the",
      "offset": 1314.24,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "program for the hardware actually what",
      "offset": 1316.96,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "we want to try and do is pick like",
      "offset": 1319.36,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "designs within the data structure and",
      "offset": 1322.08,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "within the algorithm that leverage some",
      "offset": 1324.4,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "of the lower level capabilities of the",
      "offset": 1327.52,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "hardware to like ultimately get the best",
      "offset": 1329.84,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "utilization and the best performance",
      "offset": 1332.72,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "that we can and then once you have sort",
      "offset": 1334.4,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "of like hardware and software programs",
      "offset": 1337.039,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "that are like well synced and like",
      "offset": 1339.28,
      "duration": 3.8
    },
    {
      "lang": "en",
      "text": "running together and like using the same",
      "offset": 1341.039,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "assumptions like that's when you can",
      "offset": 1343.08,
      "duration": 4.92
    },
    {
      "lang": "en",
      "text": "really scale and get like excellent you",
      "offset": 1345.2,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "know utilization and then excellent",
      "offset": 1348,
      "duration": 4.799
    },
    {
      "lang": "en",
      "text": "price performance uh and that's that's",
      "offset": 1349.84,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "you know really where where we want to",
      "offset": 1352.799,
      "duration": 3.521
    },
    {
      "lang": "en",
      "text": "help customers go nice and so speaking",
      "offset": 1354.24,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "of the connection between uh very",
      "offset": 1356.32,
      "duration": 4.44
    },
    {
      "lang": "en",
      "text": "popular deep learning libraries like",
      "offset": 1358.96,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "PyTorch and the interaction of those",
      "offset": 1360.76,
      "duration": 4.76
    },
    {
      "lang": "en",
      "text": "libraries with your hardware with",
      "offset": 1363.28,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "tranium inferentia accelerators there's",
      "offset": 1365.52,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "something called the AWS neuron SDK",
      "offset": 1368.24,
      "duration": 4.559
    },
    {
      "lang": "en",
      "text": "software development kit which is the",
      "offset": 1370.96,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "SDK the software development kit for",
      "offset": 1372.799,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "these AI chips for training and",
      "offset": 1375.28,
      "duration": 4.879
    },
    {
      "lang": "en",
      "text": "inferentia can you tell us how AWS",
      "offset": 1377.12,
      "duration": 6.64
    },
    {
      "lang": "en",
      "text": "Neuron uh enables builders to use the",
      "offset": 1380.159,
      "duration": 5.281
    },
    {
      "lang": "en",
      "text": "frameworks of their choice like PyTorch",
      "offset": 1383.76,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "or Jax without having to worry about the",
      "offset": 1385.44,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "underlying chip architecture yeah",
      "offset": 1387.76,
      "duration": 6.159
    },
    {
      "lang": "en",
      "text": "absolutely so so the Neuron SDK is a",
      "offset": 1390.48,
      "duration": 6.16
    },
    {
      "lang": "en",
      "text": "term that we use to cover a very very",
      "offset": 1393.919,
      "duration": 6.161
    },
    {
      "lang": "en",
      "text": "large variety of tools and the tools",
      "offset": 1396.64,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "essentially are capabilities that we",
      "offset": 1400.08,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "offer to developers um to easily take",
      "offset": 1402.32,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "advantage of Tranium and Infrenia some",
      "offset": 1405.52,
      "duration": 4.639
    },
    {
      "lang": "en",
      "text": "of the tools are really low-level things",
      "offset": 1407.84,
      "duration": 5.839
    },
    {
      "lang": "en",
      "text": "like the runtime the driver um the",
      "offset": 1410.159,
      "duration": 5.921
    },
    {
      "lang": "en",
      "text": "compiler that pulls everything together",
      "offset": 1413.679,
      "duration": 4.721
    },
    {
      "lang": "en",
      "text": "um some of them are much higher level so",
      "offset": 1416.08,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "something like torch neuron x tnx or",
      "offset": 1418.4,
      "duration": 5.759
    },
    {
      "lang": "en",
      "text": "essentially neuron x distributed and nxd",
      "offset": 1421.28,
      "duration": 6.16
    },
    {
      "lang": "en",
      "text": "so NXD is really the primary it's like",
      "offset": 1424.159,
      "duration": 5.441
    },
    {
      "lang": "en",
      "text": "modeling library that's that's really",
      "offset": 1427.44,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "useful for customers where when you want",
      "offset": 1429.6,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "to go you know train a model and you",
      "offset": 1431.52,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "want to go host a model on train in",
      "offset": 1433.76,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "Frenchia NXD packages up many of the",
      "offset": 1435.44,
      "duration": 7.2
    },
    {
      "lang": "en",
      "text": "lower level complexities and it makes it",
      "offset": 1439.44,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "easily available for customers to access",
      "offset": 1442.64,
      "duration": 5.279
    },
    {
      "lang": "en",
      "text": "so compiling your model for example is",
      "offset": 1445.44,
      "duration": 5.92
    },
    {
      "lang": "en",
      "text": "handled by NXD uh sharding your model",
      "offset": 1447.919,
      "duration": 6.961
    },
    {
      "lang": "en",
      "text": "actually so taking a model checkpoint",
      "offset": 1451.36,
      "duration": 7.52
    },
    {
      "lang": "en",
      "text": "say like a llama um or a you know pixart",
      "offset": 1454.88,
      "duration": 7.12
    },
    {
      "lang": "en",
      "text": "model and then sharding that across the",
      "offset": 1458.88,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "accelerators that are available on your",
      "offset": 1462,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "instance nxd actually handles the model",
      "offset": 1463.76,
      "duration": 6.64
    },
    {
      "lang": "en",
      "text": "sharding for you both from a data",
      "offset": 1466.88,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "perspective so taking the checkpoint",
      "offset": 1470.4,
      "duration": 3.519
    },
    {
      "lang": "en",
      "text": "itself and just splitting the checkpoint",
      "offset": 1472.08,
      "duration": 4.479
    },
    {
      "lang": "en",
      "text": "into you know n number of shards but",
      "offset": 1473.919,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "then also the communication",
      "offset": 1476.559,
      "duration": 5.761
    },
    {
      "lang": "en",
      "text": "um and the you know optimizer updates",
      "offset": 1479.679,
      "duration": 6.48
    },
    {
      "lang": "en",
      "text": "and the forward path so NXD is is a very",
      "offset": 1482.32,
      "duration": 6.599
    },
    {
      "lang": "en",
      "text": "very comprehensive modeling",
      "offset": 1486.159,
      "duration": 6.801
    },
    {
      "lang": "en",
      "text": "library and so NXD is is useful for of",
      "offset": 1488.919,
      "duration": 5.721
    },
    {
      "lang": "en",
      "text": "course implementing your own model but",
      "offset": 1492.96,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "also just pulling down a model and",
      "offset": 1494.64,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "running it uh so when you want to just",
      "offset": 1496.32,
      "duration": 4.959
    },
    {
      "lang": "en",
      "text": "get something that's prepackaged and",
      "offset": 1499.36,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "test it for say uh something like",
      "offset": 1501.279,
      "duration": 5.121
    },
    {
      "lang": "en",
      "text": "alignment or supervised fine-tuning or",
      "offset": 1503.6,
      "duration": 5.84
    },
    {
      "lang": "en",
      "text": "hosting uh you can pull down the model",
      "offset": 1506.4,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "packages that are pre-built and preset",
      "offset": 1509.44,
      "duration": 6.08
    },
    {
      "lang": "en",
      "text": "with NXD and just run them with your",
      "offset": 1511.84,
      "duration": 6.16
    },
    {
      "lang": "en",
      "text": "experiments and with your changes and uh",
      "offset": 1515.52,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "there there should be very little",
      "offset": 1518,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "complexity that's exposed to the",
      "offset": 1519.919,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "customer in those cases very cool we'll",
      "offset": 1521.76,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "have a link to the Neuron SDK in the",
      "offset": 1524.24,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "show notes so people can check that out",
      "offset": 1526.88,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "more but yeah as usual another great",
      "offset": 1528,
      "duration": 6.48
    },
    {
      "lang": "en",
      "text": "example uh of your ability to uh to",
      "offset": 1530.64,
      "duration": 6.08
    },
    {
      "lang": "en",
      "text": "explain technical things really well um",
      "offset": 1534.48,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "thank you so with your experience",
      "offset": 1536.72,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "previously on the SageMaker side which",
      "offset": 1538.88,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "we talked about earlier um does Trainium",
      "offset": 1540.48,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "and Inferentia work with SageMaker as",
      "offset": 1543.52,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "well are there some kinds of you know um",
      "offset": 1546.24,
      "duration": 4.799
    },
    {
      "lang": "en",
      "text": "you know just as the SDK kind of allows",
      "offset": 1548.88,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "you to take your framework of choice um",
      "offset": 1551.039,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "is it easy to have SageMaker blend on",
      "offset": 1553.52,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "the hardware side with tranium and",
      "offset": 1556.159,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "inferentia yes absolutely i mean you can",
      "offset": 1557.36,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "run uh SageMaker notebook instances you",
      "offset": 1560,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "can run SageMaker Studio on tranium so",
      "offset": 1562.88,
      "duration": 6.48
    },
    {
      "lang": "en",
      "text": "if you want to say develop a new kernel",
      "offset": 1566,
      "duration": 6.4
    },
    {
      "lang": "en",
      "text": "uh or or test you know NXD you can do",
      "offset": 1569.36,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "that very easily on SageMaker as a",
      "offset": 1572.4,
      "duration": 5.84
    },
    {
      "lang": "en",
      "text": "development environment um we also have",
      "offset": 1574.72,
      "duration": 6.48
    },
    {
      "lang": "en",
      "text": "many models uh that we've already",
      "offset": 1578.24,
      "duration": 5.439
    },
    {
      "lang": "en",
      "text": "supported on NXD that we'll make",
      "offset": 1581.2,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "available through what's called",
      "offset": 1583.679,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "SageMaker Jumpstart where SageMaker",
      "offset": 1584.88,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "Jumpstart is is sort of a marketplace",
      "offset": 1587.36,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "for machine learning models and LLMs",
      "offset": 1589.44,
      "duration": 5.839
    },
    {
      "lang": "en",
      "text": "that are prepackaged and available uh",
      "offset": 1592.48,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "and so when SageMaker customers are say",
      "offset": 1595.279,
      "duration": 5.121
    },
    {
      "lang": "en",
      "text": "browsing in SageMaker Studio they can",
      "offset": 1598.24,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "click a button to download the model but",
      "offset": 1600.4,
      "duration": 4.639
    },
    {
      "lang": "en",
      "text": "they're not actually downloading the",
      "offset": 1603.6,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "model what's happening is they're",
      "offset": 1605.039,
      "duration": 3.561
    },
    {
      "lang": "en",
      "text": "accessing the model through the",
      "offset": 1606.72,
      "duration": 5.079
    },
    {
      "lang": "en",
      "text": "marketplace the training and hosting",
      "offset": 1608.6,
      "duration": 5.24
    },
    {
      "lang": "en",
      "text": "infrastructure and a lot of the software",
      "offset": 1611.799,
      "duration": 5.081
    },
    {
      "lang": "en",
      "text": "is fully managed by SageMaker and then",
      "offset": 1613.84,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "customers can bring their own data sets",
      "offset": 1616.88,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "uh they can fine-tune the model they can",
      "offset": 1619.44,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "host the model all through SageMaker",
      "offset": 1621.6,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "jump start and so that absolutely is",
      "offset": 1623.76,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "well integrated with Tranium and",
      "offset": 1626.88,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "Infrenia",
      "offset": 1628.08,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "hey this is your host John Cone and I'm",
      "offset": 1630.08,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "excited to announce that this northern",
      "offset": 1632.159,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "hemisphere spring I'm launching my own",
      "offset": 1633.76,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "data science consultancy a firm called Y",
      "offset": 1635.679,
      "duration": 4.641
    },
    {
      "lang": "en",
      "text": "Carrot if you're an ML practitioner",
      "offset": 1638.32,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "who's familiar with Y Hat you may get",
      "offset": 1640.32,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "our name but regardless of who you are",
      "offset": 1642.32,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "if you're looking for a team that",
      "offset": 1644.72,
      "duration": 2.4
    },
    {
      "lang": "en",
      "text": "combines decades of commercial",
      "offset": 1645.76,
      "duration": 2.88
    },
    {
      "lang": "en",
      "text": "experience in software development and",
      "offset": 1647.12,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "machine learning with internationally",
      "offset": 1648.64,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "recognized expertise in all the cutting",
      "offset": 1650.32,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "edge approaches including Gen AI",
      "offset": 1652.72,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "multi-agent systems and RAG well now",
      "offset": 1654.64,
      "duration": 4.639
    },
    {
      "lang": "en",
      "text": "you've found us we have rich experience",
      "offset": 1657.12,
      "duration": 3.679
    },
    {
      "lang": "en",
      "text": "across the entire project life cycle",
      "offset": 1659.279,
      "duration": 2.801
    },
    {
      "lang": "en",
      "text": "from problem scoping and proof of",
      "offset": 1660.799,
      "duration": 2.88
    },
    {
      "lang": "en",
      "text": "concept through to high volume",
      "offset": 1662.08,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "production deployments if you'd like to",
      "offset": 1663.679,
      "duration": 3.88
    },
    {
      "lang": "en",
      "text": "be one of our first clients head to",
      "offset": 1665.52,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "ycarat.com and click partner with us to",
      "offset": 1667.559,
      "duration": 5
    },
    {
      "lang": "en",
      "text": "tell us how we can help again that's y",
      "offset": 1670.32,
      "duration": 4.959
    },
    {
      "lang": "en",
      "text": "carrot",
      "offset": 1672.559,
      "duration": 2.72
    },
    {
      "lang": "en",
      "text": "ycr.com very nice um and yeah you've",
      "offset": 1677.96,
      "duration": 6.16
    },
    {
      "lang": "en",
      "text": "been working closely with customers on",
      "offset": 1681.84,
      "duration": 4.719
    },
    {
      "lang": "en",
      "text": "adopting tranium though it's something",
      "offset": 1684.12,
      "duration": 4.12
    },
    {
      "lang": "en",
      "text": "that's picking up a lot of speed",
      "offset": 1686.559,
      "duration": 3.201
    },
    {
      "lang": "en",
      "text": "probably because Ron Diamont was on this",
      "offset": 1688.24,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "show a couple years ago no doubt no",
      "offset": 1689.76,
      "duration": 5.919
    },
    {
      "lang": "en",
      "text": "doubt and um so in fact huge companies",
      "offset": 1692.399,
      "duration": 6.321
    },
    {
      "lang": "en",
      "text": "like Apple uh Apple joined your reinvent",
      "offset": 1695.679,
      "duration": 5.521
    },
    {
      "lang": "en",
      "text": "CEO keynote last year to talk about",
      "offset": 1698.72,
      "duration": 4.559
    },
    {
      "lang": "en",
      "text": "their use of inferentia and another chip",
      "offset": 1701.2,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "called Graviton which you'll need to",
      "offset": 1703.279,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "explain to us in a minute um because we",
      "offset": 1704.64,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "haven't talked about that on air ever uh",
      "offset": 1706.96,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "but yeah they talked about their use of",
      "offset": 1709.039,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "inferentia and graviton and why they're",
      "offset": 1710.64,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "excited about Tranium 2 another thing",
      "offset": 1712.96,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "that we haven't talked about yet uh in",
      "offset": 1714.96,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "this episode so what are some of the",
      "offset": 1717.039,
      "duration": 4.721
    },
    {
      "lang": "en",
      "text": "most interesting technical challenges",
      "offset": 1719.039,
      "duration": 5.041
    },
    {
      "lang": "en",
      "text": "that uh customers like Apple are trying",
      "offset": 1721.76,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "to solve uh so let's start there you can",
      "offset": 1724.08,
      "duration": 5.839
    },
    {
      "lang": "en",
      "text": "tell us about this Graviton chip the",
      "offset": 1727.52,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "Tranium 2 chip and maybe this kind of",
      "offset": 1729.919,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "relates to a general question that I've",
      "offset": 1732,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "been meaning to ask you this whole",
      "offset": 1734,
      "duration": 2.88
    },
    {
      "lang": "en",
      "text": "episode and I have just continued to",
      "offset": 1735.12,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "forget uh with each wonderful",
      "offset": 1736.88,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "explanation that you give after another",
      "offset": 1738.96,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "which is that why should somebody why",
      "offset": 1740.72,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "should a listener for example consider",
      "offset": 1743.039,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "using an accelerator like tranium and",
      "offset": 1746,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "inferentia instead of a GPU maybe that's",
      "offset": 1747.919,
      "duration": 4.801
    },
    {
      "lang": "en",
      "text": "maybe that's a great question to start",
      "offset": 1751.36,
      "duration": 2.96
    },
    {
      "lang": "en",
      "text": "with and then I'll remind you of the",
      "offset": 1752.72,
      "duration": 3.679
    },
    {
      "lang": "en",
      "text": "other the series of questions that led",
      "offset": 1754.32,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "me to that question sounds good thank",
      "offset": 1756.399,
      "duration": 4.481
    },
    {
      "lang": "en",
      "text": "you thank you yeah so so I mean",
      "offset": 1758.72,
      "duration": 5.199
    },
    {
      "lang": "en",
      "text": "fundamentally at at AWS you know we we",
      "offset": 1760.88,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "really believe in customer choice like",
      "offset": 1763.919,
      "duration": 6.321
    },
    {
      "lang": "en",
      "text": "we believe in a cloud we believe in a",
      "offset": 1766.08,
      "duration": 6.959
    },
    {
      "lang": "en",
      "text": "cloud service you know provider that",
      "offset": 1770.24,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "enables customers to have choice about",
      "offset": 1773.039,
      "duration": 6.081
    },
    {
      "lang": "en",
      "text": "data sets have choice about models and",
      "offset": 1776.24,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "have choice about accelerated hardware",
      "offset": 1779.12,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "uh we think it's it's good for customers",
      "offset": 1781.6,
      "duration": 6.4
    },
    {
      "lang": "en",
      "text": "to have that ability um and to have real",
      "offset": 1784.08,
      "duration": 7.04
    },
    {
      "lang": "en",
      "text": "you know options uh that is ultimately",
      "offset": 1788,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "best for consumers and that that's best",
      "offset": 1791.12,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "for customers so so fundamentally that's",
      "offset": 1792.88,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "that's the direction um Annaperna Labs",
      "offset": 1794.88,
      "duration": 5.279
    },
    {
      "lang": "en",
      "text": "is an awesome company annapernal Labs",
      "offset": 1798.32,
      "duration": 4.479
    },
    {
      "lang": "en",
      "text": "has been building infrastructure for AWS",
      "offset": 1800.159,
      "duration": 6.321
    },
    {
      "lang": "en",
      "text": "for many years uh so Annaperna Labs is a",
      "offset": 1802.799,
      "duration": 7.6
    },
    {
      "lang": "en",
      "text": "startup that Amazon acquired in 2015 um",
      "offset": 1806.48,
      "duration": 6.319
    },
    {
      "lang": "en",
      "text": "primarily to develop the hypervisor",
      "offset": 1810.399,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "actually so they developed what's called",
      "offset": 1812.799,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "the Nitro system yeah we'll talk it",
      "offset": 1814.399,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "through so they de Yeah it's it's like",
      "offset": 1816.399,
      "duration": 5.841
    },
    {
      "lang": "en",
      "text": "the coolest story in tech that is is the",
      "offset": 1819.919,
      "duration": 6.561
    },
    {
      "lang": "en",
      "text": "least told so So here's the scoop um so",
      "offset": 1822.24,
      "duration": 6.48
    },
    {
      "lang": "en",
      "text": "in 2015",
      "offset": 1826.48,
      "duration": 5.24
    },
    {
      "lang": "en",
      "text": "uh the way people were doing",
      "offset": 1828.72,
      "duration": 7.04
    },
    {
      "lang": "en",
      "text": "cloud 10 years ago uh is you had this",
      "offset": 1831.72,
      "duration": 6.04
    },
    {
      "lang": "en",
      "text": "thing called the hypervisor and the",
      "offset": 1835.76,
      "duration": 6.08
    },
    {
      "lang": "en",
      "text": "hypervisor essentially was this giant",
      "offset": 1837.76,
      "duration": 6.799
    },
    {
      "lang": "en",
      "text": "monolithic software system that managed",
      "offset": 1841.84,
      "duration": 6.439
    },
    {
      "lang": "en",
      "text": "the entire host of all servers",
      "offset": 1844.559,
      "duration": 6.961
    },
    {
      "lang": "en",
      "text": "and the challenge with the hypervisor",
      "offset": 1848.279,
      "duration": 7.561
    },
    {
      "lang": "en",
      "text": "systems is that it made it really hard",
      "offset": 1851.52,
      "duration": 7.36
    },
    {
      "lang": "en",
      "text": "to innovate for the cloud uh because all",
      "offset": 1855.84,
      "duration": 6.719
    },
    {
      "lang": "en",
      "text": "of the control the communication the",
      "offset": 1858.88,
      "duration": 7.76
    },
    {
      "lang": "en",
      "text": "data at the server level was implemented",
      "offset": 1862.559,
      "duration": 6.161
    },
    {
      "lang": "en",
      "text": "in this giant monolithic thing called",
      "offset": 1866.64,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "the hypervisor so Annaperna had this",
      "offset": 1868.72,
      "duration": 7.36
    },
    {
      "lang": "en",
      "text": "crazy idea of decoupling the parts of",
      "offset": 1871.84,
      "duration": 7.36
    },
    {
      "lang": "en",
      "text": "the hypervisor that you need to scale at",
      "offset": 1876.08,
      "duration": 5.599
    },
    {
      "lang": "en",
      "text": "the cloud at the physical level so they",
      "offset": 1879.2,
      "duration": 5.16
    },
    {
      "lang": "en",
      "text": "developed what's called the Nitro system",
      "offset": 1881.679,
      "duration": 7.081
    },
    {
      "lang": "en",
      "text": "today which provides physical separation",
      "offset": 1884.36,
      "duration": 7.559
    },
    {
      "lang": "en",
      "text": "for things like the data that's running",
      "offset": 1888.76,
      "duration": 7.639
    },
    {
      "lang": "en",
      "text": "on the instance from the communication",
      "offset": 1891.919,
      "duration": 7.681
    },
    {
      "lang": "en",
      "text": "that's controlling the instance and so",
      "offset": 1896.399,
      "duration": 8.241
    },
    {
      "lang": "en",
      "text": "this is both how AWS scales and how AWS",
      "offset": 1899.6,
      "duration": 7.28
    },
    {
      "lang": "en",
      "text": "provides such strong security guarantees",
      "offset": 1904.64,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "is because physically there are two",
      "offset": 1906.88,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "different controls there's one physical",
      "offset": 1909.36,
      "duration": 5.84
    },
    {
      "lang": "en",
      "text": "you know chip there's one physical",
      "offset": 1912.88,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "component of the hardware system that is",
      "offset": 1915.2,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "managing the data the customer's data",
      "offset": 1917.6,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "and there's a different physical control",
      "offset": 1920.32,
      "duration": 3.599
    },
    {
      "lang": "en",
      "text": "that's managing the governance of the",
      "offset": 1922.24,
      "duration": 5.679
    },
    {
      "lang": "en",
      "text": "instance and so every modern EC2",
      "offset": 1923.919,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "instance today is built on the nitro",
      "offset": 1927.919,
      "duration": 4.961
    },
    {
      "lang": "en",
      "text": "system so that was the first major",
      "offset": 1929.919,
      "duration": 4.961
    },
    {
      "lang": "en",
      "text": "development for manipal labs was nitro",
      "offset": 1932.88,
      "duration": 3.279
    },
    {
      "lang": "en",
      "text": "so that's that's nitro like",
      "offset": 1934.88,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "nitroglycerin nitro",
      "offset": 1936.159,
      "duration": 6.561
    },
    {
      "lang": "en",
      "text": "uh nitro yeah explosive",
      "offset": 1938.799,
      "duration": 8.961
    },
    {
      "lang": "en",
      "text": "yes yes so so after the nitro system um",
      "offset": 1942.72,
      "duration": 7.36
    },
    {
      "lang": "en",
      "text": "anaperna started developing their second",
      "offset": 1947.76,
      "duration": 4.279
    },
    {
      "lang": "en",
      "text": "uh sort of main product line which is",
      "offset": 1950.08,
      "duration": 6.479
    },
    {
      "lang": "en",
      "text": "graviton so Graviton are custom CPUs",
      "offset": 1952.039,
      "duration": 7.321
    },
    {
      "lang": "en",
      "text": "custom ARMbased CPUs developed by",
      "offset": 1956.559,
      "duration": 6.161
    },
    {
      "lang": "en",
      "text": "Annapernal Labs and if you watched",
      "offset": 1959.36,
      "duration": 6.88
    },
    {
      "lang": "en",
      "text": "reinvent one of the uh you know",
      "offset": 1962.72,
      "duration": 6.24
    },
    {
      "lang": "en",
      "text": "highlights that you saw is that today",
      "offset": 1966.24,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "more than half of new compute that comes",
      "offset": 1968.96,
      "duration": 8.959
    },
    {
      "lang": "en",
      "text": "onto AWS is actually Graviton CPU oh yes",
      "offset": 1972,
      "duration": 7.679
    },
    {
      "lang": "en",
      "text": "so when you're looking at instances on",
      "offset": 1977.919,
      "duration": 5.041
    },
    {
      "lang": "en",
      "text": "AWS when you see that little G at the",
      "offset": 1979.679,
      "duration": 5.641
    },
    {
      "lang": "en",
      "text": "end of a family so like a",
      "offset": 1982.96,
      "duration": 7.12
    },
    {
      "lang": "en",
      "text": "C6G or even a G5G that second G means",
      "offset": 1985.32,
      "duration": 6.719
    },
    {
      "lang": "en",
      "text": "it's a Graviton",
      "offset": 1990.08,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "CPU and so that means you're going to",
      "offset": 1992.039,
      "duration": 5.401
    },
    {
      "lang": "en",
      "text": "get much better performance at a very",
      "offset": 1994.24,
      "duration": 6.919
    },
    {
      "lang": "en",
      "text": "you know competitive price uh and so the",
      "offset": 1997.44,
      "duration": 7.92
    },
    {
      "lang": "en",
      "text": "Graviton CPU is our second like main",
      "offset": 2001.159,
      "duration": 6.76
    },
    {
      "lang": "en",
      "text": "product line and then tranium and infia",
      "offset": 2005.36,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "is the third main product category from",
      "offset": 2007.919,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "Anaperna labs which is now let's take",
      "offset": 2010.08,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "you know this awesome ability that we've",
      "offset": 2013.279,
      "duration": 6.081
    },
    {
      "lang": "en",
      "text": "created in developing infrastructure and",
      "offset": 2016.08,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "scaling infrastructure across AWS and",
      "offset": 2019.36,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "let's focus that on a IML and so",
      "offset": 2021.84,
      "duration": 5.679
    },
    {
      "lang": "en",
      "text": "inferentia of course was developed and",
      "offset": 2024.96,
      "duration": 4.719
    },
    {
      "lang": "en",
      "text": "you know came out a number of years ago",
      "offset": 2027.519,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "tranium 3 is our third generation chip",
      "offset": 2029.679,
      "duration": 5.681
    },
    {
      "lang": "en",
      "text": "uh so it's the third generation",
      "offset": 2033.519,
      "duration": 6.721
    },
    {
      "lang": "en",
      "text": "accelerator for a IML um and that is why",
      "offset": 2035.36,
      "duration": 6.64
    },
    {
      "lang": "en",
      "text": "it's such an exciting moment right",
      "offset": 2040.24,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "because you see the breadth and the",
      "offset": 2042,
      "duration": 5.039
    },
    {
      "lang": "en",
      "text": "scope and the incredible results that",
      "offset": 2044.88,
      "duration": 4.479
    },
    {
      "lang": "en",
      "text": "Annaperna has delivered like over the",
      "offset": 2047.039,
      "duration": 5.761
    },
    {
      "lang": "en",
      "text": "years uh and now this is totally focused",
      "offset": 2049.359,
      "duration": 6.8
    },
    {
      "lang": "en",
      "text": "and and now a large focus is a IML and",
      "offset": 2052.8,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "so when you know customers are taking",
      "offset": 2056.159,
      "duration": 5.361
    },
    {
      "lang": "en",
      "text": "advantage of this like fundamentally",
      "offset": 2058.8,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "they're interested because they get the",
      "offset": 2061.52,
      "duration": 5.359
    },
    {
      "lang": "en",
      "text": "benefits of price performance like more",
      "offset": 2064.8,
      "duration": 4.879
    },
    {
      "lang": "en",
      "text": "than anything it's it's this you know",
      "offset": 2066.879,
      "duration": 7.401
    },
    {
      "lang": "en",
      "text": "benefit of highly optimized compute that",
      "offset": 2069.679,
      "duration": 7.801
    },
    {
      "lang": "en",
      "text": "is scarily energy",
      "offset": 2074.28,
      "duration": 6.48
    },
    {
      "lang": "en",
      "text": "efficient is so good at",
      "offset": 2077.48,
      "duration": 6.359
    },
    {
      "lang": "en",
      "text": "identifying improvement areas to just",
      "offset": 2080.76,
      "duration": 5.639
    },
    {
      "lang": "en",
      "text": "take cost out of the equation",
      "offset": 2083.839,
      "duration": 5.201
    },
    {
      "lang": "en",
      "text": "um and reduce complexity and pass",
      "offset": 2086.399,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "performance and pass you know cost",
      "offset": 2089.04,
      "duration": 5.92
    },
    {
      "lang": "en",
      "text": "savings back to customers uh while you",
      "offset": 2091.359,
      "duration": 5.841
    },
    {
      "lang": "en",
      "text": "know meeting performance and in many",
      "offset": 2094.96,
      "duration": 4.68
    },
    {
      "lang": "en",
      "text": "cases exceeding performance so",
      "offset": 2097.2,
      "duration": 5.84
    },
    {
      "lang": "en",
      "text": "TRN2 is actually the most powerful EC2",
      "offset": 2099.64,
      "duration": 7.32
    },
    {
      "lang": "en",
      "text": "instance on AWS for a IML like full stop",
      "offset": 2103.04,
      "duration": 6.4
    },
    {
      "lang": "en",
      "text": "when you look at the you know",
      "offset": 2106.96,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "performance metrics that we're seeing",
      "offset": 2109.44,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "it's it's a very exciting moment it's an",
      "offset": 2111.92,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "exciting moment for customers um",
      "offset": 2114.16,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "exciting moment for the whole group",
      "offset": 2116.48,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "tranium 2 is the most powerful on AWS",
      "offset": 2118.079,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "correct wow that's super cool and so",
      "offset": 2120.96,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "what are the key differences between the",
      "offset": 2123.359,
      "duration": 4.561
    },
    {
      "lang": "en",
      "text": "first generation Tranium chip and",
      "offset": 2126.32,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "Tranium 2 is it you know this is all",
      "offset": 2127.92,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "stuff that's new since Ron's episode on",
      "offset": 2130.16,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "the show since episode 691 a couple of",
      "offset": 2131.839,
      "duration": 7.201
    },
    {
      "lang": "en",
      "text": "years ago and so is it like one or more",
      "offset": 2134.16,
      "duration": 8
    },
    {
      "lang": "en",
      "text": "kind of big conceptual changes that that",
      "offset": 2139.04,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "lead to this leap from tranium 1 to two",
      "offset": 2142.16,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "or is it kind of a bunch of uh",
      "offset": 2144.8,
      "duration": 5.16
    },
    {
      "lang": "en",
      "text": "incremental changes that together",
      "offset": 2148.16,
      "duration": 5.199
    },
    {
      "lang": "en",
      "text": "combine to to have all of this power in",
      "offset": 2149.96,
      "duration": 6.2
    },
    {
      "lang": "en",
      "text": "tranium 2 um and and and such cost",
      "offset": 2153.359,
      "duration": 6.961
    },
    {
      "lang": "en",
      "text": "effectiveness yeah sure so so we we try",
      "offset": 2156.16,
      "duration": 6.24
    },
    {
      "lang": "en",
      "text": "to keep it easy for you and so the way",
      "offset": 2160.32,
      "duration": 5.279
    },
    {
      "lang": "en",
      "text": "we keep it easy for you is that the core",
      "offset": 2162.4,
      "duration": 5.32
    },
    {
      "lang": "en",
      "text": "compute engine",
      "offset": 2165.599,
      "duration": 4.721
    },
    {
      "lang": "en",
      "text": "design isn't that different actually the",
      "offset": 2167.72,
      "duration": 5.32
    },
    {
      "lang": "en",
      "text": "neuron core itself particularly between",
      "offset": 2170.32,
      "duration": 5.039
    },
    {
      "lang": "en",
      "text": "tier one and tier 2 is is pretty much",
      "offset": 2173.04,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "the same so what's nice about that is it",
      "offset": 2175.359,
      "duration": 5.841
    },
    {
      "lang": "en",
      "text": "means the kernels that you write for",
      "offset": 2178.32,
      "duration": 6.96
    },
    {
      "lang": "en",
      "text": "tier one to tier 2 and the development",
      "offset": 2181.2,
      "duration": 6.879
    },
    {
      "lang": "en",
      "text": "um modeling code with say like NXD is",
      "offset": 2185.28,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "really really easy to just move up from",
      "offset": 2188.079,
      "duration": 5.121
    },
    {
      "lang": "en",
      "text": "tier one to tier 2 the big different Oh",
      "offset": 2190.16,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "can I interrupt you for one quick second",
      "offset": 2193.2,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "it sounds like So you're are you saying",
      "offset": 2194.48,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "TRN1 and TRN2 is that like that's like",
      "offset": 2196.24,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "an abbreviation of tranium yes okay okay",
      "offset": 2198.96,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "okay gotcha that's also the that's the",
      "offset": 2202,
      "duration": 5.359
    },
    {
      "lang": "en",
      "text": "name of Yeah abbreviation of the name",
      "offset": 2204.32,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "and it's the instance name directly",
      "offset": 2207.359,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "right right right right so yeah gotcha",
      "offset": 2209.44,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "gotcha gotcha nice tier one and tier two",
      "offset": 2211.28,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "my apologies for interrupting carry on",
      "offset": 2213.76,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "no worries yeah so so the key",
      "offset": 2215.68,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "differences between tier one or tier two",
      "offset": 2218.079,
      "duration": 6.241
    },
    {
      "lang": "en",
      "text": "is that on tier two you have 4x the",
      "offset": 2220.48,
      "duration": 6.08
    },
    {
      "lang": "en",
      "text": "compute",
      "offset": 2224.32,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "that is a big number now the reason why",
      "offset": 2226.56,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "that happens is because you have four",
      "offset": 2228.96,
      "duration": 7.44
    },
    {
      "lang": "en",
      "text": "times more neuron cores per card so in",
      "offset": 2231.04,
      "duration": 6.92
    },
    {
      "lang": "en",
      "text": "tier",
      "offset": 2236.4,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "one you have two neuron cores that are",
      "offset": 2237.96,
      "duration": 6.44
    },
    {
      "lang": "en",
      "text": "packaged up together in a single card",
      "offset": 2241.68,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "and then you have two HBM banks and that",
      "offset": 2244.4,
      "duration": 4.92
    },
    {
      "lang": "en",
      "text": "is the accelerator the combination of",
      "offset": 2246.72,
      "duration": 8.16
    },
    {
      "lang": "en",
      "text": "those tn 2 you have eight neuron cores",
      "offset": 2249.32,
      "duration": 7.64
    },
    {
      "lang": "en",
      "text": "so just multiplied by four you have",
      "offset": 2254.88,
      "duration": 5.88
    },
    {
      "lang": "en",
      "text": "eight neuron cores you have four HBM",
      "offset": 2256.96,
      "duration": 11.639
    },
    {
      "lang": "en",
      "text": "banks each card itself is 96 gigs of HBM",
      "offset": 2260.76,
      "duration": 11.48
    },
    {
      "lang": "en",
      "text": "capacity on the instance as a whole you",
      "offset": 2268.599,
      "duration": 6.841
    },
    {
      "lang": "en",
      "text": "have 16 of those cards so at the",
      "offset": 2272.24,
      "duration": 7.28
    },
    {
      "lang": "en",
      "text": "instance as a whole you have 1.5 terab",
      "offset": 2275.44,
      "duration": 7.12
    },
    {
      "lang": "en",
      "text": "of HBM capacity",
      "offset": 2279.52,
      "duration": 4.12
    },
    {
      "lang": "en",
      "text": "and",
      "offset": 2282.56,
      "duration": 4.84
    },
    {
      "lang": "en",
      "text": "then we gave you an ultraserver so the",
      "offset": 2283.64,
      "duration": 7.16
    },
    {
      "lang": "en",
      "text": "ultraserver is where you take four tier",
      "offset": 2287.4,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "and two",
      "offset": 2290.8,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "instances and then these are all",
      "offset": 2292.04,
      "duration": 6.52
    },
    {
      "lang": "en",
      "text": "combined in one giant server actually so",
      "offset": 2294.64,
      "duration": 6.36
    },
    {
      "lang": "en",
      "text": "the reason why we say that so it's two",
      "offset": 2298.56,
      "duration": 8.48
    },
    {
      "lang": "en",
      "text": "racks four servers and then 64 cards",
      "offset": 2301,
      "duration": 8.92
    },
    {
      "lang": "en",
      "text": "that are all connected by neuron link",
      "offset": 2307.04,
      "duration": 4.76
    },
    {
      "lang": "en",
      "text": "which is our chip to chip",
      "offset": 2309.92,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "interconnect such that there is a",
      "offset": 2311.8,
      "duration": 4.84
    },
    {
      "lang": "en",
      "text": "minimum of two connection a minimum of",
      "offset": 2314,
      "duration": 6.64
    },
    {
      "lang": "en",
      "text": "two hops from one card to any other card",
      "offset": 2316.64,
      "duration": 6.8
    },
    {
      "lang": "en",
      "text": "when you do like um a neuron top or a",
      "offset": 2320.64,
      "duration": 7.28
    },
    {
      "lang": "en",
      "text": "neuron ls on a single tier one instance",
      "offset": 2323.44,
      "duration": 7.28
    },
    {
      "lang": "en",
      "text": "uh it's going to show you 128 trainable",
      "offset": 2327.92,
      "duration": 5.8
    },
    {
      "lang": "en",
      "text": "accelerators because you have 128 neuron",
      "offset": 2330.72,
      "duration": 7.2
    },
    {
      "lang": "en",
      "text": "cores on your single instance um we",
      "offset": 2333.72,
      "duration": 5.8
    },
    {
      "lang": "en",
      "text": "actually have a way of grouping those",
      "offset": 2337.92,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "you can group them by what we call like",
      "offset": 2339.52,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "a logical neuron core which is kind of",
      "offset": 2341.44,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "cool because then you can change the",
      "offset": 2343.359,
      "duration": 4.641
    },
    {
      "lang": "en",
      "text": "size of the accelerator that you want",
      "offset": 2346.16,
      "duration": 3.439
    },
    {
      "lang": "en",
      "text": "based on the workload which I think is",
      "offset": 2348,
      "duration": 5.119
    },
    {
      "lang": "en",
      "text": "very fun um and then yeah those are all",
      "offset": 2349.599,
      "duration": 6.321
    },
    {
      "lang": "en",
      "text": "packaged up into this giant ultraserver",
      "offset": 2353.119,
      "duration": 5.48
    },
    {
      "lang": "en",
      "text": "um if you watch reinvent actually Peter",
      "offset": 2355.92,
      "duration": 6.24
    },
    {
      "lang": "en",
      "text": "DeSantz wheeled out an ultraserver on",
      "offset": 2358.599,
      "duration": 7
    },
    {
      "lang": "en",
      "text": "stage um and spent his whole much of his",
      "offset": 2362.16,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "keynote just talking about it it's it's",
      "offset": 2365.599,
      "duration": 5.201
    },
    {
      "lang": "en",
      "text": "it's such an awesome moment um but so",
      "offset": 2368.16,
      "duration": 6.4
    },
    {
      "lang": "en",
      "text": "Ultra Servers are unambiguously the best",
      "offset": 2370.8,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "way to train and host the largest",
      "offset": 2374.56,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "language models on AWS and you have the",
      "offset": 2376.16,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "most powerful instances combined in a",
      "offset": 2378.72,
      "duration": 6.08
    },
    {
      "lang": "en",
      "text": "really compelling you know innovative",
      "offset": 2382.16,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "way that connects all of the cores and",
      "offset": 2384.8,
      "duration": 6.24
    },
    {
      "lang": "en",
      "text": "makes them very easy to train uh and",
      "offset": 2387.68,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "then to host while minimizing the number",
      "offset": 2391.04,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "of hops that you need to do between uh",
      "offset": 2393.44,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "hosts because they're all logically one",
      "offset": 2396,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "server so Ultraser is pretty cool",
      "offset": 2398.48,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "ultraserver does sound pretty cool i",
      "offset": 2400.88,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "might be putting you on the spot with",
      "offset": 2402.96,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "this question but how many model",
      "offset": 2404.16,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "parameters of a large language model say",
      "offset": 2406.4,
      "duration": 6.88
    },
    {
      "lang": "en",
      "text": "can you fit on an ultra server yeah so",
      "offset": 2408.64,
      "duration": 6.64
    },
    {
      "lang": "en",
      "text": "it's kind of a weird question to answer",
      "offset": 2413.28,
      "duration": 5.92
    },
    {
      "lang": "en",
      "text": "to be honest because you can fit a lot",
      "offset": 2415.28,
      "duration": 7.24
    },
    {
      "lang": "en",
      "text": "but no but what I mean is that",
      "offset": 2419.2,
      "duration": 5.919
    },
    {
      "lang": "en",
      "text": "realistically you don't actually want to",
      "offset": 2422.52,
      "duration": 5.319
    },
    {
      "lang": "en",
      "text": "max out the memory like realistically",
      "offset": 2425.119,
      "duration": 5.841
    },
    {
      "lang": "en",
      "text": "you want to give yourself space like for",
      "offset": 2427.839,
      "duration": 8
    },
    {
      "lang": "en",
      "text": "your batch size for the optimizer um for",
      "offset": 2430.96,
      "duration": 7.44
    },
    {
      "lang": "en",
      "text": "the adapters if you're training it",
      "offset": 2435.839,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "you're going to want to have multiple",
      "offset": 2438.4,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "copies of it for something that's really",
      "offset": 2439.839,
      "duration": 4.641
    },
    {
      "lang": "en",
      "text": "large if you're hosting it you're also",
      "offset": 2442,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "going to want multiple copies of it",
      "offset": 2444.48,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "because you're responding to many",
      "offset": 2445.92,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "different users at a point in time so",
      "offset": 2447.92,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "it's actually a pretty complex question",
      "offset": 2449.68,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "to answer and it's highly use case",
      "offset": 2452.16,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "dependent the rule of thumb we use",
      "offset": 2454.8,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "though is like and it's not what will",
      "offset": 2457.2,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "fit but again it's what is actually good",
      "offset": 2459.68,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "for a normal use case so for a normal",
      "offset": 2461.76,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "use case uh language models that are in",
      "offset": 2464.56,
      "duration": 5.92
    },
    {
      "lang": "en",
      "text": "the 70 billion parameter range we",
      "offset": 2467.28,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "recommend those for tier one like tier",
      "offset": 2470.48,
      "duration": 4.639
    },
    {
      "lang": "en",
      "text": "one is a good candidate for language",
      "offset": 2473.04,
      "duration": 5.279
    },
    {
      "lang": "en",
      "text": "models that aren't gigantic um but that",
      "offset": 2475.119,
      "duration": 6.24
    },
    {
      "lang": "en",
      "text": "are still sizable and tier one gives you",
      "offset": 2478.319,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "competitive you know and powerful",
      "offset": 2481.359,
      "duration": 5.041
    },
    {
      "lang": "en",
      "text": "compute um for training and hosting",
      "offset": 2483.599,
      "duration": 5.601
    },
    {
      "lang": "en",
      "text": "those models language models that are",
      "offset": 2486.4,
      "duration": 5.56
    },
    {
      "lang": "en",
      "text": "significantly larger than that go to",
      "offset": 2489.2,
      "duration": 6.56
    },
    {
      "lang": "en",
      "text": "DRN2 like by all means go you know play",
      "offset": 2491.96,
      "duration": 6.84
    },
    {
      "lang": "en",
      "text": "with an ultraserver and uh get all those",
      "offset": 2495.76,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "neuron cores and see what you can do",
      "offset": 2498.8,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "with it and again what's nice about it",
      "offset": 2500.96,
      "duration": 4.68
    },
    {
      "lang": "en",
      "text": "what I love about the stack is that",
      "offset": 2503.2,
      "duration": 8.24
    },
    {
      "lang": "en",
      "text": "NXD gives you um both the so like",
      "offset": 2505.64,
      "duration": 8.84
    },
    {
      "lang": "en",
      "text": "connection into the compiler so when you",
      "offset": 2511.44,
      "duration": 6.159
    },
    {
      "lang": "en",
      "text": "implement your modeling code in NXD by",
      "offset": 2514.48,
      "duration": 5.359
    },
    {
      "lang": "en",
      "text": "default you get a nice like sync with",
      "offset": 2517.599,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "the neuron compiler and all of the lower",
      "offset": 2519.839,
      "duration": 5.441
    },
    {
      "lang": "en",
      "text": "level XLA benefits but we also shard the",
      "offset": 2521.76,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "model for you so when you want to play",
      "offset": 2525.28,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "with different TP degrees like say you",
      "offset": 2527.52,
      "duration": 5.599
    },
    {
      "lang": "en",
      "text": "want to try a TP degree of eight on tier",
      "offset": 2530,
      "duration": 6.68
    },
    {
      "lang": "en",
      "text": "one but then on tier two you want to try",
      "offset": 2533.119,
      "duration": 8.48
    },
    {
      "lang": "en",
      "text": "TP32 and TP64 and TP 128 because why not",
      "offset": 2536.68,
      "duration": 7.72
    },
    {
      "lang": "en",
      "text": "and sort of see what happens like NXD",
      "offset": 2541.599,
      "duration": 5.441
    },
    {
      "lang": "en",
      "text": "makes it super easy to do that because",
      "offset": 2544.4,
      "duration": 4.719
    },
    {
      "lang": "en",
      "text": "you're just changing a parameter right",
      "offset": 2547.04,
      "duration": 5.92
    },
    {
      "lang": "en",
      "text": "at the top of the program to then shard",
      "offset": 2549.119,
      "duration": 7.321
    },
    {
      "lang": "en",
      "text": "your checkpoint itself and redefine your",
      "offset": 2552.96,
      "duration": 7.6
    },
    {
      "lang": "en",
      "text": "distribution you know method um and so",
      "offset": 2556.44,
      "duration": 6.28
    },
    {
      "lang": "en",
      "text": "yeah NXD handles all of that for you",
      "offset": 2560.56,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "which I just absolutely love nice and so",
      "offset": 2562.72,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "to define for our listeners that kind of",
      "offset": 2564.96,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "that idea of TPA TP32 TP64 it's the",
      "offset": 2567.119,
      "duration": 6.161
    },
    {
      "lang": "en",
      "text": "precision of the digits at these model",
      "offset": 2570.56,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "parameters right it is not oh it's not",
      "offset": 2573.28,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "yeah no it's not what I meant by TP was",
      "offset": 2576.24,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "like tensor parallel degree actually so",
      "offset": 2578.48,
      "duration": 7.599
    },
    {
      "lang": "en",
      "text": "how many cores or how many Yeah how many",
      "offset": 2582,
      "duration": 9.2
    },
    {
      "lang": "en",
      "text": "neuron cores you'll use to host one like",
      "offset": 2586.079,
      "duration": 8.721
    },
    {
      "lang": "en",
      "text": "copy of your tensor for example so if",
      "offset": 2591.2,
      "duration": 6.24
    },
    {
      "lang": "en",
      "text": "you are doing a TP of 8 that means",
      "offset": 2594.8,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "you're going to consume eight neuron",
      "offset": 2597.44,
      "duration": 7.12
    },
    {
      "lang": "en",
      "text": "cores to do operation X with your tensor",
      "offset": 2599.76,
      "duration": 8
    },
    {
      "lang": "en",
      "text": "if you're doing a TP of 32 that means",
      "offset": 2604.56,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "you're going to shard your model over",
      "offset": 2607.76,
      "duration": 4.44
    },
    {
      "lang": "en",
      "text": "those 32 neuron",
      "offset": 2609.92,
      "duration": 5.199
    },
    {
      "lang": "en",
      "text": "cores in a data type world you would be",
      "offset": 2612.2,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "thinking like",
      "offset": 2615.119,
      "duration": 4.681
    },
    {
      "lang": "en",
      "text": "FP32 and",
      "offset": 2617.24,
      "duration": 5.64
    },
    {
      "lang": "en",
      "text": "BF16 and like INT8 i know they're si",
      "offset": 2619.8,
      "duration": 5.08
    },
    {
      "lang": "en",
      "text": "they're similar but very different",
      "offset": 2622.88,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "meaning i said define for our audience",
      "offset": 2624.88,
      "duration": 4.719
    },
    {
      "lang": "en",
      "text": "but I ended up meaning define for me um",
      "offset": 2626.64,
      "duration": 5.679
    },
    {
      "lang": "en",
      "text": "and so so tell me about this so this",
      "offset": 2629.599,
      "duration": 5.081
    },
    {
      "lang": "en",
      "text": "this TPA TP32 that now you've just",
      "offset": 2632.319,
      "duration": 6.561
    },
    {
      "lang": "en",
      "text": "explained why would I make those changes",
      "offset": 2634.68,
      "duration": 5.639
    },
    {
      "lang": "en",
      "text": "and what impact does making those",
      "offset": 2638.88,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "changes have yeah sure so it it is",
      "offset": 2640.319,
      "duration": 6.561
    },
    {
      "lang": "en",
      "text": "pretty impactful it impacts the",
      "offset": 2644.64,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "collectives a lot actually it impacts",
      "offset": 2646.88,
      "duration": 7.199
    },
    {
      "lang": "en",
      "text": "how much time your workload will spend",
      "offset": 2650.24,
      "duration": 6.64
    },
    {
      "lang": "en",
      "text": "in an all reduce for example or in a",
      "offset": 2654.079,
      "duration": 5.681
    },
    {
      "lang": "en",
      "text": "reduce scatter or in a gather scatter so",
      "offset": 2656.88,
      "duration": 5.56
    },
    {
      "lang": "en",
      "text": "those are these collective operations",
      "offset": 2659.76,
      "duration": 5.92
    },
    {
      "lang": "en",
      "text": "that support the program that you define",
      "offset": 2662.44,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "and support your model and they",
      "offset": 2665.68,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "communicate across all of the cores and",
      "offset": 2668.2,
      "duration": 5.72
    },
    {
      "lang": "en",
      "text": "they collect information uh and so you",
      "offset": 2670.96,
      "duration": 5.92
    },
    {
      "lang": "en",
      "text": "use collectives when you're running",
      "offset": 2673.92,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "distributed training and hosting very",
      "offset": 2676.88,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "regularly and it's important to",
      "offset": 2679.2,
      "duration": 6.159
    },
    {
      "lang": "en",
      "text": "understand like the impact those",
      "offset": 2681.76,
      "duration": 6.16
    },
    {
      "lang": "en",
      "text": "collectives can have on your compute",
      "offset": 2685.359,
      "duration": 5.041
    },
    {
      "lang": "en",
      "text": "when you're profiling your workload um",
      "offset": 2687.92,
      "duration": 5.679
    },
    {
      "lang": "en",
      "text": "and trying to improve it and so when you",
      "offset": 2690.4,
      "duration": 6.56
    },
    {
      "lang": "en",
      "text": "experiment with different TP degrees it",
      "offset": 2693.599,
      "duration": 6.401
    },
    {
      "lang": "en",
      "text": "can improve performance and it can also",
      "offset": 2696.96,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "degrade performance um because of the",
      "offset": 2700,
      "duration": 5.92
    },
    {
      "lang": "en",
      "text": "impact of the collectives uh the impact",
      "offset": 2702.96,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "on memory it'll impact how large of a",
      "offset": 2705.92,
      "duration": 5.919
    },
    {
      "lang": "en",
      "text": "batch size you can hold uh it'll impact",
      "offset": 2708.96,
      "duration": 6.879
    },
    {
      "lang": "en",
      "text": "your overall step time etc and so that's",
      "offset": 2711.839,
      "duration": 7.721
    },
    {
      "lang": "en",
      "text": "why it's helpful to have this ability to",
      "offset": 2715.839,
      "duration": 8.081
    },
    {
      "lang": "en",
      "text": "easily test different TP degrees um also",
      "offset": 2719.56,
      "duration": 8.2
    },
    {
      "lang": "en",
      "text": "on tier 2 because you have this like LNC",
      "offset": 2723.92,
      "duration": 6.159
    },
    {
      "lang": "en",
      "text": "feature logical neuron core feature that",
      "offset": 2727.76,
      "duration": 5.16
    },
    {
      "lang": "en",
      "text": "lets you actually change the size of the",
      "offset": 2730.079,
      "duration": 5.361
    },
    {
      "lang": "en",
      "text": "accelerator logically",
      "offset": 2732.92,
      "duration": 5.8
    },
    {
      "lang": "en",
      "text": "um based on grouping it in sets of one",
      "offset": 2735.44,
      "duration": 5.84
    },
    {
      "lang": "en",
      "text": "which is LNC1 or grouping it in sets of",
      "offset": 2738.72,
      "duration": 5.119
    },
    {
      "lang": "en",
      "text": "two which is LNC2 and so what that does",
      "offset": 2741.28,
      "duration": 5.839
    },
    {
      "lang": "en",
      "text": "is it actually shrinks the total number",
      "offset": 2743.839,
      "duration": 5.201
    },
    {
      "lang": "en",
      "text": "of available accelerators to your",
      "offset": 2747.119,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "program uh so on tier and two an LNC of",
      "offset": 2749.04,
      "duration": 6.319
    },
    {
      "lang": "en",
      "text": "one shows you like 128 trainable devices",
      "offset": 2751.839,
      "duration": 6.721
    },
    {
      "lang": "en",
      "text": "or available devices to your program but",
      "offset": 2755.359,
      "duration": 8.041
    },
    {
      "lang": "en",
      "text": "when you set LNC to two that shrinks the",
      "offset": 2758.56,
      "duration": 8.92
    },
    {
      "lang": "en",
      "text": "number uh so instead of 128 then you see",
      "offset": 2763.4,
      "duration": 7.64
    },
    {
      "lang": "en",
      "text": "64 um and it makes it you know slightly",
      "offset": 2767.48,
      "duration": 6.28
    },
    {
      "lang": "en",
      "text": "more available uh in the HBM bandwidth",
      "offset": 2771.04,
      "duration": 5.039
    },
    {
      "lang": "en",
      "text": "like the the banks obviously don't stay",
      "offset": 2773.76,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "the same i mean the banks stay the same",
      "offset": 2776.079,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "physically the hardware doesn't change",
      "offset": 2778.64,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "at all between those two settings but it",
      "offset": 2780.16,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "changes how much is available per core",
      "offset": 2782.88,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "to your program so it's it's you know",
      "offset": 2785.52,
      "duration": 5.839
    },
    {
      "lang": "en",
      "text": "changes and modifications like this that",
      "offset": 2788.88,
      "duration": 5.92
    },
    {
      "lang": "en",
      "text": "let you uh you know find like the",
      "offset": 2791.359,
      "duration": 5.281
    },
    {
      "lang": "en",
      "text": "optimal balance in your program and in",
      "offset": 2794.8,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "your workload while easily experimenting",
      "offset": 2796.64,
      "duration": 5.84
    },
    {
      "lang": "en",
      "text": "with them through NXD",
      "offset": 2800.16,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "do you ever feel isolated surrounded by",
      "offset": 2802.48,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "people who don't share your enthusiasm",
      "offset": 2804.88,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "for data science and technology do you",
      "offset": 2806.72,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "wish to connect with more like-minded",
      "offset": 2808.88,
      "duration": 4.479
    },
    {
      "lang": "en",
      "text": "individuals well look no further super",
      "offset": 2810.56,
      "duration": 4.559
    },
    {
      "lang": "en",
      "text": "Data Science Community is the perfect",
      "offset": 2813.359,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "place to connect interact and exchange",
      "offset": 2815.119,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "ideas with over 600 professionals in",
      "offset": 2817.04,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "data science machine learning and AI in",
      "offset": 2818.96,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "addition to networking you can get",
      "offset": 2821.359,
      "duration": 3.441
    },
    {
      "lang": "en",
      "text": "direct support for your career through",
      "offset": 2823.28,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "the mentoring program where experienced",
      "offset": 2824.8,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "members help beginners navigate whether",
      "offset": 2826.56,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "you're looking to learn collaborate or",
      "offset": 2828.72,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "advance your career our community is",
      "offset": 2830.56,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "here to help you succeed join Kier Adlan",
      "offset": 2832.56,
      "duration": 4.559
    },
    {
      "lang": "en",
      "text": "and myself and hundreds of other members",
      "offset": 2835.04,
      "duration": 5.279
    },
    {
      "lang": "en",
      "text": "who connect daily start your free 14-day",
      "offset": 2837.119,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "trial today at superdataccience.com and",
      "offset": 2840.319,
      "duration": 5.481
    },
    {
      "lang": "en",
      "text": "become a part of the",
      "offset": 2843.119,
      "duration": 4.641
    },
    {
      "lang": "en",
      "text": "community i got you so these",
      "offset": 2845.8,
      "duration": 5.16
    },
    {
      "lang": "en",
      "text": "configuration parameters like TP degrees",
      "offset": 2847.76,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "when we are dealing with a large",
      "offset": 2850.96,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "language model that's huge so it's",
      "offset": 2853.76,
      "duration": 5
    },
    {
      "lang": "en",
      "text": "distributed across many different",
      "offset": 2856,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "accelerators many different compute",
      "offset": 2858.76,
      "duration": 5.48
    },
    {
      "lang": "en",
      "text": "nodes these kinds of configuration",
      "offset": 2860.72,
      "duration": 5.84
    },
    {
      "lang": "en",
      "text": "parameters like TP degrees need to be",
      "offset": 2864.24,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "configured to figure out for exactly",
      "offset": 2866.56,
      "duration": 3.519
    },
    {
      "lang": "en",
      "text": "your model in the situation you're using",
      "offset": 2868.079,
      "duration": 6.321
    },
    {
      "lang": "en",
      "text": "it uh what is the optimal config totally",
      "offset": 2870.079,
      "duration": 7.04
    },
    {
      "lang": "en",
      "text": "how many tokens per second can you get",
      "offset": 2874.4,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "what's your time to first token um how",
      "offset": 2877.119,
      "duration": 6.081
    },
    {
      "lang": "en",
      "text": "can you reduce your overall cost by you",
      "offset": 2879.92,
      "duration": 6.399
    },
    {
      "lang": "en",
      "text": "know having fewer resources but still",
      "offset": 2883.2,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "you know being able to respond to n",
      "offset": 2886.319,
      "duration": 5.361
    },
    {
      "lang": "en",
      "text": "number of responses you know at a time",
      "offset": 2888.48,
      "duration": 5.599
    },
    {
      "lang": "en",
      "text": "uh so all of these questions we need to",
      "offset": 2891.68,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "consider when we're trying to find like",
      "offset": 2894.079,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "the right instance and trying to find",
      "offset": 2896.4,
      "duration": 3.679
    },
    {
      "lang": "en",
      "text": "the right instance settings very cool",
      "offset": 2897.839,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "all right so now we have a great",
      "offset": 2900.079,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "understanding of why a tranium chip or a",
      "offset": 2901.76,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "tranium 2 chip might be the obvious",
      "offset": 2904.48,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "choice for a listener when they're",
      "offset": 2906.64,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "thinking about training a large language",
      "offset": 2908.16,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "model or inferentia might be when",
      "offset": 2910,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "deploying a large language model so give",
      "offset": 2912.48,
      "duration": 6.48
    },
    {
      "lang": "en",
      "text": "us some real world examples of customers",
      "offset": 2915.52,
      "duration": 5.839
    },
    {
      "lang": "en",
      "text": "that you've had um that have been able",
      "offset": 2918.96,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "to take advantage of these chips um to",
      "offset": 2921.359,
      "duration": 5.601
    },
    {
      "lang": "en",
      "text": "great effect yeah sure so so our our",
      "offset": 2923.44,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "flagship uh customer example of course",
      "offset": 2926.96,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "is Anthropic so Anthropic has been a",
      "offset": 2928.8,
      "duration": 6.319
    },
    {
      "lang": "en",
      "text": "very active um you know developer and",
      "offset": 2931.92,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "customer uh with Tayman Infrenia for",
      "offset": 2935.119,
      "duration": 6.24
    },
    {
      "lang": "en",
      "text": "quite some time uh and so the you know",
      "offset": 2937.92,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "partnership has been phenomenal",
      "offset": 2941.359,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "anthropic is a great team uh it's an",
      "offset": 2943.28,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "absolute privilege to support them as a",
      "offset": 2946.079,
      "duration": 5.841
    },
    {
      "lang": "en",
      "text": "customer and we are developing some big",
      "offset": 2948.16,
      "duration": 5.199
    },
    {
      "lang": "en",
      "text": "projects together so I don't know if you",
      "offset": 2951.92,
      "duration": 3.679
    },
    {
      "lang": "en",
      "text": "heard about project rineer um but",
      "offset": 2953.359,
      "duration": 4.2
    },
    {
      "lang": "en",
      "text": "Rayineer is",
      "offset": 2955.599,
      "duration": 6.24
    },
    {
      "lang": "en",
      "text": "a absolutely gigantic cluster that we",
      "offset": 2957.559,
      "duration": 6.601
    },
    {
      "lang": "en",
      "text": "are developing in collaboration with",
      "offset": 2961.839,
      "duration": 4.361
    },
    {
      "lang": "en",
      "text": "anthropic uh with obviously",
      "offset": 2964.16,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "state-of-the-art um tranium cards and",
      "offset": 2966.2,
      "duration": 6.52
    },
    {
      "lang": "en",
      "text": "instances uh and so it's it's just",
      "offset": 2969.04,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "fascinating and it's it's just a",
      "offset": 2972.72,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "pleasure to innovate with them so",
      "offset": 2974.4,
      "duration": 6.4
    },
    {
      "lang": "en",
      "text": "Anthropic is you know is a great example",
      "offset": 2976.16,
      "duration": 7.679
    },
    {
      "lang": "en",
      "text": "fantastic yeah they certainly are one of",
      "offset": 2980.8,
      "duration": 5.759
    },
    {
      "lang": "en",
      "text": "the leaders at the forefront of AI for",
      "offset": 2983.839,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "me personally you wouldn't know this",
      "offset": 2986.559,
      "duration": 3.441
    },
    {
      "lang": "en",
      "text": "Emily regular listeners probably would",
      "offset": 2987.839,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "that my go-to uh my go-to large language",
      "offset": 2990,
      "duration": 5.4
    },
    {
      "lang": "en",
      "text": "model for most everyday use cases is",
      "offset": 2993.359,
      "duration": 5.361
    },
    {
      "lang": "en",
      "text": "Claude i and it has been for some time",
      "offset": 2995.4,
      "duration": 6.04
    },
    {
      "lang": "en",
      "text": "so yeah love Anthropic and I'm not",
      "offset": 2998.72,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "surprised to hear that there's amazing",
      "offset": 3001.44,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "intelligent people to work with there on",
      "offset": 3002.72,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "really big on big mountains of a problem",
      "offset": 3004.88,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "like Project Reineer",
      "offset": 3007.04,
      "duration": 5.84
    },
    {
      "lang": "en",
      "text": "for for our listeners around the world",
      "offset": 3010.16,
      "duration": 5.919
    },
    {
      "lang": "en",
      "text": "uh Reineer Mountain is a big mountain in",
      "offset": 3012.88,
      "duration": 6.56
    },
    {
      "lang": "en",
      "text": "Washington state not Washington DC it is",
      "offset": 3016.079,
      "duration": 6.401
    },
    {
      "lang": "en",
      "text": "that is correct but yeah no and then so",
      "offset": 3019.44,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "so obviously we have customers across",
      "offset": 3022.48,
      "duration": 4.639
    },
    {
      "lang": "en",
      "text": "the spectrum so Anthropic you know is is",
      "offset": 3024.24,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "such a such an important customer um we",
      "offset": 3027.119,
      "duration": 6.161
    },
    {
      "lang": "en",
      "text": "also work with startups so we work with",
      "offset": 3030.24,
      "duration": 6.319
    },
    {
      "lang": "en",
      "text": "uh startups like RC uh or Ninja Techch",
      "offset": 3033.28,
      "duration": 5.92
    },
    {
      "lang": "en",
      "text": "who are training and hosting small",
      "offset": 3036.559,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "language models uh and in the small",
      "offset": 3039.2,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "language model space it's it's exciting",
      "offset": 3041.359,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "for customers because you know our price",
      "offset": 3043.2,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "performance uh and our overall",
      "offset": 3045.68,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "availability is is just really",
      "offset": 3047.44,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "compelling um they love the benefits",
      "offset": 3049.839,
      "duration": 5.121
    },
    {
      "lang": "en",
      "text": "that they get they love the price they",
      "offset": 3052.8,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "love the performance they love the",
      "offset": 3054.96,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "models they love the software stack so",
      "offset": 3056.8,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "we we definitely see some some great",
      "offset": 3059.52,
      "duration": 5.92
    },
    {
      "lang": "en",
      "text": "movement there um we also see you know",
      "offset": 3061.52,
      "duration": 6.96
    },
    {
      "lang": "en",
      "text": "customers like data bricks uh we are",
      "offset": 3065.44,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "doing some big projects with data bricks",
      "offset": 3068.48,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "not a small startup",
      "offset": 3070.72,
      "duration": 5.599
    },
    {
      "lang": "en",
      "text": "not a small startup yeah yeah no we're",
      "offset": 3073.44,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "we're doing some great work with data",
      "offset": 3076.319,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "bricks uh and then now we're expanding",
      "offset": 3077.76,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "into the academic sector uh with build",
      "offset": 3080.16,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "on trrenium cool what's the build on",
      "offset": 3083.04,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "trainium program yeah so build on",
      "offset": 3085.2,
      "duration": 6.639
    },
    {
      "lang": "en",
      "text": "tranium is a credit program that we are",
      "offset": 3088.24,
      "duration": 7.2
    },
    {
      "lang": "en",
      "text": "running which is $110 million in credits",
      "offset": 3091.839,
      "duration": 7.52
    },
    {
      "lang": "en",
      "text": "that we are offering to academics who",
      "offset": 3095.44,
      "duration": 6.8
    },
    {
      "lang": "en",
      "text": "are working on the future of AI so",
      "offset": 3099.359,
      "duration": 5.401
    },
    {
      "lang": "en",
      "text": "fundamentally this is a way for",
      "offset": 3102.24,
      "duration": 6.24
    },
    {
      "lang": "en",
      "text": "universities academics PIs uh principal",
      "offset": 3104.76,
      "duration": 6.359
    },
    {
      "lang": "en",
      "text": "investigators to submit their research",
      "offset": 3108.48,
      "duration": 6.48
    },
    {
      "lang": "en",
      "text": "ideas to us about their big ideas uh we",
      "offset": 3111.119,
      "duration": 5.361
    },
    {
      "lang": "en",
      "text": "want to know sort of what they've",
      "offset": 3114.96,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "already tested on Trannium what their",
      "offset": 3116.48,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "you know early modeling and early kernel",
      "offset": 3118.64,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "results are and then we are working to",
      "offset": 3120.559,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "scale those results with them on a",
      "offset": 3123.52,
      "duration": 7.28
    },
    {
      "lang": "en",
      "text": "cluster that is up to 40,000 TRN1 cards",
      "offset": 3126.079,
      "duration": 7.921
    },
    {
      "lang": "en",
      "text": "so we have a very significant cluster",
      "offset": 3130.8,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "that is available for researchers uh for",
      "offset": 3134,
      "duration": 6.8
    },
    {
      "lang": "en",
      "text": "the best AI projects in the world and so",
      "offset": 3136.8,
      "duration": 6.559
    },
    {
      "lang": "en",
      "text": "yeah this is this is a a big project of",
      "offset": 3140.8,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "course uh we've been working for it on",
      "offset": 3143.359,
      "duration": 3.521
    },
    {
      "lang": "en",
      "text": "quite some time sounds really cool",
      "offset": 3144.88,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "indeed we'll have a link to the build on",
      "offset": 3146.88,
      "duration": 3.439
    },
    {
      "lang": "en",
      "text": "trainium program in the show notes for",
      "offset": 3148.48,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "those academic listeners out there who",
      "offset": 3150.319,
      "duration": 3.201
    },
    {
      "lang": "en",
      "text": "would like to take advantage of this",
      "offset": 3152.24,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "$110 million program from AWS um I'd",
      "offset": 3153.52,
      "duration": 6.079
    },
    {
      "lang": "en",
      "text": "also like to highlight uh another client",
      "offset": 3157.28,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "of of training and in friendship chips",
      "offset": 3159.599,
      "duration": 5.921
    },
    {
      "lang": "en",
      "text": "that I'm aware of is Poolside and um I'm",
      "offset": 3161.76,
      "duration": 6.44
    },
    {
      "lang": "en",
      "text": "aware of that because back in episode",
      "offset": 3165.52,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "754 we had Jason Warner the CEO of",
      "offset": 3168.2,
      "duration": 5.159
    },
    {
      "lang": "en",
      "text": "Poolside on the show and it's a really",
      "offset": 3171.2,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "cool startup you know it isn't data",
      "offset": 3173.359,
      "duration": 5.681
    },
    {
      "lang": "en",
      "text": "bricks size yet but uh poolside they're",
      "offset": 3175.04,
      "duration": 6.079
    },
    {
      "lang": "en",
      "text": "trying to tackle artificial general",
      "offset": 3179.04,
      "duration": 4.799
    },
    {
      "lang": "en",
      "text": "intelligence from the perspective of",
      "offset": 3181.119,
      "duration": 7.921
    },
    {
      "lang": "en",
      "text": "software of of code um generation and u",
      "offset": 3183.839,
      "duration": 7.52
    },
    {
      "lang": "en",
      "text": "there's compelling arguments that Jason",
      "offset": 3189.04,
      "duration": 4.559
    },
    {
      "lang": "en",
      "text": "makes in episode 754 about how that",
      "offset": 3191.359,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "might be feasible so cool episode to",
      "offset": 3193.599,
      "duration": 3.441
    },
    {
      "lang": "en",
      "text": "highlight there and another trrenium",
      "offset": 3195.76,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "inferentia customer absolutely yeah",
      "offset": 3197.04,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "we're very very excited about the pull",
      "offset": 3200,
      "duration": 4.559
    },
    {
      "lang": "en",
      "text": "set partnership nice all right so um",
      "offset": 3201.52,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "when you're trying to figure out what",
      "offset": 3204.559,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "the right instance is so we've talked",
      "offset": 3206.16,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "about TRN1 TRN2",
      "offset": 3207.839,
      "duration": 5.601
    },
    {
      "lang": "en",
      "text": "um Tranium uh sorry inferentia chips as",
      "offset": 3210.4,
      "duration": 5.199
    },
    {
      "lang": "en",
      "text": "well um the other kinds of instances",
      "offset": 3213.44,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "that are available on AWS how do you",
      "offset": 3215.599,
      "duration": 4.881
    },
    {
      "lang": "en",
      "text": "pick the right kind of instance type for",
      "offset": 3217.599,
      "duration": 5.041
    },
    {
      "lang": "en",
      "text": "a particular machine learning task yeah",
      "offset": 3220.48,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "sure so so of course when you're let's",
      "offset": 3222.64,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "assume we're in the Tranium and",
      "offset": 3225.68,
      "duration": 3.439
    },
    {
      "lang": "en",
      "text": "Inferentia space for the moment so so",
      "offset": 3226.8,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "when you're in that space I mean really",
      "offset": 3229.119,
      "duration": 4.801
    },
    {
      "lang": "en",
      "text": "you have a couple questions obviously we",
      "offset": 3230.64,
      "duration": 5.199
    },
    {
      "lang": "en",
      "text": "have two you know product lines tranium",
      "offset": 3233.92,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "and infia the neuron core itself though",
      "offset": 3235.839,
      "duration": 5.601
    },
    {
      "lang": "en",
      "text": "like the fundamental acceleration unit",
      "offset": 3239.04,
      "duration": 4.799
    },
    {
      "lang": "en",
      "text": "is the same actually the neuron core is",
      "offset": 3241.44,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "the same uh the software stack is also",
      "offset": 3243.839,
      "duration": 4.881
    },
    {
      "lang": "en",
      "text": "the same so you can you know mix and",
      "offset": 3246.64,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "match go back and forth good",
      "offset": 3248.72,
      "duration": 3.359
    },
    {
      "lang": "en",
      "text": "compatibility",
      "offset": 3250.559,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "what's different between the two uh is",
      "offset": 3252.079,
      "duration": 6.401
    },
    {
      "lang": "en",
      "text": "that the instance topology is just",
      "offset": 3255.839,
      "duration": 5
    },
    {
      "lang": "en",
      "text": "configured differently so with",
      "offset": 3258.48,
      "duration": 5.24
    },
    {
      "lang": "en",
      "text": "TRN1 we assume that you're going to be",
      "offset": 3260.839,
      "duration": 6.201
    },
    {
      "lang": "en",
      "text": "training so we connect the cards in",
      "offset": 3263.72,
      "duration": 5.639
    },
    {
      "lang": "en",
      "text": "what's called a a Taurus topology or a",
      "offset": 3267.04,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "4D Taurus topology which means that the",
      "offset": 3269.359,
      "duration": 6.081
    },
    {
      "lang": "en",
      "text": "cards are connected to each other uh in",
      "offset": 3272,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "a way that you can easily do a backward",
      "offset": 3275.44,
      "duration": 4.879
    },
    {
      "lang": "en",
      "text": "pass you can easily gather the results",
      "offset": 3277.44,
      "duration": 5.919
    },
    {
      "lang": "en",
      "text": "from all of the cards and then update",
      "offset": 3280.319,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "the optimizer state so the con",
      "offset": 3283.359,
      "duration": 5.441
    },
    {
      "lang": "en",
      "text": "connectivity between the cards is much",
      "offset": 3286.079,
      "duration": 7.801
    },
    {
      "lang": "en",
      "text": "more suited for uh complex backward pass",
      "offset": 3288.8,
      "duration": 9.36
    },
    {
      "lang": "en",
      "text": "whereas in the inferentia line again the",
      "offset": 3293.88,
      "duration": 7.719
    },
    {
      "lang": "en",
      "text": "same neuron core but the topology is",
      "offset": 3298.16,
      "duration": 7.199
    },
    {
      "lang": "en",
      "text": "more aligned for just a forward pass so",
      "offset": 3301.599,
      "duration": 5.921
    },
    {
      "lang": "en",
      "text": "when you you know study the architecture",
      "offset": 3305.359,
      "duration": 5.361
    },
    {
      "lang": "en",
      "text": "you'll see that you might you have just",
      "offset": 3307.52,
      "duration": 6.72
    },
    {
      "lang": "en",
      "text": "one row of the cards for example uh",
      "offset": 3310.72,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "they're not you know it's it's not this",
      "offset": 3314.24,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "4D topology it's it's sort of more",
      "offset": 3316.48,
      "duration": 4.879
    },
    {
      "lang": "en",
      "text": "aligned for just taking you know a large",
      "offset": 3318.8,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "tensor sharding a large tensor on the",
      "offset": 3321.359,
      "duration": 5.601
    },
    {
      "lang": "en",
      "text": "fleet uh and then doing a forward pass",
      "offset": 3324.24,
      "duration": 4.879
    },
    {
      "lang": "en",
      "text": "so that's that's some of the difference",
      "offset": 3326.96,
      "duration": 4.92
    },
    {
      "lang": "en",
      "text": "uh another difference is that in in",
      "offset": 3329.119,
      "duration": 5.521
    },
    {
      "lang": "en",
      "text": "Frenchia you have kind of more you have",
      "offset": 3331.88,
      "duration": 6.92
    },
    {
      "lang": "en",
      "text": "more choices uh you have many different",
      "offset": 3334.64,
      "duration": 7.439
    },
    {
      "lang": "en",
      "text": "um options for instance size between",
      "offset": 3338.8,
      "duration": 6.4
    },
    {
      "lang": "en",
      "text": "like how many accelerators you want uh",
      "offset": 3342.079,
      "duration": 5.841
    },
    {
      "lang": "en",
      "text": "your you know HBM uh capacity as a",
      "offset": 3345.2,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "result of that whereas in tranium it's",
      "offset": 3347.92,
      "duration": 6.72
    },
    {
      "lang": "en",
      "text": "sort of really small and really large so",
      "offset": 3350.96,
      "duration": 6.24
    },
    {
      "lang": "en",
      "text": "that's why we see you know a good",
      "offset": 3354.64,
      "duration": 4.959
    },
    {
      "lang": "en",
      "text": "benefit on training where you're doing",
      "offset": 3357.2,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "your small development with like a",
      "offset": 3359.599,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "single you know tier and one and then",
      "offset": 3361.52,
      "duration": 5.279
    },
    {
      "lang": "en",
      "text": "you're scaling it up for you know one",
      "offset": 3363.92,
      "duration": 4.639
    },
    {
      "lang": "en",
      "text": "large instance and then as many",
      "offset": 3366.799,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "instances as you can get and you don't",
      "offset": 3368.559,
      "duration": 4.201
    },
    {
      "lang": "en",
      "text": "really need that flexibility whereas in",
      "offset": 3370.319,
      "duration": 5.121
    },
    {
      "lang": "en",
      "text": "inferentia you know you might want to",
      "offset": 3372.76,
      "duration": 5.319
    },
    {
      "lang": "en",
      "text": "host your you know 7 billion or your 11",
      "offset": 3375.44,
      "duration": 6.24
    },
    {
      "lang": "en",
      "text": "billion parameter model that isn't going",
      "offset": 3378.079,
      "duration": 5.921
    },
    {
      "lang": "en",
      "text": "to have the same compute requirements",
      "offset": 3381.68,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "nice that was a great explanation as as",
      "offset": 3384,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "they have been throughout this episode",
      "offset": 3386.4,
      "duration": 3.88
    },
    {
      "lang": "en",
      "text": "and actually speaking of your great",
      "offset": 3388.16,
      "duration": 6.48
    },
    {
      "lang": "en",
      "text": "explanations you do have a history uh of",
      "offset": 3390.28,
      "duration": 5.96
    },
    {
      "lang": "en",
      "text": "education i mentioned that earlier in",
      "offset": 3394.64,
      "duration": 3.439
    },
    {
      "lang": "en",
      "text": "the episode we would talk about uh some",
      "offset": 3396.24,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "of the educational stuff you did so for",
      "offset": 3398.079,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "example you wrote a big 15 chapter book",
      "offset": 3399.52,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "called pre-trained vision and large",
      "offset": 3402.48,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "language models in Python it's got a",
      "offset": 3404.4,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "long it's got a good subtitle too end",
      "offset": 3406.48,
      "duration": 3.599
    },
    {
      "lang": "en",
      "text": "toend techniques for building and",
      "offset": 3408.24,
      "duration": 4.559
    },
    {
      "lang": "en",
      "text": "deploying foundation models on AWS so",
      "offset": 3410.079,
      "duration": 4.801
    },
    {
      "lang": "en",
      "text": "short form title pre-trained vision in",
      "offset": 3412.799,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "LLM in Python um and so that's a a big",
      "offset": 3414.88,
      "duration": 6.32
    },
    {
      "lang": "en",
      "text": "15 chapter book and you have also been",
      "offset": 3418.319,
      "duration": 5.081
    },
    {
      "lang": "en",
      "text": "an adjunct professor and a startup",
      "offset": 3421.2,
      "duration": 5.359
    },
    {
      "lang": "en",
      "text": "mentor um you created a course called",
      "offset": 3423.4,
      "duration": 6.12
    },
    {
      "lang": "en",
      "text": "Generative AI foundations on AWS um so",
      "offset": 3426.559,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "we'll have that in the show notes as",
      "offset": 3429.52,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "well um and you know when I put all of",
      "offset": 3431.119,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "that into context for our listeners it's",
      "offset": 3434.64,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "probably totally unsurprising that uh",
      "offset": 3436.799,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "you're involved in the build on trainium",
      "offset": 3438.72,
      "duration": 2.8
    },
    {
      "lang": "en",
      "text": "academic program that we were talking",
      "offset": 3440.4,
      "duration": 2.8
    },
    {
      "lang": "en",
      "text": "about earlier because that involves",
      "offset": 3441.52,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "amazing uh research universities like UC",
      "offset": 3443.2,
      "duration": 4.639
    },
    {
      "lang": "en",
      "text": "Berkeley Carnegie Melon the University",
      "offset": 3445.92,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "of Texas at Austin and Oxford University",
      "offset": 3447.839,
      "duration": 6.441
    },
    {
      "lang": "en",
      "text": "um so very very cool um I",
      "offset": 3450.4,
      "duration": 6.88
    },
    {
      "lang": "en",
      "text": "have our I I think this comes from our",
      "offset": 3454.28,
      "duration": 4.6
    },
    {
      "lang": "en",
      "text": "researcher Serge Miss who's always",
      "offset": 3457.28,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "pulling in uh really interesting uh",
      "offset": 3458.88,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "pieces from our guest backgrounds um I",
      "offset": 3461.52,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "have this quote uh that at a Swiss",
      "offset": 3464.16,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "machine learning conference called AMLD",
      "offset": 3466.88,
      "duration": 5.919
    },
    {
      "lang": "en",
      "text": "you told the story of Francesco Petrarch",
      "offset": 3469.68,
      "duration": 5.919
    },
    {
      "lang": "en",
      "text": "a poet from the Italian Renaissance and",
      "offset": 3472.799,
      "duration": 8.56
    },
    {
      "lang": "en",
      "text": "how uh how this story relates to the AI",
      "offset": 3475.599,
      "duration": 7.041
    },
    {
      "lang": "en",
      "text": "development project so could you",
      "offset": 3481.359,
      "duration": 3.041
    },
    {
      "lang": "en",
      "text": "elaborate on this story and how it",
      "offset": 3482.64,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "influences your approach not only to AI",
      "offset": 3484.4,
      "duration": 4.719
    },
    {
      "lang": "en",
      "text": "development but also your efforts in AI",
      "offset": 3486.96,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "education sure yeah so there's there's a",
      "offset": 3489.119,
      "duration": 5.281
    },
    {
      "lang": "en",
      "text": "lot to unpack there let's let's try and",
      "offset": 3492.48,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "take it step by step um so again because",
      "offset": 3494.4,
      "duration": 6.719
    },
    {
      "lang": "en",
      "text": "I don't have an undergrad in computer",
      "offset": 3498,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "science uh and I don't have a PhD in",
      "offset": 3501.119,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "computer science i didn't have that",
      "offset": 3503.76,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "opportunity um I feel like I've had to",
      "offset": 3505.2,
      "duration": 6.32
    },
    {
      "lang": "en",
      "text": "teach myself a lot and obviously I've",
      "offset": 3508.96,
      "duration": 4.639
    },
    {
      "lang": "en",
      "text": "had you know phenomenal mentors and and",
      "offset": 3511.52,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "have worked on phenomenal teams that",
      "offset": 3513.599,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "push me um worked with phenomenal",
      "offset": 3515.2,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "customers who push me um I know what I",
      "offset": 3517.28,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "love about technology the reason why I",
      "offset": 3520.64,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "love software so much is because in",
      "offset": 3522.96,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "software if you build it you can",
      "offset": 3524.96,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "understand it at least that's how I feel",
      "offset": 3527.119,
      "duration": 4.561
    },
    {
      "lang": "en",
      "text": "if you know it doesn't matter how",
      "offset": 3529.68,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "complicated something is doesn't matter",
      "offset": 3531.68,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "if I didn't take that class doesn't",
      "offset": 3534.48,
      "duration": 4.879
    },
    {
      "lang": "en",
      "text": "matter if I didn't have a PhD in",
      "offset": 3536.88,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "whatever it is if I can code it I can",
      "offset": 3539.359,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "convince myself that I can probably",
      "offset": 3542.88,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "understand what's going on and so from",
      "offset": 3544.559,
      "duration": 5.841
    },
    {
      "lang": "en",
      "text": "that perspective that is the perspective",
      "offset": 3547.76,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "by which I teach because I understand",
      "offset": 3550.4,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "that we live in a world where not",
      "offset": 3553.76,
      "duration": 3.359
    },
    {
      "lang": "en",
      "text": "everyone has every opportunity that",
      "offset": 3555.44,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "maybe they wish they had but nonetheless",
      "offset": 3557.119,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "here we are and we're doing our best and",
      "offset": 3559.04,
      "duration": 5.319
    },
    {
      "lang": "en",
      "text": "so I love teaching because I",
      "offset": 3562.079,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "love taking things that were hard for me",
      "offset": 3564.359,
      "duration": 5.48
    },
    {
      "lang": "en",
      "text": "to understand that were hard for me to",
      "offset": 3566.799,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "you know explain to myself um but",
      "offset": 3569.839,
      "duration": 5.441
    },
    {
      "lang": "en",
      "text": "because it was challenging somehow I was",
      "offset": 3572.559,
      "duration": 5.601
    },
    {
      "lang": "en",
      "text": "able to find a way to simplify it to",
      "offset": 3575.28,
      "duration": 5.279
    },
    {
      "lang": "en",
      "text": "myself then I love sharing that with",
      "offset": 3578.16,
      "duration": 3.8
    },
    {
      "lang": "en",
      "text": "other people because I know it",
      "offset": 3580.559,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "simplifies their journey and it",
      "offset": 3581.96,
      "duration": 4.119
    },
    {
      "lang": "en",
      "text": "simplifies their path certainly",
      "offset": 3584.16,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "simplifies their you know experience on",
      "offset": 3586.079,
      "duration": 5.401
    },
    {
      "lang": "en",
      "text": "AWS with my own technology stack and so",
      "offset": 3588.24,
      "duration": 6.24
    },
    {
      "lang": "en",
      "text": "that you know ethos I guess I just love",
      "offset": 3591.48,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "I I've always loved and so it's",
      "offset": 3594.48,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "education you know is is a part of why I",
      "offset": 3596.44,
      "duration": 5.8
    },
    {
      "lang": "en",
      "text": "enjoy that and it's a way to you know",
      "offset": 3599.68,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "scale that and and help others grow so",
      "offset": 3602.24,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "So that I just really enjoy i want to",
      "offset": 3604.4,
      "duration": 7.6
    },
    {
      "lang": "en",
      "text": "address the petro point i love that that",
      "offset": 3607.52,
      "duration": 7.2
    },
    {
      "lang": "en",
      "text": "came up um it's it's sometimes",
      "offset": 3612,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "surprising how you know things you post",
      "offset": 3614.72,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "on the internet show up later so that's",
      "offset": 3616.72,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "that's beautiful i'm also just a",
      "offset": 3618.799,
      "duration": 5.841
    },
    {
      "lang": "en",
      "text": "humanist like I love so many things in",
      "offset": 3621.68,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "this world i love art i love art history",
      "offset": 3624.64,
      "duration": 5.679
    },
    {
      "lang": "en",
      "text": "i love philosophy i love thinking about",
      "offset": 3627.28,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "things in ways that didn't previously",
      "offset": 3630.319,
      "duration": 4.881
    },
    {
      "lang": "en",
      "text": "you know consider to me so the reason",
      "offset": 3633.28,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "why I did that I was prepping um to do",
      "offset": 3635.2,
      "duration": 6.159
    },
    {
      "lang": "en",
      "text": "an invited you know talk like an invited",
      "offset": 3638.88,
      "duration": 4.959
    },
    {
      "lang": "en",
      "text": "keynote at this conference in",
      "offset": 3641.359,
      "duration": 5.361
    },
    {
      "lang": "en",
      "text": "Switzerland um and this was at the time",
      "offset": 3643.839,
      "duration": 5.841
    },
    {
      "lang": "en",
      "text": "when LLMs were like just becoming to be",
      "offset": 3646.72,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "popular and foundation models were just",
      "offset": 3649.68,
      "duration": 4.639
    },
    {
      "lang": "en",
      "text": "becoming to be popular so I wanted like",
      "offset": 3651.68,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "a nice quote about intelligence that",
      "offset": 3654.319,
      "duration": 5.841
    },
    {
      "lang": "en",
      "text": "would feel like culturally relevant so I",
      "offset": 3656.72,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "thought Petrarch would would be a good",
      "offset": 3660.16,
      "duration": 4.84
    },
    {
      "lang": "en",
      "text": "quote so I got some nice you know phrase",
      "offset": 3662.24,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "about human intelligence and the impact",
      "offset": 3665,
      "duration": 5.559
    },
    {
      "lang": "en",
      "text": "of human intelligence and it's it's",
      "offset": 3667.92,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "funny that like we live in a world where",
      "offset": 3670.559,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "like we need to talk about human",
      "offset": 3672.96,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "intelligence as like an important thing",
      "offset": 3674.559,
      "duration": 6.56
    },
    {
      "lang": "en",
      "text": "that matters like I don't know I see you",
      "offset": 3677.28,
      "duration": 6.319
    },
    {
      "lang": "en",
      "text": "know so much going on in the LLM space",
      "offset": 3681.119,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "and the AGI space and like don't get me",
      "offset": 3683.599,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "wrong obviously I'm all about scaling",
      "offset": 3686.079,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "out you know computers and like",
      "offset": 3688,
      "duration": 5.119
    },
    {
      "lang": "en",
      "text": "developing AI but I also care a lot",
      "offset": 3690.24,
      "duration": 6.079
    },
    {
      "lang": "en",
      "text": "about human intelligence um I find it",
      "offset": 3693.119,
      "duration": 5.521
    },
    {
      "lang": "en",
      "text": "super valuable in my own life to",
      "offset": 3696.319,
      "duration": 4.881
    },
    {
      "lang": "en",
      "text": "maintain my own intelligence as a goal",
      "offset": 3698.64,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "like I find that valuable in you know",
      "offset": 3701.2,
      "duration": 5.359
    },
    {
      "lang": "en",
      "text": "the life of my team and you know people",
      "offset": 3704.16,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "that I work with it's like we need to",
      "offset": 3706.559,
      "duration": 4.881
    },
    {
      "lang": "en",
      "text": "continue to grow our own intelligence",
      "offset": 3709.44,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "while we're obviously growing the",
      "offset": 3711.44,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "intelligence of the machines um but that",
      "offset": 3712.96,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "balance between those two I I really",
      "offset": 3716,
      "duration": 5.599
    },
    {
      "lang": "en",
      "text": "enjoy and I I just I just find so fun to",
      "offset": 3718.64,
      "duration": 7.04
    },
    {
      "lang": "en",
      "text": "consider well that idea of AI being for",
      "offset": 3721.599,
      "duration": 6.72
    },
    {
      "lang": "en",
      "text": "humans and supporting our intelligence",
      "offset": 3725.68,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "and you know our actualization as",
      "offset": 3728.319,
      "duration": 5.921
    },
    {
      "lang": "en",
      "text": "individuals and as and as a society",
      "offset": 3731.68,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "that's actually a theme of two recent",
      "offset": 3734.24,
      "duration": 5.839
    },
    {
      "lang": "en",
      "text": "episodes of this show so uh we have two",
      "offset": 3737.28,
      "duration": 4.799
    },
    {
      "lang": "en",
      "text": "episodes largely dedicated to that kind",
      "offset": 3740.079,
      "duration": 5.841
    },
    {
      "lang": "en",
      "text": "of idea which is episodes 869 and 873",
      "offset": 3742.079,
      "duration": 6.441
    },
    {
      "lang": "en",
      "text": "with Verun God and Natalie Mombio",
      "offset": 3745.92,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "respectively so yeah there seems to be",
      "offset": 3748.52,
      "duration": 4.44
    },
    {
      "lang": "en",
      "text": "it's something that kind of has just",
      "offset": 3751.52,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "started to come onto my mind as well and",
      "offset": 3752.96,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "at the time of recording I'm preparing a",
      "offset": 3755.04,
      "duration": 4.559
    },
    {
      "lang": "en",
      "text": "keynote kind of along uh those those",
      "offset": 3756.64,
      "duration": 5.679
    },
    {
      "lang": "en",
      "text": "themes as well so um yeah I think",
      "offset": 3759.599,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "there's something special there um my",
      "offset": 3762.319,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "final technical question for you before",
      "offset": 3764.799,
      "duration": 3.361
    },
    {
      "lang": "en",
      "text": "we get into our kind of wrap-up",
      "offset": 3766.559,
      "duration": 5.121
    },
    {
      "lang": "en",
      "text": "questions Emily is uh just kind of your",
      "offset": 3768.16,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "insights into what's going to happen",
      "offset": 3771.68,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "next obviously it's a fastmoving field",
      "offset": 3773.68,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "but you're right at the heartbeat of it",
      "offset": 3775.76,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "they're working on hardware like tranium",
      "offset": 3777.76,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "and inferentia so field of AI is moving",
      "offset": 3779.28,
      "duration": 5.279
    },
    {
      "lang": "en",
      "text": "incredibly fast what emerging technical",
      "offset": 3781.839,
      "duration": 5.361
    },
    {
      "lang": "en",
      "text": "challenges most excite you uh you know",
      "offset": 3784.559,
      "duration": 6.081
    },
    {
      "lang": "en",
      "text": "what do you think is coming next yeah",
      "offset": 3787.2,
      "duration": 7.359
    },
    {
      "lang": "en",
      "text": "sure so so I think where you know five",
      "offset": 3790.64,
      "duration": 5.959
    },
    {
      "lang": "en",
      "text": "years ago this was a question",
      "offset": 3794.559,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "unambiguously large language models are",
      "offset": 3796.599,
      "duration": 4.76
    },
    {
      "lang": "en",
      "text": "here to stay like this this is just",
      "offset": 3798.72,
      "duration": 6.079
    },
    {
      "lang": "en",
      "text": "clear um how these continue to be",
      "offset": 3801.359,
      "duration": 6.321
    },
    {
      "lang": "en",
      "text": "integrated into applications the nature",
      "offset": 3804.799,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "of them the fine-tuning of them the",
      "offset": 3807.68,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "agentic you know systems that are built",
      "offset": 3810.799,
      "duration": 4.881
    },
    {
      "lang": "en",
      "text": "on top of them the pre-training of them",
      "offset": 3812.96,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "the data set selection for them the",
      "offset": 3815.68,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "evaluation of them all of those will",
      "offset": 3817.68,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "change all of those are in flux all of",
      "offset": 3819.68,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "those will evolve um for a while I've",
      "offset": 3822.079,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "seen you know particularly in my",
      "offset": 3825.68,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "stagemaker days like how over time it",
      "offset": 3827.039,
      "duration": 5.121
    },
    {
      "lang": "en",
      "text": "just makes so much sense to push",
      "offset": 3829.839,
      "duration": 4.801
    },
    {
      "lang": "en",
      "text": "knowledge into the model as much as",
      "offset": 3832.16,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "possible like it simplifies the lift for",
      "offset": 3834.64,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "development teams simplifies the lift on",
      "offset": 3837.2,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "data management simplifies the lift on",
      "offset": 3839.92,
      "duration": 4.639
    },
    {
      "lang": "en",
      "text": "the application management so I think",
      "offset": 3842.48,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "you'll we'll you'll continue to see like",
      "offset": 3844.559,
      "duration": 5.121
    },
    {
      "lang": "en",
      "text": "a variety of ways that people try to",
      "offset": 3846.72,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "push knowledge into LLMs like push",
      "offset": 3849.68,
      "duration": 4.639
    },
    {
      "lang": "en",
      "text": "knowledge into an LLM in the",
      "offset": 3852.16,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "pre-training stage right when you're",
      "offset": 3854.319,
      "duration": 2.881
    },
    {
      "lang": "en",
      "text": "creating the foundation model from",
      "offset": 3855.92,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "scratch you do it when you're doing",
      "offset": 3857.2,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "supervised fine-tuning to teach it how",
      "offset": 3859.92,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "to follow commands you do it when you're",
      "offset": 3861.92,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "aligning the language model to perform",
      "offset": 3864.24,
      "duration": 5.839
    },
    {
      "lang": "en",
      "text": "complex reasoning you do it uh when",
      "offset": 3866.96,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "you're designing your rag system you do",
      "offset": 3870.079,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "it when you're designing your aentic",
      "offset": 3872.16,
      "duration": 5.56
    },
    {
      "lang": "en",
      "text": "system but really all of those are just",
      "offset": 3873.76,
      "duration": 7.68
    },
    {
      "lang": "en",
      "text": "fluff compared to what's actually in the",
      "offset": 3877.72,
      "duration": 6.28
    },
    {
      "lang": "en",
      "text": "neural network itself and so what I",
      "offset": 3881.44,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "think you'll continue to see is this",
      "offset": 3884,
      "duration": 5.119
    },
    {
      "lang": "en",
      "text": "synergy between people solving problems",
      "offset": 3886.16,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "at the agentic system at the agentic",
      "offset": 3889.119,
      "duration": 6.96
    },
    {
      "lang": "en",
      "text": "level that then are absorbed by the rag",
      "offset": 3891.92,
      "duration": 6.08
    },
    {
      "lang": "en",
      "text": "that are absorbed at pre-training that",
      "offset": 3896.079,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "are absorbed by the you know data set",
      "offset": 3898,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "itself and then obviously hardware is",
      "offset": 3900.24,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "going to keep cruising like we have a",
      "offset": 3902.4,
      "duration": 6.48
    },
    {
      "lang": "en",
      "text": "lot in store um tier 3 you know was",
      "offset": 3904,
      "duration": 7.359
    },
    {
      "lang": "en",
      "text": "pre-announced at reinvent tier 3 is on",
      "offset": 3908.88,
      "duration": 5.679
    },
    {
      "lang": "en",
      "text": "the way um we are very much just getting",
      "offset": 3911.359,
      "duration": 5.361
    },
    {
      "lang": "en",
      "text": "started in what you're going to see from",
      "offset": 3914.559,
      "duration": 5.201
    },
    {
      "lang": "en",
      "text": "Trainium and Infrenia um with Nikki with",
      "offset": 3916.72,
      "duration": 6.319
    },
    {
      "lang": "en",
      "text": "Bill on Tranium so stay tuned um but in",
      "offset": 3919.76,
      "duration": 6.52
    },
    {
      "lang": "en",
      "text": "terms of the LLMs themselves",
      "offset": 3923.039,
      "duration": 6.161
    },
    {
      "lang": "en",
      "text": "like yeah there's there's a lot that's",
      "offset": 3926.28,
      "duration": 4.279
    },
    {
      "lang": "en",
      "text": "going to continue to be the case but",
      "offset": 3929.2,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "it's also you know it's kind of",
      "offset": 3930.559,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "encouraging that like the core problem",
      "offset": 3932.24,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "is the same everyone's still trying to",
      "offset": 3934.48,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "train their model the best they can and",
      "offset": 3937.28,
      "duration": 4.559
    },
    {
      "lang": "en",
      "text": "figure out how to host it and figure out",
      "offset": 3939.52,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "how to do inferencing on it the best",
      "offset": 3941.839,
      "duration": 5.121
    },
    {
      "lang": "en",
      "text": "like that has not changed i don't expect",
      "offset": 3943.68,
      "duration": 6.96
    },
    {
      "lang": "en",
      "text": "that to change ever um but now the focus",
      "offset": 3946.96,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "obviously is language models and doing",
      "offset": 3950.64,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "that the most efficiently uh with the",
      "offset": 3952.48,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "best results with the best mixture of",
      "offset": 3954.88,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "results and so I think there there's a",
      "offset": 3957.68,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "lot that you'll continue to see in that",
      "offset": 3959.76,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "space fantastic answer thank you lots to",
      "offset": 3961.2,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "look forward to and of course uh driven",
      "offset": 3963.76,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "by hardware that's what's happening",
      "offset": 3966.96,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "right now uh fantastic Emily this has",
      "offset": 3968.24,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "been a sensational episode i've learned",
      "offset": 3971.52,
      "duration": 6.64
    },
    {
      "lang": "en",
      "text": "a ton i marked down for our show notes",
      "offset": 3973.44,
      "duration": 7.04
    },
    {
      "lang": "en",
      "text": "maybe a record number of links that I'm",
      "offset": 3978.16,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "going to have to like terms interesting",
      "offset": 3980.48,
      "duration": 4.879
    },
    {
      "lang": "en",
      "text": "terms that people will dig into uh will",
      "offset": 3982.64,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "be able to dig into after the episode so",
      "offset": 3985.359,
      "duration": 6.321
    },
    {
      "lang": "en",
      "text": "clearly a huge amount of uh concrete uh",
      "offset": 3987.44,
      "duration": 6.32
    },
    {
      "lang": "en",
      "text": "useful content conveyed in this episode",
      "offset": 3991.68,
      "duration": 4.639
    },
    {
      "lang": "en",
      "text": "thank you so much before I let you go I",
      "offset": 3993.76,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "always ask my guests for a book",
      "offset": 3996.319,
      "duration": 6.881
    },
    {
      "lang": "en",
      "text": "recommendation yes so I got this book",
      "offset": 3997.839,
      "duration": 8.321
    },
    {
      "lang": "en",
      "text": "today actually delivered by Amazon i",
      "offset": 4003.2,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "don't know if this is coming through",
      "offset": 4006.16,
      "duration": 5.679
    },
    {
      "lang": "en",
      "text": "it's probably not coming through um most",
      "offset": 4008.16,
      "duration": 6.399
    },
    {
      "lang": "en",
      "text": "most of our most of our uh listeners are",
      "offset": 4011.839,
      "duration": 4.881
    },
    {
      "lang": "en",
      "text": "listeners only we do have you know there",
      "offset": 4014.559,
      "duration": 3.401
    },
    {
      "lang": "en",
      "text": "are some YouTube",
      "offset": 4016.72,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "viewers so we might But so Emily Emily",
      "offset": 4017.96,
      "duration": 6.04
    },
    {
      "lang": "en",
      "text": "was holding up the book uh delivered by",
      "offset": 4021.68,
      "duration": 5.32
    },
    {
      "lang": "en",
      "text": "Amazon uh on to the video",
      "offset": 4024,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "camera uh what's the title of the book",
      "offset": 4027,
      "duration": 5.559
    },
    {
      "lang": "en",
      "text": "yeah so the book is called Voice for the",
      "offset": 4029.68,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "Voiceless and it's a book by His",
      "offset": 4032.559,
      "duration": 5.361
    },
    {
      "lang": "en",
      "text": "Holiness the Daly Lama um so I I",
      "offset": 4034.96,
      "duration": 4.879
    },
    {
      "lang": "en",
      "text": "mentioned to you that I you know I love",
      "offset": 4037.92,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "to meditate um and I'm a Buddhist",
      "offset": 4039.839,
      "duration": 4.641
    },
    {
      "lang": "en",
      "text": "practitioner so of course I love to read",
      "offset": 4042.48,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "you know just personally I love to read",
      "offset": 4044.48,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "the the words of his holiness the Dalai",
      "offset": 4046,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "Lama um so I'm very much looking forward",
      "offset": 4048.16,
      "duration": 6.08
    },
    {
      "lang": "en",
      "text": "to reviewing this book u to reading it",
      "offset": 4051.2,
      "duration": 5.839
    },
    {
      "lang": "en",
      "text": "and and you know sympathizing with his",
      "offset": 4054.24,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "you know struggles but also with his",
      "offset": 4057.039,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "wisdom um you know I I find his Soliness",
      "offset": 4058.72,
      "duration": 5.839
    },
    {
      "lang": "en",
      "text": "to just really you know do a remarkable",
      "offset": 4061.359,
      "duration": 6.881
    },
    {
      "lang": "en",
      "text": "job of combining you know wisdom with",
      "offset": 4064.559,
      "duration": 6.48
    },
    {
      "lang": "en",
      "text": "compassion in the modern time while also",
      "offset": 4068.24,
      "duration": 5.92
    },
    {
      "lang": "en",
      "text": "holding on to the you know strength of",
      "offset": 4071.039,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "his lineage uh and so I'm I'm very much",
      "offset": 4074.16,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "looking forward to reading this book and",
      "offset": 4076.799,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "I would tentatively offer my",
      "offset": 4079.2,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "recommendation for it uh on that basis",
      "offset": 4080.96,
      "duration": 4.639
    },
    {
      "lang": "en",
      "text": "nice recommendation i'm sure it's an",
      "offset": 4083.68,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "exceptional book i have read books by",
      "offset": 4085.599,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "his holiness the Daly Lama in the past i",
      "offset": 4087.92,
      "duration": 4.639
    },
    {
      "lang": "en",
      "text": "read an open heart um some years ago",
      "offset": 4089.68,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "which I thought was great it was uh it",
      "offset": 4092.559,
      "duration": 4.481
    },
    {
      "lang": "en",
      "text": "includes some kind of introductory tips",
      "offset": 4094.079,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "on meditation um I was already I had",
      "offset": 4097.04,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "already been meditating for a few years",
      "offset": 4099.679,
      "duration": 3.281
    },
    {
      "lang": "en",
      "text": "at that point but there were some great",
      "offset": 4100.96,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "pointers in there and just some great",
      "offset": 4102.96,
      "duration": 4.799
    },
    {
      "lang": "en",
      "text": "life advice he seems to be quite sage",
      "offset": 4104.88,
      "duration": 5
    },
    {
      "lang": "en",
      "text": "he's a sage",
      "offset": 4107.759,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "maker if you read his books",
      "offset": 4109.88,
      "duration": 6.919
    },
    {
      "lang": "en",
      "text": "indeed indeed um he will yeah he he",
      "offset": 4113.279,
      "duration": 6.641
    },
    {
      "lang": "en",
      "text": "makes his readers sage um so there you",
      "offset": 4116.799,
      "duration": 7.52
    },
    {
      "lang": "en",
      "text": "go a nice AWS joke um all right Emily so",
      "offset": 4119.92,
      "duration": 7.359
    },
    {
      "lang": "en",
      "text": "how can we follow you after this episode",
      "offset": 4124.319,
      "duration": 5.201
    },
    {
      "lang": "en",
      "text": "yeah sure so you're welcome to follow me",
      "offset": 4127.279,
      "duration": 6.08
    },
    {
      "lang": "en",
      "text": "on LinkedIn um I will warn you that I am",
      "offset": 4129.52,
      "duration": 7.279
    },
    {
      "lang": "en",
      "text": "just not active on social media so how",
      "offset": 4133.359,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "could you be Buddhist centered and",
      "offset": 4136.799,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "active on social media those are",
      "offset": 4138.799,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "incompatible",
      "offset": 4140.159,
      "duration": 4.721
    },
    {
      "lang": "en",
      "text": "i'm not saying they're incompatible i'm",
      "offset": 4143.12,
      "duration": 3.679
    },
    {
      "lang": "en",
      "text": "just not that active on I bet it makes",
      "offset": 4144.88,
      "duration": 5.439
    },
    {
      "lang": "en",
      "text": "it harder but yeah uh you're you're",
      "offset": 4146.799,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "actually the first podcast that I've",
      "offset": 4150.319,
      "duration": 5.281
    },
    {
      "lang": "en",
      "text": "ever done no uh it's true it's true so",
      "offset": 4151.839,
      "duration": 7.121
    },
    {
      "lang": "en",
      "text": "I'm I'm excited to to to to burst my my",
      "offset": 4155.6,
      "duration": 7.44
    },
    {
      "lang": "en",
      "text": "podcast bubble um and yeah follow me on",
      "offset": 4158.96,
      "duration": 6.239
    },
    {
      "lang": "en",
      "text": "LinkedIn but hit me up on GitHub i'm",
      "offset": 4163.04,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "actually super active on GitHub so there",
      "offset": 4165.199,
      "duration": 5.841
    },
    {
      "lang": "en",
      "text": "I forgot to mention this on um so for",
      "offset": 4167.92,
      "duration": 6.64
    },
    {
      "lang": "en",
      "text": "build on Tranium uh we just wrapped a",
      "offset": 4171.04,
      "duration": 7.239
    },
    {
      "lang": "en",
      "text": "competition actually so we are offering",
      "offset": 4174.56,
      "duration": 7.36
    },
    {
      "lang": "en",
      "text": "$25,000 uh in cash to the top team who",
      "offset": 4178.279,
      "duration": 6.44
    },
    {
      "lang": "en",
      "text": "can develop the fastest Nikki Llama the",
      "offset": 4181.92,
      "duration": 6.319
    },
    {
      "lang": "en",
      "text": "fastest llama implementation using Nikki",
      "offset": 4184.719,
      "duration": 6.241
    },
    {
      "lang": "en",
      "text": "actually so the competition is over um",
      "offset": 4188.239,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "but I am totally expecting projects like",
      "offset": 4190.96,
      "duration": 6.96
    },
    {
      "lang": "en",
      "text": "this to pop up again uh so definitely",
      "offset": 4194.239,
      "duration": 7.361
    },
    {
      "lang": "en",
      "text": "stay tuned for more um but yeah I'm",
      "offset": 4197.92,
      "duration": 6.319
    },
    {
      "lang": "en",
      "text": "really active on GitHub um when you're",
      "offset": 4201.6,
      "duration": 5.119
    },
    {
      "lang": "en",
      "text": "you know cutting issues in the Neuron",
      "offset": 4204.239,
      "duration": 5.281
    },
    {
      "lang": "en",
      "text": "SDK or the Nikki SDK like feel free to",
      "offset": 4206.719,
      "duration": 6.561
    },
    {
      "lang": "en",
      "text": "tag me i will respond um you know shoot",
      "offset": 4209.52,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "me your kernels i'd love to see the work",
      "offset": 4213.28,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "that people have and uh yeah let's let's",
      "offset": 4215.28,
      "duration": 7.12
    },
    {
      "lang": "en",
      "text": "go build in the words of Verogals and a",
      "offset": 4219.04,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "reminder there we talked about Nikki",
      "offset": 4222.4,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "earlier in the episode but it's NKI",
      "offset": 4223.84,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "neuron kernel interface and I'll have a",
      "offset": 4226,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "link to that in the show notes too",
      "offset": 4228.64,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "beautiful thank you John nice thank you",
      "offset": 4230.88,
      "duration": 3.359
    },
    {
      "lang": "en",
      "text": "Emily for taking the time i'm so",
      "offset": 4232.719,
      "duration": 3.121
    },
    {
      "lang": "en",
      "text": "delighted to have had you uh on your",
      "offset": 4234.239,
      "duration": 3.401
    },
    {
      "lang": "en",
      "text": "first podcast appearance you are a",
      "offset": 4235.84,
      "duration": 4.879
    },
    {
      "lang": "en",
      "text": "natural and every podcast should have",
      "offset": 4237.64,
      "duration": 5.16
    },
    {
      "lang": "en",
      "text": "you on i don't even care if they're in",
      "offset": 4240.719,
      "duration": 4.721
    },
    {
      "lang": "en",
      "text": "data science or not to explain something",
      "offset": 4242.8,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "wonderful about the world thank you",
      "offset": 4245.44,
      "duration": 6.44
    },
    {
      "lang": "en",
      "text": "Emily thank you Jen",
      "offset": 4247.04,
      "duration": 4.84
    },
    {
      "lang": "en",
      "text": "what a sensationally interesting episode",
      "offset": 4253.92,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "with Emily Weber in it she covered how",
      "offset": 4255.679,
      "duration": 3.761
    },
    {
      "lang": "en",
      "text": "her background in meditation and",
      "offset": 4257.84,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "Buddhist practice provided mental tools",
      "offset": 4259.44,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "that helped her excel in computer",
      "offset": 4261.52,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "science by developing focus and calm",
      "offset": 4263.12,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "problems solving abilities she talked",
      "offset": 4265.28,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "about the Nitro system developed by",
      "offset": 4267.44,
      "duration": 3.279
    },
    {
      "lang": "en",
      "text": "Anaporna Labs that was acquired by",
      "offset": 4269.04,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "Amazon in 2015 that physically separates",
      "offset": 4270.719,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "data and instance control in cloud",
      "offset": 4273.84,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "infrastructure creating better security",
      "offset": 4275.679,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "and scalability she talked about how the",
      "offset": 4277.6,
      "duration": 5.599
    },
    {
      "lang": "en",
      "text": "build on trainium program is AWS's $110",
      "offset": 4279.76,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "million investment program providing",
      "offset": 4283.199,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "cloud credits to academic researchers",
      "offset": 4285.52,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "working on cutting edge AI at",
      "offset": 4287.199,
      "duration": 3.761
    },
    {
      "lang": "en",
      "text": "institutions like Berkeley Carnegie",
      "offset": 4288.64,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "Melon UT Austin and Oxford she talked",
      "offset": 4290.96,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "about how Tranium 2 offers four times",
      "offset": 4293.92,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "the compute power of tranium 1 with",
      "offset": 4296.08,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "eight neuron cores per card instead of",
      "offset": 4298.239,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "two and 1.5 whopping terabytes of high",
      "offset": 4300.08,
      "duration": 6.079
    },
    {
      "lang": "en",
      "text": "bandwidth memory capacity per instance",
      "offset": 4303.679,
      "duration": 4.881
    },
    {
      "lang": "en",
      "text": "she talked about the AWS Neuron SDK that",
      "offset": 4306.159,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "helps developers easily optimize and",
      "offset": 4308.56,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "deploy models on tranium and inferential",
      "offset": 4310.719,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "chips through tools like NXD which",
      "offset": 4312.64,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "handles model sharding across",
      "offset": 4314.64,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "accelerators and she talked about",
      "offset": 4316,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "hardware design decisions like TP tensor",
      "offset": 4317.84,
      "duration": 4.879
    },
    {
      "lang": "en",
      "text": "parallelism degrees that significantly",
      "offset": 4320.32,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "impact model training and inference",
      "offset": 4322.719,
      "duration": 3.361
    },
    {
      "lang": "en",
      "text": "efficiency requiring careful",
      "offset": 4324.4,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "optimization for specific workloads as",
      "offset": 4326.08,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "always you can get all the show notes",
      "offset": 4328.8,
      "duration": 2.64
    },
    {
      "lang": "en",
      "text": "including the transcript for this",
      "offset": 4330.239,
      "duration": 2.881
    },
    {
      "lang": "en",
      "text": "episode the video recording any",
      "offset": 4331.44,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "materials mentioned on the show the URLs",
      "offset": 4333.12,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "for Emily's social media profiles as",
      "offset": 4335.44,
      "duration": 5.279
    },
    {
      "lang": "en",
      "text": "well as my own at",
      "offset": 4337.6,
      "duration": 3.119
    },
    {
      "lang": "en",
      "text": "superdatcience.com/881 and if you'd like",
      "offset": 4341,
      "duration": 3.64
    },
    {
      "lang": "en",
      "text": "to engage with me in person as opposed",
      "offset": 4342.8,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "to just through social media I'd love to",
      "offset": 4344.64,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "meet you in real life at the Open Data",
      "offset": 4346.32,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "Science Conference ODSC East running",
      "offset": 4348.56,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "from May 13th to 15th in Boston i'll be",
      "offset": 4350.239,
      "duration": 4.641
    },
    {
      "lang": "en",
      "text": "hosting the keynote sessions and along",
      "offset": 4352.88,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "with my longtime friend and colleague",
      "offset": 4354.88,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "the extraordinary Ed Donner I'll be",
      "offset": 4357.199,
      "duration": 4.641
    },
    {
      "lang": "en",
      "text": "delivering a 4-hour hands-on training in",
      "offset": 4359.76,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "Python to demonstrate how you can design",
      "offset": 4361.84,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "train and deploy cutting edge multi-",
      "offset": 4364.08,
      "duration": 5.24
    },
    {
      "lang": "en",
      "text": "aent AI systems for real life",
      "offset": 4366.08,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "applications um yeah and we could also",
      "offset": 4369.32,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "just meet for a beer or whatever",
      "offset": 4371.76,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "there um thanks of course to everyone on",
      "offset": 4373.56,
      "duration": 4.84
    },
    {
      "lang": "en",
      "text": "the Super Data Science podcast team our",
      "offset": 4376.8,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "podcast manager Sonia Breovich media",
      "offset": 4378.4,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "editor Mario Pombo partnerships manager",
      "offset": 4380.32,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "Natalie Jyski researcher Serge Miss",
      "offset": 4382.4,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "writer Dr zara Carce and our founder Kir",
      "offset": 4384.88,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "Aramco thanks to all of them for",
      "offset": 4388,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "producing another fabulous episode for",
      "offset": 4389.92,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "us today for enabling that super team to",
      "offset": 4392.08,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "create this free podcast for you we are",
      "offset": 4394.4,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "deeply grateful to our sponsors you can",
      "offset": 4396.64,
      "duration": 3.519
    },
    {
      "lang": "en",
      "text": "support this show by checking out our",
      "offset": 4398.32,
      "duration": 3.359
    },
    {
      "lang": "en",
      "text": "sponsors links which are in the show",
      "offset": 4400.159,
      "duration": 3.361
    },
    {
      "lang": "en",
      "text": "notes and if you yourself are interested",
      "offset": 4401.679,
      "duration": 3.361
    },
    {
      "lang": "en",
      "text": "in sponsoring an episode you can get the",
      "offset": 4403.52,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "details on how by heading to",
      "offset": 4405.04,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "johncone.com/mpodcast all right uh share",
      "offset": 4410.12,
      "duration": 5.32
    },
    {
      "lang": "en",
      "text": "this episode with people who might like",
      "offset": 4412.48,
      "duration": 4.719
    },
    {
      "lang": "en",
      "text": "to have it shared with them review the",
      "offset": 4415.44,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "episode on your favorite podcasting app",
      "offset": 4417.199,
      "duration": 4.641
    },
    {
      "lang": "en",
      "text": "i think that helps us uh get the word",
      "offset": 4419.76,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "out about our show subscribe if you're",
      "offset": 4421.84,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "not a subscriber feel free to edit our",
      "offset": 4424.64,
      "duration": 4.559
    },
    {
      "lang": "en",
      "text": "videos into shorts or whatever you like",
      "offset": 4426.96,
      "duration": 5
    },
    {
      "lang": "en",
      "text": "just refer to us but most",
      "offset": 4429.199,
      "duration": 5.361
    },
    {
      "lang": "en",
      "text": "importantly just keep on tuning in i'm",
      "offset": 4431.96,
      "duration": 4.199
    },
    {
      "lang": "en",
      "text": "so grateful to have you listening and",
      "offset": 4434.56,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "hope I can continue to make episodes you",
      "offset": 4436.159,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "love for years and years to come till",
      "offset": 4437.92,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "next time keep on rocking it out there",
      "offset": 4439.84,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "and I'm looking forward to enjoying",
      "offset": 4442,
      "duration": 2.48
    },
    {
      "lang": "en",
      "text": "another round of the Super Data Science",
      "offset": 4443.12,
      "duration": 5.88
    },
    {
      "lang": "en",
      "text": "podcast with you very soon",
      "offset": 4444.48,
      "duration": 4.52
    }
  ],
  "cleanText": null,
  "dumpedAt": "2025-07-21T18:43:25.975Z"
}