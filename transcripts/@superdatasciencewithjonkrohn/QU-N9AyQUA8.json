{
  "episodeId": "QU-N9AyQUA8",
  "channelSlug": "@superdatasciencewithjonkrohn",
  "title": "905: Why RAG Makes LLMs Less Safe (And How to Fix It), with Bloomberg’s Dr. Sebastian Gehrmann",
  "publishedAt": "2025-07-15T11:00:58.000Z",
  "rawLines": [
    {
      "lang": "en",
      "text": "How can we move forward with all the",
      "offset": 0.24,
      "duration": 2.8
    },
    {
      "lang": "en",
      "text": "information that you provided in this",
      "offset": 1.76,
      "duration": 3.599
    },
    {
      "lang": "en",
      "text": "episode in selecting an LLM for a",
      "offset": 3.04,
      "duration": 3.279
    },
    {
      "lang": "en",
      "text": "particular use case?",
      "offset": 5.359,
      "duration": 2.641
    },
    {
      "lang": "en",
      "text": "Evaluate the system in the context that",
      "offset": 6.319,
      "duration": 3.441
    },
    {
      "lang": "en",
      "text": "it's deployed in. You're going to have a",
      "offset": 8,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "system that is in the end much more",
      "offset": 9.76,
      "duration": 4.879
    },
    {
      "lang": "en",
      "text": "trustworthy, reliable, robust, and",
      "offset": 11.36,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "you're going to have users that are",
      "offset": 14.639,
      "duration": 3.041
    },
    {
      "lang": "en",
      "text": "going to keep using it rather than",
      "offset": 16.16,
      "duration": 4.879
    },
    {
      "lang": "en",
      "text": "trying it twice, getting uh really bad",
      "offset": 17.68,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "answers both times and never touching it",
      "offset": 21.039,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "again. Rag is incredibly powerful.",
      "offset": 22.64,
      "duration": 4.479
    },
    {
      "lang": "en",
      "text": "There's a lot of investment from from",
      "offset": 24.88,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "companies that build up language models",
      "offset": 27.119,
      "duration": 3.281
    },
    {
      "lang": "en",
      "text": "into increasing the possible context",
      "offset": 28.64,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "length. But at the same time, increasing",
      "offset": 30.4,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "the possible context length also",
      "offset": 33.12,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "requires developing methods and",
      "offset": 34.8,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "developing the models to actually be",
      "offset": 37.6,
      "duration": 5.31
    },
    {
      "lang": "en",
      "text": "able to handle such a context length.",
      "offset": 38.879,
      "duration": 6.161
    },
    {
      "lang": "en",
      "text": "[Music]",
      "offset": 42.91,
      "duration": 3.89
    },
    {
      "lang": "en",
      "text": "Sebastian, welcome to the Super Data",
      "offset": 45.04,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "Science podcast. It's great to have you",
      "offset": 46.8,
      "duration": 2.4
    },
    {
      "lang": "en",
      "text": "on the show. Where are you calling in",
      "offset": 48.16,
      "duration": 1.919
    },
    {
      "lang": "en",
      "text": "from today?",
      "offset": 49.2,
      "duration": 2.32
    },
    {
      "lang": "en",
      "text": "Thank you so much for having me. I'm",
      "offset": 50.079,
      "duration": 3.201
    },
    {
      "lang": "en",
      "text": "calling in from Philadelphia.",
      "offset": 51.52,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "Nice. Uh, it's going to be a scorcher",
      "offset": 53.28,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "here in New York coming up at the time",
      "offset": 55.68,
      "duration": 3.519
    },
    {
      "lang": "en",
      "text": "of recording. Heading up to 100°",
      "offset": 57.44,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "Fahrenheit. I hope uh you're able to",
      "offset": 59.199,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "stay cool down there.",
      "offset": 61.76,
      "duration": 2.719
    },
    {
      "lang": "en",
      "text": "Yeah. Not too much different here. We",
      "offset": 62.8,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "all got the heat warning yesterday",
      "offset": 64.479,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "evening and it's going to be a rough",
      "offset": 66.32,
      "duration": 2.64
    },
    {
      "lang": "en",
      "text": "couple days.",
      "offset": 68.159,
      "duration": 2.161
    },
    {
      "lang": "en",
      "text": "Yeah. Yeah. Yeah. We'll test the air",
      "offset": 68.96,
      "duration": 2.56
    },
    {
      "lang": "en",
      "text": "conditioning systems for the first time",
      "offset": 70.32,
      "duration": 1.92
    },
    {
      "lang": "en",
      "text": "this year",
      "offset": 71.52,
      "duration": 1.599
    },
    {
      "lang": "en",
      "text": "for sure.",
      "offset": 72.24,
      "duration": 2.48
    },
    {
      "lang": "en",
      "text": "All right. So, you are the head of",
      "offset": 73.119,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "responsible AI at Bloomberg, uh, a",
      "offset": 74.72,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "hugely well-known financial software,",
      "offset": 78.159,
      "duration": 5.041
    },
    {
      "lang": "en",
      "text": "data, and media company. Long before you",
      "offset": 80.72,
      "duration": 3.759
    },
    {
      "lang": "en",
      "text": "started at Bloomberg, you were",
      "offset": 83.2,
      "duration": 3.279
    },
    {
      "lang": "en",
      "text": "researching at the intersection of",
      "offset": 84.479,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "natural language generation and",
      "offset": 86.479,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "responsible AI solutions that are",
      "offset": 88.56,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "trustworthy, transparent, reliable. And",
      "offset": 90.479,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "now you've kind of brought all those",
      "offset": 93.6,
      "duration": 2.879
    },
    {
      "lang": "en",
      "text": "things together with your latest paper,",
      "offset": 94.88,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "which of course we'll link to in the",
      "offset": 96.479,
      "duration": 4.801
    },
    {
      "lang": "en",
      "text": "show notes. It's called Rag LMS are not",
      "offset": 98,
      "duration": 6.079
    },
    {
      "lang": "en",
      "text": "safer. Um it's a safety analysis of",
      "offset": 101.28,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "retrieval augmented generation for large",
      "offset": 104.079,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "language models. And this finds",
      "offset": 106,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "counterintuitively, and this is the main",
      "offset": 108.159,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "reason why I wanted to have you on the",
      "offset": 110.159,
      "duration": 4.881
    },
    {
      "lang": "en",
      "text": "show, is because it blew my mind when I",
      "offset": 112.32,
      "duration": 6.079
    },
    {
      "lang": "en",
      "text": "discovered that rag actually makes LLMs",
      "offset": 115.04,
      "duration": 5.119
    },
    {
      "lang": "en",
      "text": "less safe and their outputs less",
      "offset": 118.399,
      "duration": 5.441
    },
    {
      "lang": "en",
      "text": "reliable because my understanding is",
      "offset": 120.159,
      "duration": 5.121
    },
    {
      "lang": "en",
      "text": "that it was supposed to be exactly the",
      "offset": 123.84,
      "duration": 2
    },
    {
      "lang": "en",
      "text": "opposite.",
      "offset": 125.28,
      "duration": 2.88
    },
    {
      "lang": "en",
      "text": "Yeah, abs. Absolutely. Um yeah I should",
      "offset": 125.84,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "I should mention this this was a paper",
      "offset": 128.16,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "that uh we had an intern work on last",
      "offset": 130.08,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "year who's been working with colleagues",
      "offset": 132.4,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "from our co's office and AI engineering",
      "offset": 133.76,
      "duration": 5.199
    },
    {
      "lang": "en",
      "text": "organization and uh this was part of our",
      "offset": 135.92,
      "duration": 5.92
    },
    {
      "lang": "en",
      "text": "broader responsible AI research uh theme",
      "offset": 138.959,
      "duration": 5.681
    },
    {
      "lang": "en",
      "text": "that we have going where we want to make",
      "offset": 141.84,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "sure that if our clients or our",
      "offset": 144.64,
      "duration": 6.8
    },
    {
      "lang": "en",
      "text": "customers use our AI that if they use it",
      "offset": 147.12,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "for something that they shouldn't that",
      "offset": 151.44,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "we can identify this we can block this",
      "offset": 153.12,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "we can monitor this over time which is",
      "offset": 155.04,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "incredibly important especially for a",
      "offset": 157.2,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "such heavily regulated industry such as",
      "offset": 159.68,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "the one that we are operating in. There",
      "offset": 162.72,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "are so many rules that apply to our",
      "offset": 164.56,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "clients. They really want to make sure",
      "offset": 166.16,
      "duration": 5.439
    },
    {
      "lang": "en",
      "text": "that people can't abuse purposefully or",
      "offset": 168,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "completely accidentally our our",
      "offset": 171.599,
      "duration": 5.841
    },
    {
      "lang": "en",
      "text": "technology. So as part of that research",
      "offset": 173.12,
      "duration": 6.64
    },
    {
      "lang": "en",
      "text": "direction we were interested in the",
      "offset": 177.44,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "safety of rag because in the end rag is",
      "offset": 179.76,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "such a ubiquitous technology and it is",
      "offset": 182.8,
      "duration": 4.799
    },
    {
      "lang": "en",
      "text": "not it is absolutely necessary to ground",
      "offset": 184.72,
      "duration": 5.439
    },
    {
      "lang": "en",
      "text": "responses in trusted sources of data",
      "offset": 187.599,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "that is there's no way around that if",
      "offset": 190.159,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "you want to answer questions that are",
      "offset": 192.239,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "grounded in in this broad and and uh",
      "offset": 194.159,
      "duration": 6.481
    },
    {
      "lang": "en",
      "text": "really challenging uh area that we",
      "offset": 198.239,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "operate in where there's hundreds of",
      "offset": 200.64,
      "duration": 3.599
    },
    {
      "lang": "en",
      "text": "billions of of pieces of data coming",
      "offset": 202.4,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "into our systems every single day. The",
      "offset": 204.239,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "only way to do this is if you use rag or",
      "offset": 206.319,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "some kind of other similar retrieval",
      "offset": 208.64,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "augmented technology or document",
      "offset": 210.48,
      "duration": 6.399
    },
    {
      "lang": "en",
      "text": "grounded technology. So what our paper",
      "offset": 213.12,
      "duration": 7.679
    },
    {
      "lang": "en",
      "text": "did was it coupled unsafe queries. So",
      "offset": 216.879,
      "duration": 5.601
    },
    {
      "lang": "en",
      "text": "think think of the the worst thing that",
      "offset": 220.799,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "you might want to ask a large language",
      "offset": 222.48,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "model, right? How do I do insider",
      "offset": 224.319,
      "duration": 5.84
    },
    {
      "lang": "en",
      "text": "trading? And we coupled that with with",
      "offset": 226.879,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "rag. So we retrieved completely",
      "offset": 230.159,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "innocuous u documents from Wikipedia",
      "offset": 232.319,
      "duration": 6.161
    },
    {
      "lang": "en",
      "text": "and while most large language models",
      "offset": 236.159,
      "duration": 5.601
    },
    {
      "lang": "en",
      "text": "that we looked at didn't respond to",
      "offset": 238.48,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "their original question when coupled",
      "offset": 241.76,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "with these completely harmless documents",
      "offset": 244.08,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "from Wikipedia the response was often",
      "offset": 246.159,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "then unsafe which is why we gave the",
      "offset": 249.12,
      "duration": 5.199
    },
    {
      "lang": "en",
      "text": "paper this this title that was very very",
      "offset": 251.599,
      "duration": 5.681
    },
    {
      "lang": "en",
      "text": "strong because everyone would has been",
      "offset": 254.319,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "talking about how rag makes things more",
      "offset": 257.28,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "safe they're more grounded they grounded",
      "offset": 258.959,
      "duration": 4.561
    },
    {
      "lang": "en",
      "text": "in actual factual information uh rather",
      "offset": 260.88,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "than using the large language model to",
      "offset": 263.52,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "kind of make up things. And what we",
      "offset": 265.12,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "found is that actually your rack can",
      "offset": 267.36,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "circumvent these built-in safety",
      "offset": 269.28,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "mechanisms that that large language",
      "offset": 271.04,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "model providers put into these models.",
      "offset": 273.199,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "I gotcha. I got you. Now I understand.",
      "offset": 275.199,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "And I guess we should also it occurs to",
      "offset": 277.199,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "me as we're talking about rag and",
      "offset": 278.88,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "probably a lot of listeners out there",
      "offset": 280.88,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "are aware of what retrieval augmented",
      "offset": 282.56,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "generation is, but maybe we should spend",
      "offset": 284.8,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "just a couple of minutes explaining it",
      "offset": 286.72,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "as well. Uh I don't know you can you can",
      "offset": 288.56,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "probably do a better job with this but",
      "offset": 290.88,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "at a high level it's it's you already",
      "offset": 292.479,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "kind of gave an example there where you",
      "offset": 295.04,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "can be using documents from Wikipedia",
      "offset": 296.4,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "the public internet or it could be you",
      "offset": 299.04,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "know a common use case with rag is to",
      "offset": 301.68,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "have lots of documents internal",
      "offset": 303.68,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "documents. So you might be a law firm",
      "offset": 305.04,
      "duration": 6.08
    },
    {
      "lang": "en",
      "text": "with millions of contracts that uh that",
      "offset": 308,
      "duration": 5.759
    },
    {
      "lang": "en",
      "text": "your firm has saved from over the years",
      "offset": 311.12,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "and you could put all of those millions",
      "offset": 313.759,
      "duration": 6.241
    },
    {
      "lang": "en",
      "text": "of contracts into a into a rag type of",
      "offset": 316,
      "duration": 6.56
    },
    {
      "lang": "en",
      "text": "system and you can search you can use",
      "offset": 320,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "natural language to query over all of",
      "offset": 322.56,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "those millions of documents. the most",
      "offset": 325.44,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "relevant ones will be pulled out from",
      "offset": 327.6,
      "duration": 6.159
    },
    {
      "lang": "en",
      "text": "the millions. And then you can you could",
      "offset": 330.08,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "typically fit that small number of",
      "offset": 333.759,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "documents that's pulled out, maybe it's",
      "offset": 336.08,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "half a dozen or a dozen into the working",
      "offset": 337.36,
      "duration": 5.279
    },
    {
      "lang": "en",
      "text": "memory of a given large language model",
      "offset": 339.84,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "and then you can have a natural language",
      "offset": 342.639,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "response uh come out as a result of",
      "offset": 344.08,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "that. What do you think about my rag",
      "offset": 346.32,
      "duration": 2.319
    },
    {
      "lang": "en",
      "text": "explanation there?",
      "offset": 347.68,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "Absolutely correct. I think just just to",
      "offset": 348.639,
      "duration": 4.481
    },
    {
      "lang": "en",
      "text": "put some more color on this um if we're",
      "offset": 350.72,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "talking about leage model very much this",
      "offset": 353.12,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "is a technology where at one point in",
      "offset": 355.039,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "time you train a model and then once",
      "offset": 356.8,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "you're done training this model it is",
      "offset": 358.72,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "stuck you freeze the model and you say",
      "offset": 360.639,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "okay this is the model the knowledge cut",
      "offset": 362.4,
      "duration": 6.639
    },
    {
      "lang": "en",
      "text": "off is January 2021 and then if you ask",
      "offset": 364.639,
      "duration": 6.4
    },
    {
      "lang": "en",
      "text": "a question that requires knowledge from",
      "offset": 369.039,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "beyond 2021 the only way that you can",
      "offset": 371.039,
      "duration": 4.481
    },
    {
      "lang": "en",
      "text": "get this into the model is by actually",
      "offset": 373.759,
      "duration": 5.201
    },
    {
      "lang": "en",
      "text": "providing it in its context. So um",
      "offset": 375.52,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "researchers a couple years ago when they",
      "offset": 378.96,
      "duration": 4.239
    },
    {
      "lang": "en",
      "text": "developed this rack technique uh for",
      "offset": 380.72,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "large language models in particular said",
      "offset": 383.199,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "well the most natural thing to do is to",
      "offset": 384.96,
      "duration": 6.079
    },
    {
      "lang": "en",
      "text": "to couple a search system with the large",
      "offset": 387.759,
      "duration": 4.801
    },
    {
      "lang": "en",
      "text": "language model language model very good",
      "offset": 391.039,
      "duration": 4.241
    },
    {
      "lang": "en",
      "text": "at synthesizing summarizing extracting",
      "offset": 392.56,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "information but this kind of freeze in",
      "offset": 395.28,
      "duration": 5.359
    },
    {
      "lang": "en",
      "text": "time is really bad. um to overcome it we",
      "offset": 397.36,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "plug in a search tool and that's why",
      "offset": 400.639,
      "duration": 3.761
    },
    {
      "lang": "en",
      "text": "it's called retrieval augmented",
      "offset": 403.12,
      "duration": 5.359
    },
    {
      "lang": "en",
      "text": "generation or before rag was was a paper",
      "offset": 404.4,
      "duration": 6.48
    },
    {
      "lang": "en",
      "text": "a lot of search engines already gave",
      "offset": 408.479,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "answer snippets and so at that point it",
      "offset": 410.88,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "was kind of search enhanced question",
      "offset": 412.8,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "answering but they all kind of this have",
      "offset": 414.24,
      "duration": 6.239
    },
    {
      "lang": "en",
      "text": "become this overall term that we that we",
      "offset": 417.6,
      "duration": 4.879
    },
    {
      "lang": "en",
      "text": "use for not just this vanilla setup",
      "offset": 420.479,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "where we have a retrieval step and a",
      "offset": 422.479,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "generation step often we we use rag as",
      "offset": 424.639,
      "duration": 5.761
    },
    {
      "lang": "en",
      "text": "kind of the overarching term for",
      "offset": 427.919,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "anything where you ground a large",
      "offset": 430.4,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "language model response with some kind",
      "offset": 432.24,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "of data that you retrieve from",
      "offset": 434.319,
      "duration": 2.641
    },
    {
      "lang": "en",
      "text": "somewhere. That could be structured",
      "offset": 435.84,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "data, it could be unstructured data, it",
      "offset": 436.96,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "could be unstructured or structured data",
      "offset": 438.96,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "from multiple different sources. All of",
      "offset": 441.039,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "these are kind of under this whole",
      "offset": 443.039,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "umbrella term of of retrieval augmented",
      "offset": 445.12,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "generation, which is why this has become",
      "offset": 447.36,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "such a big topic to talk about because",
      "offset": 448.88,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "this is one of the predominant ways in",
      "offset": 450.72,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "which applications are built.",
      "offset": 453.28,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "For sure. And I I like how you're using",
      "offset": 455.12,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "this term grounding. I think that that",
      "offset": 456.56,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "makes a lot of sense. Um, another term",
      "offset": 458.24,
      "duration": 4.959
    },
    {
      "lang": "en",
      "text": "that you've used in a recent podcast,",
      "offset": 460.56,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "um, you were emphasizing that rag is",
      "offset": 463.199,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "essential for grounding Genha products,",
      "offset": 465.68,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "um, in actual trusted information.",
      "offset": 468.319,
      "duration": 4.641
    },
    {
      "lang": "en",
      "text": "However, um, you've described REGG's",
      "offset": 470.16,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "architecture as creating unpredictable",
      "offset": 472.96,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "attack surfaces. So, that's kind of the",
      "offset": 475.36,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "other term that I want to get into here,",
      "offset": 477.28,
      "duration": 2.96
    },
    {
      "lang": "en",
      "text": "this idea of attack services. So on the",
      "offset": 478.72,
      "duration": 3.759
    },
    {
      "lang": "en",
      "text": "one hand, you know, we need rag for",
      "offset": 480.24,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "grounding Genai products in more recent",
      "offset": 482.479,
      "duration": 4.961
    },
    {
      "lang": "en",
      "text": "or in actual trusted information or",
      "offset": 485.68,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "maybe in confidential information that",
      "offset": 487.44,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "an enterprise or an organization has. Um",
      "offset": 488.96,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "but at the same time, this creates these",
      "offset": 491.52,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "unpredictable attack surfaces. So what",
      "offset": 493.84,
      "duration": 5.199
    },
    {
      "lang": "en",
      "text": "the heck are attack surfaces? Yes. So",
      "offset": 496,
      "duration": 5.039
    },
    {
      "lang": "en",
      "text": "for that, let's let's kind of explore",
      "offset": 499.039,
      "duration": 4.481
    },
    {
      "lang": "en",
      "text": "what what we mean by attack surface.",
      "offset": 501.039,
      "duration": 4.241
    },
    {
      "lang": "en",
      "text": "Obviously, if we if we think about",
      "offset": 503.52,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "something like cyber security, attack",
      "offset": 505.28,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "surfaces are everywhere where you have",
      "offset": 506.8,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "unsecured endpoints or you have code",
      "offset": 508.56,
      "duration": 3.599
    },
    {
      "lang": "en",
      "text": "that you can kind of inject into. You",
      "offset": 510.16,
      "duration": 4.239
    },
    {
      "lang": "en",
      "text": "have uh databases that are just out in",
      "offset": 512.159,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "the open. Language models are are very",
      "offset": 514.399,
      "duration": 5.041
    },
    {
      "lang": "en",
      "text": "different because they unless you give",
      "offset": 517.039,
      "duration": 4.721
    },
    {
      "lang": "en",
      "text": "them the information, they they don't",
      "offset": 519.44,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "have that kind of attack surface. But",
      "offset": 521.76,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "there are other attack surfaces or",
      "offset": 524.24,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "risks. Specifically, what we call them",
      "offset": 526.72,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "are typically content risks where either",
      "offset": 529.36,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "inputs to the light language model can",
      "offset": 532.32,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "be uh um asking for very harmful output",
      "offset": 533.92,
      "duration": 5.84
    },
    {
      "lang": "en",
      "text": "or the output itself could could lead to",
      "offset": 537.04,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "something that is harmful or against the",
      "offset": 539.76,
      "duration": 5.199
    },
    {
      "lang": "en",
      "text": "established regulation, rules, laws. Um",
      "offset": 541.36,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "so this attack surface very much is",
      "offset": 544.959,
      "duration": 4.241
    },
    {
      "lang": "en",
      "text": "grounded in the way that you want to use",
      "offset": 547.36,
      "duration": 3.599
    },
    {
      "lang": "en",
      "text": "this language model or this application",
      "offset": 549.2,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "that you're building. So take us for",
      "offset": 550.959,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "example, we're a financial services",
      "offset": 553.519,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "company. Our",
      "offset": 555.279,
      "duration": 5.441
    },
    {
      "lang": "en",
      "text": "content is very much focused on helping",
      "offset": 557.6,
      "duration": 6.08
    },
    {
      "lang": "en",
      "text": "people conduct analyses in the financial",
      "offset": 560.72,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "space, synthesize information, summarize",
      "offset": 563.68,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "information, uh ground all of this and",
      "offset": 566,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "attribute all of this to our just in",
      "offset": 568.32,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "time data that that we have on our",
      "offset": 570.24,
      "duration": 5.039
    },
    {
      "lang": "en",
      "text": "Bloomberg terminal. So for us, the",
      "offset": 572.72,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "attack surface is very much linked to",
      "offset": 575.279,
      "duration": 4.881
    },
    {
      "lang": "en",
      "text": "the domain that we operate in. So what",
      "offset": 577.76,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "we care about are things like can",
      "offset": 580.16,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "someone uh do financial conduct um can",
      "offset": 582,
      "duration": 7.6
    },
    {
      "lang": "en",
      "text": "someone conduct uh financial crimes with",
      "offset": 586.16,
      "duration": 5.359
    },
    {
      "lang": "en",
      "text": "the help of light language models? Can",
      "offset": 589.6,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "it facilitate insider trading? Does it",
      "offset": 591.519,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "give unsolicited financial advice that",
      "offset": 593.6,
      "duration": 3.359
    },
    {
      "lang": "en",
      "text": "people might trade on and lose a lot of",
      "offset": 595.519,
      "duration": 4.241
    },
    {
      "lang": "en",
      "text": "money? Uh does it create an information",
      "offset": 596.959,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "imbalance or an asymmetry where it",
      "offset": 599.76,
      "duration": 3.759
    },
    {
      "lang": "en",
      "text": "discloses trading strategies from one",
      "offset": 601.519,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "company to the other?",
      "offset": 603.519,
      "duration": 4.641
    },
    {
      "lang": "en",
      "text": "uh but we are just one of many many",
      "offset": 605.6,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "examples of of people who use these life",
      "offset": 608.16,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "language models. So when we talk about",
      "offset": 610,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "an unanticipated attack surface, the",
      "offset": 612.48,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "people who build light language models,",
      "offset": 615.2,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "they can't enumerate every single way in",
      "offset": 616.64,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "which they are being applied. They're",
      "offset": 618.8,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "being applied to healthcare, they're",
      "offset": 621.04,
      "duration": 2.239
    },
    {
      "lang": "en",
      "text": "being applied to law, they're being",
      "offset": 622.16,
      "duration": 2.64
    },
    {
      "lang": "en",
      "text": "applied to education, they're being",
      "offset": 623.279,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "applied everywhere around the world now.",
      "offset": 624.8,
      "duration": 6.64
    },
    {
      "lang": "en",
      "text": "So on top of that, the jurisdictional",
      "offset": 627.68,
      "duration": 5.279
    },
    {
      "lang": "en",
      "text": "differences, the different geographic",
      "offset": 631.44,
      "duration": 2.8
    },
    {
      "lang": "en",
      "text": "locations, they might have different",
      "offset": 632.959,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "laws even applying. So now we have this",
      "offset": 634.24,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "whole web of applications that are built",
      "offset": 637.839,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "on top of large language models, but we",
      "offset": 640.24,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "only have one provider who says, \"Yeah,",
      "offset": 642.399,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "actually our model is safe.\" There's no",
      "offset": 644.079,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "way where that would be possible to",
      "offset": 646.8,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "really anticipate every single use case",
      "offset": 649.519,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "around the world grounded in all the",
      "offset": 651.92,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "relevant regulation. So all this coming",
      "offset": 653.839,
      "duration": 4.481
    },
    {
      "lang": "en",
      "text": "to the main point that we're really",
      "offset": 656.72,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "trying to uh keep making over and over,",
      "offset": 658.32,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "you need to really evaluate your AI",
      "offset": 660.64,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "application in the context you want to",
      "offset": 663.92,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "deploy them because in the end only the",
      "offset": 665.44,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "organization developing the application",
      "offset": 667.6,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "that you integrate uh the L language",
      "offset": 669.76,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "model in understands their risks.",
      "offset": 672,
      "duration": 5.519
    },
    {
      "lang": "en",
      "text": "So that is really why we're doing this",
      "offset": 675.36,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "kind of research. We want to understand",
      "offset": 677.519,
      "duration": 3.281
    },
    {
      "lang": "en",
      "text": "what are the risks that are specific to",
      "offset": 679.12,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "us and the way that we're building",
      "offset": 680.8,
      "duration": 3.599
    },
    {
      "lang": "en",
      "text": "applications and the clients that use",
      "offset": 682.32,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "our applications. Right? So when we talk",
      "offset": 684.399,
      "duration": 4.721
    },
    {
      "lang": "en",
      "text": "about unanticipated risk, this is very",
      "offset": 687.2,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "much it. We don't understand the risk",
      "offset": 689.12,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "unless we measure it. We uh the people",
      "offset": 690.88,
      "duration": 4.639
    },
    {
      "lang": "en",
      "text": "who build models, especially if we use",
      "offset": 693.44,
      "duration": 3.519
    },
    {
      "lang": "en",
      "text": "third party models, they don't",
      "offset": 695.519,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "understand our risks, right? So we need",
      "offset": 696.959,
      "duration": 4.961
    },
    {
      "lang": "en",
      "text": "to study this to really understand and",
      "offset": 699.44,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "instead of having an unmeasurable",
      "offset": 701.92,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "unanticipated risk surface we want to",
      "offset": 703.92,
      "duration": 3.359
    },
    {
      "lang": "en",
      "text": "have one where we very much understand",
      "offset": 705.76,
      "duration": 2.72
    },
    {
      "lang": "en",
      "text": "what are the risks and how do we",
      "offset": 707.279,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "mitigate them. So does that end up being",
      "offset": 708.48,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "the case that then you you end up having",
      "offset": 710.399,
      "duration": 5.521
    },
    {
      "lang": "en",
      "text": "this kind of list of risks and",
      "offset": 713.12,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "mitigations for your specific use case",
      "offset": 715.92,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "because it like so it sounds like",
      "offset": 718.72,
      "duration": 4.239
    },
    {
      "lang": "en",
      "text": "basically it's it's the user of a rag",
      "offset": 720.72,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "setup or the user of an LLM that has to",
      "offset": 722.959,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "be cautious in their particular",
      "offset": 725.44,
      "duration": 4.959
    },
    {
      "lang": "en",
      "text": "circumstance given that the LLM creator",
      "offset": 727.36,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "couldn't have anticipated like you said",
      "offset": 730.399,
      "duration": 3.761
    },
    {
      "lang": "en",
      "text": "all the possible use cases. Is that",
      "offset": 732.16,
      "duration": 2.479
    },
    {
      "lang": "en",
      "text": "right?",
      "offset": 734.16,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "Um slightly. So I what I mean really is",
      "offset": 734.639,
      "duration": 5.841
    },
    {
      "lang": "en",
      "text": "the people who build the rack system,",
      "offset": 738.48,
      "duration": 3.359
    },
    {
      "lang": "en",
      "text": "they usually know what they're building",
      "offset": 740.48,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "it for. They understand the data that",
      "offset": 741.839,
      "duration": 3.761
    },
    {
      "lang": "en",
      "text": "goes into the database or they should at",
      "offset": 743.76,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "least uh they understand how data is",
      "offset": 745.6,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "being retrieved and how it's all being",
      "offset": 748.24,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "put together. And then there are a",
      "offset": 750,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "couple sources of risks. Number one, you",
      "offset": 751.92,
      "duration": 4.479
    },
    {
      "lang": "en",
      "text": "have the data. If there is dangerous",
      "offset": 754.399,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "information in the data and write an",
      "offset": 756.399,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "instruction on how to shelter money in",
      "offset": 758.639,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "places that money shouldn't be sheltered",
      "offset": 760.639,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "and you ask the large language model,",
      "offset": 762.639,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "hey, give me information and it adds",
      "offset": 764.079,
      "duration": 5.041
    },
    {
      "lang": "en",
      "text": "that information in the context",
      "offset": 766.72,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "that that could be one vector of of",
      "offset": 769.12,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "getting harmful information out of the",
      "offset": 771.76,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "language model. But uh there is another",
      "offset": 773.44,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "vector in which the large language model",
      "offset": 776.16,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "itself could could be unsafe. It could",
      "offset": 777.76,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "be unsolicited.",
      "offset": 780.72,
      "duration": 4.799
    },
    {
      "lang": "en",
      "text": "Give that advice. But then the user is",
      "offset": 782.72,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "another attack vector. What if the user",
      "offset": 785.519,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "there types that in like how do I",
      "offset": 787.2,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "shelter money wherever? How do I commit",
      "offset": 789.12,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "tax fraud?",
      "offset": 792,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "Right? In this case, we can rely on on",
      "offset": 793.76,
      "duration": 3.759
    },
    {
      "lang": "en",
      "text": "the large language model to kind of",
      "offset": 796.24,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "block these kind of queries which really",
      "offset": 797.519,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "puts a lot of trust in this developer of",
      "offset": 799.92,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "the large language model that often",
      "offset": 801.92,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "there is a different entity from the",
      "offset": 803.6,
      "duration": 5.84
    },
    {
      "lang": "en",
      "text": "organization that builds the rack system",
      "offset": 807.04,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "or as the builder of the rack system. I",
      "offset": 809.44,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "can take a look at those three. I can",
      "offset": 812.72,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "look at okay, what are users typically",
      "offset": 814.72,
      "duration": 3.359
    },
    {
      "lang": "en",
      "text": "doing? What are attack vectors that",
      "offset": 816.48,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "users might be trying with our system?",
      "offset": 818.079,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "Uh what is what data is in the",
      "offset": 820.56,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "databases? How do I make sure that I",
      "offset": 822,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "understand this data and safeguard us",
      "offset": 824.8,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "from from exposing information to users",
      "offset": 827.2,
      "duration": 3.439
    },
    {
      "lang": "en",
      "text": "that shouldn't have access to this",
      "offset": 829.44,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "information? And how safe is the large",
      "offset": 830.639,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "language model really for our use cases?",
      "offset": 832.56,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "Our paper is very much in that third",
      "offset": 834.48,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "realm here because we wanted to know the",
      "offset": 836.959,
      "duration": 5.201
    },
    {
      "lang": "en",
      "text": "built-in defenses of the of the language",
      "offset": 840.24,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "model. How good are they actually and",
      "offset": 842.16,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "how well do they stand up to a rack",
      "offset": 844.8,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "setup? And in our case, we found that uh",
      "offset": 846.24,
      "duration": 7.839
    },
    {
      "lang": "en",
      "text": "we found that for the general purpose uh",
      "offset": 850.24,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "dangerous queries that we that we looked",
      "offset": 854.079,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "at actually rack safety breaks down",
      "offset": 855.76,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "because light language models really are",
      "offset": 859.199,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "only secured for non-RAG setups, which",
      "offset": 860.72,
      "duration": 6.479
    },
    {
      "lang": "en",
      "text": "means that we need to build guard rails",
      "offset": 864.399,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "around our applications that go beyond",
      "offset": 867.199,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "what the Language model builders are",
      "offset": 869.519,
      "duration": 5.601
    },
    {
      "lang": "en",
      "text": "actually providing to us.",
      "offset": 871.279,
      "duration": 5.841
    },
    {
      "lang": "en",
      "text": "This episode is sponsored by Adverity,",
      "offset": 875.12,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "an integrated data platform for",
      "offset": 877.12,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "connecting, managing, and using your",
      "offset": 878.72,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "data at scale. Imagine being able to ask",
      "offset": 880.32,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "your data a question just like you would",
      "offset": 882.56,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "a colleague and getting an answer",
      "offset": 884.399,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "instantly. No more digging through",
      "offset": 886,
      "duration": 3.519
    },
    {
      "lang": "en",
      "text": "dashboards, waiting on reports, or",
      "offset": 888,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "dealing with complex BI tools. Just the",
      "offset": 889.519,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "insights you need right when you need",
      "offset": 891.76,
      "duration": 3.759
    },
    {
      "lang": "en",
      "text": "them. With Adver's AI powered data",
      "offset": 893.44,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "conversations, marketers will finally",
      "offset": 895.519,
      "duration": 4.481
    },
    {
      "lang": "en",
      "text": "talk to their data in plain English. Get",
      "offset": 897.76,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "instant answers, make smarter decisions,",
      "offset": 900,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "collaborate more easily, and cut",
      "offset": 902.24,
      "duration": 3.599
    },
    {
      "lang": "en",
      "text": "reporting time in half. What questions",
      "offset": 903.839,
      "duration": 4.481
    },
    {
      "lang": "en",
      "text": "will you ask? To learn more, check out",
      "offset": 905.839,
      "duration": 3.521
    },
    {
      "lang": "en",
      "text": "the show notes or visit",
      "offset": 908.32,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "www.adverity.com.",
      "offset": 909.36,
      "duration": 4.719
    },
    {
      "lang": "en",
      "text": "That's advi",
      "offset": 912,
      "duration": 5.079
    },
    {
      "lang": "en",
      "text": "ty.com.",
      "offset": 914.079,
      "duration": 3
    },
    {
      "lang": "en",
      "text": "Nice. Okay. Yeah, that that all makes",
      "offset": 917.839,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "sense to me. Um, so a question that",
      "offset": 919.519,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "occurs to me as you're talking about",
      "offset": 922.079,
      "duration": 3.361
    },
    {
      "lang": "en",
      "text": "this. So, you know, when I originally",
      "offset": 923.44,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "heard about this paper and about, you",
      "offset": 925.44,
      "duration": 5.199
    },
    {
      "lang": "en",
      "text": "know, uh, LMS being less safe in rag",
      "offset": 928.24,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "situations, the thing that popped into",
      "offset": 930.639,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "my head, I guess, is I was thinking",
      "offset": 932.639,
      "duration": 6.32
    },
    {
      "lang": "en",
      "text": "about how it's my my understanding is",
      "offset": 935.519,
      "duration": 6.32
    },
    {
      "lang": "en",
      "text": "that hallucinations are much less likely",
      "offset": 938.959,
      "duration": 5.361
    },
    {
      "lang": "en",
      "text": "in a rag circumstance than outside of a",
      "offset": 941.839,
      "duration": 4.481
    },
    {
      "lang": "en",
      "text": "rank rag circumstance for an LLM. when",
      "offset": 944.32,
      "duration": 3.199
    },
    {
      "lang": "en",
      "text": "you have that, you know, to use that",
      "offset": 946.32,
      "duration": 2.319
    },
    {
      "lang": "en",
      "text": "word grounding again that you've been",
      "offset": 947.519,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "using, when you have that grounding, uh,",
      "offset": 948.639,
      "duration": 4.801
    },
    {
      "lang": "en",
      "text": "it it seems to to lead to fewer",
      "offset": 951.519,
      "duration": 4.641
    },
    {
      "lang": "en",
      "text": "hallucinations. So, I guess in my mind,",
      "offset": 953.44,
      "duration": 4.959
    },
    {
      "lang": "en",
      "text": "maybe I kind of and and so I'd also I'd",
      "offset": 956.16,
      "duration": 3.679
    },
    {
      "lang": "en",
      "text": "welcome your input on the hallucination",
      "offset": 958.399,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "point if if that is actually true. But I",
      "offset": 959.839,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "guess I kind of ended up conflating",
      "offset": 962.639,
      "duration": 3.041
    },
    {
      "lang": "en",
      "text": "those two things in my head and",
      "offset": 964.399,
      "duration": 3.281
    },
    {
      "lang": "en",
      "text": "thinking, okay, if it's hallucinating",
      "offset": 965.68,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "less often, then it's surely safer. But",
      "offset": 967.68,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "b but yeah and again you can you can cut",
      "offset": 970.56,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "into my my thoughts on the hallucination",
      "offset": 973.68,
      "duration": 6.159
    },
    {
      "lang": "en",
      "text": "in a second but um uh it but now it's",
      "offset": 975.92,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "it's becoming clear to me it's be it's",
      "offset": 979.839,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "becoming clear for me to understand how",
      "offset": 981.36,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "maybe even if hallucinations are are",
      "offset": 983.519,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "reduced the issue here is that the kinds",
      "offset": 985.199,
      "duration": 4.961
    },
    {
      "lang": "en",
      "text": "of safeguards that an LLM creator put in",
      "offset": 987.199,
      "duration": 6.241
    },
    {
      "lang": "en",
      "text": "say Meta put into some llama uh models",
      "offset": 990.16,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "that they release those those safeguards",
      "offset": 993.44,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "that are built in in a rag setup often",
      "offset": 995.44,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "break down",
      "offset": 997.92,
      "duration": 3.039
    },
    {
      "lang": "en",
      "text": "exactly what what you're saying that is",
      "offset": 998.8,
      "duration": 6.399
    },
    {
      "lang": "en",
      "text": "that is absolutely the case where we say",
      "offset": 1000.959,
      "duration": 7.761
    },
    {
      "lang": "en",
      "text": "look there are typically the three H's",
      "offset": 1005.199,
      "duration": 5.521
    },
    {
      "lang": "en",
      "text": "um they were first developed by by",
      "offset": 1008.72,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "anthropic um many companies are now",
      "offset": 1010.72,
      "duration": 5.84
    },
    {
      "lang": "en",
      "text": "adopting them u the application you're",
      "offset": 1012.88,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "building it should be helpful it should",
      "offset": 1016.56,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "be honest and it should be harmless",
      "offset": 1018.32,
      "duration": 6.479
    },
    {
      "lang": "en",
      "text": "and hallucination very much goes goes",
      "offset": 1021.44,
      "duration": 5.519
    },
    {
      "lang": "en",
      "text": "into this honesty bucket which often is",
      "offset": 1024.799,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "also then combined with the helpful",
      "offset": 1026.959,
      "duration": 2.96
    },
    {
      "lang": "en",
      "text": "because how can you be helpful if you're",
      "offset": 1028.559,
      "duration": 3.041
    },
    {
      "lang": "en",
      "text": "not honest.",
      "offset": 1029.919,
      "duration": 4.241
    },
    {
      "lang": "en",
      "text": "So that if we if we just focus on being",
      "offset": 1031.6,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "helpful and being being harmless,",
      "offset": 1034.16,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "everything that goes into hallucination",
      "offset": 1036.64,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "and the advantages rag brings to to",
      "offset": 1038.319,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "helpfulness, they're they're vast and",
      "offset": 1041.12,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "they make rag a necessity. That's why we",
      "offset": 1042.72,
      "duration": 4.479
    },
    {
      "lang": "en",
      "text": "are not saying that that rag is",
      "offset": 1045.76,
      "duration": 2.96
    },
    {
      "lang": "en",
      "text": "dangerous. We're just saying it is not",
      "offset": 1047.199,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "necessarily safer. um it is absolutely",
      "offset": 1048.72,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "necessary. But the harmlessness angle is",
      "offset": 1051.6,
      "duration": 5.439
    },
    {
      "lang": "en",
      "text": "something that is completely separate",
      "offset": 1054.72,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "and the way that organizations think",
      "offset": 1057.039,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "about it is often to kind of split them",
      "offset": 1059.44,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "and look at them through two different",
      "offset": 1061.039,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "angles because the helpfulness angle",
      "offset": 1062.88,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "it's very much grounded in a specific",
      "offset": 1064.96,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "application. Right? Can a question",
      "offset": 1066.88,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "answering system that helps financial",
      "offset": 1069.84,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "analysts answer question and test",
      "offset": 1072.24,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "hypothesis? The answer to that is does",
      "offset": 1074.72,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "it help them? Yes or no?",
      "offset": 1077.28,
      "duration": 5.519
    },
    {
      "lang": "en",
      "text": "But there's always this angle of a",
      "offset": 1080.16,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "malicious or an unintended abuse of that",
      "offset": 1082.799,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "system where the same system that helps",
      "offset": 1085.2,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "people assess hypothesis could then also",
      "offset": 1086.96,
      "duration": 5.839
    },
    {
      "lang": "en",
      "text": "be used to right who is the worst broker",
      "offset": 1089.52,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "and who should I exploit",
      "offset": 1092.799,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "uh which is maybe not something that you",
      "offset": 1095.2,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "want to answer in turn. So now we have",
      "offset": 1096.559,
      "duration": 6.881
    },
    {
      "lang": "en",
      "text": "these two angles and often you can say",
      "offset": 1100.96,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "okay the the the harmlessness angle is",
      "offset": 1103.44,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "something that is usually consistent",
      "offset": 1106.16,
      "duration": 3.519
    },
    {
      "lang": "en",
      "text": "across an industry across a sector",
      "offset": 1108,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "across a domain there might be some",
      "offset": 1109.679,
      "duration": 4.561
    },
    {
      "lang": "en",
      "text": "application specific risks too and then",
      "offset": 1111.76,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "there's the helpfulness angle where you",
      "offset": 1114.24,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "provide uh answers that hopefully help",
      "offset": 1116.08,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "and here rack really helps because it",
      "offset": 1119.6,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "leads to you being able to build things",
      "offset": 1121.76,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "like transparent attribution. So",
      "offset": 1124.48,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "transparent attribution for us means",
      "offset": 1127.12,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "every time I produce some kind of",
      "offset": 1129.84,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "tidbit, some piece of information, I",
      "offset": 1131.44,
      "duration": 3.119
    },
    {
      "lang": "en",
      "text": "need to ground this in some kind of",
      "offset": 1133.12,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "document or some kind of structured",
      "offset": 1134.559,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "data. If I say the the price of meta is",
      "offset": 1136.96,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "so and so today, then I want to say want",
      "offset": 1139.679,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "to be able to look at that and say where",
      "offset": 1142.32,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "does that number actually come from? Is",
      "offset": 1143.919,
      "duration": 3.521
    },
    {
      "lang": "en",
      "text": "it hallucinated or do I actually know",
      "offset": 1145.44,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "the query that produced that that",
      "offset": 1147.44,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "number? If I'm saying like the following",
      "offset": 1150.16,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "analyst said the following statement,",
      "offset": 1152.16,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "then I want to be able to hover over",
      "offset": 1154,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "this and say, \"Oh yeah, this is where",
      "offset": 1155.76,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "that that statement came from. It is not",
      "offset": 1157.12,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "hallucinated.\"",
      "offset": 1159.28,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "Uh this to some degree can prevent the",
      "offset": 1161.039,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "the harmfulness or the harmlessness",
      "offset": 1164.16,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "issues as well, but it is a somewhat",
      "offset": 1166.799,
      "duration": 4.641
    },
    {
      "lang": "en",
      "text": "separate topic as you were saying. You",
      "offset": 1169.6,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "talk about hallucination and that's",
      "offset": 1171.44,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "where the big advantage for RA comes in,",
      "offset": 1172.72,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "but then there's the harmless or the",
      "offset": 1174.88,
      "duration": 2.96
    },
    {
      "lang": "en",
      "text": "harmfulness angle as well.",
      "offset": 1176.32,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "Okay. Nice. So maybe recap for us again.",
      "offset": 1177.84,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "So there's probably lots of listeners",
      "offset": 1180.64,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "out there who are sold on ragda and",
      "offset": 1182.72,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "they're like great I want to reduce",
      "offset": 1184.72,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "harmfulness. Uh I want to increase the",
      "offset": 1186.4,
      "duration": 7.68
    },
    {
      "lang": "en",
      "text": "honesty of my of my LLM and so I'm going",
      "offset": 1189.36,
      "duration": 6.559
    },
    {
      "lang": "en",
      "text": "to use a rag system. What are the kinds",
      "offset": 1194.08,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "of mitigations? I mean, you you went",
      "offset": 1195.919,
      "duration": 3.521
    },
    {
      "lang": "en",
      "text": "into this a little bit, but kind of",
      "offset": 1198.32,
      "duration": 2.56
    },
    {
      "lang": "en",
      "text": "recap for us again the kinds of",
      "offset": 1199.44,
      "duration": 2.88
    },
    {
      "lang": "en",
      "text": "mitigations that our listeners can take",
      "offset": 1200.88,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "home away from this episode to be able",
      "offset": 1202.32,
      "duration": 5.92
    },
    {
      "lang": "en",
      "text": "to use rag so that it is safe for their",
      "offset": 1204.96,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "particular circumstances.",
      "offset": 1208.24,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "Yeah. Um I think that's that's a great",
      "offset": 1209.84,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "opportunity to talk about a little bit",
      "offset": 1212.72,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "about how should we evaluate systems",
      "offset": 1214.32,
      "duration": 6.8
    },
    {
      "lang": "en",
      "text": "because in the end what you see talked",
      "offset": 1218.08,
      "duration": 4.959
    },
    {
      "lang": "en",
      "text": "about a lot publicly and probably the",
      "offset": 1221.12,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "most is benchmarks and you see oh hey",
      "offset": 1223.039,
      "duration": 5.441
    },
    {
      "lang": "en",
      "text": "this new model that large language model",
      "offset": 1225.84,
      "duration": 5.92
    },
    {
      "lang": "en",
      "text": "provider A or B or C produced it",
      "offset": 1228.48,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "achieves a better score on the large",
      "offset": 1231.76,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "language model arena or on the following",
      "offset": 1233.6,
      "duration": 3.439
    },
    {
      "lang": "en",
      "text": "benchmarks and it's better at reasoning",
      "offset": 1235.36,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "it's better at coding that doesn't",
      "offset": 1237.039,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "necessarily mean that it's better for",
      "offset": 1239.2,
      "duration": 3.359
    },
    {
      "lang": "en",
      "text": "all the downstream applications that are",
      "offset": 1240.88,
      "duration": 5.279
    },
    {
      "lang": "en",
      "text": "being integrated into. And I think we",
      "offset": 1242.559,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "often conflate this kind of view where",
      "offset": 1246.159,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "it's actually really really important to",
      "offset": 1247.919,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "measure and to evaluate the system in",
      "offset": 1250.159,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "the context it's deployed in. And that",
      "offset": 1252,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "includes things like safety testing and",
      "offset": 1254.24,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "specific guard rails. So we also",
      "offset": 1256.64,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "released a second paper in addition to",
      "offset": 1258.88,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "our rack LM paper where we um developed",
      "offset": 1260.559,
      "duration": 6.881
    },
    {
      "lang": "en",
      "text": "our own content risk taxonomy for for",
      "offset": 1263.6,
      "duration": 6.24
    },
    {
      "lang": "en",
      "text": "financial services where we say here are",
      "offset": 1267.44,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "12 categories of risks that we really",
      "offset": 1269.84,
      "duration": 4.959
    },
    {
      "lang": "en",
      "text": "really should address with applications",
      "offset": 1272.64,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "in our area.",
      "offset": 1274.799,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "And for each of these we can measure",
      "offset": 1276.88,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "because we we can collect data against",
      "offset": 1279.12,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "this and say okay here are 100 queries",
      "offset": 1280.72,
      "duration": 6.16
    },
    {
      "lang": "en",
      "text": "that try and do financial misconduct.",
      "offset": 1284.4,
      "duration": 6.24
    },
    {
      "lang": "en",
      "text": "100 queries that try and make the LM",
      "offset": 1286.88,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "generate financial advice. 100 queries",
      "offset": 1290.64,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "that try and get at personal",
      "offset": 1292.88,
      "duration": 5.919
    },
    {
      "lang": "en",
      "text": "information. 100 queries that uh try and",
      "offset": 1295.28,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "defame someone or create fake fake",
      "offset": 1298.799,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "information or fake narratives and all",
      "offset": 1300.88,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "of these categories. You can create",
      "offset": 1303.039,
      "duration": 3.041
    },
    {
      "lang": "en",
      "text": "data, you can measure it against this",
      "offset": 1304.48,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "and you can not only test the large",
      "offset": 1306.08,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "language models themselves but rather",
      "offset": 1308,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "you can test the entire end-to-end",
      "offset": 1309.919,
      "duration": 4.481
    },
    {
      "lang": "en",
      "text": "system that is deployed in a specific",
      "offset": 1312.32,
      "duration": 6.32
    },
    {
      "lang": "en",
      "text": "sociotechnical context and here typicail",
      "offset": 1314.4,
      "duration": 6.159
    },
    {
      "lang": "en",
      "text": "systems there are a lot of open source",
      "offset": 1318.64,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "solutions uh Nvidia has their own llama",
      "offset": 1320.559,
      "duration": 4.641
    },
    {
      "lang": "en",
      "text": "has their own Google has their own they",
      "offset": 1323.52,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "provide open- source guardrails but",
      "offset": 1325.2,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "again these open source guardrails",
      "offset": 1327.84,
      "duration": 2.88
    },
    {
      "lang": "en",
      "text": "they're shielding against these general",
      "offset": 1329.12,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "purpose risks in our paper we found that",
      "offset": 1330.72,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "If you apply these these llama guard or",
      "offset": 1333.6,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "shield gemma or aegis is is what they're",
      "offset": 1336.32,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "called. If you apply them to then to our",
      "offset": 1338.4,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "specific risks uh they're they're",
      "offset": 1340.24,
      "duration": 4.559
    },
    {
      "lang": "en",
      "text": "classifiers. They say is this input or",
      "offset": 1342.72,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "is this output safe? Yes or no? And they",
      "offset": 1344.799,
      "duration": 5.201
    },
    {
      "lang": "en",
      "text": "also fail in our domain because similar",
      "offset": 1347.6,
      "duration": 5.92
    },
    {
      "lang": "en",
      "text": "to our rack paper. It's just not a use",
      "offset": 1350,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "case that people necessarily have",
      "offset": 1353.52,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "thought about before. But it gives us",
      "offset": 1354.96,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "then the idea of okay, how do we build",
      "offset": 1357.2,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "our own guardrails? Can we have a",
      "offset": 1358.799,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "classifier on inputs and on outputs that",
      "offset": 1360.48,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "identify violations of our rules that we",
      "offset": 1363.12,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "set up ourselves? So now instead of",
      "offset": 1365.36,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "having a vanilla rag system where it's",
      "offset": 1368.32,
      "duration": 4.479
    },
    {
      "lang": "en",
      "text": "retrieval answer, we have guardrail",
      "offset": 1370.08,
      "duration": 6.56
    },
    {
      "lang": "en",
      "text": "retrieval answer guardrail. And in",
      "offset": 1372.799,
      "duration": 5.921
    },
    {
      "lang": "en",
      "text": "practice to prevent hallucination and to",
      "offset": 1376.64,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "add attribution",
      "offset": 1378.72,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "real systems that are deployed to to",
      "offset": 1380.559,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "wide ranges of audiences they have many",
      "offset": 1382.64,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "more components and it's really this end",
      "offset": 1384.559,
      "duration": 3.761
    },
    {
      "lang": "en",
      "text": "to end application that that should be",
      "offset": 1386.4,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "evaluated and where you need the subject",
      "offset": 1388.32,
      "duration": 3.599
    },
    {
      "lang": "en",
      "text": "matter expertise to also know is it",
      "offset": 1390.24,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "helpful and is a townless",
      "offset": 1391.919,
      "duration": 3.281
    },
    {
      "lang": "en",
      "text": "nice okay so yeah so a combination of",
      "offset": 1393.6,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "subject matter expertise uh you know",
      "offset": 1395.2,
      "duration": 3.599
    },
    {
      "lang": "en",
      "text": "people digging into their particular",
      "offset": 1397.6,
      "duration": 2.64
    },
    {
      "lang": "en",
      "text": "circumstances you mentioned earlier in",
      "offset": 1398.799,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "the episode being aware of your data",
      "offset": 1400.24,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "making sure that there aren't data in",
      "offset": 1402.4,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "there that are going to be harmful that",
      "offset": 1404,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "could be uh that could be used as",
      "offset": 1405.44,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "grounding by the LLM. And then you",
      "offset": 1407.36,
      "duration": 5.439
    },
    {
      "lang": "en",
      "text": "mentioned just now this idea this uh",
      "offset": 1410.96,
      "duration": 5.92
    },
    {
      "lang": "en",
      "text": "flow of guardrail retrieval answer and",
      "offset": 1412.799,
      "duration": 7.281
    },
    {
      "lang": "en",
      "text": "then another set of guardrails. Um and",
      "offset": 1416.88,
      "duration": 6.159
    },
    {
      "lang": "en",
      "text": "so yeah, so very practical advice there.",
      "offset": 1420.08,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "Um",
      "offset": 1423.039,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "changing the topic a little bit like",
      "offset": 1424.88,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "still staying on rag and still staying",
      "offset": 1427.679,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "on helpfulness but uh something that we",
      "offset": 1429.84,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "haven't talked about yet is context",
      "offset": 1432.159,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "length. So I have a couple of points",
      "offset": 1434,
      "duration": 6.08
    },
    {
      "lang": "en",
      "text": "here or a couple of questions here. Um",
      "offset": 1436.799,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "you observed in your paper that LLMs are",
      "offset": 1440.08,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "often optimized for short prompts but",
      "offset": 1442.559,
      "duration": 4.961
    },
    {
      "lang": "en",
      "text": "deployed in long text environments like",
      "offset": 1445.52,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "rags. So going back to the example that",
      "offset": 1447.52,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "I gave earlier, you I talked about there",
      "offset": 1449.679,
      "duration": 5.841
    },
    {
      "lang": "en",
      "text": "being a million uh legal documents that",
      "offset": 1452.24,
      "duration": 6.16
    },
    {
      "lang": "en",
      "text": "the rag system searches over and then it",
      "offset": 1455.52,
      "duration": 6.96
    },
    {
      "lang": "en",
      "text": "pulls out a dozen documents. Those",
      "offset": 1458.4,
      "duration": 6.159
    },
    {
      "lang": "en",
      "text": "documents could each be 10 pages long.",
      "offset": 1462.48,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "So then you're talking about 120 pages",
      "offset": 1464.559,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "of context. And if the LLM was optimized",
      "offset": 1467.36,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "for a question like what's the capital",
      "offset": 1470.159,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "of France,",
      "offset": 1472.72,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "then um then yeah, I could imagine you",
      "offset": 1475.039,
      "duration": 4.481
    },
    {
      "lang": "en",
      "text": "run into issues. So uh do you want do",
      "offset": 1477.52,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "you want to fill us more in about this?",
      "offset": 1479.52,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "The kinds of issues that arise? Um, for",
      "offset": 1482.24,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "example, it seems like there's, you",
      "offset": 1484.96,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "know, trade-offs between the benefits of",
      "offset": 1487.52,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "longer inputs versus this becoming a new",
      "offset": 1489.36,
      "duration": 4.559
    },
    {
      "lang": "en",
      "text": "risk surface, a new attack surface.",
      "offset": 1491.919,
      "duration": 3.441
    },
    {
      "lang": "en",
      "text": "Yeah, absolutely. And I think you're",
      "offset": 1493.919,
      "duration": 2.88
    },
    {
      "lang": "en",
      "text": "really hitting the nail on the head",
      "offset": 1495.36,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "here. Rag is incredibly powerful.",
      "offset": 1496.799,
      "duration": 4.721
    },
    {
      "lang": "en",
      "text": "There's a lot of investment from from",
      "offset": 1499.279,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "companies that build life language",
      "offset": 1501.52,
      "duration": 2.96
    },
    {
      "lang": "en",
      "text": "models into increasing the possible",
      "offset": 1502.799,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "context length. But at the same time,",
      "offset": 1504.48,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "increasing the possible context length",
      "offset": 1507.12,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "also requires developing methods and",
      "offset": 1508.799,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "developing the models to actually be",
      "offset": 1512,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "able to handle such a context length",
      "offset": 1513.279,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "rather than just being able to",
      "offset": 1515.44,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "technically being able to handle them by",
      "offset": 1516.96,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "uh having an attention that that goes",
      "offset": 1519.84,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "long enough back.",
      "offset": 1521.76,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "So here there there are a couple of",
      "offset": 1523.76,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "considerations in our paper. What we",
      "offset": 1525.44,
      "duration": 4.479
    },
    {
      "lang": "en",
      "text": "evaluated was how does context length",
      "offset": 1527.52,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "really influence this the safety angle.",
      "offset": 1529.919,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "And we found that especially for safety,",
      "offset": 1532.32,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "there seems to be this effect where the",
      "offset": 1535.039,
      "duration": 5.201
    },
    {
      "lang": "en",
      "text": "more context you put in, the more likely",
      "offset": 1538.08,
      "duration": 4.479
    },
    {
      "lang": "en",
      "text": "the model is to uh to forget the the",
      "offset": 1540.24,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "built-in safe safety guardrails or this",
      "offset": 1542.559,
      "duration": 5.681
    },
    {
      "lang": "en",
      "text": "alignment that that people talk about.",
      "offset": 1545.36,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "uh which absolutely shouldn't happen if",
      "offset": 1548.24,
      "duration": 4.559
    },
    {
      "lang": "en",
      "text": "you're considering how how rag is set up",
      "offset": 1550.48,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "because again you're adding innocuous",
      "offset": 1552.799,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "completely harmless information and just",
      "offset": 1554.96,
      "duration": 3.599
    },
    {
      "lang": "en",
      "text": "because there's a long long context",
      "offset": 1557.279,
      "duration": 2.481
    },
    {
      "lang": "en",
      "text": "doesn't mean that the language model",
      "offset": 1558.559,
      "duration": 3.041
    },
    {
      "lang": "en",
      "text": "needs to behave any differently from if",
      "offset": 1559.76,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "you just post in what's the capital of",
      "offset": 1561.6,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "France",
      "offset": 1563.6,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "at the same time the context length",
      "offset": 1565.2,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "question actually has also massive",
      "offset": 1567.679,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "implications of how we build rack",
      "offset": 1569.84,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "systems in practice retrieval systems",
      "offset": 1571.52,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "have multiple components too we've we've",
      "offset": 1574.48,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "been kind of glossing over this point we",
      "offset": 1576.88,
      "duration": 2.96
    },
    {
      "lang": "en",
      "text": "just say oh yeah there's a search system",
      "offset": 1578.559,
      "duration": 3.761
    },
    {
      "lang": "en",
      "text": "and there's a database but often you",
      "offset": 1579.84,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "have things like okay how do I parse the",
      "offset": 1582.32,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "query if I ask a question to what time",
      "offset": 1584.4,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "frame should I limit the search results",
      "offset": 1587.44,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "um am I filtering to particular",
      "offset": 1590,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "industries sectors companies any kind of",
      "offset": 1592.08,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "other metadata uh there's usually the",
      "offset": 1594.48,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "way that search engines are written",
      "offset": 1597.2,
      "duration": 2.959
    },
    {
      "lang": "en",
      "text": "there's usually multiple steps as well",
      "offset": 1598.64,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "where you do a first pass retrieval",
      "offset": 1600.159,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "where you go from hundreds of millions",
      "offset": 1602.24,
      "duration": 2.96
    },
    {
      "lang": "en",
      "text": "of documents or even billions of",
      "offset": 1603.84,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "documents uh to down to just a handful.",
      "offset": 1605.2,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "And then there's usually a re-ranking",
      "offset": 1608.88,
      "duration": 2.799
    },
    {
      "lang": "en",
      "text": "step that's much more computationally",
      "offset": 1610.24,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "intensive where you really pick out",
      "offset": 1611.679,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "which snippets in in the documents are",
      "offset": 1613.76,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "you actually finding the answer in. So",
      "offset": 1615.76,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "all of these components here have an",
      "offset": 1618.32,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "influence on on the context length when",
      "offset": 1620.72,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "you say you have 10 legal documents of",
      "offset": 1622.72,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "10 pages. How do you get to them? And",
      "offset": 1624.64,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "what is the effect of pasting entire",
      "offset": 1626.96,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "documents versus just a paragraph or two",
      "offset": 1628.799,
      "duration": 5.041
    },
    {
      "lang": "en",
      "text": "from each document? And typically what",
      "offset": 1631.039,
      "duration": 6.64
    },
    {
      "lang": "en",
      "text": "people find is the less context you need",
      "offset": 1633.84,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "to provide the especially if the answer",
      "offset": 1637.679,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "is in that context the easier it is for",
      "offset": 1639.84,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "the large language model to find the",
      "offset": 1641.52,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "right answer. Seems seems pretty obvious",
      "offset": 1642.88,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "but that then becomes a retrieval",
      "offset": 1646,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "problem. How do I find within the you",
      "offset": 1647.6,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "know if I have 100 million documents",
      "offset": 1649.76,
      "duration": 3.519
    },
    {
      "lang": "en",
      "text": "each 10 pages long? How do I find the",
      "offset": 1651.36,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "two paragraphs that actually answer the",
      "offset": 1653.279,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "question? So a hope really has been in",
      "offset": 1654.72,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "large language model development to just",
      "offset": 1657.919,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "increase the context length and to rely",
      "offset": 1660.4,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "less on more and more accurate retrieval",
      "offset": 1662.159,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "but rather let the language model figure",
      "offset": 1664,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "it out. Being able to handle longer",
      "offset": 1665.279,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "context also allows you to give much",
      "offset": 1667.44,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "more contextualized answers if you have",
      "offset": 1668.96,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "the entire 10-page document even if the",
      "offset": 1671.279,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "answer is found in just one paragraph.",
      "offset": 1673.12,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "It can still give you the context from",
      "offset": 1675.279,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "from page one or tell right it's tell",
      "offset": 1677.52,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "you what is this document type where is",
      "offset": 1680.559,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "it from what was in the intro what did",
      "offset": 1682.24,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "the executive summary of this document",
      "offset": 1685.039,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "say in contrast to the actual uh",
      "offset": 1686.559,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "document if we go into voice like what",
      "offset": 1689.279,
      "duration": 4.241
    },
    {
      "lang": "en",
      "text": "was the inonation if we go into video",
      "offset": 1691.279,
      "duration": 4.241
    },
    {
      "lang": "en",
      "text": "there's so many opportunities to to take",
      "offset": 1693.52,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "advantage of longer context but again we",
      "offset": 1695.52,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "have to really consider how are the",
      "offset": 1698,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "models being deployed how are they who",
      "offset": 1699.6,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "are the users of this what is the",
      "offset": 1702.48,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "application",
      "offset": 1704.32,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "And every single one of these designs I",
      "offset": 1705.52,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "just talked about can influence the",
      "offset": 1707.76,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "helpfulness and the harmful or harmless",
      "offset": 1709.44,
      "duration": 4.479
    },
    {
      "lang": "en",
      "text": "in this case of the entire system. So",
      "offset": 1711.6,
      "duration": 4.959
    },
    {
      "lang": "en",
      "text": "this is a massive undertaking and uh",
      "offset": 1713.919,
      "duration": 5.841
    },
    {
      "lang": "en",
      "text": "requires a lot of research.",
      "offset": 1716.559,
      "duration": 4.961
    },
    {
      "lang": "en",
      "text": "This episode of super data science is",
      "offset": 1719.76,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "brought to you by the Dell AI factory",
      "offset": 1721.52,
      "duration": 4.879
    },
    {
      "lang": "en",
      "text": "with Nvidia. Two trusted technology",
      "offset": 1724.08,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "leaders united to deliver a",
      "offset": 1726.399,
      "duration": 4.241
    },
    {
      "lang": "en",
      "text": "comprehensive and secure AI solution",
      "offset": 1728.48,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "customizable for any business. With a",
      "offset": 1730.64,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "portfolio of products, solutions, and",
      "offset": 1733.52,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "services tailored for AI workloads from",
      "offset": 1735.36,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "desktop to data center to cloud, the",
      "offset": 1737.6,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "Dell AI factory with NVIDIA paves the",
      "offset": 1739.679,
      "duration": 4.641
    },
    {
      "lang": "en",
      "text": "way for AI to work seamlessly for you.",
      "offset": 1741.76,
      "duration": 4.639
    },
    {
      "lang": "en",
      "text": "Integrated Dell and Nvidia capabilities",
      "offset": 1744.32,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "accelerate your AI powered use cases,",
      "offset": 1746.399,
      "duration": 4.241
    },
    {
      "lang": "en",
      "text": "integrate your data and workflows, and",
      "offset": 1748.399,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "enable you to design your own AI journey",
      "offset": 1750.64,
      "duration": 5.919
    },
    {
      "lang": "en",
      "text": "for repeatable, scalable outcomes. Visit",
      "offset": 1753.039,
      "duration": 6.081
    },
    {
      "lang": "en",
      "text": "ww.dell.com/supdatience",
      "offset": 1756.559,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "to learn more. That's",
      "offset": 1759.12,
      "duration": 4.039
    },
    {
      "lang": "en",
      "text": "dell.com/supdatience.",
      "offset": 1760.159,
      "duration": 3
    },
    {
      "lang": "en",
      "text": "That was a fascinating answer. I learned",
      "offset": 1764,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "a lot and you explained all of that very",
      "offset": 1765.84,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "clearly. Thank you. Um, something that",
      "offset": 1767.76,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "you talked about there was how longer",
      "offset": 1770,
      "duration": 4.559
    },
    {
      "lang": "en",
      "text": "context windows allow us to have more",
      "offset": 1771.679,
      "duration": 5.201
    },
    {
      "lang": "en",
      "text": "context in our answer. Um, you know,",
      "offset": 1774.559,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "more subtlety, more nuance, uh, in in",
      "offset": 1776.88,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "the answer that comes back. And you also",
      "offset": 1779.679,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "mentioned there how context windows are",
      "offset": 1782,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "getting longer and longer, which",
      "offset": 1784.08,
      "duration": 2.88
    },
    {
      "lang": "en",
      "text": "actually ties in perfectly to the next",
      "offset": 1785.36,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "question that I was going to ask you,",
      "offset": 1786.96,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "which is that, you know, we're at a",
      "offset": 1788.64,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "point now where it's getting reasonably",
      "offset": 1790.88,
      "duration": 5.679
    },
    {
      "lang": "en",
      "text": "common to see LLMs that have a million",
      "offset": 1792.96,
      "duration": 6.079
    },
    {
      "lang": "en",
      "text": "token context length. And we've seen",
      "offset": 1796.559,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "some released that are multiples of",
      "offset": 1799.039,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "that, many millions of tokens in",
      "offset": 1800.72,
      "duration": 7.28
    },
    {
      "lang": "en",
      "text": "context. And the typically when these",
      "offset": 1803.279,
      "duration": 6.081
    },
    {
      "lang": "en",
      "text": "are released it comes with these kind of",
      "offset": 1808,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "needle in a hay stack tests where uh you",
      "offset": 1809.36,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "try to",
      "offset": 1812.72,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "you know you hide a small amount of",
      "offset": 1814.48,
      "duration": 2.799
    },
    {
      "lang": "en",
      "text": "information like I think a common one is",
      "offset": 1815.76,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "like a pizza recipe like there'll be",
      "offset": 1817.279,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "something like the world's best pizza is",
      "offset": 1820.32,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "and then these like you know random",
      "offset": 1822.399,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "ingredients like anchovies um you know",
      "offset": 1824,
      "duration": 5.679
    },
    {
      "lang": "en",
      "text": "something that that is that is unique",
      "offset": 1826.799,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "and then you'll have you'll say okay you",
      "offset": 1829.679,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "know over our 10 million token context",
      "offset": 1831.279,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "length",
      "offset": 1833.52,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "um the the model was able to",
      "offset": 1834.799,
      "duration": 4.641
    },
    {
      "lang": "en",
      "text": "successfully retrieve pizza information.",
      "offset": 1836.88,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "Now, I'm going getting a little bit deep",
      "offset": 1839.44,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "in the weeds here and on a little bit of",
      "offset": 1841.36,
      "duration": 2.96
    },
    {
      "lang": "en",
      "text": "a tangent, but some people have also",
      "offset": 1842.88,
      "duration": 3.679
    },
    {
      "lang": "en",
      "text": "said, you know, that isn't a great test",
      "offset": 1844.32,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "because if you have millions of legal",
      "offset": 1846.559,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "documents and then there's one pizza",
      "offset": 1848.72,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "recipe, that's quite unusual and so it's",
      "offset": 1850.399,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "probably, you know, that's then maybe",
      "offset": 1853.2,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "something that the LLM is going to take",
      "offset": 1855.679,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "notice of.",
      "offset": 1857.2,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "Um, and so yeah, so there's there's",
      "offset": 1859.039,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "controversy controversy about needle in",
      "offset": 1861.44,
      "duration": 2.959
    },
    {
      "lang": "en",
      "text": "a haststack test, but we don't",
      "offset": 1863.279,
      "duration": 2.4
    },
    {
      "lang": "en",
      "text": "necessarily need to get into that too",
      "offset": 1864.399,
      "duration": 3.041
    },
    {
      "lang": "en",
      "text": "much unless it interests you. The",
      "offset": 1865.679,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "question that I'm getting to is",
      "offset": 1867.44,
      "duration": 4.719
    },
    {
      "lang": "en",
      "text": "do you think we'll get to a point where",
      "offset": 1869.919,
      "duration": 5.281
    },
    {
      "lang": "en",
      "text": "context windows expand so much that it",
      "offset": 1872.159,
      "duration": 5.361
    },
    {
      "lang": "en",
      "text": "is effectively like an infinite context",
      "offset": 1875.2,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "window and then that means that we don't",
      "offset": 1877.52,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "need rag at all.",
      "offset": 1880.08,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "Yeah. Um, there are additional",
      "offset": 1881.6,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "considerations to to address your needle",
      "offset": 1883.84,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "and haste point. I think this is a",
      "offset": 1885.679,
      "duration": 4.561
    },
    {
      "lang": "en",
      "text": "perfect example of the difference",
      "offset": 1887.44,
      "duration": 5.599
    },
    {
      "lang": "en",
      "text": "between developers of le language models",
      "offset": 1890.24,
      "duration": 5.039
    },
    {
      "lang": "en",
      "text": "and integrators of such language models",
      "offset": 1893.039,
      "duration": 6.401
    },
    {
      "lang": "en",
      "text": "in actual applications. As someone who",
      "offset": 1895.279,
      "duration": 6.081
    },
    {
      "lang": "en",
      "text": "who might be considering, okay, which of",
      "offset": 1899.44,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "these long context models do I use? I",
      "offset": 1901.36,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "can look at needle and haste. I can say,",
      "offset": 1903.76,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "oh yeah, this model got it 100% of the",
      "offset": 1905.279,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "time. This one did not. Clearly, I'm",
      "offset": 1907.2,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "going to look at the one that gets 100%",
      "offset": 1909.279,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "first. And that is really the decision",
      "offset": 1910.96,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "that these benchmarks, even if they're",
      "offset": 1912.96,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "artificial benchmarks, can influence.",
      "offset": 1914.88,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "But I think no one is making the point",
      "offset": 1917.6,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "that just because model can find some",
      "offset": 1919.44,
      "duration": 6.56
    },
    {
      "lang": "en",
      "text": "information in 10 million tokens, it is",
      "offset": 1923.12,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "going to be able to help you with a a",
      "offset": 1926,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "research heavy legal task. That is",
      "offset": 1928.32,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "really on the integrators in the end to",
      "offset": 1930.96,
      "duration": 3.599
    },
    {
      "lang": "en",
      "text": "identify. And in this case, it might be",
      "offset": 1932.64,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "a much much much harder task. Right? If",
      "offset": 1934.559,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "you have um a system that we just",
      "offset": 1936.96,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "released earlier this week at at",
      "offset": 1939.519,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "Bloomberg was a a tool that helps",
      "offset": 1940.799,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "research analysts search through over",
      "offset": 1943.36,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "400 million documents and news articles",
      "offset": 1945.679,
      "duration": 5.761
    },
    {
      "lang": "en",
      "text": "and and analyst reports to answer",
      "offset": 1948.64,
      "duration": 4.639
    },
    {
      "lang": "en",
      "text": "questions and to help with the",
      "offset": 1951.44,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "identification of and solution of",
      "offset": 1953.279,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "hypothesis. It's very much hypothesis",
      "offset": 1955.6,
      "duration": 3.679
    },
    {
      "lang": "en",
      "text": "driven. You ask a question, it goes",
      "offset": 1957.679,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "through all these 400 million documents",
      "offset": 1959.279,
      "duration": 4.481
    },
    {
      "lang": "en",
      "text": "and then synthesizes an answer. This is",
      "offset": 1961.039,
      "duration": 5.281
    },
    {
      "lang": "en",
      "text": "much much harder to do than a simple",
      "offset": 1963.76,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "find this piece of of pizza information",
      "offset": 1966.32,
      "duration": 4.719
    },
    {
      "lang": "en",
      "text": "or pizza recipe information and instead",
      "offset": 1968.159,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "you really need to in again evaluate in",
      "offset": 1971.039,
      "duration": 5.041
    },
    {
      "lang": "en",
      "text": "the context you deploy the system. Uh",
      "offset": 1973.279,
      "duration": 5.441
    },
    {
      "lang": "en",
      "text": "but to to then go back at at your at",
      "offset": 1976.08,
      "duration": 6.079
    },
    {
      "lang": "en",
      "text": "your question there is obviously strong",
      "offset": 1978.72,
      "duration": 4.799
    },
    {
      "lang": "en",
      "text": "advantages of models that are",
      "offset": 1982.159,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "technically capable of handling more and",
      "offset": 1983.519,
      "duration": 4.721
    },
    {
      "lang": "en",
      "text": "more complex situations. If I'm able to",
      "offset": 1985.84,
      "duration": 4.559
    },
    {
      "lang": "en",
      "text": "just paste in more documents or more of",
      "offset": 1988.24,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "a context, I don't need to rely on as",
      "offset": 1990.399,
      "duration": 5.601
    },
    {
      "lang": "en",
      "text": "many tricks to to really narrow down the",
      "offset": 1993.12,
      "duration": 4.799
    },
    {
      "lang": "en",
      "text": "the context window, I can just rely on a",
      "offset": 1996,
      "duration": 3.519
    },
    {
      "lang": "en",
      "text": "large language model. There's a",
      "offset": 1997.919,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "trade-off here though um where longer",
      "offset": 1999.519,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "context usually comes at a cost of",
      "offset": 2001.6,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "significantly increased latency and",
      "offset": 2003.039,
      "duration": 5.601
    },
    {
      "lang": "en",
      "text": "cost. So even though long context models",
      "offset": 2004.64,
      "duration": 5.919
    },
    {
      "lang": "en",
      "text": "are available, they might not",
      "offset": 2008.64,
      "duration": 3.279
    },
    {
      "lang": "en",
      "text": "necessarily be the best for the task if",
      "offset": 2010.559,
      "duration": 3.041
    },
    {
      "lang": "en",
      "text": "you want a snappy direct answer.",
      "offset": 2011.919,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "Of course, that is such an obvious point",
      "offset": 2013.6,
      "duration": 3.679
    },
    {
      "lang": "en",
      "text": "to make.",
      "offset": 2016,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "is that and you know over a long enough",
      "offset": 2017.279,
      "duration": 4.561
    },
    {
      "lang": "en",
      "text": "time scale you know over many years",
      "offset": 2020.08,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "maybe many decades compute cost over",
      "offset": 2021.84,
      "duration": 5.199
    },
    {
      "lang": "en",
      "text": "millions of tokens might be trivial uh",
      "offset": 2024.72,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "but at least for the foreseeable future",
      "offset": 2027.039,
      "duration": 5.841
    },
    {
      "lang": "en",
      "text": "it isn't and so yes that makes perfect",
      "offset": 2029.039,
      "duration": 6.801
    },
    {
      "lang": "en",
      "text": "sense because you so something that I",
      "offset": 2032.88,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "guess we could make a little bit more",
      "offset": 2035.84,
      "duration": 2.559
    },
    {
      "lang": "en",
      "text": "explicit for people who aren't familiar",
      "offset": 2036.88,
      "duration": 2.56
    },
    {
      "lang": "en",
      "text": "with rag because we haven't talked about",
      "offset": 2038.399,
      "duration": 4.561
    },
    {
      "lang": "en",
      "text": "this is that when uh the way that rag",
      "offset": 2039.44,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "systems work is like let's go back to",
      "offset": 2042.96,
      "duration": 2.88
    },
    {
      "lang": "en",
      "text": "that example of the million legal",
      "offset": 2044.64,
      "duration": 2
    },
    {
      "lang": "en",
      "text": "documents",
      "offset": 2045.84,
      "duration": 2.72
    },
    {
      "lang": "en",
      "text": "What we would do in advance before",
      "offset": 2046.64,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "running any rag queries is we would map",
      "offset": 2048.56,
      "duration": 6.48
    },
    {
      "lang": "en",
      "text": "each of those million documents into a",
      "offset": 2052,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "highdimensional space called a vector",
      "offset": 2055.04,
      "duration": 5.92
    },
    {
      "lang": "en",
      "text": "space and the location in that high",
      "offset": 2057.44,
      "duration": 5.199
    },
    {
      "lang": "en",
      "text": "dimensional space like you could you can",
      "offset": 2060.96,
      "duration": 2.959
    },
    {
      "lang": "en",
      "text": "you can only visualize in three",
      "offset": 2062.639,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "dimensions. So, so in your head you can",
      "offset": 2063.919,
      "duration": 6.72
    },
    {
      "lang": "en",
      "text": "kind of imagine on like an XY Z an XYZ",
      "offset": 2066.48,
      "duration": 6.96
    },
    {
      "lang": "en",
      "text": "plane um you know in three dimensions",
      "offset": 2070.639,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "you can kind of imagine okay you know in",
      "offset": 2073.44,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "the top right corner near the front of",
      "offset": 2075.04,
      "duration": 4.879
    },
    {
      "lang": "en",
      "text": "this space we have you know commercial",
      "offset": 2077.2,
      "duration": 6.8
    },
    {
      "lang": "en",
      "text": "law documents and then um nearby there",
      "offset": 2079.919,
      "duration": 5.92
    },
    {
      "lang": "en",
      "text": "there are some you know other kinds of",
      "offset": 2084,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "related legal documents and as you move",
      "offset": 2085.839,
      "duration": 3.361
    },
    {
      "lang": "en",
      "text": "further and further away from a given",
      "offset": 2087.28,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "point in space um you'll you'll get you",
      "offset": 2089.2,
      "duration": 6.479
    },
    {
      "lang": "en",
      "text": "know you'll get more variety",
      "offset": 2092.8,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "in the kinds in the kind of document",
      "offset": 2095.679,
      "duration": 2.801
    },
    {
      "lang": "en",
      "text": "that you're looking at. So the the",
      "offset": 2097.44,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "closer that things are in the space uh",
      "offset": 2098.48,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "the the more overlap and meaning there",
      "offset": 2100.96,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "is between the documents. And so this",
      "offset": 2102.64,
      "duration": 4.719
    },
    {
      "lang": "en",
      "text": "allows us then in real time to take the",
      "offset": 2105.2,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "user's natural language query map it",
      "offset": 2107.359,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "into that same highdimensional space but",
      "offset": 2109.359,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "you can imagine it's three dimensions.",
      "offset": 2111.839,
      "duration": 2.721
    },
    {
      "lang": "en",
      "text": "When I say highdimensional I mean",
      "offset": 2113.359,
      "duration": 3.361
    },
    {
      "lang": "en",
      "text": "hundreds or thousands of dimensions",
      "offset": 2114.56,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "which you can't visualize uh but which",
      "offset": 2116.72,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "but for which the linear algebra is",
      "offset": 2119.68,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "basically identical for a computer",
      "offset": 2121.76,
      "duration": 3.359
    },
    {
      "lang": "en",
      "text": "relative to a two or three dimensional",
      "offset": 2123.599,
      "duration": 4.641
    },
    {
      "lang": "en",
      "text": "space that you can visualize. Um, and so",
      "offset": 2125.119,
      "duration": 4.801
    },
    {
      "lang": "en",
      "text": "yeah, so we take the natural language",
      "offset": 2128.24,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "query that a user makes to the rag",
      "offset": 2129.92,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "system. We can convert that into the",
      "offset": 2132.16,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "same highdimensional space, find its",
      "offset": 2134.24,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "location, and then retrieve the",
      "offset": 2136.4,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "documents like you talked about, kind of",
      "offset": 2138.24,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "a a cheap fast um first retrieval step,",
      "offset": 2139.76,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "which could be something like I'm just",
      "offset": 2143.76,
      "duration": 3.599
    },
    {
      "lang": "en",
      "text": "describing where we take the closest",
      "offset": 2144.96,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "documents to wherever the query gets",
      "offset": 2147.359,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "mapped to in the high dimensional space.",
      "offset": 2149.92,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "Uh, and then we can do more complex",
      "offset": 2151.839,
      "duration": 2.721
    },
    {
      "lang": "en",
      "text": "processing after that, but that kind of",
      "offset": 2153.28,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "gives us our initial results. And so",
      "offset": 2154.56,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "doing that is very very fast. You know",
      "offset": 2156.4,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "we only need to convert one query which",
      "offset": 2159.68,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "might be short into the you know a",
      "offset": 2162.16,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "coordinate in a high dimensional space",
      "offset": 2164.96,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "and then we could use a very fast",
      "offset": 2166.64,
      "duration": 4.479
    },
    {
      "lang": "en",
      "text": "mathematical operation like a cosine",
      "offset": 2168.32,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "similarity score uh to find the closest",
      "offset": 2171.119,
      "duration": 6.561
    },
    {
      "lang": "en",
      "text": "documents in that space and uh that's",
      "offset": 2173.76,
      "duration": 6.64
    },
    {
      "lang": "en",
      "text": "all computationally very inexpensive",
      "offset": 2177.68,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "very fast. you can it allows the rag",
      "offset": 2180.4,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "system to work in real time even over",
      "offset": 2182.72,
      "duration": 3.359
    },
    {
      "lang": "en",
      "text": "like you said you know billions of",
      "offset": 2184.64,
      "duration": 7.6
    },
    {
      "lang": "en",
      "text": "documents um and yeah in contrast if all",
      "offset": 2186.079,
      "duration": 9.681
    },
    {
      "lang": "en",
      "text": "of that text if our millions or billions",
      "offset": 2192.24,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "of documents were in the context of an",
      "offset": 2195.76,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "LLM even if it all fits in you'd then",
      "offset": 2197.52,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "have instead of this computationally",
      "offset": 2200.88,
      "duration": 4.239
    },
    {
      "lang": "en",
      "text": "simple uh calculation this fast",
      "offset": 2202.64,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "calculation you would have to have tons",
      "offset": 2205.119,
      "duration": 5.201
    },
    {
      "lang": "en",
      "text": "and tons of really high-end GPUs",
      "offset": 2207.68,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "stunning to comb across all of the",
      "offset": 2210.32,
      "duration": 5.279
    },
    {
      "lang": "en",
      "text": "meaning in that huge context window. So",
      "offset": 2212.72,
      "duration": 6.24
    },
    {
      "lang": "en",
      "text": "yeah, uh you correct me if I",
      "offset": 2215.599,
      "duration": 5.441
    },
    {
      "lang": "en",
      "text": "No, absolutely. And what you described",
      "offset": 2218.96,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "here commonly known also as semantic",
      "offset": 2221.04,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "search because you you can really search",
      "offset": 2223.04,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "based on the meaning of of a query to to",
      "offset": 2225.359,
      "duration": 6.081
    },
    {
      "lang": "en",
      "text": "add to your point often even for for",
      "offset": 2228.56,
      "duration": 4.559
    },
    {
      "lang": "en",
      "text": "commercial systems it is still the case",
      "offset": 2231.44,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "that you rely on on keyword retrieval",
      "offset": 2233.119,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "just because it's it's even cheaper it's",
      "offset": 2235.839,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "even faster. There are techniques from",
      "offset": 2237.52,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "the early 90s or even late 80s that are",
      "offset": 2239.359,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "still around just because they're so",
      "offset": 2241.92,
      "duration": 2.96
    },
    {
      "lang": "en",
      "text": "computationally efficient because you",
      "offset": 2243.44,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "really want the retrieval to be as cheap",
      "offset": 2244.88,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "as possible. And uh often you use",
      "offset": 2246.56,
      "duration": 6.24
    },
    {
      "lang": "en",
      "text": "semantic search for for the more toned",
      "offset": 2249.68,
      "duration": 5.439
    },
    {
      "lang": "en",
      "text": "down for the you do a first pass keyword",
      "offset": 2252.8,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "retrieval. You do a second pass semantic",
      "offset": 2255.119,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "search within the keyword retrieved",
      "offset": 2257.2,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "steps. So there's a lot of engineering",
      "offset": 2259.28,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "over the years that has been developed",
      "offset": 2261.119,
      "duration": 3.041
    },
    {
      "lang": "en",
      "text": "to just get this retrieval step as",
      "offset": 2262.64,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "efficient as possible. And we're still a",
      "offset": 2264.16,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "while away from large language models",
      "offset": 2266.96,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "being able to do anything even remotely",
      "offset": 2268.64,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "as as efficient as as this step. And as",
      "offset": 2270.4,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "you said, this this can lead to a",
      "offset": 2272.88,
      "duration": 4.239
    },
    {
      "lang": "en",
      "text": "massive use of of GPU power for",
      "offset": 2274.72,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "something that you can solve otherwise.",
      "offset": 2277.119,
      "duration": 5.361
    },
    {
      "lang": "en",
      "text": "And again, grounding this in in the",
      "offset": 2280.24,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "individual end user experience. It could",
      "offset": 2282.48,
      "duration": 5.119
    },
    {
      "lang": "en",
      "text": "be that in the future you someone does a",
      "offset": 2284.4,
      "duration": 4.959
    },
    {
      "lang": "en",
      "text": "side-by-side comparison, right? I do",
      "offset": 2287.599,
      "duration": 3.441
    },
    {
      "lang": "en",
      "text": "this really expensive process where I",
      "offset": 2289.359,
      "duration": 2.881
    },
    {
      "lang": "en",
      "text": "just pipe everything into a large",
      "offset": 2291.04,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "language model. I do a cheap process and",
      "offset": 2292.24,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "it could be that in terms of",
      "offset": 2294.8,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "helpfulness, users actually prefer the",
      "offset": 2296.16,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "one that's snappy and fast rather than",
      "offset": 2298.16,
      "duration": 3.679
    },
    {
      "lang": "en",
      "text": "the one that's maybe five points more",
      "offset": 2300.079,
      "duration": 4.881
    },
    {
      "lang": "en",
      "text": "more accurate in the end. Uh this is all",
      "offset": 2301.839,
      "duration": 5.201
    },
    {
      "lang": "en",
      "text": "something we need to evaluate in the end",
      "offset": 2304.96,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "and those are all design decisions that",
      "offset": 2307.04,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "are all being evaluated all around the",
      "offset": 2308.56,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "globe right now as people are building",
      "offset": 2310.56,
      "duration": 5.279
    },
    {
      "lang": "en",
      "text": "their own genai and rack solutions.",
      "offset": 2311.92,
      "duration": 6.8
    },
    {
      "lang": "en",
      "text": "Speaking of snappy and fast, uh we've",
      "offset": 2315.839,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "talked now about context context window",
      "offset": 2318.72,
      "duration": 4.879
    },
    {
      "lang": "en",
      "text": "length. Um, how about model size? That's",
      "offset": 2321.599,
      "duration": 2.881
    },
    {
      "lang": "en",
      "text": "something that we haven't talked about",
      "offset": 2323.599,
      "duration": 3.281
    },
    {
      "lang": "en",
      "text": "yet. So, um, I know that you",
      "offset": 2324.48,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "investigated in your paper differences",
      "offset": 2326.88,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "between small models and larger ones in",
      "offset": 2328.88,
      "duration": 4.479
    },
    {
      "lang": "en",
      "text": "rag contexts. What did you find?",
      "offset": 2331.04,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "There are differences and generally what",
      "offset": 2333.359,
      "duration": 4.961
    },
    {
      "lang": "en",
      "text": "we found is if a model is is safer from",
      "offset": 2336,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "the get-go, even without rag, it tends",
      "offset": 2338.32,
      "duration": 6.48
    },
    {
      "lang": "en",
      "text": "to be more robust to to adding rag. Um,",
      "offset": 2341.2,
      "duration": 6.08
    },
    {
      "lang": "en",
      "text": "a large factor on this of this is the",
      "offset": 2344.8,
      "duration": 5.039
    },
    {
      "lang": "en",
      "text": "cont is the model size or the model",
      "offset": 2347.28,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "capability in general. I I think at this",
      "offset": 2349.839,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "point model sizes are a little bit of a",
      "offset": 2352.32,
      "duration": 3.279
    },
    {
      "lang": "en",
      "text": "misnomer because we have so many models",
      "offset": 2353.92,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "that rely on mixture of experts and that",
      "offset": 2355.599,
      "duration": 4.881
    },
    {
      "lang": "en",
      "text": "that have architectural advantages that",
      "offset": 2357.839,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "even though on paper they have more",
      "offset": 2360.48,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "parameters, they actually are using",
      "offset": 2362.16,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "fewer of them when you actually run them",
      "offset": 2364.8,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "live. So it's very hard nowadays to",
      "offset": 2366.48,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "actually compare uh the parameters and",
      "offset": 2368.56,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "we often compare based on active",
      "offset": 2371.68,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "parameters or there might be ways in",
      "offset": 2373.2,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "which models are compressed which again",
      "offset": 2375.44,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "changes the the representational power",
      "offset": 2376.96,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "but generally speaking",
      "offset": 2379.44,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "to answer your question is yeah we we",
      "offset": 2381.92,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "found that models from the get-go safer",
      "offset": 2383.68,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "they they are also harder to break",
      "offset": 2385.839,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "through rag although we found that",
      "offset": 2387.68,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "basically every every system was",
      "offset": 2389.119,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "breakable regardless of whether small or",
      "offset": 2390.8,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "large and uh I I think we specifically",
      "offset": 2393.04,
      "duration": 6.559
    },
    {
      "lang": "en",
      "text": "call Lama for for being relatively safer",
      "offset": 2396.32,
      "duration": 6.96
    },
    {
      "lang": "en",
      "text": "than many others. Uh both both Llama 70B",
      "offset": 2399.599,
      "duration": 5.841
    },
    {
      "lang": "en",
      "text": "and and",
      "offset": 2403.28,
      "duration": 6.079
    },
    {
      "lang": "en",
      "text": "7B, but Llama 70B I believe was a little",
      "offset": 2405.44,
      "duration": 6.8
    },
    {
      "lang": "en",
      "text": "bit better than than 7B even. Um",
      "offset": 2409.359,
      "duration": 5.121
    },
    {
      "lang": "en",
      "text": "although again it's it can change from",
      "offset": 2412.24,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "time to time because what we found",
      "offset": 2414.48,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "really was the the the guardrails were",
      "offset": 2416.8,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "broken because of this increased context",
      "offset": 2419.68,
      "duration": 3.679
    },
    {
      "lang": "en",
      "text": "length. It could be that once the next",
      "offset": 2421.2,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "generation of this model comes out that",
      "offset": 2423.359,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "this is being prevented that this that",
      "offset": 2425.28,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "there's an active component of the post-",
      "offset": 2427.119,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "training of the alignment step that",
      "offset": 2429.599,
      "duration": 4.641
    },
    {
      "lang": "en",
      "text": "looks at how can someone use this with a",
      "offset": 2431.52,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "longer context and our exact setup could",
      "offset": 2434.24,
      "duration": 5.119
    },
    {
      "lang": "en",
      "text": "be one of those test cases where you can",
      "offset": 2437.28,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "just continue training the model on and",
      "offset": 2439.359,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "we'll just inherently pro protect",
      "offset": 2441.359,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "against this particular angle of attack.",
      "offset": 2443.76,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "Nicely said. Uh I've learned a ton from",
      "offset": 2445.76,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "you in this episode so far. We still",
      "offset": 2448,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "have a little bit to go. Um, so I'm",
      "offset": 2449.68,
      "duration": 7.52
    },
    {
      "lang": "en",
      "text": "excited for that. Um, I'm curious is",
      "offset": 2452.4,
      "duration": 6.8
    },
    {
      "lang": "en",
      "text": "what what's the effect of refusing to",
      "offset": 2457.2,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "answer in in these? So you um so it",
      "offset": 2459.2,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "sounds like it's clear that bigger",
      "offset": 2463.2,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "models are generally better uh you know",
      "offset": 2465.2,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "they're more capable uh they fare better",
      "offset": 2467.28,
      "duration": 5.039
    },
    {
      "lang": "en",
      "text": "in red contexts generally speaking. Uh",
      "offset": 2469.68,
      "duration": 7.6
    },
    {
      "lang": "en",
      "text": "to what extent um is refusal to answer a",
      "offset": 2472.319,
      "duration": 6.561
    },
    {
      "lang": "en",
      "text": "you know how does that factor into these",
      "offset": 2477.28,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "kinds of assessments? In your paper, you",
      "offset": 2478.88,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "called out Gemma 7B uh in particular uh",
      "offset": 2480.64,
      "duration": 6.24
    },
    {
      "lang": "en",
      "text": "for showing low unsafe outputs, but",
      "offset": 2484.48,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "largely because it refused to answer",
      "offset": 2486.88,
      "duration": 2.16
    },
    {
      "lang": "en",
      "text": "questions.",
      "offset": 2488.4,
      "duration": 2.48
    },
    {
      "lang": "en",
      "text": "Yeah. So, so there are a couple of",
      "offset": 2489.04,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "different considerations here. If you",
      "offset": 2490.88,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "just refuse to answer, it could be",
      "offset": 2493.119,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "because you don't know. Um or it could",
      "offset": 2495.44,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "be because you actively",
      "offset": 2498.079,
      "duration": 6.081
    },
    {
      "lang": "en",
      "text": "find the input to be unsafe.",
      "offset": 2500.4,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "And if you can't distinguish between",
      "offset": 2504.16,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "them, it's very hard to know whether",
      "offset": 2506.16,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "well your model is just bad or whether",
      "offset": 2507.92,
      "duration": 6.08
    },
    {
      "lang": "en",
      "text": "it's unsafe or safe in this case. Um so",
      "offset": 2510.64,
      "duration": 5.679
    },
    {
      "lang": "en",
      "text": "model sizes and model capabilities again",
      "offset": 2514,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "they're all so intricately linked where",
      "offset": 2516.319,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "you want to build a system that is",
      "offset": 2518.96,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "helpful. So you always need to pair an",
      "offset": 2520.4,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "analysis like ours with one that",
      "offset": 2522.96,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "actually evaluates the how helpful the",
      "offset": 2525.2,
      "duration": 6.08
    },
    {
      "lang": "en",
      "text": "model is. And if in the end you you call",
      "offset": 2527.52,
      "duration": 6.48
    },
    {
      "lang": "en",
      "text": "Gemma here, if in the end Gemma is also",
      "offset": 2531.28,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "refusing to answer completely safe",
      "offset": 2534,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "questions and is completely safe and",
      "offset": 2536,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "correct rack setup, it's not going to be",
      "offset": 2538,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "helpful. So even though it is harmless,",
      "offset": 2540.56,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "it it still would not be able to be",
      "offset": 2542.88,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "used. Um so that that's I think just",
      "offset": 2544.8,
      "duration": 5.039
    },
    {
      "lang": "en",
      "text": "highlighting the the need for having a",
      "offset": 2547.52,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "multifaceted evaluation. You need to",
      "offset": 2549.839,
      "duration": 4.561
    },
    {
      "lang": "en",
      "text": "consider those. Similarly to how model",
      "offset": 2552.16,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "sizes will also affect latency and and",
      "offset": 2554.4,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "cost of running a system. It could be",
      "offset": 2556.64,
      "duration": 4.719
    },
    {
      "lang": "en",
      "text": "that the fast cheap small model is",
      "offset": 2558.96,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "completely up to the task. And in that",
      "offset": 2561.359,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "case, why would I use this completely",
      "offset": 2563.2,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "overblown model to do that same task",
      "offset": 2565.44,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "just because uh it is performing better",
      "offset": 2567.52,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "on on things that are completely not",
      "offset": 2570.24,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "relevant to your particular application.",
      "offset": 2572.16,
      "duration": 6.24
    },
    {
      "lang": "en",
      "text": "Nice. Nice. Um so changing gears now a",
      "offset": 2574.16,
      "duration": 8.159
    },
    {
      "lang": "en",
      "text": "fair bit. Um there's a second paper that",
      "offset": 2578.4,
      "duration": 7.52
    },
    {
      "lang": "en",
      "text": "you also recently published. So uh",
      "offset": 2582.319,
      "duration": 6.241
    },
    {
      "lang": "en",
      "text": "you're first author on a paper that was",
      "offset": 2585.92,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "uh submitted to archive in April called",
      "offset": 2588.56,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "understanding and mitigating risks of",
      "offset": 2590.96,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "generative AI in financial services. Um",
      "offset": 2592.88,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "so mostly so far in this episode we've",
      "offset": 2596.24,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "been talking about uh general you know",
      "offset": 2598.24,
      "duration": 6.24
    },
    {
      "lang": "en",
      "text": "generally how models fare under rag but",
      "offset": 2601.52,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "in that paper um it's related to risk of",
      "offset": 2604.48,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "genai and finance you emphasize that",
      "offset": 2607.04,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "most foundation models are not trained",
      "offset": 2608.72,
      "duration": 4.879
    },
    {
      "lang": "en",
      "text": "on finance specific corporate uh bodies",
      "offset": 2610.8,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "of knowledge. So, uh, what are the",
      "offset": 2613.599,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "limitations this creates? Um, you know,",
      "offset": 2616,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "for for LLMs in general, but",
      "offset": 2619.359,
      "duration": 5.841
    },
    {
      "lang": "en",
      "text": "particularly for RAG and I'm assuming",
      "offset": 2621.2,
      "duration": 6.159
    },
    {
      "lang": "en",
      "text": "that this same kind of sentiment, you",
      "offset": 2625.2,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "know, you looked at it with finance",
      "offset": 2627.359,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "specifically because Bloomberg is, you",
      "offset": 2628.64,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "know, you know, as a financial services",
      "offset": 2631.2,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "company largely. Uh, but do you think",
      "offset": 2633.44,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "that the same kind of limitation would",
      "offset": 2635.52,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "apply in other uh sectors as well?",
      "offset": 2636.96,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "Yeah, absolutely. Um so yeah I g g g g g",
      "offset": 2639.52,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "g g g g g g g g g g g g g g g gave a",
      "offset": 2642.72,
      "duration": 1.52
    },
    {
      "lang": "en",
      "text": "little bit of a teaser of this paper",
      "offset": 2643.04,
      "duration": 3.039
    },
    {
      "lang": "en",
      "text": "earlier and an answer as well and and",
      "offset": 2644.24,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "what uh the way that we wrote our paper",
      "offset": 2646.079,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "very much should be seen as a as a case",
      "offset": 2649.04,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "study. Finance here or financial",
      "offset": 2651.119,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "services in particular capital markets",
      "offset": 2652.72,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "and asset management is the case study",
      "offset": 2655.04,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "that we use to make the point that we",
      "offset": 2657.76,
      "duration": 5.359
    },
    {
      "lang": "en",
      "text": "really need to think about risk and risk",
      "offset": 2660.8,
      "duration": 5.92
    },
    {
      "lang": "en",
      "text": "taxonomies and risk management in in our",
      "offset": 2663.119,
      "duration": 6.081
    },
    {
      "lang": "en",
      "text": "domain in what we are trying to build.",
      "offset": 2666.72,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "And as you say, we made the point, yeah,",
      "offset": 2669.2,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "models are not necessarily trained on on",
      "offset": 2672,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "financial domains. We see that both in",
      "offset": 2674.8,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "helpfulness and the harmlessness angle.",
      "offset": 2676.64,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "Often, you know, complex financial tasks",
      "offset": 2679.2,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "are not being able to be sufficiently",
      "offset": 2681.2,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "handled by large language models by",
      "offset": 2683.04,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "themselves. But also in our paper we",
      "offset": 2684.4,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "make the point that even safeguards that",
      "offset": 2686.8,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "are dedicated models or systems to",
      "offset": 2689.04,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "provide these these kind of first pass",
      "offset": 2692.56,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "like is this safe is this unsafe",
      "offset": 2694.8,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "judgment they're also not trained on",
      "offset": 2696.24,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "financial services and if you use them",
      "offset": 2698.56,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "out of the box and say look I use llama",
      "offset": 2700.48,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "guard I use shield jama I use ais I'm",
      "offset": 2702.96,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "safe now right you're protected against",
      "offset": 2705.44,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "a particular view of safety that is very",
      "offset": 2708.16,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "much grounded in in in",
      "offset": 2710.72,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "uh categories that are relevant to broad",
      "offset": 2713.92,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "populations to to things like chat bots",
      "offset": 2715.92,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "that help you do productivity day-to-day",
      "offset": 2718.079,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "tasks. The typical applications that you",
      "offset": 2720,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "would see in in those AI productivity",
      "offset": 2722.079,
      "duration": 4.481
    },
    {
      "lang": "en",
      "text": "tools, no matter which one you use, they",
      "offset": 2724.16,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "all have similar mechanisms, but those",
      "offset": 2726.56,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "are not necessarily the same risks that",
      "offset": 2729.04,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "we are under in financial services.",
      "offset": 2730.88,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "Those are not the same obligations that",
      "offset": 2732.56,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "uh companies, organizations in",
      "offset": 2735.28,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "healthcare are under or law or any other",
      "offset": 2737.28,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "highly domain specific knowledge",
      "offset": 2739.92,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "intensive domain. uh that that has a lot",
      "offset": 2742.4,
      "duration": 4.719
    },
    {
      "lang": "en",
      "text": "of specific regulation, jurisdiction",
      "offset": 2745.2,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "specific regulation, considerations",
      "offset": 2747.119,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "about whether just refusing to answer or",
      "offset": 2749.119,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "giving disclaimers is enough or whether",
      "offset": 2751.52,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "questions should be blocked altogether.",
      "offset": 2753.839,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "And there's just this different of",
      "offset": 2756,
      "duration": 3.119
    },
    {
      "lang": "en",
      "text": "difference of view that can't be",
      "offset": 2757.599,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "capsulated in a single model that a",
      "offset": 2759.119,
      "duration": 6.24
    },
    {
      "lang": "en",
      "text": "provider can can give that very much is",
      "offset": 2761.68,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "focused on a different use case.",
      "offset": 2765.359,
      "duration": 4.881
    },
    {
      "lang": "en",
      "text": "Nice. Yeah. So I I don't know do you",
      "offset": 2767.44,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "have do you have guidance for us you",
      "offset": 2770.24,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "know if we're if we're trying to select",
      "offset": 2772.48,
      "duration": 6.4
    },
    {
      "lang": "en",
      "text": "an LLM for a particular use case um what",
      "offset": 2774.72,
      "duration": 5.84
    },
    {
      "lang": "en",
      "text": "do you recommend we do I mean like",
      "offset": 2778.88,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "practically",
      "offset": 2780.56,
      "duration": 3.519
    },
    {
      "lang": "en",
      "text": "how can we move forward with all the",
      "offset": 2782.56,
      "duration": 2.88
    },
    {
      "lang": "en",
      "text": "information that you provided in this",
      "offset": 2784.079,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "episode in selecting an LLM for a",
      "offset": 2785.44,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "particular use case for a particular",
      "offset": 2787.76,
      "duration": 3.599
    },
    {
      "lang": "en",
      "text": "domain particularly if we want to be",
      "offset": 2789.28,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "applying it uh in rag situations.",
      "offset": 2791.359,
      "duration": 5.121
    },
    {
      "lang": "en",
      "text": "Yeah. So in in our paper we we also have",
      "offset": 2793.92,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "a list of of best practices and",
      "offset": 2796.48,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "recommendations that we have for",
      "offset": 2798.56,
      "duration": 3.279
    },
    {
      "lang": "en",
      "text": "especially for knowledge intensive",
      "offset": 2800.16,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "domains and regulationheavy domains. Uh",
      "offset": 2801.839,
      "duration": 5.601
    },
    {
      "lang": "en",
      "text": "not necessarily everything has to be",
      "offset": 2804.48,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "followed if you're building something",
      "offset": 2807.44,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "for for a much broader general",
      "offset": 2808.72,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "population. Um but especially for these",
      "offset": 2810.48,
      "duration": 6.16
    },
    {
      "lang": "en",
      "text": "kinds of domains all I can do is spray",
      "offset": 2813.119,
      "duration": 5.281
    },
    {
      "lang": "en",
      "text": "my mantra evaluate the system in the",
      "offset": 2816.64,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "context that it's deployed in. If you",
      "offset": 2818.4,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "are building something for healthcare,",
      "offset": 2820.8,
      "duration": 3.039
    },
    {
      "lang": "en",
      "text": "well, you better evaluate it in the",
      "offset": 2822.4,
      "duration": 2.8
    },
    {
      "lang": "en",
      "text": "context of healthare. If you are",
      "offset": 2823.839,
      "duration": 2.641
    },
    {
      "lang": "en",
      "text": "building in the context of financial",
      "offset": 2825.2,
      "duration": 2.8
    },
    {
      "lang": "en",
      "text": "services, you better evaluate your",
      "offset": 2826.48,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "subject matter experts in financial",
      "offset": 2828,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "services. And specifically on the safety",
      "offset": 2829.68,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "angle, our paper makes a couple",
      "offset": 2832.8,
      "duration": 3.519
    },
    {
      "lang": "en",
      "text": "suggestions here. There are very good",
      "offset": 2834.56,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "starting points. There are taxonomies",
      "offset": 2836.319,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "such as the NISK NIST risk management",
      "offset": 2838.24,
      "duration": 5.839
    },
    {
      "lang": "en",
      "text": "framework for AI. There are",
      "offset": 2840.72,
      "duration": 5.599
    },
    {
      "lang": "en",
      "text": "other other industry collaborations",
      "offset": 2844.079,
      "duration": 5.201
    },
    {
      "lang": "en",
      "text": "going ongoing. There's ML Commons. Those",
      "offset": 2846.319,
      "duration": 6.081
    },
    {
      "lang": "en",
      "text": "all provide more general purpose",
      "offset": 2849.28,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "taxonomies, but but just taking them as",
      "offset": 2852.4,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "a starting point and then from there",
      "offset": 2854.48,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "adjusting them to your domain can often",
      "offset": 2855.92,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "save a lot of time. And especially if",
      "offset": 2858.319,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "you're a large organization with a",
      "offset": 2860.96,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "compliance or risk department, it will",
      "offset": 2862.319,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "help them also understand how one can",
      "offset": 2864.72,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "classify and then categorize these kinds",
      "offset": 2867.119,
      "duration": 4.641
    },
    {
      "lang": "en",
      "text": "of risks. Another recommendation we make",
      "offset": 2869.04,
      "duration": 6.24
    },
    {
      "lang": "en",
      "text": "is uh is to organize red teaming events",
      "offset": 2871.76,
      "duration": 6.24
    },
    {
      "lang": "en",
      "text": "and or do any other kind of red teaming.",
      "offset": 2875.28,
      "duration": 4.559
    },
    {
      "lang": "en",
      "text": "Red teaming in this case is is this",
      "offset": 2878,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "practice that had it start in the cold",
      "offset": 2879.839,
      "duration": 5.041
    },
    {
      "lang": "en",
      "text": "war where you have uh users trying to be",
      "offset": 2881.76,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "malicious. So we get people in the same",
      "offset": 2884.88,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "room and we say look for the next couple",
      "offset": 2887.04,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "hours try and break the system try and",
      "offset": 2888.88,
      "duration": 5.199
    },
    {
      "lang": "en",
      "text": "play evil. Uh here are some instructions",
      "offset": 2891.44,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "on how to do this and then afterwards we",
      "offset": 2894.079,
      "duration": 3.121
    },
    {
      "lang": "en",
      "text": "can look how often was this actually",
      "offset": 2895.52,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "broken? How often did the system give",
      "offset": 2897.2,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "financial advice? How often uh did it",
      "offset": 2898.88,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "refuse? And from there we can quantify",
      "offset": 2901.28,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "the risk surface. Since we're talking we",
      "offset": 2904.24,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "were talking earlier about this unknown",
      "offset": 2906.24,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "risk surface, well just measure it and",
      "offset": 2908,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "then you have it. Uh so that's kind of",
      "offset": 2910.319,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "the the main takeaway that we have. We",
      "offset": 2912.319,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "gave give pretty specific advice for how",
      "offset": 2913.92,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "to go about this and how to set up risk",
      "offset": 2916.079,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "management frameworks and all this needs",
      "offset": 2917.76,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "to go hand inand also with again this",
      "offset": 2920,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "this evaluate in the context it's",
      "offset": 2922.079,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "applied. Make sure you invest a lot in",
      "offset": 2924,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "evaluation. Don't just take the word of",
      "offset": 2926.079,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "of the large native model providers that",
      "offset": 2928.079,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "their benchmark scores are going to",
      "offset": 2930.48,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "translate into the all all the",
      "offset": 2932,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "downstream applications. And if you",
      "offset": 2933.68,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "follow that advice, you're going to have",
      "offset": 2935.76,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "a system that is in the end much more",
      "offset": 2937.2,
      "duration": 5.119
    },
    {
      "lang": "en",
      "text": "trustworthy, reliable, robust, and",
      "offset": 2939.04,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "you're going to have users that are",
      "offset": 2942.319,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "going to keep using it rather than",
      "offset": 2943.76,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "trying it twice, getting uh really bad",
      "offset": 2945.359,
      "duration": 4.801
    },
    {
      "lang": "en",
      "text": "answers both times, and never touching",
      "offset": 2948.64,
      "duration": 2.08
    },
    {
      "lang": "en",
      "text": "it again.",
      "offset": 2950.16,
      "duration": 2.48
    },
    {
      "lang": "en",
      "text": "Perfect. That's a great sound bite at",
      "offset": 2950.72,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "the end there. I'm sure we'll be making",
      "offset": 2952.64,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "it into a YouTube short.",
      "offset": 2954,
      "duration": 5.839
    },
    {
      "lang": "en",
      "text": "Um, so before I let you go, uh, we are",
      "offset": 2956.48,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "pretty much out of time here, but, uh, I",
      "offset": 2959.839,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "always ask my guests for a book",
      "offset": 2962.24,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "recommendation, uh, before they leave",
      "offset": 2964,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "the podcast episode, and I usually give",
      "offset": 2965.76,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "guests a warning, but we rush into",
      "offset": 2967.52,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "recording and I forgot to tell you. So,",
      "offset": 2969.52,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "uh, hopefully you have something on hand",
      "offset": 2972,
      "duration": 2.4
    },
    {
      "lang": "en",
      "text": "in your mind. It doesn't need to be",
      "offset": 2973.28,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "something AI related necessarily.",
      "offset": 2974.4,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "All right, I'm going to, uh, give you",
      "offset": 2976.72,
      "duration": 3.359
    },
    {
      "lang": "en",
      "text": "the recommendation of a book that's",
      "offset": 2978.72,
      "duration": 2.639
    },
    {
      "lang": "en",
      "text": "currently sitting right here on my",
      "offset": 2980.079,
      "duration": 3.121
    },
    {
      "lang": "en",
      "text": "table, um, which I'm reading right now,",
      "offset": 2981.359,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "which is The Unaccountability Machine.",
      "offset": 2983.2,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "It just came out a couple months ago. It",
      "offset": 2984.96,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "talks about how organizations are",
      "offset": 2987.2,
      "duration": 6.639
    },
    {
      "lang": "en",
      "text": "failing to build processes uh that uh",
      "offset": 2990,
      "duration": 6.079
    },
    {
      "lang": "en",
      "text": "that act as accountability syncs. If",
      "offset": 2993.839,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "you've ever talked to customer service",
      "offset": 2996.079,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "and you couldn't escalate and the rep",
      "offset": 2997.359,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "you talked to couldn't solve your",
      "offset": 2999.599,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "problem, you're screwed. This book is",
      "offset": 3001.2,
      "duration": 4.639
    },
    {
      "lang": "en",
      "text": "talking about why from a cybernetic",
      "offset": 3003.68,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "perspective uh this is a bad design and",
      "offset": 3005.839,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "how to set up organizations and and",
      "offset": 3008,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "processes that can help this which is",
      "offset": 3009.76,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "also applicable to AI because you want",
      "offset": 3011.92,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "to know if something gets blocked but",
      "offset": 3013.839,
      "duration": 3.201
    },
    {
      "lang": "en",
      "text": "you really need the answer where do I go",
      "offset": 3015.28,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "how do I escalate a great recommendation",
      "offset": 3017.04,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "there Sebastian thank you and then final",
      "offset": 3019.119,
      "duration": 3.761
    },
    {
      "lang": "en",
      "text": "question for you is how should people",
      "offset": 3021.359,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "follow you after this episode I learned",
      "offset": 3022.88,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "a ton from you I love the way you",
      "offset": 3025.2,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "explain information how can people",
      "offset": 3027.2,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "continue to get your thoughts after this",
      "offset": 3029.119,
      "duration": 3.121
    },
    {
      "lang": "en",
      "text": "episode",
      "offset": 3031.28,
      "duration": 2.319
    },
    {
      "lang": "en",
      "text": "right you You can follow our",
      "offset": 3032.24,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "publications on our blog called Tech at",
      "offset": 3033.599,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "Bloomberg. You can follow me personally",
      "offset": 3036,
      "duration": 5.92
    },
    {
      "lang": "en",
      "text": "on X or Blue Sky.",
      "offset": 3037.76,
      "duration": 5.92
    },
    {
      "lang": "en",
      "text": "So just the first letters of both of my",
      "offset": 3041.92,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "names just because it's a little bit",
      "offset": 3043.68,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "long or obviously on LinkedIn.",
      "offset": 3045.04,
      "duration": 3.519
    },
    {
      "lang": "en",
      "text": "Yeah. The first syllables.",
      "offset": 3047.2,
      "duration": 2.56
    },
    {
      "lang": "en",
      "text": "The first syllables even. Yes.",
      "offset": 3048.559,
      "duration": 3.441
    },
    {
      "lang": "en",
      "text": "Yeah. Yeah. Yeah. Uh it'd be amazing if",
      "offset": 3049.76,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "you got SG on",
      "offset": 3052,
      "duration": 2.24
    },
    {
      "lang": "en",
      "text": "I tried",
      "offset": 3053.68,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "on either. Uh yeah, it's it's nice. You",
      "offset": 3054.24,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "know, I it's been a while since I've",
      "offset": 3057.28,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "heard a blue sky one. uh because it seem",
      "offset": 3059.28,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "like yeah it seems like most guests",
      "offset": 3062.48,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "these days are focused on LinkedIn uh",
      "offset": 3064.4,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "but uh it's great to hear you know I",
      "offset": 3067.2,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "actually I'm really rooting for blue sky",
      "offset": 3069.76,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "me too and we'll see what comes out of",
      "offset": 3071.52,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "it a lot of academics have moved over so",
      "offset": 3073.599,
      "duration": 5.121
    },
    {
      "lang": "en",
      "text": "I I have to at this point still follow X",
      "offset": 3075.839,
      "duration": 5.361
    },
    {
      "lang": "en",
      "text": "and Blue Sky at the same time to get my",
      "offset": 3078.72,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "deep technical news but we'll we'll see",
      "offset": 3081.2,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "how it develops in the future.",
      "offset": 3083.68,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "Nice. All right, thank you so much",
      "offset": 3085.44,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "Sebastian. Uh yeah, and hopefully we can",
      "offset": 3086.96,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "get you on the show again in the future",
      "offset": 3089.28,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "when you have some more brilliant",
      "offset": 3090.72,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "research insights for us.",
      "offset": 3092.48,
      "duration": 5.32
    },
    {
      "lang": "en",
      "text": "Thank you so much for having me.",
      "offset": 3093.76,
      "duration": 4.04
    },
    {
      "lang": "en",
      "text": "What a great guest Dr. Sebastian Garman",
      "offset": 3100.079,
      "duration": 4.561
    },
    {
      "lang": "en",
      "text": "was. In today's episode, he covered how",
      "offset": 3102.319,
      "duration": 4.561
    },
    {
      "lang": "en",
      "text": "rag can circumvent built-in safety",
      "offset": 3104.64,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "mechanisms in LLM. While rag reduces",
      "offset": 3106.88,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "hallucinations, improving honesty, it",
      "offset": 3109.92,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "can compromise harmlessness. How",
      "offset": 3112,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "organizations must evaluate AI systems",
      "offset": 3114.16,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "in their specific deployment context",
      "offset": 3116.16,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "because general purpose safety measures",
      "offset": 3118.079,
      "duration": 3.361
    },
    {
      "lang": "en",
      "text": "often fail for domain specific use",
      "offset": 3119.68,
      "duration": 4.639
    },
    {
      "lang": "en",
      "text": "cases. How effective rag safety requires",
      "offset": 3121.44,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "a guardrail retrieval answer or",
      "offset": 3124.319,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "guardrail architecture, not just vanilla",
      "offset": 3126.48,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "retrieval and generation. And how",
      "offset": 3129.119,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "financial services and other regulated",
      "offset": 3131.04,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "industries need custom risk taxonomies",
      "offset": 3132.8,
      "duration": 4.799
    },
    {
      "lang": "en",
      "text": "and red teaming and redteameing",
      "offset": 3135.04,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "exercises to identify domain specific",
      "offset": 3137.599,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "vulnerabilities. As always, you can get",
      "offset": 3140.4,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "all the show notes, including the",
      "offset": 3142.559,
      "duration": 2.56
    },
    {
      "lang": "en",
      "text": "transcript for this episode, the video",
      "offset": 3143.68,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "recording, any materials mentioned on",
      "offset": 3145.119,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "the show, the URLs for Sebastian's",
      "offset": 3146.72,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "social media profiles, as well as my own",
      "offset": 3149.119,
      "duration": 5.72
    },
    {
      "lang": "en",
      "text": "at superdatcience.com/905.",
      "offset": 3151.52,
      "duration": 3.319
    },
    {
      "lang": "en",
      "text": "Thanks to everyone on the Superdatience",
      "offset": 3155.599,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "podcast team, our podcast manager Sony",
      "offset": 3157.44,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "Bryovich, media editor Mario Pombo, our",
      "offset": 3159.359,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "partnerships team, which is Nathan Daly",
      "offset": 3162,
      "duration": 3.599
    },
    {
      "lang": "en",
      "text": "and Natalie Jysky, our researcher Serge",
      "offset": 3163.599,
      "duration": 5.041
    },
    {
      "lang": "en",
      "text": "Miss, writer Dr. Zara Care, and yes, our",
      "offset": 3165.599,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "great founder Carol Aromanco. Thanks to",
      "offset": 3168.64,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "all of them for producing another",
      "offset": 3171.119,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "exceptional episode for us today for",
      "offset": 3173.04,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "enabling that super team to create this",
      "offset": 3174.96,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "free podcast for you. We are deeply",
      "offset": 3177.04,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "grateful to our sponsors. You can",
      "offset": 3178.96,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "support this show by checking out our",
      "offset": 3180.88,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "sponsors links which are in the show",
      "offset": 3182.64,
      "duration": 4.719
    },
    {
      "lang": "en",
      "text": "notes. Otherwise, share the episode with",
      "offset": 3184.96,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "someone who would like to have it review",
      "offset": 3187.359,
      "duration": 5.121
    },
    {
      "lang": "en",
      "text": "the episode on your favorite podcasting",
      "offset": 3190.16,
      "duration": 6.08
    },
    {
      "lang": "en",
      "text": "platform. Subscribe. Uh, oh, and if you",
      "offset": 3192.48,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "are ever interested in sponsoring an",
      "offset": 3196.24,
      "duration": 2.48
    },
    {
      "lang": "en",
      "text": "episode yourself, you can find out how",
      "offset": 3197.52,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "to do that at johncone.com/mpodcast.",
      "offset": 3198.72,
      "duration": 5.359
    },
    {
      "lang": "en",
      "text": "But most importantly, I just hope you'll",
      "offset": 3201.92,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "keep on tuning in. I'm so grateful to",
      "offset": 3204.079,
      "duration": 2.961
    },
    {
      "lang": "en",
      "text": "have you listening and hope I can",
      "offset": 3205.44,
      "duration": 2.96
    },
    {
      "lang": "en",
      "text": "continue to make episodes you love for",
      "offset": 3207.04,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "years and years to come. Till next time,",
      "offset": 3208.4,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "keep on rocking it out there and I'm",
      "offset": 3210.24,
      "duration": 2.56
    },
    {
      "lang": "en",
      "text": "looking forward to enjoying another",
      "offset": 3211.76,
      "duration": 2.559
    },
    {
      "lang": "en",
      "text": "round of the Super Data Science podcast",
      "offset": 3212.8,
      "duration": 5.64
    },
    {
      "lang": "en",
      "text": "with you very soon.",
      "offset": 3214.319,
      "duration": 4.121
    }
  ],
  "cleanText": "How can we move forward with all the information that you provided in this episode in selecting an LLM for a particular use case? Evaluate the system in the context that it's deployed in. You're going to have a system that is in the end much more trustworthy, reliable, robust, and you're going to have users that are going to keep using it rather than trying it twice, getting uh really bad answers both times and never touching it again. RAG is incredibly powerful. There's a lot of investment from companies that build up language models into increasing the possible context length. But at the same time, increasing the possible context length also requires developing methods and developing the models to actually be able to handle such a context length.\n\n[Music]\n\nDr. Sebastian Gehrmann, welcome to the SuperDataScience Podcast. It's great to have you on the show. Where are you calling in from today?\n\nThank you so much for having me. I'm calling in from Philadelphia.\n\nNice. Uh, it's going to be a scorcher here in New York coming up at the time of recording, heading up to 100° Fahrenheit. I hope uh you're able to stay cool down there.\n\nYeah. Not too much different here. We all got the heat warning yesterday evening and it's going to be a rough couple days.\n\nYeah. Yeah. We'll test the air conditioning systems for the first time this year for sure.\n\nAll right. So, you are the head of responsible AI at Bloomberg, uh, a hugely well-known financial software, data, and media company. Long before you started at Bloomberg, you were researching at the intersection of natural language generation and responsible AI solutions that are trustworthy, transparent, reliable. And now you've kind of brought all those things together with your latest paper, which of course we'll link to in the show notes. It's called RAG LLMs are not safer. Um it's a safety analysis of retrieval augmented generation for Large Language Models. And this finds counterintuitively, and this is the main reason why I wanted to have you on the show, is because it blew my mind when I discovered that RAG actually makes LLMs less safe and their outputs less reliable because my understanding is that it was supposed to be exactly the opposite.\n\nYeah, absolutely. Um yeah I should mention this this was a paper that uh we had an intern work on last year who's been working with colleagues from our co's office and AI engineering organization and uh this was part of our broader responsible AI research uh theme that we have going where we want to make sure that if our clients or our customers use our AI that if they use it for something that they shouldn't that we can identify this we can block this we can monitor this over time which is incredibly important especially for a such heavily regulated industry such as the one that we are operating in. There are so many rules that apply to our clients. They really want to make sure that people can't abuse purposefully or completely accidentally our our technology. So as part of that research direction we were interested in the safety of RAG because in the end RAG is such a ubiquitous technology and it is not it is absolutely necessary to ground responses in trusted sources of data that is there's no way around that if you want to answer questions that are grounded in in this broad and and uh really challenging uh area that we operate in where there's hundreds of billions of of pieces of data coming into our systems every single day. The only way to do this is if you use RAG or some kind of other similar retrieval augmented technology or document grounded technology. So what our paper did was it coupled unsafe queries. So think think of the the worst thing that you might want to ask a large language model, right? How do I do insider trading? And we coupled that with with RAG. So we retrieved completely innocuous documents from Wikipedia and while most large language models that we looked at didn't respond to their original question when coupled with these completely harmless documents from Wikipedia the response was often then unsafe which is why we gave the paper this this title that was very very strong because everyone would has been talking about how RAG makes things more safe they're more grounded they grounded in actual factual information uh rather than using the large language model to kind of make up things. And what we found is that actually your RAG can circumvent these built-in safety mechanisms that that large language model providers put into these models.\n\nI gotcha. I got you. Now I understand. And I guess we should also it occurs to me as we're talking about RAG and probably a lot of listeners out there are aware of what retrieval-augmented generation is, but maybe we should spend just a couple of minutes explaining it as well. Uh I don't know you can you can probably do a better job with this but at a high level it's it's you already kind of gave an example there where you can be using documents from Wikipedia the public internet or it could be you know a common use case with RAG is to have lots of documents internal documents. So you might be a law firm with millions of contracts that uh that your firm has saved from over the years and you could put all of those millions of contracts into a into a RAG type of system and you can search you can use natural language to query over all of those millions of documents. the most relevant ones will be pulled out from the millions. And then you can you could typically fit that small number of documents that's pulled out, maybe it's half a dozen or a dozen into the working memory of a given large language model and then you can have a natural language response uh come out as a result of that. What do you think about my RAG explanation there?\n\nAbsolutely correct. I think just just to put some more color on this um if we're talking about LLM very much this is a technology where at one point in time you train a model and then once you're done training this model it is stuck you freeze the model and you say okay this is the model the knowledge cut off is January 2021 and then if you ask a question that requires knowledge from beyond 2021 the only way that you can get this into the model is by actually providing it in its context. So um researchers a couple years ago when they developed this RAG technique uh for Large Language Models in particular said well the most natural thing to do is to to couple a search system with the large language model language model very good at synthesizing summarizing extracting information but this kind of freeze in time is really bad. um to overcome it we plug in a search tool and that's why it's called retrieval augmented generation or before RAG was was a paper a lot of search engines already gave answer snippets and so at that point it was kind of search enhanced question answering but they all kind of this have become this overall term that we that we use for not just this vanilla setup where we have a retrieval step and a generation step often we we use RAG as kind of the overarching term for anything where you ground a large language model response with some kind of data that you retrieve from somewhere. That could be structured data, it could be unstructured data, it could be unstructured or structured data from multiple different sources. All of these are kind of under this whole umbrella term of retrieval augmented generation, which is why this has become such a big topic to talk about because this is one of the predominant ways in which applications are built.\n\nFor sure. And I I like how you're using this term grounding. I think that that makes a lot of sense. Um, another term that you've used in a recent podcast, um, you were emphasizing that RAG is essential for grounding GenAI products, um, in actual trusted information. However, um, you've described RAG's architecture as creating unpredictable attack surfaces. So, that's kind of the other term that I want to get into here, this idea of attack services. So on the one hand, you know, we need RAG for grounding GenAI products in more recent or in actual trusted information or maybe in confidential information that an enterprise or an organization has. Um but at the same time, this creates these unpredictable attack surfaces. So what the heck are attack surfaces? Yes. So for that, let's let's kind of explore what what we mean by attack surface. Obviously, if we if we think about something like cyber security, attack surfaces are everywhere where you have unsecured endpoints or you have code that you can kind of inject into. You have uh databases that are just out in the open. Language models are are very different because they unless you give them the information, they they don't have that kind of attack surface. But there are other attack surfaces or risks. Specifically, what we call them are typically content risks where either inputs to the light language model can be uh um asking for very harmful output or the output itself could could lead to something that is harmful or against the established regulation, rules, laws. Um so this attack surface very much is grounded in the way that you want to use this language model or this application that you're building. So take us for example, we're a financial services company. Our content is very much focused on helping people conduct analyses in the financial space, synthesize information, summarize information, uh ground all of this and attribute all of this to our just in time data that that we have on our Bloomberg terminal. So for us, the attack surface is very much linked to the domain that we operate in. So what we care about are things like can someone uh do financial conduct um can someone conduct uh financial crimes with the help of light language models? Can it facilitate insider trading? Does it give unsolicited financial advice that people might trade on and lose a lot of money? Uh does it create an information imbalance or an asymmetry where it discloses trading strategies from one company to the other?\nuh but we are just one of many many examples of of people who use these light language models. So when we talk about an unanticipated attack surface, the people who build light language models, they can't enumerate every single way in which they are being applied. They're being applied to healthcare, they're being applied to law, they're being applied to education, they're being applied everywhere around the world now. So on top of that, the jurisdictional differences, the different geographic locations, they might have different laws even applying. So now we have this whole web of applications that are built on top of Large Language Models, but we only have one provider who says, \"Yeah, actually our model is safe.\" There's no way where that would be possible to really anticipate every single use case around the world grounded in all the relevant regulation. So all this coming to the main point that we're really trying to uh keep making over and over, you need to really evaluate your AI application in the context you want to deploy them because in the end only the organization developing the application that you integrate uh the L language model in understands their risks.\n\nSo that is really why we're doing this kind of research. We want to understand what are the risks that are specific to us and the way that we're building applications and the clients that use our applications. Right? So when we talk about unanticipated risk, this is very much it. We don't understand the risk unless we measure it. We uh the people who build models, especially if we use third party models, they don't understand our risks, right? So we need to study this to really understand and instead of having an unmeasurable unanticipated risk surface we want to have one where we very much understand what are the risks and how do we mitigate them. So does that end up being the case that then you you end up having this kind of list of risks and mitigations for your specific use case because it like so it sounds like basically it's it's the user of a RAG setup or the user of an LLM that has to be cautious in their particular circumstance given that the LLM creator couldn't have anticipated like you said all the possible use cases. Is that right?\n\nUm slightly. So I what I mean really is the people who build the RAG system, they usually know what they're building it for. They understand the data that goes into the database or they should at least uh they understand how data is being retrieved and how it's all being put together. And then there are a couple sources of risks. Number one, you have the data. If there is dangerous information in the data and write an instruction on how to shelter money in places that money shouldn't be sheltered and you ask the large language model, hey, give me information and it adds that information in the context that that could be one vector of of getting harmful information out of the language model. But uh there is another vector in which the large language model itself could could be unsafe. It could be unsolicited.\nGive that advice. But then the user is another attack vector. What if the user there types that in like how do I shelter money wherever? How do I commit tax fraud?\n\nRight? In this case, we can rely on on the large language model to kind of block these kind of queries which really puts a lot of trust in this developer of the large language model that often there is a different entity from the organization that builds the RAG system or as the builder of the RAG system. I can take a look at those three. I can look at okay, what are users typically doing? What are attack vectors that users might be trying with our system? Uh what is what data is in the databases? How do I make sure that I understand this data and safeguard us from from exposing information to users that shouldn't have access to this information? And how safe is the large language model really for our use cases? Our paper is very much in that third realm here because we wanted to know the built-in defenses of the of the language model. How good are they actually and how well do they stand up to a RAG setup? And in our case, we found that uh we found that for the general purpose uh dangerous queries that we that we looked at actually RAG safety breaks down because light language models really are only secured for non-RAG setups, which means that we need to build guard rails around our applications that go beyond what the Language model builders are actually providing to us.\n\nThis episode is sponsored by Adverity, an integrated data platform for connecting, managing, and using your data at scale. Imagine being able to ask your data a question just like you would a colleague and getting an answer instantly. No more digging through dashboards, waiting on reports, or dealing with complex BI tools. Just the insights you need right when you need them. With Adver's AI powered data conversations, marketers will finally talk to their data in plain English. Get instant answers, make smarter decisions, collaborate more easily, and cut reporting time in half. What questions will you ask? To learn more, check out the show notes or visit www.adverity.com.\n\nThat's adverity.com.\n\nNice. Okay. Yeah, that that all makes sense to me. Um, so a question that occurs to me as you're talking about this. So, you know, when I originally heard about this paper and about, you know, uh, LLMs being less safe in RAG situations, the thing that popped into my head, I guess, is I was thinking\n\n\nAbout how it's, my understanding is that hallucinations are much less likely in a RAG circumstance than outside of a RAG circumstance for an LLM. When you have that, you know, to use that word, grounding again that you've been using, when you have that grounding, uh, it seems to lead to fewer hallucinations. So, I guess in my mind, maybe I kind of, and so I'd also, I'd welcome your input on the hallucination point if that is actually true. But I guess I kind of ended up conflating those two things in my head and thinking, okay, if it's hallucinating less often, then it's surely safer. But, but yeah, and again, you can cut into my thoughts on the hallucination in a second, but, um, uh, it, but now it's, it's becoming clear to me, it's, it's becoming clear for me to understand how maybe even if hallucinations are reduced, the issue here is that the kinds of safeguards that an LLM creator put in, say Meta put into some llama models that they release, those safeguards that are built in in a RAG setup often break down.\n\nExactly what you're saying, that is absolutely the case where we say, look, there are typically the three H's. They were first developed by Anthropic. Many companies are now adopting them. The application you're building, it should be helpful, it should be honest, and it should be harmless. And hallucination very much goes into this honesty bucket, which often is also then combined with the helpful, because how can you be helpful if you're not honest?\n\nSo that if we just focus on being helpful and being harmless, everything that goes into hallucination and the advantages RAG brings to helpfulness, they're vast, and they make RAG a necessity. That's why we are not saying that RAG is dangerous. We're just saying it is not necessarily safer. It is absolutely necessary. But the harmlessness angle is something that is completely separate, and the way that organizations think about it is often to kind of split them and look at them through two different angles, because the helpfulness angle, it's very much grounded in a specific application. Right? Can a question-answering system that helps financial analysts answer questions and test hypothesis? The answer to that is, does it help them? Yes or no?\n\nBut there's always this angle of a malicious or an unintended abuse of that system where the same system that helps people assess hypothesis could then also be used to write who is the worst broker and who should I exploit, uh, which is maybe not something that you want to answer in turn. So now we have these two angles, and often you can say, okay, the harmlessness angle is something that is usually consistent across an industry, across a sector, across a domain. There might be some application-specific risks too, and then there's the helpfulness angle where you provide answers that hopefully help. And here RAG really helps because it leads to you being able to build things like transparent attribution. So transparent attribution for us means every time I produce some kind of tidbit, some piece of information, I need to ground this in some kind of document or some kind of structured data. If I say the price of Meta is so and so today, then I want to say, want to be able to look at that and say, where does that number actually come from? Is it hallucinated, or do I actually know the query that produced that number? If I'm saying, like, the following analyst said the following statement, then I want to be able to hover over this and say, \"Oh yeah, this is where that statement came from. It is not hallucinated.\"\n\nUh, this to some degree can prevent the harmfulness or the harmlessness issues as well, but it is a somewhat separate topic as you were saying. You talk about hallucination, and that's where the big advantage for RAG comes in, but then there's the harmless or the harmfulness angle as well.\n\nOkay. Nice. So maybe recap for us again. So there's probably lots of listeners out there who are sold on RAG, and they're like, great, I want to reduce harmfulness. Uh, I want to increase the honesty of my LLM, and so I'm going to use a RAG system. What are the kinds of mitigations? I mean, you went into this a little bit, but kind of recap for us again the kinds of mitigations that our listeners can take home away from this episode to be able to use RAG so that it is safe for their particular circumstances.\n\nYeah. Um, I think that's a great opportunity to talk about a little bit about how should we evaluate systems, because in the end, what you see talked about a lot publicly, and probably the most, is benchmarks, and you see, oh, hey, this new model that Large Language Model provider A or B or C produced, it achieves a better score on the Large Language Model arena or on the following benchmarks, and it's better at reasoning, it's better at coding. That doesn't necessarily mean that it's better for all the downstream applications that are being integrated into. And I think we often conflate this kind of view where it's actually really, really important to measure and to evaluate the system in the context it's deployed in. And that includes things like safety testing and specific guardrails. So we also released a second paper in addition to our RAG LM paper where we, um, developed our own content risk taxonomy for financial services where we say, here are 12 categories of risks that we really, really should address with applications in our area.\n\nAnd for each of these, we can measure, because we can collect data against this and say, okay, here are 100 queries that try and do financial misconduct. 100 queries that try and make the LLM generate financial advice. 100 queries that try and get at personal information. 100 queries that, uh, try and defame someone or create fake, fake information or fake narratives and all of these categories. You can create data, you can measure it against this, and you can not only test the Large Language Models themselves, but rather you can test the entire end-to-end system that is deployed in a specific sociotechnical context. And here typical systems, there are a lot of open-source solutions. Uh, NVIDIA has their own, llama has their own, Google has their own. They provide open-source guardrails, but again, these open-source guardrails, they're shielding against these general-purpose risks. In our paper, we found that if you apply these, these llama guard or shield, gemma or aegis is what they're called. If you apply them to then to our specific risks, uh, they're classifiers. They say, is this input or is this output safe? Yes or no? And they also fail in our domain because similar to our RAG paper, it's just not a use case that people necessarily have thought about before. But it gives us then the idea of, okay, how do we build our own guardrails? Can we have a classifier on inputs and on outputs that identify violations of our rules that we set up ourselves? So now instead of having a vanilla RAG system where it's retrieval answer, we have guardrail retrieval answer guardrail. And in practice, to prevent hallucination and to add attribution, real systems that are deployed to wide ranges of audiences, they have many more components, and it's really this end-to-end application that should be evaluated and where you need the subject matter expertise to also know, is it helpful and is it harmless?\n\nNice. Okay. So yeah, so a combination of subject matter expertise, uh, you know, people digging into their particular circumstances. You mentioned earlier in the episode being aware of your data, making sure that there aren't data in there that are going to be harmful, that could be, uh, that could be used as grounding by the LLM. And then you mentioned just now this idea, this, uh, flow of guardrail retrieval answer and then another set of guardrails. Um, and so yeah, so very practical advice there.\n\nUm, changing the topic a little bit, like still staying on RAG and still staying on helpfulness, but, uh, something that we haven't talked about yet is context length. So I have a couple of points here or a couple of questions here. Um, you observed in your paper that LLMs are often optimized for short prompts but deployed in long text environments like RAGs. So going back to the example that I gave earlier, you, I talked about there being a million, uh, legal documents that the RAG system searches over, and then it pulls out a dozen documents. Those documents could each be 10 pages long. So then you're talking about 120 pages of context. And if the LLM was optimized for a question like, what's the capital of France, then, um, then yeah, I could imagine you run into issues. So, uh, do you want, do you want to fill us more in about this? The kinds of issues that arise? Um, for example, it seems like there's, you know, trade-offs between the benefits of longer inputs versus this becoming a new risk surface, a new attack surface.\n\nYeah, absolutely. And I think you're really hitting the nail on the head here. RAG is incredibly powerful. There's a lot of investment from companies that build Large Language Models into increasing the possible context length. But at the same time, increasing the possible context length also requires developing methods and developing the models to actually be able to handle such a context length, rather than just being able to technically being able to handle them by, uh, having an attention that goes long enough back.\n\nSo here, there are a couple of considerations in our paper. What we evaluated was how does context length really influence this, the safety angle. And we found that especially for safety, there seems to be this effect where the more context you put in, the more likely the model is to, uh, to forget the built-in safety guardrails or this alignment that people talk about, uh, which absolutely shouldn't happen if you're considering how RAG is set up, because again, you're adding innocuous, completely harmless information, and just because there's a long, long context doesn't mean that the language model needs to behave any differently from if you just post in what's the capital of France.\n\nAt the same time, the context length question actually has also massive implications of how we build RAG systems in practice. Retrieval systems have multiple components too. We've been kind of glossing over this point. We just say, oh yeah, there's a search system and there's a database, but often you have things like, okay, how do I parse the query? If I ask a question, to what time frame should I limit the search results? Um, am I filtering to particular industries, sectors, companies, any kind of other metadata? Uh, there's usually the way that search engines are written, there's usually multiple steps as well, where you do a first-pass retrieval where you go from hundreds of millions of documents or even billions of documents, uh, to down to just a handful. And then there's usually a re-ranking step that's much more computationally intensive where you really pick out which snippets in the documents are you actually finding the answer in. So all of these components here have an influence on the context length. When you say you have 10 legal documents of 10 pages, how do you get to them? And what is the effect of pasting entire documents versus just a paragraph or two from each document? And typically what people find is the less context you need to provide, the, especially if the answer is in that context, the easier it is for the Large Language Model to find the right answer. Seems, seems pretty obvious, but that then becomes a retrieval problem. How do I find within the, you know, if I have 100 million documents, each 10 pages long? How do I find the two paragraphs that actually answer the question? So a hope really has been in Large Language Model development to just increase the context length and to rely less on more and more accurate retrieval, but rather let the language model figure it out. Being able to handle longer context also allows you to give much more contextualized answers if you have the entire 10-page document, even if the answer is found in just one paragraph. It can still give you the context from page one or tell, right, it's tell you what is this document type, where is it from, what was in the intro, what did the executive summary of this document say, in contrast to the actual, uh, document. If we go into voice, like what was the intonation, if we go into video, there's so many opportunities to take advantage of longer context, but again, we have to really consider how are the models being deployed, how are they, who are the users of this, what is the application?\n\nAnd every single one of these designs I just talked about can influence the helpfulness and the harmful or harmless, in this case, of the entire system. So this is a massive undertaking and, uh, requires a lot of research.\n\nThis episode of SuperDataScience is brought to you by the Dell AI Factory with NVIDIA. Two trusted technology leaders united to deliver a comprehensive and secure AI solution customizable for any business. With a portfolio of products, solutions, and services tailored for AI workloads from desktop to data center to cloud, the Dell AI Factory with NVIDIA paves the way for AI to work seamlessly for you. Integrated Dell and NVIDIA capabilities accelerate your AI powered use cases, integrate your data and workflows, and enable you to design your own AI journey for repeatable, scalable outcomes. Visit ww.dell.com/supdatience to learn more. That's dell.com/supdatience.\n\nThat was a fascinating answer. I learned a lot, and you explained all of that very clearly. Thank you. Um, something that you talked about there was how longer context windows allow us to have more context in our answer. Um, you know, more subtlety, more nuance, uh, in the answer that comes back. And you also mentioned there how context windows are getting longer and longer, which actually ties in perfectly to the next question that I was going to ask you, which is that, you know, we're at a point now where it's getting reasonably common to see LLMs that have a million token context length. And we've seen some released that are multiples of that, many millions of tokens in context. And the typically when these are released, it comes with these kind of needle in a haystack tests where, uh, you try to, you know, you hide a small amount of information, like, I think a common one is like a pizza recipe, like there'll be something like the world's best pizza is, and then these, like, you know, random ingredients, like anchovies, um, you know, something that, that is, that is unique, and then you'll have, you'll say, okay, you know, over our 10 million token context length, um, the model was able to successfully retrieve pizza information. Now, I'm going getting a little bit deep in the weeds here and on a little bit of a tangent, but some people have also said, you know, that isn't a great test because if you have millions of legal documents and then there's one pizza recipe, that's quite unusual, and so it's probably, you know, that's then maybe something that the LLM is going to take notice of.\n\nUm, and so yeah, so there's controversy, controversy about needle in a haystack test, but we don't necessarily need to get into that too much unless it interests you. The question that I'm getting to is, do you think we'll get to a point where context windows expand so much that it is effectively like an infinite context window, and then that means that we don't need RAG at all?\nYeah.\n\n\nUm, there are additional considerations to address your needle and haste point. I think this is a perfect example of the difference between developers of large language models and integrators of such language models in actual applications. As someone who might be considering, okay, which of these long context models do I use? I can look at needle and haste. I can say, oh yeah, this model got it 100% of the time. This one did not. Clearly, I'm going to look at the one that gets 100% first. And that is really the decision that these benchmarks, even if they're artificial benchmarks, can influence. But I think no one is making the point that just because a model can find some information in 10 million tokens, it is going to be able to help you with a research-heavy legal task. That is really on the integrators in the end to identify. And in this case, it might be a much, much, much harder task. Right? If you have a system that we just released earlier this week at Bloomberg, it was a tool that helps research analysts search through over 400 million documents and news articles and analyst reports to answer questions and to help with the identification of and solution of hypothesis. It's very much hypothesis-driven. You ask a question, it goes through all these 400 million documents and then synthesizes an answer. This is much, much harder to do than a simple find this piece of pizza information or pizza recipe information, and instead you really need to, again, evaluate in the context you deploy the system. But to then go back at your question, there is obviously strong advantages of models that are technically capable of handling more and more complex situations. If I'm able to just paste in more documents or more of a context, I don't need to rely on as many tricks to really narrow down the context window, I can just rely on a large language model. There's a trade-off here though, where longer context usually comes at a cost of significantly increased latency and cost. So even though long context models are available, they might not necessarily be the best for the task if you want a snappy, direct answer.\nOf course, that is such an obvious point to make.\nIs that, and you know, over a long enough time scale, you know, over many years, maybe many decades, compute cost over millions of tokens might be trivial, but at least for the foreseeable future, it isn't. And so, yes, that makes perfect sense because you, so something that I guess we could make a little bit more explicit for people who aren't familiar with retrieval-augmented generation because we haven't talked about this, is that when the way that retrieval-augmented generation systems work is like, let's go back to that example of the million legal documents.\nWhat we would do in advance before running any retrieval-augmented generation queries is we would map each of those million documents into a high-dimensional space called a vector space, and the location in that high-dimensional space, like you could, you can, you can only visualize in three dimensions. So, so in your head, you can kind of imagine on like an X, Y, Z, an X, Y, Z plane, you know, in three dimensions, you can kind of imagine, okay, you know, in the top right corner near the front of this space, we have, you know, commercial law documents, and then nearby there are some, you know, other kinds of related legal documents, and as you move further and further away from a given point in space, you'll get, you know, you'll get more variety in the kinds, in the kind of document that you're looking at. So the closer that things are in the space, the more overlap and meaning there is between the documents. And so this allows us then in real time to take the user's natural language query, map it into that same high-dimensional space, but you can imagine it's three dimensions. When I say high-dimensional, I mean hundreds or thousands of dimensions, which you can't visualize, but which, but for which the linear algebra is basically identical for a computer relative to a two or three-dimensional space that you can visualize. And so, yeah, so we take the natural language query that a user makes to the retrieval-augmented generation system. We can convert that into the same high-dimensional space, find its location, and then retrieve the documents like you talked about, kind of a cheap, fast first retrieval step, which could be something like I'm just describing where we take the closest documents to wherever the query gets mapped to in the high-dimensional space. And then we can do more complex processing after that, but that kind of gives us our initial results. And so doing that is very, very fast. You know, we only need to convert one query, which might be short, into the, you know, a coordinate in a high-dimensional space, and then we could use a very fast mathematical operation like a cosine similarity score to find the closest documents in that space, and that's all computationally very inexpensive, very fast. You can, it allows the retrieval-augmented generation system to work in real time even over, like you said, you know, billions of documents. And yeah, in contrast, if all of that text, if our millions or billions of documents were in the context of an LLM, even if it all fits in, you'd then have, instead of this computationally simple calculation, this fast calculation, you would have to have tons and tons of really high-end GPUs, stunning to comb across all of the meaning in that huge context window. So yeah, you correct me if I...\nNo, absolutely. And what you described here is commonly known also as semantic search because you can really search based on the meaning of a query. To add to your point, often even for commercial systems, it is still the case that you rely on keyword retrieval just because it's even cheaper, it's even faster. There are techniques from the early 90s or even late 80s that are still around just because they're so computationally efficient because you really want the retrieval to be as cheap as possible. And often you use semantic search for the more toned down, for the, you do a first pass keyword retrieval. You do a second pass semantic search within the keyword retrieved steps. So there's a lot of engineering over the years that has been developed to just get this retrieval step as efficient as possible. And we're still a while away from Large Language Models being able to do anything even remotely as efficient as this step. And as you said, this can lead to a massive use of GPU power for something that you can solve otherwise. And again, grounding this in the individual end-user experience, it could be that in the future, someone does a side-by-side comparison, right? I do this really expensive process where I just pipe everything into a large language model. I do a cheap process, and it could be that in terms of helpfulness, users actually prefer the one that's snappy and fast rather than the one that's maybe five points more accurate in the end. This is all something we need to evaluate in the end, and those are all design decisions that are all being evaluated all around the globe right now as people are building their own generative AI and retrieval-augmented generation solutions.\nSpeaking of snappy and fast, we've talked now about context, context window length. Um, how about model size? That's something that we haven't talked about yet. So, um, I know that you investigated in your paper differences between small models and larger ones in retrieval-augmented generation contexts. What did you find?\nThere are differences, and generally what we found is if a model is safer from the get-go, even without retrieval-augmented generation, it tends to be more robust to adding retrieval-augmented generation. A large factor on this is the model size or the model capability in general. I think at this point, model sizes are a little bit of a misnomer because we have so many models that rely on mixture of experts and that have architectural advantages that even though on paper they have more parameters, they actually are using fewer of them when you actually run them live. So it's very hard nowadays to actually compare the parameters, and we often compare based on active parameters, or there might be ways in which models are compressed, which again changes the representational power, but generally speaking, to answer your question, is yeah, we found that models from the get-go safer, they are also harder to break through retrieval-augmented generation, although we found that basically every system was breakable regardless of whether small or large. And I think we specifically call Llama for being relatively safer than many others, both Llama 70B and 7B, but Llama 70B, I believe, was a little bit better than 7B even. Um, although again, it can change from time to time because what we found really was the guardrails were broken because of this increased context length. It could be that once the next generation of this model comes out, that this is being prevented, that this, that there's an active component of the post-training of the alignment step that looks at how can someone use this with a longer context, and our exact setup could be one of those test cases where you can just continue training the model on, and we'll just inherently protect against this particular angle of attack.\nNicely said. I've learned a ton from you in this episode so far. We still have a little bit to go. Um, so I'm excited for that. Um, I'm curious, is what, what's the effect of refusing to answer in these? So you, um, so it sounds like it's clear that bigger models are generally better, you know, they're more capable, they fare better in retrieval-augmented generation contexts, generally speaking. Uh, to what extent, um, is refusal to answer a, you know, how does that factor into these kinds of assessments? In your paper, you called out Gemma 7B in particular for showing low unsafe outputs, but largely because it refused to answer questions.\nYeah. So, so there are a couple of different considerations here. If you just refuse to answer, it could be because you don't know, or it could be because you actively find the input to be unsafe. And if you can't distinguish between them, it's very hard to know whether, well, your model is just bad or whether it's unsafe or safe in this case. Um, so model sizes and model capabilities, again, they're all so intricately linked where you want to build a system that is helpful. So you always need to pair an analysis like ours with one that actually evaluates the how helpful the model is. And if in the end, you, you call Gemma here, if in the end Gemma is also refusing to answer completely safe questions and is completely safe and correct retrieval-augmented generation setup, it's not going to be helpful. So even though it is harmless, it still would not be able to be used. Um, so that, that's I think just highlighting the need for having a multifaceted evaluation. You need to consider those. Similarly to how model sizes will also affect latency and cost of running a system. It could be that the fast, cheap, small model is completely up to the task. And in that case, why would I use this completely overblown model to do that same task just because it is performing better on things that are completely not relevant to your particular application.\nNice. Nice. Um, so changing gears now a fair bit. Um, there's a second paper that you also recently published. So, uh, you're first author on a paper that was submitted to archive in April called understanding and mitigating risks of generative AI in financial services. Um, so mostly so far in this episode, we've been talking about general, you know, generally how models fare under retrieval-augmented generation, but in that paper, um, it's related to risk of generative AI and finance. You emphasize that most foundation models are not trained on finance-specific corporate bodies of knowledge. So, uh, what are the limitations this creates? Um, you know, for LLMs in general, but particularly for retrieval-augmented generation, and I'm assuming that this same kind of sentiment, you know, you looked at it with finance specifically because Bloomberg is, you know, you know, as a financial services company largely. Uh, but do you think that the same kind of limitation would apply in other sectors as well?\nYeah, absolutely. Um, so yeah, I gave a little bit of a teaser of this paper earlier and an answer as well. And what, the way that we wrote our paper very much should be seen as a case study. Finance here, or financial services in particular, capital markets and asset management, is the case study that we use to make the point that we really need to think about risk and risk taxonomies and risk management in our domain, in what we are trying to build. And as you say, we made the point, yeah, models are not necessarily trained on financial domains. We see that both in helpfulness and the harmlessness angle. Often, you know, complex financial tasks are not being able to be sufficiently handled by large language models by themselves. But also in our paper, we make the point that even safeguards that are dedicated models or systems to provide these kind of first pass, like, is this safe, is this unsafe judgment, they're also not trained on financial services. And if you use them out of the box and say, look, I use Llama Guard, I use Shield, I use AIS, I'm safe now, right? You're protected against a particular view of safety that is very much grounded in categories that are relevant to broad populations, to things like chatbots that help you do productivity day-to-day tasks. The typical applications that you would see in those AI productivity tools, no matter which one you use, they all have similar mechanisms, but those are not necessarily the same risks that we are under in financial services. Those are not the same obligations that companies, organizations in healthcare are under, or law, or any other highly domain-specific knowledge-intensive domain that has a lot of specific regulation, jurisdiction-specific regulation, considerations about whether just refusing to answer or giving disclaimers is enough, or whether questions should be blocked altogether. And there's just this difference of view that can't be encapsulated in a single model that a provider can give that very much is focused on a different use case.\nNice. Yeah. So I, I don't know, do you have, do you have guidance for us, you know, if we're, if we're trying to select an LLM for a particular use case, um, what do you recommend we do? I mean, like, practically, how can we move forward with all the information that you provided in this episode in selecting an LLM for a particular use case, for a particular domain, particularly if we want to be applying it in retrieval-augmented generation situations?\nYeah. So in our paper, we also have a list of best practices and recommendations that we have for, especially for knowledge-intensive domains and regulation-heavy domains. Uh, not necessarily everything has to be followed if you're building something for a much broader general population. Um, but especially for these kinds of domains, all I can do is spray my mantra: evaluate the system in the context that it's deployed in. If you are building something for healthcare, well, you better evaluate it in the context of healthcare. If you are building in the context of financial services, you better evaluate your subject matter experts in financial services. And specifically on the safety angle, our paper makes a couple suggestions here. There are very good starting points. There are taxonomies such as the NIST.\n\n\nRisk management framework for AI. There are other industry collaborations going ongoing. There's ML Commons. Those all provide more general purpose taxonomies, but just taking them as a starting point and then from there adjusting them to your domain can often save a lot of time. And especially if you're a large organization with a compliance or risk department, it will help them also understand how one can classify and then categorize these kinds of risks. Another recommendation we make is to organize red teaming events and or do any other kind of red teaming. Red teaming in this case is this practice that had it start in the cold war where you have users trying to be malicious. So we get people in the same room and we say look for the next couple hours try and break the system try and play evil. Here are some instructions on how to do this and then afterwards we can look how often was this actually broken? How often did the system give financial advice? How often did it refuse? And from there we can quantify the risk surface. Since we're talking we were talking earlier about this unknown risk surface, well just measure it and then you have it. So that's kind of the main takeaway that we have. We gave pretty specific advice for how to go about this and how to set up risk management frameworks and all this needs to go hand inand also with again this this evaluate in the context it's applied. Make sure you invest a lot in evaluation. Don't just take the word of the large native model providers that their benchmark scores are going to translate into the all all the downstream applications. And if you follow that advice, you're going to have a system that is in the end much more trustworthy, reliable, robust, and you're going to have users that are going to keep using it rather than trying it twice, getting really bad answers both times, and never touching it again.\nPerfect. That's a great sound bite at the end there. I'm sure we'll be making it into a YouTube short.\nUm, so before I let you go, we are pretty much out of time here, but, I always ask my guests for a book recommendation before they leave the podcast episode, and I usually give guests a warning, but we rush into recording and I forgot to tell you. So, hopefully you have something on hand in your mind. It doesn't need to be something AI related necessarily.\nAll right, I'm going to give you the recommendation of a book that's currently sitting right here on my table, which I'm reading right now, which is The Unaccountability Machine. It just came out a couple months ago. It talks about how organizations are failing to build processes that act as accountability syncs. If you've ever talked to customer service and you couldn't escalate and the rep you talked to couldn't solve your problem, you're screwed. This book is talking about why from a cybernetic perspective this is a bad design and how to set up organizations and and processes that can help this which is also applicable to AI because you want to know if something gets blocked but you really need the answer where do I go how do I escalate a great recommendation there Sebastian thank you and then final question for you is how should people follow you after this episode I learned a ton from you I love the way you explain information how can people continue to get your thoughts after this episode\nright you You can follow our publications on our blog called Tech at Bloomberg. You can follow me personally on X or Blue Sky.\nSo just the first letters of both of my names just because it's a little bit long or obviously on LinkedIn.\nYeah. The first syllables.\nThe first syllables even. Yes.\nYeah. Yeah. Yeah. Uh it'd be amazing if you got SG on\nI tried\non either. Uh yeah, it's it's nice. You know, I it's been a while since I've heard a blue sky one. uh because it seem like yeah it seems like most guests these days are focused on LinkedIn uh but uh it's great to hear you know I actually I'm really rooting for blue sky me too and we'll see what comes out of it a lot of academics have moved over so I I have to at this point still follow X and Blue Sky at the same time to get my deep technical news but we'll we'll see how it develops in the future.\nNice. All right, thank you so much Sebastian. Uh yeah, and hopefully we can get you on the show again in the future when you have some more brilliant research insights for us.\nThank you so much for having me.\nWhat a great guest Dr. Sebastian Gehrmann was. In today's episode, he covered how RAG can circumvent built-in safety mechanisms in LLMs. While RAG reduces hallucinations, improving honesty, it can compromise harmlessness. How organizations must evaluate AI systems in their specific deployment context because general purpose safety measures often fail for domain specific use cases. How effective RAG safety requires a guardrail retrieval answer or guardrail architecture, not just vanilla retrieval and generation. And how financial services and other regulated industries need custom risk taxonomies and red teaming exercises to identify domain specific vulnerabilities. As always, you can get all the show notes, including the transcript for this episode, the video recording, any materials mentioned on the show, the URLs for Sebastian's social media profiles, as well as my own at superdatcience.com/905.\nThanks to everyone on the SuperDataScience podcast team, our podcast manager Sony Bryovich, media editor Mario Pombo, our partnerships team, which is Nathan Daly and Natalie Jysky, our researcher Serge Miss, writer Dr. Zara Care, and yes, our great founder Carol Aromanco. Thanks to all of them for producing another exceptional episode for us today for enabling that super team to create this free podcast for you. We are deeply grateful to our sponsors. You can support this show by checking out our sponsors links which are in the show notes. Otherwise, share the episode with someone who would like to have it review the episode on your favorite podcasting platform. Subscribe. Uh, oh, and if you are ever interested in sponsoring an episode yourself, you can find out how to do that at johncone.com/mpodcast.\nBut most importantly, I just hope you'll keep on tuning in. I'm so grateful to have you listening and hope I can continue to make episodes you love for years and years to come. Till next time, keep on rocking it out there and I'm looking forward to enjoying another round of the Super Data Science podcast with you very soon.\n",
  "dumpedAt": "2025-07-21T18:43:25.952Z"
}