{
  "episodeId": "bUFVFrOzyfw",
  "channelSlug": "@superdatasciencewithjonkrohn",
  "title": "Fixing Hallucinations Doesnâ€™t Fix AI Safety (with Sebastian Gehrmann)",
  "publishedAt": "2025-07-19T11:00:56.000Z",
  "rawLines": [
    {
      "lang": "en",
      "text": "[Music]",
      "offset": 2.35,
      "duration": 3.65
    },
    {
      "lang": "en",
      "text": "You know, when I originally heard about",
      "offset": 4.16,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "this paper and about, you know, uh, LMS",
      "offset": 6,
      "duration": 5.92
    },
    {
      "lang": "en",
      "text": "being less safe in rag situations, the",
      "offset": 9.44,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "thing that popped into my head, I guess,",
      "offset": 11.92,
      "duration": 6.24
    },
    {
      "lang": "en",
      "text": "is I was thinking about how it's my my",
      "offset": 14.4,
      "duration": 6.16
    },
    {
      "lang": "en",
      "text": "understanding is that hallucinations are",
      "offset": 18.16,
      "duration": 5.359
    },
    {
      "lang": "en",
      "text": "much less likely in a rag circumstance",
      "offset": 20.56,
      "duration": 4.879
    },
    {
      "lang": "en",
      "text": "than outside of a rank rag circumstance",
      "offset": 23.519,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "for an LLM. So when you have that, you",
      "offset": 25.439,
      "duration": 2.881
    },
    {
      "lang": "en",
      "text": "know, to use that word grounding again",
      "offset": 27.039,
      "duration": 2.721
    },
    {
      "lang": "en",
      "text": "that you've been using, when you have",
      "offset": 28.32,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "that grounding, uh, it it seems to to",
      "offset": 29.76,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "lead to fewer hallucinations. So I guess",
      "offset": 33.04,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "in my mind, maybe I kind of and and so",
      "offset": 34.96,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "I'd also I'd welcome your input on the",
      "offset": 37.76,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "hallucination point if if that is",
      "offset": 39.44,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "actually true. But I guess I kind of",
      "offset": 41.12,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "ended up conflating those two things in",
      "offset": 43.52,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "my head and thinking, okay, if it's",
      "offset": 45.28,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "hallucinating less often, then it's",
      "offset": 47.12,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "surely safer. But they but yeah and",
      "offset": 49.12,
      "duration": 5.759
    },
    {
      "lang": "en",
      "text": "again you can you can cut into my my",
      "offset": 52.32,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "thoughts on the hallucination in a",
      "offset": 54.879,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "second. But um uh it but now it's it's",
      "offset": 56.399,
      "duration": 5.121
    },
    {
      "lang": "en",
      "text": "becoming clear to me. It's be it's",
      "offset": 60.239,
      "duration": 3.441
    },
    {
      "lang": "en",
      "text": "becoming clear for me to understand how",
      "offset": 61.52,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "maybe even if hallucinations are are",
      "offset": 63.68,
      "duration": 3.439
    },
    {
      "lang": "en",
      "text": "reduced. The issue here is that the",
      "offset": 65.28,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "kinds of safeguards that an LLM creator",
      "offset": 67.119,
      "duration": 6.161
    },
    {
      "lang": "en",
      "text": "put in say Meta put into some llama uh",
      "offset": 69.68,
      "duration": 5.439
    },
    {
      "lang": "en",
      "text": "models that they release those those",
      "offset": 73.28,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "safeguards that are built in in a rag",
      "offset": 75.119,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "setup often break down. Exactly what",
      "offset": 77.2,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "what you're saying that is that is",
      "offset": 79.52,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "absolutely the case where we say",
      "offset": 81.52,
      "duration": 7.36
    },
    {
      "lang": "en",
      "text": "look there are typically the three H's",
      "offset": 85.28,
      "duration": 5.519
    },
    {
      "lang": "en",
      "text": "um they were first developed by by",
      "offset": 88.88,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "anthropic um many companies are now",
      "offset": 90.799,
      "duration": 5.841
    },
    {
      "lang": "en",
      "text": "adopting them um the application you're",
      "offset": 93.04,
      "duration": 5.439
    },
    {
      "lang": "en",
      "text": "building it should be helpful it should",
      "offset": 96.64,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "be honest and it should be harmless",
      "offset": 98.479,
      "duration": 6.481
    },
    {
      "lang": "en",
      "text": "and hallucination very much goes goes",
      "offset": 101.6,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "into this honesty bucket which often is",
      "offset": 104.96,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "also then combined with the helpful",
      "offset": 107.04,
      "duration": 2.96
    },
    {
      "lang": "en",
      "text": "Because how can you be helpful if you're",
      "offset": 108.64,
      "duration": 3.119
    },
    {
      "lang": "en",
      "text": "not honest?",
      "offset": 110,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "So that if we if we just focus on being",
      "offset": 111.759,
      "duration": 4.961
    },
    {
      "lang": "en",
      "text": "helpful and being being harmless,",
      "offset": 114.24,
      "duration": 4.239
    },
    {
      "lang": "en",
      "text": "everything that goes into hallucination",
      "offset": 116.72,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "and the advantages rag brings to to",
      "offset": 118.479,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "helpfulness, they're they're vast and",
      "offset": 121.2,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "they make rag a necessity.",
      "offset": 122.799,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "That's why we're not saying that that",
      "offset": 125.28,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "rag is dangerous. We're just saying it",
      "offset": 126.799,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "is not necessarily safer. um it is",
      "offset": 128.56,
      "duration": 5.039
    },
    {
      "lang": "en",
      "text": "absolutely necessary. But the",
      "offset": 131.2,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "harmlessness angle is something that is",
      "offset": 133.599,
      "duration": 5.041
    },
    {
      "lang": "en",
      "text": "completely separate and the way that",
      "offset": 135.36,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "organizations think about it is often to",
      "offset": 138.64,
      "duration": 3.679
    },
    {
      "lang": "en",
      "text": "kind of split them and look at them",
      "offset": 140.48,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "through two different angles because the",
      "offset": 142.319,
      "duration": 3.361
    },
    {
      "lang": "en",
      "text": "helpfulness angle it's very much",
      "offset": 143.76,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "grounded in a specific application.",
      "offset": 145.68,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "Right? Can a question answering system",
      "offset": 148.16,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "that helps financial analysts answer",
      "offset": 151.12,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "question and test hypothesis? The answer",
      "offset": 153.36,
      "duration": 6.879
    },
    {
      "lang": "en",
      "text": "to that is does it help them? Yes or no.",
      "offset": 156.56,
      "duration": 6.319
    },
    {
      "lang": "en",
      "text": "But there's always this angle of a",
      "offset": 160.239,
      "duration": 5.121
    },
    {
      "lang": "en",
      "text": "malicious or an unintended abuse of that",
      "offset": 162.879,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "system where the same system that helps",
      "offset": 165.36,
      "duration": 4.239
    },
    {
      "lang": "en",
      "text": "people assess hypothesis could then also",
      "offset": 167.04,
      "duration": 5.919
    },
    {
      "lang": "en",
      "text": "be used to right who is the worst broker",
      "offset": 169.599,
      "duration": 5.681
    },
    {
      "lang": "en",
      "text": "and who should I exploit",
      "offset": 172.959,
      "duration": 3.761
    },
    {
      "lang": "en",
      "text": "uh which is maybe not something that you",
      "offset": 175.28,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "want to answer in turn. So now we have",
      "offset": 176.72,
      "duration": 6.799
    },
    {
      "lang": "en",
      "text": "these two angles and often you can say",
      "offset": 181.04,
      "duration": 5.199
    },
    {
      "lang": "en",
      "text": "okay the the the harmlessness angle is",
      "offset": 183.519,
      "duration": 4.561
    },
    {
      "lang": "en",
      "text": "something that is usually consistent",
      "offset": 186.239,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "across an industry across a sector",
      "offset": 188.08,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "across a domain there might be some",
      "offset": 189.84,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "application specific risks too and then",
      "offset": 191.92,
      "duration": 4.239
    },
    {
      "lang": "en",
      "text": "there's the helpfulness angle where you",
      "offset": 194.4,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "provide uh answers that hopefully help",
      "offset": 196.159,
      "duration": 5.761
    },
    {
      "lang": "en",
      "text": "and here rack really helps because it",
      "offset": 199.68,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "leads to you being able to build things",
      "offset": 201.92,
      "duration": 5.039
    },
    {
      "lang": "en",
      "text": "like transparent attribution.",
      "offset": 204.64,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "So transparent attribution for us means",
      "offset": 206.959,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "every time I produce some kind of",
      "offset": 209.92,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "tidbit, some piece of information, I",
      "offset": 211.599,
      "duration": 3.121
    },
    {
      "lang": "en",
      "text": "need to ground this in some kind of",
      "offset": 213.28,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "document or some kind of structured",
      "offset": 214.72,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "data. If I say the the price of meta is",
      "offset": 217.12,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "so and so today, then I want to say want",
      "offset": 219.76,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "to be able to look at that and say where",
      "offset": 222.4,
      "duration": 3.199
    },
    {
      "lang": "en",
      "text": "does that number actually come from? Is",
      "offset": 224.08,
      "duration": 3.519
    },
    {
      "lang": "en",
      "text": "it hallucinated or do I actually know",
      "offset": 225.599,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "the query that produced that that",
      "offset": 227.599,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "number? If I'm saying like the following",
      "offset": 230.239,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "analyst said the following statement,",
      "offset": 232.319,
      "duration": 3.521
    },
    {
      "lang": "en",
      "text": "then I want to be able to hover over",
      "offset": 234.08,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "this and say, \"Oh yeah, this is where",
      "offset": 235.84,
      "duration": 3.599
    },
    {
      "lang": "en",
      "text": "that that statement came from. It is not",
      "offset": 237.28,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "hallucinated.\"",
      "offset": 239.439,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "Uh this to some degree can prevent the",
      "offset": 241.2,
      "duration": 5.759
    },
    {
      "lang": "en",
      "text": "the harmfulness or the harmlessness",
      "offset": 244.239,
      "duration": 5.521
    },
    {
      "lang": "en",
      "text": "issues as well, but it is a somewhat",
      "offset": 246.959,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "separate topic as you were saying. You",
      "offset": 249.76,
      "duration": 3.119
    },
    {
      "lang": "en",
      "text": "talk about hallucination and that's",
      "offset": 251.599,
      "duration": 3.441
    },
    {
      "lang": "en",
      "text": "where the big advantage for RA comes in,",
      "offset": 252.879,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "but then there's the harmless or the",
      "offset": 255.04,
      "duration": 2.879
    },
    {
      "lang": "en",
      "text": "harmfulness angle as well.",
      "offset": 256.479,
      "duration": 4.241
    },
    {
      "lang": "en",
      "text": "Okay. Nice. So maybe recap for us again.",
      "offset": 257.919,
      "duration": 4.961
    },
    {
      "lang": "en",
      "text": "So there's probably lots of listeners",
      "offset": 260.72,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "out there who are sold on ragda and",
      "offset": 262.88,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "they're like great, I want to reduce",
      "offset": 264.8,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "harmfulness. Uh I want to increase the",
      "offset": 266.56,
      "duration": 7.6
    },
    {
      "lang": "en",
      "text": "honesty of my of my LLM and so I'm going",
      "offset": 269.52,
      "duration": 6.56
    },
    {
      "lang": "en",
      "text": "to use a rag system. What are the kinds",
      "offset": 274.16,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "of mitigations? I mean, you you went",
      "offset": 276.08,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "into this a little bit, but kind of",
      "offset": 278.4,
      "duration": 2.64
    },
    {
      "lang": "en",
      "text": "recap for us again the kinds of",
      "offset": 279.6,
      "duration": 2.8
    },
    {
      "lang": "en",
      "text": "mitigations that our listeners can take",
      "offset": 281.04,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "home away from this episode to be able",
      "offset": 282.4,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "to use rag so that it is safe for their",
      "offset": 285.12,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "particular circumstances.",
      "offset": 288.4,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "Yeah. Um I think that's that's a great",
      "offset": 290,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "opportunity to talk about a little bit",
      "offset": 292.8,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "about how should we evaluate systems",
      "offset": 294.4,
      "duration": 6.88
    },
    {
      "lang": "en",
      "text": "because in the end what you see talked",
      "offset": 298.24,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "about a lot publicly and probably the",
      "offset": 301.28,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "most is benchmarks and you see oh hey",
      "offset": 303.12,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "this new model that large language model",
      "offset": 306,
      "duration": 5.919
    },
    {
      "lang": "en",
      "text": "provider A or B or C produced it",
      "offset": 308.56,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "achieves a better score on the large",
      "offset": 311.919,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "language model arena or on the following",
      "offset": 313.68,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "benchmarks and it's better at reasoning",
      "offset": 315.52,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "it's better at coding that doesn't",
      "offset": 317.12,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "necessarily mean that it's better for",
      "offset": 319.28,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "all the downstream applications that are",
      "offset": 321.039,
      "duration": 5.201
    },
    {
      "lang": "en",
      "text": "being integrated into. And I think we",
      "offset": 322.72,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "often conflate this kind of view where",
      "offset": 326.24,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "it's actually really really important to",
      "offset": 328,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "measure and to evaluate the system in",
      "offset": 330.24,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "the context it's deployed in. And that",
      "offset": 332.08,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "includes things like safety testing and",
      "offset": 334.32,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "specific guard rails. So we also",
      "offset": 336.72,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "released a second paper in addition to",
      "offset": 338.96,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "our rack LLM paper where we um developed",
      "offset": 340.72,
      "duration": 6.88
    },
    {
      "lang": "en",
      "text": "our own content risk taxonomy for for",
      "offset": 343.68,
      "duration": 6.32
    },
    {
      "lang": "en",
      "text": "financial services where we say here are",
      "offset": 347.6,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "12 categories of risks that we really",
      "offset": 350,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "really should address with applications",
      "offset": 352.72,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "in our area.",
      "offset": 354.96,
      "duration": 4.239
    },
    {
      "lang": "en",
      "text": "And for each of these we can measure",
      "offset": 357.039,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "because we we can collect data against",
      "offset": 359.199,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "this and say okay here are 100 queries",
      "offset": 360.88,
      "duration": 6.159
    },
    {
      "lang": "en",
      "text": "that try and do a financial misconduct.",
      "offset": 364.479,
      "duration": 6.241
    },
    {
      "lang": "en",
      "text": "100 queries that try and make the LM",
      "offset": 367.039,
      "duration": 5.921
    },
    {
      "lang": "en",
      "text": "generate financial advice. 100 queries",
      "offset": 370.72,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "that try and get at personal",
      "offset": 372.96,
      "duration": 5.92
    },
    {
      "lang": "en",
      "text": "information. 100 queries that uh try and",
      "offset": 375.44,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "defame someone or create fake fake",
      "offset": 378.88,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "information or fake narratives and all",
      "offset": 380.96,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "of these categories. You can create",
      "offset": 383.12,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "data, you can measure it against this",
      "offset": 384.56,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "and you can not only test the large",
      "offset": 386.16,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "language models themselves, but rather",
      "offset": 388.16,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "you can test the entire end-toend system",
      "offset": 390,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "that is deployed in a specific",
      "offset": 392.72,
      "duration": 5.039
    },
    {
      "lang": "en",
      "text": "sociotechnical context. And here",
      "offset": 394.56,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "typicail systems there are a lot of open",
      "offset": 397.759,
      "duration": 5.121
    },
    {
      "lang": "en",
      "text": "source solutions. Uh Nvidia has their",
      "offset": 400.24,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "own, Lama has their own, Google has",
      "offset": 402.88,
      "duration": 3.759
    },
    {
      "lang": "en",
      "text": "their own. They provide open- source",
      "offset": 404.72,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "guardrails. But again, these open source",
      "offset": 406.639,
      "duration": 3.521
    },
    {
      "lang": "en",
      "text": "guardrails, they're shielding against",
      "offset": 408.8,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "these general purpose risks. Um in our",
      "offset": 410.16,
      "duration": 4.879
    },
    {
      "lang": "en",
      "text": "paper we found that if you apply these",
      "offset": 412.96,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "these llama guard or shield gemma or",
      "offset": 415.039,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "aegis is is what they're called if you",
      "offset": 417.28,
      "duration": 4.479
    },
    {
      "lang": "en",
      "text": "apply them to then to our specific risks",
      "offset": 419.199,
      "duration": 4.881
    },
    {
      "lang": "en",
      "text": "uh they're they're classifiers they say",
      "offset": 421.759,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "is this input or is this output safe yes",
      "offset": 424.08,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "or no and they also fail in our domain",
      "offset": 425.919,
      "duration": 6.881
    },
    {
      "lang": "en",
      "text": "because similar to our rack paper it's",
      "offset": 429.12,
      "duration": 5.359
    },
    {
      "lang": "en",
      "text": "just not a use case that people",
      "offset": 432.8,
      "duration": 3.679
    },
    {
      "lang": "en",
      "text": "necessarily have thought about before",
      "offset": 434.479,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "but it gives us then the idea of okay",
      "offset": 436.479,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "how do we build our own guardrails can",
      "offset": 438.4,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "we have a classifier on inputs and on",
      "offset": 440.08,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "outputs that identify violations of our",
      "offset": 442.16,
      "duration": 5.84
    },
    {
      "lang": "en",
      "text": "rules that we set up ourselves. So now",
      "offset": 444.8,
      "duration": 4.959
    },
    {
      "lang": "en",
      "text": "instead of having a vanilla rag system",
      "offset": 448,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "where it's retrieval answer, we have",
      "offset": 449.759,
      "duration": 6.321
    },
    {
      "lang": "en",
      "text": "guardrail retrieval answer guardrail.",
      "offset": 452.319,
      "duration": 6.16
    },
    {
      "lang": "en",
      "text": "And in practice to prevent hallucination",
      "offset": 456.08,
      "duration": 4.559
    },
    {
      "lang": "en",
      "text": "and to add attribution",
      "offset": 458.479,
      "duration": 4.241
    },
    {
      "lang": "en",
      "text": "real systems that are deployed to to",
      "offset": 460.639,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "wide ranges of audiences they have many",
      "offset": 462.72,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "more components and it's really this end",
      "offset": 464.72,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "to end application that that should be",
      "offset": 466.56,
      "duration": 3.759
    },
    {
      "lang": "en",
      "text": "evaluated and where you need the subject",
      "offset": 468.4,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "matter expertise to also know is it",
      "offset": 470.319,
      "duration": 5.041
    },
    {
      "lang": "en",
      "text": "helpful and is it harmless.",
      "offset": 472,
      "duration": 3.36
    }
  ],
  "cleanText": "[Music]\nYou know, when I originally heard about this paper and about, you know, uh, LLMs being less safe in RAG situations, the thing that popped into my head, I guess, is I was thinking about how it's my understanding is that hallucinations are much less likely in a RAG circumstance than outside of a RAG circumstance for an LLM.\nSo when you have that, you know, to use that word grounding again that you've been using, when you have that grounding, uh, it it seems to to lead to fewer hallucinations.\nSo I guess in my mind, maybe I kind of and and so I'd also I'd welcome your input on the hallucination point if if that is actually true.\nBut I guess I kind of ended up conflating those two things in my head and thinking, okay, if it's hallucinating less often, then it's surely safer.\nBut they but yeah and again you can you can cut into my my thoughts on the hallucination in a second.\nBut um uh it but now it's it's becoming clear to me.\nIt's becoming clear for me to understand how maybe even if hallucinations are reduced.\nThe issue here is that the kinds of safeguards that an LLM creator put in, say Meta, put into some llama uh models that they release, those safeguards that are built in in a RAG setup often break down.\nExactly what what you're saying, that is absolutely the case where we say, look, there are typically the three H's.\nUm, they were first developed by by anthropic.\nUm, many companies are now adopting them.\nUm, the application you're building, it should be helpful, it should be honest, and it should be harmless, and hallucination very much goes goes into this honesty bucket, which often is also then combined with the helpful.\nBecause how can you be helpful if you're not honest?\nSo that if we if we just focus on being helpful and being being harmless, everything that goes into hallucination and the advantages RAG brings to to helpfulness, they're they're vast and they make RAG a necessity.\nThat's why we're not saying that that RAG is dangerous.\nWe're just saying it is not necessarily safer.\nUm, it is absolutely necessary.\nBut the harmlessness angle is something that is completely separate, and the way that organizations think about it is often to kind of split them and look at them through two different angles because the helpfulness angle, it's very much grounded in a specific application.\nRight?\nCan a question answering system that helps financial analysts answer question and test hypothesis?\nThe answer to that is does it help them?\nYes or no.\nBut there's always this angle of a malicious or an unintended abuse of that system where the same system that helps people assess hypothesis could then also be used to right who is the worst broker and who should I exploit, uh, which is maybe not something that you want to answer in turn.\nSo now we have these two angles, and often you can say, okay, the the the harmlessness angle is something that is usually consistent across an industry, across a sector, across a domain.\nThere might be some application specific risks too, and then there's the helpfulness angle where you provide uh answers that hopefully help, and here RAG really helps because it leads to you being able to build things like transparent attribution.\nSo transparent attribution for us means every time I produce some kind of tidbit, some piece of information, I need to ground this in some kind of document or some kind of structured data.\nIf I say the the price of meta is so and so today, then I want to say want to be able to look at that and say where does that number actually come from?\nIs it hallucinated or do I actually know the query that produced that that number?\nIf I'm saying like the following analyst said the following statement, then I want to be able to hover over this and say, \"Oh yeah, this is where that that statement came from.\nIt is not hallucinated.\"\nUh, this to some degree can prevent the the harmfulness or the harmlessness issues as well, but it is a somewhat separate topic as you were saying.\nYou talk about hallucination and that's where the big advantage for RAG comes in, but then there's the harmless or the harmfulness angle as well.\nOkay.\nNice.\nSo maybe recap for us again.\nSo there's probably lots of listeners out there who are sold on RAG and they're like great, I want to reduce harmlessness.\nUh, I want to increase the honesty of my of my LLM, and so I'm going to use a RAG system.\nWhat are the kinds of mitigations?\nI mean, you you went into this a little bit, but kind of recap for us again the kinds of mitigations that our listeners can take home away from this episode to be able to use RAG so that it is safe for their particular circumstances.\nYeah.\nUm, I think that's that's a great opportunity to talk about a little bit about how should we evaluate systems because in the end what you see talked about a lot publicly and probably the most is benchmarks, and you see, oh hey, this new model that large language model provider A or B or C produced, it achieves a better score on the large language model arena or on the following benchmarks, and it's better at reasoning, it's better at coding.\nThat doesn't necessarily mean that it's better for all the downstream applications that are being integrated into.\nAnd I think we often conflate this kind of view where it's actually really, really important to measure and to evaluate the system in the context it's deployed in.\nAnd that includes things like safety testing and specific guard rails.\nSo we also released a second paper in addition to our RAG LLM paper where we um developed our own content risk taxonomy for for financial services where we say here are 12 categories of risks that we really, really should address with applications in our area.\nAnd for each of these we can measure because we we can collect data against this and say okay here are 100 queries that try and do a financial misconduct.\n100 queries that try and make the LM generate financial advice.\n100 queries that try and get at personal information.\n100 queries that uh try and defame someone or create fake fake information or fake narratives and all of these categories.\nYou can create data, you can measure it against this, and you can not only test the large language models themselves, but rather you can test the entire end-to-end system that is deployed in a specific sociotechnical context.\nAnd here typicail systems there are a lot of open source solutions.\nUh Nvidia has their own, Lama has their own, Google has their own.\nThey provide open- source guardrails.\nBut again, these open source guardrails, they're shielding against these general purpose risks.\nUm in our paper we found that if you apply these these llama guard or shield gemma or aegis is is what they're called if you apply them to then to our specific risks uh they're they're classifiers they say is this input or is this output safe yes or no and they also fail in our domain because similar to our RAG paper it's just not a use case that people necessarily have thought about before but it gives us then the idea of okay how do we build our own guardrails can we have a classifier on inputs and on outputs that identify violations of our rules that we set up ourselves.\nSo now instead of having a vanilla RAG system where it's retrieval answer, we have guardrail retrieval answer guardrail.\nAnd in practice to prevent hallucination and to add attribution, real systems that are deployed to to wide ranges of audiences they have many more components and it's really this end to end application that that should be evaluated and where you need the subject matter expertise to also know is it helpful and is it harmless.\n",
  "dumpedAt": "2025-07-21T18:43:25.803Z"
}