{
  "episodeId": "BUfrkEPl0Ws",
  "channelSlug": "@superdatasciencewithjonkrohn",
  "title": "903: LLM Benchmarks Are Lying to You (And What to Do Instead) â€” with Sinan Ozdemir",
  "publishedAt": "2025-07-08T11:00:29.000Z",
  "rawLines": [
    {
      "lang": "en",
      "text": "So, how does this kind of leaderboard",
      "offset": 0.08,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "mentality",
      "offset": 1.68,
      "duration": 3.679
    },
    {
      "lang": "en",
      "text": "skew our understanding of a model's real",
      "offset": 3.2,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "abilities on everyday tasks that the",
      "offset": 5.359,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "rest of us use them for? That mismatch",
      "offset": 7.44,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "of what's being tested on the benchmark",
      "offset": 8.96,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "versus what's being marketed the",
      "offset": 11.36,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "benchmark is for can be quite disperate.",
      "offset": 13.12,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "And if humanity's last exam includes",
      "offset": 16.4,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "knowing what happened in season 14 of",
      "offset": 18.64,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "League of Legends, I I don't want to",
      "offset": 20.48,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "take this exam either, quite frankly.",
      "offset": 22.96,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "Recognizing that you have gaps in your",
      "offset": 24.8,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "knowledge, for me, that's even more",
      "offset": 26.32,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "interesting. A benchmark should be the",
      "offset": 28.64,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "start of a conversation, not the end of",
      "offset": 30.64,
      "duration": 6.48
    },
    {
      "lang": "en",
      "text": "a conversation. Who has the right to",
      "offset": 32.96,
      "duration": 6.4
    },
    {
      "lang": "en",
      "text": "judge whether or not the AI was correct",
      "offset": 37.12,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "or not?",
      "offset": 39.36,
      "duration": 5.32
    },
    {
      "lang": "en",
      "text": "That's a big question.",
      "offset": 41.2,
      "duration": 3.48
    },
    {
      "lang": "en",
      "text": "San, welcome back to the Super Data",
      "offset": 46.399,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "Science podcast. How you doing today,",
      "offset": 48.719,
      "duration": 3.761
    },
    {
      "lang": "en",
      "text": "John? Thank you for having me yet again.",
      "offset": 50.399,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "I'm I'm super excited to be here as",
      "offset": 52.48,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "always. Yes, we were just tallying prior",
      "offset": 54.239,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "to starting recording how many times",
      "offset": 57.28,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "you've been on the show. We you've been",
      "offset": 59.199,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "on more times than you even knew. You",
      "offset": 61.28,
      "duration": 5.199
    },
    {
      "lang": "en",
      "text": "you came into the the green room the",
      "offset": 63.28,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "like before we get into the recording",
      "offset": 66.479,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "studio and you said you've been on the",
      "offset": 68.08,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "This is going to be your fifth time, but",
      "offset": 70.88,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "actually it's your sixth. Uh so you're",
      "offset": 72.08,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "one of our first guests ever. Episode 21",
      "offset": 75.36,
      "duration": 6.079
    },
    {
      "lang": "en",
      "text": "back in January 2017. Exactly. Old",
      "offset": 77.68,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "enough to drink. that podcast episode",
      "offset": 81.439,
      "duration": 5.761
    },
    {
      "lang": "en",
      "text": "was finally in the US. And uh yeah, then",
      "offset": 83.04,
      "duration": 7.439
    },
    {
      "lang": "en",
      "text": "you were back about a year later in 161",
      "offset": 87.2,
      "duration": 5.599
    },
    {
      "lang": "en",
      "text": "and then jumped a couple years at",
      "offset": 90.479,
      "duration": 5.521
    },
    {
      "lang": "en",
      "text": "episode 333 in January 2020. And then",
      "offset": 92.799,
      "duration": 5.121
    },
    {
      "lang": "en",
      "text": "significant for me was another year",
      "offset": 96,
      "duration": 5.439
    },
    {
      "lang": "en",
      "text": "after that in February 2021. You were",
      "offset": 97.92,
      "duration": 6.08
    },
    {
      "lang": "en",
      "text": "one of my first guests when I took over",
      "offset": 101.439,
      "duration": 4.241
    },
    {
      "lang": "en",
      "text": "hosting the show from Kurroll. That's",
      "offset": 104,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "right. That was episode 445. And then",
      "offset": 105.68,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "last year at the Open Data Science",
      "offset": 109.28,
      "duration": 4.479
    },
    {
      "lang": "en",
      "text": "Conference East in Boston, we we met up",
      "offset": 111.04,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "quickly. I set up a camera and you and I",
      "offset": 113.759,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "recorded a quick episode live in person",
      "offset": 116.24,
      "duration": 6.64
    },
    {
      "lang": "en",
      "text": "in Boston um on AI alignment. Yes. LLM",
      "offset": 118.479,
      "duration": 6.96
    },
    {
      "lang": "en",
      "text": "alignment. Um and yeah, so that was",
      "offset": 122.88,
      "duration": 6.4
    },
    {
      "lang": "en",
      "text": "episode 784. So lots of episodes. Uh",
      "offset": 125.439,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "this is number six. It's going to be the",
      "offset": 129.28,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "best yet. That's Yeah, that's how I",
      "offset": 130.879,
      "duration": 5.201
    },
    {
      "lang": "en",
      "text": "think about it, too.",
      "offset": 133.76,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "just like do you think Okay, so you're",
      "offset": 136.08,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "currently writing your 10th book. Is",
      "offset": 138.72,
      "duration": 5.599
    },
    {
      "lang": "en",
      "text": "that right? That sounds right.",
      "offset": 140.56,
      "duration": 6.48
    },
    {
      "lang": "en",
      "text": "It's It's up there. I'm working on Yeah,",
      "offset": 144.319,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "like I'm working on two right now",
      "offset": 147.04,
      "duration": 3.199
    },
    {
      "lang": "en",
      "text": "actually. Do you think that the books",
      "offset": 148.64,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "get better or do you think you're like",
      "offset": 150.239,
      "duration": 4.481
    },
    {
      "lang": "en",
      "text": "Cuz often rock bands, you know, they",
      "offset": 152.48,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "have many years to make their first",
      "offset": 154.72,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "album. So like I don't know, Bush was a",
      "offset": 156.8,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "band in the 90s that was super popular.",
      "offset": 159.12,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "Oh yeah. in Canada. Their first album,",
      "offset": 161.84,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "16 Stone, I guess it was popular in the",
      "offset": 163.44,
      "duration": 3.439
    },
    {
      "lang": "en",
      "text": "US as well. You know them. You know,",
      "offset": 165.76,
      "duration": 2.64
    },
    {
      "lang": "en",
      "text": "it's funny. They're British. People",
      "offset": 166.879,
      "duration": 3.041
    },
    {
      "lang": "en",
      "text": "don't know them in the UK. Machine Head.",
      "offset": 168.4,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "Are you some of my favorite? Exactly.",
      "offset": 169.92,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "Glycerine. Oh, yeah. And that one album",
      "offset": 172,
      "duration": 4.959
    },
    {
      "lang": "en",
      "text": "it was like everyone knew every track",
      "offset": 174.4,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "and you know, huge huge global hit.",
      "offset": 176.959,
      "duration": 4.721
    },
    {
      "lang": "en",
      "text": "They're doing world tours and then so",
      "offset": 179.92,
      "duration": 2.88
    },
    {
      "lang": "en",
      "text": "the record company's like, you know,",
      "offset": 181.68,
      "duration": 2.32
    },
    {
      "lang": "en",
      "text": "we're going to need another album next",
      "offset": 182.8,
      "duration": 3.439
    },
    {
      "lang": "en",
      "text": "year. And they're like, oh man, we spent",
      "offset": 184,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "like five years making the first one.",
      "offset": 186.239,
      "duration": 5.121
    },
    {
      "lang": "en",
      "text": "Uh, and yeah, that seems to happen all",
      "offset": 189.36,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "the time with rock bands and then, you",
      "offset": 191.36,
      "duration": 2.32
    },
    {
      "lang": "en",
      "text": "know, they never quite have the same",
      "offset": 192.56,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "kinds of of hits. Do you think you're",
      "offset": 193.68,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "like a rock band or do you think your",
      "offset": 195.76,
      "duration": 2.88
    },
    {
      "lang": "en",
      "text": "books get better? Do you think number 10",
      "offset": 197.12,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "is better than number one? Uh, bold",
      "offset": 198.64,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "question for throwing shade to all the",
      "offset": 200.72,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "rock bands out there. No, I I think I I",
      "offset": 202.64,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "very much go in with to my books with a",
      "offset": 204.879,
      "duration": 5.121
    },
    {
      "lang": "en",
      "text": "mentality of not necessarily better, but",
      "offset": 207.28,
      "duration": 5.519
    },
    {
      "lang": "en",
      "text": "something different. Like I I'm very",
      "offset": 210,
      "duration": 5.519
    },
    {
      "lang": "en",
      "text": "conscious about I wrote about this four",
      "offset": 212.799,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "years ago. Do I really have something",
      "offset": 215.519,
      "duration": 4.561
    },
    {
      "lang": "en",
      "text": "new to say here or do I digress to",
      "offset": 217.2,
      "duration": 4.959
    },
    {
      "lang": "en",
      "text": "something else? So I I I I aim very much",
      "offset": 220.08,
      "duration": 5.439
    },
    {
      "lang": "en",
      "text": "for diversity more than I aim for just",
      "offset": 222.159,
      "duration": 5.521
    },
    {
      "lang": "en",
      "text": "kind of building upon the same content",
      "offset": 225.519,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "every year. Do you do second editions",
      "offset": 227.68,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "ever? Oh yeah, actually one of the books",
      "offset": 229.44,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "this year is a third edition of my most",
      "offset": 231.12,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "recent Quickstar guide to LLM. Like kind",
      "offset": 233.84,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "of like the So only only really two of",
      "offset": 236.08,
      "duration": 4.239
    },
    {
      "lang": "en",
      "text": "my books have ever gotten second and",
      "offset": 238.56,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "third editions and they are very much",
      "offset": 240.319,
      "duration": 3.521
    },
    {
      "lang": "en",
      "text": "the holistic books. Like my first book",
      "offset": 241.84,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "ever was the principles of data science",
      "offset": 243.84,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "and that was almost 10 years ago at this",
      "offset": 245.84,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "point and it was very much a zero to",
      "offset": 247.92,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "deep learning in 300 pages. So that's",
      "offset": 250.72,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "gotten updates over the year just as an",
      "offset": 253.92,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "introduction to data science. And the",
      "offset": 255.92,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "same thing with quick start guide to",
      "offset": 257.84,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "LLM. It's very much meant for someone",
      "offset": 259.04,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "who is just diving in for the first time",
      "offset": 261.84,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "engineer or not just what do I need to",
      "offset": 264.08,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "know to understand LLM? So that book",
      "offset": 266.8,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "gets updated because that's pretty much",
      "offset": 268.88,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "evergreen content at this point. Nice.",
      "offset": 270.96,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "Tell us about the quick start guide to",
      "offset": 273.52,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "LLMs. Tell us about what's in that book",
      "offset": 274.8,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "uh and what's new in the third edition.",
      "offset": 278,
      "duration": 5.919
    },
    {
      "lang": "en",
      "text": "Sure. The book is um actually it was",
      "offset": 280.08,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "literally had a copy here just because I",
      "offset": 283.919,
      "duration": 2.961
    },
    {
      "lang": "en",
      "text": "was holding up for someone else earlier",
      "offset": 285.36,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "right there. But um the the book is very",
      "offset": 286.88,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "much organized into a few sections",
      "offset": 289.52,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "starting with kind of a level set like",
      "offset": 292.4,
      "duration": 3.519
    },
    {
      "lang": "en",
      "text": "what is a language model? What is an",
      "offset": 294.4,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "auto reggressive language model versus",
      "offset": 295.919,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "autoenccoding language model? Like what",
      "offset": 297.44,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "does that mean? In fact, in in one of my",
      "offset": 299.759,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "episodes on super data science, the one",
      "offset": 302.16,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "from 2020, like January 2020, that was",
      "offset": 303.759,
      "duration": 5.521
    },
    {
      "lang": "en",
      "text": "actually the first time I had brought up",
      "offset": 307.28,
      "duration": 5.359
    },
    {
      "lang": "en",
      "text": "like BERT and GPT on the show. So, the",
      "offset": 309.28,
      "duration": 4.639
    },
    {
      "lang": "en",
      "text": "first part of the book really just talks",
      "offset": 312.639,
      "duration": 2.641
    },
    {
      "lang": "en",
      "text": "about what is the difference between",
      "offset": 313.919,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "these kinds of LLMs. Then it gets into",
      "offset": 315.28,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "the different applications and how to",
      "offset": 317.6,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "evaluate them and the kind of philosophy",
      "offset": 319.84,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "of alignment. What do we mean when we",
      "offset": 322,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "say alignment? Then the last parts are",
      "offset": 323.68,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "usually all right now that we're",
      "offset": 326.08,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "speaking the same language let's make a",
      "offset": 328.4,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "a phone bot let's make a embeddings",
      "offset": 330.88,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "classifier let's actually build these",
      "offset": 333.6,
      "duration": 3.599
    },
    {
      "lang": "en",
      "text": "things let's make a chatbot from scratch",
      "offset": 335.28,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "so it's very much organized into that",
      "offset": 337.199,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "those three sections and the third",
      "offset": 338.96,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "edition is pretty much the same the",
      "offset": 340.88,
      "duration": 4.879
    },
    {
      "lang": "en",
      "text": "additions are mostly around obviously",
      "offset": 343.28,
      "duration": 5.199
    },
    {
      "lang": "en",
      "text": "newer loms newer evaluation criteria",
      "offset": 345.759,
      "duration": 6.481
    },
    {
      "lang": "en",
      "text": "newer benchmarks and just um different",
      "offset": 348.479,
      "duration": 6.801
    },
    {
      "lang": "en",
      "text": "ways of applying LOM M like reasoning",
      "offset": 352.24,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "models for example. This will be the",
      "offset": 355.28,
      "duration": 2.88
    },
    {
      "lang": "en",
      "text": "first time that I talk about reasoning",
      "offset": 356.72,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "models in one of those books. Very cool.",
      "offset": 358.16,
      "duration": 5.759
    },
    {
      "lang": "en",
      "text": "So yeah, reasoning models like 01 03. We",
      "offset": 360.8,
      "duration": 5.839
    },
    {
      "lang": "en",
      "text": "actually at the time R1. Yeah. From",
      "offset": 363.919,
      "duration": 5.041
    },
    {
      "lang": "en",
      "text": "Deepseek. We at the time of recording",
      "offset": 366.639,
      "duration": 4.961
    },
    {
      "lang": "en",
      "text": "have a new Have you played with uh 03",
      "offset": 368.96,
      "duration": 5.84
    },
    {
      "lang": "en",
      "text": "Pro? Yes. No, I have not played with it.",
      "offset": 371.6,
      "duration": 5.92
    },
    {
      "lang": "en",
      "text": "I I got the email I think yesterday like",
      "offset": 374.8,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "late night yesterday.",
      "offset": 377.52,
      "duration": 4.799
    },
    {
      "lang": "en",
      "text": "Yeah. But um I have not yet tried it.",
      "offset": 379.68,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "What's the What's the shtick here?",
      "offset": 382.319,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "Better, better, faster, cheaper, all the",
      "offset": 384.4,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "above. I think it's I think it's I don't",
      "offset": 386.4,
      "duration": 4.799
    },
    {
      "lang": "en",
      "text": "think it's cheaper. I think it's kind of",
      "offset": 388.96,
      "duration": 4.799
    },
    {
      "lang": "en",
      "text": "it's bigger and better because we have",
      "offset": 391.199,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "the 03 Mini some months ago. And they",
      "offset": 393.759,
      "duration": 5.121
    },
    {
      "lang": "en",
      "text": "had things like 03 Mini High where you",
      "offset": 397.199,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "could have it do inference for longer.",
      "offset": 398.88,
      "duration": 5.039
    },
    {
      "lang": "en",
      "text": "And so I believe 03 03 Pro is kind of",
      "offset": 401.199,
      "duration": 4.481
    },
    {
      "lang": "en",
      "text": "orders of magnitude larger in terms of",
      "offset": 403.919,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "model weights. And so theoretically",
      "offset": 405.68,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "nuance. Well, that makes sense. Yeah.",
      "offset": 407.919,
      "duration": 4.481
    },
    {
      "lang": "en",
      "text": "But I I actually I haven't used it yet.",
      "offset": 410.88,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "It's been a busy day so far. And now I'm",
      "offset": 412.4,
      "duration": 2.96
    },
    {
      "lang": "en",
      "text": "recording this podcast episode. You",
      "offset": 414.08,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "know, it's tough to tough to stay up to",
      "offset": 415.36,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "date on all the fastmoving things in AI.",
      "offset": 417.44,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "It is. And again, that's also why a lot",
      "offset": 419.759,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "of the book is about models will change.",
      "offset": 421.759,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "But at the end of the day, this thing is",
      "offset": 424.639,
      "duration": 3.361
    },
    {
      "lang": "en",
      "text": "the next token predictor. And just",
      "offset": 426.08,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "because it thinks before it speaks to",
      "offset": 428,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "you doesn't mean we can't evaluate it",
      "offset": 429.68,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "the same way as we evaluate everything",
      "offset": 431.52,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "else. For sure. For sure. There are",
      "offset": 433.12,
      "duration": 5.519
    },
    {
      "lang": "en",
      "text": "definitely there are mega trends that",
      "offset": 436.4,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "you can that you can ease into and find",
      "offset": 438.639,
      "duration": 5.761
    },
    {
      "lang": "en",
      "text": "comfort in despite you know brands maybe",
      "offset": 441.12,
      "duration": 5.519
    },
    {
      "lang": "en",
      "text": "changing quickly model brands company",
      "offset": 444.4,
      "duration": 6.079
    },
    {
      "lang": "en",
      "text": "brands going from 4.5 to 4.1 from 01 to",
      "offset": 446.639,
      "duration": 7.761
    },
    {
      "lang": "en",
      "text": "03 to 04 back to 03 but 03 but better it",
      "offset": 450.479,
      "duration": 6.641
    },
    {
      "lang": "en",
      "text": "can be a lot to keep up with. Exactly.",
      "offset": 454.4,
      "duration": 6.16
    },
    {
      "lang": "en",
      "text": "That's right. Um so you're working on",
      "offset": 457.12,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "another book right now I understand as",
      "offset": 460.56,
      "duration": 2.72
    },
    {
      "lang": "en",
      "text": "well. I don't know if you want to talk",
      "offset": 462.24,
      "duration": 2.72
    },
    {
      "lang": "en",
      "text": "about that on air. Maybe it's secret.",
      "offset": 463.28,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "It's not secret. I mean, I'd love to",
      "offset": 464.96,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "talk about it. The the title is not",
      "offset": 466.96,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "known yet. So, I'll give you at least",
      "offset": 468.72,
      "duration": 3.759
    },
    {
      "lang": "en",
      "text": "the working title. It It's very much an",
      "offset": 470,
      "duration": 5.199
    },
    {
      "lang": "en",
      "text": "applied AI book. It is very much around",
      "offset": 472.479,
      "duration": 4.881
    },
    {
      "lang": "en",
      "text": "it's very much a cookbook of AI",
      "offset": 475.199,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "applications. It's assuming you've read",
      "offset": 477.36,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "my quick start guide. And again, we are",
      "offset": 479.759,
      "duration": 4.641
    },
    {
      "lang": "en",
      "text": "speaking the same language here is let's",
      "offset": 481.68,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "just dive into the top 20 applications",
      "offset": 484.4,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "of LLM I have seen in the last 10 years.",
      "offset": 486.56,
      "duration": 6.319
    },
    {
      "lang": "en",
      "text": "everything from let's build a prompt to",
      "offset": 490,
      "duration": 6.08
    },
    {
      "lang": "en",
      "text": "summarize a podcast transcript and",
      "offset": 492.879,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "really evaluate this thing to its core",
      "offset": 496.08,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "all the way to let's use reinforcement",
      "offset": 498.879,
      "duration": 4.481
    },
    {
      "lang": "en",
      "text": "learning to actually build some of these",
      "offset": 501.36,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "reasoning models from scratch for your",
      "offset": 503.36,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "specific domain. So it's a pretty wide",
      "offset": 505.52,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "spectrum of things that we do but it",
      "offset": 508,
      "duration": 3.199
    },
    {
      "lang": "en",
      "text": "very much starts hits the ground running",
      "offset": 509.68,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "kind of book. Very nice. Very nice. I",
      "offset": 511.199,
      "duration": 4.001
    },
    {
      "lang": "en",
      "text": "like that cookbook model. Uh and I",
      "offset": 513.36,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "assume both of these books applied AI",
      "offset": 515.2,
      "duration": 3.279
    },
    {
      "lang": "en",
      "text": "and quick start they're both in Python.",
      "offset": 516.88,
      "duration": 3.279
    },
    {
      "lang": "en",
      "text": "Yes. So everything, all the code that",
      "offset": 518.479,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "I'm writing is in Python. Nice. Nice.",
      "offset": 520.159,
      "duration": 5.041
    },
    {
      "lang": "en",
      "text": "And um in addition to your books, to",
      "offset": 522.719,
      "duration": 5.921
    },
    {
      "lang": "en",
      "text": "your many books, you also do a ton of",
      "offset": 525.2,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "teaching in the O'Reilly platform, which",
      "offset": 528.64,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "also actually kind of brings up, we",
      "offset": 530.32,
      "duration": 2.72
    },
    {
      "lang": "en",
      "text": "don't need to go into this in too much",
      "offset": 532,
      "duration": 1.839
    },
    {
      "lang": "en",
      "text": "detail, but it's kind of interesting",
      "offset": 533.04,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "because O'Reilly is a uniquely",
      "offset": 533.839,
      "duration": 7.281
    },
    {
      "lang": "en",
      "text": "predominant brand in tech publishing,",
      "offset": 537.36,
      "duration": 7.12
    },
    {
      "lang": "en",
      "text": "but you and I both write for Pearson.",
      "offset": 541.12,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "Mhm. Uh and I think even when you and I",
      "offset": 544.48,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "are teaching in the O'Reilly platform,",
      "offset": 546.8,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "we're usually doing that for Pearson.",
      "offset": 548.8,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "Yep. Um and it's and I I love them. I",
      "offset": 551.04,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "absolutely love same every Pearson book",
      "offset": 553.44,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "that comes out, everyone that I work",
      "offset": 556,
      "duration": 6.08
    },
    {
      "lang": "en",
      "text": "with there. Um yeah, hopefully we're uh",
      "offset": 557.68,
      "duration": 7.68
    },
    {
      "lang": "en",
      "text": "you and I are contributing to increasing",
      "offset": 562.08,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "kind of awareness of Pearson as being a",
      "offset": 565.36,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "great technical publisher for for",
      "offset": 567.2,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "hands-on data science people. Exactly.",
      "offset": 568.88,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "and and and the way that they curate all",
      "offset": 571.12,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "that information, like they have like",
      "offset": 572.72,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "those expert playlists, which I think is",
      "offset": 574.24,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "a really cool little feature. So, they",
      "offset": 576,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "basically take a lot of my videos and",
      "offset": 578,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "books and put them in order to basically",
      "offset": 579.44,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "say here's your journey. Here's how you",
      "offset": 581.68,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "should be watching these and reading",
      "offset": 583.519,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "these in in what order. So, it's not",
      "offset": 585.12,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "just here's your content. It's more like",
      "offset": 587.519,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "here's your journey. What are you trying",
      "offset": 589.68,
      "duration": 3.279
    },
    {
      "lang": "en",
      "text": "to do here? And here's what you should",
      "offset": 591.44,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "watch. I I I love that because I think a",
      "offset": 592.959,
      "duration": 4.721
    },
    {
      "lang": "en",
      "text": "lot of that education journey is is hard",
      "offset": 595.36,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "to disseminate, especially when you are",
      "offset": 597.68,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "new to the field of AI. It's I don't I",
      "offset": 599.279,
      "duration": 3.761
    },
    {
      "lang": "en",
      "text": "don't know where to start. I don't know",
      "offset": 601.76,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "how these things work. And having that",
      "offset": 603.04,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "curation is really helpful. For sure. If",
      "offset": 604.88,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "we have book authors out there or people",
      "offset": 607.6,
      "duration": 3.679
    },
    {
      "lang": "en",
      "text": "who have, you know, kind of maybe you've",
      "offset": 609.6,
      "duration": 2.96
    },
    {
      "lang": "en",
      "text": "been writing for a long time and you",
      "offset": 611.279,
      "duration": 3.521
    },
    {
      "lang": "en",
      "text": "have a book proposal in mind, reach out",
      "offset": 612.56,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "to me or reach out to son on LinkedIn",
      "offset": 614.8,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "probably and we'd be delighted to",
      "offset": 617.12,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "introduce you to folks at Pearson or",
      "offset": 618.8,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "O'Reilly for that matter. Oh yeah. Uh",
      "offset": 620.24,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "but uh if you want you know with Pearson",
      "offset": 622,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "the folks over there that we work with",
      "offset": 624.079,
      "duration": 4.561
    },
    {
      "lang": "en",
      "text": "they are so switched on about the",
      "offset": 625.92,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "industry and they can really help you uh",
      "offset": 628.64,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "kind of massage the content of your",
      "offset": 631.68,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "book. So you have big hits like Sand",
      "offset": 633.12,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "does and you we both do and yeah so in",
      "offset": 635.04,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "addition to your books you do lots of",
      "offset": 638.48,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "trainings for Pearson in the O'Reilly",
      "offset": 640.56,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "platform and uh so or.com probably lots",
      "offset": 642.64,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "of our listeners know it. Millions of",
      "offset": 645.68,
      "duration": 2.96
    },
    {
      "lang": "en",
      "text": "people subscribe to it, often through",
      "offset": 647.12,
      "duration": 3.279
    },
    {
      "lang": "en",
      "text": "their employer or through their",
      "offset": 648.64,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "university. And you teach in there a",
      "offset": 650.399,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "couple of times a month, pretty much",
      "offset": 653.44,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "every month, right? Oh, yeah. Uh about",
      "offset": 654.56,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "once a week, right? About once a week.",
      "offset": 656.72,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "That's wild. And so, uh this episode is",
      "offset": 658.8,
      "duration": 5.92
    },
    {
      "lang": "en",
      "text": "supposed to be published on July 8th,",
      "offset": 662.24,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "which means the very next day on July",
      "offset": 664.72,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "9th, you have a transformer",
      "offset": 667.04,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "architectures course, which I think kind",
      "offset": 669.04,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "of dives deeply. And actually, this one",
      "offset": 671.2,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "might really resonate with Super Data",
      "offset": 673.2,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "Science podcast listeners because the",
      "offset": 675.2,
      "duration": 6.24
    },
    {
      "lang": "en",
      "text": "most popular episode of 2024 was episode",
      "offset": 677.44,
      "duration": 6.959
    },
    {
      "lang": "en",
      "text": "747 with Kier Arnango, the founder and",
      "offset": 681.44,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "original host of this podcast. And it",
      "offset": 684.399,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "was an intro to Transformers. And it",
      "offset": 686.56,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "kind of it went into the nitty-gritty.",
      "offset": 688.959,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "And I said to him, I paused recording",
      "offset": 690.72,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "and I said to Carol, &quot;This is too much.",
      "offset": 692.8,
      "duration": 5.599
    },
    {
      "lang": "en",
      "text": "Like, you're going too deep. This is not",
      "offset": 695.36,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "going to work. like the people can't see",
      "offset": 698.399,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "things in a podcast and it was the most",
      "offset": 700.48,
      "duration": 5.039
    },
    {
      "lang": "en",
      "text": "popular episode of 2024. Exa I I",
      "offset": 702.959,
      "duration": 5.521
    },
    {
      "lang": "en",
      "text": "honestly I bet like I I I think when I",
      "offset": 705.519,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "first made that content the transformer",
      "offset": 708.48,
      "duration": 4.799
    },
    {
      "lang": "en",
      "text": "architectures for Genai was like one of",
      "offset": 711.519,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "the first pieces of content I made for",
      "offset": 713.279,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "Pearson and O'Reilly. I originally made",
      "offset": 715.44,
      "duration": 6.88
    },
    {
      "lang": "en",
      "text": "that content in 2020 I believe 2021.",
      "offset": 717.6,
      "duration": 6.64
    },
    {
      "lang": "en",
      "text": "uh Chad GPT had not come out yet and and",
      "offset": 722.32,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "and it was very much around this idea of",
      "offset": 724.24,
      "duration": 4.719
    },
    {
      "lang": "en",
      "text": "this architecture is changing things and",
      "offset": 726.32,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "what people do with it is now you know",
      "offset": 728.959,
      "duration": 4.241
    },
    {
      "lang": "en",
      "text": "open sky like we don't know what's going",
      "offset": 731.68,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "to happen and then chat GPT came out a",
      "offset": 733.2,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "couple months later so I think when that",
      "offset": 735.2,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "happened people really came back down to",
      "offset": 737.279,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "kind of back down to the roots of where",
      "offset": 739.92,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "does this come from and then people are",
      "offset": 742.639,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "shocked to realize oh you know this",
      "offset": 744.8,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "thing was invented in 2017",
      "offset": 746.32,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "what have we been doing since then why",
      "offset": 749.04,
      "duration": 4.239
    },
    {
      "lang": "en",
      "text": "Haven't we been doing anything with this",
      "offset": 751.92,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "since 2017? And then they they're even",
      "offset": 753.279,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "more shocked to realize that it actually",
      "offset": 755.44,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "came out of Google. Google invented the",
      "offset": 757.12,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "transformer architecture. And then",
      "offset": 759.519,
      "duration": 3.201
    },
    {
      "lang": "en",
      "text": "people re think about that and say,",
      "offset": 761.12,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "well, hold on. Why are they still not at",
      "offset": 762.72,
      "duration": 6.16
    },
    {
      "lang": "en",
      "text": "the top of the pack then of LLMs? You",
      "offset": 765.519,
      "duration": 4.481
    },
    {
      "lang": "en",
      "text": "know, they're doing their best to get up",
      "offset": 768.88,
      "duration": 2.48
    },
    {
      "lang": "en",
      "text": "there. But it's also it's always a very",
      "offset": 770,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "funny history to think about, you know,",
      "offset": 771.36,
      "duration": 4.479
    },
    {
      "lang": "en",
      "text": "how long ago this all was relative to",
      "offset": 773.44,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "even today. Yep. Fastmoving space. I",
      "offset": 775.839,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "mean, lots of competitors. It seems like",
      "offset": 778.32,
      "duration": 2.959
    },
    {
      "lang": "en",
      "text": "you probably know this better than me,",
      "offset": 780,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "but my understanding is that it was",
      "offset": 781.279,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "OpenAI",
      "offset": 783.6,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "uh betting big on scaling that you know",
      "offset": 785.12,
      "duration": 6.64
    },
    {
      "lang": "en",
      "text": "like Google Deep Mind which there used",
      "offset": 788.24,
      "duration": 5.92
    },
    {
      "lang": "en",
      "text": "to be kind of two big AI labs at Google,",
      "offset": 791.76,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "Google Brain and Google Deep Mind and",
      "offset": 794.16,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "DeepMind was kind of I think I mean in",
      "offset": 796.56,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "some ways they were kind of they they",
      "offset": 799.2,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "had more nature papers. They were kind",
      "offset": 800.88,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "of a lot of people might have argued",
      "offset": 802.56,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "that they were the leading AI lab in the",
      "offset": 804.72,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "world and they focused really",
      "offset": 806.48,
      "duration": 4.799
    },
    {
      "lang": "en",
      "text": "specifically on things like deep",
      "offset": 809.44,
      "duration": 5.519
    },
    {
      "lang": "en",
      "text": "reinforcement learning and uh uh having",
      "offset": 811.279,
      "duration": 5.761
    },
    {
      "lang": "en",
      "text": "you know generalizing to gradually more",
      "offset": 814.959,
      "duration": 5.521
    },
    {
      "lang": "en",
      "text": "and more tasks whereas Ilioskver at",
      "offset": 817.04,
      "duration": 6.4
    },
    {
      "lang": "en",
      "text": "OpenAI at that time",
      "offset": 820.48,
      "duration": 6.64
    },
    {
      "lang": "en",
      "text": "just had this hunch that scaling big",
      "offset": 823.44,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "would you know that we would just have",
      "offset": 827.12,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "emergent properties kind of",
      "offset": 829.04,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "automatically And uh that ended up being",
      "offset": 830.32,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "right being true. Yeah. I mean it's a",
      "offset": 833.44,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "big bet to say hey this thing works when",
      "offset": 835.04,
      "duration": 5.359
    },
    {
      "lang": "en",
      "text": "it's 200 megabytes. What if it were 200",
      "offset": 837.36,
      "duration": 6.08
    },
    {
      "lang": "en",
      "text": "gigabytes large you know and yeah it was",
      "offset": 840.399,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "right. I mean even before that though",
      "offset": 843.44,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "they were a reinforcement learning lab",
      "offset": 845.199,
      "duration": 3.361
    },
    {
      "lang": "en",
      "text": "for the most part. I mean if you know",
      "offset": 847.04,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "open before the transformer they are",
      "offset": 848.56,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "responsible for the reinforcement",
      "offset": 851.199,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "learning gym. They made a lot of content",
      "offset": 852.48,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "to teach people reinforcement learning",
      "offset": 854.959,
      "duration": 4.641
    },
    {
      "lang": "en",
      "text": "and that matters because the whole in",
      "offset": 857.12,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "their words one of the reasons chat GBT",
      "offset": 859.6,
      "duration": 6.239
    },
    {
      "lang": "en",
      "text": "works is that alignment phase including",
      "offset": 861.92,
      "duration": 5.359
    },
    {
      "lang": "en",
      "text": "reinforcement learning from human",
      "offset": 865.839,
      "duration": 3.521
    },
    {
      "lang": "en",
      "text": "feedback. So there are only so many labs",
      "offset": 867.279,
      "duration": 5.041
    },
    {
      "lang": "en",
      "text": "on the planet who really had the the",
      "offset": 869.36,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "combination of well we're already",
      "offset": 872.32,
      "duration": 2.959
    },
    {
      "lang": "en",
      "text": "working on reinforcement learning and",
      "offset": 873.76,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "this transformer architecture seems to",
      "offset": 875.279,
      "duration": 4.961
    },
    {
      "lang": "en",
      "text": "be pretty amazing and emergent. What if",
      "offset": 877.04,
      "duration": 4.799
    },
    {
      "lang": "en",
      "text": "you know what if we put those two things",
      "offset": 880.24,
      "duration": 3.039
    },
    {
      "lang": "en",
      "text": "together? What would happen? And then we",
      "offset": 881.839,
      "duration": 5.041
    },
    {
      "lang": "en",
      "text": "got chat GPT to put it simply at least.",
      "offset": 883.279,
      "duration": 5.92
    },
    {
      "lang": "en",
      "text": "Yeah. So there you go. Little uh little",
      "offset": 886.88,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "history lesson. I I assume people can",
      "offset": 889.199,
      "duration": 3.361
    },
    {
      "lang": "en",
      "text": "learn more in your transformer",
      "offset": 890.8,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "architectures course uh which you must",
      "offset": 892.56,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "you must teach recurringly on a rally if",
      "offset": 894.959,
      "duration": 5.361
    },
    {
      "lang": "en",
      "text": "if you missed it on July 9th 2025",
      "offset": 897.44,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "tomorrow theoretically uh at the time of",
      "offset": 900.32,
      "duration": 4.959
    },
    {
      "lang": "en",
      "text": "publication then you can you I'm sure",
      "offset": 902.56,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "you can check it out in the future. And",
      "offset": 905.279,
      "duration": 2.161
    },
    {
      "lang": "en",
      "text": "then you have other courses coming up in",
      "offset": 906.24,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "O'Reilly. You've got an AI agents a Toz",
      "offset": 907.44,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "and you've got a rag class coming up in",
      "offset": 909.6,
      "duration": 5.599
    },
    {
      "lang": "en",
      "text": "the coming weeks. Those are always fun.",
      "offset": 912.16,
      "duration": 5.039
    },
    {
      "lang": "en",
      "text": "Lot a lot of big crowd, a lot of people",
      "offset": 915.199,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "asking a lot of agent questions. Always",
      "offset": 917.199,
      "duration": 4.721
    },
    {
      "lang": "en",
      "text": "fun. Very nice. And in addition to the",
      "offset": 919.04,
      "duration": 5.599
    },
    {
      "lang": "en",
      "text": "books, in addition to the O'Reilly",
      "offset": 921.92,
      "duration": 5.039
    },
    {
      "lang": "en",
      "text": "teaching that you do, you also you have",
      "offset": 924.639,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "your own podcast these days, don't you?",
      "offset": 926.959,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "I do. It's it's not as big as yours,",
      "offset": 928.8,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "just don't worry.",
      "offset": 931.839,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "It's called practically intelligent and",
      "offset": 933.68,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "it started I was working with a a friend",
      "offset": 935.76,
      "duration": 6.079
    },
    {
      "lang": "en",
      "text": "of mine former student uh Akshai Bushan",
      "offset": 938.88,
      "duration": 6.56
    },
    {
      "lang": "en",
      "text": "he he's my co-host he's now the partner",
      "offset": 941.839,
      "duration": 7.92
    },
    {
      "lang": "en",
      "text": "at a VC uh Tola Capital and he basically",
      "offset": 945.44,
      "duration": 6.72
    },
    {
      "lang": "en",
      "text": "asked me one day uh over lunch or drinks",
      "offset": 949.759,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "or something and said hey you know what",
      "offset": 952.16,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "you know I I I meet a lot of cool people",
      "offset": 953.44,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "you know how to how to teach AI what if",
      "offset": 955.44,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "we just started bring some guests on and",
      "offset": 957.839,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "we've had um we've had some pretty",
      "offset": 959.839,
      "duration": 4.721
    },
    {
      "lang": "en",
      "text": "amazing people talking about the the the",
      "offset": 961.839,
      "duration": 5.521
    },
    {
      "lang": "en",
      "text": "beginnings of IBM Watson and Amazon Sage",
      "offset": 964.56,
      "duration": 5.279
    },
    {
      "lang": "en",
      "text": "Maker and we we we've we've been with a",
      "offset": 967.36,
      "duration": 3.599
    },
    {
      "lang": "en",
      "text": "lot of interesting people talking about",
      "offset": 969.839,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "a lot of interesting AI products in the",
      "offset": 970.959,
      "duration": 4.721
    },
    {
      "lang": "en",
      "text": "throughout the years.",
      "offset": 973.199,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "This episode of Super Data Science is",
      "offset": 975.68,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "brought to you by AWS Tranium 2, the",
      "offset": 977.519,
      "duration": 6.641
    },
    {
      "lang": "en",
      "text": "latest generation AI chip from AWS. AWS",
      "offset": 980.32,
      "duration": 6.4
    },
    {
      "lang": "en",
      "text": "Tranium 2 instances deliver 20.8 8",
      "offset": 984.16,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "pedaflops of compute, while the new",
      "offset": 986.72,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "Trannium 2 ultra servers combine 64",
      "offset": 988.88,
      "duration": 6.639
    },
    {
      "lang": "en",
      "text": "chips to achieve over 83 pedlops in a",
      "offset": 992.48,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "single node. Purpose-built for today's",
      "offset": 995.519,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "largest AI models, these instances offer",
      "offset": 998,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "30 to 40% better price performance",
      "offset": 1000.959,
      "duration": 4.721
    },
    {
      "lang": "en",
      "text": "relative to GPU alternatives. That's why",
      "offset": 1002.88,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "companies across the spectrum from",
      "offset": 1005.68,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "giants like Anthropic and Data Bricks to",
      "offset": 1007.36,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "cutting edge startups like Poolside are",
      "offset": 1009.6,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "choosing Trrenium 2 to power their next",
      "offset": 1011.759,
      "duration": 5.281
    },
    {
      "lang": "en",
      "text": "generation of AI workloads. Learn how",
      "offset": 1014.24,
      "duration": 5.279
    },
    {
      "lang": "en",
      "text": "AWS Trinium 2 can transform your AI",
      "offset": 1017.04,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "workloads through the links in our show",
      "offset": 1019.519,
      "duration": 5.761
    },
    {
      "lang": "en",
      "text": "notes. All right, now back to the show.",
      "offset": 1021.12,
      "duration": 6.64
    },
    {
      "lang": "en",
      "text": "Now, Tula Capital Ta Capital sounds",
      "offset": 1025.28,
      "duration": 5.679
    },
    {
      "lang": "en",
      "text": "familiar to me. Is that because Yes, it",
      "offset": 1027.76,
      "duration": 5.679
    },
    {
      "lang": "en",
      "text": "is. So, you advise them? They also advi",
      "offset": 1030.959,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "that's how we kind of got together",
      "offset": 1033.439,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "again. So Ash was a student of mine at",
      "offset": 1034.799,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "General Assembly many many years ago and",
      "offset": 1036.559,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "then eventually independently he became",
      "offset": 1039.039,
      "duration": 4.241
    },
    {
      "lang": "en",
      "text": "a partner at Tola. He invited me to help",
      "offset": 1040.88,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "advise and then that's how we started",
      "offset": 1043.28,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "talking again into eventually starting",
      "offset": 1044.88,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "uh our own show. Nice. Tell us a bit",
      "offset": 1047.199,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "about that about being a Tola Capital",
      "offset": 1049.039,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "and you know what it's like being an",
      "offset": 1050.88,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "like an adviser on AI to a financial",
      "offset": 1053.039,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "institution. Absolutely. It's it's it's",
      "offset": 1055.44,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "not what I expected. I I'll say that. Uh",
      "offset": 1059.039,
      "duration": 3.281
    },
    {
      "lang": "en",
      "text": "when they when they first asked me to",
      "offset": 1060.96,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "come on, my my expectation was was that",
      "offset": 1062.32,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "I was going to be looking at a lot of",
      "offset": 1064.96,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "different companies just kind of just",
      "offset": 1066.64,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "figuring out, you know, who who's lying,",
      "offset": 1068.32,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "who's who's on to something and and and",
      "offset": 1070.24,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "kind of where the technology actually",
      "offset": 1072.96,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "sits. But really, it's become a lot more",
      "offset": 1074.559,
      "duration": 7.521
    },
    {
      "lang": "en",
      "text": "around the education side of AI, meaning",
      "offset": 1077.2,
      "duration": 7.359
    },
    {
      "lang": "en",
      "text": "I I would rather not just be called in",
      "offset": 1082.08,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "whenever they don't know what's going",
      "offset": 1084.559,
      "duration": 3.441
    },
    {
      "lang": "en",
      "text": "on. My my thinking about it was, well,",
      "offset": 1085.919,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "what if I just teach you how it works so",
      "offset": 1088,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "that when the next company comes in, you",
      "offset": 1090.32,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "may not need to call me, which kind of",
      "offset": 1092.64,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "sounds counterintuitive because they're",
      "offset": 1094.72,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "paying me to help them do this. But",
      "offset": 1096.64,
      "duration": 5.039
    },
    {
      "lang": "en",
      "text": "that's always been my philosophy is a",
      "offset": 1099.2,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "conversation with me is not just",
      "offset": 1101.679,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "supposed to, you know, get you to your",
      "offset": 1103.28,
      "duration": 3.759
    },
    {
      "lang": "en",
      "text": "goal. It's supposed to kind of give you",
      "offset": 1105.52,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "the framework for how to actually tackle",
      "offset": 1107.039,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "this problem the next time it comes",
      "offset": 1109.28,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "around. Same with my books, right? It's,",
      "offset": 1111.2,
      "duration": 4.479
    },
    {
      "lang": "en",
      "text": "you know, this LLM will be dead in the",
      "offset": 1113.36,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "matter of years. But if the next one is",
      "offset": 1115.679,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "just some auto reggressive decoder based",
      "offset": 1118.16,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "LLM, basically everything's the same,",
      "offset": 1120,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "just replace the model name. Same thing",
      "offset": 1122.72,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "with TA. It's, hey, look, when you see a",
      "offset": 1124.64,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "company promising this, your first",
      "offset": 1126.799,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "question should be, you know, whatever",
      "offset": 1128.72,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "XYZ. So ask them that and see what they",
      "offset": 1130.4,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "say. Nice. That's some cool insight. And",
      "offset": 1133.36,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "it makes sense in that case to have",
      "offset": 1136,
      "duration": 5.919
    },
    {
      "lang": "en",
      "text": "someone like you who is such a renowned",
      "offset": 1138.48,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "AI educator to come in and do that kind",
      "offset": 1141.919,
      "duration": 3.441
    },
    {
      "lang": "en",
      "text": "of teaching role makes a lot of sense. I",
      "offset": 1144,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "bet with a lot of firms, they don't get",
      "offset": 1145.36,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "to enjoy that. And so then they do end",
      "offset": 1147.44,
      "duration": 4.239
    },
    {
      "lang": "en",
      "text": "up having to constantly be calling",
      "offset": 1150.08,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "someone in, wait to schedule a meeting",
      "offset": 1151.679,
      "duration": 4.561
    },
    {
      "lang": "en",
      "text": "when they have availability. Um, and so",
      "offset": 1153.6,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "yeah, by teaching them how to fish as it",
      "offset": 1156.24,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "were, you are allowing the kind of",
      "offset": 1157.679,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "investment cycle to proceed more",
      "offset": 1160.4,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "rapidly. And plus, they're the domain",
      "offset": 1161.679,
      "duration": 3.041
    },
    {
      "lang": "en",
      "text": "experts here. They understand market",
      "offset": 1163.44,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "share better than I do. You know, when",
      "offset": 1164.72,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "if they have a technology question, I'm",
      "offset": 1166.72,
      "duration": 2.88
    },
    {
      "lang": "en",
      "text": "happy to walk them through it. But at",
      "offset": 1168.24,
      "duration": 2.559
    },
    {
      "lang": "en",
      "text": "the end of the day, they're making the",
      "offset": 1169.6,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "business decisions here. Yeah. Yeah.",
      "offset": 1170.799,
      "duration": 3.441
    },
    {
      "lang": "en",
      "text": "Yeah. Well, you must learn from them a",
      "offset": 1172.88,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "bit. I have for sure. Yes. I've done my",
      "offset": 1174.24,
      "duration": 3.679
    },
    {
      "lang": "en",
      "text": "own investing since then. I've become a",
      "offset": 1176.16,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "little bit of a of an angel investor,",
      "offset": 1177.919,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "which has been so so rewarding. Like I I",
      "offset": 1179.6,
      "duration": 5.199
    },
    {
      "lang": "en",
      "text": "remember Yeah. Like mostly through Tola",
      "offset": 1182.799,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "or like through through companies that",
      "offset": 1184.799,
      "duration": 3.281
    },
    {
      "lang": "en",
      "text": "they recommend or you're you're kind of",
      "offset": 1186.4,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "you're you're getting them even sooner.",
      "offset": 1188.08,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "Oh, some mostly even sooner. So, I",
      "offset": 1190,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "actually live in San Francisco,",
      "offset": 1192.48,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "specifically in the Dog Patch",
      "offset": 1194.64,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "neighborhood, which if you're not",
      "offset": 1196.48,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "familiar, is the new location of where Y",
      "offset": 1198.08,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "Combinator lives. Uh, in fact, where I",
      "offset": 1200.64,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "in my apartment building, there's a lot",
      "offset": 1203.2,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "of YC founders and I can tell because",
      "offset": 1204.64,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "they they wear all the all the gear. So,",
      "offset": 1206.64,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "I just happen to meet a lot of YC",
      "offset": 1208.88,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "companies just like in my day-to-day",
      "offset": 1210.72,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "life, and I get to talking to them and",
      "offset": 1212.32,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "eventually, you know, sign a safe",
      "offset": 1214,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "because I because I can see what they're",
      "offset": 1215.6,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "doing and and I can say, I think that's",
      "offset": 1217.2,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "the right way to to think about this",
      "offset": 1219.679,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "problem. I hope and then you hope too.",
      "offset": 1221.28,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "And if we're both right, you know,",
      "offset": 1223.28,
      "duration": 3.759
    },
    {
      "lang": "en",
      "text": "win-win. Very cool. I didn't know that.",
      "offset": 1224.64,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "I didn't know that you were uh in the YC",
      "offset": 1227.039,
      "duration": 2.721
    },
    {
      "lang": "en",
      "text": "neighborhood there in Dog Patch. Knew",
      "offset": 1228.72,
      "duration": 2.88
    },
    {
      "lang": "en",
      "text": "you were in San Fran, but yeah, right in",
      "offset": 1229.76,
      "duration": 3.279
    },
    {
      "lang": "en",
      "text": "the thick of it there. That was an",
      "offset": 1231.6,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "accident. I moved here first. They",
      "offset": 1233.039,
      "duration": 5.841
    },
    {
      "lang": "en",
      "text": "follow Maybe it's not an accident. Um",
      "offset": 1235.679,
      "duration": 6.401
    },
    {
      "lang": "en",
      "text": "Okay. So, the main topic that I want to",
      "offset": 1238.88,
      "duration": 6.88
    },
    {
      "lang": "en",
      "text": "cover in this episode is related to the",
      "offset": 1242.08,
      "duration": 5.599
    },
    {
      "lang": "en",
      "text": "talk that you gave at ODSC East this",
      "offset": 1245.76,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "year. So we caught that was the last",
      "offset": 1247.679,
      "duration": 3.041
    },
    {
      "lang": "en",
      "text": "time that you and I caught up in person",
      "offset": 1249.44,
      "duration": 2.96
    },
    {
      "lang": "en",
      "text": "about a month ago at the time of",
      "offset": 1250.72,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "recording. And so you'd given a talk in",
      "offset": 1252.4,
      "duration": 8.639
    },
    {
      "lang": "en",
      "text": "May at ODSC East on um on benchmarks and",
      "offset": 1255.12,
      "duration": 8.88
    },
    {
      "lang": "en",
      "text": "specifically on limitations and pitfalls",
      "offset": 1261.039,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "around current AI benchmarks and and",
      "offset": 1264,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "what we could be doing instead. So uh",
      "offset": 1265.679,
      "duration": 6.161
    },
    {
      "lang": "en",
      "text": "I've got lots of questions for you here.",
      "offset": 1269.2,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "I we'll see how many we can get through",
      "offset": 1271.84,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "uh in one podcast episode. Let's do it.",
      "offset": 1274.24,
      "duration": 6.96
    },
    {
      "lang": "en",
      "text": "So benchmarks today, they they tend to",
      "offset": 1276.4,
      "duration": 8.159
    },
    {
      "lang": "en",
      "text": "lead the AI labs, the frontier AI labs",
      "offset": 1281.2,
      "duration": 6.16
    },
    {
      "lang": "en",
      "text": "to be competing to chase high scores on",
      "offset": 1284.559,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "the popular benchmarks, things like",
      "offset": 1287.36,
      "duration": 5.679
    },
    {
      "lang": "en",
      "text": "MMLU, humanity's last exam. Uh and so",
      "offset": 1288.72,
      "duration": 8.319
    },
    {
      "lang": "en",
      "text": "that leads teams to teach to test to use",
      "offset": 1293.039,
      "duration": 7.281
    },
    {
      "lang": "en",
      "text": "the quote where you are deliberately",
      "offset": 1297.039,
      "duration": 4.721
    },
    {
      "lang": "en",
      "text": "fine-tuning your models to be really",
      "offset": 1300.32,
      "duration": 2.56
    },
    {
      "lang": "en",
      "text": "good at these popular kinds of",
      "offset": 1301.76,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "benchmarks. Um, so how does this kind of",
      "offset": 1302.88,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "leaderboard mentality skew our",
      "offset": 1305.44,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "understanding of a model's real",
      "offset": 1308.32,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "abilities on everyday tasks that the",
      "offset": 1309.84,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "rest of us use them for? Great question.",
      "offset": 1312,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "It's a it's a tough opening question. I",
      "offset": 1313.84,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "the way I would approach that thinking",
      "offset": 1316.159,
      "duration": 5.041
    },
    {
      "lang": "en",
      "text": "about a benchmark is kind of what I said",
      "offset": 1318.4,
      "duration": 5.519
    },
    {
      "lang": "en",
      "text": "earlier. A benchmark should be the start",
      "offset": 1321.2,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "of a conversation, not the end of a",
      "offset": 1323.919,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "conversation. So even even before we you",
      "offset": 1325.76,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "or I look at a benchmark for a specific",
      "offset": 1328.559,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "model, benchmarks are used for a few",
      "offset": 1331.12,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "reasons. Benchmarks are used to evaluate",
      "offset": 1333.679,
      "duration": 5.041
    },
    {
      "lang": "en",
      "text": "the general macro trends of LLM in a",
      "offset": 1335.84,
      "duration": 6.16
    },
    {
      "lang": "en",
      "text": "specific domain or task. benchmarks are",
      "offset": 1338.72,
      "duration": 7.04
    },
    {
      "lang": "en",
      "text": "used much more intimately to decide for",
      "offset": 1342,
      "duration": 6.24
    },
    {
      "lang": "en",
      "text": "an individual or an organization which",
      "offset": 1345.76,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "models should we be considering which",
      "offset": 1348.24,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "which ones are quote unquote good at",
      "offset": 1350.159,
      "duration": 4.561
    },
    {
      "lang": "en",
      "text": "coding or good at X and they will look",
      "offset": 1351.76,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "at a benchmark performance to kind of",
      "offset": 1354.72,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "give them that that gist of of it.",
      "offset": 1356.32,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "Benchmarks, to your point, are also used",
      "offset": 1360,
      "duration": 4.559
    },
    {
      "lang": "en",
      "text": "as a marketing tactic for a company to",
      "offset": 1362,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "say, &quot;Hey, we're beating XYZ at",
      "offset": 1364.559,
      "duration": 6.161
    },
    {
      "lang": "en",
      "text": "benchmark Z. Therefore, we are a better",
      "offset": 1367.36,
      "duration": 8.96
    },
    {
      "lang": "en",
      "text": "company at task here.&quot; So, when when I",
      "offset": 1370.72,
      "duration": 7.199
    },
    {
      "lang": "en",
      "text": "think about benchmarks, the number one",
      "offset": 1376.32,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "thing I want to remind everybody is I'm",
      "offset": 1377.919,
      "duration": 3.361
    },
    {
      "lang": "en",
      "text": "not against benchmarks. Benchmarks are",
      "offset": 1379.52,
      "duration": 3.279
    },
    {
      "lang": "en",
      "text": "necessary. They are they are pretty",
      "offset": 1381.28,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "crucial to our conversation because",
      "offset": 1382.799,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "without them we're all just kind of",
      "offset": 1384.4,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "stuck in a spid's web of how I do my",
      "offset": 1386.4,
      "duration": 4.639
    },
    {
      "lang": "en",
      "text": "evaluations versus how you do your",
      "offset": 1389.2,
      "duration": 3.359
    },
    {
      "lang": "en",
      "text": "evaluations.",
      "offset": 1391.039,
      "duration": 4.241
    },
    {
      "lang": "en",
      "text": "But when it comes to these open-ended or",
      "offset": 1392.559,
      "duration": 4.801
    },
    {
      "lang": "en",
      "text": "rather I should say just open source",
      "offset": 1395.28,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "benchmarks, you're right, you you end up",
      "offset": 1397.36,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "having these harder conversations around",
      "offset": 1399.84,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "how do we know without a shadow of a",
      "offset": 1402.64,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "doubt that you are not training to test",
      "offset": 1405.28,
      "duration": 5.84
    },
    {
      "lang": "en",
      "text": "or what we might call contaminating your",
      "offset": 1408.32,
      "duration": 4.719
    },
    {
      "lang": "en",
      "text": "training data with the test set of your",
      "offset": 1411.12,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "benchmark. And a lot of that comes back",
      "offset": 1413.039,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "to the question of what is the",
      "offset": 1415.28,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "difference between open source and open",
      "offset": 1416.72,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "weights. This question came up actually",
      "offset": 1418.4,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "at a lecture today where I I mentioned",
      "offset": 1420.48,
      "duration": 6.559
    },
    {
      "lang": "en",
      "text": "LMD decontamination uh of training data",
      "offset": 1423.44,
      "duration": 6.88
    },
    {
      "lang": "en",
      "text": "for for to remove items similar to",
      "offset": 1427.039,
      "duration": 6.561
    },
    {
      "lang": "en",
      "text": "benchmark questions. And I had mentioned",
      "offset": 1430.32,
      "duration": 6.479
    },
    {
      "lang": "en",
      "text": "that the the method for doing so for a",
      "offset": 1433.6,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "lot of companies just comes down to a",
      "offset": 1436.799,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "keyword search like an engram match or",
      "offset": 1438.4,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "some kind of embedding similarity, which",
      "offset": 1440.72,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "is simply not going to be enough because",
      "offset": 1443.2,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "you can rephrase a question enough. And",
      "offset": 1444.88,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "there was their papers even found that",
      "offset": 1446.72,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "if you if you trained Llama 2 on data",
      "offset": 1448.24,
      "duration": 7.12
    },
    {
      "lang": "en",
      "text": "that was rephrased just enough to miss",
      "offset": 1451.44,
      "duration": 6.479
    },
    {
      "lang": "en",
      "text": "all of those those industry standard",
      "offset": 1455.36,
      "duration": 5.919
    },
    {
      "lang": "en",
      "text": "checks it would have beaten GPT4 at",
      "offset": 1457.919,
      "duration": 5.601
    },
    {
      "lang": "en",
      "text": "pretty common benchmarks.",
      "offset": 1461.279,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "And on one hand that's bad because well",
      "offset": 1463.52,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "clearly we don't want that. But on the",
      "offset": 1466.159,
      "duration": 2.801
    },
    {
      "lang": "en",
      "text": "other hand, it's actually good because",
      "offset": 1467.679,
      "duration": 3.521
    },
    {
      "lang": "en",
      "text": "it gives us a sense of well, we can get",
      "offset": 1468.96,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "a gut check if someone is cheating.",
      "offset": 1471.2,
      "duration": 3.359
    },
    {
      "lang": "en",
      "text": "Because if they're actually performing",
      "offset": 1473.2,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "worse than the state-of-the-art model,",
      "offset": 1474.559,
      "duration": 3.761
    },
    {
      "lang": "en",
      "text": "you would think, well, they're probably",
      "offset": 1476.96,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "not cheating. But that's also kind of a",
      "offset": 1478.32,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "double-edged sword because you would",
      "offset": 1480.64,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "say, well, hold on. I don't want to be",
      "offset": 1482,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "worse. I want to be at the same level of",
      "offset": 1483.84,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "these models. So then I want to be at",
      "offset": 1485.84,
      "duration": 5.439
    },
    {
      "lang": "en",
      "text": "the level, but I also want to prove to",
      "offset": 1488.64,
      "duration": 4.639
    },
    {
      "lang": "en",
      "text": "everyone that we're not cheating. But if",
      "offset": 1491.279,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "you're not an open source model, meaning",
      "offset": 1493.279,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "you're not also releasing the data set",
      "offset": 1495.12,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "that you use to train your system, Llama",
      "offset": 1497.6,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "is the kind of perfect example of this,",
      "offset": 1500.08,
      "duration": 4.719
    },
    {
      "lang": "en",
      "text": "it's hard to make that claim. And it",
      "offset": 1502.4,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "gets to a point where I mean I don't",
      "offset": 1504.799,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "know if you saw this but there were",
      "offset": 1506.32,
      "duration": 6.08
    },
    {
      "lang": "en",
      "text": "allegations like published in in um in",
      "offset": 1508.4,
      "duration": 7.04
    },
    {
      "lang": "en",
      "text": "TechCrunch that even the meta VP of",
      "offset": 1512.4,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "generative AI had to come out and say we",
      "offset": 1515.44,
      "duration": 5.119
    },
    {
      "lang": "en",
      "text": "did not manipulate our benchmark tests",
      "offset": 1517.52,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "because the rumors got so big because",
      "offset": 1520.559,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "people were using law before and they",
      "offset": 1522.64,
      "duration": 3.519
    },
    {
      "lang": "en",
      "text": "were kind of noticing this discrepancy",
      "offset": 1524.48,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "between it's not working for me",
      "offset": 1526.159,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "dayto-day but I'm looking at this",
      "offset": 1528.48,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "benchmark score and it's pretty darn",
      "offset": 1529.919,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "good. What's what's the deal here?",
      "offset": 1532,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "Rumors start, allegations start, and",
      "offset": 1533.919,
      "duration": 4.801
    },
    {
      "lang": "en",
      "text": "because Medic doesn't release their",
      "offset": 1536.96,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "data, all we can do is really take their",
      "offset": 1538.72,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "word for it. And they could be lying,",
      "offset": 1540.48,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "they could be telling the truth.",
      "offset": 1542.72,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "Frankly, we'll never know. And I think",
      "offset": 1544.559,
      "duration": 3.281
    },
    {
      "lang": "en",
      "text": "that's kind of the hard part. And that",
      "offset": 1546.24,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "starts to erode that trust of AI",
      "offset": 1547.84,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "Frontier Labs. You know, OpenAI",
      "offset": 1550.559,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "similarly hasn't open sourced an",
      "offset": 1553.12,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "autogressive language model in some",
      "offset": 1554.799,
      "duration": 4.721
    },
    {
      "lang": "en",
      "text": "years at this point. And they've also",
      "offset": 1556.96,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "stopped releasing, to my knowledge, they",
      "offset": 1559.52,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "stopped releasing the contents of their",
      "offset": 1561.2,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "training data after GPT3, right before",
      "offset": 1562.72,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "chat GPT. So it's been years since we've",
      "offset": 1565.039,
      "duration": 4.961
    },
    {
      "lang": "en",
      "text": "actually had a sense for what they were",
      "offset": 1568.08,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "using to train their models. And that",
      "offset": 1570,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "also leads to that sycopantic debacle,",
      "offset": 1572,
      "duration": 6.559
    },
    {
      "lang": "en",
      "text": "right? In May of this year, 2025, OpenAI",
      "offset": 1574.64,
      "duration": 6.24
    },
    {
      "lang": "en",
      "text": "released a model with little fanfare and",
      "offset": 1578.559,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "then within a week pulled it off the",
      "offset": 1580.88,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "shelf because it was just agreeing with",
      "offset": 1582.559,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "people too much. It wasn't actually",
      "offset": 1584.96,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "being a good language model. it was just",
      "offset": 1586.559,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "agreeing with everything the human said.",
      "offset": 1588.4,
      "duration": 4.879
    },
    {
      "lang": "en",
      "text": "And after the fact, they admitted, we",
      "offset": 1590.4,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "changed the reward signal in our",
      "offset": 1593.279,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "reinforcement learning alignment. And we",
      "offset": 1594.64,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "think that's what happened. But again,",
      "offset": 1596.799,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "we have to take their word for it. We",
      "offset": 1598.799,
      "duration": 2.88
    },
    {
      "lang": "en",
      "text": "have no way of actually double-checking",
      "offset": 1600.159,
      "duration": 3.201
    },
    {
      "lang": "en",
      "text": "any of this. It's just, okay, I guess",
      "offset": 1601.679,
      "duration": 3.441
    },
    {
      "lang": "en",
      "text": "please don't do that again. And that",
      "offset": 1603.36,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "starts to eat at this this kind of trust",
      "offset": 1605.12,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "in these companies, whether it's open",
      "offset": 1608.24,
      "duration": 3.439
    },
    {
      "lang": "en",
      "text": "weights or not. Yep. Some great examples",
      "offset": 1609.76,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "there that you gave. Another issue with",
      "offset": 1611.679,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "LLM benchmarks is that a lot of the the",
      "offset": 1614,
      "duration": 6.159
    },
    {
      "lang": "en",
      "text": "questions in them, they don't they don't",
      "offset": 1617.279,
      "duration": 5.121
    },
    {
      "lang": "en",
      "text": "they often don't seem practically",
      "offset": 1620.159,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "related to the kinds of problems that",
      "offset": 1622.4,
      "duration": 2.879
    },
    {
      "lang": "en",
      "text": "people solve. So, for example, I would",
      "offset": 1623.84,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "agree. Um, yeah, I think I I think I'm",
      "offset": 1625.279,
      "duration": 4.801
    },
    {
      "lang": "en",
      "text": "pulling this out of your content here.",
      "offset": 1627.679,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "Uh, but I have uh on humanity's last",
      "offset": 1630.08,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "exam, there's questions like uh how long",
      "offset": 1632.799,
      "duration": 5.601
    },
    {
      "lang": "en",
      "text": "was the second great war in Starcraft?",
      "offset": 1635.6,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "And there's also three questions on",
      "offset": 1638.4,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "League of Legends in there. Yeah. So,",
      "offset": 1640.32,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "yeah, these kinds of questions, you",
      "offset": 1643.44,
      "duration": 6.16
    },
    {
      "lang": "en",
      "text": "know, gaming trivia knowledge probably",
      "offset": 1645.44,
      "duration": 6.16
    },
    {
      "lang": "en",
      "text": "Yeah. often not the kinds of things that",
      "offset": 1649.6,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "people in a business context are",
      "offset": 1651.6,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "concerned about. But that's a good point",
      "offset": 1653.6,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "because again that that mismatch of",
      "offset": 1655.919,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "what's being tested on the benchmark",
      "offset": 1657.76,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "versus what's being marketed the",
      "offset": 1659.919,
      "duration": 5.201
    },
    {
      "lang": "en",
      "text": "benchmark is for can be quite disperate,",
      "offset": 1661.76,
      "duration": 5.519
    },
    {
      "lang": "en",
      "text": "right? A humanity's last exam, those are",
      "offset": 1665.12,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "some pretty big words, right? And if",
      "offset": 1667.279,
      "duration": 4.961
    },
    {
      "lang": "en",
      "text": "humanity's last exam includes knowing",
      "offset": 1670.08,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "what happened in season 14 of League of",
      "offset": 1672.24,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "Legends, I I don't want to take this",
      "offset": 1674.08,
      "duration": 4.719
    },
    {
      "lang": "en",
      "text": "exam either, quite frankly. Now, to be",
      "offset": 1676.72,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "fair, the counter to that would be,",
      "offset": 1678.799,
      "duration": 5.201
    },
    {
      "lang": "en",
      "text": "well, the point of the question is so",
      "offset": 1681.84,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "that the AI doesn't know the answer, it",
      "offset": 1684,
      "duration": 6.24
    },
    {
      "lang": "en",
      "text": "knows how to go find it. Okay, but",
      "offset": 1686.48,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "that's not what we're testing. There's",
      "offset": 1690.24,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "an answer and we're just checking if the",
      "offset": 1692,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "answer is right or not. So whether it",
      "offset": 1694.159,
      "duration": 4.481
    },
    {
      "lang": "en",
      "text": "memorized it just from reading it on the",
      "offset": 1696.64,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "internet versus recognized it didn't",
      "offset": 1698.64,
      "duration": 5.919
    },
    {
      "lang": "en",
      "text": "know that, looked it up, pieced together",
      "offset": 1701.84,
      "duration": 4.719
    },
    {
      "lang": "en",
      "text": "some information, and came back with the",
      "offset": 1704.559,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "right answer. That's more interesting to",
      "offset": 1706.559,
      "duration": 3.761
    },
    {
      "lang": "en",
      "text": "me. And whether it's League of Legends",
      "offset": 1708.799,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "or not, I care less because now I'm",
      "offset": 1710.32,
      "duration": 6.64
    },
    {
      "lang": "en",
      "text": "evaluating its ability to generalize the",
      "offset": 1712.799,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "process of finding new information.",
      "offset": 1716.96,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "Allah, a GI. So simply memorizing a fact",
      "offset": 1718.799,
      "duration": 6.321
    },
    {
      "lang": "en",
      "text": "and knowing how to go fill in the gaps",
      "offset": 1722.64,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "of your own knowledge and recognizing",
      "offset": 1725.12,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "that you have gaps in your knowledge for",
      "offset": 1726.88,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "me that's even more interesting. But",
      "offset": 1728.96,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "again for us when it comes to a",
      "offset": 1730.96,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "benchmark it's just no the answer was",
      "offset": 1732.799,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "17. So we're moving on now. Yeah. Yeah.",
      "offset": 1734.48,
      "duration": 4.559
    },
    {
      "lang": "en",
      "text": "Yeah. Interesting points there. What do",
      "offset": 1737.279,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "you think? So how could people do",
      "offset": 1739.039,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "better? How could benchmark makers do",
      "offset": 1741.12,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "better on this trivia versus",
      "offset": 1743.919,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "practicality kind of issue? I I think a",
      "offset": 1746,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "lot of the onus should not be on the",
      "offset": 1748.24,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "benchmark creators because I think the I",
      "offset": 1751.12,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "guess let me let me say that a different",
      "offset": 1754.24,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "way. The people who create benchmarks",
      "offset": 1755.52,
      "duration": 5.84
    },
    {
      "lang": "en",
      "text": "are already putting in a lot of work for",
      "offset": 1757.84,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "the most part. Not every benchmark is",
      "offset": 1761.36,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "perfect but for the top call it 20 30",
      "offset": 1763.2,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "benchmarks that people would recognize.",
      "offset": 1766,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "The institutions behind them generally",
      "offset": 1768.88,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "they are also frontier labs partnering",
      "offset": 1770.96,
      "duration": 5.92
    },
    {
      "lang": "en",
      "text": "with academic institutions like for SWE.",
      "offset": 1772.96,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "They are putting in a lot of work to",
      "offset": 1776.88,
      "duration": 5.039
    },
    {
      "lang": "en",
      "text": "curate read over thoroughly vet a lot of",
      "offset": 1778.72,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "these questions and answers. So I I I",
      "offset": 1781.919,
      "duration": 3.521
    },
    {
      "lang": "en",
      "text": "think a lot of that work is already",
      "offset": 1784.24,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "being done extremely well. I think the",
      "offset": 1785.44,
      "duration": 5.92
    },
    {
      "lang": "en",
      "text": "actual onus is now back on us the",
      "offset": 1788.24,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "consumer and on the frontier labs",
      "offset": 1791.36,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "themselves because again when you're",
      "offset": 1793.2,
      "duration": 6.56
    },
    {
      "lang": "en",
      "text": "chasing a a large number on a benchmark",
      "offset": 1796.24,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "you can take shortcuts. I'll give you",
      "offset": 1799.76,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "another example. If you look at I mean",
      "offset": 1801.76,
      "duration": 7.12
    },
    {
      "lang": "en",
      "text": "honestly any LLM um marketing page",
      "offset": 1804.08,
      "duration": 7.52
    },
    {
      "lang": "en",
      "text": "you're you're going to find some table",
      "offset": 1808.88,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "where each row is a benchmark in each",
      "offset": 1811.6,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "column is an LLM and usually theirs is",
      "offset": 1813.76,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "the first one and they circle their",
      "offset": 1816.32,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "their numbers and they're showing you",
      "offset": 1817.679,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "the scores on the benchmarks compared to",
      "offset": 1820.32,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "other leading models in that category.",
      "offset": 1822.08,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "Sure, great. However, underneath the",
      "offset": 1823.84,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "name of the benchmark, often they will",
      "offset": 1826.48,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "also in small print say something like",
      "offset": 1828.48,
      "duration": 6.079
    },
    {
      "lang": "en",
      "text": "five shot coot. And what they're saying",
      "offset": 1831.2,
      "duration": 6.959
    },
    {
      "lang": "en",
      "text": "is we tried this just by asking the",
      "offset": 1834.559,
      "duration": 6.48
    },
    {
      "lang": "en",
      "text": "questions and it didn't go so well. So",
      "offset": 1838.159,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "what we did is we added fot learning and",
      "offset": 1841.039,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "chain of thought prompting and then all",
      "offset": 1843.679,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "of a sudden our model was better than",
      "offset": 1845.919,
      "duration": 5.841
    },
    {
      "lang": "en",
      "text": "this other one. And you go, okay, so",
      "offset": 1848.08,
      "duration": 5.599
    },
    {
      "lang": "en",
      "text": "that's fine, but you're not telling me",
      "offset": 1851.76,
      "duration": 3.279
    },
    {
      "lang": "en",
      "text": "the whole story. If I don't know",
      "offset": 1853.679,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "anything about LLM's, I might look at",
      "offset": 1855.039,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "that and just say, &quot;Oh, LLM A is better",
      "offset": 1856.799,
      "duration": 6.081
    },
    {
      "lang": "en",
      "text": "than LLM B.&quot; But actually, the takeaway",
      "offset": 1859.679,
      "duration": 7.36
    },
    {
      "lang": "en",
      "text": "is LLMA responds very positively to fot",
      "offset": 1862.88,
      "duration": 7.039
    },
    {
      "lang": "en",
      "text": "learning. So, when I use LMA for",
      "offset": 1867.039,
      "duration": 5.921
    },
    {
      "lang": "en",
      "text": "whatever task, I should attempt to",
      "offset": 1869.919,
      "duration": 5.601
    },
    {
      "lang": "en",
      "text": "induce fot learning into that system",
      "offset": 1872.96,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "because they're claiming they can only",
      "offset": 1875.52,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "make it better than other models by",
      "offset": 1877.6,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "introducing that prompting technique. So",
      "offset": 1879.6,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "the onus I think in in my opinion is is",
      "offset": 1881.76,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "less on the benchmark creators and just",
      "offset": 1884.64,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "more back on the education side of the",
      "offset": 1886.88,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "frontier labs is to say look we're an",
      "offset": 1888.559,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "open book here when we say our model got",
      "offset": 1890.799,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "x% this is how we did it this is what we",
      "offset": 1892.72,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "use you can replicate it here and if",
      "offset": 1894.96,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "you're going to use it we recommended",
      "offset": 1897.12,
      "duration": 3.279
    },
    {
      "lang": "en",
      "text": "doing it this way and then if you do I",
      "offset": 1898.64,
      "duration": 3.279
    },
    {
      "lang": "en",
      "text": "think everything is going to be great",
      "offset": 1900.399,
      "duration": 5.201
    },
    {
      "lang": "en",
      "text": "that's what more of what I want to see",
      "offset": 1901.919,
      "duration": 5.841
    },
    {
      "lang": "en",
      "text": "this episode is sponsored by adverity an",
      "offset": 1905.6,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "integrated data platform for connecting",
      "offset": 1907.76,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "managing and using your data at scale.",
      "offset": 1909.76,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "Imagine being able to ask your data a",
      "offset": 1911.919,
      "duration": 3.521
    },
    {
      "lang": "en",
      "text": "question just like you would a colleague",
      "offset": 1913.84,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "and getting an answer instantly. No more",
      "offset": 1915.44,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "digging through dashboards, waiting on",
      "offset": 1917.919,
      "duration": 3.441
    },
    {
      "lang": "en",
      "text": "reports, or dealing with complex BI",
      "offset": 1919.44,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "tools. Just the insights you need right",
      "offset": 1921.36,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "when you need them. With Adverity's AI",
      "offset": 1923.44,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "powered data conversations, marketers",
      "offset": 1925.36,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "will finally talk to their data in plain",
      "offset": 1927.44,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "English. Get instant answers, make",
      "offset": 1929.76,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "smarter decisions, collaborate more",
      "offset": 1931.6,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "easily, and cut reporting time in half.",
      "offset": 1933.36,
      "duration": 4.559
    },
    {
      "lang": "en",
      "text": "What questions will you ask? To learn",
      "offset": 1935.76,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "more, check out the show notes or visit",
      "offset": 1937.919,
      "duration": 4.561
    },
    {
      "lang": "en",
      "text": "www.adverity.com.",
      "offset": 1939.84,
      "duration": 4.719
    },
    {
      "lang": "en",
      "text": "That's advi",
      "offset": 1942.48,
      "duration": 5.079
    },
    {
      "lang": "en",
      "text": "ty.com.",
      "offset": 1944.559,
      "duration": 3
    },
    {
      "lang": "en",
      "text": "Nice. And in your response, you",
      "offset": 1948.32,
      "duration": 4.479
    },
    {
      "lang": "en",
      "text": "mentioned SWE or it's very often often",
      "offset": 1949.919,
      "duration": 6.161
    },
    {
      "lang": "en",
      "text": "called SWEBench. Yeah.",
      "offset": 1952.799,
      "duration": 7.441
    },
    {
      "lang": "en",
      "text": "Uh so yeah, uh software evaluation",
      "offset": 1956.08,
      "duration": 6.959
    },
    {
      "lang": "en",
      "text": "benchmark. Oh man, I don't even know.",
      "offset": 1960.24,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "Should have looked it up before I asked",
      "offset": 1963.039,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "the question. The software engineering",
      "offset": 1964.08,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "software engineering. Software",
      "offset": 1967.12,
      "duration": 2.799
    },
    {
      "lang": "en",
      "text": "engineering. Yeah. Benchmark. Right.",
      "offset": 1968.32,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "Right. Right. Um and so are benchmarks",
      "offset": 1969.919,
      "duration": 6.64
    },
    {
      "lang": "en",
      "text": "like that that are domain specific are",
      "offset": 1974.08,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "are they starting to resolve some of the",
      "offset": 1976.559,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "issues that that you have with",
      "offset": 1978.48,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "benchmarks that that maybe you know are",
      "offset": 1980.799,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "are trying to be so broad that you don't",
      "offset": 1983.2,
      "duration": 2.719
    },
    {
      "lang": "en",
      "text": "even really know what they're testing",
      "offset": 1984.96,
      "duration": 2.16
    },
    {
      "lang": "en",
      "text": "when they have things like trivia in",
      "offset": 1985.919,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "them. Well, SUI uh is actually a really",
      "offset": 1987.12,
      "duration": 4.559
    },
    {
      "lang": "en",
      "text": "good example of a benchmark that goes",
      "offset": 1989.76,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "beyond just answer the question because",
      "offset": 1991.679,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "I think before before SUI, most",
      "offset": 1994.159,
      "duration": 5.041
    },
    {
      "lang": "en",
      "text": "benchmarks were multiple choice or some",
      "offset": 1996.799,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "kind of one to two sentence free",
      "offset": 1999.2,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "response. The one that comes to mind a",
      "offset": 2001.679,
      "duration": 4.961
    },
    {
      "lang": "en",
      "text": "lot is MMLU. MMLU is entirely multiple",
      "offset": 2003.6,
      "duration": 5.439
    },
    {
      "lang": "en",
      "text": "choice. It's basically the SAT, but even",
      "offset": 2006.64,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "the SAT has free response sections,",
      "offset": 2009.039,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "which is fine. Again, on one hand,",
      "offset": 2011.44,
      "duration": 4.239
    },
    {
      "lang": "en",
      "text": "that's fine. You're allowed to ask an AI",
      "offset": 2013.2,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "a multiple choice question. However, you",
      "offset": 2015.679,
      "duration": 6.88
    },
    {
      "lang": "en",
      "text": "you forget sometimes or one forgets that",
      "offset": 2018.08,
      "duration": 6.24
    },
    {
      "lang": "en",
      "text": "transformer-based architectures are very",
      "offset": 2022.559,
      "duration": 2.96
    },
    {
      "lang": "en",
      "text": "very prone to something called a",
      "offset": 2024.32,
      "duration": 2.64
    },
    {
      "lang": "en",
      "text": "positional bias where they tend to",
      "offset": 2025.519,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "prefer the first elements in a multiple",
      "offset": 2026.96,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "choice over the last elements of a",
      "offset": 2029.44,
      "duration": 4.719
    },
    {
      "lang": "en",
      "text": "multiple choice. In more recent models",
      "offset": 2031.12,
      "duration": 5.279
    },
    {
      "lang": "en",
      "text": "that that positional bias is quite small",
      "offset": 2034.159,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "mostly because of the uh the",
      "offset": 2036.399,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "improvements in positional embeddings",
      "offset": 2038.399,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "but we can talk about that another time",
      "offset": 2040.24,
      "duration": 5.279
    },
    {
      "lang": "en",
      "text": "or positional encodings. But the point",
      "offset": 2042.799,
      "duration": 5.521
    },
    {
      "lang": "en",
      "text": "stands is actually transformer-based",
      "offset": 2045.519,
      "duration": 5.921
    },
    {
      "lang": "en",
      "text": "decoderbased LLMs are naturally biased",
      "offset": 2048.32,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "against being good at multiple choice",
      "offset": 2051.44,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "questions. So if that's true, when you",
      "offset": 2053.2,
      "duration": 5.84
    },
    {
      "lang": "en",
      "text": "give it an entirely multiple choice",
      "offset": 2057.2,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "benchmark like MMLU, you have to",
      "offset": 2059.04,
      "duration": 4.879
    },
    {
      "lang": "en",
      "text": "remember with a grain of salt that hey,",
      "offset": 2061.44,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "you know, maybe ask the same question 10",
      "offset": 2063.919,
      "duration": 4.881
    },
    {
      "lang": "en",
      "text": "times. Switch up the order of the",
      "offset": 2066.24,
      "duration": 4.639
    },
    {
      "lang": "en",
      "text": "answers and see if it gets the right",
      "offset": 2068.8,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "answer even when it's the first one, the",
      "offset": 2070.879,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "last one or something in the middle",
      "offset": 2072.639,
      "duration": 2.96
    },
    {
      "lang": "en",
      "text": "because if you can't get that",
      "offset": 2074.159,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "resistance, that resiliency, consistency",
      "offset": 2075.599,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "out of the LLM, that's also going to be",
      "offset": 2078.32,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "a problem. So you can still use the same",
      "offset": 2080.399,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "benchmark, but manipulate it in such a",
      "offset": 2082.399,
      "duration": 4.801
    },
    {
      "lang": "en",
      "text": "way that you actually get that sense of",
      "offset": 2085.119,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "consistency. Ask the same question 20",
      "offset": 2087.2,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "times and you change the temperature up",
      "offset": 2089.119,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "and down, switch everything around, you",
      "offset": 2091.119,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "better hope it still gets the same",
      "offset": 2093.2,
      "duration": 3.679
    },
    {
      "lang": "en",
      "text": "answer more often than not. For folks",
      "offset": 2094.399,
      "duration": 4.641
    },
    {
      "lang": "en",
      "text": "listening who maybe haven't been using",
      "offset": 2096.879,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "LLM's hands-on in a coding environment,",
      "offset": 2099.04,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "what's temperature? Temperature is",
      "offset": 2101.04,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "probably the most popular inference",
      "offset": 2103.2,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "parameter. It's basically a number. It's",
      "offset": 2105.52,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "a lever you're allowed to change while",
      "offset": 2107.28,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "you are asking the LLM a question. So",
      "offset": 2109.92,
      "duration": 5.439
    },
    {
      "lang": "en",
      "text": "when you ask the LLM a question, by",
      "offset": 2112.96,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "default, the temperature, which is a",
      "offset": 2115.359,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "number, is one. And that just means the",
      "offset": 2116.88,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "LM is picking tokens one after another.",
      "offset": 2119.28,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "If you ask it again, it it'll it'll give",
      "offset": 2122.24,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "something relatively similar, but the",
      "offset": 2124.32,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "words might be a little bit different,",
      "offset": 2126,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "but basically the same. If you turn the",
      "offset": 2127.44,
      "duration": 5.679
    },
    {
      "lang": "en",
      "text": "temperature down, what you're basically",
      "offset": 2130.32,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "doing is you're changing that",
      "offset": 2133.119,
      "duration": 3.281
    },
    {
      "lang": "en",
      "text": "distribution, that probability",
      "offset": 2134.72,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "distribution, so that what was 80%",
      "offset": 2136.4,
      "duration": 6.8
    },
    {
      "lang": "en",
      "text": "likely to show up now is 99% likely to",
      "offset": 2139.76,
      "duration": 6.24
    },
    {
      "lang": "en",
      "text": "show up. What was 2% likely to show up",
      "offset": 2143.2,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "is now 0.1% likely to show up. You're",
      "offset": 2146,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "really sharpening the distribution. It's",
      "offset": 2148.96,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "more likely that you'll get the same",
      "offset": 2151.2,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "answer over and over and over again. If",
      "offset": 2152.72,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "you increase the temperature, the",
      "offset": 2155.119,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "opposite happens. it, you get much more",
      "offset": 2156.56,
      "duration": 5.279
    },
    {
      "lang": "en",
      "text": "diverse responses. Fun fact, if you go",
      "offset": 2159.119,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "right now to OpenAI and their playground",
      "offset": 2161.839,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "and you turn the temperature up all the",
      "offset": 2164.079,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "way they let you, which is two, and you",
      "offset": 2165.839,
      "duration": 4.721
    },
    {
      "lang": "en",
      "text": "ask it a basic question, you are very,",
      "offset": 2168.16,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "very likely going to see some literal",
      "offset": 2170.56,
      "duration": 5.039
    },
    {
      "lang": "en",
      "text": "absolute gibberish come out of the LLM.",
      "offset": 2173.2,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "So, it's a little fun thing that I tell",
      "offset": 2175.599,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "my students to do because they used to",
      "offset": 2177.52,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "not let you turn the temperature up",
      "offset": 2179.68,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "beyond one. It used to be 0 to one. Now,",
      "offset": 2181.839,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "it's 0 to2. And for the life of me,",
      "offset": 2184.72,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "someone has never explained this to me.",
      "offset": 2187.599,
      "duration": 3.441
    },
    {
      "lang": "en",
      "text": "I don't understand the decision as to",
      "offset": 2189.04,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "why to let someone increase the",
      "offset": 2191.04,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "temperature more than one. You are",
      "offset": 2192.88,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "asking for trouble. So when I say change",
      "offset": 2194.72,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "the temperature, I'm I'm very much",
      "offset": 2197.04,
      "duration": 4.799
    },
    {
      "lang": "en",
      "text": "saying put it in hot water. Like make it",
      "offset": 2198.88,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "harder for the LLM by turning up the",
      "offset": 2201.839,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "temperature. You know, the analogy still",
      "offset": 2204.32,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "fits. Turn the temperature up. Ask it",
      "offset": 2206,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "again. And if it still answers the",
      "offset": 2208.48,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "question correctly pretty consistently,",
      "offset": 2210.72,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "you you've got yourself a pretty smart",
      "offset": 2212.96,
      "duration": 2.8
    },
    {
      "lang": "en",
      "text": "model.",
      "offset": 2214.64,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "Nice. Uh, thanks for those insights into",
      "offset": 2215.76,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "temperature there. I learned some things",
      "offset": 2218.32,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "there. Uh, I have never tried turning it",
      "offset": 2219.76,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "up to two. Maybe I will just for fun.",
      "offset": 2222.4,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "Oh, it's fun. Yeah. One other issue. So,",
      "offset": 2224,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "we've talked about already about issues",
      "offset": 2226,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "like um teaching to test with benchmarks",
      "offset": 2227.92,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "being a problem. We've talked about",
      "offset": 2231.76,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "trivia being included when maybe the",
      "offset": 2233.68,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "benchmark you kind of expect it to be",
      "offset": 2236.079,
      "duration": 4.641
    },
    {
      "lang": "en",
      "text": "just kind of a general intelligence kind",
      "offset": 2238.16,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "of benchmark. Maybe useful for your",
      "offset": 2240.72,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "enterprise. Trivia is still use. Trivia",
      "offset": 2242.4,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "is still useful mostly for hallucination",
      "offset": 2244.32,
      "duration": 4.799
    },
    {
      "lang": "en",
      "text": "rates because if you want a really quick",
      "offset": 2247.04,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "and cheap way to test how much your",
      "offset": 2249.119,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "model will make something up slash",
      "offset": 2251.28,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "generate something with confidence that",
      "offset": 2253.599,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "is untrue, trivia is actually perfect",
      "offset": 2255.2,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "for that. Like person QA, simple QA,",
      "offset": 2257.28,
      "duration": 4.559
    },
    {
      "lang": "en",
      "text": "those are two benchmarks which are about",
      "offset": 2260.16,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "just basic question and answer. I have a",
      "offset": 2261.839,
      "duration": 4.481
    },
    {
      "lang": "en",
      "text": "trivia question, there's a relatively",
      "offset": 2264,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "static answer that I'm expecting. So for",
      "offset": 2266.32,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "those kinds of benchmarks, they they can",
      "offset": 2269.04,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "also test things like hallucination.",
      "offset": 2271.04,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "Everything has a place. But if you don't",
      "offset": 2272.64,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "care about hallucinations, like you're",
      "offset": 2274.8,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "not expecting your model to regurgitate",
      "offset": 2276.72,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "facts and therefore I don't care if it",
      "offset": 2278.72,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "hallucinates, that's debatable, but then",
      "offset": 2280.24,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "you don't care about those benchmarks.",
      "offset": 2283.119,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "So, but every benchmark generally does",
      "offset": 2284.56,
      "duration": 4.799
    },
    {
      "lang": "en",
      "text": "have its purpose. Nice. Okay, I see. Uh",
      "offset": 2286.8,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "that was a good clarification. Um but uh",
      "offset": 2289.359,
      "duration": 4.961
    },
    {
      "lang": "en",
      "text": "yeah, so still for sure the teaching to",
      "offset": 2292.56,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "test was a big issue. Um the we talked",
      "offset": 2294.32,
      "duration": 6.32
    },
    {
      "lang": "en",
      "text": "about domain specific benchmarks and how",
      "offset": 2298.32,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "those can potentially",
      "offset": 2300.64,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "uh be more useful especially if you're",
      "offset": 2303.28,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "going to be doing like something like",
      "offset": 2304.96,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "Swebench is going to be useful for you",
      "offset": 2306.4,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "if you're going to be taking an open",
      "offset": 2308.96,
      "duration": 5.119
    },
    {
      "lang": "en",
      "text": "source LLM and putting it in your IDE",
      "offset": 2311.44,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "that you're developing for software",
      "offset": 2314.079,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "developers. Um another issue that we",
      "offset": 2315.92,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "haven't talked about yet is well",
      "offset": 2319.359,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "actually maybe it is maybe you just said",
      "offset": 2321.68,
      "duration": 2.48
    },
    {
      "lang": "en",
      "text": "it there with hallucinations. I guess",
      "offset": 2322.96,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "that's kind of the same as truthfulness",
      "offset": 2324.16,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "because you can end up in a situation",
      "offset": 2326.64,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "where a model could say ACE MMLU",
      "offset": 2327.92,
      "duration": 6.72
    },
    {
      "lang": "en",
      "text": "uh in terms of capabilities but struggle",
      "offset": 2332.32,
      "duration": 5.279
    },
    {
      "lang": "en",
      "text": "on something like truth QA, truthful QA.",
      "offset": 2334.64,
      "duration": 6.719
    },
    {
      "lang": "en",
      "text": "Um and so like it outputs convincing",
      "offset": 2337.599,
      "duration": 6.721
    },
    {
      "lang": "en",
      "text": "misinformation. So I guess what you were",
      "offset": 2341.359,
      "duration": 5.121
    },
    {
      "lang": "en",
      "text": "describing there with uh some of these",
      "offset": 2344.32,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "questions like the trivia I guess",
      "offset": 2346.48,
      "duration": 2.8
    },
    {
      "lang": "en",
      "text": "they're kind of addressing they're",
      "offset": 2348.16,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "trying to something like hle humanity's",
      "offset": 2349.28,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "last exam by including the trivia are",
      "offset": 2352.079,
      "duration": 4.801
    },
    {
      "lang": "en",
      "text": "they trying to get at the the",
      "offset": 2354.24,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "hallucinations the truthfulness at the",
      "offset": 2356.88,
      "duration": 6.08
    },
    {
      "lang": "en",
      "text": "same time as uh capabilities maybe I I",
      "offset": 2358.56,
      "duration": 6.16
    },
    {
      "lang": "en",
      "text": "don't think so I I I don't think so",
      "offset": 2362.96,
      "duration": 4.639
    },
    {
      "lang": "en",
      "text": "because we already have if you are",
      "offset": 2364.72,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "trying to test a model's just basic",
      "offset": 2367.599,
      "duration": 5.281
    },
    {
      "lang": "en",
      "text": "ability to not make stuff up. Why go as",
      "offset": 2369.68,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "far as a very niche thing like",
      "offset": 2372.88,
      "duration": 4.719
    },
    {
      "lang": "en",
      "text": "Starcraft? Why not like person QA,",
      "offset": 2374.8,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "Truthful QA, stick to the big things",
      "offset": 2377.599,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "like this is a real question from",
      "offset": 2379.92,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "Truthful QA. What happens if you eat",
      "offset": 2381.44,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "watermelon seeds? That is a real",
      "offset": 2383.839,
      "duration": 6.161
    },
    {
      "lang": "en",
      "text": "question on truthful QA. Um, that's a",
      "offset": 2385.92,
      "duration": 6.48
    },
    {
      "lang": "en",
      "text": "fair question and technically you could",
      "offset": 2390,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "answer it in a few different ways. There",
      "offset": 2392.4,
      "duration": 2.719
    },
    {
      "lang": "en",
      "text": "are a few different reference answers",
      "offset": 2393.839,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "for that one question. But again, it's a",
      "offset": 2395.119,
      "duration": 5.281
    },
    {
      "lang": "en",
      "text": "general piece of knowledge that in",
      "offset": 2398.16,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "theory anyone on the planet can get",
      "offset": 2400.4,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "some, you know, advice from. Is it that",
      "offset": 2402.64,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "you grow a watermelon in your stomach",
      "offset": 2405.76,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "sit on? Is that the correct answer?",
      "offset": 2407.44,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "Well, if you watch Magic School Bus, I'm",
      "offset": 2409.04,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "pretty sure that isn't that is on the",
      "offset": 2410.88,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "table. Um, so like when when you talk",
      "offset": 2412.64,
      "duration": 5.199
    },
    {
      "lang": "en",
      "text": "about these benchmarks, it it's it's it",
      "offset": 2415.76,
      "duration": 3.599
    },
    {
      "lang": "en",
      "text": "baffles me to think why does it have to",
      "offset": 2417.839,
      "duration": 3.041
    },
    {
      "lang": "en",
      "text": "be Starcraft? like why can't it be",
      "offset": 2419.359,
      "duration": 3.361
    },
    {
      "lang": "en",
      "text": "something that we all kind of recognize",
      "offset": 2420.88,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "as correct gen because again even even",
      "offset": 2422.72,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "on the simple person QA and simple QA",
      "offset": 2425.68,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "benchmarks a model like 03 according to",
      "offset": 2428.24,
      "duration": 5.599
    },
    {
      "lang": "en",
      "text": "OpenAI themselves will hallucinate as",
      "offset": 2431.28,
      "duration": 6.24
    },
    {
      "lang": "en",
      "text": "much as 40% of the time that's a lot if",
      "offset": 2433.839,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "it's already hallucinating that much on",
      "offset": 2437.52,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "a relatively basic benchmark like tell",
      "offset": 2439.839,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "me about these famous people who you",
      "offset": 2442.16,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "should really know about by reading the",
      "offset": 2443.76,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "internet at this point why go niche and",
      "offset": 2445.2,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "go to Starcraft if we can't even that",
      "offset": 2447.76,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "person trivia, right? It's so",
      "offset": 2449.599,
      "duration": 3.281
    },
    {
      "lang": "en",
      "text": "interesting when I hear things like that",
      "offset": 2451.28,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "40% hallucination rate with models like",
      "offset": 2452.88,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "that. I'm so surprised because when I",
      "offset": 2455.44,
      "duration": 5.84
    },
    {
      "lang": "en",
      "text": "use like 01",
      "offset": 2458,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "particularly, and maybe it's because of",
      "offset": 2461.28,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "most of my usage of models like 01 and",
      "offset": 2463.76,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "03 is within OpenAI's deep research",
      "offset": 2466.16,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "framework. I was about to say you're",
      "offset": 2468.72,
      "duration": 2.56
    },
    {
      "lang": "en",
      "text": "probably getting some grounded",
      "offset": 2470.16,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "information from the web and these are",
      "offset": 2471.28,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "not using these are not allowed to go to",
      "offset": 2473.2,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "the web. These these have to be from the",
      "offset": 2475.04,
      "duration": 4.799
    },
    {
      "lang": "en",
      "text": "gut. From the LLM's gut. Tell me about",
      "offset": 2477.359,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "Albert Einstein or whatever. I don't",
      "offset": 2479.839,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "actually know who he's in. In person QA.",
      "offset": 2481.76,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "The old LLM gut.",
      "offset": 2483.68,
      "duration": 6.56
    },
    {
      "lang": "en",
      "text": "Um, nice. Okay. You uh you right at the",
      "offset": 2486.56,
      "duration": 5.759
    },
    {
      "lang": "en",
      "text": "beginning, you were near the beginning I",
      "offset": 2490.24,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "was talking about benchmarks. Um, you",
      "offset": 2492.319,
      "duration": 5.121
    },
    {
      "lang": "en",
      "text": "talked about contamination.",
      "offset": 2495.04,
      "duration": 6.24
    },
    {
      "lang": "en",
      "text": "Um, and so what is the resolution there?",
      "offset": 2497.44,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "This seems like a really tricky problem.",
      "offset": 2501.28,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "like how do we prevent leaks, you know,",
      "offset": 2503.04,
      "duration": 6.96
    },
    {
      "lang": "en",
      "text": "once once a benchmark's been out and the",
      "offset": 2505.52,
      "duration": 6.64
    },
    {
      "lang": "en",
      "text": "answers are online? I mean, I guess one",
      "offset": 2510,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "solution is to just not have answers",
      "offset": 2512.16,
      "duration": 3.439
    },
    {
      "lang": "en",
      "text": "online. Tell that to the internet. Well,",
      "offset": 2513.44,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "because here's the thing. If a benchmark",
      "offset": 2515.599,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "literally comes with the answers, that's",
      "offset": 2518,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "the whole point of the benchmark is",
      "offset": 2520,
      "duration": 2.72
    },
    {
      "lang": "en",
      "text": "you're supposed to know the right",
      "offset": 2521.44,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "answer. So, the same place where you get",
      "offset": 2522.72,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "the questions for the benchmark also has",
      "offset": 2524.88,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "the answers to the benchmarks where you",
      "offset": 2527.119,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "can validate that it's correct. So it's",
      "offset": 2528.88,
      "duration": 4.959
    },
    {
      "lang": "en",
      "text": "impossible to not have the answers not",
      "offset": 2531.44,
      "duration": 4.879
    },
    {
      "lang": "en",
      "text": "on the internet. Couldn't you couldn't",
      "offset": 2533.839,
      "duration": 4.801
    },
    {
      "lang": "en",
      "text": "you have something like it could be like",
      "offset": 2536.319,
      "duration": 5.681
    },
    {
      "lang": "en",
      "text": "kegle? Exactly. I mean you could but",
      "offset": 2538.64,
      "duration": 6.16
    },
    {
      "lang": "en",
      "text": "then who owns it? Who owns who owns",
      "offset": 2542,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "someone has to own it? Well, someone has",
      "offset": 2544.8,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "to because if it's going to be hidden",
      "offset": 2546.96,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "from everybody else, someone now is in",
      "offset": 2548.56,
      "duration": 4.559
    },
    {
      "lang": "en",
      "text": "charge of holding those those answers.",
      "offset": 2550.72,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "So who is it? The developer. like I",
      "offset": 2553.119,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "guess in kind of the same way that um so",
      "offset": 2554.96,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "so okay here's an interesting here's an",
      "offset": 2557.44,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "interesting idea so what about a",
      "offset": 2559.68,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "solution like chatbot arena where in",
      "offset": 2560.96,
      "duration": 6.32
    },
    {
      "lang": "en",
      "text": "chatbot arena there's no there there's",
      "offset": 2564.24,
      "duration": 5.359
    },
    {
      "lang": "en",
      "text": "no correct answer necessarily it's so",
      "offset": 2567.28,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "it's run by Berkeley uh the LM CIS lab",
      "offset": 2569.599,
      "duration": 5.281
    },
    {
      "lang": "en",
      "text": "if I'm remembering correctly I think",
      "offset": 2573.04,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "it's Joey Gonzalez's lab and so Joey",
      "offset": 2574.88,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "Gonzalez has actually been on this show",
      "offset": 2577.28,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "talking about it uh if I can find that",
      "offset": 2579.04,
      "duration": 6.72
    },
    {
      "lang": "en",
      "text": "episode quickly yes episode 707 uh you",
      "offset": 2581.52,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "can hear from the Berkeley professor",
      "offset": 2585.76,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "that you know was in his lab that this",
      "offset": 2587.52,
      "duration": 4.559
    },
    {
      "lang": "en",
      "text": "chatbot arena was devised and so in the",
      "offset": 2590,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "chat arena it's different from",
      "offset": 2592.079,
      "duration": 4.721
    },
    {
      "lang": "en",
      "text": "benchmarks in the sense that you don't",
      "offset": 2594.079,
      "duration": 4.881
    },
    {
      "lang": "en",
      "text": "have a specific set of questions and",
      "offset": 2596.8,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "answers you pit two LLMs against each",
      "offset": 2598.96,
      "duration": 6.639
    },
    {
      "lang": "en",
      "text": "other and you as a human evaluator of",
      "offset": 2602.24,
      "duration": 5.599
    },
    {
      "lang": "en",
      "text": "the arena you don't know which two",
      "offset": 2605.599,
      "duration": 4.561
    },
    {
      "lang": "en",
      "text": "you're seeking output from but you you",
      "offset": 2607.839,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "pick one as better than the other and so",
      "offset": 2610.16,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "first of of all, I'd love to hear your",
      "offset": 2613.599,
      "duration": 2.72
    },
    {
      "lang": "en",
      "text": "thoughts on the arena, but the the",
      "offset": 2614.48,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "reason why I'm bringing the arena up is",
      "offset": 2616.319,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "that in that situation, I mean, so",
      "offset": 2618.24,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "you're talking about like ownership, you",
      "offset": 2620.4,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "could have a similar kind of thing where",
      "offset": 2622.079,
      "duration": 4.721
    },
    {
      "lang": "en",
      "text": "for a benchmark where, you know,",
      "offset": 2624.72,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "somebody creates a training set like",
      "offset": 2626.8,
      "duration": 3.519
    },
    {
      "lang": "en",
      "text": "humanity's last exam, you could have a",
      "offset": 2628.16,
      "duration": 6.24
    },
    {
      "lang": "en",
      "text": "hold out uh answer set and yeah, I mean,",
      "offset": 2630.319,
      "duration": 6.081
    },
    {
      "lang": "en",
      "text": "some like a university like Berkeley",
      "offset": 2634.4,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "could be administering it. Um, you know,",
      "offset": 2636.4,
      "duration": 6.48
    },
    {
      "lang": "en",
      "text": "people submit uh Yeah, people submit",
      "offset": 2639.04,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "their responses and then they get a",
      "offset": 2642.88,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "grade back. Yeah, I a few things. I I",
      "offset": 2644.48,
      "duration": 5.119
    },
    {
      "lang": "en",
      "text": "I'm a fan of the arena in general. The",
      "offset": 2647.04,
      "duration": 6.079
    },
    {
      "lang": "en",
      "text": "the idea of blind judging from a human",
      "offset": 2649.599,
      "duration": 6.961
    },
    {
      "lang": "en",
      "text": "for me is one of the best ways to really",
      "offset": 2653.119,
      "duration": 7.681
    },
    {
      "lang": "en",
      "text": "get a good sense of an LLM's usability.",
      "offset": 2656.56,
      "duration": 6.72
    },
    {
      "lang": "en",
      "text": "Now, a couple things caveats there. If",
      "offset": 2660.8,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "I'm just a lay person talking to a",
      "offset": 2663.28,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "chatbot, to your point, I'm not coming",
      "offset": 2665.28,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "in with structured questions. I'm just",
      "offset": 2667.52,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "going to pick the one I like the most.",
      "offset": 2669.359,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "And that might come down to which one's",
      "offset": 2671.92,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "talking the way I like it to talk, which",
      "offset": 2673.599,
      "duration": 4.561
    },
    {
      "lang": "en",
      "text": "kind of leads to the whole sick fancy",
      "offset": 2676.64,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "thing, right? When OpenAI said, well, we",
      "offset": 2678.16,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "relied too much on people's thumbs up",
      "offset": 2680.48,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "and thumbs down, and that's what got us",
      "offset": 2682,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "in trouble. The yellow marina is pretty",
      "offset": 2683.76,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "much a thumbs up and a thumbs down. It's",
      "offset": 2685.839,
      "duration": 3.201
    },
    {
      "lang": "en",
      "text": "all we're really doing is saying, I like",
      "offset": 2687.28,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "that better. I'm not telling you why. um",
      "offset": 2689.04,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "just because it cursed once and I",
      "offset": 2691.28,
      "duration": 2.96
    },
    {
      "lang": "en",
      "text": "thought that was cool. You know, we have",
      "offset": 2692.64,
      "duration": 5.199
    },
    {
      "lang": "en",
      "text": "no idea. Uh and sure over a at scale",
      "offset": 2694.24,
      "duration": 5.359
    },
    {
      "lang": "en",
      "text": "when you when you aggregate these you'll",
      "offset": 2697.839,
      "duration": 4.881
    },
    {
      "lang": "en",
      "text": "get a much more stable answer, but again",
      "offset": 2699.599,
      "duration": 4.561
    },
    {
      "lang": "en",
      "text": "at this point we're just judging",
      "offset": 2702.72,
      "duration": 4.639
    },
    {
      "lang": "en",
      "text": "preference as opposed to knowledge. uh",
      "offset": 2704.16,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "and again without that structured data",
      "offset": 2707.359,
      "duration": 4.881
    },
    {
      "lang": "en",
      "text": "set. Now also I I I think you mentioned",
      "offset": 2709.2,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "this there is no answer to any questions",
      "offset": 2712.24,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "on the arena right you are just you're",
      "offset": 2714.56,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "just shown response like you are not",
      "offset": 2716.64,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "coming in with a question you are just",
      "offset": 2719.04,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "kind of shown answers and the human it's",
      "offset": 2720.96,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "up to the human to decide which one is",
      "offset": 2722.72,
      "duration": 5.92
    },
    {
      "lang": "en",
      "text": "correct so whoever is judging it behind",
      "offset": 2724.88,
      "duration": 6.32
    },
    {
      "lang": "en",
      "text": "the scenes how are they doing it are",
      "offset": 2728.64,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "they paying a human being to read each",
      "offset": 2731.2,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "one and actually comparing it to the",
      "offset": 2732.8,
      "duration": 4.799
    },
    {
      "lang": "en",
      "text": "right answer or are they going the LLM",
      "offset": 2734.4,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "as a judge route where they're saying",
      "offset": 2737.599,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "well we have yet another LLM who is",
      "offset": 2739.2,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "given a reference answer and this answer",
      "offset": 2741.52,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "and it is asked to say how closely does",
      "offset": 2743.359,
      "duration": 5.841
    },
    {
      "lang": "en",
      "text": "it compare we don't know and again a lot",
      "offset": 2745.92,
      "duration": 5.439
    },
    {
      "lang": "en",
      "text": "of it just comes back to what actually",
      "offset": 2749.2,
      "duration": 5.119
    },
    {
      "lang": "en",
      "text": "is the right way to judge the system",
      "offset": 2751.359,
      "duration": 7.681
    },
    {
      "lang": "en",
      "text": "who's who has the right to judge whether",
      "offset": 2754.319,
      "duration": 8.081
    },
    {
      "lang": "en",
      "text": "or not the AI was correct or not",
      "offset": 2759.04,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "that's a big question and again that's",
      "offset": 2762.4,
      "duration": 3.439
    },
    {
      "lang": "en",
      "text": "why we have benchmarks is that is our",
      "offset": 2764,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "current proxy to that question which is",
      "offset": 2765.839,
      "duration": 6.721
    },
    {
      "lang": "en",
      "text": "well. If we all agree that Pablo Picasso",
      "offset": 2769.04,
      "duration": 5.279
    },
    {
      "lang": "en",
      "text": "painted this thing and that's one of the",
      "offset": 2772.56,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "answers they can pick from, it's on the",
      "offset": 2774.319,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "right track to knowing general world",
      "offset": 2776.56,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "knowledge. But if it just comes down to",
      "offset": 2778.48,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "which one do you like talking to better,",
      "offset": 2780.4,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "like like an arena would be, you're",
      "offset": 2782.48,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "going to miss a lot of the actual",
      "offset": 2785.44,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "important pieces of information you're",
      "offset": 2787.44,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "trying to get out of that LLM. I'll say",
      "offset": 2789.599,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "one more thing. It's funny you brought",
      "offset": 2791.599,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "up the arena. That's actually one of the",
      "offset": 2793.599,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "allegations from law before. Again,",
      "offset": 2795.76,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "total allegations. But one of the",
      "offset": 2797.839,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "separate allegations from Llama 4 was",
      "offset": 2799.92,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "they released a tested or a trained to",
      "offset": 2802,
      "duration": 6.4
    },
    {
      "lang": "en",
      "text": "test model specifically for the arena",
      "offset": 2805.52,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "that was different than the Llama before",
      "offset": 2808.4,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "we all got in the end. Again, total",
      "offset": 2811.04,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "allegation. But those rumors start",
      "offset": 2813.68,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "bubbling up when people notice",
      "offset": 2816.72,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "discrepancies.",
      "offset": 2818.72,
      "duration": 4.879
    },
    {
      "lang": "en",
      "text": "And who's to say those discrepancies are",
      "offset": 2820.24,
      "duration": 5.359
    },
    {
      "lang": "en",
      "text": "correct? They're all just our own",
      "offset": 2823.599,
      "duration": 4.561
    },
    {
      "lang": "en",
      "text": "interpretations and our own expectations",
      "offset": 2825.599,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "maybe not being met by what we were",
      "offset": 2828.16,
      "duration": 6.4
    },
    {
      "lang": "en",
      "text": "shown. There's no way to prove this.",
      "offset": 2830.079,
      "duration": 6.161
    },
    {
      "lang": "en",
      "text": "This episode of Super Data Science is",
      "offset": 2834.56,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "brought to you by the Dell AI factory",
      "offset": 2836.24,
      "duration": 5.119
    },
    {
      "lang": "en",
      "text": "with Nvidia. Two trusted technology",
      "offset": 2838.72,
      "duration": 4.639
    },
    {
      "lang": "en",
      "text": "leaders united to deliver a",
      "offset": 2841.359,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "comprehensive and secure AI solution.",
      "offset": 2843.359,
      "duration": 4.561
    },
    {
      "lang": "en",
      "text": "Dell Technologies and NVIDIA can help",
      "offset": 2846.079,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "you leverage AI to drive innovation and",
      "offset": 2847.92,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "achieve your business goals. The Dell AI",
      "offset": 2850.16,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "factory with NVIDIA is the industry's",
      "offset": 2852.56,
      "duration": 4.799
    },
    {
      "lang": "en",
      "text": "first and only end-to-end enterprise AI",
      "offset": 2854.48,
      "duration": 5.119
    },
    {
      "lang": "en",
      "text": "solution designed to speed AI adoption",
      "offset": 2857.359,
      "duration": 4.881
    },
    {
      "lang": "en",
      "text": "by delivering integrated Dell and NVIDIA",
      "offset": 2859.599,
      "duration": 4.961
    },
    {
      "lang": "en",
      "text": "capabilities to accelerate your AI",
      "offset": 2862.24,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "powered use cases, integrate your data",
      "offset": 2864.56,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "and workflows and enable you to design",
      "offset": 2866.64,
      "duration": 5.199
    },
    {
      "lang": "en",
      "text": "your own AI journey for repeatable,",
      "offset": 2869.44,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "scalable outcomes. Learn more at",
      "offset": 2871.839,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "ww.dell.com/supdatience.",
      "offset": 2874.48,
      "duration": 6.119
    },
    {
      "lang": "en",
      "text": "That's dell.com/supdatience.",
      "offset": 2877.359,
      "duration": 3.24
    },
    {
      "lang": "en",
      "text": "Um, so we've, you know, we're bringing",
      "offset": 2882.96,
      "duration": 5.359
    },
    {
      "lang": "en",
      "text": "up problem after problem with",
      "offset": 2886.16,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "benchmarks. I have solutions too. Yes.",
      "offset": 2888.319,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "So that's that's kind of what I wanted",
      "offset": 2891.28,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "to get into next. So you, for example,",
      "offset": 2892.48,
      "duration": 6.32
    },
    {
      "lang": "en",
      "text": "if I am an enterprise and I want to be",
      "offset": 2895.68,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "having an LLM deployed for a specific",
      "offset": 2898.8,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "set of use cases, you have a",
      "offset": 2900.88,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "recommendation uh from, you know, I've",
      "offset": 2903.04,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "I've checked out your slides. They",
      "offset": 2905.92,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "checked out your blog posts and one of",
      "offset": 2907.28,
      "duration": 5.039
    },
    {
      "lang": "en",
      "text": "the key tips that you have is for",
      "offset": 2910.4,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "organizations to be creating their own",
      "offset": 2912.319,
      "duration": 5.361
    },
    {
      "lang": "en",
      "text": "test sets specific to exactly the",
      "offset": 2914.4,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "application that they're going to be",
      "offset": 2917.68,
      "duration": 2.879
    },
    {
      "lang": "en",
      "text": "deployed into. Uh do you want to tell us",
      "offset": 2918.8,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "more about that? Yeah, absolutely. For",
      "offset": 2920.559,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "any of my clients, the the first thing I",
      "offset": 2922.88,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "ask when I get into their AI systems is,",
      "offset": 2924.96,
      "duration": 6.08
    },
    {
      "lang": "en",
      "text": "&quot;How do you know your AI is working?&quot;",
      "offset": 2928.4,
      "duration": 4.959
    },
    {
      "lang": "en",
      "text": "And I just stand there quietly and",
      "offset": 2931.04,
      "duration": 3.519
    },
    {
      "lang": "en",
      "text": "they're like, &quot;What do you mean?&quot; And",
      "offset": 2933.359,
      "duration": 2.72
    },
    {
      "lang": "en",
      "text": "I'm like, &quot;I don't know. you tell me",
      "offset": 2934.559,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "what I mean. How do you know your AI is",
      "offset": 2936.079,
      "duration": 4.961
    },
    {
      "lang": "en",
      "text": "working? And usually they'll say",
      "offset": 2938.319,
      "duration": 4.481
    },
    {
      "lang": "en",
      "text": "something like, &quot;Oh, well, you know, we",
      "offset": 2941.04,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "picked the model with the best benchmark",
      "offset": 2942.8,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "or we picked the newest Open AI model",
      "offset": 2944.48,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "and we wrote a prompt and we had our",
      "offset": 2946.16,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "intern talk to it a couple times and it",
      "offset": 2948.16,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "all seemed to check out. So now we're in",
      "offset": 2950,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "production.&quot; That happens way more often",
      "offset": 2951.68,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "than I would like to admit from a lot of",
      "offset": 2954.96,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "the people that I talk to and it's just",
      "offset": 2956.8,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "not going to be as efficient. So, at",
      "offset": 2959.44,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "this point, one of the first things I",
      "offset": 2961.28,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "always recommend is let's actually build",
      "offset": 2962.72,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "a testing framework. It's going to be",
      "offset": 2965.119,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "annoying, but it's only going to take a",
      "offset": 2966.88,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "week. We're going to build out a couple",
      "offset": 2969.119,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "of questions. We can even help, you",
      "offset": 2970.96,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "know, we can get some help from GPT to",
      "offset": 2972.96,
      "duration": 3.359
    },
    {
      "lang": "en",
      "text": "build some synthetic data sets as long",
      "offset": 2974.88,
      "duration": 3.679
    },
    {
      "lang": "en",
      "text": "as a human actually overlooks all of",
      "offset": 2976.319,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "them and make sure they're okay. We can",
      "offset": 2978.559,
      "duration": 4.481
    },
    {
      "lang": "en",
      "text": "speed up this process. But once you have",
      "offset": 2980.72,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "that test set, you have two things. Once",
      "offset": 2983.04,
      "duration": 5.92
    },
    {
      "lang": "en",
      "text": "you have a test set for your domain a,",
      "offset": 2985.52,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "you can now get a better sense of how",
      "offset": 2988.96,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "your AI is doing. That's table stakes.",
      "offset": 2990.88,
      "duration": 5.92
    },
    {
      "lang": "en",
      "text": "Now however it really opens up your",
      "offset": 2994.16,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "experimentation cuz the next phase of",
      "offset": 2996.8,
      "duration": 5.92
    },
    {
      "lang": "en",
      "text": "your AI labs or your AI team is to say",
      "offset": 2999.44,
      "duration": 6.639
    },
    {
      "lang": "en",
      "text": "okay now we have a way we all agree that",
      "offset": 3002.72,
      "duration": 6.08
    },
    {
      "lang": "en",
      "text": "if this number is bigger given these",
      "offset": 3006.079,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "prompting you know chain of thought",
      "offset": 3008.8,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "non-chain of thought if we all agree",
      "offset": 3010.4,
      "duration": 4.719
    },
    {
      "lang": "en",
      "text": "that a higher number on this test set",
      "offset": 3012.64,
      "duration": 6.719
    },
    {
      "lang": "en",
      "text": "means it's better for us go it's now",
      "offset": 3015.119,
      "duration": 6.48
    },
    {
      "lang": "en",
      "text": "everyone's job to prompt better",
      "offset": 3019.359,
      "duration": 4.561
    },
    {
      "lang": "en",
      "text": "fine-tune better do whatever you have to",
      "offset": 3021.599,
      "duration": 4.881
    },
    {
      "lang": "en",
      "text": "do to get better at our internal",
      "offset": 3023.92,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "benchmark? Cuz what you're doing is",
      "offset": 3026.48,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "you're creating a leaderboard. And we",
      "offset": 3028.4,
      "duration": 2.959
    },
    {
      "lang": "en",
      "text": "just got done talking about how",
      "offset": 3030.319,
      "duration": 3.441
    },
    {
      "lang": "en",
      "text": "leaderboards can be bad for for the",
      "offset": 3031.359,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "general benchmark public. But when it's",
      "offset": 3033.76,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "for your organization, you're basically",
      "offset": 3036.559,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "treating it the same way you would might",
      "offset": 3038.88,
      "duration": 3.679
    },
    {
      "lang": "en",
      "text": "treat a sales team. You you're you're",
      "offset": 3040.24,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "trying to figure out what is going to",
      "offset": 3042.559,
      "duration": 5.121
    },
    {
      "lang": "en",
      "text": "get be the best way to get close that",
      "offset": 3044.72,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "sale or in our case get a better score",
      "offset": 3047.68,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "on our test set. Now hopefully that",
      "offset": 3050.16,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "doesn't also breed a uh culture of",
      "offset": 3052.8,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "contamination and cheating and and you",
      "offset": 3055.92,
      "duration": 6.24
    },
    {
      "lang": "en",
      "text": "know training to test. Uh but it it's",
      "offset": 3058.4,
      "duration": 5.919
    },
    {
      "lang": "en",
      "text": "more of a fair application of chase the",
      "offset": 3062.16,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "top of that leaderboard because now I'll",
      "offset": 3064.319,
      "duration": 4.961
    },
    {
      "lang": "en",
      "text": "give you a really good example is it",
      "offset": 3066.559,
      "duration": 6.401
    },
    {
      "lang": "en",
      "text": "Stripe both Stripe and eBay made an",
      "offset": 3069.28,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "embedding model specific to their",
      "offset": 3072.96,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "domain. Stripe more recently, but eBay",
      "offset": 3074.72,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "actually built a BERT models uh for",
      "offset": 3077.04,
      "duration": 4.799
    },
    {
      "lang": "en",
      "text": "their recommendation engine years ago.",
      "offset": 3079.04,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "And I say this a lot. I'm willing to bet",
      "offset": 3081.839,
      "duration": 4.641
    },
    {
      "lang": "en",
      "text": "that if you ever got your hands on those",
      "offset": 3084.48,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "benchmarks, they would be abysmal at",
      "offset": 3086.48,
      "duration": 4.879
    },
    {
      "lang": "en",
      "text": "embedding benchmarks, which exists, the",
      "offset": 3089.44,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "MTEB, they would probably be abysmal at",
      "offset": 3091.359,
      "duration": 5.681
    },
    {
      "lang": "en",
      "text": "the benchmark. But they don't care.",
      "offset": 3094.8,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "They're using it to detect financial",
      "offset": 3097.04,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "fraud or stripe is at least eBay is",
      "offset": 3099.44,
      "duration": 4.639
    },
    {
      "lang": "en",
      "text": "using it to sell stuff on their",
      "offset": 3101.68,
      "duration": 4.879
    },
    {
      "lang": "en",
      "text": "platform. They don't care about the",
      "offset": 3104.079,
      "duration": 4.721
    },
    {
      "lang": "en",
      "text": "document retrieval nature of it in in",
      "offset": 3106.559,
      "duration": 4.961
    },
    {
      "lang": "en",
      "text": "terms of MTV. So once you start",
      "offset": 3108.8,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "realizing the benchmark's actually not",
      "offset": 3111.52,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "testing for anything we care about our",
      "offset": 3113.68,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "test set is. Now let's chase that",
      "offset": 3116,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "leaderboard because that's now tuned to",
      "offset": 3118.48,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "us. Very nice. That was a well explained",
      "offset": 3120.48,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "solution. What other solutions do you",
      "offset": 3124.24,
      "duration": 4.879
    },
    {
      "lang": "en",
      "text": "have for benchmark issues? Son, for for",
      "offset": 3126.24,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "back to creating that test set as well,",
      "offset": 3129.119,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "um, one thing that you can do that is",
      "offset": 3131.2,
      "duration": 4.639
    },
    {
      "lang": "en",
      "text": "also true in benchmarks is a",
      "offset": 3133.839,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "decontamination phase of your training",
      "offset": 3135.839,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "data. Like I mentioned earlier, kind of",
      "offset": 3137.68,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "the classical quote unquote classical",
      "offset": 3140.079,
      "duration": 4.721
    },
    {
      "lang": "en",
      "text": "ways of of matching a test set to a",
      "offset": 3141.76,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "training set would be something like an",
      "offset": 3144.8,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "engram match, right? Like are are these",
      "offset": 3146,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "are there keywords in in common between",
      "offset": 3148.8,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "our training and our test set or a",
      "offset": 3150.96,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "cosign similarity? Are they actually",
      "offset": 3152.24,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "semantically too similar that the AI",
      "offset": 3154.4,
      "duration": 5.919
    },
    {
      "lang": "en",
      "text": "might be able to cheat off of it? There",
      "offset": 3157.52,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "are papers who actually go as far as to",
      "offset": 3160.319,
      "duration": 7.121
    },
    {
      "lang": "en",
      "text": "create fine-tuned LLMs whose only job is",
      "offset": 3162.96,
      "duration": 7.28
    },
    {
      "lang": "en",
      "text": "to detect rephrasing of questions.",
      "offset": 3167.44,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "That's a task. Is this a rephrased",
      "offset": 3170.24,
      "duration": 6.72
    },
    {
      "lang": "en",
      "text": "version of that? Yes or no? That's a",
      "offset": 3173.2,
      "duration": 6.159
    },
    {
      "lang": "en",
      "text": "task that we can fine-tune an LLM for.",
      "offset": 3176.96,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "And that's what the um I believe it was",
      "offset": 3179.359,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "the LLM decontaminator. what exactly",
      "offset": 3180.88,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "was. And that's the paper that also made",
      "offset": 3183.599,
      "duration": 5.041
    },
    {
      "lang": "en",
      "text": "that experiment of we rephrase these to",
      "offset": 3185.68,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "a degree that industry standard ways",
      "offset": 3188.64,
      "duration": 5.439
    },
    {
      "lang": "en",
      "text": "didn't catch it, but ours did. And if we",
      "offset": 3190.96,
      "duration": 6.159
    },
    {
      "lang": "en",
      "text": "hadn't existed and Meta had tried some",
      "offset": 3194.079,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "funny business, they would have been",
      "offset": 3197.119,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "beating GPT4. They weren't. So that's",
      "offset": 3199.119,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "our assumption that they weren't",
      "offset": 3201.52,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "cheating. But they made the point of",
      "offset": 3202.8,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "it's actually not that hard to cheat.",
      "offset": 3204.72,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "It's pretty easy to rephrase these",
      "offset": 3207.28,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "questions to make them sound different",
      "offset": 3209.2,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "enough but still learn that information.",
      "offset": 3211.119,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "So doing some kind of decontamination",
      "offset": 3213.76,
      "duration": 5.839
    },
    {
      "lang": "en",
      "text": "step in your training data would really",
      "offset": 3216.559,
      "duration": 4.881
    },
    {
      "lang": "en",
      "text": "uh just at least help the",
      "offset": 3219.599,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "generalizability of the system because",
      "offset": 3221.44,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "if you are using data that is too",
      "offset": 3223.92,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "similar to your testing set. Sure maybe",
      "offset": 3225.68,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "in the short term in your in your",
      "offset": 3228.24,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "production phase it's going to look good",
      "offset": 3230.079,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "but eventually drift will happen. drift,",
      "offset": 3232.559,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "meaning people will ask new questions.",
      "offset": 3235.119,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "People will ask it a different way. New",
      "offset": 3236.96,
      "duration": 3.599
    },
    {
      "lang": "en",
      "text": "products will come up, the LM won't know",
      "offset": 3238.8,
      "duration": 3.759
    },
    {
      "lang": "en",
      "text": "about it, you won't know how to test a",
      "offset": 3240.559,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "generalization.",
      "offset": 3242.559,
      "duration": 3.121
    },
    {
      "lang": "en",
      "text": "It's going to go off the rails at some",
      "offset": 3244.24,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "point. And if you if you don't watch out",
      "offset": 3245.68,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "for that as early as possible, you are",
      "offset": 3247.92,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "more likely to fall into that trap",
      "offset": 3250.24,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "sooner than you want. And then you just",
      "offset": 3252.48,
      "duration": 3.599
    },
    {
      "lang": "en",
      "text": "don't know what to do about it. Nice.",
      "offset": 3254.079,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "Nice. Yeah, another great solution",
      "offset": 3256.079,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "there. What about going beyond",
      "offset": 3257.92,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "benchmark? So for example, something",
      "offset": 3260.16,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "that I've had success with in the past",
      "offset": 3262.079,
      "duration": 7.04
    },
    {
      "lang": "en",
      "text": "was so developing um a test set that um",
      "offset": 3263.52,
      "duration": 8.72
    },
    {
      "lang": "en",
      "text": "that was specific to a task um a",
      "offset": 3269.119,
      "duration": 5.361
    },
    {
      "lang": "en",
      "text": "generation task. So a very specific we",
      "offset": 3272.24,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "had uh in a previous company that I",
      "offset": 3274.48,
      "duration": 5.92
    },
    {
      "lang": "en",
      "text": "worked at, we had a very specific uh we",
      "offset": 3276.72,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "had a a relatively small large language",
      "offset": 3280.4,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "model, something like seven billion",
      "offset": 3282.72,
      "duration": 2.8
    },
    {
      "lang": "en",
      "text": "parameters. Sure. I think it was one of",
      "offset": 3284,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "the early llama models and it was doing",
      "offset": 3285.52,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "something very specific. it was turning",
      "offset": 3288.319,
      "duration": 4.561
    },
    {
      "lang": "en",
      "text": "natural language into a JSON file that",
      "offset": 3290,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "and that JSON file had specific",
      "offset": 3292.88,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "structured fields that were useful for",
      "offset": 3294.48,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "us to present to users and to do um and",
      "offset": 3296.4,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "and to search over embeddings, that kind",
      "offset": 3299.68,
      "duration": 9.04
    },
    {
      "lang": "en",
      "text": "of thing. And um so we we used a whole",
      "offset": 3301.52,
      "duration": 11.76
    },
    {
      "lang": "en",
      "text": "bunch of LLM calls. So at that time you",
      "offset": 3308.72,
      "duration": 7.28
    },
    {
      "lang": "en",
      "text": "certainly couldn't even the leading uh",
      "offset": 3313.28,
      "duration": 4.799
    },
    {
      "lang": "en",
      "text": "proprietary LLM of that time you",
      "offset": 3316,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "couldn't reliably create this JSON",
      "offset": 3318.079,
      "duration": 4.641
    },
    {
      "lang": "en",
      "text": "object with all the parameters that we",
      "offset": 3320.96,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "wanted um in one call but you could do",
      "offset": 3322.72,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "it in multiple calls so you could kind",
      "offset": 3325.52,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "of go field by field and so",
      "offset": 3326.96,
      "duration": 5.599
    },
    {
      "lang": "en",
      "text": "exactly and so it would be it would be",
      "offset": 3330.64,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "too slow it would be too expensive to do",
      "offset": 3332.559,
      "duration": 5.361
    },
    {
      "lang": "en",
      "text": "in real time uh with with our you know",
      "offset": 3335.04,
      "duration": 4.799
    },
    {
      "lang": "en",
      "text": "users of the client with our users of",
      "offset": 3337.92,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "our platform.",
      "offset": 3339.839,
      "duration": 2.961
    },
    {
      "lang": "en",
      "text": "who are expecting like real-time",
      "offset": 3341.28,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "results, but we could use that to create",
      "offset": 3342.8,
      "duration": 4.559
    },
    {
      "lang": "en",
      "text": "a test set or or to create a training",
      "offset": 3345.119,
      "duration": 5.761
    },
    {
      "lang": "en",
      "text": "set rather uh as well as a test set. And",
      "offset": 3347.359,
      "duration": 6.72
    },
    {
      "lang": "en",
      "text": "um and then we could also actually you",
      "offset": 3350.88,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "know what now that I'm saying this a lot",
      "offset": 3354.079,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "that's actually that's more related",
      "offset": 3355.92,
      "duration": 3.199
    },
    {
      "lang": "en",
      "text": "that's that's more related to creating",
      "offset": 3357.68,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "our own benchmark and so that is",
      "offset": 3359.119,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "something that we were able to do and",
      "offset": 3360.96,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "training set though and and training set",
      "offset": 3362.72,
      "duration": 2.96
    },
    {
      "lang": "en",
      "text": "for sure. Exactly. Which was really",
      "offset": 3364.48,
      "duration": 2.72
    },
    {
      "lang": "en",
      "text": "useful because then you can actually you",
      "offset": 3365.68,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "can fine-tune.",
      "offset": 3367.2,
      "duration": 3.119
    },
    {
      "lang": "en",
      "text": "So you could take something like a seven",
      "offset": 3369.04,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "billion parameter llama model and you",
      "offset": 3370.319,
      "duration": 5.201
    },
    {
      "lang": "en",
      "text": "can fine-tune it very rapidly. Laura or",
      "offset": 3372.72,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "something like that. Laura, exactly with",
      "offset": 3375.52,
      "duration": 2.88
    },
    {
      "lang": "en",
      "text": "lower rank adaptation. Usually I have",
      "offset": 3376.88,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "that uh it's something that I can just",
      "offset": 3378.4,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "say, but uh it's been a few months since",
      "offset": 3380.24,
      "duration": 4.879
    },
    {
      "lang": "en",
      "text": "I've done Laura. Um yeah, so L O R A.",
      "offset": 3382.48,
      "duration": 5.359
    },
    {
      "lang": "en",
      "text": "And we've done podcast episodes on Laura",
      "offset": 3385.119,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "if you want to hear about it",
      "offset": 3387.839,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "specifically. I love Laura. Laura is",
      "offset": 3389.04,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "like one of my favorite Laura was one of",
      "offset": 3391.44,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "the last times like very recently I read",
      "offset": 3393.92,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "a paper and I just saw like the basics",
      "offset": 3396.16,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "of linear algebra being applied in such",
      "offset": 3398.88,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "a simple way. I think that and Deepseek",
      "offset": 3401.2,
      "duration": 5.599
    },
    {
      "lang": "en",
      "text": "the Deepseek the R1 paper and the the",
      "offset": 3404.16,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "Laura paper were the last two papers",
      "offset": 3406.799,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "where I was just like man sometimes all",
      "offset": 3408.559,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "it is is just linear algebra 101 and and",
      "offset": 3411.2,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "that's awesome. That's all it takes",
      "offset": 3414.319,
      "duration": 3.441
    },
    {
      "lang": "en",
      "text": "sometimes. And am I remembering",
      "offset": 3416,
      "duration": 3.359
    },
    {
      "lang": "en",
      "text": "correctly that you have a math degree? I",
      "offset": 3417.76,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "do. I have my masters and bachelor's",
      "offset": 3419.359,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "both in theoretical mathematics. Right.",
      "offset": 3421.68,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "Right. Right. A likely guide to find the",
      "offset": 3423.76,
      "duration": 5.039
    },
    {
      "lang": "en",
      "text": "linear algebra beautiful. Um yeah. So we",
      "offset": 3425.76,
      "duration": 5.839
    },
    {
      "lang": "en",
      "text": "did a Laura episode episode 674 if you",
      "offset": 3428.799,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "want to learn about that. But basically",
      "offset": 3431.599,
      "duration": 3.361
    },
    {
      "lang": "en",
      "text": "you can use it to very efficiently in",
      "offset": 3432.799,
      "duration": 4.881
    },
    {
      "lang": "en",
      "text": "terms of time and money. Um you add in",
      "offset": 3434.96,
      "duration": 4.639
    },
    {
      "lang": "en",
      "text": "some extra parameters like half a",
      "offset": 3437.68,
      "duration": 4.879
    },
    {
      "lang": "en",
      "text": "percent more um into your model",
      "offset": 3439.599,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "something like that. And then you can",
      "offset": 3442.559,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "fine-tune very rapidly just those that",
      "offset": 3444.799,
      "duration": 5.841
    },
    {
      "lang": "en",
      "text": "half percent more that you've added in",
      "offset": 3448.319,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "and you get pretty remarkable results.",
      "offset": 3450.64,
      "duration": 2.959
    },
    {
      "lang": "en",
      "text": "You don't you don't end up with",
      "offset": 3452.4,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "catastrophic catastrophic collapse. Um",
      "offset": 3453.599,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "and so so that approach that I was",
      "offset": 3457.28,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "talking about earlier where we stitched",
      "offset": 3459.119,
      "duration": 3.041
    },
    {
      "lang": "en",
      "text": "a bunch of LLM calls together to to",
      "offset": 3460.64,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "create the training set and the test set",
      "offset": 3462.16,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "that is actually that's more like your",
      "offset": 3463.92,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "benchmark thing. In addition to that, we",
      "offset": 3466.079,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "also on a separate task, now I'm",
      "offset": 3469.2,
      "duration": 2.96
    },
    {
      "lang": "en",
      "text": "realizing as I get through the whole",
      "offset": 3471.119,
      "duration": 4.641
    },
    {
      "lang": "en",
      "text": "story, um we would use large language",
      "offset": 3472.16,
      "duration": 7.12
    },
    {
      "lang": "en",
      "text": "models to judge the quality of LLM",
      "offset": 3475.76,
      "duration": 7.76
    },
    {
      "lang": "en",
      "text": "outputs. So, for example, use, you know,",
      "offset": 3479.28,
      "duration": 7.039
    },
    {
      "lang": "en",
      "text": "let's say we we fine-tune",
      "offset": 3483.52,
      "duration": 6.48
    },
    {
      "lang": "en",
      "text": "um you know, a cheap fast 7 billion",
      "offset": 3486.319,
      "duration": 5.441
    },
    {
      "lang": "en",
      "text": "llama model to be able to do something",
      "offset": 3490,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "and then we want to be able to test it.",
      "offset": 3491.76,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "uh and maybe like there's some reason",
      "offset": 3494.24,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "why creating benchmarks for this would",
      "offset": 3496.64,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "be very labor intensive. You could",
      "offset": 3498.319,
      "duration": 5.121
    },
    {
      "lang": "en",
      "text": "actually use LLMs to judge performance",
      "offset": 3500.96,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "and that gives you something",
      "offset": 3503.44,
      "duration": 2.399
    },
    {
      "lang": "en",
      "text": "comparative. Maybe the LLM isn't",
      "offset": 3504.48,
      "duration": 4.639
    },
    {
      "lang": "en",
      "text": "perfect, but you use an expensive one um",
      "offset": 3505.839,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "you know, you use whatever the",
      "offset": 3509.119,
      "duration": 3.761
    },
    {
      "lang": "en",
      "text": "state-of-the-art LLM is at the time of",
      "offset": 3510.24,
      "duration": 5.359
    },
    {
      "lang": "en",
      "text": "listening to this. You call that API and",
      "offset": 3512.88,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "you use it to judge your outputs. That's",
      "offset": 3515.599,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "something that I love because it allows",
      "offset": 3518.48,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "you, it's so cheap and fast that you can",
      "offset": 3519.92,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "do it, you know, as you're fine-tuning",
      "offset": 3522.24,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "with Laura and see, you know, have we",
      "offset": 3524.48,
      "duration": 4.639
    },
    {
      "lang": "en",
      "text": "gone too far, have we overtrained? Um,",
      "offset": 3525.92,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "uh, yeah, there's lots of great, you",
      "offset": 3529.119,
      "duration": 3.521
    },
    {
      "lang": "en",
      "text": "know, check marks there, checkpoints",
      "offset": 3531.04,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "there, or you could compare different",
      "offset": 3532.64,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "models, different ways you fine-tuned",
      "offset": 3534.16,
      "duration": 5.199
    },
    {
      "lang": "en",
      "text": "and, uh, yeah, and so it's very cheap",
      "offset": 3536.799,
      "duration": 4.481
    },
    {
      "lang": "en",
      "text": "and effective, way, way, way cheaper",
      "offset": 3539.359,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "than having humans evaluate. And",
      "offset": 3541.28,
      "duration": 2.64
    },
    {
      "lang": "en",
      "text": "something that we've done, sorry I've",
      "offset": 3542.96,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "been talking way too long, son. But",
      "offset": 3543.92,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "something that we did in a previous",
      "offset": 3546.24,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "company was we compared on a small",
      "offset": 3547.839,
      "duration": 5.201
    },
    {
      "lang": "en",
      "text": "number human evaluations which were",
      "offset": 3550.48,
      "duration": 5.119
    },
    {
      "lang": "en",
      "text": "super everyone hated doing it. Like we",
      "offset": 3553.04,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "asked everyone on the product team, the",
      "offset": 3555.599,
      "duration": 2.72
    },
    {
      "lang": "en",
      "text": "software engineering team, the sales",
      "offset": 3556.96,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "team to be evaluating model outputs and",
      "offset": 3558.319,
      "duration": 5.601
    },
    {
      "lang": "en",
      "text": "ranking them or saying which ones were",
      "offset": 3562,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "correct, which ones weren't. And people",
      "offset": 3563.92,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "hate it because it turns out it's really",
      "offset": 3565.92,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "hard. Like we've gotten to a point Yeah.",
      "offset": 3567.68,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "with a lot of tasks now. It's not like",
      "offset": 3570,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "you're like, &quot;Wow, one LLM is garbage",
      "offset": 3571.76,
      "duration": 2.88
    },
    {
      "lang": "en",
      "text": "and the other one's great.&quot; You're like,",
      "offset": 3573.68,
      "duration": 2.48
    },
    {
      "lang": "en",
      "text": "&quot;Wow, these are two great sets of",
      "offset": 3574.64,
      "duration": 3.199
    },
    {
      "lang": "en",
      "text": "results. There's nuances here.&quot; Like,",
      "offset": 3576.16,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "&quot;This one is better here. This one is",
      "offset": 3577.839,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "better there.&quot; I I mean, I don't know",
      "offset": 3579.92,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "what to tell you. So, yeah. So, it can",
      "offset": 3581.359,
      "duration": 2.96
    },
    {
      "lang": "en",
      "text": "be really labor intensive. People hate",
      "offset": 3583.2,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "doing it, but we forced people to do it.",
      "offset": 3584.319,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "And so, we got this small set and we",
      "offset": 3586.48,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "were able to compare. Okay, there is a",
      "offset": 3588.16,
      "duration": 6.08
    },
    {
      "lang": "en",
      "text": "high rate of interrator reliability",
      "offset": 3590.16,
      "duration": 6.88
    },
    {
      "lang": "en",
      "text": "between the humans and this expensive",
      "offset": 3594.24,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "LLM that we're calling. Um, and so let's",
      "offset": 3597.04,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "just use the LLM from now on. What you",
      "offset": 3599.04,
      "duration": 3.519
    },
    {
      "lang": "en",
      "text": "just said is is I want to say that",
      "offset": 3600.64,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "again. I I I because I talk about this",
      "offset": 3602.559,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "in my eval classes. What you what you",
      "offset": 3604.559,
      "duration": 3.121
    },
    {
      "lang": "en",
      "text": "are using is called a rubric.",
      "offset": 3606.4,
      "duration": 3.199
    },
    {
      "lang": "en",
      "text": "Effectively, you are you are judging a",
      "offset": 3607.68,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "single piece of content against some",
      "offset": 3609.599,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "criteria, maybe some references or some",
      "offset": 3612.48,
      "duration": 5.839
    },
    {
      "lang": "en",
      "text": "guidelines or in your case structure of",
      "offset": 3615.119,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "the actual output. For example, it's",
      "offset": 3618.319,
      "duration": 5.121
    },
    {
      "lang": "en",
      "text": "it's a rubric effectively. And one of",
      "offset": 3620.799,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "the problems with rubrics is they're",
      "offset": 3623.44,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "just prompts on top of an LLM. And if",
      "offset": 3624.88,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "you give that prompt to 10 different",
      "offset": 3627.52,
      "duration": 3.279
    },
    {
      "lang": "en",
      "text": "LLMs, they're all going to give probably",
      "offset": 3628.72,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "some different scores across the board.",
      "offset": 3630.799,
      "duration": 4.721
    },
    {
      "lang": "en",
      "text": "So, which one actually matches the",
      "offset": 3634,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "human? Because that's the right answer.",
      "offset": 3635.52,
      "duration": 3.279
    },
    {
      "lang": "en",
      "text": "Which one is correct is not the one with",
      "offset": 3637.04,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "the highest score. It's the one that",
      "offset": 3638.799,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "actually matches the human. But to do",
      "offset": 3640.24,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "that, you need a human and it's really",
      "offset": 3642.799,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "hard to make these evaluations. So, to",
      "offset": 3645.28,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "to go through what you just talked about",
      "offset": 3647.359,
      "duration": 4.801
    },
    {
      "lang": "en",
      "text": "is not easy. But once you do it and you",
      "offset": 3649.44,
      "duration": 6.399
    },
    {
      "lang": "en",
      "text": "know this LLM knows how to judge this",
      "offset": 3652.16,
      "duration": 6.8
    },
    {
      "lang": "en",
      "text": "this task given this prompt again",
      "offset": 3655.839,
      "duration": 5.681
    },
    {
      "lang": "en",
      "text": "experiments open because now we have a",
      "offset": 3658.96,
      "duration": 4.639
    },
    {
      "lang": "en",
      "text": "relatively reliable way to make that",
      "offset": 3661.52,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "evaluation in real time. I'll I'll go",
      "offset": 3663.599,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "one step further with the rise of",
      "offset": 3665.68,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "reasoning models the ability to use",
      "offset": 3667.28,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "reinforcement learning to train kind of",
      "offset": 3669.92,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "like uh I'll I'll I'll name drop some",
      "offset": 3672.88,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "acronyms here. some GRPO or PO",
      "offset": 3675.68,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "algorithms. These are types of",
      "offset": 3678.16,
      "duration": 2.959
    },
    {
      "lang": "en",
      "text": "reinforcement learning systems where you",
      "offset": 3679.44,
      "duration": 5.679
    },
    {
      "lang": "en",
      "text": "basically let an LLM try a task and",
      "offset": 3681.119,
      "duration": 6.081
    },
    {
      "lang": "en",
      "text": "before the LM tries again, you have to",
      "offset": 3685.119,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "give it a score to say that was good or",
      "offset": 3687.2,
      "duration": 3.599
    },
    {
      "lang": "en",
      "text": "that was bad or that was really good or",
      "offset": 3689.2,
      "duration": 3.599
    },
    {
      "lang": "en",
      "text": "that was really bad. If you have a",
      "offset": 3690.799,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "rubric providing that answer or at the",
      "offset": 3692.799,
      "duration": 5.201
    },
    {
      "lang": "en",
      "text": "very least just say hey this is not a",
      "offset": 3696.079,
      "duration": 5.921
    },
    {
      "lang": "en",
      "text": "JSON so thumbs down try that again over",
      "offset": 3698,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "and over and over again. You're",
      "offset": 3702,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "basically teaching the AI how to solve a",
      "offset": 3704,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "task through reward and punishment. I I",
      "offset": 3706.24,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "mean, which is the basic point of",
      "offset": 3709.28,
      "duration": 3.279
    },
    {
      "lang": "en",
      "text": "reinforcement learning anyways, but it",
      "offset": 3710.4,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "it's almost perfect in the way that the",
      "offset": 3712.559,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "way we think about evaluation lends",
      "offset": 3714.319,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "itself quite nicely to the way we think",
      "offset": 3716.4,
      "duration": 5.199
    },
    {
      "lang": "en",
      "text": "about training these LLMs today. Nice.",
      "offset": 3718.72,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "I'm glad to get the uh stamp of approval",
      "offset": 3721.599,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "from you there, son. Um yeah, rubric",
      "offset": 3723.92,
      "duration": 4.639
    },
    {
      "lang": "en",
      "text": "based based grading. Thank you for",
      "offset": 3726.799,
      "duration": 2.961
    },
    {
      "lang": "en",
      "text": "bringing that up. That was one of the",
      "offset": 3728.559,
      "duration": 2.56
    },
    {
      "lang": "en",
      "text": "thing things that I wanted to to make",
      "offset": 3729.76,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "sure we talked about. What about um in",
      "offset": 3731.119,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "terms of you know solutions and emerging",
      "offset": 3733.04,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "techniques for AI evaluations that kind",
      "offset": 3734.96,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "of go beyond just standard benchmarks?",
      "offset": 3736.72,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "What about perplexity and confidence",
      "offset": 3739.04,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "signals where the model kind of has its",
      "offset": 3740.96,
      "duration": 5.359
    },
    {
      "lang": "en",
      "text": "own ability to recognize that this is a",
      "offset": 3743.92,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "situation where it maybe isn't sure it",
      "offset": 3746.319,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "could be hallucinating. Yeah, perplexity",
      "offset": 3748.72,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "is a tricky one because perplexity is a",
      "offset": 3750.559,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "metric that we have been using for",
      "offset": 3752.72,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "decades but only recently have been",
      "offset": 3754.24,
      "duration": 6.64
    },
    {
      "lang": "en",
      "text": "using as a proxy for hallucinations. And",
      "offset": 3756.16,
      "duration": 7.04
    },
    {
      "lang": "en",
      "text": "for those who are who are the the",
      "offset": 3760.88,
      "duration": 5.439
    },
    {
      "lang": "en",
      "text": "uninitiated, perplexity is effectively a",
      "offset": 3763.2,
      "duration": 5.599
    },
    {
      "lang": "en",
      "text": "judge of the confidence of the tokens",
      "offset": 3766.319,
      "duration": 5.361
    },
    {
      "lang": "en",
      "text": "being predicted. I it is correlated to",
      "offset": 3768.799,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "the actual token probabilities",
      "offset": 3771.68,
      "duration": 3.439
    },
    {
      "lang": "en",
      "text": "themselves. As the pro the confidence",
      "offset": 3773.2,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "goes up, the perplexity goes down. A",
      "offset": 3775.119,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "lower perplexity is better. The problem",
      "offset": 3777.2,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "with perplexity among other things is",
      "offset": 3780.079,
      "duration": 6.24
    },
    {
      "lang": "en",
      "text": "that a it requires other answers to be",
      "offset": 3782.48,
      "duration": 6.16
    },
    {
      "lang": "en",
      "text": "judged against. For example, if I ask",
      "offset": 3786.319,
      "duration": 4.721
    },
    {
      "lang": "en",
      "text": "what planet is known as the red planet",
      "offset": 3788.64,
      "duration": 4.959
    },
    {
      "lang": "en",
      "text": "and I take the word Mars, which is the",
      "offset": 3791.04,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "answer, I could I could calculate a",
      "offset": 3793.599,
      "duration": 5.281
    },
    {
      "lang": "en",
      "text": "perplexity given a model. Let's call it",
      "offset": 3796.72,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "1.3.",
      "offset": 3798.88,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "I could then do it for Jupiter and Venus",
      "offset": 3800.4,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "and I would get different numbers.",
      "offset": 3802.4,
      "duration": 2.8
    },
    {
      "lang": "en",
      "text": "Hopefully, they're going to be much",
      "offset": 3804,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "larger. So, at that point, it's easy.",
      "offset": 3805.2,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "Okay, great. The lowest one wins. What",
      "offset": 3807.28,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "if you don't have options? What if you",
      "offset": 3809.28,
      "duration": 3.279
    },
    {
      "lang": "en",
      "text": "don't have other things to compare it",
      "offset": 3811.2,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "to? Now, you need a threshold. Well,",
      "offset": 3812.559,
      "duration": 2.881
    },
    {
      "lang": "en",
      "text": "what's the threshold for a good",
      "offset": 3814.4,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "perplexity? I don't know that's not",
      "offset": 3815.44,
      "duration": 3.599
    },
    {
      "lang": "en",
      "text": "really a textbook answer. Now you have",
      "offset": 3817.52,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "to figure out in your own domain what a",
      "offset": 3819.039,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "good threshold is and and gez at that",
      "offset": 3821.599,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "point you might as well write a rubric",
      "offset": 3823.359,
      "duration": 2.96
    },
    {
      "lang": "en",
      "text": "and figure out some human grading",
      "offset": 3825.039,
      "duration": 3.441
    },
    {
      "lang": "en",
      "text": "solution. So perplexity itself is not",
      "offset": 3826.319,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "perfect. The the other thing that's a",
      "offset": 3828.48,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "problem with perplexity not the company",
      "offset": 3830.48,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "the metric. Uh they are obviously",
      "offset": 3832.559,
      "duration": 6.48
    },
    {
      "lang": "en",
      "text": "related but that the value of perplexity",
      "offset": 3835.2,
      "duration": 6.399
    },
    {
      "lang": "en",
      "text": "is also dependent on the prevalence of",
      "offset": 3839.039,
      "duration": 5.201
    },
    {
      "lang": "en",
      "text": "that token in the training data. So that",
      "offset": 3841.599,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "same example if you give it the word",
      "offset": 3844.24,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "earth as the answer to the question",
      "offset": 3846,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "which is not the right answer our little",
      "offset": 3848.079,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "blue marble is not known as the red",
      "offset": 3850,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "planet the perplexity will also be quite",
      "offset": 3852,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "low but not because the model is",
      "offset": 3854.4,
      "duration": 4.719
    },
    {
      "lang": "en",
      "text": "confident in it in the answer but",
      "offset": 3856.72,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "because it's just seen that token so",
      "offset": 3859.119,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "often so it's just going to have a",
      "offset": 3861.039,
      "duration": 5.201
    },
    {
      "lang": "en",
      "text": "naturally lower uh lower perplexity and",
      "offset": 3862.799,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "a higher confidence. So perplexity is a",
      "offset": 3866.24,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "fine",
      "offset": 3868.799,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "correlated proxy to hallucination, but",
      "offset": 3870.319,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "really you're just measuring the",
      "offset": 3873.359,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "confidence of the LLM. And if we equate",
      "offset": 3874.64,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "confidence with truthfulness,",
      "offset": 3877.599,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "I got a problem for some humans that I",
      "offset": 3880.16,
      "duration": 3.439
    },
    {
      "lang": "en",
      "text": "know. Confidence does not mean",
      "offset": 3881.76,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "truthfulness, unfortunately. And it's",
      "offset": 3883.599,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "the same goes for LLM. So it's tricky. I",
      "offset": 3885.44,
      "duration": 5.119
    },
    {
      "lang": "en",
      "text": "I'll say one more thing. I promise one",
      "offset": 3888.799,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "more. The LLM doesn't know its own",
      "offset": 3890.559,
      "duration": 5.601
    },
    {
      "lang": "en",
      "text": "perplexity. To be clear, it doesn't know",
      "offset": 3892.88,
      "duration": 5.439
    },
    {
      "lang": "en",
      "text": "the probability confidences of its own",
      "offset": 3896.16,
      "duration": 4.639
    },
    {
      "lang": "en",
      "text": "token distribution when it predicts that",
      "offset": 3898.319,
      "duration": 4.961
    },
    {
      "lang": "en",
      "text": "token. The p the actual act of",
      "offset": 3900.799,
      "duration": 5.121
    },
    {
      "lang": "en",
      "text": "predicting a token is technically not",
      "offset": 3903.28,
      "duration": 6.16
    },
    {
      "lang": "en",
      "text": "done by the LLM. It's done by the system",
      "offset": 3905.92,
      "duration": 5.919
    },
    {
      "lang": "en",
      "text": "hosting the LLM. It's just choosing from",
      "offset": 3909.44,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "that probability distribution. So, in a",
      "offset": 3911.839,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "weird way, the LM doesn't actually know",
      "offset": 3914.16,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "how confident it is is purely based on",
      "offset": 3916.559,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "its own probabilities. It has to be",
      "offset": 3919.44,
      "duration": 5.679
    },
    {
      "lang": "en",
      "text": "somehow devised parametrically within",
      "offset": 3922.079,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "its own parameters. It has to somehow",
      "offset": 3925.119,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "come to the conclusion along the way",
      "offset": 3927.599,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "that it doesn't know the answer. To my",
      "offset": 3929.839,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "knowledge, it's not able to actually",
      "offset": 3932.559,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "judge that simply from its token out",
      "offset": 3933.92,
      "duration": 4.879
    },
    {
      "lang": "en",
      "text": "next token probabilities itself. And",
      "offset": 3936.24,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "that's when you start talking about",
      "offset": 3938.799,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "world models that the idea of probing of",
      "offset": 3940.079,
      "duration": 5.201
    },
    {
      "lang": "en",
      "text": "can you hijack an LLM's internal",
      "offset": 3943.119,
      "duration": 5.041
    },
    {
      "lang": "en",
      "text": "parameters to try to see what is it",
      "offset": 3945.28,
      "duration": 4.559
    },
    {
      "lang": "en",
      "text": "thinking about here? like what what's",
      "offset": 3948.16,
      "duration": 4.879
    },
    {
      "lang": "en",
      "text": "going on through those 20 billion",
      "offset": 3949.839,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "parameters so that by the time it gets",
      "offset": 3953.039,
      "duration": 4.961
    },
    {
      "lang": "en",
      "text": "to the next token, a lot's happened.",
      "offset": 3955.119,
      "duration": 5.121
    },
    {
      "lang": "en",
      "text": "What's going on in there? Nice. Thank",
      "offset": 3958,
      "duration": 4.559
    },
    {
      "lang": "en",
      "text": "you for that explanation of perplexity.",
      "offset": 3960.24,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "Uh that is definitely the most we've",
      "offset": 3962.559,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "gotten into perplexity on this podcast,",
      "offset": 3964.88,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "believe it or not. So, thank you very",
      "offset": 3966.96,
      "duration": 6.24
    },
    {
      "lang": "en",
      "text": "much for that. Um nice. Okay, so that",
      "offset": 3968.24,
      "duration": 6.96
    },
    {
      "lang": "en",
      "text": "gets into the confidence thing a bit. I",
      "offset": 3973.2,
      "duration": 5.119
    },
    {
      "lang": "en",
      "text": "just have two last technical questions",
      "offset": 3975.2,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "for you if you have the time. Let's do",
      "offset": 3978.319,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "it. Okay. So the first one is with",
      "offset": 3979.76,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "respect to multimodal models. So now all",
      "offset": 3982.72,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "of a sudden we can have AI systems that",
      "offset": 3985.76,
      "duration": 5.359
    },
    {
      "lang": "en",
      "text": "can be processing images, natural",
      "offset": 3987.92,
      "duration": 7.28
    },
    {
      "lang": "en",
      "text": "language, audio, maybe all at once. And",
      "offset": 3991.119,
      "duration": 6.72
    },
    {
      "lang": "en",
      "text": "so testing has to become more complex,",
      "offset": 3995.2,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "probably more expensive to create as",
      "offset": 3997.839,
      "duration": 5.361
    },
    {
      "lang": "en",
      "text": "well. So where are we on this? And you",
      "offset": 3999.52,
      "duration": 4.799
    },
    {
      "lang": "en",
      "text": "know, I'd just love to hear your",
      "offset": 4003.2,
      "duration": 3.599
    },
    {
      "lang": "en",
      "text": "thoughts on on multimodal evaluation.",
      "offset": 4004.319,
      "duration": 4.961
    },
    {
      "lang": "en",
      "text": "There multimodal evaluation in a lot of",
      "offset": 4006.799,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "ways is not much different in a lot of",
      "offset": 4009.28,
      "duration": 5.039
    },
    {
      "lang": "en",
      "text": "ways. For example, there is an MMLU",
      "offset": 4011.839,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "version for multimodal. It's called MMU.",
      "offset": 4014.319,
      "duration": 5.121
    },
    {
      "lang": "en",
      "text": "I'll I'll give you three guesses what",
      "offset": 4017.839,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "the new M stands for it multimodal. Um,",
      "offset": 4019.44,
      "duration": 5.679
    },
    {
      "lang": "en",
      "text": "and they're just multiple choice",
      "offset": 4023.839,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "questions. Here's an image. Here's a",
      "offset": 4025.119,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "question. Here's your multiple choice.",
      "offset": 4027.039,
      "duration": 3.441
    },
    {
      "lang": "en",
      "text": "Please answer the question. Because the",
      "offset": 4028.559,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "second you say multimodal for me, and I",
      "offset": 4030.48,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "did a whole video on this, several hours",
      "offset": 4033.039,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "long. What do you mean by multimodal? Is",
      "offset": 4035.2,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "it audio? Is it video? Is it documents?",
      "offset": 4037.359,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "Is it 3D images? Is it just 2D images?",
      "offset": 4039.76,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "What do you mean by multimodal? And",
      "offset": 4043.039,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "again, to your point, well, what's the",
      "offset": 4044.96,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "architecture? Is it an omni model like",
      "offset": 4046.64,
      "duration": 5.199
    },
    {
      "lang": "en",
      "text": "40 or lava where it's able to take in",
      "offset": 4049.039,
      "duration": 5.361
    },
    {
      "lang": "en",
      "text": "these different modes of data and",
      "offset": 4051.839,
      "duration": 5.601
    },
    {
      "lang": "en",
      "text": "basically project them to all look like",
      "offset": 4054.4,
      "duration": 6.719
    },
    {
      "lang": "en",
      "text": "text tokens? That's how OpenAI uh 40",
      "offset": 4057.44,
      "duration": 6.32
    },
    {
      "lang": "en",
      "text": "does their their image input and also in",
      "offset": 4061.119,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "a lot of ways how they do their newest",
      "offset": 4063.76,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "image output. Now, technically that",
      "offset": 4065.2,
      "duration": 3.599
    },
    {
      "lang": "en",
      "text": "shouldn't matter because if you're just",
      "offset": 4067.52,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "testing something like VQA, visual",
      "offset": 4068.799,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "question and answering, here's a",
      "offset": 4070.88,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "question, here's an image, answer the",
      "offset": 4072.48,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "question. Shouldn't matter. If the AI",
      "offset": 4074.24,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "can come up with the answer, we can",
      "offset": 4076.48,
      "duration": 5.359
    },
    {
      "lang": "en",
      "text": "judge the answer. But it's also going to",
      "offset": 4078.48,
      "duration": 5.119
    },
    {
      "lang": "en",
      "text": "come down to, well, what's the goal",
      "offset": 4081.839,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "here? I is the goal to be a trivia",
      "offset": 4083.599,
      "duration": 4.641
    },
    {
      "lang": "en",
      "text": "answer with images or is the goal to",
      "offset": 4085.92,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "actually be able to read what's in the",
      "offset": 4088.24,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "image and use what's in that image for",
      "offset": 4090.4,
      "duration": 5.199
    },
    {
      "lang": "en",
      "text": "some other task. The point of it all is",
      "offset": 4092.64,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "to say I don't think we should be",
      "offset": 4095.599,
      "duration": 4.801
    },
    {
      "lang": "en",
      "text": "judging multimodal models really any",
      "offset": 4097.6,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "differently. We are still trying to",
      "offset": 4100.4,
      "duration": 3.759
    },
    {
      "lang": "en",
      "text": "understand if they can perform a",
      "offset": 4102.56,
      "duration": 3.759
    },
    {
      "lang": "en",
      "text": "specific task for us. Whether or not",
      "offset": 4104.159,
      "duration": 4.241
    },
    {
      "lang": "en",
      "text": "that task involves an image should",
      "offset": 4106.319,
      "duration": 4.241
    },
    {
      "lang": "en",
      "text": "frankly be irrelevant. It's just now",
      "offset": 4108.4,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "that these models can start to take in",
      "offset": 4110.56,
      "duration": 4.239
    },
    {
      "lang": "en",
      "text": "images, we have to update our",
      "offset": 4112.96,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "benchmarks. And there are hundreds of",
      "offset": 4114.799,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "multimodal benchmarks out there, ranging",
      "offset": 4116.96,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "from video ones to audio ones, mostly",
      "offset": 4119.279,
      "duration": 5.121
    },
    {
      "lang": "en",
      "text": "image ones. And there's even new LLM as",
      "offset": 4121.92,
      "duration": 5.919
    },
    {
      "lang": "en",
      "text": "judges specifically for multimodals.",
      "offset": 4124.4,
      "duration": 6.16
    },
    {
      "lang": "en",
      "text": "There's Lava Critic, who is specifically",
      "offset": 4127.839,
      "duration": 5.121
    },
    {
      "lang": "en",
      "text": "designed to take in an image, a",
      "offset": 4130.56,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "question, and an answer, and give you a",
      "offset": 4132.96,
      "duration": 4.799
    },
    {
      "lang": "en",
      "text": "rubric score from 0 to 100.",
      "offset": 4134.96,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "even does LLM as a judge, meaning it",
      "offset": 4137.759,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "gives you an image, a question, two",
      "offset": 4139.92,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "answers, and it tells you which one is",
      "offset": 4141.759,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "better and why. So, we're still doing it",
      "offset": 4144.08,
      "duration": 4.639
    },
    {
      "lang": "en",
      "text": "the same way. It's just that it happens",
      "offset": 4146.719,
      "duration": 4.801
    },
    {
      "lang": "en",
      "text": "to be such that the input includes an",
      "offset": 4148.719,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "image. Now, if the output includes an",
      "offset": 4151.52,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "image and we have to judge that, it's a",
      "offset": 4153.759,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "little bit of a more murky territory",
      "offset": 4155.92,
      "duration": 2.96
    },
    {
      "lang": "en",
      "text": "because that now involves that the",
      "offset": 4157.44,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "system who is able to read the images is",
      "offset": 4158.88,
      "duration": 4.479
    },
    {
      "lang": "en",
      "text": "itself good enough to understand what's",
      "offset": 4161.44,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "in that image. So, there's kind of this",
      "offset": 4163.359,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "kind of self",
      "offset": 4165.279,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "um self-fulfilling prophecy of well if",
      "offset": 4167.279,
      "duration": 4.721
    },
    {
      "lang": "en",
      "text": "this AI is trying to output an image and",
      "offset": 4170.159,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "this one is trying to ingest the image",
      "offset": 4172,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "to evaluate it how do we know if the",
      "offset": 4173.839,
      "duration": 4.241
    },
    {
      "lang": "en",
      "text": "evaluating model is actually good enough",
      "offset": 4176.159,
      "duration": 4.241
    },
    {
      "lang": "en",
      "text": "to do that task. Nice. Thank you for",
      "offset": 4178.08,
      "duration": 6.88
    },
    {
      "lang": "en",
      "text": "that tour of multimodal evaluation. My",
      "offset": 4180.4,
      "duration": 7.359
    },
    {
      "lang": "en",
      "text": "last technical question for you is on",
      "offset": 4184.96,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "and you could probably do a whole",
      "offset": 4187.759,
      "duration": 3.361
    },
    {
      "lang": "en",
      "text": "episode on this, so it's probably not",
      "offset": 4188.799,
      "duration": 3.761
    },
    {
      "lang": "en",
      "text": "even fair of me to squeeze this in at",
      "offset": 4191.12,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "the end, but one of the hottest topics",
      "offset": 4192.56,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "in AI today we can probably agree is",
      "offset": 4194.64,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "agents. How the heck do you evaluate an",
      "offset": 4196.4,
      "duration": 9.759
    },
    {
      "lang": "en",
      "text": "agent when they are being asked to do a",
      "offset": 4200.64,
      "duration": 8.16
    },
    {
      "lang": "en",
      "text": "you could have a team of agents being",
      "offset": 4206.159,
      "duration": 6.721
    },
    {
      "lang": "en",
      "text": "asked to gather information and create a",
      "offset": 4208.8,
      "duration": 6.48
    },
    {
      "lang": "en",
      "text": "website you know do they could be",
      "offset": 4212.88,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "potentially working for days.",
      "offset": 4215.28,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "How do you come up with a good benchmark",
      "offset": 4217.76,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "or evaluation in any way of whether an",
      "offset": 4219.84,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "agent is doing what you want it to be or",
      "offset": 4223.76,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "not? How do you compare different",
      "offset": 4225.36,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "agentic frameworks, different LLMs",
      "offset": 4227.12,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "within the same agentic framework and so",
      "offset": 4229.6,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "on? Yeah, you are right that it's going",
      "offset": 4231.28,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "to be a total episode on its own. But",
      "offset": 4233.92,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "let me let me let me try to break it",
      "offset": 4235.76,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "down. There's there's two big components",
      "offset": 4237.44,
      "duration": 5.759
    },
    {
      "lang": "en",
      "text": "of the agent to put it very very simply.",
      "offset": 4240.4,
      "duration": 6.24
    },
    {
      "lang": "en",
      "text": "There's the final answer, whatever that",
      "offset": 4243.199,
      "duration": 6.081
    },
    {
      "lang": "en",
      "text": "final answer is, but there is eventually",
      "offset": 4246.64,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "usually a final answer. And that answer",
      "offset": 4249.28,
      "duration": 4.879
    },
    {
      "lang": "en",
      "text": "could be, &quot;Here's the email to this",
      "offset": 4252.4,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "person that you asked me to email.&quot; Or",
      "offset": 4254.159,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "it could be, &quot;I've answered your",
      "offset": 4256.96,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "question. Here's the answer to your",
      "offset": 4258.56,
      "duration": 3.119
    },
    {
      "lang": "en",
      "text": "question, and I've done so by reaching",
      "offset": 4260.08,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "out to 20 agents.&quot; So, you can judge",
      "offset": 4261.679,
      "duration": 4.801
    },
    {
      "lang": "en",
      "text": "that answer using a lot of the ways that",
      "offset": 4264.32,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "we've been talking about before. That",
      "offset": 4266.48,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "that part I'm not going to get into. The",
      "offset": 4268.48,
      "duration": 3.679
    },
    {
      "lang": "en",
      "text": "part that I want to get into is the fact",
      "offset": 4270.32,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "that really agents are themselves hidden",
      "offset": 4272.159,
      "duration": 7.281
    },
    {
      "lang": "en",
      "text": "workflows. We're not designating if yes,",
      "offset": 4275.76,
      "duration": 6.399
    },
    {
      "lang": "en",
      "text": "go here, if no, go there. But the agent",
      "offset": 4279.44,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "does have the agency, pun intended, to",
      "offset": 4282.159,
      "duration": 4.961
    },
    {
      "lang": "en",
      "text": "be able to say, I need to look this up.",
      "offset": 4284.64,
      "duration": 5.84
    },
    {
      "lang": "en",
      "text": "Call tool to look this up. I need to now",
      "offset": 4287.12,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "write Python code to do something.",
      "offset": 4290.48,
      "duration": 3.759
    },
    {
      "lang": "en",
      "text": "Writes Python code to do something.",
      "offset": 4292.08,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "Every single one of those steps in",
      "offset": 4294.239,
      "duration": 6.321
    },
    {
      "lang": "en",
      "text": "theory can be evaluated ranging from did",
      "offset": 4296.4,
      "duration": 6.56
    },
    {
      "lang": "en",
      "text": "you pick the right tool to even begin",
      "offset": 4300.56,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "with or did you just go off the cliff",
      "offset": 4302.96,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "immediately and then have to stumble",
      "offset": 4305.6,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "your way back towards the end. That's",
      "offset": 4307.36,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "just tool selection accuracy. It's a big",
      "offset": 4310,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "case study that I do also falls victim",
      "offset": 4312.48,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "to the positional bias. Then it's did",
      "offset": 4314.32,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "you call the right arguments? Did you",
      "offset": 4316.56,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "Google the right thing? For example, I",
      "offset": 4318.08,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "you googled something but did you Google",
      "offset": 4320.8,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "the right thing? The point is every",
      "offset": 4322.48,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "micro thing work part of the workflow",
      "offset": 4324.8,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "can be evaluated. So the question",
      "offset": 4327.36,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "becomes do we evaluate every micro",
      "offset": 4329.6,
      "duration": 6.72
    },
    {
      "lang": "en",
      "text": "action that an agent takes? No. But",
      "offset": 4332.96,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "there is a middle ground. There is a",
      "offset": 4336.32,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "midlevel where you can say, well, look,",
      "offset": 4338.48,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "I'm going to build a data set that's",
      "offset": 4340.8,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "just going to test first tool selection.",
      "offset": 4342.88,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "Here's a 100 questions and here's the",
      "offset": 4344.96,
      "duration": 5.199
    },
    {
      "lang": "en",
      "text": "tool I'm expecting it to call. I don't",
      "offset": 4347.44,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "even care about the arguments. If I ask",
      "offset": 4350.159,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "this question, I want you to Google it.",
      "offset": 4351.92,
      "duration": 4.239
    },
    {
      "lang": "en",
      "text": "If I ask this question, I want you to",
      "offset": 4353.84,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "pass it off to this other agent just to",
      "offset": 4356.159,
      "duration": 5.601
    },
    {
      "lang": "en",
      "text": "test the first act because usually",
      "offset": 4358.239,
      "duration": 5.92
    },
    {
      "lang": "en",
      "text": "that's where agents fail the most is the",
      "offset": 4361.76,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "first action. Because then the second",
      "offset": 4364.159,
      "duration": 3.761
    },
    {
      "lang": "en",
      "text": "thing you want to test is how efficient",
      "offset": 4366.4,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "was this whole process? How many tool",
      "offset": 4367.92,
      "duration": 4.239
    },
    {
      "lang": "en",
      "text": "calls? How many tokens? How long did it",
      "offset": 4369.84,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "take? And if I ask you the same question",
      "offset": 4372.159,
      "duration": 5.361
    },
    {
      "lang": "en",
      "text": "with more and more context, does that",
      "offset": 4374.48,
      "duration": 5.679
    },
    {
      "lang": "en",
      "text": "efficiency window shrink? Meaning, is it",
      "offset": 4377.52,
      "duration": 6.4
    },
    {
      "lang": "en",
      "text": "getting more and more efficient? If yes,",
      "offset": 4380.159,
      "duration": 5.681
    },
    {
      "lang": "en",
      "text": "how much context does it take before you",
      "offset": 4383.92,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "see that plateau? And is there a way to",
      "offset": 4385.84,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "give you that much context in real life?",
      "offset": 4388.64,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "So you're now you're just kind of",
      "offset": 4391.28,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "figuring out the ceiling of the",
      "offset": 4392.48,
      "duration": 4.239
    },
    {
      "lang": "en",
      "text": "performance. and then asking yourself,",
      "offset": 4394.32,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "can we tweak our system in order to give",
      "offset": 4396.719,
      "duration": 5.681
    },
    {
      "lang": "en",
      "text": "it the context that it so craves in",
      "offset": 4399.6,
      "duration": 4.559
    },
    {
      "lang": "en",
      "text": "order to make this entire process more",
      "offset": 4402.4,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "efficient? So there's a when it comes",
      "offset": 4404.159,
      "duration": 4.801
    },
    {
      "lang": "en",
      "text": "down to it, you can just evaluate the",
      "offset": 4406.96,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "end result, which is fine. You should be",
      "offset": 4408.96,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "doing that, but realistically, you",
      "offset": 4410.96,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "should also be testing the kind of micro",
      "offset": 4412.96,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "actions along the way. And every single",
      "offset": 4414.56,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "agent, if you I don't care if you have a",
      "offset": 4416.8,
      "duration": 3.359
    },
    {
      "lang": "en",
      "text": "hundred agents in your system. If you",
      "offset": 4418.08,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "have a hundred agents, you better make",
      "offset": 4420.159,
      "duration": 4.801
    },
    {
      "lang": "en",
      "text": "sure that each 100 of those agents has a",
      "offset": 4422.159,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "has some thing that they're good at. If",
      "offset": 4424.96,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "they don't have anything that they are",
      "offset": 4427.679,
      "duration": 3.121
    },
    {
      "lang": "en",
      "text": "good at, then another agent is not good",
      "offset": 4428.88,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "at, kill it. So, by the time you end up",
      "offset": 4430.8,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "with the agents that are good at",
      "offset": 4433.12,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "something, test them on it. Make your",
      "offset": 4434.48,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "own benchmarks. same thing we've been",
      "offset": 4436.4,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "talking about before. Test them on their",
      "offset": 4438,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "individual characteristics and that",
      "offset": 4439.92,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "should bubble up to an overall",
      "offset": 4441.92,
      "duration": 6.4
    },
    {
      "lang": "en",
      "text": "performance of the system. Very nice. Uh",
      "offset": 4444.4,
      "duration": 8
    },
    {
      "lang": "en",
      "text": "you said that so so well. It's amazing",
      "offset": 4448.32,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "how well you can communicate these kinds",
      "offset": 4452.4,
      "duration": 3.279
    },
    {
      "lang": "en",
      "text": "of technical concepts. So yeah, so",
      "offset": 4453.84,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "definitely it sounds tricky. You know,",
      "offset": 4455.679,
      "duration": 2.961
    },
    {
      "lang": "en",
      "text": "there's going to be a lot. It's going to",
      "offset": 4457.44,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "be labor intensive to be able to come up",
      "offset": 4458.64,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "with a good agent. It is. Yeah, it is",
      "offset": 4460.96,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "and it will be. And that makes sense. As",
      "offset": 4462.64,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "these machines get more capable, it's",
      "offset": 4465.12,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "going to be trickier and trickier to",
      "offset": 4467.12,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "evaluate them. And that's a good thing",
      "offset": 4468.4,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "because they're more and more capable.",
      "offset": 4470.32,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "And exciting things lie ahead for",
      "offset": 4471.92,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "enterprises that can be jumping on, you",
      "offset": 4473.36,
      "duration": 6.72
    },
    {
      "lang": "en",
      "text": "know, cautious but uh thoughtful use um",
      "offset": 4475.44,
      "duration": 6.64
    },
    {
      "lang": "en",
      "text": "of of Agentic systems. A lot of",
      "offset": 4480.08,
      "duration": 5.599
    },
    {
      "lang": "en",
      "text": "possibility out there. Um Son, you've",
      "offset": 4482.08,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "been very generous with your time. We've",
      "offset": 4485.679,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "gone over the scheduled slot so that we",
      "offset": 4486.96,
      "duration": 2.88
    },
    {
      "lang": "en",
      "text": "can get in these extra technical",
      "offset": 4488.719,
      "duration": 4.801
    },
    {
      "lang": "en",
      "text": "questions. Happens. Um, uh, before I let",
      "offset": 4489.84,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "you go, do you have a book",
      "offset": 4493.52,
      "duration": 2.8
    },
    {
      "lang": "en",
      "text": "recommendation for us? It can't be my",
      "offset": 4494.56,
      "duration": 3.679
    },
    {
      "lang": "en",
      "text": "book, right? I'm kidding. Uh, honestly,",
      "offset": 4496.32,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "okay, I'm gonna give you less of a",
      "offset": 4498.239,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "recommendation",
      "offset": 4500.88,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "and",
      "offset": 4502.719,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "more See, here's You know what? Now that",
      "offset": 4504.32,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "I'm thinking about this, I don't even",
      "offset": 4506.32,
      "duration": 2.72
    },
    {
      "lang": "en",
      "text": "remember the last book that I",
      "offset": 4507.6,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "recommended to you. I don't want to like",
      "offset": 4509.04,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "accidentally recommend the same book",
      "offset": 4510.96,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "again. Well, I'm confident that if it's",
      "offset": 4513.28,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "the one we talked about before",
      "offset": 4515.36,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "recording, we should be good. Well, that",
      "offset": 4516.48,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "one is is also true, but I was I was",
      "offset": 4518.8,
      "duration": 2.72
    },
    {
      "lang": "en",
      "text": "thinking about other books in the",
      "offset": 4520.64,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "meantime. The book I am excited to read",
      "offset": 4521.52,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "and I will I will report back with my",
      "offset": 4523.76,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "findings is a book called AI Snake Oil.",
      "offset": 4525.84,
      "duration": 6.16
    },
    {
      "lang": "en",
      "text": "Um it's by Arvind Narayan, I hope I'm",
      "offset": 4528.96,
      "duration": 5.92
    },
    {
      "lang": "en",
      "text": "saying that right, and Sash Kapoor. Uh",
      "offset": 4532,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "both, I believe both from from",
      "offset": 4534.88,
      "duration": 2.96
    },
    {
      "lang": "en",
      "text": "Princeton. I had the pleasure of meeting",
      "offset": 4536.48,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "Arvind actually at ODSC when we when we",
      "offset": 4537.84,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "last hung out. and he gave a keynote",
      "offset": 4540.32,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "that was just basically the 30inut",
      "offset": 4542.32,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "version of my workshop you know less",
      "offset": 4544.239,
      "duration": 5.121
    },
    {
      "lang": "en",
      "text": "code and more just direct um knowledge",
      "offset": 4546.64,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "and he was actually really instrumental",
      "offset": 4549.36,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "in in in in benchmarks like sui and and",
      "offset": 4551.28,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "working on on on and things like that",
      "offset": 4553.92,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "the book is really exciting for me",
      "offset": 4556,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "because I've always been",
      "offset": 4557.44,
      "duration": 6.16
    },
    {
      "lang": "en",
      "text": "call it ranting about the gap of",
      "offset": 4561.12,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "marketing and functionality I mean I am",
      "offset": 4563.6,
      "duration": 5.599
    },
    {
      "lang": "en",
      "text": "on record really laying into IBM Watson",
      "offset": 4565.84,
      "duration": 5.839
    },
    {
      "lang": "en",
      "text": "10 years ago and just kind of the",
      "offset": 4569.199,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "marketing mishaps that they had and how",
      "offset": 4571.679,
      "duration": 2.881
    },
    {
      "lang": "en",
      "text": "they weren't living up to a lot of",
      "offset": 4573.36,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "expectations. I stand by everything I",
      "offset": 4574.56,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "said, but that the whole concept of",
      "offset": 4576.48,
      "duration": 5.84
    },
    {
      "lang": "en",
      "text": "snake oil in AI is not new, but it is",
      "offset": 4578.32,
      "duration": 7.12
    },
    {
      "lang": "en",
      "text": "just explosive right now. So, I I am",
      "offset": 4582.32,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "really excited to hear and read about",
      "offset": 4585.44,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "kind of what are the modern takes on",
      "offset": 4587.6,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "snake oil because it used to just be big",
      "offset": 4589.52,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "company makes big claims. Google says",
      "offset": 4591.84,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "they can call your hairdresser and make",
      "offset": 4594.32,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "an appointment in 2017. Do we believe",
      "offset": 4596.159,
      "duration": 7.04
    },
    {
      "lang": "en",
      "text": "them? No. Now, do we believe them? Yes.",
      "offset": 4599.36,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "So, things can change quickly. So, what",
      "offset": 4603.199,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "is the new snake oil that people are",
      "offset": 4605.36,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "selling? That's what I'm really excited",
      "offset": 4607.679,
      "duration": 4.241
    },
    {
      "lang": "en",
      "text": "to dig into. Fantastic. Thanks, son.",
      "offset": 4609.199,
      "duration": 4.881
    },
    {
      "lang": "en",
      "text": "That's a great recommendation. And yeah,",
      "offset": 4611.92,
      "duration": 6.319
    },
    {
      "lang": "en",
      "text": "uh that author Arvvent, right? Uh he was",
      "offset": 4614.08,
      "duration": 6.159
    },
    {
      "lang": "en",
      "text": "highly recommended by Sheamus McGovern,",
      "offset": 4618.239,
      "duration": 4.721
    },
    {
      "lang": "en",
      "text": "who runs ODSC East. He said that I got",
      "offset": 4620.239,
      "duration": 4.641
    },
    {
      "lang": "en",
      "text": "to get him on the show. So, maybe we",
      "offset": 4622.96,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "will have him on the show for an AI",
      "offset": 4624.88,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "snake oil episode soon. Uh in the",
      "offset": 4626.32,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "meantime for people who want to be",
      "offset": 4629.44,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "hearing more from you on we know about",
      "offset": 4630.8,
      "duration": 4.879
    },
    {
      "lang": "en",
      "text": "your books. So quick start guide to LLM",
      "offset": 4633.36,
      "duration": 5.359
    },
    {
      "lang": "en",
      "text": "for example third edition is now out. Uh",
      "offset": 4635.679,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "third edition is coming out. Second",
      "offset": 4638.719,
      "duration": 3.361
    },
    {
      "lang": "en",
      "text": "edition edition is coming out. Gotcha.",
      "offset": 4640.239,
      "duration": 4.721
    },
    {
      "lang": "en",
      "text": "Gotcha. Um your O'Reilly trainings",
      "offset": 4642.08,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "people can find you there about once a",
      "offset": 4644.96,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "week uh for classes like trans uh",
      "offset": 4646.64,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "transformer architectures AI agents a",
      "offset": 4649.44,
      "duration": 6.32
    },
    {
      "lang": "en",
      "text": "toz a to zed a toz in America. Um, and",
      "offset": 4651.44,
      "duration": 6.719
    },
    {
      "lang": "en",
      "text": "RAG. Uh, of course you have agent",
      "offset": 4655.76,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "classes in O'Reilly as well that I don't",
      "offset": 4658.159,
      "duration": 3.121
    },
    {
      "lang": "en",
      "text": "we've spoken about, but of course you",
      "offset": 4660,
      "duration": 3.199
    },
    {
      "lang": "en",
      "text": "do. Yeah. Agent and RAG courses also in",
      "offset": 4661.28,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "July and then in the next week or two.",
      "offset": 4663.199,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "Yeah. And then practically intelligent",
      "offset": 4665.28,
      "duration": 4.879
    },
    {
      "lang": "en",
      "text": "your podcast. Maybe our listeners maybe",
      "offset": 4666.88,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "won't be too long before they hear me as",
      "offset": 4670.159,
      "duration": 2.801
    },
    {
      "lang": "en",
      "text": "a guest on that show. I was going to say",
      "offset": 4671.52,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "I didn't want to uh ruin the surprise,",
      "offset": 4672.96,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "but yes, you can also hear John on my",
      "offset": 4674.96,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "own show when it comes out. Nice. Nice.",
      "offset": 4676.96,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "And yeah, so that'll be interesting",
      "offset": 4679.52,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "because, you know, we if there are",
      "offset": 4680.4,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "there's probably some dedicated",
      "offset": 4683.12,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "listeners out there that are listening",
      "offset": 4685.12,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "to most episodes of this show and maybe",
      "offset": 4686.32,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "they actually don't know very much about",
      "offset": 4689.28,
      "duration": 2.56
    },
    {
      "lang": "en",
      "text": "me at all except for, you know, my kind",
      "offset": 4690.48,
      "duration": 3.199
    },
    {
      "lang": "en",
      "text": "of quips. How often are you a guest on a",
      "offset": 4691.84,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "show? Because you're always you're",
      "offset": 4693.679,
      "duration": 2.56
    },
    {
      "lang": "en",
      "text": "always the host. You're always",
      "offset": 4695.12,
      "duration": 2.559
    },
    {
      "lang": "en",
      "text": "interviewing. How often do you get to be",
      "offset": 4696.239,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "the guest? Yeah, I mean I've gone",
      "offset": 4697.679,
      "duration": 5.281
    },
    {
      "lang": "en",
      "text": "through phases. So when my book Deep",
      "offset": 4699.84,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "Learning Illustrated came out in 2019, I",
      "offset": 4702.96,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "kind of did a podcast tour where I was",
      "offset": 4705.6,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "like actively reaching out to to be on",
      "offset": 4707.28,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "shows. And in fact, that's how I ended",
      "offset": 4709.44,
      "duration": 3.279
    },
    {
      "lang": "en",
      "text": "up becoming the host of Super Data",
      "offset": 4710.96,
      "duration": 5.279
    },
    {
      "lang": "en",
      "text": "Science because Oh, well Kurill asked me",
      "offset": 4712.719,
      "duration": 6.161
    },
    {
      "lang": "en",
      "text": "to be a guest on his show on on on this",
      "offset": 4716.239,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "podcast on the Super Data Science",
      "offset": 4718.88,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "podcast. Um, and so I can actually",
      "offset": 4720.08,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "probably look that episode up. Uh, I",
      "offset": 4722.48,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "think it might be 365. I have that",
      "offset": 4725.04,
      "duration": 2.96
    },
    {
      "lang": "en",
      "text": "number in my head because it's kind of",
      "offset": 4727.04,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "like an easy number to remember. Um, let",
      "offset": 4728,
      "duration": 6.96
    },
    {
      "lang": "en",
      "text": "me double check. Yeah, 365.",
      "offset": 4731.76,
      "duration": 8.24
    },
    {
      "lang": "en",
      "text": "And um, all year round. Uh, and",
      "offset": 4734.96,
      "duration": 6.719
    },
    {
      "lang": "en",
      "text": "and I asked him at that time basically",
      "offset": 4740,
      "duration": 2.96
    },
    {
      "lang": "en",
      "text": "the same question you just asked me,",
      "offset": 4741.679,
      "duration": 3.361
    },
    {
      "lang": "en",
      "text": "which was, &quot;How often are you a guest on",
      "offset": 4742.96,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "other people's podcasts?&quot; And he said",
      "offset": 4745.04,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "never. He said he'd done it one time.",
      "offset": 4746.96,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "And I said, &quot;Well, I've actually just",
      "offset": 4749.12,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "launched my own little podcast, which",
      "offset": 4750.8,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "was supposed to be uh, it was called the",
      "offset": 4753.36,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "artificial neural the artificial neural",
      "offset": 4755.84,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "network news network. And so it was",
      "offset": 4758.32,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "supposed to be a weekly news show about",
      "offset": 4760.56,
      "duration": 5.119
    },
    {
      "lang": "en",
      "text": "AI news. And the thing that was fun",
      "offset": 4762.88,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "about it, we got to film one episode in",
      "offset": 4765.679,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "February 2020. And you can find people",
      "offset": 4767.52,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "can find this online on any on all the",
      "offset": 4769.679,
      "duration": 5.921
    },
    {
      "lang": "en",
      "text": "major podcasting apps as well as on",
      "offset": 4772.64,
      "duration": 6.16
    },
    {
      "lang": "en",
      "text": "YouTube. Um it's called A4N, the",
      "offset": 4775.6,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "artificial neural network news network.",
      "offset": 4778.8,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "And",
      "offset": 4780.8,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "the first episode was in February 2020.",
      "offset": 4782.32,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "And it it it was my vision. So we had it",
      "offset": 4784.8,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "was me and four other data scientists",
      "offset": 4788,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "and and I was like the anchor of this",
      "offset": 4790,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "news show and I'd say all right let's go",
      "offset": 4792,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "over to Andrew for sports and he would",
      "offset": 4794.56,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "talk about cheating and Kaggle and let's",
      "offset": 4796.159,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "go over to Vince for weather and he'd",
      "offset": 4798.08,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "talk about AI uh being used to tackle",
      "offset": 4799.84,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "climate change and we had such a laugh",
      "offset": 4802.48,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "recording it and then the next week the",
      "offset": 4805.04,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "pandemic hit. I was about to say",
      "offset": 4807.44,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "something else was about to happen in",
      "offset": 4809.199,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "February 2020. Exactly. And then so",
      "offset": 4810.56,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "nobody wanted to come into the office.",
      "offset": 4813.199,
      "duration": 3.201
    },
    {
      "lang": "en",
      "text": "We weren't able to keep doing it that",
      "offset": 4814.48,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "way. So, I did four more episodes where",
      "offset": 4816.4,
      "duration": 5.839
    },
    {
      "lang": "en",
      "text": "I interviewed guests.",
      "offset": 4819.92,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "Um,",
      "offset": 4822.239,
      "duration": 5.681
    },
    {
      "lang": "en",
      "text": "and Kurroll was one of those four. Huh.",
      "offset": 4823.76,
      "duration": 6.479
    },
    {
      "lang": "en",
      "text": "And then like six months after that, he",
      "offset": 4827.92,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "was like, &quot;Do you want to host the Super",
      "offset": 4830.239,
      "duration": 5.121
    },
    {
      "lang": "en",
      "text": "Designs podcast?&quot; Wow. Wow. That's",
      "offset": 4832.4,
      "duration": 6.24
    },
    {
      "lang": "en",
      "text": "crazy. I had no idea. That's cool. Yeah.",
      "offset": 4835.36,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "And what's really funny is if you",
      "offset": 4838.64,
      "duration": 5.039
    },
    {
      "lang": "en",
      "text": "listen, people listen to Kier's episode.",
      "offset": 4840.32,
      "duration": 8
    },
    {
      "lang": "en",
      "text": "We made fake ads for that episode. About",
      "offset": 4843.679,
      "duration": 8.241
    },
    {
      "lang": "en",
      "text": "what? And um so we had uh it was an app",
      "offset": 4848.32,
      "duration": 6.879
    },
    {
      "lang": "en",
      "text": "for finding toilet paper. Uh",
      "offset": 4851.92,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "because it was the pandemic. It was like",
      "offset": 4855.199,
      "duration": 4.641
    },
    {
      "lang": "en",
      "text": "the pandemic had just started. Uh I",
      "offset": 4856.8,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "can't remember. We had a silly name for",
      "offset": 4859.84,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "it. We had music. Um and we just",
      "offset": 4861.28,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "recorded it in one shot with Kurill with",
      "offset": 4864.159,
      "duration": 4.641
    },
    {
      "lang": "en",
      "text": "the guest there. Um I was just like,",
      "offset": 4866.64,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "&quot;Okay, I need to take a break here to",
      "offset": 4868.8,
      "duration": 5.359
    },
    {
      "lang": "en",
      "text": "record this fake ad.&quot; That's so funny.",
      "offset": 4870.96,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "Yeah. Um, so yeah, I was kind of like I",
      "offset": 4874.159,
      "duration": 3.761
    },
    {
      "lang": "en",
      "text": "didn't know but I was auditioning for",
      "offset": 4876.56,
      "duration": 2.88
    },
    {
      "lang": "en",
      "text": "this podcast where we actually have real",
      "offset": 4877.92,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "ads. I'm very much looking forward to",
      "offset": 4879.44,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "being on practically intelligent and",
      "offset": 4880.96,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "having a conversation and also meeting",
      "offset": 4882.48,
      "duration": 5.92
    },
    {
      "lang": "en",
      "text": "remind me of your a yeah looking forward",
      "offset": 4884.56,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "to meeting him and I'm sure we'll have a",
      "offset": 4888.4,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "lot of fun. Uh, and yeah, so uh I'll be",
      "offset": 4890,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "yeah people follow me on LinkedIn or",
      "offset": 4893.76,
      "duration": 2.88
    },
    {
      "lang": "en",
      "text": "whatever I'll be posting about that when",
      "offset": 4895.28,
      "duration": 2.879
    },
    {
      "lang": "en",
      "text": "the practically intelligent episode",
      "offset": 4896.64,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "comes out. And on that note, how should",
      "offset": 4898.159,
      "duration": 4.481
    },
    {
      "lang": "en",
      "text": "people be, you know, other than all like",
      "offset": 4900.64,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "what's a social media place to follow",
      "offset": 4902.64,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "you, son? For me, it's LinkedIn. Um, it",
      "offset": 4903.92,
      "duration": 3.759
    },
    {
      "lang": "en",
      "text": "was always funny to think about now,",
      "offset": 4906.32,
      "duration": 2.8
    },
    {
      "lang": "en",
      "text": "like I never really thought I'd be that",
      "offset": 4907.679,
      "duration": 3.761
    },
    {
      "lang": "en",
      "text": "guy on LinkedIn, but for me, my LinkedIn",
      "offset": 4909.12,
      "duration": 4.559
    },
    {
      "lang": "en",
      "text": "has been my social media of choice. I I",
      "offset": 4911.44,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "kind of grew tired of Twitterx.",
      "offset": 4913.679,
      "duration": 5.201
    },
    {
      "lang": "en",
      "text": "Uh, and that's where most of my",
      "offset": 4916.96,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "followers kind of can find my my my",
      "offset": 4918.88,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "newsletters and my different blog",
      "offset": 4921.6,
      "duration": 3.119
    },
    {
      "lang": "en",
      "text": "articles and just everything that I'm",
      "offset": 4923.12,
      "duration": 5.92
    },
    {
      "lang": "en",
      "text": "doing. Yeah. Nice. Yeah, same for me. I",
      "offset": 4924.719,
      "duration": 6.881
    },
    {
      "lang": "en",
      "text": "yeah I don't know I got tired of like",
      "offset": 4929.04,
      "duration": 5.119
    },
    {
      "lang": "en",
      "text": "there's just so much more interaction on",
      "offset": 4931.6,
      "duration": 7.52
    },
    {
      "lang": "en",
      "text": "LinkedIn lately than X and so",
      "offset": 4934.159,
      "duration": 6.641
    },
    {
      "lang": "en",
      "text": "yeah at least for what we do in data",
      "offset": 4939.12,
      "duration": 3.519
    },
    {
      "lang": "en",
      "text": "science seems to be the place to be now.",
      "offset": 4940.8,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "Yeah nice son thank you so much for",
      "offset": 4942.639,
      "duration": 5.441
    },
    {
      "lang": "en",
      "text": "taking the time and I'm sure it won't be",
      "offset": 4945.199,
      "duration": 4.881
    },
    {
      "lang": "en",
      "text": "long before you're on an episode again.",
      "offset": 4948.08,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "Well, thank you, John. It's always a",
      "offset": 4950.08,
      "duration": 4.44
    },
    {
      "lang": "en",
      "text": "pleasure.",
      "offset": 4951.52,
      "duration": 3
    },
    {
      "lang": "en",
      "text": "Always great to have Son Osdemer on the",
      "offset": 4956.32,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "show. In today's episode, he covered how",
      "offset": 4958.239,
      "duration": 3.361
    },
    {
      "lang": "en",
      "text": "current AI benchmarks suffer from",
      "offset": 4959.76,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "teaching to test where labs optimize for",
      "offset": 4961.6,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "high scores rather than real world",
      "offset": 4963.84,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "performance, as well as contamination",
      "offset": 4965.28,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "issues where test questions leak into",
      "offset": 4967.28,
      "duration": 2.959
    },
    {
      "lang": "en",
      "text": "training data. He talked about",
      "offset": 4969.04,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "allegations emerging that Meta had to",
      "offset": 4970.239,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "publicly deny manipulating Llama 4's",
      "offset": 4972.32,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "benchmark scores, highlighting how the",
      "offset": 4974.4,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "lack of transparency in training data",
      "offset": 4976.4,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "makes it impossible to verify claims. He",
      "offset": 4978.239,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "talked about how even advanced reasoning",
      "offset": 4980.8,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "models like OpenAI's 03 hallucinate up",
      "offset": 4982.56,
      "duration": 5.119
    },
    {
      "lang": "en",
      "text": "to 40% of the time on basic factual",
      "offset": 4985.36,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "benchmarks like simple QA, demonstrating",
      "offset": 4987.679,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "that high capability scores don't",
      "offset": 4989.92,
      "duration": 3.759
    },
    {
      "lang": "en",
      "text": "guarantee truthfulness. And he talked",
      "offset": 4991.679,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "about how organizations should create",
      "offset": 4993.679,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "custom test sets specific to their use",
      "offset": 4995.6,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "cases, implement rubricbased evaluation",
      "offset": 4997.6,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "with LLMs as judges after validating",
      "offset": 5000.32,
      "duration": 4.879
    },
    {
      "lang": "en",
      "text": "against human evaluators ideally, and",
      "offset": 5002.48,
      "duration": 4.719
    },
    {
      "lang": "en",
      "text": "how they should chase their own internal",
      "offset": 5005.199,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "leaderboards rather than generic",
      "offset": 5007.199,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "benchmarks that don't reflect the",
      "offset": 5008.88,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "enterprises actual needs. As always, you",
      "offset": 5011.04,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "can get all the show notes, including",
      "offset": 5014.08,
      "duration": 2.48
    },
    {
      "lang": "en",
      "text": "the transcript for this episode, the",
      "offset": 5015.28,
      "duration": 2.8
    },
    {
      "lang": "en",
      "text": "video recording, any materials mentioned",
      "offset": 5016.56,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "on the show, the URLs for Son's social",
      "offset": 5018.08,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "media profiles, as well as my own at",
      "offset": 5020.32,
      "duration": 4.919
    },
    {
      "lang": "en",
      "text": "superdatience.com/903.",
      "offset": 5022.239,
      "duration": 3
    },
    {
      "lang": "en",
      "text": "Thanks to everyone on the Super Data",
      "offset": 5025.44,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "Science podcast team, our podcast",
      "offset": 5027.12,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "manager Sonia Bryovich, media editor,",
      "offset": 5028.48,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "Mario Pombo, Nathan Daly, and Natalie",
      "offset": 5030.4,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "Jysky on partnerships, our researcher",
      "offset": 5032.4,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "Serge Miss, writer Dr. Zara Care, and",
      "offset": 5034.48,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "yes, of course, our founder Kira Lamnco.",
      "offset": 5036.88,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "Thanks to all of them for producing",
      "offset": 5039.36,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "another excellent episode for us today,",
      "offset": 5040.96,
      "duration": 3.759
    },
    {
      "lang": "en",
      "text": "for enabling that super team to create",
      "offset": 5043.04,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "this free podcast for you. We are deeply",
      "offset": 5044.719,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "grateful to our sponsors. You, yes you,",
      "offset": 5046.56,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "can support this show by checking out",
      "offset": 5049.12,
      "duration": 3.519
    },
    {
      "lang": "en",
      "text": "our sponsors links which are in the show",
      "offset": 5050.56,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "notes. And if you yourself are",
      "offset": 5052.639,
      "duration": 2.881
    },
    {
      "lang": "en",
      "text": "interested in sponsoring an episode, you",
      "offset": 5054,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "can find out how to do that by going to",
      "offset": 5055.52,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "john.com/mpodcast.",
      "offset": 5057.12,
      "duration": 5.039
    },
    {
      "lang": "en",
      "text": "Otherwise, share, review, subscribe, uh,",
      "offset": 5059.679,
      "duration": 4.881
    },
    {
      "lang": "en",
      "text": "edit videos into shorts if you want to.",
      "offset": 5062.159,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "But most importantly, just keep on",
      "offset": 5064.56,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "tuning in. and I'm so grateful to have",
      "offset": 5066.56,
      "duration": 2.88
    },
    {
      "lang": "en",
      "text": "you listening and I hope I can continue",
      "offset": 5067.84,
      "duration": 2.96
    },
    {
      "lang": "en",
      "text": "to make episodes you love for years and",
      "offset": 5069.44,
      "duration": 3.199
    },
    {
      "lang": "en",
      "text": "years to come. Until next time, keep on",
      "offset": 5070.8,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "rocking out there and I'm looking",
      "offset": 5072.639,
      "duration": 2.481
    },
    {
      "lang": "en",
      "text": "forward to enjoying another round of the",
      "offset": 5073.84,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "Super Data Science podcast with you very",
      "offset": 5075.12,
      "duration": 5
    },
    {
      "lang": "en",
      "text": "soon.",
      "offset": 5077.12,
      "duration": 3
    }
  ],
  "cleanText": "So, how does this kind of leaderboard mentality skew our understanding of a model's real abilities on everyday tasks that the rest of us use them for?\nThat mismatch of what's being tested on the benchmark versus what's being marketed the benchmark is for can be quite disparate.\nAnd if humanity's last exam includes knowing what happened in season 14 of League of Legends, I, I don't want to take this exam either, quite frankly.\nRecognizing that you have gaps in your knowledge, for me, that's even more interesting.\nA benchmark should be the start of a conversation, not the end of a conversation.\nWho has the right to judge whether or not the AI was correct or not?\nThat's a big question.\nSinan, welcome back to the SuperDataScience Podcast.\nHow you doing today, Jon?\nThank you for having me yet again.\nI'm, I'm super excited to be here as always.\nYes, we were just tallying prior to starting recording how many times you've been on the show.\nWe, you've been on more times than you even knew.\nYou, you came into the green room, like before we get into the recording studio, and you said you've been on the...\nThis is going to be your fifth time, but actually it's your sixth.\nUh, so you're one of our first guests ever.\nEpisode 21 back in January 2017.\nExactly.\nOld enough to drink.\nThat podcast episode was finally in the US.\nAnd uh yeah, then you were back about a year later in 161 and then jumped a couple years at episode 333 in January 2020.\nAnd then significant for me was another year after that in February 2021.\nYou were one of my first guests when I took over hosting the show from Kurroll.\nThat's right.\nThat was episode 445.\nAnd then last year at the Open Data Science Conference East in Boston, we met up quickly.\nI set up a camera and you and I recorded a quick episode live in person in Boston um on AI alignment.\nYes.\nLLM alignment.\nUm and yeah, so that was episode 784.\nSo lots of episodes.\nUh this is number six.\nIt's going to be the best yet.\nThat's Yeah, that's how I think about it, too.\nJust like, do you think...\nOkay, so you're currently writing your 10th book.\nIs that right?\nThat sounds right.\nIt's, it's up there.\nI'm working on...\nYeah, like I'm working on two right now actually.\nDo you think that the books get better or do you think you're like...\nCuz often rock bands, you know, they have many years to make their first album.\nSo like, I don't know, Bush was a band in the 90s that was super popular.\nOh yeah.\nIn Canada.\nTheir first album, 16 Stone, I guess it was popular in the US as well.\nYou know them.\nYou know, it's funny.\nThey're British.\nPeople don't know them in the UK.\nMachine Head.\nAre you some of my favorite?\nExactly.\nGlycerine.\nOh, yeah.\nAnd that one album, it was like everyone knew every track and you know, huge, huge global hit.\nThey're doing world tours and then so the record company's like, you know, we're going to need another album next year.\nAnd they're like, oh man, we spent like five years making the first one.\nUh, and yeah, that seems to happen all the time with rock bands and then, you know, they never quite have the same kinds of hits.\nDo you think you're like a rock band or do you think your books get better?\nDo you think number 10 is better than number one?\nUh, bold question for throwing shade to all the rock bands out there.\nNo, I, I think I, I very much go in with to my books with a mentality of not necessarily better, but something different.\nLike I, I'm very conscious about, I wrote about this four years ago.\nDo I really have something new to say here or do I digress to something else?\nSo I, I, I aim very much for diversity more than I aim for just kind of building upon the same content every year.\nDo you do second editions ever?\nOh yeah, actually one of the books this year is a third edition of my most recent Quickstart Guide to LLM.\nLike kind of like the...\nSo only, only really two of my books have ever gotten second and third editions and they are very much the holistic books.\nLike my first book ever was the principles of data science and that was almost 10 years ago at this point and it was very much a zero to deep learning in 300 pages.\nSo that's gotten updates over the year just as an introduction to data science.\nAnd the same thing with Quickstart Guide to LLM.\nIt's very much meant for someone who is just diving in for the first time engineer or not, just what do I need to know to understand LLM?\nSo that book gets updated because that's pretty much evergreen content at this point.\nNice.\nTell us about the Quickstart Guide to LLMs.\nTell us about what's in that book uh and what's new in the third edition.\nSure.\nThe book is um, actually it was literally had a copy here just because I was holding up for someone else earlier right there.\nBut um, the book is very much organized into a few sections starting with kind of a level set, like what is a language model?\nWhat is an auto regressive language model versus autoencoding language model?\nLike what does that mean?\nIn fact, in one of my episodes on SuperDataScience, the one from 2020, like January 2020, that was actually the first time I had brought up like BERT and GPT on the show.\nSo, the first part of the book really just talks about what is the difference between these kinds of LLMs.\nThen it gets into the different applications and how to evaluate them and the kind of philosophy of alignment.\nWhat do we mean when we say alignment?\nThen the last parts are usually, all right, now that we're speaking the same language, let's make a phone bot, let's make a embeddings classifier, let's actually build these things, let's make a chatbot from scratch.\nSo it's very much organized into that, those three sections, and the third edition is pretty much the same.\nThe additions are mostly around obviously newer LLMs, newer evaluation criteria, newer benchmarks, and just um, different ways of applying LLM, like reasoning models, for example.\nThis will be the first time that I talk about reasoning models in one of those books.\nVery cool.\nSo yeah, reasoning models like 01, 03.\nWe actually at the time R1.\nYeah.\nFrom Deepseek.\nWe at the time of recording have a new...\nHave you played with uh 03 Pro?\nYes.\nNo, I have not played with it.\nI, I got the email, I think yesterday, like late night yesterday.\nYeah.\nBut um, I have not yet tried it.\nWhat's the...\nWhat's the shtick here?\nBetter, better, faster, cheaper, all the above.\nI think it's, I think it's, I don't think it's cheaper.\nI think it's kind of, it's bigger and better because we have the 03 Mini some months ago.\nAnd they had things like 03 Mini High where you could have it do inference for longer.\nAnd so I believe 03, 03 Pro is kind of orders of magnitude larger in terms of model weights.\nAnd so theoretically nuance.\nWell, that makes sense.\nYeah.\nBut I, I actually, I haven't used it yet.\nIt's been a busy day so far.\nAnd now I'm recording this podcast episode.\nYou know, it's tough to, tough to stay up to date on all the fast-moving things in AI.\nIt is.\nAnd again, that's also why a lot of the book is about models will change.\nBut at the end of the day, this thing is the next token predictor.\nAnd just because it thinks before it speaks to you doesn't mean we can't evaluate it the same way as we evaluate everything else.\nFor sure.\nFor sure.\nThere are definitely, there are mega trends that you can that you can ease into and find comfort in despite, you know, brands maybe changing quickly, model brands, company brands going from 4.5 to 4.1, from 01 to 03 to 04, back to 03, but 03 but better.\nIt can be a lot to keep up with.\nExactly.\nThat's right.\nUm, so you're working on another book right now, I understand as well.\nI don't know if you want to talk about that on air.\nMaybe it's secret.\nIt's not secret.\nI mean, I'd love to talk about it.\nThe, the title is not known yet.\nSo, I'll give you at least the working title.\nIt, it's very much an applied AI book.\nIt is very much around, it's very much a cookbook of AI applications.\nIt's assuming you've read my Quickstart Guide.\nAnd again, we are speaking the same language here is let's just dive into the top 20 applications of LLM I have seen in the last 10 years.\nEverything from let's build a prompt to summarize a podcast transcript and really evaluate this thing to its core all the way to let's use reinforcement learning to actually build some of these reasoning models from scratch for your specific domain.\nSo it's a pretty wide spectrum of things that we do, but it very much starts, hits the ground running kind of book.\nVery nice.\nVery nice.\nI like that cookbook model.\nUh and I assume both of these books, Applied AI and Quickstart, they're both in Python.\nYes.\nSo everything, all the code that I'm writing is in Python.\nNice.\nNice.\nAnd um, in addition to your books, to your many books, you also do a ton of teaching in the O'Reilly platform, which also actually kind of brings up, we don't need to go into this in too much detail, but it's kind of interesting because O'Reilly is a uniquely predominant brand in tech publishing, but you and I both write for Pearson.\nMhm.\nUh and I think even when you and I are teaching in the O'Reilly platform, we're usually doing that for Pearson.\nYep.\nUm and it's and I, I love them.\nI absolutely love same every Pearson book that comes out, everyone that I work with there.\nUm yeah, hopefully we're uh you and I are contributing to increasing kind of awareness of Pearson as being a great technical publisher for for hands-on data science people.\nExactly.\nAnd and and the way that they curate all that information, like they have like those expert playlists, which I think is a really cool little feature.\nSo, they basically take a lot of my videos and books and put them in order to basically say, here's your journey.\nHere's how you should be watching these and reading these in in what order.\nSo, it's not just here's your content.\nIt's more like here's your journey.\nWhat are you trying to do here?\nAnd here's what you should watch.\nI, I, I love that because I think a lot of that education journey is is hard to disseminate, especially when you are new to the field of AI.\nIt's, I don't, I don't know where to start.\nI don't know how these things work.\nAnd having that curation is really helpful.\nFor sure.\nIf we have book authors out there or people who have, you know, kind of maybe you've been writing for a long time and you have a book proposal in mind, reach out to me or reach out to Sinan on LinkedIn probably and we'd be delighted to introduce you to folks at Pearson or O'Reilly for that matter.\nOh yeah.\nUh but uh if you want, you know, with Pearson, the folks over there that we work with, they are so switched on about the industry and they can really help you uh kind of massage the content of your book.\nSo you have big hits like Sinan does and you, we both do.\nAnd yeah, so in addition to your books, you do lots of trainings for Pearson in the O'Reilly platform and uh so oreilly.com probably lots of our listeners know it.\nMillions of people subscribe to it, often through their employer or through their university.\nAnd you teach in there a couple of times a month, pretty much every month, right?\nOh, yeah.\nUh about once a week, right?\nAbout once a week.\nThat's wild.\nAnd so, uh this episode is supposed to be published on July 8th, which means the very next day on July 9th, you have a transformer architectures course, which I think kind of dives deeply.\nAnd actually, this one might really resonate with SuperDataScience podcast listeners because the most popular episode of 2024 was episode 747 with Kier Arnango, the founder and original host of this podcast.\nAnd it was an intro to Transformers.\nAnd it kind of it went into the nitty-gritty.\nAnd I said to him, I paused recording and I said to Carol, \"This is too much.\nLike, you're going too deep.\nThis is not going to work.\nLike the people can't see things in a podcast and it was the most popular episode of 2024.\nExa...\nI, I honestly, I bet like, I, I think when I first made that content, the transformer architectures for GenAI was like one of the first pieces of content I made for Pearson and O'Reilly.\nI originally made that content in 2020, I believe, 2021.\nUh, Chad GPT had not come out yet and and it was very much around this idea of this architecture is changing things and what people do with it is now, you know, open sky, like we don't know what's going to happen.\nAnd then chat GPT came out a couple months later.\nSo I think when that happened, people really came back down to kind of back down to the roots of where does this come from?\nAnd then people are shocked to realize, oh, you know, this thing was invented in 2017.\nWhat have we been doing since then?\nWhy haven't we been doing anything with this since 2017?\nAnd then they, they're even more shocked to realize that it actually came out of Google.\nGoogle invented the transformer architecture.\nAnd then people re-think about that and say, well, hold on.\nWhy are they still not at the top of the pack then of LLMs?\nYou know, they're doing their best to get up there.\nBut it's also, it's always a very funny history to think about, you know, how long ago this all was relative to even today.\nYep.\nFast-moving space.\nI mean, lots of competitors.\nIt seems like you probably know this better than me, but my understanding is that it was OpenAI uh betting big on scaling that, you know, like Google DeepMind, which there used to be kind of two big AI labs at Google, Google Brain and Google DeepMind, and DeepMind was kind of, I think, I mean, in some ways they were kind of, they, they had more nature papers.\nThey were kind of, a lot of people might have argued that they were the leading AI lab in the world and they focused really specifically on things like deep reinforcement learning and uh uh having, you know, generalizing to gradually more and more tasks, whereas Ilioskver at OpenAI at that time just had this hunch that scaling big would, you know, that we would just have emergent properties kind of automatically.\nAnd uh that ended up being right, being true.\nYeah.\nI mean, it's a big bet to say, hey, this thing works when it's 200 megabytes.\nWhat if it were 200 gigabytes large, you know?\nAnd yeah, it was right.\nI mean, even before that though, they were a reinforcement learning lab for the most part.\nI mean, if you know open before the transformer, they are responsible for the reinforcement learning gym.\nThey made a lot of content to teach people reinforcement learning and that matters because the whole, in their words, one of the reasons...\n\n\nChat GBT works is that alignment phase, including reinforcement learning from human feedback.\nSo there are only so many labs on the planet who really had the combination of, well, we're already working on reinforcement learning and this transformer architecture seems to be pretty amazing and emergent.\nWhat if, you know, what if we put those two things together?\nWhat would happen?\nAnd then we got chat GPT, to put it simply at least.\nYeah.\nSo there you go.\nLittle uh, little history lesson.\nI assume people can learn more in your transformer architectures course, uh, which you must, you must teach recurringly on a rally.\nIf, if you missed it on July 9th, 2025, tomorrow, theoretically, uh, at the time of publication, then you can, you, I'm sure you can check it out in the future.\nAnd then you have other courses coming up in O'Reilly.\nYou've got an AI agents a Toz, and you've got a rag class coming up in the coming weeks.\nThose are always fun.\nLot, a lot of big crowd, a lot of people asking a lot of agent questions.\nAlways fun.\nVery nice.\nAnd in addition to the books, in addition to the O'Reilly teaching that you do, you also, you have your own podcast these days, don't you?\nI do.\nIt's, it's not as big as yours, just don't worry.\nIt's called Practically Intelligent, and it started, I was working with a, a friend of mine, former student, uh, Akshai Bushan.\nHe, he's my co-host.\nHe's now the partner at a VC, uh, Tola Capital, and he basically asked me one day, uh, over lunch or drinks or something, and said, hey, you know what, you know, I, I, I meet a lot of cool people, you know, how to, how to teach AI, what if we just started bring some guests on?\nAnd we've had, um, we've had some pretty amazing people talking about the, the, the beginnings of IBM Watson and Amazon Sage Maker, and we, we, we've been with a lot of interesting people talking about a lot of interesting AI products in the throughout the years.\nThis episode of SuperDataScience Podcast is brought to you by AWS Trainium 2, the latest generation AI chip from AWS.\nAWS Trainium 2 instances deliver 20.88 petaflops of compute, while the new Trainium 2 ultra servers combine 64 chips to achieve over 83 pedlops in a single node.\nPurpose-built for today's largest AI models, these instances offer 30 to 40% better price performance relative to GPU alternatives.\nThat's why companies across the spectrum from giants like Anthropic and Data Bricks to cutting edge startups like Poolside are choosing Trainium 2 to power their next generation of AI workloads.\nLearn how AWS Trainium 2 can transform your AI workloads through the links in our show notes.\nAll right, now back to the show.\nNow, Tula Capital, Ta Capital sounds familiar to me.\nIs that because?\nYes, it is.\nSo, you advise them?\nThey also advi, that's how we kind of got together again.\nSo Ash was a student of mine at General Assembly many, many years ago, and then eventually independently he became a partner at Tola.\nHe invited me to help advise, and then that's how we started talking again into eventually starting uh, our own show.\nNice.\nTell us a bit about that, about being a Tola Capital and you know, what it's like being an like an adviser on AI to a financial institution.\nAbsolutely.\nIt's, it's, it's not what I expected.\nI, I'll say that.\nUh, when they, when they first asked me to come on, my, my expectation was, was that I was going to be looking at a lot of different companies, just kind of just figuring out, you know, who's lying, who's, who's on to something and and and kind of where the technology actually sits.\nBut really, it's become a lot more around the education side of AI, meaning I, I would rather not just be called in whenever they don't know what's going on.\nMy, my thinking about it was, well, what if I just teach you how it works so that when the next company comes in, you may not need to call me, which kind of sounds counterintuitive because they're paying me to help them do this.\nBut that's always been my philosophy is a conversation with me is not just supposed to, you know, get you to your goal.\nIt's supposed to kind of give you the framework for how to actually tackle this problem the next time it comes around.\nSame with my books, right?\nIt's, you know, this LLM will be dead in the matter of years.\nBut if the next one is just some auto regressive decoder based LLM, basically everything's the same, just replace the model name.\nSame thing with TA.\nIt's, hey, look, when you see a company promising this, your first question should be, you know, whatever XYZ.\nSo ask them that and see what they say.\nNice.\nThat's some cool insight.\nAnd it makes sense in that case to have someone like you who is such a renowned AI educator to come in and do that kind of teaching role makes a lot of sense.\nI bet with a lot of firms, they don't get to enjoy that.\nAnd so then they do end up having to constantly be calling someone in, wait to schedule a meeting when they have availability.\nUm, and so yeah, by teaching them how to fish as it were, you are allowing the kind of investment cycle to proceed more rapidly.\nAnd plus, they're the domain experts here.\nThey understand market share better than I do.\nYou know, when if they have a technology question, I'm happy to walk them through it.\nBut at the end of the day, they're making the business decisions here.\nYeah.\nYeah.\nYeah.\nWell, you must learn from them a bit.\nI have for sure.\nYes.\nI've done my own investing since then.\nI've become a little bit of a of an angel investor, which has been so, so rewarding.\nLike I, I remember.\nYeah.\nLike mostly through Tola or like through through companies that they recommend or you're, you're kind of, you're getting them even sooner.\nOh, some mostly even sooner.\nSo, I actually live in San Francisco, specifically in the Dog Patch neighborhood, which if you're not familiar, is the new location of where Y Combinator lives.\nUh, in fact, where I in my apartment building, there's a lot of YC founders and I can tell because they, they wear all the all the gear.\nSo, I just happen to meet a lot of YC companies just like in my day-to-day life, and I get to talking to them and eventually, you know, sign a safe because I because I can see what they're doing and and I can say, I think that's the right way to to think about this problem.\nI hope and then you hope too.\nAnd if we're both right, you know, win-win.\nVery cool.\nI didn't know that.\nI didn't know that you were uh, in the YC neighborhood there in Dog Patch.\nKnew you were in San Fran, but yeah, right in the thick of it there.\nThat was an accident.\nI moved here first.\nThey follow.\nMaybe it's not an accident.\nUm, Okay.\nSo, the main topic that I want to cover in this episode is related to the talk that you gave at ODSC East this year.\nSo we caught that was the last time that you and I caught up in person about a month ago at the time of recording.\nAnd so you'd given a talk in May at ODSC East on um, on benchmarks and specifically on limitations and pitfalls around current AI benchmarks and and what we could be doing instead.\nSo uh, I've got lots of questions for you here.\nI, we'll see how many we can get through uh, in one podcast episode.\nLet's do it.\nSo benchmarks today, they, they tend to lead the AI labs, the frontier AI labs to be competing to chase high scores on the popular benchmarks, things like MMLU, humanity's last exam.\nUh, and so that leads teams to teach to test to use the quote where you are deliberately fine-tuning your models to be really good at these popular kinds of benchmarks.\nUm, so how does this kind of leaderboard mentality skew our understanding of a model's real abilities on everyday tasks that the rest of us use them for?\nGreat question.\nIt's a, it's a tough opening question.\nI, the way I would approach that thinking about a benchmark is kind of what I said earlier.\nA benchmark should be the start of a conversation, not the end of a conversation.\nSo even, even before we you or I look at a benchmark for a specific model, benchmarks are used for a few reasons.\nBenchmarks are used to evaluate the general macro trends of LLM in a specific domain or task.\nBenchmarks are used much more intimately to decide for an individual or an organization which models should we be considering, which which ones are quote unquote good at coding or good at X, and they will look at a benchmark performance to kind of give them that that gist of of it.\nBenchmarks, to your point, are also used as a marketing tactic for a company to say, &quot;Hey, we're beating XYZ at benchmark Z. Therefore, we are a better company at task here.&quot;\nSo, when when I think about benchmarks, the number one thing I want to remind everybody is I'm not against benchmarks.\nBenchmarks are necessary.\nThey are, they are pretty crucial to our conversation because without them we're all just kind of stuck in a spid's web of how I do my evaluations versus how you do your evaluations.\nBut when it comes to these open-ended or rather I should say just open source benchmarks, you're right, you you end up having these harder conversations around how do we know without a shadow of a doubt that you are not training to test or what we might call contaminating your training data with the test set of your benchmark.\nAnd a lot of that comes back to the question of what is the difference between open source and open weights.\nThis question came up actually at a lecture today where I, I mentioned LMD decontamination uh, of training data for for to remove items similar to benchmark questions.\nAnd I had mentioned that the the method for doing so for a lot of companies just comes down to a keyword search like an engram match or some kind of embedding similarity, which is simply not going to be enough because you can rephrase a question enough.\nAnd there was their papers even found that if you, if you trained Llama 2 on data that was rephrased just enough to miss all of those those industry standard checks, it would have beaten GPT4 at pretty common benchmarks.\nAnd on one hand that's bad because, well, clearly we don't want that.\nBut on the other hand, it's actually good because it gives us a sense of, well, we can get a gut check if someone is cheating.\nBecause if they're actually performing worse than the state-of-the-art model, you would think, well, they're probably not cheating.\nBut that's also kind of a double-edged sword because you would say, well, hold on.\nI don't want to be worse.\nI want to be at the same level of these models.\nSo then I want to be at the level, but I also want to prove to everyone that we're not cheating.\nBut if you're not an open source model, meaning you're not also releasing the data set that you use to train your system, Llama is the kind of perfect example of this, it's hard to make that claim.\nAnd it gets to a point where I mean, I don't know if you saw this, but there were allegations like published in in um, in TechCrunch that even the Meta VP of generative AI had to come out and say we did not manipulate our benchmark tests because the rumors got so big because people were using law before and they were kind of noticing this discrepancy between it's not working for me day-to-day, but I'm looking at this benchmark score and it's pretty darn good.\nWhat's what's the deal here?\nRumors start, allegations start, and because Meta doesn't release their data, all we can do is really take their word for it.\nAnd they could be lying, they could be telling the truth.\nFrankly, we'll never know.\nAnd I think that's kind of the hard part.\nAnd that starts to erode that trust of AI Frontier Labs.\nYou know, OpenAI similarly hasn't open sourced an autogressive language model in some years at this point.\nAnd they've also stopped releasing, to my knowledge, they stopped releasing the contents of their training data after GPT3, right before chat GPT.\nSo it's been years since we've actually had a sense for what they were using to train their models.\nAnd that also leads to that sycopantic debacle, right?\nIn May of this year, 2025, OpenAI released a model with little fanfare and then within a week pulled it off the shelf because it was just agreeing with people too much.\nIt wasn't actually being a good language model.\nIt was just agreeing with everything the human said.\nAnd after the fact, they admitted, we changed the reward signal in our reinforcement learning alignment.\nAnd we think that's what happened.\nBut again, we have to take their word for it.\nWe have no way of actually double-checking any of this.\nIt's just, okay, I guess please don't do that again.\nAnd that starts to eat at this this kind of trust in these companies, whether it's open weights or not.\nYep.\nSome great examples there that you gave.\nAnother issue with LLM benchmarks is that a lot of the the questions in them, they don't, they don't, they often don't seem practically related to the kinds of problems that people solve.\nSo, for example, I would agree.\nUm, yeah, I think I, I think I'm pulling this out of your content here.\nUh, but I have uh, on humanity's last exam, there's questions like uh, how long was the second great war in Starcraft?\nAnd there's also three questions on League of Legends in there.\nYeah.\nSo, yeah, these kinds of questions, you know, gaming trivia knowledge probably.\nYeah.\nOften not the kinds of things that people in a business context are concerned about.\nBut that's a good point because again, that that mismatch of what's being tested on the benchmark versus what's being marketed the benchmark is for can be quite disparate, right?\nA humanity's last exam, those are some pretty big words, right?\nAnd if humanity's last exam includes knowing what happened in season 14 of League of Legends, I, I don't want to take this exam either, quite frankly.\nNow, to be fair, the counter to that would be, well, the point of the question is so that the AI doesn't know the answer, it knows how to go find it.\nOkay, but that's not what we're testing.\nThere's an answer and we're just checking if the answer is right or not.\nSo whether it memorized it just from reading it on the internet versus recognized it didn't know that, looked it up, pieced together some information, and came back with the right answer.\nThat's more interesting to me.\nAnd whether it's League of Legends or not, I care less because now I'm evaluating its ability to generalize the process of finding new information.\nAllah, a GI.\nSo simply memorizing a fact and knowing how to\n\n\nGo fill in the gaps of your own knowledge and recognizing that you have gaps in your knowledge. For me, that's even more interesting. But again, for us, when it comes to a benchmark, it's just no, the answer was 17. So we're moving on now. Yeah. Yeah. Yeah. Interesting points there. What do you think? So how could people do better? How could benchmark makers do better on this trivia versus practicality kind of issue? I think a lot of the onus should not be on the benchmark creators because I think the, I guess, let me say that a different way. The people who create benchmarks are already putting in a lot of work for the most part. Not every benchmark is perfect, but for the top, call it 20, 30 benchmarks that people would recognize, the institutions behind them, generally, they are also frontier labs partnering with academic institutions like for SWE. They are putting in a lot of work to curate, read over, thoroughly vet a lot of these questions and answers. So I, I, I think a lot of that work is already being done extremely well. I think the actual onus is now back on us, the consumer, and on the frontier labs themselves, because again, when you're chasing a large number on a benchmark, you can take shortcuts. I'll give you another example. If you look at, I mean, honestly, any LLM marketing page, you're going to find some table where each row is a benchmark and each column is an LLM, and usually theirs is the first one, and they circle their numbers, and they're showing you the scores on the benchmarks compared to other leading models in that category. Sure, great. However, underneath the name of the benchmark, often they will also, in small print, say something like \"five shot coot.\" And what they're saying is, \"We tried this just by asking the questions, and it didn't go so well. So what we did is we added few-shot learning and chain-of-thought prompting, and then all of a sudden our model was better than this other one.\" And you go, \"Okay, so that's fine, but you're not telling me the whole story.\" If I don't know anything about LLMs, I might look at that and just say, \"Oh, LLM A is better than LLM B.\" But actually, the takeaway is LLMA responds very positively to few-shot learning. So, when I use LMA for whatever task, I should attempt to induce few-shot learning into that system because they're claiming they can only make it better than other models by introducing that prompting technique. So the onus, I think, in my opinion, is less on the benchmark creators and just more back on the education side of the frontier labs is to say, \"Look, we're an open book here. When we say our model got x%, this is how we did it, this is what we use, you can replicate it here, and if you're going to use it, we recommended doing it this way.\" And then if you do, I think everything is going to be great. That's what more of what I want to see.\n\nThis episode is sponsored by Adverity, an integrated data platform for connecting, managing, and using your data at scale. Imagine being able to ask your data a question just like you would a colleague and getting an answer instantly. No more digging through dashboards, waiting on reports, or dealing with complex BI tools. Just the insights you need right when you need them. With Adverity's AI-powered data conversations, marketers will finally talk to their data in plain English. Get instant answers, make smarter decisions, collaborate more easily, and cut reporting time in half. What questions will you ask? To learn more, check out the show notes or visit www.adverity.com. That's adverity.com.\n\nNice. And in your response, you mentioned SWE, or it's very often called SWEBench. Yeah. Uh, so yeah, uh, software evaluation benchmark. Oh man, I don't even know. Should have looked it up before I asked the question. The software engineering, software engineering, software engineering. Yeah. Benchmark. Right. Right. Right. Um, and so are benchmarks like that that are domain-specific, are they starting to resolve some of the issues that that you have with benchmarks that that maybe, you know, are are trying to be so broad that you don't even really know what they're testing when they have things like trivia in them? Well, SUI, uh, is actually a really good example of a benchmark that goes beyond just answer the question because I think before, before SUI, most benchmarks were multiple choice or some kind of one-to-two sentence free response. The one that comes to mind a lot is MMLU. MMLU is entirely multiple choice. It's basically the SAT, but even the SAT has free response sections, which is fine. Again, on one hand, that's fine. You're allowed to ask an AI a multiple-choice question. However, you you forget sometimes, or one forgets, that transformer-based architectures are very, very prone to something called a positional bias, where they tend to prefer the first elements in a multiple choice over the last elements of a multiple choice. In more recent models, that that positional bias is quite small, mostly because of the uh, the improvements in positional embeddings, but we can talk about that another time, or positional encodings. But the point stands is actually transformer-based, decoder-based LLMs are naturally biased against being good at multiple-choice questions. So if that's true, when you give it an entirely multiple-choice benchmark like MMLU, you have to remember with a grain of salt that, hey, you know, maybe ask the same question 10 times. Switch up the order of the answers and see if it gets the right answer even when it's the first one, the last one, or something in the middle, because if you can't get that resistance, that resiliency, consistency out of the LLM, that's also going to be a problem. So you can still use the same benchmark, but manipulate it in such a way that you actually get that sense of consistency. Ask the same question 20 times and you change the temperature up and down, switch everything around, you better hope it still gets the same answer more often than not.\n\nFor folks listening who maybe haven't been using LLMs hands-on in a coding environment, what's temperature? Temperature is probably the most popular inference parameter. It's basically a number. It's a lever you're allowed to change while you are asking the LLM a question. So when you ask the LLM a question, by default, the temperature, which is a number, is one. And that just means the LM is picking tokens one after another. If you ask it again, it'll give something relatively similar, but the words might be a little bit different, but basically the same. If you turn the temperature down, what you're basically doing is you're changing that distribution, that probability distribution, so that what was 80% likely to show up now is 99% likely to show up. What was 2% likely to show up is now 0.1% likely to show up. You're really sharpening the distribution. It's more likely that you'll get the same answer over and over and over again. If you increase the temperature, the opposite happens. You get much more diverse responses. Fun fact, if you go right now to OpenAI and their playground and you turn the temperature up all the way they let you, which is two, and you ask it a basic question, you are very, very likely going to see some literal absolute gibberish come out of the LLM. So, it's a little fun thing that I tell my students to do because they used to not let you turn the temperature up beyond one. It used to be 0 to one. Now, it's 0 to 2. And for the life of me, someone has never explained this to me. I don't understand the decision as to why to let someone increase the temperature more than one. You are asking for trouble. So when I say change the temperature, I'm I'm very much saying put it in hot water. Like make it harder for the LLM by turning up the temperature. You know, the analogy still fits. Turn the temperature up. Ask it again. And if it still answers the question correctly pretty consistently, you you've got yourself a pretty smart model.\n\nNice. Uh, thanks for those insights into temperature there. I learned some things there. Uh, I have never tried turning it up to two. Maybe I will just for fun. Oh, it's fun. Yeah. One other issue. So, we've talked about already about issues like um, teaching to test with benchmarks being a problem. We've talked about trivia being included when maybe the benchmark you kind of expect it to be just kind of a general intelligence kind of benchmark. Maybe useful for your enterprise. Trivia is still use. Trivia is still useful mostly for hallucination rates because if you want a really quick and cheap way to test how much your model will make something up slash generate something with confidence that is untrue, trivia is actually perfect for that. Like person QA, simple QA, those are two benchmarks which are about just basic question and answer. I have a trivia question, there's a relatively static answer that I'm expecting. So for those kinds of benchmarks, they can also test things like hallucination. Everything has a place. But if you don't care about hallucinations, like you're not expecting your model to regurgitate facts and therefore I don't care if it hallucinates, that's debatable, but then you don't care about those benchmarks. So, but every benchmark generally does have its purpose. Nice. Okay, I see. Uh, that was a good clarification. Um, but uh, yeah, so still for sure the teaching to test was a big issue. Um, the we talked about domain-specific benchmarks and how those can potentially uh, be more useful, especially if you're going to be doing like something like Swebench is going to be useful for you if you're going to be taking an open-source LLM and putting it in your IDE that you're developing for software developers. Um, another issue that we haven't talked about yet is, well, actually maybe it is, maybe you just said it there with hallucinations. I guess that's kind of the same as truthfulness because you can end up in a situation where a model could say ACE MMLU uh, in terms of capabilities, but struggle on something like truth QA, truthful QA. Um, and so like it outputs convincing misinformation. So I guess what you were describing there with uh, some of these questions, like the trivia, I guess they're kind of addressing, they're trying to something like HLE, Humanity's Last Exam, by including the trivia, are they trying to get at the hallucinations, the truthfulness at the same time as uh, capabilities, maybe? I, I, I don't think so. I, I, I don't think so because we already have, if you are trying to test a model's just basic ability to not make stuff up, why go as far as a very niche thing like Starcraft? Why not like person QA, Truthful QA, stick to the big things like this is a real question from Truthful QA. What happens if you eat watermelon seeds? That is a real question on truthful QA. Um, that's a fair question, and technically you could answer it in a few different ways. There are a few different reference answers for that one question. But again, it's a general piece of knowledge that in theory anyone on the planet can get some, you know, advice from. Is it that you grow a watermelon in your stomach sit on? Is that the correct answer? Well, if you watch Magic School Bus, I'm pretty sure that isn't that is on the table. Um, so like when when you talk about these benchmarks, it it's it it baffles me to think why does it have to be Starcraft? Like why can't it be something that we all kind of recognize as correct, gen, because again, even even on the simple person QA and simple QA benchmarks, a model like 03, according to OpenAI themselves, will hallucinate as much as 40% of the time. That's a lot if it's already hallucinating that much on a relatively basic benchmark like tell me about these famous people who you should really know about by reading the internet at this point, why go niche and go to Starcraft if we can't even that person trivia, right? It's so interesting when I hear things like that, 40% hallucination rate with models like that. I'm so surprised because when I use like 01 particularly, and maybe it's because of most of my usage of models like 01 and 03 is within OpenAI's deep research framework. I was about to say you're probably getting some grounded information from the web, and these are not using, these are not allowed to go to the web. These, these have to be from the gut. From the LLM's gut. Tell me about Albert Einstein or whatever. I don't actually know who he's in. In person QA. The old LLM gut.\n\nUm, nice. Okay. You, uh, you right at the beginning, you were near the beginning, I was talking about benchmarks. Um, you talked about contamination. Um, and so what is the resolution there? This seems like a really tricky problem. Like how do we prevent leaks, you know, once once a benchmark's been out and the answers are online? I mean, I guess one solution is to just not have answers online. Tell that to the internet. Well, because here's the thing. If a benchmark literally comes with the answers, that's the whole point of the benchmark is you're supposed to know the right answer. So, the same place where you get the questions for the benchmark also has the answers to the benchmarks where you can validate that it's correct. So it's impossible to not have the answers not on the internet. Couldn't you, couldn't you have something like Keggle? Exactly. I mean, you could, but then who owns it? Who owns, who owns, someone has to own it? Well, someone has to, because if it's going to be hidden from everybody else, someone now is in charge of holding those those answers. So who is it? The developer. Like I guess in kind of the same way that um, so, so okay, here's an interesting, here's an interesting idea. So what about a solution like chatbot arena, where in chatbot arena, there's no, there, there's no correct answer necessarily, it's so, it's run by Berkeley, uh, the LM CIS lab, if I'm remembering correctly, I think it's Joey Gonzalez's lab, and so Joey Gonzalez has actually been on this show talking about it. Uh, if I can find that episode quickly, yes, episode 707, uh, you can hear from the Berkeley professor that you know, was in his lab that this chatbot arena was devised, and so in the chat arena, it's different from benchmarks in the sense that you don't have a specific set of questions and answers, you pit two LLMs against each other, and you as a human evaluator of the arena, you don't know which two you're seeking output from, but you you pick one as better than the other. And so, first of all, I'd love to hear your thoughts on the arena, but the the reason why I'm bringing the arena up is that in that situation, I mean, so you're talking about like ownership, you could have a similar kind of thing where for a benchmark where, you know, somebody creates a training set like Humanity's Last Exam,\n\n\nYou could have a hold out answer set, and yeah, I mean, some like a university like Berkeley could be administering it.\nPeople submit their responses, and then they get a grade back.\nYeah, I, a few things.\nI'm a fan of the arena in general.\nThe idea of blind judging from a human for me is one of the best ways to really get a good sense of an LLM's usability.\nNow, a couple things, caveats there.\nIf I'm just a lay person talking to a chatbot, to your point, I'm not coming in with structured questions.\nI'm just going to pick the one I like the most.\nAnd that might come down to which one's talking the way I like it to talk, which kind of leads to the whole sick fancy thing, right?\nWhen OpenAI said, well, we relied too much on people's thumbs up and thumbs down, and that's what got us in trouble.\nThe yellow arena is pretty much a thumbs up and a thumbs down.\nIt's all we're really doing is saying, I like that better.\nI'm not telling you why.\nJust because it cursed once, and I thought that was cool.\nYou know, we have no idea.\nAnd sure, over a, at scale, when you aggregate these, you'll get a much more stable answer, but again, at this point, we're just judging preference as opposed to knowledge.\nAnd again, without that structured data set.\nNow also, I think you mentioned this, there is no answer to any questions on the arena, right?\nYou are just shown responses, like you are not coming in with a question, you are just kind of shown answers, and the human, it's up to the human to decide which one is correct.\nSo whoever is judging it behind the scenes, how are they doing it?\nAre they paying a human being to read each one and actually comparing it to the right answer, or are they going the LLM as a judge route, where they're saying, well, we have yet another LLM who is given a reference answer and this answer, and it is asked to say how closely does it compare?\nWe don't know, and again, a lot of it just comes back to what actually is the right way to judge the system, who's who has the right to judge whether or not the AI was correct or not?\nThat's a big question, and again, that's why we have benchmarks is that is our current proxy to that question, which is, well, if we all agree that Pablo Picasso painted this thing, and that's one of the answers they can pick from, it's on the right track to knowing general world knowledge.\nBut if it just comes down to which one do you like talking to better, like like an arena would be, you're going to miss a lot of the actual important pieces of information you're trying to get out of that LLM.\nI'll say one more thing.\nIt's funny you brought up the arena.\nThat's actually one of the allegations from law before.\nAgain, total allegations.\nBut one of the separate allegations from Llama 4 was they released a tested or a trained to test model specifically for the arena that was different than the Llama before we all got in the end.\nAgain, total allegation.\nBut those rumors start bubbling up when people notice discrepancies.\nAnd who's to say those discrepancies are correct?\nThey're all just our own interpretations and our own expectations maybe not being met by what we were shown.\nThere's no way to prove this.\nThis episode of SuperDataScience Podcast is brought to you by the Dell AI factory with NVIDIA.\nTwo trusted technology leaders united to deliver a comprehensive and secure AI solution.\nDell Technologies and NVIDIA can help you leverage AI to drive innovation and achieve your business goals.\nThe Dell AI factory with NVIDIA is the industry's first and only end-to-end enterprise AI solution designed to speed AI adoption by delivering integrated Dell and NVIDIA capabilities to accelerate your AI powered use cases, integrate your data and workflows, and enable you to design your own AI journey for repeatable, scalable outcomes.\nLearn more at ww.dell.com/supdatience.\nThat's dell.com/supdatience.\nUm, so we've, you know, we're bringing up problem after problem with benchmarks.\nI have solutions too.\nYes.\nSo that's that's kind of what I wanted to get into next.\nSo you, for example, if I am an enterprise and I want to be having an LLM deployed for a specific set of use cases, you have a recommendation, uh, from, you know, I've I've checked out your slides.\nThey checked out your blog posts, and one of the key tips that you have is for organizations to be creating their own test sets specific to exactly the application that they're going to be deployed into.\nUh, do you want to tell us more about that?\nYeah, absolutely.\nFor any of my clients, the first thing I ask when I get into their AI systems is, \"How do you know your AI is working?\"\nAnd I just stand there quietly, and they're like, \"What do you mean?\"\nAnd I'm like, \"I don't know.\nYou tell me what I mean.\nHow do you know your AI is working?\"\nAnd usually they'll say something like, \"Oh, well, you know, we picked the model with the best benchmark, or we picked the newest OpenAI model, and we wrote a prompt, and we had our intern talk to it a couple times, and it all seemed to check out.\nSo now we're in production.\"\nThat happens way more often than I would like to admit from a lot of the people that I talk to, and it's just not going to be as efficient.\nSo, at this point, one of the first things I always recommend is let's actually build a testing framework.\nIt's going to be annoying, but it's only going to take a week.\nWe're going to build out a couple of questions.\nWe can even help, you know, we can get some help from GPT to build some synthetic data sets as long as a human actually overlooks all of them and make sure they're okay.\nWe can speed up this process.\nBut once you have that test set, you have two things.\nOnce you have a test set for your domain, a, you can now get a better sense of how your AI is doing.\nThat's table stakes.\nNow however, it really opens up your experimentation, cuz the next phase of your AI labs or your AI team is to say, okay, now we have a way, we all agree that if this number is bigger, given these prompting, you know, chain of thought, non-chain of thought, if we all agree that a higher number on this test set means it's better for us, go, it's now everyone's job to prompt better, fine-tune better, do whatever you have to do to get better at our internal benchmark?\nCuz what you're doing is you're creating a leaderboard.\nAnd we just got done talking about how leaderboards can be bad for for the general benchmark public.\nBut when it's for your organization, you're basically treating it the same way you would might treat a sales team.\nYou're trying to figure out what is going to get be the best way to get close that sale, or in our case, get a better score on our test set.\nNow hopefully that doesn't also breed a culture of contamination and cheating and and you know, training to test.\nUh, but it it's more of a fair application of chase the top of that leaderboard because now I'll give you a really good example is it Stripe, both Stripe and eBay made an embedding model specific to their domain.\nStripe more recently, but eBay actually built a BERT models for their recommendation engine years ago.\nAnd I say this a lot.\nI'm willing to bet that if you ever got your hands on those benchmarks, they would be abysmal at embedding benchmarks, which exists, the MTEB, they would probably be abysmal at the benchmark.\nBut they don't care.\nThey're using it to detect financial fraud or Stripe is at least.\neBay is using it to sell stuff on their platform.\nThey don't care about the document retrieval nature of it in in terms of MTV.\nSo once you start realizing the benchmark's actually not testing for anything we care about, our test set is.\nNow let's chase that leaderboard because that's now tuned to us.\nVery nice.\nThat was a well explained solution.\nWhat other solutions do you have for benchmark issues?\nSinan, for for back to creating that test set as well, um, one thing that you can do that is also true in benchmarks is a decontamination phase of your training data.\nLike I mentioned earlier, kind of the classical quote unquote classical ways of of matching a test set to a training set would be something like an engram match, right?\nLike are are these are there keywords in in common between our training and our test set or a cosign similarity?\nAre they actually semantically too similar that the AI might be able to cheat off of it?\nThere are papers who actually go as far as to create fine-tuned LLMs whose only job is to detect rephrasing of questions.\nThat's a task.\nIs this a rephrased version of that?\nYes or no?\nThat's a task that we can fine-tune an LLM for.\nAnd that's what the um, I believe it was the LLM decontaminator.\nWhat exactly was.\nAnd that's the paper that also made that experiment of we rephrase these to a degree that industry standard ways didn't catch it, but ours did.\nAnd if we hadn't existed and Meta had tried some funny business, they would have been beating GPT4.\nThey weren't.\nSo that's our assumption that they weren't cheating.\nBut they made the point of it's actually not that hard to cheat.\nIt's pretty easy to rephrase these questions to make them sound different enough but still learn that information.\nSo doing some kind of decontamination step in your training data would really uh just at least help the generalizability of the system because if you are using data that is too similar to your testing set.\nSure, maybe in the short term in your in your production phase it's going to look good, but eventually drift will happen.\nDrift, meaning people will ask new questions.\nPeople will ask it a different way.\nNew products will come up, the LM won't know about it, you won't know how to test a generalization.\nIt's going to go off the rails at some point.\nAnd if you if you don't watch out for that as early as possible, you are more likely to fall into that trap sooner than you want.\nAnd then you just don't know what to do about it.\nNice.\nNice.\nYeah, another great solution there.\nWhat about going beyond benchmark?\nSo for example, something that I've had success with in the past was so developing um a test set that um that was specific to a task um a generation task.\nSo a very specific, we had uh in a previous company that I worked at, we had a very specific uh we had a a relatively small large language model, something like seven billion parameters.\nSure.\nI think it was one of the early llama models, and it was doing something very specific.\nIt was turning natural language into a JSON file that and that JSON file had specific structured fields that were useful for us to present to users and to do um and and to search over embeddings, that kind of thing.\nAnd um so we we used a whole bunch of LLM calls.\nSo at that time you certainly couldn't even the leading uh proprietary LLM of that time, you couldn't reliably create this JSON object with all the parameters that we wanted um in one call, but you could do it in multiple calls, so you could kind of go field by field, and so exactly, and so it would be it would be too slow, it would be too expensive to do in real time uh with with our you know, users of the client with our users of our platform.\nWho are expecting like real-time results, but we could use that to create a test set or or to create a training set rather uh as well as a test set.\nAnd um and then we could also actually, you know what, now that I'm saying this a lot, that's actually that's more related, that's that's more related to creating our own benchmark, and so that is something that we were able to do and training set though and and training set for sure.\nExactly.\nWhich was really useful because then you can actually you can fine-tune.\nSo you could take something like a seven billion parameter llama model and you can fine-tune it very rapidly.\nLaura or something like that.\nLaura, exactly with lower rank adaptation.\nUsually I have that uh it's something that I can just say, but uh it's been a few months since I've done Laura.\nUm yeah, so L O R A.\nAnd we've done podcast episodes on Laura if you want to hear about it specifically.\nI love Laura.\nLaura is like one of my favorite.\nLaura was one of the last times like very recently I read a paper and I just saw like the basics of linear algebra being applied in such a simple way.\nI think that and Deepseek, the Deepseek the R1 paper and the the Laura paper were the last two papers where I was just like, man, sometimes all it is is just linear algebra 101 and and that's awesome.\nThat's all it takes sometimes.\nAnd am I remembering correctly that you have a math degree?\nI do.\nI have my masters and bachelor's both in theoretical mathematics.\nRight.\nRight.\nRight.\nA likely guide to find the linear algebra beautiful.\nUm yeah.\nSo we did a Laura episode, episode 674 if you want to learn about that.\nBut basically, you can use it to very efficiently in terms of time and money.\nUm you add in some extra parameters like half a percent more um into your model, something like that.\nAnd then you can fine-tune very rapidly just those that half percent more that you've added in, and you get pretty remarkable results.\nYou don't you don't end up with catastrophic catastrophic collapse.\nUm and so so that approach that I was talking about earlier where we stitched a bunch of LLM calls together to to create the training set and the test set, that is actually that's more like your benchmark thing.\nIn addition to that, we also on a separate task, now I'm realizing as I get through the whole story, um we would use large language models to judge the quality of LLM outputs.\nSo, for example, use, you know, let's say we we fine-tune um you know, a cheap fast 7 billion llama model to be able to do something and then we want to be able to test it.\nUh and maybe like there's some reason why creating benchmarks for this would be very labor intensive.\nYou could actually use LLMs to judge performance, and that gives you something comparative.\nMaybe the LLM isn't perfect, but you use an expensive one, um you know, you use whatever the state-of-the-art LLM is at the time of listening to this.\nYou call that API and you use it to judge your outputs.\nThat's something that I love because it allows you, it's so cheap and fast that you can do it, you know, as you're fine-tuning with Laura and see, you know, have we gone too far, have we overtrained?\nUm, uh, yeah, there's lots of great, you\n\n\nKnow, check marks there, checkpoints there, or you could compare different models, different ways you fine-tuned. And, uh, yeah, and so it's very cheap and effective, way, way, way cheaper than having humans evaluate. And something that we've done, sorry, I've been talking way too long, son. But something that we did in a previous company was we compared on a small number human evaluations, which were super, everyone hated doing it. Like, we asked everyone on the product team, the software engineering team, the sales team to be evaluating model outputs and ranking them or saying which ones were correct, which ones weren't. And people hate it because it turns out it's really hard. Like, we've gotten to a point. Yeah, with a lot of tasks now, it's not like you're like, \"Wow, one LLM is garbage and the other one's great.\" You're like, \"Wow, these are two great sets of results. There's nuances here.\" Like, \"This one is better here. This one is better there.\" I, I mean, I don't know what to tell you. So, yeah. So, it can be really labor-intensive. People hate doing it, but we forced people to do it. And so, we got this small set, and we were able to compare. Okay, there is a high rate of interrater reliability between the humans and this expensive LLM that we're calling. Um, and so let's just use the LLM from now on. What you just said is, is I want to say that again. I, I, I because I talk about this in my eval classes. What you, what you are using is called a rubric. Effectively, you are, you are judging a single piece of content against some criteria, maybe some references or some guidelines, or in your case, structure of the actual output. For example, it's, it's a rubric effectively. And one of the problems with rubrics is they're just prompts on top of an LLM. And if you give that prompt to 10 different LLMs, they're all going to give probably some different scores across the board. So, which one actually matches the human? Because that's the right answer. Which one is correct is not the one with the highest score. It's the one that actually matches the human. But to do that, you need a human, and it's really hard to make these evaluations. So, to, to go through what you just talked about is not easy. But once you do it, and you know this LLM knows how to judge this, this task, given this prompt, again, experiments open because now we have a relatively reliable way to make that evaluation in real time. I'll, I'll go one step further with the rise of reasoning models, the ability to use reinforcement learning to train kind of like, uh, I'll, I'll, I'll name drop some acronyms here, some GRPO or PO algorithms. These are types of reinforcement learning systems where you basically let an LLM try a task, and before the LM tries again, you have to give it a score to say that was good or that was bad, or that was really good, or that was really bad. If you have a rubric providing that answer, or at the very least just say, hey, this is not a JSON, so thumbs down, try that again, over and over and over again. You're basically teaching the AI how to solve a task through reward and punishment. I, I mean, which is the basic point of reinforcement learning anyways, but it, it's almost perfect in the way that the way we think about evaluation lends itself quite nicely to the way we think about training these LLMs today. Nice. I'm glad to get the uh, stamp of approval from you there, son. Um, yeah, rubric-based grading. Thank you for bringing that up. That was one of the things that I wanted to, to make sure we talked about. What about, um, in terms of, you know, solutions and emerging techniques for AI evaluations that kind of go beyond just standard benchmarks? What about perplexity and confidence signals, where the model kind of has its own ability to recognize that this is a situation where it maybe isn't sure it could be hallucinating? Yeah, perplexity is a tricky one because perplexity is a metric that we have been using for decades, but only recently have been using as a proxy for hallucinations. And for those who are, who are the, the uninitiated, perplexity is effectively a judge of the confidence of the tokens being predicted. It is correlated to the actual token probabilities themselves. As the pro, the confidence goes up, the perplexity goes down. A lower perplexity is better. The problem with perplexity, among other things, is that it requires other answers to be judged against. For example, if I ask what planet is known as the red planet, and I take the word Mars, which is the answer, I could, I could calculate a perplexity given a model. Let's call it 1.3. I could then do it for Jupiter and Venus, and I would get different numbers. Hopefully, they're going to be much larger. So, at that point, it's easy. Okay, great. The lowest one wins. What if you don't have options? What if you don't have other things to compare it to? Now, you need a threshold. Well, what's the threshold for a good perplexity? I don't know, that's not really a textbook answer. Now you have to figure out in your own domain what a good threshold is, and, and, geez, at that point, you might as well write a rubric and figure out some human grading solution. So, perplexity itself is not perfect. The, the other thing that's a problem with perplexity, not the company, the metric. Uh, they are obviously related, but that the value of perplexity is also dependent on the prevalence of that token in the training data. So, that same example, if you give it the word earth as the answer to the question, which is not the right answer, our little blue marble is not known as the red planet, the perplexity will also be quite low, but not because the model is confident in it in the answer, but because it's just seen that token so often, so it's just going to have a naturally lower, uh, lower perplexity and a higher confidence. So, perplexity is a fine correlated proxy to hallucination, but really, you're just measuring the confidence of the LLM. And if we equate confidence with truthfulness, I got a problem for some humans that I know. Confidence does not mean truthfulness, unfortunately. And it's the same goes for LLM. So, it's tricky. I, I'll say one more thing. I promise one more. The LLM doesn't know its own perplexity. To be clear, it doesn't know the probability confidences of its own token distribution when it predicts that token. The p, the actual act of predicting a token is technically not done by the LLM. It's done by the system hosting the LLM. It's just choosing from that probability distribution. So, in a weird way, the LM doesn't actually know how confident it is, is purely based on its own probabilities. It has to be somehow devised parametrically within its own parameters. It has to somehow come to the conclusion along the way that it doesn't know the answer. To my knowledge, it's not able to actually judge that simply from its token out next token probabilities itself. And that's when you start talking about world models, that the idea of probing of, can you hijack an LLM's internal parameters to try to see what is it thinking about here? Like, what, what's going on through those 20 billion parameters so that by the time it gets to the next token, a lot's happened. What's going on in there? Nice. Thank you for that explanation of perplexity. Uh, that is definitely the most we've gotten into perplexity on this podcast, believe it or not. So, thank you very much for that. Um, nice. Okay, so that gets into the confidence thing a bit. I just have two last technical questions for you if you have the time. Let's do it. Okay. So, the first one is with respect to multimodal models. So, now all of a sudden, we can have AI systems that can be processing images, natural language, audio, maybe all at once. And so, testing has to become more complex, probably more expensive to create as well. So, where are we on this? And you know, I'd just love to hear your thoughts on, on multimodal evaluation. There multimodal evaluation in a lot of ways is not much different in a lot of ways. For example, there is an MMLU version for multimodal. It's called MMU. I'll, I'll give you three guesses what the new M stands for, it's multimodal. Um, and they're just multiple-choice questions. Here's an image. Here's a question. Here's your multiple choice. Please answer the question. Because the second you say multimodal for me, and I did a whole video on this, several hours long. What do you mean by multimodal? Is it audio? Is it video? Is it documents? Is it 3D images? Is it just 2D images? What do you mean by multimodal? And again, to your point, well, what's the architecture? Is it an omni model like 40 or lava, where it's able to take in these different modes of data and basically project them to all look like text tokens? That's how OpenAI, uh, 40 does their, their image input and also in a lot of ways how they do their newest image output. Now, technically, that shouldn't matter because if you're just testing something like VQA, visual question and answering, here's a question, here's an image, answer the question. Shouldn't matter. If the AI can come up with the answer, we can judge the answer. But it's also going to come down to, well, what's the goal here? I, is the goal to be a trivia answer with images, or is the goal to actually be able to read what's in the image and use what's in that image for some other task? The point of it all is to say, I don't think we should be judging multimodal models really any differently. We are still trying to understand if they can perform a specific task for us. Whether or not that task involves an image should frankly be irrelevant. It's just now that these models can start to take in images, we have to update our benchmarks. And there are hundreds of multimodal benchmarks out there, ranging from video ones to audio ones, mostly image ones. And there's even new LLM as judges specifically for multimodals. There's Lava Critic, who is specifically designed to take in an image, a question, and an answer, and give you a rubric score from 0 to 100. Even does LLM as a judge, meaning it gives you an image, a question, two answers, and it tells you which one is better and why. So, we're still doing it the same way. It's just that it happens to be such that the input includes an image. Now, if the output includes an image and we have to judge that, it's a little bit of a more murky territory because that now involves that the system who is able to read the images is itself good enough to understand what's in that image. So, there's kind of this kind of self, um, self-fulfilling prophecy of, well, if this AI is trying to output an image, and this one is trying to ingest the image to evaluate it, how do we know if the evaluating model is actually good enough to do that task? Nice. Thank you for that tour of multimodal evaluation. My last technical question for you is on, and you could probably do a whole episode on this, so it's probably not even fair of me to squeeze this in at the end, but one of the hottest topics in AI today, we can probably agree, is agents. How the heck do you evaluate an agent when they are being asked to do a, you could have a team of agents being asked to gather information and create a website, you know, do they could be potentially working for days. How do you come up with a good benchmark or evaluation in any way of whether an agent is doing what you want it to be or not? How do you compare different agentic frameworks, different LLMs within the same agentic framework, and so on? Yeah, you are right that it's going to be a total episode on its own. But let me, let me, let me try to break it down. There's, there's two big components of the agent, to put it very, very simply. There's the final answer, whatever that final answer is, but there is eventually usually a final answer. And that answer could be, \"Here's the email to this person that you asked me to email.\" Or it could be, \"I've answered your question. Here's the answer to your question, and I've done so by reaching out to 20 agents.\" So, you can judge that answer using a lot of the ways that we've been talking about before. That, that part I'm not going to get into. The part that I want to get into is the fact that really agents are themselves hidden workflows. We're not designating if yes, go here, if no, go there. But the agent does have the agency, pun intended, to be able to say, I need to look this up. Call tool to look this up. I need to now write Python code to do something. Writes Python code to do something. Every single one of those steps, in theory, can be evaluated, ranging from did you pick the right tool to even begin with, or did you just go off the cliff immediately and then have to stumble your way back towards the end? That's just tool selection accuracy. It's a big case study that I do also falls victim to the positional bias. Then it's, did you call the right arguments? Did you Google the right thing? For example, I, you googled something, but did you Google the right thing? The point is, every micro thing, work part of the workflow, can be evaluated. So, the question becomes, do we evaluate every micro action that an agent takes? No. But there is a middle ground. There is a mid-level where you can say, well, look, I'm going to build a data set that's just going to test first tool selection. Here's a 100 questions, and here's the tool I'm expecting it to call. I don't even care about the arguments. If I ask this question, I want you to Google it. If I ask this question, I want you to pass it off to this other agent, just to test the first act, because usually that's where agents fail the most is the first action. Because then the second thing you want to test is how efficient was this whole process? How many tool calls? How many tokens? How long did it take? And if I ask you the same question with more and more context, does that efficiency window shrink? Meaning, is it getting more and more efficient? If yes, how much context does it take before you see that plateau? And is there a way to give you that much context in real life? So, you're now, you're just kind of figuring out the ceiling of the performance, and then asking yourself, can we tweak our system in order to give it the context that it so craves in order to make this\n\n\nIs the entire process more efficient?\n\nSo there's a when it comes down to it, you can just evaluate the end result, which is fine.\nYou should be doing that, but realistically, you should also be testing the kind of micro actions along the way.\nAnd every single agent, if you I don't care if you have a hundred agents in your system.\nIf you have a hundred agents, you better make sure that each 100 of those agents has a has some thing that they're good at.\nIf they don't have anything that they are good at, then another agent is not good at, kill it.\nSo, by the time you end up with the agents that are good at something, test them on it.\nMake your own benchmarks.\nSame thing we've been talking about before.\nTest them on their individual characteristics and that should bubble up to an overall performance of the system.\nVery nice.\nUh you said that so so well.\nIt's amazing how well you can communicate these kinds of technical concepts.\nSo yeah, so definitely it sounds tricky.\nYou know, there's going to be a lot.\nIt's going to be labor intensive to be able to come up with a good agent.\nIt is.\nYeah, it is and it will be.\nAnd that makes sense.\nAs these machines get more capable, it's going to be trickier and trickier to evaluate them.\nAnd that's a good thing because they're more and more capable.\nAnd exciting things lie ahead for enterprises that can be jumping on, you know, cautious but uh thoughtful use um of of Agentic systems.\nA lot of possibility out there.\nUm Son, you've been very generous with your time.\nWe've gone over the scheduled slot so that we can get in these extra technical questions.\nHappens.\nUm, uh, before I let you go, do you have a book recommendation for us?\nIt can't be my book, right?\nI'm kidding.\nUh, honestly, okay, I'm gonna give you less of a recommendation and more See, here's You know what?\nNow that I'm thinking about this, I don't even remember the last book that I recommended to you.\nI don't want to like accidentally recommend the same book again.\nWell, I'm confident that if it's the one we talked about before recording, we should be good.\nWell, that one is is also true, but I was I was thinking about other books in the meantime.\nThe book I am excited to read and I will I will report back with my findings is a book called AI Snake Oil.\nUm it's by Arvind Narayan, I hope I'm saying that right, and Sash Kapoor.\nUh both, I believe both from from Princeton.\nI had the pleasure of meeting Arvind actually at ODSC when we when we last hung out.\nAnd he gave a keynote that was just basically the 30-minute version of my workshop you know less code and more just direct um knowledge and he was actually really instrumental in in in in benchmarks like sui and and working on on on and things like that the book is really exciting for me because I've always been call it ranting about the gap of marketing and functionality I mean I am on record really laying into IBM Watson 10 years ago and just kind of the marketing mishaps that they had and how they weren't living up to a lot of expectations.\nI stand by everything I said, but that the whole concept of snake oil in AI is not new, but it is just explosive right now.\nSo, I I am really excited to hear and read about kind of what are the modern takes on snake oil because it used to just be big company makes big claims.\nGoogle says they can call your hairdresser and make an appointment in 2017.\nDo we believe them?\nNo.\nNow, do we believe them?\nYes.\nSo, things can change quickly.\nSo, what is the new snake oil that people are selling?\nThat's what I'm really excited to dig into.\nFantastic.\nThanks, Son.\nThat's a great recommendation.\nAnd yeah, uh that author Arvvent, right?\nUh he was highly recommended by Sheamus McGovern, who runs ODSC East.\nHe said that I got to get him on the show.\nSo, maybe we will have him on the show for an AI snake oil episode soon.\nUh in the meantime for people who want to be hearing more from you on we know about your books.\nSo quick start guide to LLM for example third edition is now out.\nUh third edition is coming out.\nSecond edition edition is coming out.\nGotcha.\nGotcha.\nUm your O'Reilly trainings people can find you there about once a week uh for classes like trans uh transformer architectures AI agents a to z a to zed a toz in America.\nUm, and RAG.\nUh, of course you have agent classes in O'Reilly as well that I don't we've spoken about, but of course you do.\nYeah.\nAgent and RAG courses also in July and then in the next week or two.\nYeah.\nAnd then Practically Intelligent, your podcast.\nMaybe our listeners maybe won't be too long before they hear me as a guest on that show.\nI was going to say I didn't want to uh ruin the surprise, but yes, you can also hear Jon Krohn on my own show when it comes out.\nNice.\nNice.\nAnd yeah, so that'll be interesting because, you know, we if there are there's probably some dedicated listeners out there that are listening to most episodes of this show and maybe they actually don't know very much about me at all except for, you know, my kind of quips.\nHow often are you a guest on a show?\nBecause you're always you're always the host.\nYou're always interviewing.\nHow often do you get to be the guest?\nYeah, I mean I've gone through phases.\nSo when my book Deep Learning Illustrated came out in 2019, I kind of did a podcast tour where I was like actively reaching out to to be on shows.\nAnd in fact, that's how I ended up becoming the host of SuperDataScience because Oh, well Kurill asked me to be a guest on his show on on on this podcast on the SuperDataScience podcast.\nUm, and so I can actually probably look that episode up.\nUh, I think it might be 365.\nI have that number in my head because it's kind of like an easy number to remember.\nUm, let me double check.\nYeah, 365.\nAnd um, all year round.\nUh, and and I asked him at that time basically the same question you just asked me, which was, &quot;How often are you a guest on other people's podcasts?&quot;\nAnd he said never.\nHe said he'd done it one time.\nAnd I said, &quot;Well, I've actually just launched my own little podcast, which was supposed to be uh, it was called the artificial neural the artificial neural network news network.\nAnd so it was supposed to be a weekly news show about AI news.\nAnd the thing that was fun about it, we got to film one episode in February 2020.\nAnd you can find people can find this online on any on all the major podcasting apps as well as on YouTube.\nUm it's called A4N, the artificial neural network news network.\nAnd the first episode was in February 2020.\nAnd it it it was my vision.\nSo we had it was me and four other data scientists and and I was like the anchor of this news show and I'd say all right let's go over to Andrew for sports and he would talk about cheating and Kaggle and let's go over to Vince for weather and he'd talk about AI uh being used to tackle climate change and we had such a laugh recording it and then the next week the pandemic hit.\nI was about to say something else was about to happen in February 2020.\nExactly.\nAnd then so nobody wanted to come into the office.\nWe weren't able to keep doing it that way.\nSo, I did four more episodes where I interviewed guests.\nUm, and Kurroll was one of those four.\nHuh.\nAnd then like six months after that, he was like, &quot;Do you want to host the SuperDataScience podcast?&quot;\nWow.\nWow.\nThat's crazy.\nI had no idea.\nThat's cool.\nYeah.\nAnd what's really funny is if you listen, people listen to Kier's episode.\nWe made fake ads for that episode.\nAbout what?\nAnd um so we had uh it was an app for finding toilet paper.\nUh because it was the pandemic.\nIt was like the pandemic had just started.\nUh I can't remember.\nWe had a silly name for it.\nWe had music.\nUm and we just recorded it in one shot with Kurill with the guest there.\nUm I was just like, &quot;Okay, I need to take a break here to record this fake ad.&quot;\nThat's so funny.\nYeah.\nUm, so yeah, I was kind of like I didn't know but I was auditioning for this podcast where we actually have real ads.\nI'm very much looking forward to being on Practically Intelligent and having a conversation and also meeting remind me of your a yeah looking forward to meeting him and I'm sure we'll have a lot of fun.\nUh, and yeah, so uh I'll be yeah people follow me on LinkedIn or whatever I'll be posting about that when the Practically Intelligent episode comes out.\nAnd on that note, how should people be, you know, other than all like what's a social media place to follow you, Son?\nFor me, it's LinkedIn.\nUm, it was always funny to think about now, like I never really thought I'd be that guy on LinkedIn, but for me, my LinkedIn has been my social media of choice.\nI I kind of grew tired of Twitterx.\nUh, and that's where most of my followers kind of can find my my my newsletters and my different blog articles and just everything that I'm doing.\nYeah.\nNice.\nYeah, same for me.\nI yeah I don't know I got tired of like there's just so much more interaction on LinkedIn lately than X and so yeah at least for what we do in data science seems to be the place to be now.\nYeah nice Son thank you so much for taking the time and I'm sure it won't be long before you're on an episode again.\nWell, thank you, Jon.\nIt's always a pleasure.\nAlways great to have Sinan Ozdemir on the show.\nIn today's episode, he covered how current AI benchmarks suffer from teaching to test where labs optimize for high scores rather than real world performance, as well as contamination issues where test questions leak into training data.\nHe talked about allegations emerging that Meta had to publicly deny manipulating Llama 4's benchmark scores, highlighting how the lack of transparency in training data makes it impossible to verify claims.\nHe talked about how even advanced reasoning models like OpenAI's 03 hallucinate up to 40% of the time on basic factual benchmarks like simple QA, demonstrating that high capability scores don't guarantee truthfulness.\nAnd he talked about how organizations should create custom test sets specific to their use cases, implement rubricbased evaluation with LLMs as judges after validating against human evaluators ideally, and how they should chase their own internal leaderboards rather than generic benchmarks that don't reflect the enterprises actual needs.\nAs always, you can get all the show notes, including the transcript for this episode, the video recording, any materials mentioned on the show, the URLs for Son's social media profiles, as well as my own at superdatience.com/903.\nThanks to everyone on the SuperDataScience podcast team, our podcast manager Sonia Bryovich, media editor, Mario Pombo, Nathan Daly, and Natalie Jysky on partnerships, our researcher Serge Miss, writer Dr. Zara Care, and yes, of course, our founder Kira Lamnco.\nThanks to all of them for producing another excellent episode for us today, for enabling that super team to create this free podcast for you.\nWe are deeply grateful to our sponsors.\nYou, yes you, can support this show by checking out our sponsors links which are in the show notes.\nAnd if you yourself are interested in sponsoring an episode, you can find out how to do that by going to john.com/mpodcast.\nOtherwise, share, review, subscribe, uh, edit videos into shorts if you want to.\nBut most importantly, just keep on tuning in.\nAnd I'm so grateful to have you listening and I hope I can continue to make episodes you love for years and years to come.\nUntil next time, keep on rocking out there and I'm looking forward to enjoying another round of the SuperDataScience podcast with you very soon.\n",
  "dumpedAt": "2025-07-21T18:43:26.491Z"
}