{
  "episodeId": "zFnu5X4hd7U",
  "channelSlug": "@superdatasciencewithjonkrohn",
  "title": "886: In Case You Missed it In April 2025 â€” with Jon Krohn (@JonKrohnLearns)",
  "publishedAt": "2025-05-09T11:01:37.000Z",
  "rawLines": [
    {
      "lang": "en",
      "text": "This is episode number 886, our in case",
      "offset": 0.24,
      "duration": 6.48
    },
    {
      "lang": "en",
      "text": "you missed it in April",
      "offset": 3.12,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "episode. Welcome back to the Super Data",
      "offset": 8.679,
      "duration": 4.281
    },
    {
      "lang": "en",
      "text": "Science podcast. I am your host John",
      "offset": 10.88,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "Cone. This is an in case you missed it",
      "offset": 12.96,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "episode that highlights the best parts",
      "offset": 15.44,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "of conversations we had on the show over",
      "offset": 17.6,
      "duration": 4.839
    },
    {
      "lang": "en",
      "text": "the past month. Our",
      "offset": 19.68,
      "duration": 5.519
    },
    {
      "lang": "en",
      "text": "Icy in case you missed it this month",
      "offset": 22.439,
      "duration": 5.561
    },
    {
      "lang": "en",
      "text": "starts with Sama Bali and Logan Lawler.",
      "offset": 25.199,
      "duration": 5.761
    },
    {
      "lang": "en",
      "text": "Sama is from Nvidia and Logan is from",
      "offset": 28,
      "duration": 6.8
    },
    {
      "lang": "en",
      "text": "Dell. And in episode 883, I asked them",
      "offset": 30.96,
      "duration": 6.64
    },
    {
      "lang": "en",
      "text": "about libraries like CUDA that make up",
      "offset": 34.8,
      "duration": 6.32
    },
    {
      "lang": "en",
      "text": "the AI software stack on NVIDIA GPUs. I",
      "offset": 37.6,
      "duration": 5.279
    },
    {
      "lang": "en",
      "text": "love the scenic route that Sama took me",
      "offset": 41.12,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "on to get us there as it knocked so many",
      "offset": 42.879,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "novel concepts in AI and emerging tech",
      "offset": 44.8,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "into place. Here she talks about",
      "offset": 47.28,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "Nvidia's new software and services and",
      "offset": 49.44,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "how they interconnect. I want to get",
      "offset": 52,
      "duration": 3.039
    },
    {
      "lang": "en",
      "text": "back to the Nvidia story from around the",
      "offset": 53.76,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "time and kind of this this visionary",
      "offset": 55.039,
      "duration": 3.281
    },
    {
      "lang": "en",
      "text": "nature of what Nvidia's done and",
      "offset": 56.8,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "reflected in their share price is this",
      "offset": 58.32,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "idea that okay deep learning is going to",
      "offset": 60.879,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "be gigantic or let's assume that deep",
      "offset": 62.32,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "learning is going to be gigantic and so",
      "offset": 64.159,
      "duration": 4.561
    },
    {
      "lang": "en",
      "text": "let's build a software ecosystem going",
      "offset": 66.64,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "back to your point earlier sama y that",
      "offset": 68.72,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "supports that um so yeah so tell us",
      "offset": 70.96,
      "duration": 5.199
    },
    {
      "lang": "en",
      "text": "about things like CUDA tensor RT maybe a",
      "offset": 73.36,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "bit of the history and why those are so",
      "offset": 76.159,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "important in this GPU ecosystem and in",
      "offset": 78.4,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "this AI era yep I'm I'm actually going",
      "offset": 80.24,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "Start first with Nvidia AI Enterprise,",
      "offset": 82.88,
      "duration": 3.599
    },
    {
      "lang": "en",
      "text": "right? Just completing the story of how",
      "offset": 84.72,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "we're doing things um especially with",
      "offset": 86.479,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "Dell Promax AIPCs. So u think of NVIDIA",
      "offset": 88.24,
      "duration": 5.919
    },
    {
      "lang": "en",
      "text": "AI enterprise as our version of you know",
      "offset": 92.079,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "end toend um software development",
      "offset": 94.159,
      "duration": 5.041
    },
    {
      "lang": "en",
      "text": "platform which is helping you not just",
      "offset": 96.799,
      "duration": 4.481
    },
    {
      "lang": "en",
      "text": "accelerate your data science pipelines",
      "offset": 99.2,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "but also really helping you uh build",
      "offset": 101.28,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "nextG it can be generative AI",
      "offset": 103.84,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "applications it could be computer vision",
      "offset": 105.92,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "applications it can be speech AI",
      "offset": 107.52,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "applications and it has it has a lot of",
      "offset": 109.2,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "components uh we've got NIM",
      "offset": 111.52,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "microservices um this is how we are",
      "offset": 113.6,
      "duration": 6.159
    },
    {
      "lang": "en",
      "text": "delivering all kinds of AI models as",
      "offset": 117.2,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "containerized microservices. So, uh",
      "offset": 119.759,
      "duration": 5.121
    },
    {
      "lang": "en",
      "text": "literally think of any other any AI",
      "offset": 122.88,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "model in the world. We work with um open",
      "offset": 124.88,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "source partners, proprietary partners.",
      "offset": 127.36,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "Uh we have our own NVIDIA AI models as",
      "offset": 129.36,
      "duration": 5.519
    },
    {
      "lang": "en",
      "text": "well. We're taking each of these AI",
      "offset": 131.68,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "models uh putting them into a container",
      "offset": 134.879,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "um and then adding our um I won't say",
      "offset": 137.28,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "secret source because everybody knows",
      "offset": 140.879,
      "duration": 3.761
    },
    {
      "lang": "en",
      "text": "about Tensor RLM and all kinds of",
      "offset": 142.16,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "services which are really helping you",
      "offset": 144.64,
      "duration": 4.959
    },
    {
      "lang": "en",
      "text": "get the best inference possible on",
      "offset": 147.12,
      "duration": 5.32
    },
    {
      "lang": "en",
      "text": "Nvidia GPUs and we're offering them as",
      "offset": 149.599,
      "duration": 4.881
    },
    {
      "lang": "en",
      "text": "microservices and the reason being and",
      "offset": 152.44,
      "duration": 4.28
    },
    {
      "lang": "en",
      "text": "you'll start soon start seeing this from",
      "offset": 154.48,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "Nvidia perspective that we're providing",
      "offset": 156.72,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "almost all of our AI software as",
      "offset": 158.4,
      "duration": 5.119
    },
    {
      "lang": "en",
      "text": "microservices is because things are",
      "offset": 160.879,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "changing quickly. Uh I'm a developer",
      "offset": 163.519,
      "duration": 3.201
    },
    {
      "lang": "en",
      "text": "today who built an application with",
      "offset": 165.28,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "Llama 3 and guess what? In two months",
      "offset": 166.72,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "Llama 3.1 comes and then another two",
      "offset": 168.8,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "months 3.2 comes up. So we want to make",
      "offset": 170.72,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "it really really easy for people to just",
      "offset": 173.28,
      "duration": 4.239
    },
    {
      "lang": "en",
      "text": "swap in the model as quickly as possible",
      "offset": 175.44,
      "duration": 3.72
    },
    {
      "lang": "en",
      "text": "without really disrupting that entire",
      "offset": 177.519,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "pipeline. So um that's NIM",
      "offset": 179.16,
      "duration": 5.64
    },
    {
      "lang": "en",
      "text": "microservices. Um we've gotten all kinds",
      "offset": 181.84,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "of models from uh if you want to build a",
      "offset": 184.8,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "digital human to actually building",
      "offset": 187.2,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "speech related applications to now uh we",
      "offset": 189.04,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "also have NIM microservices for our",
      "offset": 191.599,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "reasoning AI models as well. So that's",
      "offset": 193.2,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "that's the first component of NVIDIA",
      "offset": 195.519,
      "duration": 5.201
    },
    {
      "lang": "en",
      "text": "enterprise. really quickly before so",
      "offset": 197.519,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "it's it's going to be obvious for sure",
      "offset": 200.72,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "to you to both of you as well as to many",
      "offset": 202.959,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "of our listeners exactly what a microser",
      "offset": 204.8,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "is but could you define that for our",
      "offset": 206.56,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "listeners that don't know just so that",
      "offset": 208.4,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "you know they understand what it is and",
      "offset": 209.92,
      "duration": 6.16
    },
    {
      "lang": "en",
      "text": "why it's important why it's helpful um I",
      "offset": 212.239,
      "duration": 5.041
    },
    {
      "lang": "en",
      "text": "actually don't have a definition of",
      "offset": 216.08,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "micros well I'm going to give you not",
      "offset": 217.28,
      "duration": 4.959
    },
    {
      "lang": "en",
      "text": "like a textbook definition but I'm going",
      "offset": 219.92,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "to give you a practical definition right",
      "offset": 222.239,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "is let's say you're you know a data",
      "offset": 224.4,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "scientist and you have created let's",
      "offset": 226.56,
      "duration": 7.36
    },
    {
      "lang": "en",
      "text": "just pretend a chatbot with llama 3 and",
      "offset": 229.76,
      "duration": 6.32
    },
    {
      "lang": "en",
      "text": "you create that without a micros service",
      "offset": 233.92,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "without you know an nvidia nim like sama",
      "offset": 236.08,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "said every time that that model updates",
      "offset": 239.12,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "any if there's security all this stuff",
      "offset": 241.36,
      "duration": 4.799
    },
    {
      "lang": "en",
      "text": "you're doing a ton of I hate to say it",
      "offset": 243.76,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "but background tedious work to get that",
      "offset": 246.159,
      "duration": 5.921
    },
    {
      "lang": "en",
      "text": "to a point where you can deploy it where",
      "offset": 249.12,
      "duration": 5.039
    },
    {
      "lang": "en",
      "text": "when things change for example if you",
      "offset": 252.08,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "don't like that's the whole point of a",
      "offset": 254.159,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "microser with nim is you basically and",
      "offset": 255.84,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "load that literally one line of code and",
      "offset": 257.519,
      "duration": 4.641
    },
    {
      "lang": "en",
      "text": "the LLM part of it is really done for",
      "offset": 260,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "you. It is containerized. It's packaged.",
      "offset": 262.16,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "It's ready to go. So a data scientist",
      "offset": 264.32,
      "duration": 3.439
    },
    {
      "lang": "en",
      "text": "can focus on well how am I going to",
      "offset": 266.479,
      "duration": 2.881
    },
    {
      "lang": "en",
      "text": "customize it or building whatever",
      "offset": 267.759,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "application wrapper around it versus",
      "offset": 269.36,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "like ooh I need to update the code here",
      "offset": 271.44,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "to get this to connect like that's",
      "offset": 273.759,
      "duration": 4.641
    },
    {
      "lang": "en",
      "text": "really the point of a NIM is how quickly",
      "offset": 275.52,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "can I leverage the power of an LM vision",
      "offset": 278.4,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "model whatever with one line of code.",
      "offset": 280.88,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "That's the power of a NIM. And it runs",
      "offset": 283.12,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "on a workstation too. runs on Delp Pro",
      "offset": 285.44,
      "duration": 3.759
    },
    {
      "lang": "en",
      "text": "Max servers. It runs pretty much",
      "offset": 287.6,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "everywhere. Yeah, that that was going to",
      "offset": 289.199,
      "duration": 4.241
    },
    {
      "lang": "en",
      "text": "be my point that the key point being",
      "offset": 291.44,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "with these NIM microservices, you don't",
      "offset": 293.44,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "have to make sure that the AI model is",
      "offset": 296.24,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "tuned to the GPU, right? We've done all",
      "offset": 298,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "of that work for you. So, as soon as",
      "offset": 300.24,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "you're downloading this locally on your",
      "offset": 301.84,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "Dell Pro Max PC, it already understands",
      "offset": 304,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "the kind of GPU it's running on. The",
      "offset": 306.56,
      "duration": 3.639
    },
    {
      "lang": "en",
      "text": "only thing you have to make sure",
      "offset": 308.32,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "is, you know, the model you're",
      "offset": 310.199,
      "duration": 3.961
    },
    {
      "lang": "en",
      "text": "downloading fits onto your GPU memory",
      "offset": 312.08,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "size. now. But with 96 gigs of memory,",
      "offset": 314.16,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "you've got you've got the entire world",
      "offset": 316.56,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "for you here. Nice. And so I've been",
      "offset": 318.56,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "trying to as you've been speaking, I've",
      "offset": 320.56,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "tried to kind of look up quickly online",
      "offset": 322.4,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "what NIM stands for. It doesn't seem to",
      "offset": 324.8,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "stand for anything that I can find",
      "offset": 326.56,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "easily. It just sounds Oh, I'm going to",
      "offset": 327.84,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "let the secrets out. It actually stands",
      "offset": 330.16,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "for Nvidia inference microser, but then",
      "offset": 331.759,
      "duration": 6.081
    },
    {
      "lang": "en",
      "text": "we also use name microser. So it's like",
      "offset": 334.96,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "it's like chai tea kind of a thing. They",
      "offset": 337.84,
      "duration": 6.72
    },
    {
      "lang": "en",
      "text": "mean the same thing in potato. Yeah. A",
      "offset": 340.24,
      "duration": 6.72
    },
    {
      "lang": "en",
      "text": "potato potato. Potato potato. A potato",
      "offset": 344.56,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "brand potato. Exactly. Cheese queso.",
      "offset": 346.96,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "That's what I always say. I go at a",
      "offset": 350.08,
      "duration": 2.16
    },
    {
      "lang": "en",
      "text": "restaurant, I'll say, &quot;I want cheese",
      "offset": 351.28,
      "duration": 2.639
    },
    {
      "lang": "en",
      "text": "queso.&quot; And then my wife always gives me",
      "offset": 352.24,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "a hard time. But yeah, cheese queso.",
      "offset": 353.919,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "Nice. Yeah, now I understand perfectly.",
      "offset": 355.68,
      "duration": 2.959
    },
    {
      "lang": "en",
      "text": "Uh, thank you for giving us that",
      "offset": 357.52,
      "duration": 2.88
    },
    {
      "lang": "en",
      "text": "insight. It It's interesting. It isn't",
      "offset": 358.639,
      "duration": 3.521
    },
    {
      "lang": "en",
      "text": "it isn't something that's very public.",
      "offset": 360.4,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "So, people really are getting an inside",
      "offset": 362.16,
      "duration": 3.599
    },
    {
      "lang": "en",
      "text": "scoop on Nim. And yeah, it's just",
      "offset": 363.6,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "spelled NIM for our listeners uh who are",
      "offset": 365.759,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "wondering what word we're saying. It's",
      "offset": 368.96,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "exactly like it sounds. NIM in all caps.",
      "offset": 370.319,
      "duration": 4.481
    },
    {
      "lang": "en",
      "text": "And I'll have a link to that in the show",
      "offset": 373.44,
      "duration": 2.56
    },
    {
      "lang": "en",
      "text": "notes, of course. Anyway, so I",
      "offset": 374.8,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "interrupted you. Oh, go ahead, Tom. Oh,",
      "offset": 376,
      "duration": 3.759
    },
    {
      "lang": "en",
      "text": "I I was just on the same topic of N",
      "offset": 377.84,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "microservices. I I was going to say",
      "offset": 379.759,
      "duration": 4.121
    },
    {
      "lang": "en",
      "text": "we've got a website called",
      "offset": 381.6,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "build.envidia.com. Um, that's where we",
      "offset": 383.88,
      "duration": 5.56
    },
    {
      "lang": "en",
      "text": "host all of these name microservices. U,",
      "offset": 386.08,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "it's a good website to not just just go",
      "offset": 389.44,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "try out these different kinds of AI",
      "offset": 391.84,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "models. You have the ability to",
      "offset": 393.52,
      "duration": 3.679
    },
    {
      "lang": "en",
      "text": "prototype on the website itself. There",
      "offset": 395.12,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "are no charges for it at all. Um, you",
      "offset": 397.199,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "can see models again by all kinds of",
      "offset": 399.68,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "partners that you work with, including",
      "offset": 402.319,
      "duration": 3.281
    },
    {
      "lang": "en",
      "text": "Nvidia models as well. They're",
      "offset": 403.84,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "segregated by the industry you work with",
      "offset": 405.6,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "or the use case you're trying to build.",
      "offset": 407.919,
      "duration": 3.041
    },
    {
      "lang": "en",
      "text": "So, it's easy to kind of maneuver",
      "offset": 409.52,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "around, find the exact model you want to",
      "offset": 410.96,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "work with. Uh, and then once you want to",
      "offset": 413.44,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "download this, uh, we've made it easier.",
      "offset": 415.68,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "So, if you really sign up for our Nvidia",
      "offset": 417.6,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "developer program, we actually let you",
      "offset": 419.52,
      "duration": 3.679
    },
    {
      "lang": "en",
      "text": "download the these models and then",
      "offset": 421.36,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "continue to your do your testing",
      "offset": 423.199,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "experimentation free of cost. There are",
      "offset": 425.199,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "no charges at all. So you can continue",
      "offset": 427.039,
      "duration": 4.481
    },
    {
      "lang": "en",
      "text": "as a developer. Um I would want to go",
      "offset": 429.36,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "try out different kinds of models, see",
      "offset": 431.52,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "what's working with my um application.",
      "offset": 432.88,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "So we we like to do that as well.",
      "offset": 435.52,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "Fantastic. That was a great rundown.",
      "offset": 437.52,
      "duration": 2.88
    },
    {
      "lang": "en",
      "text": "What I was going to say and I'm glad",
      "offset": 439.36,
      "duration": 2.16
    },
    {
      "lang": "en",
      "text": "that you had more to say on Nim",
      "offset": 440.4,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "microservices because my transition was",
      "offset": 441.52,
      "duration": 4.799
    },
    {
      "lang": "en",
      "text": "going to be that uh the last time I",
      "offset": 443.52,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "interrupted you, you were about to I",
      "offset": 446.319,
      "duration": 3.521
    },
    {
      "lang": "en",
      "text": "think start talking about other aspects",
      "offset": 447.84,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "other aspects of the AI enterprise. So",
      "offset": 449.84,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "now I'll let you go on that. So outside",
      "offset": 451.84,
      "duration": 4.639
    },
    {
      "lang": "en",
      "text": "of net microservices we've got u Nemo",
      "offset": 454.08,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "which really helps you um build train",
      "offset": 456.479,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "fine-tune your own models but also gets",
      "offset": 459.12,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "you the ability to add guardrails to",
      "offset": 460.88,
      "duration": 3.759
    },
    {
      "lang": "en",
      "text": "your model so that you know whenever",
      "offset": 462.56,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "you're deploying your application you",
      "offset": 464.639,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "are making sure that the application",
      "offset": 466.24,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "gets used exactly the way that you want",
      "offset": 468.24,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "to do it itself. Uh we've got AI",
      "offset": 470.319,
      "duration": 4.961
    },
    {
      "lang": "en",
      "text": "blueprints. Uh think of these as",
      "offset": 472.88,
      "duration": 5.84
    },
    {
      "lang": "en",
      "text": "reference AI workflows. So we give you",
      "offset": 475.28,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "the ability to build different kinds of",
      "offset": 478.72,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "AI applications. So we give you think of",
      "offset": 480.56,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "this as a recipe. You've got the",
      "offset": 482.639,
      "duration": 3.441
    },
    {
      "lang": "en",
      "text": "step-by-step process to actually build",
      "offset": 484.16,
      "duration": 3.4
    },
    {
      "lang": "en",
      "text": "an application. There's a reference",
      "offset": 486.08,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "architecture, but we also get you the",
      "offset": 487.56,
      "duration": 4.199
    },
    {
      "lang": "en",
      "text": "ability to add your own data to it. And",
      "offset": 489.919,
      "duration": 4.241
    },
    {
      "lang": "en",
      "text": "that's what gets every company their own",
      "offset": 491.759,
      "duration": 4.241
    },
    {
      "lang": "en",
      "text": "uh edge, right? You want to add your",
      "offset": 494.16,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "data, which is your differentiation at",
      "offset": 496,
      "duration": 3.599
    },
    {
      "lang": "en",
      "text": "this point in time. So you have the",
      "offset": 497.84,
      "duration": 3.24
    },
    {
      "lang": "en",
      "text": "ability to build different kinds of",
      "offset": 499.599,
      "duration": 3.761
    },
    {
      "lang": "en",
      "text": "applications. Uh what else do we have?",
      "offset": 501.08,
      "duration": 3.64
    },
    {
      "lang": "en",
      "text": "Oh, we've got different kinds of",
      "offset": 503.36,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "frameworks and tools. So we actually do",
      "offset": 504.72,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "support different kinds of AI frameworks",
      "offset": 507.12,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "like PyTorch, TensorFlow. Uh we also",
      "offset": 509.12,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "have our CUDA library. So I think this",
      "offset": 512.64,
      "duration": 3.519
    },
    {
      "lang": "en",
      "text": "is a good time to kind of talk about",
      "offset": 514.64,
      "duration": 4.959
    },
    {
      "lang": "en",
      "text": "CUDA as well which really stands for uh",
      "offset": 516.159,
      "duration": 6.481
    },
    {
      "lang": "en",
      "text": "compute unified device architecture. I",
      "offset": 519.599,
      "duration": 4.881
    },
    {
      "lang": "en",
      "text": "didn't know that. I didn't know that.",
      "offset": 522.64,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "I've been using that word for like a",
      "offset": 524.48,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "decade now. Thank you.",
      "offset": 526.24,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "So this really has been playing a",
      "offset": 528.72,
      "duration": 5.48
    },
    {
      "lang": "en",
      "text": "crucial role in AI development by",
      "offset": 531.36,
      "duration": 5.919
    },
    {
      "lang": "en",
      "text": "enabling efficient parallel computing on",
      "offset": 534.2,
      "duration": 6.68
    },
    {
      "lang": "en",
      "text": "Nvidia GPUs. Right? So the idea was this",
      "offset": 537.279,
      "duration": 7.601
    },
    {
      "lang": "en",
      "text": "entire architecture really helps you",
      "offset": 540.88,
      "duration": 6.16
    },
    {
      "lang": "en",
      "text": "train different kinds of models",
      "offset": 544.88,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "significantly faster which means that",
      "offset": 547.04,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "you can in some scenarios actually",
      "offset": 548.959,
      "duration": 4.641
    },
    {
      "lang": "en",
      "text": "reduce your training times from weeks to",
      "offset": 550.8,
      "duration": 6.56
    },
    {
      "lang": "en",
      "text": "days. Right? It is also helping you get",
      "offset": 553.6,
      "duration": 5.919
    },
    {
      "lang": "en",
      "text": "better and better inference. So you see",
      "offset": 557.36,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "higher inference performance on Nvidia",
      "offset": 559.519,
      "duration": 5.281
    },
    {
      "lang": "en",
      "text": "GPUs because of this architecture of of",
      "offset": 562,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "uh parallel processing. If you're",
      "offset": 564.8,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "comparing it to just CPUon platforms, uh",
      "offset": 566.56,
      "duration": 6.48
    },
    {
      "lang": "en",
      "text": "we now have and I'll have to look up the",
      "offset": 570.24,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "right number of how many CUDA libraries",
      "offset": 573.04,
      "duration": 4.479
    },
    {
      "lang": "en",
      "text": "we have, but we've got tons and tons of",
      "offset": 575.12,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "these CUDA libraries and these are GPU",
      "offset": 577.519,
      "duration": 5.121
    },
    {
      "lang": "en",
      "text": "accelerated libraries. So a good example",
      "offset": 580.24,
      "duration": 5.32
    },
    {
      "lang": "en",
      "text": "I'll give you is of",
      "offset": 582.64,
      "duration": 6.639
    },
    {
      "lang": "en",
      "text": "um in uh rapid scudf right so the the",
      "offset": 585.56,
      "duration": 5.719
    },
    {
      "lang": "en",
      "text": "idea and um Logan touched on this",
      "offset": 589.279,
      "duration": 4.801
    },
    {
      "lang": "en",
      "text": "earlier as well is the way rapid scoof",
      "offset": 591.279,
      "duration": 5.921
    },
    {
      "lang": "en",
      "text": "works is that it tends to mimic the the",
      "offset": 594.08,
      "duration": 6.08
    },
    {
      "lang": "en",
      "text": "APIs of you know a lot of data frames",
      "offset": 597.2,
      "duration": 6.72
    },
    {
      "lang": "en",
      "text": "like pandas polars so if you are you",
      "offset": 600.16,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "know in that process of pre-processing",
      "offset": 603.92,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "your data in your data science workflow",
      "offset": 605.92,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "it can actually accelerate that entire",
      "offset": 608.8,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "IO your process by 100x on our on our",
      "offset": 611.44,
      "duration": 6.399
    },
    {
      "lang": "en",
      "text": "6,000 GPUs u without any kind of code",
      "offset": 614.56,
      "duration": 4.959
    },
    {
      "lang": "en",
      "text": "change. That's that's the beauty of it",
      "offset": 617.839,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "that as a data scientist all I'm doing",
      "offset": 619.519,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "is adding that one API line of code and",
      "offset": 621.279,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "then it actually uh accelerates the",
      "offset": 624.079,
      "duration": 5.121
    },
    {
      "lang": "en",
      "text": "entire process by 100x. So that's that's",
      "offset": 626.959,
      "duration": 5.201
    },
    {
      "lang": "en",
      "text": "like massive timesaving from a data",
      "offset": 629.2,
      "duration": 5.759
    },
    {
      "lang": "en",
      "text": "scientist perspective. U at GTC we",
      "offset": 632.16,
      "duration": 5.84
    },
    {
      "lang": "en",
      "text": "announced uh QML which is again one of",
      "offset": 634.959,
      "duration": 4.961
    },
    {
      "lang": "en",
      "text": "our CUDA libraries as well. This is",
      "offset": 638,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "helping you accelerate your machine",
      "offset": 639.92,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "learning tasks as well. So if you're",
      "offset": 642.32,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "using using skit uh you have the ability",
      "offset": 643.68,
      "duration": 6.08
    },
    {
      "lang": "en",
      "text": "to go up to 50x acceleration uh for your",
      "offset": 646.32,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "ML tasks as well. So each one of these",
      "offset": 649.76,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "libraries and as I said we've got tons",
      "offset": 651.76,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "of these right now but depending on the",
      "offset": 653.6,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "data science task that you're doing",
      "offset": 656,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "these are all designed to then offload",
      "offset": 657.519,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "that work to the GPU so that you can see",
      "offset": 660.32,
      "duration": 4.639
    },
    {
      "lang": "en",
      "text": "that massive acceleration from Nvidia's",
      "offset": 662.079,
      "duration": 5.681
    },
    {
      "lang": "en",
      "text": "AI enterprise. We turn now to AWS's",
      "offset": 664.959,
      "duration": 5.841
    },
    {
      "lang": "en",
      "text": "Graviton and Tranium 2 chips. I'm taking",
      "offset": 667.76,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "this clip from my conversation in",
      "offset": 670.8,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "episode 881 with Emily Weber, a",
      "offset": 672.32,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "principal machine learning specialist",
      "offset": 675.2,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "from AWS's Elite Anapuna division. In",
      "offset": 677.04,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "the clip, Emily explained why one might",
      "offset": 680.88,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "elect to use a specialized AI",
      "offset": 682.8,
      "duration": 4.719
    },
    {
      "lang": "en",
      "text": "accelerator over a GPU. So, let's start",
      "offset": 684.88,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "there. You can tell us about this",
      "offset": 687.519,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "Graviton chip, the Tranium 2 chip. And",
      "offset": 690.24,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "maybe this kind of relates to a general",
      "offset": 692.399,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "question that I've been meaning to ask",
      "offset": 694.399,
      "duration": 3.201
    },
    {
      "lang": "en",
      "text": "you this whole episode and I have just",
      "offset": 695.839,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "continued to forget uh with each",
      "offset": 697.6,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "wonderful explanation that you give",
      "offset": 699.839,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "after another which is that why should",
      "offset": 701.04,
      "duration": 4.28
    },
    {
      "lang": "en",
      "text": "somebody why should a listener for",
      "offset": 703.68,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "example consider using an accelerator",
      "offset": 705.32,
      "duration": 5.959
    },
    {
      "lang": "en",
      "text": "like tranium and inferentia instead of a",
      "offset": 708.48,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "GPU? Maybe that's maybe that's a great",
      "offset": 711.279,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "question to start with and then I'll",
      "offset": 713.36,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "remind you of the other the series of",
      "offset": 714.88,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "questions that led me to that question.",
      "offset": 716.56,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "Sounds good. Thank you. Thank you. Yeah.",
      "offset": 718.959,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "So, so I mean fundamentally at at AWS,",
      "offset": 721.12,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "you know, we we really believe in",
      "offset": 724.399,
      "duration": 5.841
    },
    {
      "lang": "en",
      "text": "customer choice. Like we believe in a",
      "offset": 726,
      "duration": 6.48
    },
    {
      "lang": "en",
      "text": "cloud. We believe in a cloud service,",
      "offset": 730.24,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "you know, provider that enables",
      "offset": 732.48,
      "duration": 5.359
    },
    {
      "lang": "en",
      "text": "customers to have choice about data",
      "offset": 735.04,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "sets, have choice about models, and have",
      "offset": 737.839,
      "duration": 5.521
    },
    {
      "lang": "en",
      "text": "choice about accelerated hardware. Uh we",
      "offset": 740.56,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "think it's it's good for customers to",
      "offset": 743.36,
      "duration": 5.919
    },
    {
      "lang": "en",
      "text": "have that ability um and to have real,",
      "offset": 746.32,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "you know, options. uh that is ultimately",
      "offset": 749.279,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "best for consumers and that that's best",
      "offset": 752.32,
      "duration": 3.519
    },
    {
      "lang": "en",
      "text": "for customers. So so fundamentally",
      "offset": 754.079,
      "duration": 4.481
    },
    {
      "lang": "en",
      "text": "that's that's the direction. Um",
      "offset": 755.839,
      "duration": 4.641
    },
    {
      "lang": "en",
      "text": "Annapernal Labs is an awesome company.",
      "offset": 758.56,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "Annapernal Labs has been building",
      "offset": 760.48,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "infrastructure for AWS for many years.",
      "offset": 762.399,
      "duration": 6.24
    },
    {
      "lang": "en",
      "text": "Uh so Annapernal Labs is a startup that",
      "offset": 765.76,
      "duration": 6.8
    },
    {
      "lang": "en",
      "text": "Amazon acquired in 2015 um primarily to",
      "offset": 768.639,
      "duration": 6.32
    },
    {
      "lang": "en",
      "text": "develop the hypervisor actually. So they",
      "offset": 772.56,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "developed what's called the Nitro",
      "offset": 774.959,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "system. Yeah, we'll talk it through. So",
      "offset": 776.399,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "they de Yeah, it's it's like the coolest",
      "offset": 778.399,
      "duration": 6.321
    },
    {
      "lang": "en",
      "text": "story in tech that is is the least told.",
      "offset": 781.839,
      "duration": 8.161
    },
    {
      "lang": "en",
      "text": "So So here's the scoop. Um so in 2015",
      "offset": 784.72,
      "duration": 8.28
    },
    {
      "lang": "en",
      "text": "uh the way people were doing",
      "offset": 790,
      "duration": 7.04
    },
    {
      "lang": "en",
      "text": "cloud 10 years ago uh is you had this",
      "offset": 793,
      "duration": 6.04
    },
    {
      "lang": "en",
      "text": "thing called the hypervisor. And the",
      "offset": 797.04,
      "duration": 6.08
    },
    {
      "lang": "en",
      "text": "hypervisor essentially was this giant",
      "offset": 799.04,
      "duration": 6.72
    },
    {
      "lang": "en",
      "text": "monolithic software system that managed",
      "offset": 803.12,
      "duration": 6.44
    },
    {
      "lang": "en",
      "text": "the entire host of all servers.",
      "offset": 805.76,
      "duration": 7.04
    },
    {
      "lang": "en",
      "text": "And the challenge with the hypervisor",
      "offset": 809.56,
      "duration": 7.56
    },
    {
      "lang": "en",
      "text": "systems is that it made it really hard",
      "offset": 812.8,
      "duration": 7.039
    },
    {
      "lang": "en",
      "text": "to innovate for the cloud. Uh because",
      "offset": 817.12,
      "duration": 6.32
    },
    {
      "lang": "en",
      "text": "all of the control, the communication,",
      "offset": 819.839,
      "duration": 7.521
    },
    {
      "lang": "en",
      "text": "the data at the server level was",
      "offset": 823.44,
      "duration": 6.24
    },
    {
      "lang": "en",
      "text": "implemented in this giant monolithic",
      "offset": 827.36,
      "duration": 4.2
    },
    {
      "lang": "en",
      "text": "thing called the hypervisor. So",
      "offset": 829.68,
      "duration": 5.08
    },
    {
      "lang": "en",
      "text": "Annaperna had this crazy idea of",
      "offset": 831.56,
      "duration": 6.76
    },
    {
      "lang": "en",
      "text": "decoupling the parts of the hypervisor",
      "offset": 834.76,
      "duration": 6.28
    },
    {
      "lang": "en",
      "text": "that you need to scale at the cloud at",
      "offset": 838.32,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "the physical level. So they developed",
      "offset": 841.04,
      "duration": 5.599
    },
    {
      "lang": "en",
      "text": "what's called the Nitro system today",
      "offset": 843.76,
      "duration": 5.24
    },
    {
      "lang": "en",
      "text": "which provides physical",
      "offset": 846.639,
      "duration": 5.601
    },
    {
      "lang": "en",
      "text": "separation for things like the data",
      "offset": 849,
      "duration": 7.8
    },
    {
      "lang": "en",
      "text": "that's running on the instance from the",
      "offset": 852.24,
      "duration": 6.92
    },
    {
      "lang": "en",
      "text": "communication that's controlling the",
      "offset": 856.8,
      "duration": 6.76
    },
    {
      "lang": "en",
      "text": "instance. And so this is both how AWS",
      "offset": 859.16,
      "duration": 7.72
    },
    {
      "lang": "en",
      "text": "scales and how AWS provides such strong",
      "offset": 863.56,
      "duration": 5.279
    },
    {
      "lang": "en",
      "text": "security guarantees is because",
      "offset": 866.88,
      "duration": 4.519
    },
    {
      "lang": "en",
      "text": "physically there are two different",
      "offset": 868.839,
      "duration": 5.481
    },
    {
      "lang": "en",
      "text": "controls. There's one physical, you",
      "offset": 871.399,
      "duration": 5
    },
    {
      "lang": "en",
      "text": "know, chip, there's one physical",
      "offset": 874.32,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "component of the hardware system that is",
      "offset": 876.399,
      "duration": 5.201
    },
    {
      "lang": "en",
      "text": "managing the data, the customer's data,",
      "offset": 878.8,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "and there's a different physical control",
      "offset": 881.6,
      "duration": 3.599
    },
    {
      "lang": "en",
      "text": "that's managing the governance of the",
      "offset": 883.44,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "instance. And so every modern EC2",
      "offset": 885.199,
      "duration": 5.921
    },
    {
      "lang": "en",
      "text": "instance today is built on the nitro",
      "offset": 889.12,
      "duration": 4.959
    },
    {
      "lang": "en",
      "text": "system. So that was the first major",
      "offset": 891.12,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "development for manipal labs was nitro.",
      "offset": 894.079,
      "duration": 3.361
    },
    {
      "lang": "en",
      "text": "So that's that's nitro like",
      "offset": 896.16,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "nitroglycerin. Nitro",
      "offset": 897.44,
      "duration": 6.56
    },
    {
      "lang": "en",
      "text": "uh nitro. Yeah. Explosive.",
      "offset": 900,
      "duration": 8.72
    },
    {
      "lang": "en",
      "text": "Yes. Yes. So so after the nitrous system",
      "offset": 904,
      "duration": 6.8
    },
    {
      "lang": "en",
      "text": "um anaperna started developing their",
      "offset": 908.72,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "second uh sort of main product line",
      "offset": 910.8,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "which is graviton. So, Graviton are",
      "offset": 912.72,
      "duration": 6.96
    },
    {
      "lang": "en",
      "text": "custom CPUs, custom ARMbased CPUs",
      "offset": 916.24,
      "duration": 5.159
    },
    {
      "lang": "en",
      "text": "developed by",
      "offset": 919.68,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "AnnapernaLabs. And if you watched",
      "offset": 921.399,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "reinvent, one of the",
      "offset": 924,
      "duration": 6.24
    },
    {
      "lang": "en",
      "text": "uh highlights that you saw is that today",
      "offset": 926.519,
      "duration": 6.76
    },
    {
      "lang": "en",
      "text": "more than half of new compute that comes",
      "offset": 930.24,
      "duration": 8.32
    },
    {
      "lang": "en",
      "text": "onto AWS is actually Graviton CPU. Oh,",
      "offset": 933.279,
      "duration": 7.441
    },
    {
      "lang": "en",
      "text": "yes. So when you're looking at instances",
      "offset": 938.56,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "on AWS, when you see that little G at",
      "offset": 940.72,
      "duration": 5.88
    },
    {
      "lang": "en",
      "text": "the end of a family, so like a",
      "offset": 944,
      "duration": 7.279
    },
    {
      "lang": "en",
      "text": "C6G or even a G5G, that second G means",
      "offset": 946.6,
      "duration": 6.72
    },
    {
      "lang": "en",
      "text": "it's a Graviton",
      "offset": 951.279,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "CPU. And so that means you're going to",
      "offset": 953.32,
      "duration": 5.4
    },
    {
      "lang": "en",
      "text": "get much better performance at a very,",
      "offset": 955.519,
      "duration": 6.32
    },
    {
      "lang": "en",
      "text": "you know, competitive price. Uh, and so",
      "offset": 958.72,
      "duration": 7.919
    },
    {
      "lang": "en",
      "text": "the Graviton CPU is our second like main",
      "offset": 961.839,
      "duration": 7.36
    },
    {
      "lang": "en",
      "text": "product line. And then tranium and infia",
      "offset": 966.639,
      "duration": 4.721
    },
    {
      "lang": "en",
      "text": "is the third main product category from",
      "offset": 969.199,
      "duration": 5.281
    },
    {
      "lang": "en",
      "text": "Anaperna labs which is now let's take",
      "offset": 971.36,
      "duration": 5.919
    },
    {
      "lang": "en",
      "text": "you know this awesome ability that we've",
      "offset": 974.48,
      "duration": 6.08
    },
    {
      "lang": "en",
      "text": "created in developing infrastructure and",
      "offset": 977.279,
      "duration": 5.841
    },
    {
      "lang": "en",
      "text": "scaling infrastructure across AWS and",
      "offset": 980.56,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "let's focus that on a IML and so",
      "offset": 983.12,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "inferentia of course was developed and",
      "offset": 986.24,
      "duration": 4.719
    },
    {
      "lang": "en",
      "text": "you know came out a number of years ago",
      "offset": 988.8,
      "duration": 5.92
    },
    {
      "lang": "en",
      "text": "trrenium 3 is our third generation chip",
      "offset": 990.959,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "uh so it's the third generation",
      "offset": 994.72,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "accelerator for a IML. Um, and that is",
      "offset": 996.639,
      "duration": 6.56
    },
    {
      "lang": "en",
      "text": "why it's such an exciting moment, right?",
      "offset": 1000.48,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "Because you see the breadth and the",
      "offset": 1003.199,
      "duration": 5.121
    },
    {
      "lang": "en",
      "text": "scope and the incredible results that",
      "offset": 1006.16,
      "duration": 4.479
    },
    {
      "lang": "en",
      "text": "Annaperna has delivered like over the",
      "offset": 1008.32,
      "duration": 4.959
    },
    {
      "lang": "en",
      "text": "years. Uh, and now this is totally",
      "offset": 1010.639,
      "duration": 5.401
    },
    {
      "lang": "en",
      "text": "focused and and now a large focus is a",
      "offset": 1013.279,
      "duration": 6.401
    },
    {
      "lang": "en",
      "text": "IML. And so when you know customers are",
      "offset": 1016.04,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "taking advantage of this like",
      "offset": 1019.68,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "fundamentally they're interested because",
      "offset": 1021.8,
      "duration": 5.239
    },
    {
      "lang": "en",
      "text": "they get the benefits of price",
      "offset": 1024.72,
      "duration": 4.479
    },
    {
      "lang": "en",
      "text": "performance like more than anything it's",
      "offset": 1027.039,
      "duration": 6.241
    },
    {
      "lang": "en",
      "text": "it's this you know benefit of highly",
      "offset": 1029.199,
      "duration": 9.48
    },
    {
      "lang": "en",
      "text": "optimized compute that is scarily energy",
      "offset": 1033.28,
      "duration": 8.759
    },
    {
      "lang": "en",
      "text": "efficient is so good at",
      "offset": 1038.679,
      "duration": 6.441
    },
    {
      "lang": "en",
      "text": "identifying improvement areas to just",
      "offset": 1042.039,
      "duration": 5.64
    },
    {
      "lang": "en",
      "text": "take cost out of the equation.",
      "offset": 1045.12,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "um and reduce complexity and pass",
      "offset": 1047.679,
      "duration": 4.961
    },
    {
      "lang": "en",
      "text": "performance and pass you know cost",
      "offset": 1050.32,
      "duration": 5.92
    },
    {
      "lang": "en",
      "text": "savings back to customers uh while you",
      "offset": 1052.64,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "know meeting performance and in many",
      "offset": 1056.24,
      "duration": 5.679
    },
    {
      "lang": "en",
      "text": "cases exceeding performance. So, TRN 2",
      "offset": 1058.4,
      "duration": 5.84
    },
    {
      "lang": "en",
      "text": "is actually the most powerful EC2",
      "offset": 1061.919,
      "duration": 6.321
    },
    {
      "lang": "en",
      "text": "instance on AWS for a IML like full stop",
      "offset": 1064.24,
      "duration": 6.48
    },
    {
      "lang": "en",
      "text": "when you look at the, you know,",
      "offset": 1068.24,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "performance metrics that we're seeing.",
      "offset": 1070.72,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "It's it's a very exciting moment. It's",
      "offset": 1073.28,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "an exciting moment for customers. Um,",
      "offset": 1075.2,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "exciting moment for the whole group.",
      "offset": 1077.76,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "Trainium 2 is the most powerful on AWS.",
      "offset": 1079.36,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "Correct. Performance and power are",
      "offset": 1082.16,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "certainly crucial for measuring chip",
      "offset": 1084.48,
      "duration": 5.92
    },
    {
      "lang": "en",
      "text": "efficacy. But what good is AWS's chip if",
      "offset": 1086.32,
      "duration": 6.16
    },
    {
      "lang": "en",
      "text": "it's not being used in deploying AI",
      "offset": 1090.4,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "models? Deployment can become a real",
      "offset": 1092.48,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "problem for teams where data scientists",
      "offset": 1095.2,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "outnumber software engineers. And in",
      "offset": 1096.96,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "episode number 879, I talk about the",
      "offset": 1099.039,
      "duration": 5.201
    },
    {
      "lang": "en",
      "text": "issues of model deployment with Greg",
      "offset": 1102.08,
      "duration": 4.479
    },
    {
      "lang": "en",
      "text": "Michaelelsson, Dr. Greg Michaelelsson,",
      "offset": 1104.24,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "co-founder and chief product officer of",
      "offset": 1106.559,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "Zerve. Nice. So another kind of tricky",
      "offset": 1109.2,
      "duration": 5.359
    },
    {
      "lang": "en",
      "text": "thing that uh data scientists maybe even",
      "offset": 1111.679,
      "duration": 7.921
    },
    {
      "lang": "en",
      "text": "myself have difficulty with is um is",
      "offset": 1114.559,
      "duration": 7.761
    },
    {
      "lang": "en",
      "text": "deploying AI models. So something that's",
      "offset": 1119.6,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "been intuitive for me for literally",
      "offset": 1122.32,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "decades is opening up uh some kind of",
      "offset": 1124,
      "duration": 6.16
    },
    {
      "lang": "en",
      "text": "IDE Jupyter notebook something like that",
      "offset": 1127.28,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "and uh getting going on inputting some",
      "offset": 1130.16,
      "duration": 5.759
    },
    {
      "lang": "en",
      "text": "data doing some EDA and building a",
      "offset": 1132.72,
      "duration": 5.199
    },
    {
      "lang": "en",
      "text": "model. But the thing that hasn't been",
      "offset": 1135.919,
      "duration": 3.441
    },
    {
      "lang": "en",
      "text": "intuitive to me, and it's probably just",
      "offset": 1137.919,
      "duration": 2.961
    },
    {
      "lang": "en",
      "text": "because I haven't been doing it as much,",
      "offset": 1139.36,
      "duration": 3.679
    },
    {
      "lang": "en",
      "text": "had the luxury kind of working at",
      "offset": 1140.88,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "companies where machine learning",
      "offset": 1143.039,
      "duration": 3.121
    },
    {
      "lang": "en",
      "text": "engineers or software developers,",
      "offset": 1144.799,
      "duration": 4.561
    },
    {
      "lang": "en",
      "text": "backend engineers take then the model",
      "offset": 1146.16,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "weights that I've created and they put",
      "offset": 1149.36,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "them into a production system. So on a",
      "offset": 1151.76,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "smaller team or on a team where there's",
      "offset": 1154.96,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "huge demand for software engineers,",
      "offset": 1157.76,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "which is often the case, you can end up",
      "offset": 1159.28,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "having more data scientists creating",
      "offset": 1161.28,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "models than there are software engineers",
      "offset": 1163.84,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "to deploy in a lot of companies. That",
      "offset": 1165.44,
      "duration": 5.599
    },
    {
      "lang": "en",
      "text": "creates a bottleneck. So how does Zer's",
      "offset": 1167.6,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "built-in API builder and GPU manager",
      "offset": 1171.039,
      "duration": 5.441
    },
    {
      "lang": "en",
      "text": "remove those kinds of barriers? Yeah, it",
      "offset": 1173.6,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "it's not just a bottleneck, it's also",
      "offset": 1176.48,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "kind of a a problematic dependency.",
      "offset": 1178.64,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "um because at the end of the day the the",
      "offset": 1182,
      "duration": 5.039
    },
    {
      "lang": "en",
      "text": "software developers that are uh",
      "offset": 1183.84,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "deploying these things are probably",
      "offset": 1187.039,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "aren't uh data scientists. So it's not",
      "offset": 1188.72,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "obvious that they are going to",
      "offset": 1191.36,
      "duration": 3.4
    },
    {
      "lang": "en",
      "text": "understand what is supposed to be do",
      "offset": 1192.64,
      "duration": 5.279
    },
    {
      "lang": "en",
      "text": "done and uh you know there's a lot of",
      "offset": 1194.76,
      "duration": 5.08
    },
    {
      "lang": "en",
      "text": "subtlety to this sort of thing. So you",
      "offset": 1197.919,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "can get mistakes introduced in really",
      "offset": 1199.84,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "easily here as well. Um, so yeah, so",
      "offset": 1201.76,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "like if you think about the deployment",
      "offset": 1204.88,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "process, um, you know, you're there's a",
      "offset": 1206.4,
      "duration": 5.279
    },
    {
      "lang": "en",
      "text": "lot of lot of hurdles to overcome. Uh,",
      "offset": 1209.2,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "if you've ever been slacked or emailed a",
      "offset": 1211.679,
      "duration": 4.961
    },
    {
      "lang": "en",
      "text": "Jupyter notebook and tried to run it,",
      "offset": 1214.72,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "you you know what some of them are,",
      "offset": 1216.64,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "right? Like you have the wrong version",
      "offset": 1218.64,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "of this package installed. Oh, you you",
      "offset": 1220,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "got a pip install a whole bunch of other",
      "offset": 1222.16,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "stuff to make that work. And so you",
      "offset": 1223.76,
      "duration": 3.48
    },
    {
      "lang": "en",
      "text": "might spend an hour trying to get your",
      "offset": 1225.52,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "your trying to even get the code to run",
      "offset": 1227.24,
      "duration": 3.64
    },
    {
      "lang": "en",
      "text": "assuming that you have the data and that",
      "offset": 1229.52,
      "duration": 3.519
    },
    {
      "lang": "en",
      "text": "all the folders and file paths are the",
      "offset": 1230.88,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "same and and all that sort of stuff. Um",
      "offset": 1233.039,
      "duration": 5.681
    },
    {
      "lang": "en",
      "text": "so you know at the end of the day what",
      "offset": 1236.48,
      "duration": 3.679
    },
    {
      "lang": "en",
      "text": "data scientists spend most of their time",
      "offset": 1238.72,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "doing today is building prototypes. Uh",
      "offset": 1240.159,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "and then those prototypes get handed off",
      "offset": 1242.24,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "to another team to kind of like recode",
      "offset": 1243.919,
      "duration": 5.441
    },
    {
      "lang": "en",
      "text": "uh in another environment with you know",
      "offset": 1246.48,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "you know dockerized and deployed and",
      "offset": 1249.36,
      "duration": 5.439
    },
    {
      "lang": "en",
      "text": "managing servers and stuff like that.",
      "offset": 1252,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "It's not obvious to me that data",
      "offset": 1254.799,
      "duration": 2.88
    },
    {
      "lang": "en",
      "text": "scientists know how to do that and it's",
      "offset": 1256.159,
      "duration": 3.201
    },
    {
      "lang": "en",
      "text": "really not obvious that they have the",
      "offset": 1257.679,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "privileges to do those kinds of things",
      "offset": 1259.36,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "in terms of just like the infrastructure",
      "offset": 1260.799,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "and all that kind of stuff. So, Zerf",
      "offset": 1263.44,
      "duration": 3.56
    },
    {
      "lang": "en",
      "text": "kind of like",
      "offset": 1265.919,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "uh uh handles all of those problems. So,",
      "offset": 1267,
      "duration": 5.4
    },
    {
      "lang": "en",
      "text": "every canvas inside observe has a Docker",
      "offset": 1270,
      "duration": 3.679
    },
    {
      "lang": "en",
      "text": "container that's supporting it. So,",
      "offset": 1272.4,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "anybody that logs into that canvas uh",
      "offset": 1273.679,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "doesn't have to worry about dependencies",
      "offset": 1276,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "uh because it's all it's all saved in",
      "offset": 1278,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "that project. And so those those",
      "offset": 1279.76,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "environments are reusable and sharable",
      "offset": 1281.76,
      "duration": 5.039
    },
    {
      "lang": "en",
      "text": "and so on. So uh if I wanted to start a",
      "offset": 1284.159,
      "duration": 5.041
    },
    {
      "lang": "en",
      "text": "new project using the same uh you know",
      "offset": 1286.799,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "the same docker container that the the",
      "offset": 1289.2,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "another project was in it's really easy",
      "offset": 1292.559,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "to do that. And so you know it's when",
      "offset": 1294.08,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "you have a new data scientist join your",
      "offset": 1296.24,
      "duration": 2.88
    },
    {
      "lang": "en",
      "text": "team. They don't have to spend their",
      "offset": 1297.76,
      "duration": 3.039
    },
    {
      "lang": "en",
      "text": "first week getting their getting Python",
      "offset": 1299.12,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "installed and making sure everything oh",
      "offset": 1300.799,
      "duration": 6.721
    },
    {
      "lang": "en",
      "text": "we use numpy 0.19 and you got 0.23 23",
      "offset": 1303.28,
      "duration": 5.84
    },
    {
      "lang": "en",
      "text": "installed and like none of those",
      "offset": 1307.52,
      "duration": 3.08
    },
    {
      "lang": "en",
      "text": "conversations have to really happen",
      "offset": 1309.12,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "anymore because we manage all of that.",
      "offset": 1310.6,
      "duration": 5.079
    },
    {
      "lang": "en",
      "text": "Uh and then let's say that I did train",
      "offset": 1313.44,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "like a random forest. I mean you",
      "offset": 1315.679,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "mentioned using your weights like if I",
      "offset": 1317.28,
      "duration": 3.279
    },
    {
      "lang": "en",
      "text": "train a you know a linear model or a",
      "offset": 1318.799,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "logistic regression or something then",
      "offset": 1320.559,
      "duration": 2.881
    },
    {
      "lang": "en",
      "text": "maybe it's just a vector of weights that",
      "offset": 1321.919,
      "duration": 3.361
    },
    {
      "lang": "en",
      "text": "need to be handed off but if it's a more",
      "offset": 1323.44,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "complicated model like a random forest",
      "offset": 1325.28,
      "duration": 3.759
    },
    {
      "lang": "en",
      "text": "or an XG boost or a neural network or",
      "offset": 1327.12,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "something like that it's not as simple",
      "offset": 1329.039,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "as just like here's some weights to put",
      "offset": 1330.72,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "into a formula. uh you know it's a more",
      "offset": 1332.559,
      "duration": 4.801
    },
    {
      "lang": "en",
      "text": "complex thing and so then you've got to",
      "offset": 1334.88,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "figure out okay I'm going to serialize",
      "offset": 1337.36,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "this model you know pickle it and then",
      "offset": 1339.2,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "and then dump all the dependencies out",
      "offset": 1341.6,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "and dockerize it and then hand that",
      "offset": 1343.52,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "thing off and like that's also beyond",
      "offset": 1345.44,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "the skill set of a lot of data",
      "offset": 1348,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "scientists too so observe handles all of",
      "offset": 1349.36,
      "duration": 4.559
    },
    {
      "lang": "en",
      "text": "that so every block inside observe when",
      "offset": 1351.919,
      "duration": 4.481
    },
    {
      "lang": "en",
      "text": "you execute it creates serialized",
      "offset": 1353.919,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "versions of all of the variables that",
      "offset": 1356.4,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "you've that you've worked through uh so",
      "offset": 1358.159,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "if I train a random forest in a model or",
      "offset": 1360,
      "duration": 3.799
    },
    {
      "lang": "en",
      "text": "in a",
      "offset": 1362.48,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "then it's there and it's accessible. So",
      "offset": 1363.799,
      "duration": 6.36
    },
    {
      "lang": "en",
      "text": "I can I could access it from external to",
      "offset": 1366.96,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "to Zer using like an API. I can",
      "offset": 1370.159,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "reference it in other layers. Uh so when",
      "offset": 1372.64,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "it comes time to say make an API, maybe",
      "offset": 1375.039,
      "duration": 4.721
    },
    {
      "lang": "en",
      "text": "I want to make a a post route where I",
      "offset": 1377.12,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "send in a payload of of predictor",
      "offset": 1379.76,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "columns. Uh and then I want a a",
      "offset": 1382.24,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "prediction back from that random forest.",
      "offset": 1384.72,
      "duration": 2.88
    },
    {
      "lang": "en",
      "text": "Well, then I just say, &quot;Hey, remember",
      "offset": 1386.4,
      "duration": 2.88
    },
    {
      "lang": "en",
      "text": "that random forest?&quot; and I just point at",
      "offset": 1387.6,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "it instead of having to figure out, you",
      "offset": 1389.28,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "know, like how to package that thing up",
      "offset": 1391.36,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "so that it could be be deployed as a as",
      "offset": 1393.2,
      "duration": 6.32
    },
    {
      "lang": "en",
      "text": "an API. So we we uh we handle all of",
      "offset": 1395.52,
      "duration": 5.92
    },
    {
      "lang": "en",
      "text": "that stuff. Uh and then when you deploy",
      "offset": 1399.52,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "in serve, you also don't have to worry",
      "offset": 1401.44,
      "duration": 2.479
    },
    {
      "lang": "en",
      "text": "about the infrastructure stuff because",
      "offset": 1402.72,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "all of our APIs utilize lambdas uh like",
      "offset": 1403.919,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "serverless technology again. So you",
      "offset": 1406.72,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "don't have like longunning uh services",
      "offset": 1408.32,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "that are that are out there. Uh it just,",
      "offset": 1410.4,
      "duration": 4.639
    },
    {
      "lang": "en",
      "text": "you know, it's just there. So a lot of",
      "offset": 1413.12,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "the the infrastructure stuff and the",
      "offset": 1415.039,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "DevOps stuff and the uh you know the the",
      "offset": 1417.12,
      "duration": 5.439
    },
    {
      "lang": "en",
      "text": "kind of picky engineering stuff that can",
      "offset": 1420.159,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "trip you up is stuff that we've just",
      "offset": 1422.559,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "sort of handled so that it's easy for",
      "offset": 1424.48,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "the user and that means that data",
      "offset": 1426.64,
      "duration": 4.039
    },
    {
      "lang": "en",
      "text": "scientists can start to deploy their own",
      "offset": 1428.559,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "stuff. Uh but in or in some",
      "offset": 1430.679,
      "duration": 3.721
    },
    {
      "lang": "en",
      "text": "organizations they still might not be",
      "offset": 1432.88,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "allowed. So then we have like a handoff",
      "offset": 1434.4,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "system where it's really easy to take",
      "offset": 1436.72,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "something that a data scientist has done",
      "offset": 1438.88,
      "duration": 2.96
    },
    {
      "lang": "en",
      "text": "who by the way aren't building",
      "offset": 1440.72,
      "duration": 2.48
    },
    {
      "lang": "en",
      "text": "prototypes anymore. Now they're building",
      "offset": 1441.84,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "software that can actually be uh",
      "offset": 1443.2,
      "duration": 4.479
    },
    {
      "lang": "en",
      "text": "deployed uh in Zerve and we can hand",
      "offset": 1445.28,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "that off to uh to to other teams to",
      "offset": 1447.679,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "actually do the the the deployments. My",
      "offset": 1450.48,
      "duration": 6.24
    },
    {
      "lang": "en",
      "text": "next clip is from episode 875 with Kai",
      "offset": 1453.279,
      "duration": 5.841
    },
    {
      "lang": "en",
      "text": "Beckman. Kai is an expert on something I",
      "offset": 1456.72,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "hadn't previously heard of called",
      "offset": 1459.12,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "heterogeneous integration. And I wanted",
      "offset": 1460.559,
      "duration": 5.441
    },
    {
      "lang": "en",
      "text": "to know how does this capability power",
      "offset": 1463.52,
      "duration": 5.039
    },
    {
      "lang": "en",
      "text": "up AI chips? When we were doing research",
      "offset": 1466,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "about you, we uncovered the something",
      "offset": 1468.559,
      "duration": 5.041
    },
    {
      "lang": "en",
      "text": "called heterogeneous integration in AI",
      "offset": 1471.44,
      "duration": 4.68
    },
    {
      "lang": "en",
      "text": "chips. So what is heterogeneous",
      "offset": 1473.6,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "integration and how does it impact",
      "offset": 1476.12,
      "duration": 5.08
    },
    {
      "lang": "en",
      "text": "performance and the packaging density of",
      "offset": 1478.88,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "AI chips? This density thing being",
      "offset": 1481.2,
      "duration": 4.479
    },
    {
      "lang": "en",
      "text": "critical to building more more and more",
      "offset": 1483.36,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "powerful chips because obviously the",
      "offset": 1485.679,
      "duration": 2.961
    },
    {
      "lang": "en",
      "text": "more transistors you can get in a",
      "offset": 1486.96,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "smaller space um the more powerful a",
      "offset": 1488.64,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "chip can be. Yeah, that that's an",
      "offset": 1490.88,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "important um area and I called it",
      "offset": 1492.48,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "earlier in the in our in our",
      "offset": 1494.24,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "conversation. So this is like what is",
      "offset": 1495.76,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "more than ma. So what dimension drives",
      "offset": 1498.48,
      "duration": 5.92
    },
    {
      "lang": "en",
      "text": "uh drives uh performance or allows to",
      "offset": 1501.36,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "scale performance beyond just making",
      "offset": 1504.4,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "smaller transistors on on a chip. This",
      "offset": 1507.12,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "is the addition additional dimension",
      "offset": 1509.2,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "driven driven by by heterogeneous",
      "offset": 1511.52,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "integration. And maybe let me just",
      "offset": 1513.44,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "quickly with a sentence come back to um",
      "offset": 1516.24,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "the AI for AI. So we call that we have",
      "offset": 1518.72,
      "duration": 5.439
    },
    {
      "lang": "en",
      "text": "like branded it a way that we call that",
      "offset": 1521.52,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "materials intelligence. This is the use",
      "offset": 1524.159,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "of artificial intelligence to drive the",
      "offset": 1526.48,
      "duration": 6.799
    },
    {
      "lang": "en",
      "text": "development of novel materials uh for",
      "offset": 1529.919,
      "duration": 6.481
    },
    {
      "lang": "en",
      "text": "applications in in um in in electronics.",
      "offset": 1533.279,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "We call that materials intelligence. And",
      "offset": 1536.4,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "this is bit how our team uh works um as",
      "offset": 1538.159,
      "duration": 5.601
    },
    {
      "lang": "en",
      "text": "a global R&amp;D team. not just in a",
      "offset": 1541.2,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "traditional way sequentially improving",
      "offset": 1543.76,
      "duration": 6.64
    },
    {
      "lang": "en",
      "text": "uh properties of materials by using AI",
      "offset": 1546.72,
      "duration": 6.88
    },
    {
      "lang": "en",
      "text": "to replace experiments in order to kind",
      "offset": 1550.4,
      "duration": 6.96
    },
    {
      "lang": "en",
      "text": "of avoid um yeah unnecessary experiments",
      "offset": 1553.6,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "and going straight into where it really",
      "offset": 1557.36,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "matters. Where can you really make an",
      "offset": 1559.36,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "make a difference for the customer",
      "offset": 1560.96,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "technology? How can you anticipate how a",
      "offset": 1562.96,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "material works in a customer setup and",
      "offset": 1565.6,
      "duration": 5.199
    },
    {
      "lang": "en",
      "text": "and how does it drive the solution of",
      "offset": 1568.08,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "their problems and not just uh chemicals",
      "offset": 1570.799,
      "duration": 4.801
    },
    {
      "lang": "en",
      "text": "properties in in a in a in in in the",
      "offset": 1573.36,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "first in in the first um glance. So this",
      "offset": 1575.6,
      "duration": 5.439
    },
    {
      "lang": "en",
      "text": "is how we drive um the the the",
      "offset": 1578.24,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "development of novel materials. We talk",
      "offset": 1581.039,
      "duration": 4.801
    },
    {
      "lang": "en",
      "text": "about millions of different options that",
      "offset": 1582.72,
      "duration": 5.439
    },
    {
      "lang": "en",
      "text": "need to be optimized in order to drive",
      "offset": 1585.84,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "the the performance of of material. So",
      "offset": 1588.159,
      "duration": 4.241
    },
    {
      "lang": "en",
      "text": "this just to give you the idea on how",
      "offset": 1590.4,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "that blends into AI for AI. Second is",
      "offset": 1592.4,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "then driving the different aspects of",
      "offset": 1595.6,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "how our our customers um improve the",
      "offset": 1597.6,
      "duration": 6.4
    },
    {
      "lang": "en",
      "text": "performance of their devices and besides",
      "offset": 1600.72,
      "duration": 6.8
    },
    {
      "lang": "en",
      "text": "shrinking the transistor um building",
      "offset": 1604,
      "duration": 5.919
    },
    {
      "lang": "en",
      "text": "more integrated systems and",
      "offset": 1607.52,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "heterogeneous integration is the",
      "offset": 1609.919,
      "duration": 4.481
    },
    {
      "lang": "en",
      "text": "important area here. You know it started",
      "offset": 1612.4,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "traditionally with which uh with what is",
      "offset": 1614.4,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "called kind of a front end process",
      "offset": 1616.96,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "making a transistor and back end was",
      "offset": 1619.2,
      "duration": 5.599
    },
    {
      "lang": "en",
      "text": "then you wire it somehow that at the end",
      "offset": 1621.84,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "um the signal gets to um to the outside",
      "offset": 1624.799,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "which is then called in a broader scheme",
      "offset": 1627.6,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "packaging. Now there's something between",
      "offset": 1629.919,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "these two extremes that it's called",
      "offset": 1631.919,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "heterogeneous integration when at the",
      "offset": 1633.679,
      "duration": 5.761
    },
    {
      "lang": "en",
      "text": "end the chip is not just one die one one",
      "offset": 1636.559,
      "duration": 5.761
    },
    {
      "lang": "en",
      "text": "single chip anymore when you combine",
      "offset": 1639.44,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "different chips to a system and I refer",
      "offset": 1642.32,
      "duration": 5.839
    },
    {
      "lang": "en",
      "text": "to it in the in this specific example as",
      "offset": 1645.2,
      "duration": 6.68
    },
    {
      "lang": "en",
      "text": "kovas this these these structures being",
      "offset": 1648.159,
      "duration": 6.561
    },
    {
      "lang": "en",
      "text": "built in the examples I've used I can",
      "offset": 1651.88,
      "duration": 5
    },
    {
      "lang": "en",
      "text": "use different customer examples here as",
      "offset": 1654.72,
      "duration": 5.199
    },
    {
      "lang": "en",
      "text": "well just wanted to use one nomenclature",
      "offset": 1656.88,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "which is u pretty common in in in a",
      "offset": 1659.919,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "current in a current conversation. This",
      "offset": 1662.48,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "is when um you you glue dyes on top of",
      "offset": 1664,
      "duration": 4.799
    },
    {
      "lang": "en",
      "text": "one another in order to build memory",
      "offset": 1667.2,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "stacks, for example, or you build a",
      "offset": 1668.799,
      "duration": 5.041
    },
    {
      "lang": "en",
      "text": "memory stack and you you kind of almost",
      "offset": 1671.6,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "glue it next to a GPU in order to",
      "offset": 1673.84,
      "duration": 6.079
    },
    {
      "lang": "en",
      "text": "shorten uh the the the transfer of data",
      "offset": 1676.72,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "and to make it more efficient in in",
      "offset": 1679.919,
      "duration": 4.561
    },
    {
      "lang": "en",
      "text": "getting the data to the GPU and and that",
      "offset": 1681.76,
      "duration": 4.639
    },
    {
      "lang": "en",
      "text": "is called heterogeneous integration to",
      "offset": 1684.48,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "make that possible and and it requires",
      "offset": 1686.399,
      "duration": 5.041
    },
    {
      "lang": "en",
      "text": "of course technologies well advanced",
      "offset": 1688.72,
      "duration": 5
    },
    {
      "lang": "en",
      "text": "from what was used in packaging",
      "offset": 1691.44,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "historically. So much smaller structure",
      "offset": 1693.72,
      "duration": 6.679
    },
    {
      "lang": "en",
      "text": "sizes, much more complicated um efforts",
      "offset": 1696.72,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "to get your heat out of the system as",
      "offset": 1700.399,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "one example or to optimize power",
      "offset": 1702.32,
      "duration": 3.8
    },
    {
      "lang": "en",
      "text": "consumption. The",
      "offset": 1704.399,
      "duration": 5.201
    },
    {
      "lang": "en",
      "text": "precision required then needs different",
      "offset": 1706.12,
      "duration": 6.32
    },
    {
      "lang": "en",
      "text": "technologies more front end like",
      "offset": 1709.6,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "technologies and which is makes it an",
      "offset": 1712.44,
      "duration": 5.08
    },
    {
      "lang": "en",
      "text": "area of course for materials innovations",
      "offset": 1715.2,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "and for mrology innovation. Um, as per",
      "offset": 1717.52,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "what our company is focused on, widening",
      "offset": 1720.72,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "the capabilities of realworld",
      "offset": 1722.96,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "applications is a must for new AI",
      "offset": 1724.799,
      "duration": 4.961
    },
    {
      "lang": "en",
      "text": "product developers and AI product",
      "offset": 1727.52,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "manager Sherish Gupta has come up with",
      "offset": 1729.76,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "the easy to remember pneummonic AI PC to",
      "offset": 1731.84,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "help you determine whether your",
      "offset": 1735.52,
      "duration": 3.519
    },
    {
      "lang": "en",
      "text": "particular application might be ideally",
      "offset": 1736.96,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "suited to local inference with an AI PC,",
      "offset": 1739.039,
      "duration": 5.921
    },
    {
      "lang": "en",
      "text": "an artificial intelligence personal",
      "offset": 1742.64,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "computer, as opposed to relying on cloud",
      "offset": 1744.96,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "compute. Here's my final, in case you",
      "offset": 1748,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "missed it, clip coming from episode 877.",
      "offset": 1750.32,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "So, we're talking about taking",
      "offset": 1753.44,
      "duration": 4.479
    },
    {
      "lang": "en",
      "text": "capabilities that today might require",
      "offset": 1755.36,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "you to have an internet connection and",
      "offset": 1757.919,
      "duration": 6.561
    },
    {
      "lang": "en",
      "text": "depend upon some cloud service in order",
      "offset": 1760.64,
      "duration": 6.48
    },
    {
      "lang": "en",
      "text": "to get some kind of like say large",
      "offset": 1764.48,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "language model or other foundation model",
      "offset": 1767.12,
      "duration": 4.559
    },
    {
      "lang": "en",
      "text": "capability. But instead with an MPU, you",
      "offset": 1768.88,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "could potentially have the operations,",
      "offset": 1771.679,
      "duration": 4.801
    },
    {
      "lang": "en",
      "text": "the inference time calls instead of",
      "offset": 1774.24,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "going out over the internet uh and using",
      "offset": 1776.48,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "cloud cloud compute. You can have it",
      "offset": 1779.44,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "running locally on device. So you're",
      "offset": 1781.52,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "also probably going to get get lower",
      "offset": 1784,
      "duration": 4.559
    },
    {
      "lang": "en",
      "text": "latency. You have fewer dependencies. Uh",
      "offset": 1785.44,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "yeah, talk us through some of the other",
      "offset": 1788.559,
      "duration": 5.681
    },
    {
      "lang": "en",
      "text": "advantages of being able to now do this",
      "offset": 1790.08,
      "duration": 5.599
    },
    {
      "lang": "en",
      "text": "do things on edge instead of having",
      "offset": 1794.24,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "cloud reliance. Yeah, I think you this a",
      "offset": 1795.679,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "perfect segue. In fact, this is a",
      "offset": 1798.48,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "pneummonic that I came up with myself.",
      "offset": 1799.84,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "The term that is being thrown around for",
      "offset": 1802.32,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "these devices with NPUs is an AIPC.",
      "offset": 1803.919,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "Sure, you heard of it, right? So to",
      "offset": 1806.72,
      "duration": 4.52
    },
    {
      "lang": "en",
      "text": "think about the benefits of an",
      "offset": 1809.039,
      "duration": 4.561
    },
    {
      "lang": "en",
      "text": "AIPC, I've I've created a pneummonic",
      "offset": 1811.24,
      "duration": 5.319
    },
    {
      "lang": "en",
      "text": "with with those four letters. So A is",
      "offset": 1813.6,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "accelerated.",
      "offset": 1816.559,
      "duration": 3.201
    },
    {
      "lang": "en",
      "text": "It's basically you have now a local",
      "offset": 1818.08,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "hardware accelerator that gives you that",
      "offset": 1819.76,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "low latency real-time um you know",
      "offset": 1821.52,
      "duration": 6.759
    },
    {
      "lang": "en",
      "text": "performance for things like",
      "offset": 1825.36,
      "duration": 5.919
    },
    {
      "lang": "en",
      "text": "translation transcription captioning",
      "offset": 1828.279,
      "duration": 5.241
    },
    {
      "lang": "en",
      "text": "where you know and other use cases where",
      "offset": 1831.279,
      "duration": 4.481
    },
    {
      "lang": "en",
      "text": "latency is super important for",
      "offset": 1833.52,
      "duration": 6.279
    },
    {
      "lang": "en",
      "text": "persistent workloads. So that's a I is",
      "offset": 1835.76,
      "duration": 6.08
    },
    {
      "lang": "en",
      "text": "individualized. Again, this is great",
      "offset": 1839.799,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "because if you have an AI that",
      "offset": 1841.84,
      "duration": 6.319
    },
    {
      "lang": "en",
      "text": "is on your box, it has the ability to",
      "offset": 1844.279,
      "duration": 5.241
    },
    {
      "lang": "en",
      "text": "learn your styles. Let's say if you're",
      "offset": 1848.159,
      "duration": 3.041
    },
    {
      "lang": "en",
      "text": "creating emails, if you're using it to",
      "offset": 1849.52,
      "duration": 3.279
    },
    {
      "lang": "en",
      "text": "generate emails, it's learning your",
      "offset": 1851.2,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "styles. It starts writing in your style.",
      "offset": 1852.799,
      "duration": 4.801
    },
    {
      "lang": "en",
      "text": "It's great for um you know, we had we",
      "offset": 1855.36,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "had a a healthcare customer that we've",
      "offset": 1857.6,
      "duration": 6.48
    },
    {
      "lang": "en",
      "text": "been working with on a use case where uh",
      "offset": 1860.32,
      "duration": 8.16
    },
    {
      "lang": "en",
      "text": "you know, they were um there's two parts",
      "offset": 1864.08,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "to it. I'll talk about the second part.",
      "offset": 1868.48,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "The first part is even more interesting",
      "offset": 1869.84,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "but I think it's it's related to a",
      "offset": 1871.84,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "different u example that we'll come back",
      "offset": 1873.6,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "to later. But the second part of the AI",
      "offset": 1875.84,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "you know AI solution is that they were",
      "offset": 1879.2,
      "duration": 6.479
    },
    {
      "lang": "en",
      "text": "taking uh information from a physician's",
      "offset": 1881.6,
      "duration": 7.84
    },
    {
      "lang": "en",
      "text": "diagnosis of a patient in the ER and",
      "offset": 1885.679,
      "duration": 5.041
    },
    {
      "lang": "en",
      "text": "they were using that information to",
      "offset": 1889.44,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "autogenerate the physician's report. You",
      "offset": 1890.72,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "know mundane stuff. Physicians don't",
      "offset": 1893.2,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "like spending time on that. they'd",
      "offset": 1895.76,
      "duration": 2.96
    },
    {
      "lang": "en",
      "text": "rather go to the next patient, have that",
      "offset": 1897.12,
      "duration": 4.559
    },
    {
      "lang": "en",
      "text": "interaction um you know increase uh",
      "offset": 1898.72,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "their ability to spend time with",
      "offset": 1901.679,
      "duration": 3.521
    },
    {
      "lang": "en",
      "text": "patients. What they the feedback they",
      "offset": 1903.039,
      "duration": 5.321
    },
    {
      "lang": "en",
      "text": "gave was you know with this with this",
      "offset": 1905.2,
      "duration": 5.839
    },
    {
      "lang": "en",
      "text": "solution now that I've it started seeing",
      "offset": 1908.36,
      "duration": 5.88
    },
    {
      "lang": "en",
      "text": "the way that I'm changing and editing",
      "offset": 1911.039,
      "duration": 5.201
    },
    {
      "lang": "en",
      "text": "its initial draft. It's starting to take",
      "offset": 1914.24,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "on my style and now it's just sounds",
      "offset": 1916.24,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "like me. So, and I love it because I",
      "offset": 1919.36,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "don't have to do this report generation.",
      "offset": 1922,
      "duration": 2.96
    },
    {
      "lang": "en",
      "text": "It does it for me and I've got more time",
      "offset": 1923.6,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "for my patients. So that's the",
      "offset": 1924.96,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "individualized value. The third is P.",
      "offset": 1926.72,
      "duration": 3
    },
    {
      "lang": "en",
      "text": "It's",
      "offset": 1928.96,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "private like you said. You know, the",
      "offset": 1929.72,
      "duration": 4.439
    },
    {
      "lang": "en",
      "text": "data doesn't have to leave your device",
      "offset": 1932.24,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "and its immediate ecosystem. You don't",
      "offset": 1934.159,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "have to send it back and forth um to a,",
      "offset": 1936.64,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "you know, a public tenant or even a",
      "offset": 1939.679,
      "duration": 3.521
    },
    {
      "lang": "en",
      "text": "private tenant for that matter. You may",
      "offset": 1941.6,
      "duration": 3
    },
    {
      "lang": "en",
      "text": "have confidential",
      "offset": 1943.2,
      "duration": 4.479
    },
    {
      "lang": "en",
      "text": "information with PII that you have",
      "offset": 1944.6,
      "duration": 4.84
    },
    {
      "lang": "en",
      "text": "access to, but you don't want to merge",
      "offset": 1947.679,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "with even a private tenant, right? there",
      "offset": 1949.44,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "is sensitive information like that or",
      "offset": 1952,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "unclassified information depending on",
      "offset": 1953.76,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "your vantage point. So that inherent",
      "offset": 1956,
      "duration": 7.039
    },
    {
      "lang": "en",
      "text": "privacy and uh you know of data and the",
      "offset": 1959.76,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "inherent security of running the model",
      "offset": 1963.039,
      "duration": 5.681
    },
    {
      "lang": "en",
      "text": "locally on your device gives you that",
      "offset": 1965.12,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "assurance that you know this is more",
      "offset": 1968.72,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "private than it would be. So that's P.",
      "offset": 1970.64,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "And C, this is really important because",
      "offset": 1973.12,
      "duration": 3
    },
    {
      "lang": "en",
      "text": "I hear this from",
      "offset": 1974.88,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "customers. It is an important cost uh",
      "offset": 1976.12,
      "duration": 5.799
    },
    {
      "lang": "en",
      "text": "paradigm shift. And I'm starting to hear",
      "offset": 1979.44,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "this from some of our early, you know,",
      "offset": 1981.919,
      "duration": 5.841
    },
    {
      "lang": "en",
      "text": "maybe earliest adopters of ondevice AI.",
      "offset": 1984.32,
      "duration": 5.92
    },
    {
      "lang": "en",
      "text": "Uh which by the way is not ubiquitous",
      "offset": 1987.76,
      "duration": 4.639
    },
    {
      "lang": "en",
      "text": "today, right? In terms of enterprises",
      "offset": 1990.24,
      "duration": 4.799
    },
    {
      "lang": "en",
      "text": "building out their own AI capabilities",
      "offset": 1992.399,
      "duration": 5.041
    },
    {
      "lang": "en",
      "text": "and using ondevice accelerators or",
      "offset": 1995.039,
      "duration": 4.961
    },
    {
      "lang": "en",
      "text": "offloading that. We're we're at the tip",
      "offset": 1997.44,
      "duration": 4.479
    },
    {
      "lang": "en",
      "text": "of the spear with delro studio and we'll",
      "offset": 2000,
      "duration": 4.679
    },
    {
      "lang": "en",
      "text": "come back to that later but the early",
      "offset": 2001.919,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "adopters what they say and I had a",
      "offset": 2004.679,
      "duration": 5.161
    },
    {
      "lang": "en",
      "text": "finserve or financial services customer",
      "offset": 2007.519,
      "duration": 6.16
    },
    {
      "lang": "en",
      "text": "tell me shares my developers are using",
      "offset": 2009.84,
      "duration": 7.439
    },
    {
      "lang": "en",
      "text": "codegen um and and they're using our",
      "offset": 2013.679,
      "duration": 5.84
    },
    {
      "lang": "en",
      "text": "data center compute 15% of my data",
      "offset": 2017.279,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "center compute is going to these",
      "offset": 2019.519,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "developers that are using it for codegen",
      "offset": 2021.519,
      "duration": 5.601
    },
    {
      "lang": "en",
      "text": "or code completion or writing test cases",
      "offset": 2023.679,
      "duration": 5.161
    },
    {
      "lang": "en",
      "text": "uh unit tests what have",
      "offset": 2027.12,
      "duration": 7.399
    },
    {
      "lang": "en",
      "text": "you I have they all have PCs. Um I want",
      "offset": 2028.84,
      "duration": 10.079
    },
    {
      "lang": "en",
      "text": "to get them to an AIPC with a performant",
      "offset": 2034.519,
      "duration": 7.561
    },
    {
      "lang": "en",
      "text": "NPU so I can take that offload. I mean I",
      "offset": 2038.919,
      "duration": 5.961
    },
    {
      "lang": "en",
      "text": "can offload that compute from my from my",
      "offset": 2042.08,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "data center because they don't need",
      "offset": 2044.88,
      "duration": 5.08
    },
    {
      "lang": "en",
      "text": "H100s to do that code",
      "offset": 2047.2,
      "duration": 4.959
    },
    {
      "lang": "en",
      "text": "completion. I think I can do that with",
      "offset": 2049.96,
      "duration": 4.439
    },
    {
      "lang": "en",
      "text": "my uh with with the NPUs on your Dell",
      "offset": 2052.159,
      "duration": 6.24
    },
    {
      "lang": "en",
      "text": "devices. So that's a real opportunity as",
      "offset": 2054.399,
      "duration": 5.921
    },
    {
      "lang": "en",
      "text": "well is just because you have the",
      "offset": 2058.399,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "compute doesn't mean you should use it.",
      "offset": 2060.32,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "It's it's like the right compute uh or",
      "offset": 2062.079,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "the right engine for the right workload",
      "offset": 2064.639,
      "duration": 4.2
    },
    {
      "lang": "en",
      "text": "at the right time. Right? So there's",
      "offset": 2066.24,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "plenty of use cases where offloading",
      "offset": 2068.839,
      "duration": 6.52
    },
    {
      "lang": "en",
      "text": "from even your uh private data center to",
      "offset": 2071.76,
      "duration": 5.96
    },
    {
      "lang": "en",
      "text": "a ondevice capability makes a ton of",
      "offset": 2075.359,
      "duration": 4.961
    },
    {
      "lang": "en",
      "text": "sense. Um and then if you're actually",
      "offset": 2077.72,
      "duration": 5.72
    },
    {
      "lang": "en",
      "text": "using the cloud you're paying for every",
      "offset": 2080.32,
      "duration": 5.92
    },
    {
      "lang": "en",
      "text": "inference, right? it's tokens and and",
      "offset": 2083.44,
      "duration": 5.439
    },
    {
      "lang": "en",
      "text": "API access. So now that you've got an",
      "offset": 2086.24,
      "duration": 4.639
    },
    {
      "lang": "en",
      "text": "AIPC, there's no cost to you. You built",
      "offset": 2088.879,
      "duration": 4.52
    },
    {
      "lang": "en",
      "text": "your solution, you're using it on the",
      "offset": 2090.879,
      "duration": 5.361
    },
    {
      "lang": "en",
      "text": "device. That's it. So cost is a big",
      "offset": 2093.399,
      "duration": 5.321
    },
    {
      "lang": "en",
      "text": "factor. It's uh now you'll argue that",
      "offset": 2096.24,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "the cost of inferencing in the cloud is",
      "offset": 2098.72,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "coming down. It's scaling very fast. But",
      "offset": 2100.72,
      "duration": 4.52
    },
    {
      "lang": "en",
      "text": "again, I get back to the point that",
      "offset": 2103.52,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "it's, you know, it's the right engine",
      "offset": 2105.24,
      "duration": 6.68
    },
    {
      "lang": "en",
      "text": "for the right uh you know, use case for",
      "offset": 2109.04,
      "duration": 4.799
    },
    {
      "lang": "en",
      "text": "the at the right time. All right, that's",
      "offset": 2111.92,
      "duration": 3.439
    },
    {
      "lang": "en",
      "text": "it for today's in case you missed it",
      "offset": 2113.839,
      "duration": 3.041
    },
    {
      "lang": "en",
      "text": "episode. To be sure not to miss any of",
      "offset": 2115.359,
      "duration": 3.521
    },
    {
      "lang": "en",
      "text": "our exciting upcoming episodes,",
      "offset": 2116.88,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "subscribe to this podcast if you haven't",
      "offset": 2118.88,
      "duration": 4.479
    },
    {
      "lang": "en",
      "text": "already. But most importantly, I hope",
      "offset": 2121.04,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "you'll just keep on listening. Until",
      "offset": 2123.359,
      "duration": 3.441
    },
    {
      "lang": "en",
      "text": "next time, keep on rocking it out there",
      "offset": 2125.28,
      "duration": 2.64
    },
    {
      "lang": "en",
      "text": "and I'm looking forward to enjoying",
      "offset": 2126.8,
      "duration": 2.559
    },
    {
      "lang": "en",
      "text": "another round of the Super Data Science",
      "offset": 2127.92,
      "duration": 5.88
    },
    {
      "lang": "en",
      "text": "podcast with you very soon.",
      "offset": 2129.359,
      "duration": 4.441
    }
  ],
  "cleanText": null,
  "dumpedAt": "2025-07-21T18:43:25.290Z"
}