{
  "episodeId": "QGUUgXXhWeE",
  "channelSlug": "@falkordb",
  "title": "How to Use a Knowledge Graph Ft Yohei Nakajima",
  "publishedAt": "2025-06-19T07:16:00.000Z",
  "rawLines": [
    {
      "lang": "en",
      "text": "really nice to see familiar faces and uh",
      "offset": 0.08,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "familiar names joining us again. So,",
      "offset": 2.32,
      "duration": 3.999
    },
    {
      "lang": "en",
      "text": "thanks for being here. Uh Roy and I are",
      "offset": 4,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "actually really glad to welcome Yoi.",
      "offset": 6.319,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "He's here with us today to chat and demo",
      "offset": 8.96,
      "duration": 4.559
    },
    {
      "lang": "en",
      "text": "really cool projects that he's built. Uh",
      "offset": 11.599,
      "duration": 3.361
    },
    {
      "lang": "en",
      "text": "and we're going to take a closer look",
      "offset": 13.519,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "today at knowledge graphs. This is",
      "offset": 14.96,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "actually the fifth installment that",
      "offset": 17.119,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "we're doing in the series uh graph and",
      "offset": 19.279,
      "duration": 5.441
    },
    {
      "lang": "en",
      "text": "rag. And um before we're going to go",
      "offset": 21.52,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "into it, just a bit of an introduction.",
      "offset": 24.72,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "Uh, Falco DB is an open- source graph",
      "offset": 26.72,
      "duration": 4.559
    },
    {
      "lang": "en",
      "text": "database management system uh, designed",
      "offset": 28.8,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "to manage connected data and complex",
      "offset": 31.279,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "relationships. Uh, by representing data",
      "offset": 33.12,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "is interconnected nodes and edges, the",
      "offset": 35.44,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "system enables really efficient storage",
      "offset": 37.84,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "and super fast retrieval. There's a Q&amp;A",
      "offset": 39.6,
      "duration": 4.799
    },
    {
      "lang": "en",
      "text": "in the end uh, so you can feel free to",
      "offset": 42.48,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "send your questions in and the chat box",
      "offset": 44.399,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "below. We're going to collect them.",
      "offset": 46.64,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "Those that we can get to definitely",
      "offset": 48.32,
      "duration": 2.96
    },
    {
      "lang": "en",
      "text": "we'll get back to you over email or",
      "offset": 49.76,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "Discord. Uh but without further ado,",
      "offset": 51.28,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "let's kick things off and we'll go go",
      "offset": 53.52,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "ahead and share our screen. Not too many",
      "offset": 55.92,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "slides, a lot of uh really hands-on",
      "offset": 58.32,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "stuff. So, we're in for something really",
      "offset": 60.32,
      "duration": 5.879
    },
    {
      "lang": "en",
      "text": "interesting in my opinion.",
      "offset": 62.48,
      "duration": 3.719
    },
    {
      "lang": "en",
      "text": "Roy, do you want to share or do you want",
      "offset": 69.6,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "me to",
      "offset": 71.439,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "No, go ahead. You can share the screen.",
      "offset": 73.92,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "I think we're",
      "offset": 75.6,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "kicking things off uh with one of Yoi's",
      "offset": 77.68,
      "duration": 6.64
    },
    {
      "lang": "en",
      "text": "demos, but",
      "offset": 80.64,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "Oh, yeah. I mean, we could show the",
      "offset": 84.32,
      "duration": 3.439
    },
    {
      "lang": "en",
      "text": "title slider. We can just dive into the",
      "offset": 86.4,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "demo.",
      "offset": 87.759,
      "duration": 4.801
    },
    {
      "lang": "en",
      "text": "Uh yeah, let's go right ahead. Actually,",
      "offset": 90.32,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "the only show is VCP. So, that's",
      "offset": 92.56,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "actually the first project we want to",
      "offset": 95.28,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "show. So, let's go right ahead. Yeah,",
      "offset": 96.64,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "this is a project from a few weeks ago.",
      "offset": 99.119,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "Um uh the history is that I spend a lot",
      "offset": 101.6,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "of time on Twitter and X. That's where I",
      "offset": 104.799,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "do a lot of learning. I learn a lot",
      "offset": 106.72,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "about AI trends. Um and I and so I",
      "offset": 108.159,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "thought I would uh try building a tool",
      "offset": 111.04,
      "duration": 5.439
    },
    {
      "lang": "en",
      "text": "to capture AI trends on Twitter um using",
      "offset": 113.439,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "the Twitter API.",
      "offset": 116.479,
      "duration": 4.481
    },
    {
      "lang": "en",
      "text": "When I was running that experiment, um I",
      "offset": 118.479,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "noticed it was capturing funding rounds.",
      "offset": 120.96,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "And as a VC, knowing you know up-to-date",
      "offset": 123.439,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "information on funding rounds,",
      "offset": 126.64,
      "duration": 2.88
    },
    {
      "lang": "en",
      "text": "especially at the preede stage, which",
      "offset": 127.84,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "which you don't find on a lot of other",
      "offset": 129.52,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "uh databases, uh is important. I'm a",
      "offset": 131.28,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "preede investor and I noticed that a lot",
      "offset": 133.36,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "of preede funding rounds were being",
      "offset": 135.44,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "announced on on Twitter. So I uh had",
      "offset": 136.8,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "this idea on a Friday uh vibe coded it",
      "offset": 139.2,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "with Replet and I'm going to go ahead",
      "offset": 141.68,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "and share it with you. Um",
      "offset": 143.2,
      "duration": 7.119
    },
    {
      "lang": "en",
      "text": "it looks like this uh VCedia um the",
      "offset": 147.04,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "number of startups, investors, rounds,",
      "offset": 150.319,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "and recent funding. This is what's been",
      "offset": 152,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "captured this week. Um, here's some",
      "offset": 153.519,
      "duration": 4.561
    },
    {
      "lang": "en",
      "text": "trending startups based on social",
      "offset": 156.08,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "signals. It does capture some noise. Um,",
      "offset": 158.08,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "I'll touch on that. Uh, funding rounds",
      "offset": 161.2,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "by type, funding trends, uh, notable AI",
      "offset": 163.04,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "startups. I set up a section for that",
      "offset": 165.68,
      "duration": 2.639
    },
    {
      "lang": "en",
      "text": "cuz that's something I'm personally",
      "offset": 167.2,
      "duration": 2.72
    },
    {
      "lang": "en",
      "text": "curious about. And then you can see kind",
      "offset": 168.319,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "of the recently funded uh, added funding",
      "offset": 169.92,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "rounds. Now, if you click into one of",
      "offset": 172.16,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "the startups, for example, Pistachio,",
      "offset": 174.72,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "you know, this is the most recently",
      "offset": 176.64,
      "duration": 3.599
    },
    {
      "lang": "en",
      "text": "captured funding round. I click through",
      "offset": 177.92,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "to it, it will give me information about",
      "offset": 180.239,
      "duration": 7.561
    },
    {
      "lang": "en",
      "text": "Let's give it a second. Um,",
      "offset": 183.36,
      "duration": 4.44
    },
    {
      "lang": "en",
      "text": "it's not optimized for speed.",
      "offset": 189.04,
      "duration": 4.119
    },
    {
      "lang": "en",
      "text": "Uh, it captures information um, company",
      "offset": 194,
      "duration": 4.959
    },
    {
      "lang": "en",
      "text": "info, business info, industry tags,",
      "offset": 196.48,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "business model, similar startups, which",
      "offset": 198.959,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "is just a vector search against other",
      "offset": 200.8,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "startups in the system. Um, funding uh,",
      "offset": 202.239,
      "duration": 4.801
    },
    {
      "lang": "en",
      "text": "funding rounds it's captured on Twitter.",
      "offset": 205.2,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "Again, this doesn't go historical. It's",
      "offset": 207.04,
      "duration": 2.96
    },
    {
      "lang": "en",
      "text": "only capturing funding rounds from when",
      "offset": 208.56,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "I started this um investors uh that",
      "offset": 210,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "it'll extract and create a page for and",
      "offset": 212.959,
      "duration": 5.121
    },
    {
      "lang": "en",
      "text": "then you can see the uh actual tweets",
      "offset": 215.44,
      "duration": 5.84
    },
    {
      "lang": "en",
      "text": "where it captured the um the funding",
      "offset": 218.08,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "round",
      "offset": 221.28,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "when you go or I guess if you go back",
      "offset": 223.68,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "here and you look at you know the ones",
      "offset": 225.28,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "that are trending and let's say if I",
      "offset": 227.92,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "were to click through those those will",
      "offset": 229.68,
      "duration": 3.279
    },
    {
      "lang": "en",
      "text": "be um those are actually using social",
      "offset": 231.28,
      "duration": 2.959
    },
    {
      "lang": "en",
      "text": "signals. So if we click through to the",
      "offset": 232.959,
      "duration": 2.56
    },
    {
      "lang": "en",
      "text": "tweet you'll see that those tweets are",
      "offset": 234.239,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "getting a lot of engagement. So, the way",
      "offset": 235.519,
      "duration": 4.961
    },
    {
      "lang": "en",
      "text": "this is set up, actually, I did a little",
      "offset": 237.439,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "um",
      "offset": 240.48,
      "duration": 3.759
    },
    {
      "lang": "en",
      "text": "yes, if you click through to here, you",
      "offset": 242.799,
      "duration": 3.281
    },
    {
      "lang": "en",
      "text": "see this, you know, Twitter",
      "offset": 244.239,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "announcement. So, this one said it was",
      "offset": 246.08,
      "duration": 2.879
    },
    {
      "lang": "en",
      "text": "trending. So, if I click through, I'm",
      "offset": 247.519,
      "duration": 3.041
    },
    {
      "lang": "en",
      "text": "likely going to see that this one has a",
      "offset": 248.959,
      "duration": 2.801
    },
    {
      "lang": "en",
      "text": "decent amount of engagement. So, I'm not",
      "offset": 250.56,
      "duration": 2.56
    },
    {
      "lang": "en",
      "text": "just capturing funding rounds, but I'm",
      "offset": 251.76,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "also able to identify funding rounds",
      "offset": 253.12,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "that captured a lot of people's",
      "offset": 255.2,
      "duration": 2.48
    },
    {
      "lang": "en",
      "text": "attention. This is really helpful for",
      "offset": 256.32,
      "duration": 6.72
    },
    {
      "lang": "en",
      "text": "me. Um, I I threw the code into NLM to",
      "offset": 257.68,
      "duration": 7.12
    },
    {
      "lang": "en",
      "text": "describe how it's working is that I have",
      "offset": 263.04,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "the Twitter API, a couple search queries",
      "offset": 264.8,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "set up uh that run on a certain",
      "offset": 266.72,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "frequency. It runs through the Twitter",
      "offset": 268.4,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "client. I enhance the queries a little",
      "offset": 270.72,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "bit. You know, I don't want retweets. I",
      "offset": 272.24,
      "duration": 2.88
    },
    {
      "lang": "en",
      "text": "want to make sure they're verified just",
      "offset": 273.84,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "to remove some noise. Um, we I",
      "offset": 275.12,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "dduplicate tweets because I don't want",
      "offset": 277.68,
      "duration": 2.88
    },
    {
      "lang": "en",
      "text": "to analyze the same tweet twice. And",
      "offset": 278.88,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "then once we have a tweet object, then",
      "offset": 280.56,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "we will go through a funding detection.",
      "offset": 282.24,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "Is there a funding round? If there is,",
      "offset": 284.4,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "let's extract the information that it",
      "offset": 286.4,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "has uh which is uh information about the",
      "offset": 288.32,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "startup, the funding round, the founders",
      "offset": 290.32,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "and the investors. Um there's an entity",
      "offset": 293.36,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "resolution layer here where for all of",
      "offset": 296,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "these it will go through a dduplication",
      "offset": 298.08,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "um to see if it already uh if any of",
      "offset": 300.8,
      "duration": 3.119
    },
    {
      "lang": "en",
      "text": "these exist such as the startup, the",
      "offset": 302.4,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "founders, the investors and then once uh",
      "offset": 303.919,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "it's dduplicated then there's a data",
      "offset": 306,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "enrichment layer. You see here there's",
      "offset": 307.759,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "like SER, EXA, OpenAI. tried a couple of",
      "offset": 309.68,
      "duration": 3.519
    },
    {
      "lang": "en",
      "text": "different enrichments, but they'll",
      "offset": 311.919,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "enrich the data and then uh this all",
      "offset": 313.199,
      "duration": 5.521
    },
    {
      "lang": "en",
      "text": "gets added into the relationship tables.",
      "offset": 316.08,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "So, that's kind of VCedia um as a as a",
      "offset": 318.72,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "quick intro. I know we were going to",
      "offset": 321.52,
      "duration": 5.08
    },
    {
      "lang": "en",
      "text": "talk about this a little bit, but",
      "offset": 322.72,
      "duration": 3.88
    },
    {
      "lang": "en",
      "text": "this is very very cool. Um,",
      "offset": 326.72,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "so I would say with that background, I",
      "offset": 330.16,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "think Roy, now would be a good time to",
      "offset": 332.72,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "sort of go into a little bit about",
      "offset": 334.4,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "what's happening in the background so",
      "offset": 336.08,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "that when we're further talking about",
      "offset": 338,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "this, we can refer back and people",
      "offset": 340,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "understand sort of what we're referring",
      "offset": 342,
      "duration": 4.639
    },
    {
      "lang": "en",
      "text": "to. So I'm going to go ahead and maybe",
      "offset": 343.44,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "uh actually Yi, I'm seeing you have the",
      "offset": 346.639,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "slides open on your end. Maybe you can",
      "offset": 348.72,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "jump. I I did open them up. Perfect.",
      "offset": 350.32,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "Yeah. So essentially what we have was",
      "offset": 352.88,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "VCPedia and then we wanted to go a",
      "offset": 355.28,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "little bit into um the fundamentals of a",
      "offset": 357.44,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "knowledge graph of what's happening",
      "offset": 360.32,
      "duration": 3.439
    },
    {
      "lang": "en",
      "text": "behind the scenes which is slide number",
      "offset": 361.68,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "three. Cool.",
      "offset": 363.759,
      "duration": 7.841
    },
    {
      "lang": "en",
      "text": "Right. So thank you Yoi and uh Dan",
      "offset": 367.12,
      "duration": 6.24
    },
    {
      "lang": "en",
      "text": "um",
      "offset": 371.6,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "in a in a kind of a brief we we have",
      "offset": 373.36,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "just a few slides",
      "offset": 375.52,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "to give the audience some information",
      "offset": 377.759,
      "duration": 6.16
    },
    {
      "lang": "en",
      "text": "about what's empowering all of those new",
      "offset": 380.08,
      "duration": 6.72
    },
    {
      "lang": "en",
      "text": "applications that are coming into the",
      "offset": 383.919,
      "duration": 8.081
    },
    {
      "lang": "en",
      "text": "market and um are using LLMs and AI to",
      "offset": 386.8,
      "duration": 8.56
    },
    {
      "lang": "en",
      "text": "drive both insights but also really help",
      "offset": 392,
      "duration": 6.8
    },
    {
      "lang": "en",
      "text": "with capturing the data. uh analyzing it",
      "offset": 395.36,
      "duration": 6.959
    },
    {
      "lang": "en",
      "text": "and then uh prepare it for storage. And",
      "offset": 398.8,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "so one of the fundamental data",
      "offset": 402.319,
      "duration": 5.041
    },
    {
      "lang": "en",
      "text": "structures that are being used these",
      "offset": 404.8,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "days is a knowledge graph. And a",
      "offset": 407.36,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "knowledge graph is not a new idea. It's",
      "offset": 409.84,
      "duration": 5.919
    },
    {
      "lang": "en",
      "text": "been around for at least 10 years now,",
      "offset": 412.4,
      "duration": 7.04
    },
    {
      "lang": "en",
      "text": "but now with the explosion of Gen AI,",
      "offset": 415.759,
      "duration": 7.28
    },
    {
      "lang": "en",
      "text": "um it got the spotlight back on it. And",
      "offset": 419.44,
      "duration": 7.28
    },
    {
      "lang": "en",
      "text": "so with a knowledge graph basically you",
      "offset": 423.039,
      "duration": 5.201
    },
    {
      "lang": "en",
      "text": "have",
      "offset": 426.72,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "uh graph entities. Those are either",
      "offset": 428.24,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "nodes which represent",
      "offset": 430.88,
      "duration": 6.159
    },
    {
      "lang": "en",
      "text": "some type of an entity in your domain",
      "offset": 433.84,
      "duration": 6.079
    },
    {
      "lang": "en",
      "text": "and then you can connect those entities",
      "offset": 437.039,
      "duration": 5.761
    },
    {
      "lang": "en",
      "text": "with edges to capture the different",
      "offset": 439.919,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "relationships",
      "offset": 442.8,
      "duration": 5.519
    },
    {
      "lang": "en",
      "text": "between them. Nodes and edges can be",
      "offset": 444.319,
      "duration": 8
    },
    {
      "lang": "en",
      "text": "labeled. So you can have a label",
      "offset": 448.319,
      "duration": 6.481
    },
    {
      "lang": "en",
      "text": "representing a person and you can have",
      "offset": 452.319,
      "duration": 6.88
    },
    {
      "lang": "en",
      "text": "an edge um capturing some type of an",
      "offset": 454.8,
      "duration": 6.48
    },
    {
      "lang": "en",
      "text": "interaction for example between two",
      "offset": 459.199,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "different persons. Also you can enrich",
      "offset": 461.28,
      "duration": 7.359
    },
    {
      "lang": "en",
      "text": "the data with an attribute set and the",
      "offset": 464.479,
      "duration": 6.401
    },
    {
      "lang": "en",
      "text": "attribute set is basically you can think",
      "offset": 468.639,
      "duration": 5.361
    },
    {
      "lang": "en",
      "text": "of it as a key value storage",
      "offset": 470.88,
      "duration": 5.999
    },
    {
      "lang": "en",
      "text": "um attached to a graph entity. So for",
      "offset": 474,
      "duration": 6.4
    },
    {
      "lang": "en",
      "text": "example, a person can have an attribute",
      "offset": 476.879,
      "duration": 7.44
    },
    {
      "lang": "en",
      "text": "set containing name, maybe a zip code, a",
      "offset": 480.4,
      "duration": 7.919
    },
    {
      "lang": "en",
      "text": "birth date, um whatever information you",
      "offset": 484.319,
      "duration": 7.681
    },
    {
      "lang": "en",
      "text": "need to make the entity usable for your",
      "offset": 488.319,
      "duration": 6.88
    },
    {
      "lang": "en",
      "text": "use case. Um, and obviously there's a",
      "offset": 492,
      "duration": 6.56
    },
    {
      "lang": "en",
      "text": "variety of different data types that can",
      "offset": 495.199,
      "duration": 6.241
    },
    {
      "lang": "en",
      "text": "be used such as numerical values,",
      "offset": 498.56,
      "duration": 6.72
    },
    {
      "lang": "en",
      "text": "strings, array, vectors,",
      "offset": 501.44,
      "duration": 7.199
    },
    {
      "lang": "en",
      "text": "uh, and more. If we can move on to the",
      "offset": 505.28,
      "duration": 6.8
    },
    {
      "lang": "en",
      "text": "next slide, please.",
      "offset": 508.639,
      "duration": 6.801
    },
    {
      "lang": "en",
      "text": "Thanks. So here's a example of a more",
      "offset": 512.08,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "concrete",
      "offset": 515.44,
      "duration": 4.959
    },
    {
      "lang": "en",
      "text": "um knowledge graph in which uh the",
      "offset": 517.2,
      "duration": 7.68
    },
    {
      "lang": "en",
      "text": "domain here is uh art. I would I would",
      "offset": 520.399,
      "duration": 7.521
    },
    {
      "lang": "en",
      "text": "assume um the entities that are being",
      "offset": 524.88,
      "duration": 6.56
    },
    {
      "lang": "en",
      "text": "captured are artists such as Leonardo da",
      "offset": 527.92,
      "duration": 8.88
    },
    {
      "lang": "en",
      "text": "Vinci uh the paintings and museums and",
      "offset": 531.44,
      "duration": 8.32
    },
    {
      "lang": "en",
      "text": "so there is an interaction between those",
      "offset": 536.8,
      "duration": 5.599
    },
    {
      "lang": "en",
      "text": "different entities. So for example, an",
      "offset": 539.76,
      "duration": 8.4
    },
    {
      "lang": "en",
      "text": "artist had drawn uh uh a picture and the",
      "offset": 542.399,
      "duration": 8.241
    },
    {
      "lang": "en",
      "text": "picture might be presented",
      "offset": 548.16,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "uh at an at the museum. I think there's",
      "offset": 550.64,
      "duration": 6.16
    },
    {
      "lang": "en",
      "text": "a lot of value representing your data in",
      "offset": 553.44,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "such a way. First, it's it's very",
      "offset": 556.8,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "visual. So you can look at it and you",
      "offset": 558.64,
      "duration": 6.56
    },
    {
      "lang": "en",
      "text": "can reason about it relatively easily.",
      "offset": 561.36,
      "duration": 6.08
    },
    {
      "lang": "en",
      "text": "Second, the fact that most knowledge",
      "offset": 565.2,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "graphs or the essence of knowledge graph",
      "offset": 567.44,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "is schemalis.",
      "offset": 569.44,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "This really helps or give you the",
      "offset": 571.6,
      "duration": 4.799
    },
    {
      "lang": "en",
      "text": "flexibility that you might need when",
      "offset": 573.36,
      "duration": 6.56
    },
    {
      "lang": "en",
      "text": "representing your data. And lastly,",
      "offset": 576.399,
      "duration": 6.641
    },
    {
      "lang": "en",
      "text": "there's no restriction on the number of",
      "offset": 579.92,
      "duration": 5.599
    },
    {
      "lang": "en",
      "text": "different entities and the and the",
      "offset": 583.04,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "number of different relations that you",
      "offset": 585.519,
      "duration": 5.841
    },
    {
      "lang": "en",
      "text": "can have uh in your graph. So, you can",
      "offset": 588.08,
      "duration": 6.8
    },
    {
      "lang": "en",
      "text": "actually go quite wild with it.",
      "offset": 591.36,
      "duration": 6.72
    },
    {
      "lang": "en",
      "text": "With that said, if we can move on to the",
      "offset": 594.88,
      "duration": 5.92
    },
    {
      "lang": "en",
      "text": "uh last slide.",
      "offset": 598.08,
      "duration": 6.319
    },
    {
      "lang": "en",
      "text": "Um constructing a knowledge graph can be",
      "offset": 600.8,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "challenging.",
      "offset": 604.399,
      "duration": 6.88
    },
    {
      "lang": "en",
      "text": "Um it's not like the one of the other",
      "offset": 605.92,
      "duration": 7.76
    },
    {
      "lang": "en",
      "text": "solutions that we see uh these days with",
      "offset": 611.279,
      "duration": 5.841
    },
    {
      "lang": "en",
      "text": "vectoral databases where the ingestion",
      "offset": 613.68,
      "duration": 6.159
    },
    {
      "lang": "en",
      "text": "procedure is really straightforward but",
      "offset": 617.12,
      "duration": 7.44
    },
    {
      "lang": "en",
      "text": "extremely limited uh in terms of your",
      "offset": 619.839,
      "duration": 6.881
    },
    {
      "lang": "en",
      "text": "reasoning capabilities.",
      "offset": 624.56,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "And so these are our suggestions",
      "offset": 626.72,
      "duration": 5.359
    },
    {
      "lang": "en",
      "text": "whenever it comes to knowledge graph",
      "offset": 630.16,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "construction. First make sure that the",
      "offset": 632.079,
      "duration": 7.521
    },
    {
      "lang": "en",
      "text": "domain that you're um trying to capture",
      "offset": 634.72,
      "duration": 9.76
    },
    {
      "lang": "en",
      "text": "is well defined meaning that you try to",
      "offset": 639.6,
      "duration": 6.96
    },
    {
      "lang": "en",
      "text": "limit yourself",
      "offset": 644.48,
      "duration": 7.68
    },
    {
      "lang": "en",
      "text": "uh in a kind of a focused scope. Um so",
      "offset": 646.56,
      "duration": 8.56
    },
    {
      "lang": "en",
      "text": "once you have defined or know what type",
      "offset": 652.16,
      "duration": 5.919
    },
    {
      "lang": "en",
      "text": "of data you want to capture with like",
      "offset": 655.12,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "with every other system there's this",
      "offset": 658.079,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "phase of data collection and data",
      "offset": 660.24,
      "duration": 7.599
    },
    {
      "lang": "en",
      "text": "cleaning and that could go to an extent",
      "offset": 663.519,
      "duration": 7.521
    },
    {
      "lang": "en",
      "text": "uh or you can just work with the data",
      "offset": 667.839,
      "duration": 5.281
    },
    {
      "lang": "en",
      "text": "that you have without performing any",
      "offset": 671.04,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "cleaning really depends on how are you",
      "offset": 673.12,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "ingesting the data.",
      "offset": 676.32,
      "duration": 6.079
    },
    {
      "lang": "en",
      "text": "Um so after data had been collected and",
      "offset": 678.64,
      "duration": 7.12
    },
    {
      "lang": "en",
      "text": "clean what we suggest that really uh",
      "offset": 682.399,
      "duration": 7.12
    },
    {
      "lang": "en",
      "text": "helps LLMs to interact with your data is",
      "offset": 685.76,
      "duration": 6.639
    },
    {
      "lang": "en",
      "text": "to define the semantics and usually that",
      "offset": 689.519,
      "duration": 6.161
    },
    {
      "lang": "en",
      "text": "means defining a clear ontology and I'm",
      "offset": 692.399,
      "duration": 6.641
    },
    {
      "lang": "en",
      "text": "sorry for using this terminology",
      "offset": 695.68,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "um I I would try to keep it simple",
      "offset": 699.04,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "basically an ontology is a schema for of",
      "offset": 701.12,
      "duration": 6.959
    },
    {
      "lang": "en",
      "text": "your data uh something that you might be",
      "offset": 704.48,
      "duration": 6.32
    },
    {
      "lang": "en",
      "text": "famili familiar with with the relational",
      "offset": 708.079,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "model. Uh it's basically a schema for",
      "offset": 710.8,
      "duration": 5.84
    },
    {
      "lang": "en",
      "text": "your graph. Although I I said just a few",
      "offset": 713.839,
      "duration": 5.921
    },
    {
      "lang": "en",
      "text": "minutes ago that um N graph are",
      "offset": 716.64,
      "duration": 6.56
    },
    {
      "lang": "en",
      "text": "schemalas, there is value in following a",
      "offset": 719.76,
      "duration": 6.879
    },
    {
      "lang": "en",
      "text": "strict schema um later on in the",
      "offset": 723.2,
      "duration": 6.319
    },
    {
      "lang": "en",
      "text": "retrieval phases of your application.",
      "offset": 726.639,
      "duration": 5.521
    },
    {
      "lang": "en",
      "text": "And so this is where you're saying, oh",
      "offset": 729.519,
      "duration": 6.481
    },
    {
      "lang": "en",
      "text": "my graph contains a person and a person",
      "offset": 732.16,
      "duration": 7.52
    },
    {
      "lang": "en",
      "text": "is is associated with these attributes.",
      "offset": 736,
      "duration": 7.68
    },
    {
      "lang": "en",
      "text": "A person uh might have edges coming into",
      "offset": 739.68,
      "duration": 7.2
    },
    {
      "lang": "en",
      "text": "it or going out of it of these specific",
      "offset": 743.68,
      "duration": 5.92
    },
    {
      "lang": "en",
      "text": "types and maybe some of these",
      "offset": 746.88,
      "duration": 5.92
    },
    {
      "lang": "en",
      "text": "relationship types are also associated",
      "offset": 749.6,
      "duration": 6.239
    },
    {
      "lang": "en",
      "text": "with some attributes. So this is the",
      "offset": 752.8,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "ontology",
      "offset": 755.839,
      "duration": 4.881
    },
    {
      "lang": "en",
      "text": "uh defining my graph. Once you have the",
      "offset": 757.44,
      "duration": 6.16
    },
    {
      "lang": "en",
      "text": "ontology and your data, it's time to",
      "offset": 760.72,
      "duration": 6.08
    },
    {
      "lang": "en",
      "text": "ingest uh meaning pushing the data into",
      "offset": 763.6,
      "duration": 7.44
    },
    {
      "lang": "en",
      "text": "your graph. And lastly, doing uh some",
      "offset": 766.8,
      "duration": 7.599
    },
    {
      "lang": "en",
      "text": "validations, making sure that the",
      "offset": 771.04,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "knowledge that is being captured is",
      "offset": 774.399,
      "duration": 4.481
    },
    {
      "lang": "en",
      "text": "really valuable. And for example, if",
      "offset": 776.24,
      "duration": 5.839
    },
    {
      "lang": "en",
      "text": "you're using an LLM to query your",
      "offset": 778.88,
      "duration": 6.56
    },
    {
      "lang": "en",
      "text": "knowledge graph, uh that the accuracy of",
      "offset": 782.079,
      "duration": 6.801
    },
    {
      "lang": "en",
      "text": "the results for different questions that",
      "offset": 785.44,
      "duration": 7.959
    },
    {
      "lang": "en",
      "text": "you're asking is satisfied.",
      "offset": 788.88,
      "duration": 4.519
    },
    {
      "lang": "en",
      "text": "Uh you can move on to the next slide.",
      "offset": 794.56,
      "duration": 4.36
    },
    {
      "lang": "en",
      "text": "Cool. Um actually before we jump into",
      "offset": 800.88,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "Fractal KG I think just applying it to",
      "offset": 802.959,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "to VCPedia obviously in the case of",
      "offset": 804.72,
      "duration": 6.559
    },
    {
      "lang": "en",
      "text": "VCPedia the the the domain is is",
      "offset": 807.12,
      "duration": 6.399
    },
    {
      "lang": "en",
      "text": "startups funding right um data",
      "offset": 811.279,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "collections happening on Twitter in this",
      "offset": 813.519,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "case there is a very clear ontology",
      "offset": 815.36,
      "duration": 3.039
    },
    {
      "lang": "en",
      "text": "right it's the the funding round",
      "offset": 817.12,
      "duration": 2.64
    },
    {
      "lang": "en",
      "text": "relationship with people people",
      "offset": 818.399,
      "duration": 3.361
    },
    {
      "lang": "en",
      "text": "relationship with startups uh and I",
      "offset": 819.76,
      "duration": 5.199
    },
    {
      "lang": "en",
      "text": "think the the uh um for me at least I",
      "offset": 821.76,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "found that using structured output with",
      "offset": 824.959,
      "duration": 4.241
    },
    {
      "lang": "en",
      "text": "LLM is a great way to get the structured",
      "offset": 826.72,
      "duration": 4.799
    },
    {
      "lang": "en",
      "text": "data out of your unstructured data you",
      "offset": 829.2,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "can essentially use the ontology that he",
      "offset": 831.519,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "was describing and what I essentially do",
      "offset": 833.44,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "is turn that ontology into the",
      "offset": 835.519,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "structured output format uh to to get",
      "offset": 837.44,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "the data and then the validation step I",
      "offset": 839.68,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "think is is the one where I think uh um",
      "offset": 841.76,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "you know mine could use a little more",
      "offset": 844.24,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "work but uh uh we were talking about",
      "offset": 845.839,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "this the other day uh my strategy has",
      "offset": 847.68,
      "duration": 4.959
    },
    {
      "lang": "en",
      "text": "has mostly been to um every time you add",
      "offset": 850.079,
      "duration": 5.361
    },
    {
      "lang": "en",
      "text": "a node or relationship look for similar",
      "offset": 852.639,
      "duration": 5.121
    },
    {
      "lang": "en",
      "text": "nodes and then most recently I've been",
      "offset": 855.44,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "feeding those similar nodes and new node",
      "offset": 857.76,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "into an LLM and having the LLM decide.",
      "offset": 859.519,
      "duration": 4.721
    },
    {
      "lang": "en",
      "text": "Uh but but I think you can go even",
      "offset": 862.32,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "further and do kind of deterministic",
      "offset": 864.24,
      "duration": 3.599
    },
    {
      "lang": "en",
      "text": "validation. If it's the exact same",
      "offset": 866.32,
      "duration": 2.8
    },
    {
      "lang": "en",
      "text": "domain, then then they're the same",
      "offset": 867.839,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "entity and so on. So So yeah, that's",
      "offset": 869.12,
      "duration": 7.24
    },
    {
      "lang": "en",
      "text": "basically exactly how VC VCID was built,",
      "offset": 871.279,
      "duration": 5.081
    },
    {
      "lang": "en",
      "text": "right?",
      "offset": 876.48,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "Um",
      "offset": 878.079,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "I know the next one we uh we were going",
      "offset": 879.6,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "to talk about is Fractal KG. Um I think",
      "offset": 881.519,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "before I jump in um I was going to",
      "offset": 883.44,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "quickly just share uh that I've been",
      "offset": 885.36,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "trying to",
      "offset": 888,
      "duration": 4.639
    },
    {
      "lang": "en",
      "text": "you know I I think I started exploring",
      "offset": 889.92,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "knowledge graphs initially when I right",
      "offset": 892.639,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "after I built baby AGI I had a couple",
      "offset": 894.24,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "people reach out saying you should look",
      "offset": 896.639,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "at knowledge graphs you'll like it. Um",
      "offset": 898.079,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "after enough time I thought okay I'll",
      "offset": 900.079,
      "duration": 3.041
    },
    {
      "lang": "en",
      "text": "take a look and then immediately",
      "offset": 901.68,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "clicked. um it just felt like a very um",
      "offset": 903.12,
      "duration": 6.159
    },
    {
      "lang": "en",
      "text": "intuitive and natural way for AI to to",
      "offset": 905.92,
      "duration": 5.919
    },
    {
      "lang": "en",
      "text": "kind of traverse data, right? Um if you",
      "offset": 909.279,
      "duration": 6.321
    },
    {
      "lang": "en",
      "text": "think about uh um you know VCedia, if I",
      "offset": 911.839,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "have a startup, right? Being able to",
      "offset": 915.6,
      "duration": 4.239
    },
    {
      "lang": "en",
      "text": "just like for the AI to be able to pull",
      "offset": 917.519,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "just all the edges related to that",
      "offset": 919.839,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "startup is a fantastic way to pull all",
      "offset": 921.519,
      "duration": 4.241
    },
    {
      "lang": "en",
      "text": "the context. If you were to do that with",
      "offset": 923.92,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "relational tables, you essentially have",
      "offset": 925.76,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "to find the relationship mapping between",
      "offset": 927.44,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "the startup and each table that exists.",
      "offset": 929.839,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "You have to find the relationship in the",
      "offset": 932,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "startup people table. Search through the",
      "offset": 933.44,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "people table for all people that match",
      "offset": 935.68,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "that startup. Then you go to the startup",
      "offset": 937.44,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "funding round relationship mapping and",
      "offset": 939.519,
      "duration": 2.88
    },
    {
      "lang": "en",
      "text": "then go through all the funding rounds",
      "offset": 941.12,
      "duration": 2.399
    },
    {
      "lang": "en",
      "text": "and then grab all the funding rounds",
      "offset": 942.399,
      "duration": 3.041
    },
    {
      "lang": "en",
      "text": "that match the startup and then you go",
      "offset": 943.519,
      "duration": 3.361
    },
    {
      "lang": "en",
      "text": "through all the investors that map",
      "offset": 945.44,
      "duration": 3.759
    },
    {
      "lang": "en",
      "text": "versus just being able to pull edges. To",
      "offset": 946.88,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "me intuitively made more sense. So I've",
      "offset": 949.199,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "been playing around. I've tried a couple",
      "offset": 950.88,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "of approaches",
      "offset": 952.88,
      "duration": 5.199
    },
    {
      "lang": "en",
      "text": "on what it's now called graph rag. Uh",
      "offset": 954.88,
      "duration": 5.519
    },
    {
      "lang": "en",
      "text": "the first one I tried was looked like",
      "offset": 958.079,
      "duration": 4.481
    },
    {
      "lang": "en",
      "text": "this. This was called mind graph and and",
      "offset": 960.399,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "the key really here was this kind of add",
      "offset": 962.56,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "multiple conditional. The the big big",
      "offset": 964.32,
      "duration": 3.199
    },
    {
      "lang": "en",
      "text": "thing about building these massive",
      "offset": 966.32,
      "duration": 2.24
    },
    {
      "lang": "en",
      "text": "knowledge graph is really in the",
      "offset": 967.519,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "dduping. So so this is where I had the",
      "offset": 968.56,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "add multiple edges and rows",
      "offset": 971.199,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "conditionally. There's a conditional",
      "offset": 973.36,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "entity edition which was the kind of",
      "offset": 975.279,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "ddup and add um and that was a while",
      "offset": 977.04,
      "duration": 6.479
    },
    {
      "lang": "en",
      "text": "ago. It was pretty beefy code. I then",
      "offset": 980.639,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "tried a more recent one earlier this",
      "offset": 983.519,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "year. This is not yet fractal kg. I",
      "offset": 985.279,
      "duration": 4.881
    },
    {
      "lang": "en",
      "text": "called it graphista. Um this was I was",
      "offset": 987.12,
      "duration": 4.719
    },
    {
      "lang": "en",
      "text": "really trying to simplify the code. What",
      "offset": 990.16,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "I did was I had a smart uh uh um node",
      "offset": 991.839,
      "duration": 6.081
    },
    {
      "lang": "en",
      "text": "processor and retrieval tool and I",
      "offset": 995.92,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "basically it was an LLM loop with a",
      "offset": 997.92,
      "duration": 5.279
    },
    {
      "lang": "en",
      "text": "whole bunch of graph query tools. Um and",
      "offset": 999.92,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "I thought the idea was if the LL if I",
      "offset": 1003.199,
      "duration": 3.281
    },
    {
      "lang": "en",
      "text": "gave the LLM enough prompts it would",
      "offset": 1004.88,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "figure out how to ddup correctly. It",
      "offset": 1006.48,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "somewhat worked. Uh but realistically I",
      "offset": 1009.04,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "found that I think the earlier version",
      "offset": 1011.36,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "was better. The deterministic was uh end",
      "offset": 1012.959,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "up working better. though. So the most",
      "offset": 1015.04,
      "duration": 5.039
    },
    {
      "lang": "en",
      "text": "recent uh approach I did was uh a",
      "offset": 1016.959,
      "duration": 7.441
    },
    {
      "lang": "en",
      "text": "fractal kg which has an added uh added",
      "offset": 1020.079,
      "duration": 7.6
    },
    {
      "lang": "en",
      "text": "element of uh trying to self-organize",
      "offset": 1024.4,
      "duration": 6.48
    },
    {
      "lang": "en",
      "text": "itself um into kind of a fractal based",
      "offset": 1027.679,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "uh uh graph which which I'll kind of",
      "offset": 1030.88,
      "duration": 3.199
    },
    {
      "lang": "en",
      "text": "explain through a through a quick demo",
      "offset": 1032.799,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "in a second. Um what you're seeing here",
      "offset": 1034.079,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "is uh a knowledge graph of a whole bunch",
      "offset": 1036.48,
      "duration": 5.199
    },
    {
      "lang": "en",
      "text": "of uh articles pulled in from Wikipedia.",
      "offset": 1038.799,
      "duration": 4.561
    },
    {
      "lang": "en",
      "text": "Um it's automatically extracting",
      "offset": 1041.679,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "entities uh relationships and mapping",
      "offset": 1043.36,
      "duration": 5.439
    },
    {
      "lang": "en",
      "text": "them into a graph.",
      "offset": 1046.079,
      "duration": 8.001
    },
    {
      "lang": "en",
      "text": "Um I think somewhere I had a",
      "offset": 1048.799,
      "duration": 8.24
    },
    {
      "lang": "en",
      "text": "actually a quick explanation of how this",
      "offset": 1054.08,
      "duration": 5.599
    },
    {
      "lang": "en",
      "text": "version works. I I asked trusty Claude",
      "offset": 1057.039,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "to to work through it. In this case, uh",
      "offset": 1059.679,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "there's the uh raw document text that",
      "offset": 1061.919,
      "duration": 8.321
    },
    {
      "lang": "en",
      "text": "goes in. It first uh identifies entities",
      "offset": 1064.559,
      "duration": 7.281
    },
    {
      "lang": "en",
      "text": "and then it goes through an entity",
      "offset": 1070.24,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "resolution step where for each entity it",
      "offset": 1071.84,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "looks to see if there's existing",
      "offset": 1074.64,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "entities. Um so in some cases it might",
      "offset": 1076.24,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "say there's an existing node in some",
      "offset": 1079.76,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "cases might say you know we need a new",
      "offset": 1081.36,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "node and then once we do that there's an",
      "offset": 1083.28,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "extract fact step facts in this case and",
      "offset": 1086,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "in the case of fractal kg every fact is",
      "offset": 1088.64,
      "duration": 5.039
    },
    {
      "lang": "en",
      "text": "a triplet which is a entity relationship",
      "offset": 1091.12,
      "duration": 5.84
    },
    {
      "lang": "en",
      "text": "entity like Einstein developed theory",
      "offset": 1093.679,
      "duration": 5.521
    },
    {
      "lang": "en",
      "text": "relativity and then those are then",
      "offset": 1096.96,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "mapped into uh um attach the facts to",
      "offset": 1099.2,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "the entities create the graph edges",
      "offset": 1102.72,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "based on the relationships batch",
      "offset": 1105.2,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "dduplicate and kind of self-organize.",
      "offset": 1106.96,
      "duration": 6.88
    },
    {
      "lang": "en",
      "text": "So, let's do a little um",
      "offset": 1110.48,
      "duration": 6.88
    },
    {
      "lang": "en",
      "text": "live demo. I think this was uh",
      "offset": 1113.84,
      "duration": 7.44
    },
    {
      "lang": "en",
      "text": "all right. I think I did. So, what I um",
      "offset": 1117.36,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "one of the things I noticed when I was",
      "offset": 1121.28,
      "duration": 3.519
    },
    {
      "lang": "en",
      "text": "trying to do graph rag, right, kind of",
      "offset": 1122.96,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "retrieve context is that if I just added",
      "offset": 1124.799,
      "duration": 5.281
    },
    {
      "lang": "en",
      "text": "if I the graph got too big, pulling in",
      "offset": 1127.76,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "all the edges kind of uh went over the",
      "offset": 1130.08,
      "duration": 3.599
    },
    {
      "lang": "en",
      "text": "context limit. So what I wanted to",
      "offset": 1132.32,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "figure out was can I uh build a system",
      "offset": 1133.679,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "that can reflect on itself and",
      "offset": 1136.4,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "self-organize maybe if one one node has",
      "offset": 1137.919,
      "duration": 4.721
    },
    {
      "lang": "en",
      "text": "too many children it can then cluster",
      "offset": 1140.559,
      "duration": 3.441
    },
    {
      "lang": "en",
      "text": "the children create kind of",
      "offset": 1142.64,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "subcategories between them so that",
      "offset": 1144,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "there's uh no single node has too many",
      "offset": 1146.16,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "edges uh and so that was inspired kind",
      "offset": 1148.4,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "of like the way we dream right so",
      "offset": 1150.64,
      "duration": 2.88
    },
    {
      "lang": "en",
      "text": "there's that kind of go through each",
      "offset": 1152,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "node and self-organize but to show you",
      "offset": 1153.52,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "kind of how that happens live I think",
      "offset": 1155.28,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "the the test I did was yo loves let's",
      "offset": 1156.88,
      "duration": 6.4
    },
    {
      "lang": "en",
      "text": "say AI John loves tech. Now, what you",
      "offset": 1159.76,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "would expect, at least for my previous",
      "offset": 1163.28,
      "duration": 3.759
    },
    {
      "lang": "en",
      "text": "one, was that it would just generate a",
      "offset": 1164.64,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "yohay to AI relationship and a John to",
      "offset": 1167.039,
      "duration": 5.681
    },
    {
      "lang": "en",
      "text": "tech relationship. But, uh, in this",
      "offset": 1170.4,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "case, uh, because it's trying to",
      "offset": 1172.72,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "self-organize and understand and infer",
      "offset": 1174.799,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "relationship between nodes as it's",
      "offset": 1176.96,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "creating them, it should build a",
      "offset": 1178.4,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "relationship between AI and technology",
      "offset": 1180.24,
      "duration": 5.439
    },
    {
      "lang": "en",
      "text": "automatically. Uh, when it displays, um,",
      "offset": 1182.24,
      "duration": 7.6
    },
    {
      "lang": "en",
      "text": "I think it's should display in",
      "offset": 1185.679,
      "duration": 5.441
    },
    {
      "lang": "en",
      "text": "a second. There it goes. Okay, in this",
      "offset": 1189.84,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "case it did not. But let's try the",
      "offset": 1191.12,
      "duration": 6.64
    },
    {
      "lang": "en",
      "text": "was it self-organize",
      "offset": 1195.44,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "or",
      "offset": 1197.76,
      "duration": 5.279
    },
    {
      "lang": "en",
      "text": "I guess it didn't work in this case.",
      "offset": 1199.28,
      "duration": 6.32
    },
    {
      "lang": "en",
      "text": "Earlier when I did this test, it did a",
      "offset": 1203.039,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "Yeah, let's just jump to the earlier",
      "offset": 1205.6,
      "duration": 5.079
    },
    {
      "lang": "en",
      "text": "test I did.",
      "offset": 1207.12,
      "duration": 3.559
    },
    {
      "lang": "en",
      "text": "Earlier when I did the same query, it",
      "offset": 1211.52,
      "duration": 3.519
    },
    {
      "lang": "en",
      "text": "did this. And then if I go in and say",
      "offset": 1213.039,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "what is",
      "offset": 1215.039,
      "duration": 4.721
    },
    {
      "lang": "en",
      "text": "John's relationship",
      "offset": 1217.2,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "with",
      "offset": 1219.76,
      "duration": 2.4
    },
    {
      "lang": "en",
      "text": "with AI.",
      "offset": 1222.24,
      "duration": 3.4
    },
    {
      "lang": "en",
      "text": "It says there's no direct relationship",
      "offset": 1229.84,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "between John and AI based on given",
      "offset": 1232.159,
      "duration": 4.281
    },
    {
      "lang": "en",
      "text": "facts.",
      "offset": 1233.44,
      "duration": 3
    },
    {
      "lang": "en",
      "text": "While AI is a subset of technology, the",
      "offset": 1236.64,
      "duration": 2.96
    },
    {
      "lang": "en",
      "text": "fact is not a specific state that John",
      "offset": 1238.32,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "loves AI, only technology in general. So",
      "offset": 1239.6,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "it does it does remember that Jon loves",
      "offset": 1241.44,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "technology, but it does see that John,",
      "offset": 1243.679,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "you know, technology has a relationship",
      "offset": 1245.6,
      "duration": 5.84
    },
    {
      "lang": "en",
      "text": "with AI, if that makes sense.",
      "offset": 1247.039,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "I think it does you I mean especially in",
      "offset": 1252.64,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "the context of people that are trying to",
      "offset": 1254.4,
      "duration": 3.759
    },
    {
      "lang": "en",
      "text": "build an agent that is supposed to have",
      "offset": 1256,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "memory and hold that memory and provide",
      "offset": 1258.159,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "answers that actually bear some context.",
      "offset": 1260.32,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "So I think what you're showing here is",
      "offset": 1262.559,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "very cool. Yeah. And and the and most of",
      "offset": 1264.96,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "the um kind of ingestion and retrieval",
      "offset": 1268.159,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "is is in a single file that's about a",
      "offset": 1270.96,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "thousand thousand lines of code. And I",
      "offset": 1272.799,
      "duration": 3.281
    },
    {
      "lang": "en",
      "text": "think we're we're working on getting it",
      "offset": 1274.64,
      "duration": 2.88
    },
    {
      "lang": "en",
      "text": "ready to open source too. So, if you",
      "offset": 1276.08,
      "duration": 2.64
    },
    {
      "lang": "en",
      "text": "want to play around at least with this",
      "offset": 1277.52,
      "duration": 2.24
    },
    {
      "lang": "en",
      "text": "approach, we'll be able to share it",
      "offset": 1278.72,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "soon. That's very cool. Yeah,",
      "offset": 1279.76,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "definitely. I mean, once that's up",
      "offset": 1282.559,
      "duration": 3.441
    },
    {
      "lang": "en",
      "text": "there, we're going to put it on Discord",
      "offset": 1283.84,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "and disseminate it to everybody that",
      "offset": 1286,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "attended so they can play with it as",
      "offset": 1287.76,
      "duration": 4.799
    },
    {
      "lang": "en",
      "text": "well. But I think it's really cool. It's",
      "offset": 1289.2,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "what we had in mind, I think, when we",
      "offset": 1292.559,
      "duration": 5.161
    },
    {
      "lang": "en",
      "text": "started building this.",
      "offset": 1294.08,
      "duration": 3.64
    },
    {
      "lang": "en",
      "text": "Yeah. Um,",
      "offset": 1298.64,
      "duration": 3.64
    },
    {
      "lang": "en",
      "text": "I know we were talking about like wh why",
      "offset": 1302.559,
      "duration": 5.761
    },
    {
      "lang": "en",
      "text": "graphs a little bit the other day. Yeah.",
      "offset": 1305.44,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "Um and I'm not someone who studied",
      "offset": 1308.32,
      "duration": 7.68
    },
    {
      "lang": "en",
      "text": "graphs but uh I think",
      "offset": 1310.64,
      "duration": 8.159
    },
    {
      "lang": "en",
      "text": "you know in in understand like most of",
      "offset": 1316,
      "duration": 4.799
    },
    {
      "lang": "en",
      "text": "most of business right and and the way",
      "offset": 1318.799,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "um we work is actually just a lot of",
      "offset": 1320.799,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "relationships right there's even when I",
      "offset": 1322.4,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "look at the way I work there's emails",
      "offset": 1324.48,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "there's notes there's people there's",
      "offset": 1326.96,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "relationship between people businesses",
      "offset": 1328.88,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "and so uh I think graphs do an",
      "offset": 1331.2,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "incredible job of capturing uh the way",
      "offset": 1333.36,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "in which the real world works",
      "offset": 1335.84,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "Um, one of the opportunities I'm excited",
      "offset": 1338.4,
      "duration": 5.519
    },
    {
      "lang": "en",
      "text": "about is that, uh, with graphs, there's,",
      "offset": 1341.2,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "you know, and again, I'm pretty still",
      "offset": 1343.919,
      "duration": 2.721
    },
    {
      "lang": "en",
      "text": "shallow on this, but there's there's a",
      "offset": 1345.36,
      "duration": 2.799
    },
    {
      "lang": "en",
      "text": "lot of kind of algorithms that help you",
      "offset": 1346.64,
      "duration": 2.72
    },
    {
      "lang": "en",
      "text": "better understand kind of the",
      "offset": 1348.159,
      "duration": 2.64
    },
    {
      "lang": "en",
      "text": "relationship between graphs and the",
      "offset": 1349.36,
      "duration": 3.439
    },
    {
      "lang": "en",
      "text": "network at large. And I think as I think",
      "offset": 1350.799,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "about especially for me right in in the",
      "offset": 1352.799,
      "duration": 3.521
    },
    {
      "lang": "en",
      "text": "startup ecosystem and I think for other",
      "offset": 1354.64,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "people um you'll find similar things is",
      "offset": 1356.32,
      "duration": 4.719
    },
    {
      "lang": "en",
      "text": "that I believe that if I can create a",
      "offset": 1358.799,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "strong graph that captures the",
      "offset": 1361.039,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "innovation ecosystem right what are the",
      "offset": 1362.72,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "industries what are the technologies who",
      "offset": 1364.799,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "are the investors who are the customers",
      "offset": 1366.559,
      "duration": 4.881
    },
    {
      "lang": "en",
      "text": "then eventually we'll be able to start",
      "offset": 1368.799,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "identifying pockets of underserved",
      "offset": 1371.44,
      "duration": 4.479
    },
    {
      "lang": "en",
      "text": "innovation right opportunities where",
      "offset": 1373.679,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "we're seeing a lot of where we should",
      "offset": 1375.919,
      "duration": 3.521
    },
    {
      "lang": "en",
      "text": "see a lot of activity but maybe aren't",
      "offset": 1377.84,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "seeing as much funding happening and",
      "offset": 1379.44,
      "duration": 3.119
    },
    {
      "lang": "en",
      "text": "then If I if I'm able to start",
      "offset": 1381.12,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "identifying those I mean for for myself",
      "offset": 1382.559,
      "duration": 3.201
    },
    {
      "lang": "en",
      "text": "I can start looking at those and",
      "offset": 1384.48,
      "duration": 3.199
    },
    {
      "lang": "en",
      "text": "investing in those but for founders they",
      "offset": 1385.76,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "can start you know looking for you know",
      "offset": 1387.679,
      "duration": 4.641
    },
    {
      "lang": "en",
      "text": "uh you might there's probably",
      "offset": 1390.08,
      "duration": 3.599
    },
    {
      "lang": "en",
      "text": "innovations that happen in certain",
      "offset": 1392.32,
      "duration": 2.96
    },
    {
      "lang": "en",
      "text": "industries that should obviously apply",
      "offset": 1393.679,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "in another it just hasn't happened yet",
      "offset": 1395.28,
      "duration": 3.519
    },
    {
      "lang": "en",
      "text": "and being able to identify those",
      "offset": 1397.36,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "automatically I think graphs are are",
      "offset": 1398.799,
      "duration": 3.201
    },
    {
      "lang": "en",
      "text": "really well suited for that so I think",
      "offset": 1400.4,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "it's beyond just capturing the existing",
      "offset": 1402,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "relationships and the businesses but",
      "offset": 1403.76,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "also um being able to uh infer",
      "offset": 1405.6,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "opportunities uh within those graphs and",
      "offset": 1408.4,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "I I think uh um at least from my",
      "offset": 1410.72,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "understanding is that the biggest",
      "offset": 1412.96,
      "duration": 2.8
    },
    {
      "lang": "en",
      "text": "challenge with knowledge graphs at least",
      "offset": 1414.32,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "prior to LLMs was building and",
      "offset": 1415.76,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "maintaining these clean knowledge",
      "offset": 1418.24,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "graphs. Um it just took too much",
      "offset": 1420.32,
      "duration": 4.239
    },
    {
      "lang": "en",
      "text": "manpower and I think with the reasoning",
      "offset": 1422.24,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "capabilities the the data structuring",
      "offset": 1424.559,
      "duration": 3.441
    },
    {
      "lang": "en",
      "text": "capabilities of LMS I think we're",
      "offset": 1426.24,
      "duration": 4.559
    },
    {
      "lang": "en",
      "text": "finally at a place where we are able to",
      "offset": 1428,
      "duration": 5.039
    },
    {
      "lang": "en",
      "text": "build and maintain large knowledge",
      "offset": 1430.799,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "graphs and then if we can do that we can",
      "offset": 1433.039,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "infer insight from them. And I think",
      "offset": 1434.96,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "we're still early and you know as as I",
      "offset": 1436.72,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "talk to people but I think it's it's the",
      "offset": 1438.64,
      "duration": 3.039
    },
    {
      "lang": "en",
      "text": "right time to figure it out and I think",
      "offset": 1440.24,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "if you can figure it out uh you can",
      "offset": 1441.679,
      "duration": 3.041
    },
    {
      "lang": "en",
      "text": "definitely have a have a leg up in",
      "offset": 1443.36,
      "duration": 3.199
    },
    {
      "lang": "en",
      "text": "helping people organize data and and",
      "offset": 1444.72,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "gain insight from it. So so that's been",
      "offset": 1446.559,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "my motivation that's my hypothesis as I",
      "offset": 1448.24,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "dug into and play with knowledge graphs",
      "offset": 1450.48,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "and and of course that exploration uh uh",
      "offset": 1452.32,
      "duration": 4.479
    },
    {
      "lang": "en",
      "text": "led me to uh working with you guys at",
      "offset": 1454.72,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "Falore. So that that's been my uh my my",
      "offset": 1456.799,
      "duration": 5.841
    },
    {
      "lang": "en",
      "text": "experience. That's really I'm really",
      "offset": 1460.32,
      "duration": 3.599
    },
    {
      "lang": "en",
      "text": "happy you brought that up. I know we",
      "offset": 1462.64,
      "duration": 2.88
    },
    {
      "lang": "en",
      "text": "talked about it a few days ago and I was",
      "offset": 1463.919,
      "duration": 3.281
    },
    {
      "lang": "en",
      "text": "hoping that the insights you shared back",
      "offset": 1465.52,
      "duration": 3.279
    },
    {
      "lang": "en",
      "text": "then would be ones that you would share",
      "offset": 1467.2,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "with the audience today too because I I",
      "offset": 1468.799,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "think we feel the same way and we see it",
      "offset": 1470.72,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "pop up on a lot of the conversations",
      "offset": 1472.799,
      "duration": 2.961
    },
    {
      "lang": "en",
      "text": "that we're having. I think people are",
      "offset": 1474.4,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "reaching the same conclusions. Um I'm",
      "offset": 1475.76,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "just looking at the time and I know",
      "offset": 1478.96,
      "duration": 3.199
    },
    {
      "lang": "en",
      "text": "before we even started the session we",
      "offset": 1480.4,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "had gotten questions people wanted",
      "offset": 1482.159,
      "duration": 3.281
    },
    {
      "lang": "en",
      "text": "answered and there's a few that have",
      "offset": 1483.84,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "gathered in the in the chat. So would",
      "offset": 1485.44,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "you guys mind if we uh because we didn't",
      "offset": 1488.4,
      "duration": 5.84
    },
    {
      "lang": "en",
      "text": "want this to be slideheavy, right? There",
      "offset": 1491.2,
      "duration": 4.719
    },
    {
      "lang": "en",
      "text": "wasn't like a presentation in mind. It",
      "offset": 1494.24,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "was more like a demo showing what's",
      "offset": 1495.919,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "going on behind the scenes and sort of",
      "offset": 1498.48,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "the rationale behind things. So I think",
      "offset": 1500,
      "duration": 3.279
    },
    {
      "lang": "en",
      "text": "it would make sense to keep the",
      "offset": 1502,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "discussion going instead of showing more",
      "offset": 1503.279,
      "duration": 6.321
    },
    {
      "lang": "en",
      "text": "slides. Um so the first actual the first",
      "offset": 1505.12,
      "duration": 7.12
    },
    {
      "lang": "en",
      "text": "question is a bit long. It's quite cool.",
      "offset": 1509.6,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "So, I'm going to read it out loud and if",
      "offset": 1512.24,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "you need me to repeat a part of it,",
      "offset": 1514.96,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "please let me know. So,",
      "offset": 1516.4,
      "duration": 6.8
    },
    {
      "lang": "en",
      "text": "uh it's from uh I can't really tell the",
      "offset": 1519.279,
      "duration": 5.921
    },
    {
      "lang": "en",
      "text": "name of who asked it. So, we're just",
      "offset": 1523.2,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "going to answer it live and later on",
      "offset": 1525.2,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "when we send the email recapping this.",
      "offset": 1527.6,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "If you've asked this question, you're",
      "offset": 1529.76,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "probably going to recognize the answer.",
      "offset": 1531.36,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "So the question goes, what rule or",
      "offset": 1533.12,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "heristic should one use to determine",
      "offset": 1535.52,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "whether some information should be a",
      "offset": 1537.76,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "node versus an attribute of a node? The",
      "offset": 1539.76,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "example given here is an individual",
      "offset": 1543.52,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "might be a node in a graph and their",
      "offset": 1545.44,
      "duration": 4.479
    },
    {
      "lang": "en",
      "text": "name would likely be an attribute, but",
      "offset": 1547.44,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "what about their country? Uh the person",
      "offset": 1549.919,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "also says, I can see a case for that",
      "offset": 1552.48,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "being either a node or an attribute.",
      "offset": 1554.799,
      "duration": 5.041
    },
    {
      "lang": "en",
      "text": "Perhaps this is where upfront on your",
      "offset": 1557.12,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "definition comes into play. Roy, I think",
      "offset": 1559.84,
      "duration": 5.199
    },
    {
      "lang": "en",
      "text": "you touched a little bit on this, but",
      "offset": 1562,
      "duration": 6.159
    },
    {
      "lang": "en",
      "text": "yeah, it's a it's a good question and I",
      "offset": 1565.039,
      "duration": 6.64
    },
    {
      "lang": "en",
      "text": "think it's a question that a lot are",
      "offset": 1568.159,
      "duration": 5.281
    },
    {
      "lang": "en",
      "text": "um",
      "offset": 1571.679,
      "duration": 4.561
    },
    {
      "lang": "en",
      "text": "yet to ask themselves whenever they're",
      "offset": 1573.44,
      "duration": 7.359
    },
    {
      "lang": "en",
      "text": "uh trying to model their data. And so",
      "offset": 1576.24,
      "duration": 8.559
    },
    {
      "lang": "en",
      "text": "there isn't a clear and correct answer.",
      "offset": 1580.799,
      "duration": 7.201
    },
    {
      "lang": "en",
      "text": "Uh for some treating a piece of",
      "offset": 1584.799,
      "duration": 5.601
    },
    {
      "lang": "en",
      "text": "information as an attribute might be the",
      "offset": 1588,
      "duration": 5.84
    },
    {
      "lang": "en",
      "text": "right way to go. For others",
      "offset": 1590.4,
      "duration": 6.399
    },
    {
      "lang": "en",
      "text": "um it might make sense to treat this",
      "offset": 1593.84,
      "duration": 6.16
    },
    {
      "lang": "en",
      "text": "piece of information as a node. My",
      "offset": 1596.799,
      "duration": 4.961
    },
    {
      "lang": "en",
      "text": "general",
      "offset": 1600,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "uh way of thinking about this is if",
      "offset": 1601.76,
      "duration": 7.36
    },
    {
      "lang": "en",
      "text": "you're trying to visual data is a graph.",
      "offset": 1604.24,
      "duration": 8.4
    },
    {
      "lang": "en",
      "text": "um what ha whatever comes to your mind",
      "offset": 1609.12,
      "duration": 5.439
    },
    {
      "lang": "en",
      "text": "naturally",
      "offset": 1612.64,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "that's the data model that you probably",
      "offset": 1614.559,
      "duration": 6.801
    },
    {
      "lang": "en",
      "text": "want to start experimenting with. Also,",
      "offset": 1617.2,
      "duration": 7.12
    },
    {
      "lang": "en",
      "text": "if the data uh the data point which",
      "offset": 1621.36,
      "duration": 8.799
    },
    {
      "lang": "en",
      "text": "we're thinking of seems trivial like uh",
      "offset": 1624.32,
      "duration": 8.64
    },
    {
      "lang": "en",
      "text": "at the beginning of the question then",
      "offset": 1630.159,
      "duration": 6.961
    },
    {
      "lang": "en",
      "text": "you know there's there's not much to",
      "offset": 1632.96,
      "duration": 8.079
    },
    {
      "lang": "en",
      "text": "uh to think about. Um but let's let's",
      "offset": 1637.12,
      "duration": 7.28
    },
    {
      "lang": "en",
      "text": "try and think about the country piece of",
      "offset": 1641.039,
      "duration": 8.321
    },
    {
      "lang": "en",
      "text": "information. So a person might be uh a",
      "offset": 1644.4,
      "duration": 6.96
    },
    {
      "lang": "en",
      "text": "resident",
      "offset": 1649.36,
      "duration": 6.48
    },
    {
      "lang": "en",
      "text": "uh or have a certain nationality.",
      "offset": 1651.36,
      "duration": 8.96
    },
    {
      "lang": "en",
      "text": "And so you might represent the country",
      "offset": 1655.84,
      "duration": 8.079
    },
    {
      "lang": "en",
      "text": "as an attribute for every person in your",
      "offset": 1660.32,
      "duration": 6.4
    },
    {
      "lang": "en",
      "text": "graph. And so for example, if you're",
      "offset": 1663.919,
      "duration": 6.481
    },
    {
      "lang": "en",
      "text": "just maintaining the the string of that",
      "offset": 1666.72,
      "duration": 6.48
    },
    {
      "lang": "en",
      "text": "person, then one thing that comes to",
      "offset": 1670.4,
      "duration": 6.24
    },
    {
      "lang": "en",
      "text": "mind is the memory consumption. If you",
      "offset": 1673.2,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "have millions",
      "offset": 1676.64,
      "duration": 8.159
    },
    {
      "lang": "en",
      "text": "of uh different persons, then this small",
      "offset": 1678.96,
      "duration": 9.52
    },
    {
      "lang": "en",
      "text": "set of strings representing countries",
      "offset": 1684.799,
      "duration": 6.961
    },
    {
      "lang": "en",
      "text": "um would duplicate itself over and over",
      "offset": 1688.48,
      "duration": 6.96
    },
    {
      "lang": "en",
      "text": "and over again. So memory might come to",
      "offset": 1691.76,
      "duration": 6.399
    },
    {
      "lang": "en",
      "text": "mind and actually we've addressed this",
      "offset": 1695.44,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "in in our latest release. Uh we have",
      "offset": 1698.159,
      "duration": 6.081
    },
    {
      "lang": "en",
      "text": "this feature called string interning",
      "offset": 1701.44,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "where you can specify hey this is a",
      "offset": 1704.24,
      "duration": 7.039
    },
    {
      "lang": "en",
      "text": "string which comes pretty often. Uh",
      "offset": 1706.72,
      "duration": 8.88
    },
    {
      "lang": "en",
      "text": "don't do don't duplicate it. Use unique",
      "offset": 1711.279,
      "duration": 6.64
    },
    {
      "lang": "en",
      "text": "uh value of it and everything is being",
      "offset": 1715.6,
      "duration": 4.559
    },
    {
      "lang": "en",
      "text": "shared. So this is one thing to take",
      "offset": 1717.919,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "into consideration. Another thing is the",
      "offset": 1720.159,
      "duration": 5.201
    },
    {
      "lang": "en",
      "text": "way in which you're going about",
      "offset": 1722.799,
      "duration": 5.041
    },
    {
      "lang": "en",
      "text": "traversing or searching for knowledge.",
      "offset": 1725.36,
      "duration": 4.799
    },
    {
      "lang": "en",
      "text": "So you need to think about the different",
      "offset": 1727.84,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "type of questions that your system is",
      "offset": 1730.159,
      "duration": 7.12
    },
    {
      "lang": "en",
      "text": "intended to answer. So for example, if",
      "offset": 1733.84,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "you're",
      "offset": 1737.279,
      "duration": 6.4
    },
    {
      "lang": "en",
      "text": "uh want to do traversal from a country",
      "offset": 1738.96,
      "duration": 7.28
    },
    {
      "lang": "en",
      "text": "outward, it would make sense to",
      "offset": 1743.679,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "represent the country as a node.",
      "offset": 1746.24,
      "duration": 5.679
    },
    {
      "lang": "en",
      "text": "But if you are more focused on on",
      "offset": 1749.039,
      "duration": 6.481
    },
    {
      "lang": "en",
      "text": "person, you're trying to locate a person",
      "offset": 1751.919,
      "duration": 8.401
    },
    {
      "lang": "en",
      "text": "via its uh unique identifier or social",
      "offset": 1755.52,
      "duration": 7.36
    },
    {
      "lang": "en",
      "text": "security number and you just want to see",
      "offset": 1760.32,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "for example in which state that person",
      "offset": 1762.88,
      "duration": 6.48
    },
    {
      "lang": "en",
      "text": "lives then uh it might make sense to",
      "offset": 1765.52,
      "duration": 6.8
    },
    {
      "lang": "en",
      "text": "have this as an attribute. you you can",
      "offset": 1769.36,
      "duration": 5.439
    },
    {
      "lang": "en",
      "text": "still go with a node but then you would",
      "offset": 1772.32,
      "duration": 6.16
    },
    {
      "lang": "en",
      "text": "have to traverse from that person to a",
      "offset": 1774.799,
      "duration": 5.681
    },
    {
      "lang": "en",
      "text": "country node and retrieve the name of",
      "offset": 1778.48,
      "duration": 6.799
    },
    {
      "lang": "en",
      "text": "the country. So um kind of summaring",
      "offset": 1780.48,
      "duration": 8.559
    },
    {
      "lang": "en",
      "text": "things up go with the most natural way",
      "offset": 1785.279,
      "duration": 6.561
    },
    {
      "lang": "en",
      "text": "of thinking about the data as a graph",
      "offset": 1789.039,
      "duration": 7.841
    },
    {
      "lang": "en",
      "text": "and um see if if uh the data model that",
      "offset": 1791.84,
      "duration": 7.68
    },
    {
      "lang": "en",
      "text": "you have chosen fits the different type",
      "offset": 1796.88,
      "duration": 6.159
    },
    {
      "lang": "en",
      "text": "of queries and questions that you're uh",
      "offset": 1799.52,
      "duration": 8.6
    },
    {
      "lang": "en",
      "text": "intending to um answer.",
      "offset": 1803.039,
      "duration": 5.081
    },
    {
      "lang": "en",
      "text": "Yeah, I would I would say the same",
      "offset": 1809.52,
      "duration": 3.039
    },
    {
      "lang": "en",
      "text": "thing. like like the last thing you",
      "offset": 1810.88,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "said, especially for me, right? Again, I",
      "offset": 1812.559,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "I'm not as deep on the understanding how",
      "offset": 1814.24,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "to optimize the queries piece, but but I",
      "offset": 1816.559,
      "duration": 3.201
    },
    {
      "lang": "en",
      "text": "think starting from the queries is",
      "offset": 1818.399,
      "duration": 2.481
    },
    {
      "lang": "en",
      "text": "important, right? If you're going to",
      "offset": 1819.76,
      "duration": 4.639
    },
    {
      "lang": "en",
      "text": "constantly filter your data by country,",
      "offset": 1820.88,
      "duration": 5.679
    },
    {
      "lang": "en",
      "text": "um I I would guess that it would be",
      "offset": 1824.399,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "intuitive to turn that into a node. Um",
      "offset": 1826.559,
      "duration": 4.881
    },
    {
      "lang": "en",
      "text": "but if it's something you're just like",
      "offset": 1829.039,
      "duration": 4.561
    },
    {
      "lang": "en",
      "text": "want to see when you visit their page as",
      "offset": 1831.44,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "a as a side note, then then you might",
      "offset": 1833.6,
      "duration": 3.439
    },
    {
      "lang": "en",
      "text": "not need to add that as a node is kind",
      "offset": 1835.36,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "of how I would think about it. And I",
      "offset": 1837.039,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "think again if you have a lot of data",
      "offset": 1838.96,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "you do have to worry about the costs. Um",
      "offset": 1841.12,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "so I'll speak as kind of a more of a",
      "offset": 1843.36,
      "duration": 2.96
    },
    {
      "lang": "en",
      "text": "prototype or getting going stage.",
      "offset": 1844.88,
      "duration": 3.519
    },
    {
      "lang": "en",
      "text": "Initially I think keeping it simple is",
      "offset": 1846.32,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "good and you can kind of test around",
      "offset": 1848.399,
      "duration": 3.041
    },
    {
      "lang": "en",
      "text": "with small pieces of data and then if",
      "offset": 1849.6,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "you feel like it's helpful I mean if you",
      "offset": 1851.44,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "have the location data as an attribute",
      "offset": 1853.36,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "you know it should be pretty easy to",
      "offset": 1856,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "convert that location data and map it to",
      "offset": 1858.24,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "a location node. Again, if you have",
      "offset": 1860.24,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "millions of data, you might want to do",
      "offset": 1862,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "it up front versus doing it later. But",
      "offset": 1863.6,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "at least in the in this uh in the",
      "offset": 1865.36,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "prototyping stage, you can you can",
      "offset": 1866.88,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "easily add that uh after the fact.",
      "offset": 1868.72,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "Yeah, maybe let let me just add a few",
      "offset": 1872.24,
      "duration": 6.24
    },
    {
      "lang": "en",
      "text": "things to that. Um graphs are dynamic",
      "offset": 1874.48,
      "duration": 6.24
    },
    {
      "lang": "en",
      "text": "and so if you are going, you know, you",
      "offset": 1878.48,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "have experimented with m with one data",
      "offset": 1880.72,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "model, you can quite easily transition",
      "offset": 1882.96,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "to another. That's one thing. Another",
      "offset": 1886,
      "duration": 6.96
    },
    {
      "lang": "en",
      "text": "maybe um thing to keep in mind following",
      "offset": 1888.48,
      "duration": 6.64
    },
    {
      "lang": "en",
      "text": "on this country with this country",
      "offset": 1892.96,
      "duration": 5.439
    },
    {
      "lang": "en",
      "text": "example is are you expecting the country",
      "offset": 1895.12,
      "duration": 7.439
    },
    {
      "lang": "en",
      "text": "to be interacting with other pieces of",
      "offset": 1898.399,
      "duration": 6.4
    },
    {
      "lang": "en",
      "text": "information like maybe now you only have",
      "offset": 1902.559,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "the relation between a person and a",
      "offset": 1904.799,
      "duration": 5.921
    },
    {
      "lang": "en",
      "text": "country but maybe uh in the near future",
      "offset": 1906.64,
      "duration": 7.279
    },
    {
      "lang": "en",
      "text": "you're seeing country being referenced",
      "offset": 1910.72,
      "duration": 6.48
    },
    {
      "lang": "en",
      "text": "or interacting with different entities",
      "offset": 1913.919,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "And if that's the case, I would lean",
      "offset": 1917.2,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "toward representing it as a node just",
      "offset": 1919.919,
      "duration": 6.321
    },
    {
      "lang": "en",
      "text": "because the ability of capturing those",
      "offset": 1922.64,
      "duration": 7.159
    },
    {
      "lang": "en",
      "text": "uh different interactions.",
      "offset": 1926.24,
      "duration": 3.559
    },
    {
      "lang": "en",
      "text": "Excellent guys. Uh another question we",
      "offset": 1933.039,
      "duration": 5.921
    },
    {
      "lang": "en",
      "text": "have is from MJ. He's asking, &quot;When",
      "offset": 1935.36,
      "duration": 6.08
    },
    {
      "lang": "en",
      "text": "working with documents, what detail are",
      "offset": 1938.96,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "we saving in Fal DB? Would you store",
      "offset": 1941.44,
      "duration": 5.599
    },
    {
      "lang": "en",
      "text": "sentences, paragraphs or summaries? If",
      "offset": 1944.24,
      "duration": 5.039
    },
    {
      "lang": "en",
      "text": "only storing summaries, are you also",
      "offset": 1947.039,
      "duration": 4.561
    },
    {
      "lang": "en",
      "text": "storing entire documents in a separate",
      "offset": 1949.279,
      "duration": 5.321
    },
    {
      "lang": "en",
      "text": "database?",
      "offset": 1951.6,
      "duration": 3
    },
    {
      "lang": "en",
      "text": "Right. Um, this is classic rag question",
      "offset": 1954.72,
      "duration": 10.4
    },
    {
      "lang": "en",
      "text": "I would say and once again there's no",
      "offset": 1959.919,
      "duration": 9.841
    },
    {
      "lang": "en",
      "text": "right answer. I think uh all options are",
      "offset": 1965.12,
      "duration": 9.76
    },
    {
      "lang": "en",
      "text": "viable and it really depends on um the",
      "offset": 1969.76,
      "duration": 7.68
    },
    {
      "lang": "en",
      "text": "type of questions and the level of",
      "offset": 1974.88,
      "duration": 6.08
    },
    {
      "lang": "en",
      "text": "accuracy that you are aiming for. Um",
      "offset": 1977.44,
      "duration": 8.32
    },
    {
      "lang": "en",
      "text": "we've seen all all different options.",
      "offset": 1980.96,
      "duration": 9.28
    },
    {
      "lang": "en",
      "text": "Um some some people are actually",
      "offset": 1985.76,
      "duration": 7.36
    },
    {
      "lang": "en",
      "text": "um analyzing the documents for example",
      "offset": 1990.24,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "with LLMs",
      "offset": 1993.12,
      "duration": 4.799
    },
    {
      "lang": "en",
      "text": "um creating embeddings extracting",
      "offset": 1995.2,
      "duration": 6.16
    },
    {
      "lang": "en",
      "text": "sentences creating summaries and all of",
      "offset": 1997.919,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "the relationship between the different",
      "offset": 2001.36,
      "duration": 3.199
    },
    {
      "lang": "en",
      "text": "components",
      "offset": 2003.039,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "paragraph sentences summaries entire",
      "offset": 2004.559,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "documents",
      "offset": 2007.36,
      "duration": 5.919
    },
    {
      "lang": "en",
      "text": "these can be represented as nodes in a",
      "offset": 2008.88,
      "duration": 8.32
    },
    {
      "lang": "en",
      "text": "graph. So for example, whenever you're",
      "offset": 2013.279,
      "duration": 7.52
    },
    {
      "lang": "en",
      "text": "trying to answer a question via the",
      "offset": 2017.2,
      "duration": 6.479
    },
    {
      "lang": "en",
      "text": "classical rag approach where you are",
      "offset": 2020.799,
      "duration": 6.321
    },
    {
      "lang": "en",
      "text": "creating embeddings for the question and",
      "offset": 2023.679,
      "duration": 6.561
    },
    {
      "lang": "en",
      "text": "then you're doing semantic search to get",
      "offset": 2027.12,
      "duration": 7.439
    },
    {
      "lang": "en",
      "text": "to uh maybe the summary or maybe to get",
      "offset": 2030.24,
      "duration": 7.679
    },
    {
      "lang": "en",
      "text": "to the relevant paragraphs. Then you can",
      "offset": 2034.559,
      "duration": 7.281
    },
    {
      "lang": "en",
      "text": "utilize the graph in order to get a hold",
      "offset": 2037.919,
      "duration": 6.561
    },
    {
      "lang": "en",
      "text": "of the original document and maybe",
      "offset": 2041.84,
      "duration": 5.199
    },
    {
      "lang": "en",
      "text": "there's a hierarchy of documents saying",
      "offset": 2044.48,
      "duration": 7.04
    },
    {
      "lang": "en",
      "text": "oh this document is a page from a",
      "offset": 2047.039,
      "duration": 6.08
    },
    {
      "lang": "en",
      "text": "broader",
      "offset": 2051.52,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "um",
      "offset": 2053.119,
      "duration": 6.48
    },
    {
      "lang": "en",
      "text": "corpus or oh this is an uh a Wikipedia",
      "offset": 2055.04,
      "duration": 7.359
    },
    {
      "lang": "en",
      "text": "article that is linked to other",
      "offset": 2059.599,
      "duration": 5.601
    },
    {
      "lang": "en",
      "text": "Wikipedia pages. Maybe I want to extend",
      "offset": 2062.399,
      "duration": 7.121
    },
    {
      "lang": "en",
      "text": "my context and get some extra data in by",
      "offset": 2065.2,
      "duration": 7.52
    },
    {
      "lang": "en",
      "text": "traversing the graph. And so there's no",
      "offset": 2069.52,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "clear answer. I think you should",
      "offset": 2072.72,
      "duration": 7.04
    },
    {
      "lang": "en",
      "text": "experiment with it. Um but the benefits",
      "offset": 2074.48,
      "duration": 7.599
    },
    {
      "lang": "en",
      "text": "of storing this information in a graph",
      "offset": 2079.76,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "allows you to retrieve additional",
      "offset": 2082.079,
      "duration": 7.201
    },
    {
      "lang": "en",
      "text": "context which uh usually it's relevant",
      "offset": 2084.8,
      "duration": 8.16
    },
    {
      "lang": "en",
      "text": "uh to extending the context with",
      "offset": 2089.28,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "um",
      "offset": 2092.96,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "information that would help your LLM to",
      "offset": 2094.8,
      "duration": 7.319
    },
    {
      "lang": "en",
      "text": "generate the correct uh answer.",
      "offset": 2097.04,
      "duration": 5.079
    },
    {
      "lang": "en",
      "text": "Yeah, this this feels like more of a",
      "offset": 2104.96,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "Falore DB specific one, but I think uh",
      "offset": 2106.16,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "that like again going back to like what",
      "offset": 2108.24,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "is the query, how would you want to",
      "offset": 2111.2,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "display it, I think is is what what",
      "offset": 2112.96,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "comes to mind. Um in a lot of cases when",
      "offset": 2114.64,
      "duration": 4.479
    },
    {
      "lang": "en",
      "text": "you do rag, you might want to uh provide",
      "offset": 2116.48,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "the source snippet of the fact, you",
      "offset": 2119.119,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "know, whether you do or don't should",
      "offset": 2121.68,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "affect your decision around whether to",
      "offset": 2123.44,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "keep the document, right? If it's a",
      "offset": 2124.96,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "massive PDF that you had to chunk to",
      "offset": 2126.8,
      "duration": 6.24
    },
    {
      "lang": "en",
      "text": "analyze and store, um maybe it makes",
      "offset": 2129.2,
      "duration": 6.159
    },
    {
      "lang": "en",
      "text": "sense to store the chunks because if you",
      "offset": 2133.04,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "want to store, you know, if you want,",
      "offset": 2135.359,
      "duration": 2.401
    },
    {
      "lang": "en",
      "text": "you know, if you find a fact and you",
      "offset": 2136.64,
      "duration": 2.32
    },
    {
      "lang": "en",
      "text": "want to grab the snippet, you don't want",
      "offset": 2137.76,
      "duration": 2.8
    },
    {
      "lang": "en",
      "text": "to have to go through and search through",
      "offset": 2138.96,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "the entire PDF for that snippet again.",
      "offset": 2140.56,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "That seems just really inefficient. You",
      "offset": 2142.32,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "would almost rather store the snippet",
      "offset": 2144,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "with the fact so that you can quickly",
      "offset": 2145.76,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "pull the snippet instead of searching",
      "offset": 2147.44,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "for it each time. So again, kind of",
      "offset": 2148.88,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "depends on what's the information you",
      "offset": 2150.72,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "want to display, how do you display it,",
      "offset": 2152.8,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "what is uh what is the flow to get that",
      "offset": 2155.119,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "information in front of the user. Uh and",
      "offset": 2157.28,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "I think that comes through, you know,",
      "offset": 2159.04,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "testing not just the graph itself, but",
      "offset": 2160.96,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "also the the UI uh and making sure it's",
      "offset": 2163.359,
      "duration": 7.321
    },
    {
      "lang": "en",
      "text": "it's kind of cohesive and makes sense.",
      "offset": 2166.24,
      "duration": 4.44
    },
    {
      "lang": "en",
      "text": "The next one guys comes from Brett. He",
      "offset": 2174,
      "duration": 5.599
    },
    {
      "lang": "en",
      "text": "says, &quot;If I understand correctly from",
      "offset": 2177.599,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "the earlier slides, despite the",
      "offset": 2179.599,
      "duration": 4.641
    },
    {
      "lang": "en",
      "text": "knowledge graph system being schemaless,",
      "offset": 2181.68,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "developing an ontology is useful in an",
      "offset": 2184.24,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "actual exercise to help nudge the",
      "offset": 2187.04,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "development and maintenance of the model",
      "offset": 2189.52,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "that the system develops. Are there any",
      "offset": 2191.68,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "useful mechanisms for enforcing that",
      "offset": 2194.4,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "ontology within the knowledge graph",
      "offset": 2196.96,
      "duration": 5.48
    },
    {
      "lang": "en",
      "text": "system automatically?&quot;",
      "offset": 2199.04,
      "duration": 3.4
    },
    {
      "lang": "en",
      "text": "Um, there are some mechanisms. Yes.",
      "offset": 2202.88,
      "duration": 9.04
    },
    {
      "lang": "en",
      "text": "But the uh the overall model that we're",
      "offset": 2207.68,
      "duration": 7.679
    },
    {
      "lang": "en",
      "text": "following is known as the uh property",
      "offset": 2211.92,
      "duration": 6.96
    },
    {
      "lang": "en",
      "text": "graph model which in its core is",
      "offset": 2215.359,
      "duration": 7.76
    },
    {
      "lang": "en",
      "text": "schemalis. The way in which you can",
      "offset": 2218.88,
      "duration": 7.76
    },
    {
      "lang": "en",
      "text": "start enforcing the schema",
      "offset": 2223.119,
      "duration": 7.041
    },
    {
      "lang": "en",
      "text": "uh the feature that falcob offers is",
      "offset": 2226.64,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "with constraints.",
      "offset": 2230.16,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "Um currently we have two different",
      "offset": 2232.16,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "constraints. one is unique constraints",
      "offset": 2234.16,
      "duration": 7.28
    },
    {
      "lang": "en",
      "text": "and the other one is exists constraints.",
      "offset": 2237.44,
      "duration": 7.12
    },
    {
      "lang": "en",
      "text": "The unique constraint make sure that an",
      "offset": 2241.44,
      "duration": 6.639
    },
    {
      "lang": "en",
      "text": "attribute is unique throughout",
      "offset": 2244.56,
      "duration": 6.24
    },
    {
      "lang": "en",
      "text": "uh an entire entity type. So for",
      "offset": 2248.079,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "example, social social security number",
      "offset": 2250.8,
      "duration": 8.559
    },
    {
      "lang": "en",
      "text": "should be unique for every uh person. Um",
      "offset": 2254.079,
      "duration": 8.721
    },
    {
      "lang": "en",
      "text": "in addition the exist uh constraint make",
      "offset": 2259.359,
      "duration": 7.921
    },
    {
      "lang": "en",
      "text": "sure that every entity of a certain type",
      "offset": 2262.8,
      "duration": 9.76
    },
    {
      "lang": "en",
      "text": "let's say a country um must have a",
      "offset": 2267.28,
      "duration": 7.52
    },
    {
      "lang": "en",
      "text": "population attribute. It doesn't have to",
      "offset": 2272.56,
      "duration": 6.48
    },
    {
      "lang": "en",
      "text": "be unique but it must exist.",
      "offset": 2274.8,
      "duration": 9.12
    },
    {
      "lang": "en",
      "text": "Um that's what we currently offer. It",
      "offset": 2279.04,
      "duration": 8.079
    },
    {
      "lang": "en",
      "text": "would not enforce for example",
      "offset": 2283.92,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "introducing new labels or new",
      "offset": 2287.119,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "relationship types that are not part of",
      "offset": 2289.92,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "the ontology.",
      "offset": 2291.839,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "It would not enforce the type of edges",
      "offset": 2293.52,
      "duration": 7.28
    },
    {
      "lang": "en",
      "text": "coming in or going out from a certain uh",
      "offset": 2297.359,
      "duration": 6.561
    },
    {
      "lang": "en",
      "text": "node type. So for example, if your",
      "offset": 2300.8,
      "duration": 6.96
    },
    {
      "lang": "en",
      "text": "ontology says that um there should not",
      "offset": 2303.92,
      "duration": 9.36
    },
    {
      "lang": "en",
      "text": "be an edge of type driven to uh that",
      "offset": 2307.76,
      "duration": 7.68
    },
    {
      "lang": "en",
      "text": "would not be enforced and I and I think",
      "offset": 2313.28,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "that over time",
      "offset": 2315.44,
      "duration": 6.08
    },
    {
      "lang": "en",
      "text": "uh the plan is into introduce",
      "offset": 2318.16,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "schema enforcement",
      "offset": 2321.52,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "mechanisms and features into Falore DB.",
      "offset": 2323.52,
      "duration": 6.96
    },
    {
      "lang": "en",
      "text": "But at the moment the intention is for",
      "offset": 2326.96,
      "duration": 4.879
    },
    {
      "lang": "en",
      "text": "or the",
      "offset": 2330.48,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "uh responsibility for the user to",
      "offset": 2331.839,
      "duration": 6.561
    },
    {
      "lang": "en",
      "text": "enforce the ontology to make sure that",
      "offset": 2335.44,
      "duration": 7.76
    },
    {
      "lang": "en",
      "text": "the underlying graph follows um follows",
      "offset": 2338.4,
      "duration": 6.959
    },
    {
      "lang": "en",
      "text": "the ontology and and that could be done",
      "offset": 2343.2,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "either uh via",
      "offset": 2345.359,
      "duration": 5.121
    },
    {
      "lang": "en",
      "text": "uh code that has been written by the",
      "offset": 2348.24,
      "duration": 6.08
    },
    {
      "lang": "en",
      "text": "user or by guiding an LLM to strictly",
      "offset": 2350.48,
      "duration": 6.8
    },
    {
      "lang": "en",
      "text": "follow the onology whenever doing",
      "offset": 2354.32,
      "duration": 6.48
    },
    {
      "lang": "en",
      "text": "updates, deletions or uh ingesting",
      "offset": 2357.28,
      "duration": 6.079
    },
    {
      "lang": "en",
      "text": "community.",
      "offset": 2360.8,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "I think there's um it's not a question,",
      "offset": 2363.359,
      "duration": 4.801
    },
    {
      "lang": "en",
      "text": "but it's rather a comment on what Brett",
      "offset": 2365.92,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "asked, and I think it ties in a little",
      "offset": 2368.16,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "bit with something Yoey talked about",
      "offset": 2370.4,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "when he spoke when he sorry, when he",
      "offset": 2372.079,
      "duration": 5.201
    },
    {
      "lang": "en",
      "text": "presented Fractal KG. So in response to",
      "offset": 2374.16,
      "duration": 6.24
    },
    {
      "lang": "en",
      "text": "Brett's question, we have Alec saying,",
      "offset": 2377.28,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "&quot;Based on my observation, the ontology",
      "offset": 2380.4,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "schema behaves like prompt engineering",
      "offset": 2383.04,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "technique with your LLM that you are",
      "offset": 2385.28,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "using to classify the data you are",
      "offset": 2387.92,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "processing either as entities or edges.&quot;",
      "offset": 2390,
      "duration": 7.8
    },
    {
      "lang": "en",
      "text": "What do we what do we think about that?",
      "offset": 2393.2,
      "duration": 4.6
    },
    {
      "lang": "en",
      "text": "I mean the ontology schema is something",
      "offset": 2399.76,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "you if you set ahead of time, right? I",
      "offset": 2401.92,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "think the the earlier point was it makes",
      "offset": 2404.32,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "retrieval easier because uh it's you can",
      "offset": 2406.079,
      "duration": 5.921
    },
    {
      "lang": "en",
      "text": "more deterministically uh ask questions",
      "offset": 2409.28,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "without worrying about uh having two",
      "offset": 2412,
      "duration": 5.119
    },
    {
      "lang": "en",
      "text": "similar edge types right because you've",
      "offset": 2415.04,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "already defined the edge types um and I",
      "offset": 2417.119,
      "duration": 3.281
    },
    {
      "lang": "en",
      "text": "think the original question was around",
      "offset": 2419.04,
      "duration": 2.96
    },
    {
      "lang": "en",
      "text": "whether whether you can enforce it in in",
      "offset": 2420.4,
      "duration": 3.679
    },
    {
      "lang": "en",
      "text": "the kg which it seems like it doesn't I",
      "offset": 2422,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "think and I don't know if I'm answering",
      "offset": 2424.079,
      "duration": 3.441
    },
    {
      "lang": "en",
      "text": "the question but you can enforce it up",
      "offset": 2425.44,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "front um using for example in my case I",
      "offset": 2427.52,
      "duration": 5.839
    },
    {
      "lang": "en",
      "text": "use structured outputs and so I asked",
      "offset": 2430.8,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "the structure output when I'm extracting",
      "offset": 2433.359,
      "duration": 5.921
    },
    {
      "lang": "en",
      "text": "data to extract nodes or edges uh in a",
      "offset": 2435.04,
      "duration": 6.72
    },
    {
      "lang": "en",
      "text": "specific format and if if I want certain",
      "offset": 2439.28,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "relationship types that'll just be one",
      "offset": 2441.76,
      "duration": 3.599
    },
    {
      "lang": "en",
      "text": "of these structured output parameters",
      "offset": 2443.92,
      "duration": 3.679
    },
    {
      "lang": "en",
      "text": "and I can stick an enum and you know",
      "offset": 2445.359,
      "duration": 5.201
    },
    {
      "lang": "en",
      "text": "give the specific types that I want um I",
      "offset": 2447.599,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "don't know if I'm answering that",
      "offset": 2450.56,
      "duration": 2.32
    },
    {
      "lang": "en",
      "text": "question but to some extent I think you",
      "offset": 2451.52,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "can use you know prompt engineering or",
      "offset": 2452.88,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "structured output engineering techniques",
      "offset": 2455.04,
      "duration": 5.279
    },
    {
      "lang": "en",
      "text": "to uh to enforce that ontology at least",
      "offset": 2456.8,
      "duration": 6.64
    },
    {
      "lang": "en",
      "text": "in the um in the data creation",
      "offset": 2460.319,
      "duration": 5.441
    },
    {
      "lang": "en",
      "text": "step before you throw it into the graph.",
      "offset": 2463.44,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "Um",
      "offset": 2465.76,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "I yeah I'm going to add to that. I think",
      "offset": 2467.44,
      "duration": 6.879
    },
    {
      "lang": "en",
      "text": "that um ontology can be thought of as",
      "offset": 2469.839,
      "duration": 7.361
    },
    {
      "lang": "en",
      "text": "home engineering. I think that the main",
      "offset": 2474.319,
      "duration": 7.76
    },
    {
      "lang": "en",
      "text": "idea here is to restrict or make sure",
      "offset": 2477.2,
      "duration": 9.68
    },
    {
      "lang": "en",
      "text": "that the LLM is aware of what exactly is",
      "offset": 2482.079,
      "duration": 8
    },
    {
      "lang": "en",
      "text": "captured in the in your knowledge graph.",
      "offset": 2486.88,
      "duration": 6.8
    },
    {
      "lang": "en",
      "text": "So think about the the situation in",
      "offset": 2490.079,
      "duration": 6.561
    },
    {
      "lang": "en",
      "text": "which you're telling your LLM, hey, you",
      "offset": 2493.68,
      "duration": 7.679
    },
    {
      "lang": "en",
      "text": "have access to a graph capturing",
      "offset": 2496.64,
      "duration": 6.24
    },
    {
      "lang": "en",
      "text": "um",
      "offset": 2501.359,
      "duration": 4.561
    },
    {
      "lang": "en",
      "text": "uh driving information. And that's all",
      "offset": 2502.88,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "the information that you're giving it in",
      "offset": 2505.92,
      "duration": 6.24
    },
    {
      "lang": "en",
      "text": "addition to a question uh that says um",
      "offset": 2507.76,
      "duration": 8.88
    },
    {
      "lang": "en",
      "text": "find me all of the driving sessions",
      "offset": 2512.16,
      "duration": 9.919
    },
    {
      "lang": "en",
      "text": "that um had a top speed",
      "offset": 2516.64,
      "duration": 9.6
    },
    {
      "lang": "en",
      "text": "over 60 miles. And so there are some",
      "offset": 2522.079,
      "duration": 7.361
    },
    {
      "lang": "en",
      "text": "hints within the question for the LLM to",
      "offset": 2526.24,
      "duration": 8.16
    },
    {
      "lang": "en",
      "text": "try and um guess which attributes, which",
      "offset": 2529.44,
      "duration": 8.159
    },
    {
      "lang": "en",
      "text": "nodes and which relationships are within",
      "offset": 2534.4,
      "duration": 4.959
    },
    {
      "lang": "en",
      "text": "the Nedcraft.",
      "offset": 2537.599,
      "duration": 4.801
    },
    {
      "lang": "en",
      "text": "But it would have made more sense and it",
      "offset": 2539.359,
      "duration": 5.601
    },
    {
      "lang": "en",
      "text": "would really help the LLM to get this",
      "offset": 2542.4,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "information up front knowing that there",
      "offset": 2544.96,
      "duration": 6.72
    },
    {
      "lang": "en",
      "text": "is a driving session entity. It has a",
      "offset": 2547.52,
      "duration": 7.2
    },
    {
      "lang": "en",
      "text": "top speed attribute. it is it is",
      "offset": 2551.68,
      "duration": 6.639
    },
    {
      "lang": "en",
      "text": "connected to roads and so now the LM is",
      "offset": 2554.72,
      "duration": 8.48
    },
    {
      "lang": "en",
      "text": "confined and it is um certain about what",
      "offset": 2558.319,
      "duration": 7.601
    },
    {
      "lang": "en",
      "text": "exactly is in the knowledge graph and",
      "offset": 2563.2,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "that would really boost the accuracy of",
      "offset": 2565.92,
      "duration": 6.32
    },
    {
      "lang": "en",
      "text": "the LLM when composing queries against",
      "offset": 2568.96,
      "duration": 6.52
    },
    {
      "lang": "en",
      "text": "the graph.",
      "offset": 2572.24,
      "duration": 3.24
    },
    {
      "lang": "en",
      "text": "Excellent. I'm looking at some of those",
      "offset": 2576.96,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "questions. Some have to do with uh",
      "offset": 2578.72,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "Yuri's projects and some speak more",
      "offset": 2581.28,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "about the core product that Falor",
      "offset": 2583.2,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "essentially has developed. Um so just in",
      "offset": 2585.44,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "the interest of time, I'm going to read",
      "offset": 2588,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "them from top to bottom. And no worries,",
      "offset": 2589.52,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "we're going to answer all of those",
      "offset": 2592.079,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "questions and the very detailed answers",
      "offset": 2593.2,
      "duration": 5.919
    },
    {
      "lang": "en",
      "text": "to all of them later on. But there's a",
      "offset": 2596,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "question that came in. What graph",
      "offset": 2599.119,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "embedding models are supported? And they",
      "offset": 2601.28,
      "duration": 7.72
    },
    {
      "lang": "en",
      "text": "specify node, edge, or graph embeddings?",
      "offset": 2604.079,
      "duration": 4.921
    },
    {
      "lang": "en",
      "text": "Oh, that's easy. Um,",
      "offset": 2609.68,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "none. Um,",
      "offset": 2612.64,
      "duration": 8.4
    },
    {
      "lang": "en",
      "text": "we do not have GNN's capabilities or",
      "offset": 2615.2,
      "duration": 8
    },
    {
      "lang": "en",
      "text": "graph embeddings. The only type of",
      "offset": 2621.04,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "embeddings that we're supporting at the",
      "offset": 2623.2,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "moment are vector embeddings. the ones",
      "offset": 2625.04,
      "duration": 7.039
    },
    {
      "lang": "en",
      "text": "in which you can generate with um",
      "offset": 2628.88,
      "duration": 5.84
    },
    {
      "lang": "en",
      "text": "different um",
      "offset": 2632.079,
      "duration": 5.441
    },
    {
      "lang": "en",
      "text": "LLMs or AI",
      "offset": 2634.72,
      "duration": 6.08
    },
    {
      "lang": "en",
      "text": "uh vendors. Uh once you have those",
      "offset": 2637.52,
      "duration": 6.24
    },
    {
      "lang": "en",
      "text": "vector embeddings, then you can utilize",
      "offset": 2640.8,
      "duration": 6.16
    },
    {
      "lang": "en",
      "text": "our semantic index to do vector",
      "offset": 2643.76,
      "duration": 6.48
    },
    {
      "lang": "en",
      "text": "searches. But I know that there's",
      "offset": 2646.96,
      "duration": 9.04
    },
    {
      "lang": "en",
      "text": "interest in GNN's to do both node label",
      "offset": 2650.24,
      "duration": 9.839
    },
    {
      "lang": "en",
      "text": "um prediction, edge prediction and uh",
      "offset": 2656,
      "duration": 6.64
    },
    {
      "lang": "en",
      "text": "subgraph classification.",
      "offset": 2660.079,
      "duration": 4.801
    },
    {
      "lang": "en",
      "text": "Unfortunately, that's that's not",
      "offset": 2662.64,
      "duration": 4.479
    },
    {
      "lang": "en",
      "text": "supported at the moment.",
      "offset": 2664.88,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "Yeah,",
      "offset": 2667.119,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "there's a question that came in from",
      "offset": 2669.04,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "Discord and they're asking, should I use",
      "offset": 2670.72,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "a knowledge graph per domain or a single",
      "offset": 2673.68,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "knowledge graph containing all the",
      "offset": 2676.48,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "domain data?",
      "offset": 2677.839,
      "duration": 6.881
    },
    {
      "lang": "en",
      "text": "So, this is a cool question. Um,",
      "offset": 2680.24,
      "duration": 6.96
    },
    {
      "lang": "en",
      "text": "I think that it really depends on the",
      "offset": 2684.72,
      "duration": 5.359
    },
    {
      "lang": "en",
      "text": "use case, but let me say this. If you do",
      "offset": 2687.2,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "see value in storing all of your",
      "offset": 2690.079,
      "duration": 4.481
    },
    {
      "lang": "en",
      "text": "information which might span across",
      "offset": 2692.48,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "multiple domains in a single graph, you",
      "offset": 2694.56,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "can do that. Uh and the nice thing about",
      "offset": 2697.92,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "this is that you can have multiple",
      "offset": 2700.56,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "ontologies",
      "offset": 2702.4,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "all describing describing different",
      "offset": 2703.92,
      "duration": 5.199
    },
    {
      "lang": "en",
      "text": "portions of your graph. So you would",
      "offset": 2706.319,
      "duration": 6.961
    },
    {
      "lang": "en",
      "text": "have one ontology for example defining",
      "offset": 2709.119,
      "duration": 8.401
    },
    {
      "lang": "en",
      "text": "um one domain which might be uh around",
      "offset": 2713.28,
      "duration": 7.839
    },
    {
      "lang": "en",
      "text": "driving sessions but your graph expands",
      "offset": 2717.52,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "further. It doesn't contains only",
      "offset": 2721.119,
      "duration": 6.48
    },
    {
      "lang": "en",
      "text": "driving sessions with roads and",
      "offset": 2723.52,
      "duration": 7.52
    },
    {
      "lang": "en",
      "text": "intersections. It might contain um other",
      "offset": 2727.599,
      "duration": 6.48
    },
    {
      "lang": "en",
      "text": "information that is still related to",
      "offset": 2731.04,
      "duration": 6.799
    },
    {
      "lang": "en",
      "text": "that. let's say cities and population",
      "offset": 2734.079,
      "duration": 5.921
    },
    {
      "lang": "en",
      "text": "and universities",
      "offset": 2737.839,
      "duration": 6.401
    },
    {
      "lang": "en",
      "text": "uh whatever have you. Um but then you",
      "offset": 2740,
      "duration": 6.8
    },
    {
      "lang": "en",
      "text": "can still have maintaining you can still",
      "offset": 2744.24,
      "duration": 5.119
    },
    {
      "lang": "en",
      "text": "maintain two different ontologies. One",
      "offset": 2746.8,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "which is focusing on the driving",
      "offset": 2749.359,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "sessions and the other one which focus",
      "offset": 2750.96,
      "duration": 9.6
    },
    {
      "lang": "en",
      "text": "on let's say um population and uh um",
      "offset": 2753.839,
      "duration": 8.561
    },
    {
      "lang": "en",
      "text": "employment.",
      "offset": 2760.56,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "Um but those two all coexist within a",
      "offset": 2762.4,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "single graph. It is the LLM and the",
      "offset": 2765.44,
      "duration": 7.04
    },
    {
      "lang": "en",
      "text": "ontology that is represented to it um",
      "offset": 2768.4,
      "duration": 7.439
    },
    {
      "lang": "en",
      "text": "that would know how to filter or focus",
      "offset": 2772.48,
      "duration": 6.56
    },
    {
      "lang": "en",
      "text": "on the relevant pieces of of information",
      "offset": 2775.839,
      "duration": 7.681
    },
    {
      "lang": "en",
      "text": "within this uh larger graph.",
      "offset": 2779.04,
      "duration": 6.799
    },
    {
      "lang": "en",
      "text": "The other option is is you know if you",
      "offset": 2783.52,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "don't see value in connecting everything",
      "offset": 2785.839,
      "duration": 4.961
    },
    {
      "lang": "en",
      "text": "together is another very cool feature of",
      "offset": 2787.68,
      "duration": 7.04
    },
    {
      "lang": "en",
      "text": "Falor DB uh that allows you to maintain",
      "offset": 2790.8,
      "duration": 7.76
    },
    {
      "lang": "en",
      "text": "multiple graphs in a single database.",
      "offset": 2794.72,
      "duration": 8.879
    },
    {
      "lang": "en",
      "text": "And so similar to uh SQL where you have",
      "offset": 2798.56,
      "duration": 8.16
    },
    {
      "lang": "en",
      "text": "multiple tables within a single database",
      "offset": 2803.599,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "here you can have multiple disjoint",
      "offset": 2806.72,
      "duration": 8
    },
    {
      "lang": "en",
      "text": "graphs all within a single database. Um",
      "offset": 2809.599,
      "duration": 7.841
    },
    {
      "lang": "en",
      "text": "so you can keep them separated, you can",
      "offset": 2814.72,
      "duration": 5.84
    },
    {
      "lang": "en",
      "text": "join them together, you can have one",
      "offset": 2817.44,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "ontology per graph or you can have",
      "offset": 2820.56,
      "duration": 4.799
    },
    {
      "lang": "en",
      "text": "multiple ontologies capturing data from",
      "offset": 2822.48,
      "duration": 7.359
    },
    {
      "lang": "en",
      "text": "SAB graphs within a single one.",
      "offset": 2825.359,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "I'm glad you brought the multi-tenency",
      "offset": 2830.8,
      "duration": 5.039
    },
    {
      "lang": "en",
      "text": "aspect of it. Uh the next question is",
      "offset": 2833.04,
      "duration": 5.92
    },
    {
      "lang": "en",
      "text": "for Yoi. Uh if VCPedia supported",
      "offset": 2835.839,
      "duration": 5.361
    },
    {
      "lang": "en",
      "text": "multiple languages, would you add a",
      "offset": 2838.96,
      "duration": 5.119
    },
    {
      "lang": "en",
      "text": "translation step or store the tweets in",
      "offset": 2841.2,
      "duration": 6.56
    },
    {
      "lang": "en",
      "text": "their original language?",
      "offset": 2844.079,
      "duration": 7.441
    },
    {
      "lang": "en",
      "text": "I would probably store the tweets in the",
      "offset": 2847.76,
      "duration": 7.359
    },
    {
      "lang": "en",
      "text": "original language and simply translate",
      "offset": 2851.52,
      "duration": 7.839
    },
    {
      "lang": "en",
      "text": "the output of the site.",
      "offset": 2855.119,
      "duration": 5.681
    },
    {
      "lang": "en",
      "text": "But that's just my gut reaction. I don't",
      "offset": 2859.359,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "really have a strong reason for it.",
      "offset": 2860.8,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "Yeah, I wish I wish maybe the question",
      "offset": 2863.119,
      "duration": 4.561
    },
    {
      "lang": "en",
      "text": "uh elaborated a bit more, but you know,",
      "offset": 2865.2,
      "duration": 4.879
    },
    {
      "lang": "en",
      "text": "that's actually what I had in mind that",
      "offset": 2867.68,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "you would say.",
      "offset": 2870.079,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "Uh so we have another question from uh",
      "offset": 2871.76,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "Discord that I think is actually very",
      "offset": 2874.24,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "interesting. Uh we touched on it early",
      "offset": 2875.76,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "on I think a little bit in the beginning",
      "offset": 2878.96,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "but maybe it's worth uh taking maybe a",
      "offset": 2880.96,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "few minutes to talk about it as well.",
      "offset": 2883.44,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "How does an ontology scale when my data",
      "offset": 2885.119,
      "duration": 5.281
    },
    {
      "lang": "en",
      "text": "updates?",
      "offset": 2887.839,
      "duration": 6.24
    },
    {
      "lang": "en",
      "text": "Okay. So it really depends on the",
      "offset": 2890.4,
      "duration": 6.8
    },
    {
      "lang": "en",
      "text": "update. I mean you can think there are",
      "offset": 2894.079,
      "duration": 5.681
    },
    {
      "lang": "en",
      "text": "for this particular question you can",
      "offset": 2897.2,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "think about two different types of",
      "offset": 2899.76,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "updates. One updates that doesn't change",
      "offset": 2901.04,
      "duration": 4.799
    },
    {
      "lang": "en",
      "text": "the ontology meaning that you're just",
      "offset": 2904,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "adding a new city or a new university or",
      "offset": 2905.839,
      "duration": 5.841
    },
    {
      "lang": "en",
      "text": "a new person into your graph that",
      "offset": 2908.319,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "doesn't change the ontology. It remain",
      "offset": 2911.68,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "the same. The other type of update is if",
      "offset": 2913.599,
      "duration": 6.321
    },
    {
      "lang": "en",
      "text": "you anti adding a new type of entity.",
      "offset": 2916.88,
      "duration": 6.64
    },
    {
      "lang": "en",
      "text": "So, for example, maybe you are adding",
      "offset": 2919.92,
      "duration": 7.76
    },
    {
      "lang": "en",
      "text": "uh a truck to your driving session which",
      "offset": 2923.52,
      "duration": 7.44
    },
    {
      "lang": "en",
      "text": "only had cars in it, but now there is a",
      "offset": 2927.68,
      "duration": 9.04
    },
    {
      "lang": "en",
      "text": "truck. And so, um we do not enforce",
      "offset": 2930.96,
      "duration": 8.32
    },
    {
      "lang": "en",
      "text": "um alignment between the underlying",
      "offset": 2936.72,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "graph and the ontology. This is",
      "offset": 2939.28,
      "duration": 6.319
    },
    {
      "lang": "en",
      "text": "something that the user need to maintain",
      "offset": 2942.48,
      "duration": 5.119
    },
    {
      "lang": "en",
      "text": "just like the way in which we're not",
      "offset": 2945.599,
      "duration": 5.681
    },
    {
      "lang": "en",
      "text": "enforcing schema. Um whenever you're",
      "offset": 2947.599,
      "duration": 8.881
    },
    {
      "lang": "en",
      "text": "introducing a new type of entity it is",
      "offset": 2951.28,
      "duration": 9.279
    },
    {
      "lang": "en",
      "text": "uh you should extend your ontology to",
      "offset": 2956.48,
      "duration": 6.4
    },
    {
      "lang": "en",
      "text": "capture that. So with this truck",
      "offset": 2960.559,
      "duration": 5.121
    },
    {
      "lang": "en",
      "text": "example, you should add a new entity to",
      "offset": 2962.88,
      "duration": 6.719
    },
    {
      "lang": "en",
      "text": "your ontology describing",
      "offset": 2965.68,
      "duration": 6.96
    },
    {
      "lang": "en",
      "text": "u how does the truck looks like, meaning",
      "offset": 2969.599,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "the the attributes associated with it",
      "offset": 2972.64,
      "duration": 6.4
    },
    {
      "lang": "en",
      "text": "and the different type of relationship",
      "offset": 2975.599,
      "duration": 7.121
    },
    {
      "lang": "en",
      "text": "um that are interacting with the with",
      "offset": 2979.04,
      "duration": 7.48
    },
    {
      "lang": "en",
      "text": "this new truck entity.",
      "offset": 2982.72,
      "duration": 3.8
    },
    {
      "lang": "en",
      "text": "I want to um since we only have 10",
      "offset": 2989.44,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "minutes left, I think it would be worthy",
      "offset": 2992.559,
      "duration": 4.881
    },
    {
      "lang": "en",
      "text": "to take one more question and then there",
      "offset": 2994.88,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "was another question on Discord that uh",
      "offset": 2997.44,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "I think sort of leads into what I want",
      "offset": 3000.16,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "to say to sort of recap everything. So",
      "offset": 3002.64,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "the question we got from Discord was is",
      "offset": 3005.76,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "there an automated way to build a",
      "offset": 3007.92,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "knowledge graph which is the topic for",
      "offset": 3009.76,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "actually the next workshop we want to",
      "offset": 3013.04,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "put together. So, let me pause on that",
      "offset": 3014.64,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "and we're going to go into what we're",
      "offset": 3016.8,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "going to do next time, which is a more",
      "offset": 3018.48,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "of a hands-on workshop that talks",
      "offset": 3020,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "specifically about that. But the other",
      "offset": 3021.76,
      "duration": 7.2
    },
    {
      "lang": "en",
      "text": "question that we got here on uh Zoom is",
      "offset": 3025.04,
      "duration": 6.16
    },
    {
      "lang": "en",
      "text": "how can I improve the attribute",
      "offset": 3028.96,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "extraction for each entity from my",
      "offset": 3031.2,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "strict ontology schema for my knowledge",
      "offset": 3034,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "graph. For example, I would get",
      "offset": 3036.96,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "non-relevant context assigned to an",
      "offset": 3038.8,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "entity or incomplete.",
      "offset": 3041.04,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "uh I hypothesize my chunking is wrong or",
      "offset": 3043.76,
      "duration": 5.839
    },
    {
      "lang": "en",
      "text": "I need to employ more natural language",
      "offset": 3046.72,
      "duration": 6.76
    },
    {
      "lang": "en",
      "text": "processing steps.",
      "offset": 3049.599,
      "duration": 3.881
    },
    {
      "lang": "en",
      "text": "The again it's hard to see I feel like",
      "offset": 3053.839,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "with graphs it's hard to solve a problem",
      "offset": 3057.28,
      "duration": 4.799
    },
    {
      "lang": "en",
      "text": "without knowing the specifics because it",
      "offset": 3059.839,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "is really kind of case by case in terms",
      "offset": 3062.079,
      "duration": 3.441
    },
    {
      "lang": "en",
      "text": "of like what data you're playing with.",
      "offset": 3064,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "But the few things that popped to mind",
      "offset": 3065.52,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "um that's worked for me again in",
      "offset": 3068.079,
      "duration": 4.721
    },
    {
      "lang": "en",
      "text": "different cases is uh I mean Kshot is",
      "offset": 3069.76,
      "duration": 4.559
    },
    {
      "lang": "en",
      "text": "always helpful right giving a couple of",
      "offset": 3072.8,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "examples",
      "offset": 3074.319,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "um if you're converting large documents",
      "offset": 3075.92,
      "duration": 6.88
    },
    {
      "lang": "en",
      "text": "and you need to chunk it uh again this",
      "offset": 3079.599,
      "duration": 4.801
    },
    {
      "lang": "en",
      "text": "is a simple example but sometimes you",
      "offset": 3082.8,
      "duration": 3.519
    },
    {
      "lang": "en",
      "text": "need kind of higher level context of the",
      "offset": 3084.4,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "document for each chunk right a simple",
      "offset": 3086.319,
      "duration": 5.601
    },
    {
      "lang": "en",
      "text": "example might be it's you know the book",
      "offset": 3089.28,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "starts by using people names but later",
      "offset": 3091.92,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "on it uses he or she instead said and if",
      "offset": 3093.599,
      "duration": 3.361
    },
    {
      "lang": "en",
      "text": "you grab that paragraph and try to",
      "offset": 3095.52,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "convert it that he like the name might",
      "offset": 3096.96,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "not be matching. So you might need to",
      "offset": 3099.52,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "have kind of higher level context that",
      "offset": 3101.119,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "you feed into the chunk if you're",
      "offset": 3102.88,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "chunking and then extracting. Um and",
      "offset": 3104.319,
      "duration": 6.081
    },
    {
      "lang": "en",
      "text": "then uh and then just uh I think a lot",
      "offset": 3108.16,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "of uh I I found that um adding clear",
      "offset": 3110.4,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "descriptions when you use structured",
      "offset": 3114.16,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "output for each parameter, you can",
      "offset": 3115.92,
      "duration": 3.199
    },
    {
      "lang": "en",
      "text": "provide descriptions, you can provide",
      "offset": 3117.52,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "kind of hard-coded rules on on options",
      "offset": 3119.119,
      "duration": 5.921
    },
    {
      "lang": "en",
      "text": "um and and using that kind of the the",
      "offset": 3121.839,
      "duration": 6.321
    },
    {
      "lang": "en",
      "text": "structured output defining JSON uh uh",
      "offset": 3125.04,
      "duration": 5.92
    },
    {
      "lang": "en",
      "text": "and uh improving the prompt there um I",
      "offset": 3128.16,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "found is also helpful. So those just",
      "offset": 3130.96,
      "duration": 2.48
    },
    {
      "lang": "en",
      "text": "those are just some techniques that",
      "offset": 3132.24,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "popped in my mind.",
      "offset": 3133.44,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "Right. Yeah, I think that going",
      "offset": 3135.52,
      "duration": 6.16
    },
    {
      "lang": "en",
      "text": "structure can can really help here. Um,",
      "offset": 3137.839,
      "duration": 5.441
    },
    {
      "lang": "en",
      "text": "I don't know if this feature is still",
      "offset": 3141.68,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "available, but uh back then a few months",
      "offset": 3143.28,
      "duration": 7.12
    },
    {
      "lang": "en",
      "text": "ago where I uh was constructing",
      "offset": 3146.4,
      "duration": 6.88
    },
    {
      "lang": "en",
      "text": "knowledge graph from unstructured data,",
      "offset": 3150.4,
      "duration": 6.56
    },
    {
      "lang": "en",
      "text": "open a open AI had this feature of",
      "offset": 3153.28,
      "duration": 5.92
    },
    {
      "lang": "en",
      "text": "defining functions.",
      "offset": 3156.96,
      "duration": 6.08
    },
    {
      "lang": "en",
      "text": "Um so you can define functions or tools",
      "offset": 3159.2,
      "duration": 8.72
    },
    {
      "lang": "en",
      "text": "or your LLM to uh use whenever um",
      "offset": 3163.04,
      "duration": 8.96
    },
    {
      "lang": "en",
      "text": "instructed to let's say extract entities",
      "offset": 3167.92,
      "duration": 8
    },
    {
      "lang": "en",
      "text": "and relations from documents. And so",
      "offset": 3172,
      "duration": 7.28
    },
    {
      "lang": "en",
      "text": "what what I did was to say okay I have",
      "offset": 3175.92,
      "duration": 6.48
    },
    {
      "lang": "en",
      "text": "let's for example five different types",
      "offset": 3179.28,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "of entities. So I would create a",
      "offset": 3182.4,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "function",
      "offset": 3184.72,
      "duration": 5.359
    },
    {
      "lang": "en",
      "text": "uh create function for each one of those",
      "offset": 3186.319,
      "duration": 7.441
    },
    {
      "lang": "en",
      "text": "and each function would get a set of um",
      "offset": 3190.079,
      "duration": 7.28
    },
    {
      "lang": "en",
      "text": "arguments attributes. Some of them were",
      "offset": 3193.76,
      "duration": 6.88
    },
    {
      "lang": "en",
      "text": "optionals other were mandatory. uh you",
      "offset": 3197.359,
      "duration": 7.361
    },
    {
      "lang": "en",
      "text": "can specify the type and now the LLM is",
      "offset": 3200.64,
      "duration": 9.12
    },
    {
      "lang": "en",
      "text": "equipped with the with this uh set of",
      "offset": 3204.72,
      "duration": 8
    },
    {
      "lang": "en",
      "text": "functions and so it is the LLM",
      "offset": 3209.76,
      "duration": 6.72
    },
    {
      "lang": "en",
      "text": "responsibility to invoke uh the most",
      "offset": 3212.72,
      "duration": 7.28
    },
    {
      "lang": "en",
      "text": "relevant function whenever it encounters",
      "offset": 3216.48,
      "duration": 5.839
    },
    {
      "lang": "en",
      "text": "data that can be translated into an",
      "offset": 3220,
      "duration": 6.319
    },
    {
      "lang": "en",
      "text": "entity and so the LM knows okay I'm for",
      "offset": 3222.319,
      "duration": 7.76
    },
    {
      "lang": "en",
      "text": "example I'm seeing here um some",
      "offset": 3226.319,
      "duration": 7.121
    },
    {
      "lang": "en",
      "text": "description of a city. Okay. Do I have a",
      "offset": 3230.079,
      "duration": 6.081
    },
    {
      "lang": "en",
      "text": "create city function? Yes. Okay. Which",
      "offset": 3233.44,
      "duration": 4.639
    },
    {
      "lang": "en",
      "text": "arguments do I need? Oh, the name is",
      "offset": 3236.16,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "mandatory and it should be a string. And",
      "offset": 3238.079,
      "duration": 5.601
    },
    {
      "lang": "en",
      "text": "so now the LM is very restricted and",
      "offset": 3240.96,
      "duration": 6.72
    },
    {
      "lang": "en",
      "text": "have certain rules uh to follow when",
      "offset": 3243.68,
      "duration": 6.879
    },
    {
      "lang": "en",
      "text": "invoking a function or you know creating",
      "offset": 3247.68,
      "duration": 7.36
    },
    {
      "lang": "en",
      "text": "an entity. So that really helped out.",
      "offset": 3250.559,
      "duration": 7.921
    },
    {
      "lang": "en",
      "text": "Um, so that's another uh way that you",
      "offset": 3255.04,
      "duration": 6.319
    },
    {
      "lang": "en",
      "text": "can go about uh experimenting with",
      "offset": 3258.48,
      "duration": 5.119
    },
    {
      "lang": "en",
      "text": "detecting and creating entities from",
      "offset": 3261.359,
      "duration": 5.441
    },
    {
      "lang": "en",
      "text": "unstructured data.",
      "offset": 3263.599,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "Super good. I'm going to hijack the",
      "offset": 3266.8,
      "duration": 5.759
    },
    {
      "lang": "en",
      "text": "screen just for a little bit.",
      "offset": 3269.599,
      "duration": 5.841
    },
    {
      "lang": "en",
      "text": "Can everybody see me?",
      "offset": 3272.559,
      "duration": 6.081
    },
    {
      "lang": "en",
      "text": "Yep. Perfect. So, first of all, thank",
      "offset": 3275.44,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "you Yoi for taking the time. Thank you,",
      "offset": 3278.64,
      "duration": 4.959
    },
    {
      "lang": "en",
      "text": "Roy, for you are my trusty partner.",
      "offset": 3280.88,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "We're doing this maybe for the fifth",
      "offset": 3283.599,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "time. We're getting I think really good",
      "offset": 3285.04,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "at this and every time I think the level",
      "offset": 3287.28,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "of questions that we're getting I'm",
      "offset": 3289.52,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "really liking it every time we're I",
      "offset": 3291.52,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "would say it's a healthy balance between",
      "offset": 3293.68,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "challenge and just uh passion like it's",
      "offset": 3295.28,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "what we do every day and it's nice to",
      "offset": 3298,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "share it with everybody. Uh speaking",
      "offset": 3299.359,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "about the question we got on discord on",
      "offset": 3302,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "how to actually build a knowledge graph.",
      "offset": 3304.079,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "This is exactly what we want to do next",
      "offset": 3306.079,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "time we meet. Uh, I put up here on the",
      "offset": 3307.76,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "screen a QR code, but you don't have to",
      "offset": 3310.24,
      "duration": 3.119
    },
    {
      "lang": "en",
      "text": "scan it right now. If you don't have a",
      "offset": 3312.079,
      "duration": 2.48
    },
    {
      "lang": "en",
      "text": "phone, I'm definitely going to send you",
      "offset": 3313.359,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "a link later. Um, but this would be the",
      "offset": 3314.559,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "topic of what we're doing the next time.",
      "offset": 3317.839,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "We want to be able to show you how you",
      "offset": 3319.839,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "construct a graph, how we go about this,",
      "offset": 3321.76,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "the methodology that we use, and also",
      "offset": 3323.92,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "the logic behind how we do what we do.",
      "offset": 3326.48,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "Uh, that's happening in a little bit",
      "offset": 3329.2,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "over a month. So, uh, that you",
      "offset": 3331.04,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "definitely have time to sign up. And",
      "offset": 3333.359,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "there's a few questions that I saw on",
      "offset": 3335.76,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "the Q&amp;A. U everything that we do here is",
      "offset": 3337.839,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "recorded. It's going to be on Discord",
      "offset": 3340.64,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "and on YouTube within the next 24 hours.",
      "offset": 3342.079,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "So there's no worries if you've missed",
      "offset": 3344.559,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "parts of it in the beginning. And we're",
      "offset": 3346.079,
      "duration": 4.881
    },
    {
      "lang": "en",
      "text": "going to like we did last time, we sort",
      "offset": 3348.48,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "of collate all the questions that were",
      "offset": 3350.96,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "pulled here. We're going to answer them",
      "offset": 3353.52,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "and that's going to be something that",
      "offset": 3355.119,
      "duration": 3.121
    },
    {
      "lang": "en",
      "text": "exists on our blog so that you can",
      "offset": 3356.64,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "revisit it later. And also we tend to",
      "offset": 3358.24,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "pick out the really good questions that",
      "offset": 3360.799,
      "duration": 3.361
    },
    {
      "lang": "en",
      "text": "we wanted to focus on and put that in an",
      "offset": 3362.319,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "email as well. So nothing is lost there.",
      "offset": 3364.16,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "There's no worries there. Uh and we",
      "offset": 3366.079,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "really if you felt this was uh useful to",
      "offset": 3368.4,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "what you're building right now, I think",
      "offset": 3371.359,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "the next installment on in July on how",
      "offset": 3372.799,
      "duration": 4.721
    },
    {
      "lang": "en",
      "text": "to actually build a knowledge graph is",
      "offset": 3375.359,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "something you definitely want to check",
      "offset": 3377.52,
      "duration": 3.599
    },
    {
      "lang": "en",
      "text": "out. Uh with that being said, I really",
      "offset": 3378.799,
      "duration": 4.641
    },
    {
      "lang": "en",
      "text": "appreciate you guys' time um speaking",
      "offset": 3381.119,
      "duration": 4.801
    },
    {
      "lang": "en",
      "text": "with us today. I thought it was awesome.",
      "offset": 3383.44,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "um every time we do one of these",
      "offset": 3385.92,
      "duration": 3.679
    },
    {
      "lang": "en",
      "text": "workshops and somebody shares their",
      "offset": 3387.599,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "screen and actually shows a project that",
      "offset": 3389.599,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "they've worked on and sort of explains",
      "offset": 3391.44,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "the rationale behind it that's the kind",
      "offset": 3392.799,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "of content I want to consume and I think",
      "offset": 3394.64,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "that's the kind of content people are",
      "offset": 3396.4,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "coming here for. So I would say for",
      "offset": 3398.4,
      "duration": 3.679
    },
    {
      "lang": "en",
      "text": "there are a few people that I'm",
      "offset": 3400.72,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "recognizing have attended before but for",
      "offset": 3402.079,
      "duration": 6.081
    },
    {
      "lang": "en",
      "text": "those who are new to um to this sort of",
      "offset": 3404.4,
      "duration": 6.48
    },
    {
      "lang": "en",
      "text": "format of what does these tend to be the",
      "offset": 3408.16,
      "duration": 4.639
    },
    {
      "lang": "en",
      "text": "sort of conversations that we're having",
      "offset": 3410.88,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "tend to be very technical and very",
      "offset": 3412.799,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "hands-on. So, we hope you appreciate it.",
      "offset": 3414.24,
      "duration": 4.559
    },
    {
      "lang": "en",
      "text": "Um, anything else we want to say, Yoi,",
      "offset": 3416.559,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "Roy, before we go? No, thanks for having",
      "offset": 3418.799,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "me. It's always fun to nerd out on",
      "offset": 3421.839,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "graphs. 100%. Yeah, these are really",
      "offset": 3423.119,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "cool projects. I think when we were",
      "offset": 3425.92,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "putting this together, I was I thought",
      "offset": 3427.119,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "it was really cool. I really wanted you",
      "offset": 3428.96,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "to share it with everyone. Um,",
      "offset": 3430.319,
      "duration": 5.201
    },
    {
      "lang": "en",
      "text": "I'm seeing more questions come in. Uh,",
      "offset": 3433.44,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "there's no worries. We're going to, like",
      "offset": 3435.52,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "I said, pull all of them together and",
      "offset": 3436.88,
      "duration": 4.479
    },
    {
      "lang": "en",
      "text": "answer them. Um, with that being said,",
      "offset": 3438.64,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "please uh scan the QR code that you see",
      "offset": 3441.359,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "here to join us on the next event. Uh,",
      "offset": 3443.28,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "if you can't, there's no worries. After",
      "offset": 3445.599,
      "duration": 2.96
    },
    {
      "lang": "en",
      "text": "this event is finished, I'm going to",
      "offset": 3447.28,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "send the link. And with that being said,",
      "offset": 3448.559,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "I we want to thank you for for being",
      "offset": 3451.04,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "with us today, and we'll see you the",
      "offset": 3453.119,
      "duration": 5.761
    },
    {
      "lang": "en",
      "text": "next time. Thank you. Thanks, guys.",
      "offset": 3454.64,
      "duration": 7.24
    },
    {
      "lang": "en",
      "text": "Thanks.",
      "offset": 3458.88,
      "duration": 3
    }
  ],
  "cleanText": "Really nice to see familiar faces and familiar names joining us again.\nSo, thanks for being here.\nUh, Roy and I are actually really glad to welcome Yohei.\nHe's here with us today to chat and demo really cool projects that he's built.\nUh, and we're going to take a closer look today at knowledge graphs.\nThis is actually the fifth installment that we're doing in the series, uh, Graph and RAG.\nAnd, um, before we're going to go into it, just a bit of an introduction.\nUh, FalkorDB is an open-source graph database management system, uh, designed to manage connected data and complex relationships.\nUh, by representing data as interconnected nodes and edges, the system enables really efficient storage and super fast retrieval.\nThere's a Q&A in the end, uh, so you can feel free to send your questions in the chat box below.\nWe're going to collect them.\nThose that we can get to, definitely we'll get back to you over email or Discord.\nUh, but without further ado, let's kick things off and we'll go ahead and share our screen.\nNot too many slides, a lot of uh, really hands-on stuff.\nSo, we're in for something really interesting in my opinion.\nRoy, do you want to share or do you want me to?\nNo, go ahead.\nYou can share the screen.\nI think we're kicking things off, uh, with one of Yohei's demos, but\nOh, yeah.\nI mean, we could show the title slider.\nWe can just dive into the demo.\nUh, yeah, let's go right ahead.\nActually, the only show is VCPedia.\nSo, that's actually the first project we want to show.\nSo, let's go right ahead.\nYeah, this is a project from a few weeks ago.\nUm, uh, the history is that I spend a lot of time on Twitter and X.\nThat's where I do a lot of learning.\nI learn a lot about AI trends.\nUm, and I, and so I thought I would, uh, try building a tool to capture AI trends on Twitter, um, using the Twitter API.\nWhen I was running that experiment, um, I noticed it was capturing funding rounds.\nAnd as a VC, knowing, you know, up-to-date information on funding rounds, especially at the pre-seed stage, which, which you don't find on a lot of other, uh, databases, uh, is important.\nI'm a pre-seed investor, and I noticed that a lot of pre-seed funding rounds were being announced on Twitter.\nSo I, uh, had this idea on a Friday, uh, vibe coded it with Replet, and I'm going to go ahead and share it with you.\nUm, it looks like this, uh, VCPedia, um, the number of startups, investors, rounds, and recent funding.\nThis is what's been captured this week.\nUm, here's some trending startups based on social signals.\nIt does capture some noise.\nUm, I'll touch on that.\nUh, funding rounds by type, funding trends, uh, notable AI startups.\nI set up a section for that, cuz that's something I'm personally curious about.\nAnd then you can see kind of the recently funded, uh, added funding rounds.\nNow, if you click into one of the startups, for example, Pistachio, you know, this is the most recently captured funding round.\nI click through to it, it will give me information about\nLet's give it a second.\nUm, it's not optimized for speed.\nUh, it captures information, um, company info, business info, industry tags, business model, similar startups, which is just a vector search against other startups in the system.\nUm, funding, uh, funding rounds it's captured on Twitter.\nAgain, this doesn't go historical.\nIt's only capturing funding rounds from when I started this, um, investors, uh, that it'll extract and create a page for, and then you can see the, uh, actual tweets where it captured the, um, the funding round.\nWhen you go, or I guess if you go back here and you look at, you know, the ones that are trending, and let's say if I were to click through, those, those will be, um, those are actually using social signals.\nSo if we click through to the tweet, you'll see that those tweets are getting a lot of engagement.\nSo, the way this is set up, actually, I did a little, um,\nyes, if you click through to here, you see this, you know, Twitter announcement.\nSo, this one said it was trending.\nSo, if I click through, I'm likely going to see that this one has a decent amount of engagement.\nSo, I'm not just capturing funding rounds, but I'm also able to identify funding rounds that captured a lot of people's attention.\nThis is really helpful for me.\nUm, I, I threw the code into NLM to describe how it's working is that I have the Twitter API, a couple search queries set up, uh, that run on a certain frequency.\nIt runs through the Twitter client.\nI enhance the queries a little bit.\nYou know, I don't want retweets.\nI want to make sure they're verified just to remove some noise.\nUm, we, I dduplicate tweets because I don't want to analyze the same tweet twice.\nAnd then once we have a tweet object, then we will go through a funding detection.\nIs there a funding round?\nIf there is, let's extract the information that it has, uh, which is, uh, information about the startup, the funding round, the founders, and the investors.\nUm, there's an entity resolution layer here where for all of these, it will go through a dduplication, um, to see if it already, uh, if any of these exist, such as the startup, the founders, the investors, and then once, uh, it's dduplicated, then there's a data enrichment layer.\nYou see here, there's like SER, EXA, OpenAI.\nI tried a couple of different enrichments, but they'll enrich the data, and then, uh, this all gets added into the relationship tables.\nSo, that's kind of VCPedia, um, as a, as a quick intro.\nI know we were going to talk about this a little bit, but this is very, very cool.\nUm, so I would say with that background, I think Roy, now would be a good time to sort of go into a little bit about what's happening in the background so that when we're further talking about this, we can refer back and people understand sort of what we're referring to.\nSo I'm going to go ahead and maybe, uh, actually, Yi, I'm seeing you have the slides open on your end.\nMaybe you can jump.\nI, I did open them up.\nPerfect.\nYeah.\nSo essentially what we have was VCPedia, and then we wanted to go a little bit into, um, the fundamentals of a knowledge graph of what's happening behind the scenes, which is slide number three.\nCool.\nRight.\nSo thank you Yoi and, uh, Dan, um, in a, in a kind of a brief, we, we have just a few slides to give the audience some information about what's empowering all of those new applications that are coming into the market and, um, are using LLMs and AI to drive both insights, but also really help with capturing the data, uh, analyzing it, and then, uh, prepare it for storage.\nAnd so one of the fundamental data structures that are being used these days is a knowledge graph.\nAnd a knowledge graph is not a new idea.\nIt's been around for at least 10 years now, but now with the explosion of Gen AI, um, it got the spotlight back on it.\nAnd so with a knowledge graph, basically, you have, uh, graph entities.\nThose are either nodes, which represent some type of an entity in your domain, and then you can connect those entities with edges to capture the different relationships between them.\nNodes and edges can be labeled.\nSo you can have a label representing a person, and you can have an edge, um, capturing some type of an interaction, for example, between two different persons.\nAlso, you can enrich the data with an attribute set, and the attribute set is basically, you can think of it as a key-value storage, um, attached to a graph entity.\nSo, for example, a person can have an attribute set containing name, maybe a zip code, a birth date, um, whatever information you need to make the entity usable for your use case.\nUm, and obviously, there's a variety of different data types that can be used, such as numerical values, strings, array, vectors, uh, and more.\nIf we can move on to the next slide, please.\nThanks.\nSo here's a example of a more concrete, um, knowledge graph in which, uh, the domain here is, uh, art.\nI would, I would assume, um, the entities that are being captured are artists, such as Leonardo da Vinci, uh, the paintings and museums, and so there is an interaction between those different entities.\nSo, for example, an artist had drawn, uh, uh, a picture, and the picture might be presented, uh, at an at the museum.\nI think there's a lot of value representing your data in such a way.\nFirst, it's very visual.\nSo you can look at it and you can reason about it relatively easily.\nSecond, the fact that most knowledge graphs, or the essence of knowledge graph, is schemaless.\nThis really helps or give you the flexibility that you might need when representing your data.\nAnd lastly, there's no restriction on the number of different entities and the and the number of different relations that you can have, uh, in your graph.\nSo, you can actually go quite wild with it.\nWith that said, if we can move on to the, uh, last slide.\nUm, constructing a knowledge graph can be challenging.\nUm, it's not like the one of the other solutions that we see, uh, these days with vectoral databases where the ingestion procedure is really straightforward, but extremely limited, uh, in terms of your reasoning capabilities.\nAnd so these are our suggestions whenever it comes to knowledge graph construction.\nFirst, make sure that the domain that you're, um, trying to capture is well defined, meaning that you try to limit yourself, uh, in a kind of a focused scope.\nUm, so once you have defined or know what type of data you want to capture, with like, with every other system, there's this phase of data collection and data cleaning, and that could go to an extent, uh, or you can just work with the data that you have without performing any cleaning, really depends on how are you ingesting the data.\nUm, so after data had been collected and clean, what we suggest that really, uh, helps LLMs to interact with your data is to define the semantics, and usually that means defining a clear ontology, and I'm sorry for using this terminology, um, I, I would try to keep it simple, basically an ontology is a schema for of your data, uh, something that you might be famili familiar with with the relational model.\nUh, it's basically a schema for your graph.\nAlthough I, I said just a few minutes ago that, um, N graph are schemaless, there is value in following a strict schema, um, later on in the retrieval phases of your application.\nAnd so this is where you're saying, oh, my graph contains a person, and a person is is associated with these attributes.\nA person, uh, might have edges coming into it or going out of it of these specific types, and maybe some of these relationship types are also associated with some attributes.\nSo this is the ontology, uh, defining my graph.\nOnce you have the ontology and your data, it's time to ingest, uh, meaning pushing the data into your graph.\nAnd lastly, doing, uh, some validations, making sure that the knowledge that is being captured is really valuable.\nAnd for example, if you're using an LLM to query your knowledge graph, uh, that the accuracy of the results for different questions that you're asking is satisfied.\nUh, you can move on to the next slide.\nCool.\nUm, actually, before we jump into Fractal KG, I think just applying it to VCPedia, obviously, in the case of VCPedia, the, the, the domain is startups funding, right?\nUm, data collections happening on Twitter.\nIn this case, there is a very clear ontology, right?\nIt's the, the funding round relationship with people, people relationship with startups, uh, and I think the, the, um, for me at least, I found that using structured output with LLM is a great way to get the structured data out of your unstructured data.\nYou can essentially use the ontology that he was describing, and what I essentially do is turn that ontology into the structured output format, uh, to get the data, and then the validation step, I think is, is the one where I think, uh, um, you know, mine could use a little more work, but, uh, uh, we were talking about this the other day, uh, my strategy has, has mostly been to, um, every time you add a node or relationship, look for similar nodes, and then most recently, I've been feeding those similar nodes and new node into an LLM and having the LLM decide.\nUh, but, but I think you can go even further and do kind of deterministic validation.\nIf it's the exact same domain, then, then they're the same entity and so on.\nSo, so yeah, that's basically exactly how VC VCPedia was built, right?\nUm, I know the next one we, uh, we were going to talk about is Fractal KG.\nUm, I think before I jump in, um, I was going to quickly just share, uh, that I've been trying to, you know, I, I think I started exploring knowledge graphs initially when I, right after I built baby AGI, I had a couple people reach out saying you should look at knowledge graphs, you'll like it.\nUm, after enough time, I thought, okay, I'll take a look, and then immediately clicked.\nUm, it just felt like a very, um, intuitive and natural way for AI to, to kind of traverse data, right?\nUm, if you think about, uh, um, you know, VCPedia, if I have a startup, right?\nBeing able to just like, for the AI to be able to pull just all the edges related to that startup is a fantastic way to pull all the context.\nIf you were to do that with relational tables, you essentially have to find the relationship mapping between the startup and each table that exists.\nYou have to find the relationship in the startup people table.\nSearch through the people table for all people that match that startup.\nThen you go to the startup funding round relationship mapping and then go through all the funding rounds and then grab all the funding rounds that match the startup, and then you go through all the investors that map versus just being able to pull edges.\nTo me, intuitively made more sense.\nSo I've been playing around.\nI've tried a couple of approaches on what it's now called Fractal KG.\nUh, the first one I tried was looked like this.\nThis was called mind graph, and and the key really here was this kind of add multiple conditional.\nThe the big, big thing about building these massive knowledge graph is really in the dduping.\nSo, so this is where I had the add multiple edges and rows conditionally.\nThere's a conditional entity edition, which was the kind of ddup and add, um, and that was a while ago.\nIt was pretty beefy code.\nI then tried a more recent one earlier this year.\nThis is not yet Fractal KG.\nI called it graphista.\nUm, this was I was really trying to simplify the code.\nWhat I did was I had a smart, uh, uh, um, node processor and retrieval tool, and I basically, it was an LLM loop with a whole bunch of graph query tools.\nUm, and I thought the idea was if the LL, if I gave the LLM enough prompts, it would figure out how to ddup correctly.\nIt somewhat worked.\nUh, but realistically, I found that I think the earlier version was better.\nThe deterministic was, uh,\n\n\nend\nup working better.\nThough, so the most recent uh approach I did was uh a Fractal KG, which has an added uh added element of uh trying to self-organize itself um into kind of a fractal-based uh uh graph, which which I'll kind of explain through a through a quick demo in a second.\nUm, what you're seeing here is uh a Knowledge Graph of a whole bunch of uh articles pulled in from Wikipedia.\nUm, it's automatically extracting entities uh relationships and mapping them into a graph.\nUm, I think somewhere I had a actually a quick explanation of how this version works.\nI I asked trusty Claude to to work through it.\nIn this case, uh, there's the uh raw document text that goes in.\nIt first uh identifies entities and then it goes through an entity resolution step where for each entity it looks to see if there's existing entities.\nUm, so in some cases it might say there's an existing node, in some cases it might say, you know, we need a new node, and then once we do that, there's an extract fact step, facts in this case, and in the case of Fractal KG, every fact is a triplet, which is a entity relationship entity, like Einstein developed theory relativity, and then those are then mapped into uh um attach the facts to the entities, create the graph edges based on the relationships, batch deduplicate and kind of self-organize.\nSo, let's do a little um Live demo.\nI think this was uh all right.\nI think I did.\nSo, what I um one of the things I noticed when I was trying to do graph rag, right, kind of retrieve context, is that if I just added, if I the graph got too big, pulling in all the edges kind of uh went over the context limit.\nSo what I wanted to figure out was can I uh build a system that can reflect on itself and self-organize, maybe if one node has too many children, it can then cluster the children, create kind of subcategories between them so that there's uh no single node has too many edges, uh, and so that was inspired kind of like the way we dream, right?\nSo there's that kind of go through each node and self-organize, but to show you kind of how that happens live, I think the the test I did was Yohei loves, let's say AI, John loves tech.\nNow, what you would expect, at least for my previous one, was that it would just generate a Yohei to AI relationship and a John to tech relationship.\nBut, uh, in this case, uh, because it's trying to self-organize and understand and infer relationship between nodes as it's creating them, it should build a relationship between AI and technology automatically.\nUh, when it displays, um, I think it's should display in a second.\nThere it goes.\nOkay, in this case it did not.\nBut let's try the was it self-organize or I guess it didn't work in this case.\nEarlier when I did this test, it did a Yeah, let's just jump to the earlier test I did.\nEarlier when I did the same query, it did this.\nAnd then if I go in and say what is John's relationship with with AI.\nIt says there's no direct relationship between John and AI based on given facts.\nWhile AI is a subset of technology, the fact is not a specific state that John loves AI, only technology in general.\nSo it does it does remember that Jon loves technology, but it does see that John, you know, technology has a relationship with AI, if that makes sense.\nI think it does, you I mean, especially in the context of people that are trying to build an agent that is supposed to have memory and hold that memory and provide answers that actually bear some context.\nSo I think what you're showing here is very cool.\nYeah.\nAnd and the and most of the um kind of ingestion and retrieval is is in a single file that's about a thousand thousand lines of code.\nAnd I think we're we're working on getting it ready to open source too.\nSo, if you want to play around at least with this approach, we'll be able to share it soon.\nThat's very cool.\nYeah, definitely.\nI mean, once that's up there, we're going to put it on Discord and disseminate it to everybody that attended so they can play with it as well.\nBut I think it's really cool.\nIt's what we had in mind, I think, when we started building this.\nYeah.\nUm, I know we were talking about like why graphs a little bit the other day.\nYeah.\nUm and I'm not someone who studied graphs, but uh I think you know in in understand like most of most of business, right, and and the way um we work is actually just a lot of relationships, right?\nThere's even when I look at the way I work, there's emails, there's notes, there's people, there's relationship between people, businesses, and so uh I think graphs do an incredible job of capturing uh the way in which the real world works.\nUm, one of the opportunities I'm excited about is that, uh, with graphs, there's, you know, and again, I'm pretty still shallow on this, but there's there's a lot of kind of algorithms that help you better understand kind of the relationship between graphs and the network at large.\nAnd I think as I think about especially for me, right, in in the startup ecosystem and I think for other people um you'll find similar things is that I believe that if I can create a strong graph that captures the innovation ecosystem, right, what are the industries, what are the technologies, who are the investors, who are the customers, then eventually we'll be able to start identifying pockets of underserved innovation, right, opportunities where we're seeing a lot of where we should see a lot of activity but maybe aren't seeing as much funding happening, and then If I if I'm able to start identifying those, I mean, for for myself, I can start looking at those and investing in those, but for founders, they can start you know looking for you know uh you might there's probably innovations that happen in certain industries that should obviously apply in another, it just hasn't happened yet, and being able to identify those automatically, I think graphs are are really well suited for that.\nSo I think it's beyond just capturing the existing relationships and the businesses, but also um being able to uh infer opportunities uh within those graphs.\nAnd I I think uh um at least from my understanding is that the biggest challenge with Knowledge Graphs, at least prior to LLMs, was building and maintaining these clean Knowledge Graphs.\nUm, it just took too much manpower, and I think with the reasoning capabilities, the the data structuring capabilities of LMS, I think we're finally at a place where we are able to build and maintain large Knowledge Graphs, and then if we can do that, we can infer insight from them.\nAnd I think we're still early, and you know, as as I talk to people, but I think it's it's the right time to figure it out, and I think if you can figure it out, uh, you can definitely have a have a leg up in helping people organize data and and gain insight from it.\nSo so that's been my motivation, that's my hypothesis as I dug into and play with Knowledge Graphs, and and of course that exploration uh uh led me to uh working with you guys at FalkorDB.\nSo that that's been my uh my my experience.\nThat's really I'm really happy you brought that up.\nI know we talked about it a few days ago, and I was hoping that the insights you shared back then would be ones that you would share with the audience today too, because I I think we feel the same way, and we see it pop up on a lot of the conversations that we're having.\nI think people are reaching the same conclusions.\nUm, I'm just looking at the time, and I know before we even started the session, we had gotten questions people wanted answered, and there's a few that have gathered in the in the chat.\nSo would you guys mind if we uh because we didn't want this to be slide-heavy, right?\nThere wasn't like a presentation in mind.\nIt was more like a demo showing what's going on behind the scenes and sort of the rationale behind things.\nSo I think it would make sense to keep the discussion going instead of showing more slides.\nUm, so the first actual the first question is a bit long.\nIt's quite cool.\nSo, I'm going to read it out loud, and if you need me to repeat a part of it, please let me know.\nSo, uh it's from uh I can't really tell the name of who asked it.\nSo, we're just going to answer it live, and later on when we send the email recapping this.\nIf you've asked this question, you're probably going to recognize the answer.\nSo the question goes, what rule or heuristic should one use to determine whether some information should be a node versus an attribute of a node?\nThe example given here is an individual might be a node in a graph and their name would likely be an attribute, but what about their country?\nUh the person also says, I can see a case for that being either a node or an attribute.\nPerhaps this is where upfront on your definition comes into play.\nRoy, I think you touched a little bit on this, but yeah, it's a it's a good question, and I think it's a question that a lot are um yet to ask themselves whenever they're uh trying to model their data.\nAnd so there isn't a clear and correct answer.\nUh for some, treating a piece of information as an attribute might be the right way to go.\nFor others um it might make sense to treat this piece of information as a node.\nMy general uh way of thinking about this is if you're trying to visual data is a graph.\nUm what ha whatever comes to your mind naturally, that's the data model that you probably want to start experimenting with.\nAlso, if the data uh the data point which we're thinking of seems trivial, like uh at the beginning of the question, then you know, there's there's not much to uh to think about.\nUm but let's let's try and think about the country piece of information.\nSo a person might be uh a resident uh or have a certain nationality.\nAnd so you might represent the country as an attribute for every person in your graph.\nAnd so for example, if you're just maintaining the the string of that person, then one thing that comes to mind is the memory consumption.\nIf you have millions of uh different persons, then this small set of strings representing countries um would duplicate itself over and over and over again.\nSo memory might come to mind, and actually we've addressed this in in our latest release.\nUh we have this feature called string interning where you can specify, hey, this is a string which comes pretty often.\nUh don't do don't duplicate it.\nUse unique uh value of it and everything is being shared.\nSo this is one thing to take into consideration.\nAnother thing is the way in which you're going about traversing or searching for knowledge.\nSo you need to think about the different type of questions that your system is intended to answer.\nSo for example, if you're uh want to do traversal from a country outward, it would make sense to represent the country as a node.\nBut if you are more focused on on person, you're trying to locate a person via its uh unique identifier or social security number and you just want to see for example in which state that person lives, then uh it might make sense to have this as an attribute.\nYou you can still go with a node, but then you would have to traverse from that person to a country node and retrieve the name of the country.\nSo um kind of summaring things up, go with the most natural way of thinking about the data as a graph and um see if if uh the data model that you have chosen fits the different type of queries and questions that you're uh intending to um answer.\nYeah, I would I would say the same thing.\nLike like the last thing you said, especially for me, right?\nAgain, I I'm not as deep on the understanding how to optimize the queries piece, but but I think starting from the queries is important, right?\nIf you're going to constantly filter your data by country, um I I would guess that it would be intuitive to turn that into a node.\nUm but if it's something you're just like want to see when you visit their page as a as a side note, then then you might not need to add that as a node is kind of how I would think about it.\nAnd I think again if you have a lot of data, you do have to worry about the costs.\nUm so I'll speak as kind of a more of a prototype or getting going stage.\nInitially I think keeping it simple is good, and you can kind of test around with small pieces of data, and then if you feel like it's helpful, I mean if you have the location data as an attribute, you know, it should be pretty easy to convert that location data and map it to a location node.\nAgain, if you have millions of data, you might want to do it up front versus doing it later.\nBut at least in the in this uh in the prototyping stage, you can you can easily add that uh after the fact.\nYeah, maybe let let me just add a few things to that.\nUm graphs are dynamic, and so if you are going, you know, you have experimented with m with one data model, you can quite easily transition to another.\nThat's one thing.\nAnother maybe um thing to keep in mind, following on this country with this country example, is are you expecting the country to be interacting with other pieces of information, like maybe now you only have the relation between a person and a country, but maybe uh in the near future you're seeing country being referenced or interacting with different entities?\nAnd if that's the case, I would lean toward representing it as a node just because the ability of capturing those uh different interactions.\nExcellent, guys.\nUh another question we have is from MJ.\nHe's asking, \"When working with documents, what detail are we saving in FalkorDB?\nWould you store sentences, paragraphs, or summaries?\nIf only storing summaries, are you also storing entire documents in a separate database?\nRight.\nUm, this is classic rag question, I would say, and once again, there's no right answer.\nI think uh all options are viable, and it really depends on um the type of questions and the level of accuracy that you are aiming for.\nUm, we've seen all all different options.\nUm, some some people are actually um analyzing the documents, for example, with LLMs, um creating embeddings, extracting sentences, creating summaries, and all of the relationship between the different components, paragraph sentences, summaries, entire documents, these can be represented as nodes in a graph.\nSo for example, whenever you're trying to answer a question via the classical rag approach where you are creating embeddings for the question and then you're doing semantic search to get to uh maybe the summary or maybe to get to the relevant paragraphs, then you can utilize the graph in order to get a hold of the original document and maybe there's a hierarchy of documents saying, oh, this document is a page from a broader um corpus or oh, this is an uh a Wikipedia article that is linked to other Wikipedia pages.\nMaybe I want to extend my context and get some extra data in by traversing the graph.\nAnd so there's no clear answer.\nI think you should experiment with it.\nUm, but the benefits of storing this information in a graph allows you\n\n\nTo retrieve additional context, which, uh, usually, it's relevant, uh, to extending the context with, um, information that would help your LLM to generate the correct, uh, answer.\n\nYeah, this, this feels like more of a FalcoreDB specific one, but I think, uh, that, like, again, going back to, like, what is the query, how would you want to display it, I think is, is what comes to mind. Um, in a lot of cases when you do RAG, you might want to, uh, provide the source snippet of the fact. You know, whether you do or don't should affect your decision around whether to keep the document, right? If it's a massive PDF that you had to chunk to analyze and store, um, maybe it makes sense to store the chunks because if you want to store, you know, if you want, you know, if you find a fact and you want to grab the snippet, you don't want to have to go through and search through the entire PDF for that snippet again. That seems just really inefficient. You would almost rather store the snippet with the fact so that you can quickly pull the snippet instead of searching for it each time. So, again, kind of depends on what's the information you want to display, how do you display it, what is, uh, what is the flow to get that information in front of the user. Uh, and I think that comes through, you know, testing not just the graph itself, but also the, the UI, uh, and making sure it's, it's kind of cohesive and makes sense.\n\nThe next one, guys, comes from Brett. He says, \"If I understand correctly from the earlier slides, despite the Knowledge Graph system being schemaless, developing an ontology is useful in an actual exercise to help nudge the development and maintenance of the model that the system develops. Are there any useful mechanisms for enforcing that ontology within the Knowledge Graph system automatically?\"\n\nUm, there are some mechanisms. Yes. But the, uh, the overall model that we're following is known as the, uh, property graph model, which, in its core, is schemaless. The way in which you can start enforcing the schema, uh, the feature that Falcor offers is with constraints.\n\nUm, currently, we have two different constraints. One is unique constraints, and the other one is exists constraints. The unique constraint makes sure that an attribute is unique throughout, uh, an entire entity type. So, for example, social security number should be unique for every, uh, person. Um, in addition, the exist, uh, constraint makes sure that every entity of a certain type, let's say, a country, um, must have a population attribute. It doesn't have to be unique, but it must exist.\n\nUm, that's what we currently offer. It would not enforce, for example, introducing new labels or new relationship types that are not part of the ontology. It would not enforce the type of edges coming in or going out from a certain, uh, node type. So, for example, if your ontology says that, um, there should not be an edge of type driven to, uh, that would not be enforced, and I, and I think that over time, uh, the plan is to introduce schema enforcement mechanisms and features into FalcoreDB. But at the moment, the intention is for, or the, uh, responsibility for the user to enforce the ontology to make sure that the underlying graph follows, um, follows the ontology, and, and that could be done either, uh, via, uh, code that has been written by the user or by guiding an LLM to strictly follow the ontology whenever doing updates, deletions, or, uh, ingesting community.\n\nI think there's, um, it's not a question, but it's rather a comment on what Brett asked, and I think it ties in a little bit with something Yohei Nakajima talked about when he spoke, when he, sorry, when he presented Fractal KG. So, in response to Brett's question, we have Alec saying, \"Based on my observation, the ontology schema behaves like prompt engineering technique with your LLM that you are using to classify the data you are processing either as entities or edges.\" What do we, what do we think about that?\n\nI mean, the ontology schema is something you, if you set ahead of time, right? I think the, the earlier point was, it makes retrieval easier because, uh, it's, you can more deterministically, uh, ask questions without worrying about, uh, having two similar edge types, right, because you've already defined the edge types, um, and I think the original question was around whether, whether you can enforce it in, in the KG, which it seems like it doesn't, I think, and I don't know if I'm answering the question, but you can enforce it up front, um, using, for example, in my case, I use structured outputs, and so I asked the structured output when I'm extracting data to extract nodes or edges, uh, in a specific format, and if, if I want certain relationship types, that'll just be one of these structured output parameters, and I can stick an enum and, you know, give the specific types that I want. Um, I don't know if I'm answering that question, but to some extent, I think you can use, you know, prompt engineering or structured output engineering techniques to, uh, to enforce that ontology, at least in the, um, in the data creation step before you throw it into the graph.\n\nUm, I, yeah, I'm going to add to that. I think that, um, ontology can be thought of as home engineering. I think that the main idea here is to restrict or make sure that the LLM is aware of what exactly is captured in the, in your Knowledge Graph. So, think about the, the situation in which you're telling your LLM, hey, you have access to a graph capturing, um, uh, driving information. And that's all the information that you're giving it in addition to a question, uh, that says, um, find me all of the driving sessions that, um, had a top speed over 60 miles. And so, there are some hints within the question for the LLM to try and, um, guess which attributes, which nodes, and which relationships are within the Knowledge Graph. But it would have made more sense, and it would really help the LLM to get this information up front, knowing that there is a driving session entity. It has a top speed attribute. It is, it is connected to roads, and so now the LM is confined, and it is, um, certain about what exactly is in the Knowledge Graph, and that would really boost the accuracy of the LLM when composing queries against the graph.\n\nExcellent. I'm looking at some of those questions. Some have to do with, uh, Yuri's projects, and some speak more about the core product that Falcor essentially has developed. Um, so just in the interest of time, I'm going to read them from top to bottom. And no worries, we're going to answer all of those questions and the very detailed answers to all of them later on. But there's a question that came in. What graph embedding models are supported? And they specify node, edge, or graph embeddings?\n\nOh, that's easy. Um, none. Um, we do not have GNN's capabilities or graph embeddings. The only type of embeddings that we're supporting at the moment are vector embeddings, the ones in which you can generate with, um, different, um, LLMs or AI, uh, vendors. Uh, once you have those vector embeddings, then you can utilize our semantic index to do vector searches. But I know that there's interest in GNN's to do both node label, um, prediction, edge prediction, and, uh, subgraph classification. Unfortunately, that's, that's not supported at the moment.\n\nYeah, there's a question that came in from Discord, and they're asking, should I use a Knowledge Graph per domain or a single Knowledge Graph containing all the domain data?\n\nSo, this is a cool question. Um, I think that it really depends on the use case, but let me say this. If you do see value in storing all of your information, which might span across multiple domains in a single graph, you can do that. Uh, and the nice thing about this is that you can have multiple ontologies, all describing, describing different portions of your graph. So, you would have one ontology, for example, defining, um, one domain, which might be, uh, around driving sessions, but your graph expands further. It doesn't contain only driving sessions with roads and intersections. It might contain, um, other information that is still related to that. Let's say, cities and population and universities, uh, whatever have you. Um, but then you can still have maintaining, you can still maintain two different ontologies. One which is focusing on the driving sessions, and the other one which focuses on, let's say, um, population and, uh, um, employment.\n\nUm, but those two all coexist within a single graph. It is the LLM and the ontology that is represented to it, um, that would know how to filter or focus on the relevant pieces of, of information within this, uh, larger graph. The other option is, is, you know, if you don't see value in connecting everything together, is another very cool feature of FalcorDB, uh, that allows you to maintain multiple graphs in a single database. And so, similar to, uh, SQL, where you have multiple tables within a single database, here you can have multiple disjoint graphs all within a single database. Um, so you can keep them separated, you can join them together, you can have one ontology per graph, or you can have multiple ontologies capturing data from SAB graphs within a single one.\n\nI'm glad you brought the multi-tenancy aspect of it. Uh, the next question is for Yoi. Uh, if VCPedia supported multiple languages, would you add a translation step or store the tweets in their original language?\n\nI would probably store the tweets in the original language and simply translate the output of the site. But that's just my gut reaction. I don't really have a strong reason for it.\n\nYeah, I wish, I wish maybe the question, uh, elaborated a bit more, but, you know, that's actually what I had in mind that you would say.\n\nUh, so we have another question from, uh, Discord that I think is actually very interesting. Uh, we touched on it early on, I think, a little bit in the beginning, but maybe it's worth, uh, taking maybe a few minutes to talk about it as well. How does an ontology scale when my data updates?\n\nOkay. So, it really depends on the update. I mean, you can think there are, for this particular question, you can think about two different types of updates. One updates that doesn't change the ontology, meaning that you're just adding a new city or a new university or a new person into your graph, that doesn't change the ontology. It remains the same. The other type of update is if you're adding a new type of entity. So, for example, maybe you are adding, uh, a truck to your driving session, which only had cars in it, but now there is a truck. And so, um, we do not enforce, um, alignment between the underlying graph and the ontology. This is something that the user needs to maintain, just like the way in which we're not enforcing schema. Um, whenever you're introducing a new type of entity, it is, uh, you should extend your ontology to capture that. So, with this truck example, you should add a new entity to your ontology describing, uh, how does the truck look like, meaning the, the attributes associated with it and the different type of relationship, um, that are interacting with the, with this new truck entity.\n\nI want to, um, since we only have 10 minutes left, I think it would be worthy to take one more question, and then there was another question on Discord that, uh, I think sort of leads into what I want to say to sort of recap everything. So, the question we got from Discord was, is there an automated way to build a Knowledge Graph, which is the topic for actually the next Workshop we want to put together. So, let me pause on that, and we're going to go into what we're going to do next time, which is a more of a hands-on workshop that talks specifically about that. But the other question that we got here on, uh, Zoom is, how can I improve the attribute extraction for each entity from my strict ontology schema for my Knowledge Graph? For example, I would get non-relevant context assigned to an entity or incomplete. Uh, I hypothesize my chunking is wrong, or I need to employ more natural language processing steps.\n\nThe, again, it's hard to see, I feel like with graphs, it's hard to solve a problem without knowing the specifics because it is really kind of case by case in terms of, like, what data you're playing with. But the few things that popped to mind, um, that's worked for me, again, in different cases, is, uh, I mean, K-shot is always helpful, right, giving a couple of examples. Um, if you're converting large documents and you need to chunk it, uh, again, this is a simple example, but sometimes you need kind of higher level context of the document for each chunk, right? A simple example might be, it's, you know, the book starts by using people names, but later on, it uses he or she instead, said, and if you grab that paragraph and try to convert it, that he, like, the name might not be matching. So, you might need to have kind of higher level context that you feed into the chunk if you're chunking and then extracting. Um, and then, uh, and then just, uh, I think a lot of, uh, I, I found that, um, adding clear descriptions when you use structured output for each parameter, you can provide descriptions, you can provide kind of hard-coded rules on, on options, um, and, and using that kind of the, the structured output, defining JSON, uh, uh, and, uh, improving the prompt there, um, I found is also helpful. So, those just, those are just some techniques that popped in my mind.\n\nRight. Yeah, I think that going structure can, can really help here. Um, I don't know if this feature is still available, but, uh, back then, a few months ago, where I, uh, was constructing Knowledge Graph from unstructured data, open, a, open AI had this feature of defining functions. Um, so you can define functions or tools or your LLM to, uh, use whenever, um, instructed to, let's say, extract entities and relations from documents. And so, what, what I did was to say, okay, I have, let's, for example, five different types of entities. So, I would create a function, uh, create function for each one of those, and each function would get a set of, um, arguments, attributes. Some of them were optionals, others were mandatory. Uh, you can specify the type, and now the LLM is equipped with the, with this, uh, set of functions, and so it is the LLM responsibility to invoke, uh, the most relevant function whenever it encounters data that can be translated into an entity, and so the LM knows, okay, I'm, for example, I'm seeing here, um, some description of a city. Okay. Do I have a create city function? Yes. Okay. Which arguments do I need? Oh, the name is mandatory, and it should be a string. And so, now the LM is very restricted and have certain rules, uh, to follow when invoking a function or, you know, creating an entity. So, that really helped out.\n\nUm, so that's another, uh, way that you can go about, uh, experimenting with detecting and creating entities from unstructured data.\n\nSuper good. I'm going to hijack the screen just for a little bit. Can everybody see me?\n\nYep. Perfect. So, first of all, thank you, Yoi, for taking the time. Thank you, Roy, for you are my trusty partner. We're doing this maybe for the fifth time. We're getting, I think, really good at this, and every time I think the level of questions that we're getting, I'm really liking it every time.\n\n\nWe're I would say it's a healthy balance between challenge and just uh passion, like it's what we do every day, and it's nice to share it with everybody.\nUh, speaking about the question we got on Discord on how to actually build a Knowledge Graph.\nThis is exactly what we want to do next time we meet.\nUh, I put up here on the screen a QR code, but you don't have to scan it right now.\nIf you don't have a phone, I'm definitely going to send you a link later.\nUm, but this would be the topic of what we're doing the next time.\nWe want to be able to show you how you construct a graph, how we go about this, the methodology that we use, and also the logic behind how we do what we do.\nUh, that's happening in a little bit over a month.\nSo, uh, that you definitely have time to sign up.\nAnd there's a few questions that I saw on the Q&amp;A.\nUh, everything that we do here is recorded.\nIt's going to be on Discord and on YouTube within the next 24 hours.\nSo there's no worries if you've missed parts of it in the beginning.\nAnd we're going to like we did last time, we sort of collate all the questions that were pulled here.\nWe're going to answer them, and that's going to be something that exists on our blog so that you can revisit it later.\nAnd also we tend to pick out the really good questions that we wanted to focus on and put that in an email as well.\nSo nothing is lost there.\nThere's no worries there.\nUh, and we really if you felt this was uh useful to what you're building right now, I think the next installment on in July on how to actually build a Knowledge Graph is something you definitely want to check out.\nUh, with that being said, I really appreciate you guys' time um speaking with us today.\nI thought it was awesome.\nUm, every time we do one of these workshops and somebody shares their screen and actually shows a project that they've worked on and sort of explains the rationale behind it, that's the kind of content I want to consume, and I think that's the kind of content people are coming here for.\nSo I would say for there are a few people that I'm recognizing have attended before, but for those who are new to um to this sort of format of what does these tend to be the sort of conversations that we're having tend to be very technical and very hands-on.\nSo, we hope you appreciate it.\nUm, anything else we want to say, Yoi, Roy, before we go?\nNo, thanks for having me.\nIt's always fun to nerd out on graphs.\n100%.\nYeah, these are really cool projects.\nI think when we were putting this together, I was I thought it was really cool.\nI really wanted you to share it with everyone.\nUm, I'm seeing more questions come in.\nUh, there's no worries.\nWe're going to, like I said, pull all of them together and answer them.\nUm, with that being said, please uh scan the QR code that you see here to join us on the next event.\nUh, if you can't, there's no worries.\nAfter this event is finished, I'm going to send the link.\nAnd with that being said, I we want to thank you for for being with us today, and we'll see you the next time.\nThank you.\nThanks, guys.\nThanks.\n",
  "dumpedAt": "2025-07-21T18:43:25.545Z"
}