{
  "episodeId": "JYaGAqvPfYA",
  "channelSlug": "@latentspacepod",
  "title": "⚡️Anthropic vs Cognition on Multi-Agents: A Breakdown with Dylan Davis",
  "publishedAt": "2025-07-05T16:00:36.000Z",
  "rawLines": [
    {
      "lang": "en",
      "text": "[Music]",
      "offset": 2.17,
      "duration": 5.109
    },
    {
      "lang": "en",
      "text": "Alrighty. So, we are in a remote studio",
      "offset": 4.16,
      "duration": 5.359
    },
    {
      "lang": "en",
      "text": "with a lightning pod with Dylan Davis or",
      "offset": 7.279,
      "duration": 6.48
    },
    {
      "lang": "en",
      "text": "DS squared from you're you're a big",
      "offset": 9.519,
      "duration": 5.921
    },
    {
      "lang": "en",
      "text": "member of the community. I' I've sort of",
      "offset": 13.759,
      "duration": 2.801
    },
    {
      "lang": "en",
      "text": "interacted with you over the years",
      "offset": 15.44,
      "duration": 2
    },
    {
      "lang": "en",
      "text": "actually. I don't know. How did you",
      "offset": 16.56,
      "duration": 2.639
    },
    {
      "lang": "en",
      "text": "first come across in space?\n Well, I",
      "offset": 17.44,
      "duration": 3.999
    },
    {
      "lang": "en",
      "text": "first came across you. So, I I I found",
      "offset": 19.199,
      "duration": 5.92
    },
    {
      "lang": "en",
      "text": "your working in public blog post book",
      "offset": 21.439,
      "duration": 5.361
    },
    {
      "lang": "en",
      "text": "and and conversations probably like",
      "offset": 25.119,
      "duration": 2.721
    },
    {
      "lang": "en",
      "text": "seven years ago. I don't know, like",
      "offset": 26.8,
      "duration": 2.799
    },
    {
      "lang": "en",
      "text": "seven, six years ago.\n Damn. And from",
      "offset": 27.84,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "there, yeah, I'm a I'm an OG. I'm I'm a",
      "offset": 29.599,
      "duration": 6.001
    },
    {
      "lang": "en",
      "text": "Swix OG fan.\n So, yeah, I found Yeah, I",
      "offset": 32.64,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "found you through that and then just",
      "offset": 35.6,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "basically followed you and saw laten",
      "offset": 37.36,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "space and then followed there.\n And uh",
      "offset": 39.2,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "how do you introduce yourself these",
      "offset": 42.64,
      "duration": 2.16
    },
    {
      "lang": "en",
      "text": "days? Like what do you what do you work",
      "offset": 43.76,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "on?\n Yeah. Yeah. So, uh I'm the founder",
      "offset": 44.8,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "of Gradient Labs. It's a company that",
      "offset": 47.2,
      "duration": 2.8
    },
    {
      "lang": "en",
      "text": "helps other organizations, usually",
      "offset": 48.8,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "mid-size companies, implement AI",
      "offset": 50,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "internally to help automate their",
      "offset": 51.84,
      "duration": 2.8
    },
    {
      "lang": "en",
      "text": "processes, saving time, money, and",
      "offset": 53.12,
      "duration": 2.88
    },
    {
      "lang": "en",
      "text": "sometimes generating revenue.\n That's",
      "offset": 54.64,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "very tight. I'm sure you say that a lot.",
      "offset": 56,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "Awesome.",
      "offset": 57.76,
      "duration": 5.439
    },
    {
      "lang": "en",
      "text": "So, I put out a call on Small AI for um",
      "offset": 59.52,
      "duration": 5.599
    },
    {
      "lang": "en",
      "text": "you know this comparison thing between",
      "offset": 63.199,
      "duration": 4.721
    },
    {
      "lang": "en",
      "text": "Cognition and Enthropic on their multi-",
      "offset": 65.119,
      "duration": 4.561
    },
    {
      "lang": "en",
      "text": "aents articles and you answered it with",
      "offset": 67.92,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "like I think the best answer which was",
      "offset": 69.68,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "you made your own video like you're",
      "offset": 71.52,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "trying to wrap up your your YouTube as",
      "offset": 73.2,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "well. Uh and it was like a really good",
      "offset": 74.88,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "analysis. So, I just figured we would",
      "offset": 76.72,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "sort of rehash it a little bit. People",
      "offset": 78.4,
      "duration": 3.759
    },
    {
      "lang": "en",
      "text": "can obviously watch the full thing on",
      "offset": 80,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "your YouTube, but this is meant to be",
      "offset": 82.159,
      "duration": 2.481
    },
    {
      "lang": "en",
      "text": "more of a discussion between the two of",
      "offset": 83.36,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "us. uh what's going on.",
      "offset": 84.64,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "Yeah. No, I appreciate it, man. And I'm",
      "offset": 87.68,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "I'm glad that uh it resonated.",
      "offset": 89.28,
      "duration": 5.519
    },
    {
      "lang": "en",
      "text": "So, do you want me to get started?\n Let's",
      "offset": 92.64,
      "duration": 3.439
    },
    {
      "lang": "en",
      "text": "get right into it. Unless you you have",
      "offset": 94.799,
      "duration": 2.721
    },
    {
      "lang": "en",
      "text": "anything else you want to sort of set as",
      "offset": 96.079,
      "duration": 2.961
    },
    {
      "lang": "en",
      "text": "context.",
      "offset": 97.52,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "Yeah. I mean, I I guess the the and you",
      "offset": 99.04,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "probably have a better insight into",
      "offset": 101.2,
      "duration": 2.879
    },
    {
      "lang": "en",
      "text": "this, but there's I guess some",
      "offset": 102.32,
      "duration": 3.439
    },
    {
      "lang": "en",
      "text": "discussion around the fact that both of",
      "offset": 104.079,
      "duration": 3.441
    },
    {
      "lang": "en",
      "text": "these blog posts and context for the",
      "offset": 105.759,
      "duration": 4.561
    },
    {
      "lang": "en",
      "text": "viewers or listeners is uh Anthropic and",
      "offset": 107.52,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "Both Cognition posted blog posts one",
      "offset": 110.32,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "after the other. uh I think it was like",
      "offset": 112.24,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "June 12th and June 13th. Uh one",
      "offset": 113.6,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "basically pushed the fact that",
      "offset": 116.079,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "multi-agent architectures are beneficial",
      "offset": 117.28,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "and useful and the other one basically",
      "offset": 119.439,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "stated the the opposite saying that",
      "offset": 120.96,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "single agent architectures is more more",
      "offset": 122.799,
      "duration": 5.041
    },
    {
      "lang": "en",
      "text": "superior for different use cases.",
      "offset": 124.96,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "And if you actually read into both blog",
      "offset": 127.84,
      "duration": 2.72
    },
    {
      "lang": "en",
      "text": "posts you realize that they're both",
      "offset": 129.28,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "right. So it's not either or but yes and",
      "offset": 130.56,
      "duration": 5.759
    },
    {
      "lang": "en",
      "text": "if you're uh if you're a what is it",
      "offset": 133.04,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "like the standup comedy?\n Yeah,\n there you",
      "offset": 136.319,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "go. That's it.",
      "offset": 139.04,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "So, um, I created this image. It looks",
      "offset": 140.879,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "really cool, but it's also kind of",
      "offset": 142.959,
      "duration": 3.521
    },
    {
      "lang": "en",
      "text": "convoluted and not correct. So, what's",
      "offset": 144.48,
      "duration": 3.119
    },
    {
      "lang": "en",
      "text": "what's happening is they're actually",
      "offset": 146.48,
      "duration": 2.399
    },
    {
      "lang": "en",
      "text": "holding hands instead of fighting each",
      "offset": 147.599,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "other. True love.",
      "offset": 148.879,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "All right. So, uh, what I'm going to",
      "offset": 152.239,
      "duration": 2.64
    },
    {
      "lang": "en",
      "text": "show on the left hand side, we'll start",
      "offset": 153.599,
      "duration": 3.121
    },
    {
      "lang": "en",
      "text": "with anthropic, we'll go to cognition,",
      "offset": 154.879,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "and then we'll end with, um, I think",
      "offset": 156.72,
      "duration": 3.519
    },
    {
      "lang": "en",
      "text": "kind of like overall insights and how to",
      "offset": 158.72,
      "duration": 2.64
    },
    {
      "lang": "en",
      "text": "think about when to use which",
      "offset": 160.239,
      "duration": 2.801
    },
    {
      "lang": "en",
      "text": "architecture.",
      "offset": 161.36,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "So, for the anthropic blog post, they",
      "offset": 163.04,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "focused mainly on their use case for",
      "offset": 165.36,
      "duration": 3.519
    },
    {
      "lang": "en",
      "text": "deep research. So I'm sure if you're",
      "offset": 167.12,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "aware if you have access to claude I",
      "offset": 168.879,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "think it's pro and max and all the paid",
      "offset": 170.8,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "plans they have access to this new deep",
      "offset": 172.72,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "research feature it was released a few",
      "offset": 174.48,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "few weeks ago and with this research",
      "offset": 176,
      "duration": 5.599
    },
    {
      "lang": "en",
      "text": "feature I I tend to compare a lot of the",
      "offset": 179.28,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "models. So when I do deep research, I I",
      "offset": 181.599,
      "duration": 5.521
    },
    {
      "lang": "en",
      "text": "do Gemini, I do I do Perplexity, I do",
      "offset": 183.599,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "opening, I do all of them when I ask",
      "offset": 187.12,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "different questions. And time and time",
      "offset": 188.879,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "again over the last couple of weeks, I",
      "offset": 190.8,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "found that Claude has by far",
      "offset": 192.56,
      "duration": 5.039
    },
    {
      "lang": "en",
      "text": "outperformed the others. And I guess the",
      "offset": 194.48,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "definition of good for me right now is",
      "offset": 197.599,
      "duration": 5.201
    },
    {
      "lang": "en",
      "text": "not just length, but also the number of",
      "offset": 199.76,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "sources and divers diversity of",
      "offset": 202.8,
      "duration": 4.719
    },
    {
      "lang": "en",
      "text": "response. My guess is part of the reason",
      "offset": 204.48,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "it's so highly effective is the way",
      "offset": 207.519,
      "duration": 3.201
    },
    {
      "lang": "en",
      "text": "they've structured their agent. So they",
      "offset": 209.36,
      "duration": 2.799
    },
    {
      "lang": "en",
      "text": "took a multi- aent approach with this",
      "offset": 210.72,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "feature",
      "offset": 212.159,
      "duration": 3.521
    },
    {
      "lang": "en",
      "text": "and they gave us a beautiful little",
      "offset": 213.76,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "graphic in their blog post that kind of",
      "offset": 215.68,
      "duration": 2.88
    },
    {
      "lang": "en",
      "text": "walks you through exactly how this",
      "offset": 217.28,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "functions. So on the lefth hand side we",
      "offset": 218.56,
      "duration": 4.239
    },
    {
      "lang": "en",
      "text": "have a conversation from an AI that's",
      "offset": 221.2,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "basically or from a human asking a",
      "offset": 222.799,
      "duration": 4.481
    },
    {
      "lang": "en",
      "text": "question. So this question is uh what",
      "offset": 225.2,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "are all the companies in the United",
      "offset": 227.28,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "States working on AI agents in 2025?",
      "offset": 228.56,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "Make a list of at least 100. For each",
      "offset": 231.04,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "company include the name, website,",
      "offset": 232.879,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "product description of what they do, the",
      "offset": 234.72,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "type of agents they build and their",
      "offset": 236.799,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "vertical industry. Now at the surface",
      "offset": 238.4,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "this is obviously a pretty beefy",
      "offset": 241.12,
      "duration": 5.119
    },
    {
      "lang": "en",
      "text": "question and the",
      "offset": 242.799,
      "duration": 5.121
    },
    {
      "lang": "en",
      "text": "I would say the the thing that's",
      "offset": 246.239,
      "duration": 3.761
    },
    {
      "lang": "en",
      "text": "happening here that's useful for this",
      "offset": 247.92,
      "duration": 4.879
    },
    {
      "lang": "en",
      "text": "specific structure for multi- aents is",
      "offset": 250,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "that it's a broad question. They're",
      "offset": 252.799,
      "duration": 3.041
    },
    {
      "lang": "en",
      "text": "asking about a variety of things and",
      "offset": 254.48,
      "duration": 2.8
    },
    {
      "lang": "en",
      "text": "they're asking for multiple perspectives",
      "offset": 255.84,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "on that specific thing. So what happens",
      "offset": 257.28,
      "duration": 6.32
    },
    {
      "lang": "en",
      "text": "is they send the question over to their",
      "offset": 259.68,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "agent architecture which where they have",
      "offset": 263.6,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "a lead architect. So lead agent at the",
      "offset": 265.68,
      "duration": 4.239
    },
    {
      "lang": "en",
      "text": "top that's orchestrating everything and",
      "offset": 267.919,
      "duration": 4.641
    },
    {
      "lang": "en",
      "text": "they'll then send off this question",
      "offset": 269.919,
      "duration": 4.241
    },
    {
      "lang": "en",
      "text": "broken into sub questions. So they'll",
      "offset": 272.56,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "send over the question, they create a",
      "offset": 274.16,
      "duration": 2.56
    },
    {
      "lang": "en",
      "text": "plan, they create a bunch of sub",
      "offset": 275.6,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "questions and they send off these",
      "offset": 276.72,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "requests to multi multiple agents and",
      "offset": 278.88,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "they do it in parallel. And that's kind",
      "offset": 281.04,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "of the unique thing here that I found.",
      "offset": 283.44,
      "duration": 5.199
    },
    {
      "lang": "en",
      "text": "It's and maybe so you have an answer to",
      "offset": 286.08,
      "duration": 5.679
    },
    {
      "lang": "en",
      "text": "this or maybe you have insight is I've I",
      "offset": 288.639,
      "duration": 5.441
    },
    {
      "lang": "en",
      "text": "don't necessarily know",
      "offset": 291.759,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "I can't confirm this is happening but I",
      "offset": 294.08,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "know in their documentation it says that",
      "offset": 295.919,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "that it is where where they'll send off",
      "offset": 297.44,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "a request as the lead agent to multiple",
      "offset": 300.08,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "sub agents to then do the research. I",
      "offset": 302.32,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "I'll pause and yeah I mean I think",
      "offset": 304.96,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "that's that's what they're saying",
      "offset": 307.36,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "they're doing. I don't know why you",
      "offset": 309.6,
      "duration": 3.599
    },
    {
      "lang": "en",
      "text": "wouldn't doubt it.",
      "offset": 311.199,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "Yeah. Well because I'm I'm a skeptic.",
      "offset": 313.199,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "All right,",
      "offset": 314.88,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "just kidding. All right, so um basically",
      "offset": 317.12,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "all these sub agents are doing their",
      "offset": 319.68,
      "duration": 2.799
    },
    {
      "lang": "en",
      "text": "work and they'll go off and research a",
      "offset": 320.96,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "specific sub question in that parent",
      "offset": 322.479,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "question. And as they're doing in their",
      "offset": 324.4,
      "duration": 3.359
    },
    {
      "lang": "en",
      "text": "research, each one of these sub agents",
      "offset": 326.08,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "have the 200k context window and that",
      "offset": 327.759,
      "duration": 4.801
    },
    {
      "lang": "en",
      "text": "means that all of them are going to have",
      "offset": 330.56,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "tons and tons of insights and research",
      "offset": 332.56,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "for that sub question. They'll",
      "offset": 334.479,
      "duration": 2.72
    },
    {
      "lang": "en",
      "text": "synthesize that. Once they've",
      "offset": 336,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "synthesized the responses, they'll feed",
      "offset": 337.199,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "that back through the lead agent and the",
      "offset": 339.12,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "lead agent then will put a variety of",
      "offset": 340.8,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "insights that are relevant for answering",
      "offset": 343.199,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "the question in its memory. After that's",
      "offset": 345.199,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "done, it'll then consolidate the memory",
      "offset": 347.6,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "uh insights and then create its uh",
      "offset": 349.759,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "report back to the user. Another",
      "offset": 351.84,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "important caveat here is they have",
      "offset": 353.84,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "another citations sub agent that's",
      "offset": 355.12,
      "duration": 3.519
    },
    {
      "lang": "en",
      "text": "working as these sub agents are",
      "offset": 357.12,
      "duration": 4.639
    },
    {
      "lang": "en",
      "text": "responding to validate that the citation",
      "offset": 358.639,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "in the piece that it sent back is",
      "offset": 361.759,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "connected to the source that it",
      "offset": 363.759,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "referred. So that's kind of the overall",
      "offset": 365.199,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "flow of how this works. Pause and see.",
      "offset": 367.6,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "Swix, what are you uh insights,",
      "offset": 369.759,
      "duration": 4.241
    },
    {
      "lang": "en",
      "text": "feedback, questions?",
      "offset": 371.759,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "I I think it's a relatively",
      "offset": 374,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "straightforward",
      "offset": 376.479,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "implementation so far. I think the the",
      "offset": 378.08,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "thing about the the nuance here is the",
      "offset": 379.919,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "communication back and forth, you know,",
      "offset": 382.24,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "dare I call it agent to agent and like",
      "offset": 384.639,
      "duration": 5.601
    },
    {
      "lang": "en",
      "text": "when they interrupt each other or you",
      "offset": 387.84,
      "duration": 4.479
    },
    {
      "lang": "en",
      "text": "know, how they how the lead agent",
      "offset": 390.24,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "orchestrates them. That can get into a",
      "offset": 392.319,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "lot of complexity. So, this image",
      "offset": 394,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "actually looks simpler than it really is",
      "offset": 395.919,
      "duration": 5.84
    },
    {
      "lang": "en",
      "text": "in real life.\n Yeah. And and it's funny",
      "offset": 398.16,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "to that you say that because when I when",
      "offset": 401.759,
      "duration": 3.201
    },
    {
      "lang": "en",
      "text": "I initially made this video, I thought",
      "offset": 403.44,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "to myself, I was like, &quot;Oh, maybe maybe",
      "offset": 404.96,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "I'll show this one.&quot; And this chart is",
      "offset": 406.8,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "more detailed as to what you're talking",
      "offset": 409.44,
      "duration": 2.72
    },
    {
      "lang": "en",
      "text": "about of how the multi-agent structure",
      "offset": 410.72,
      "duration": 3.039
    },
    {
      "lang": "en",
      "text": "works and how the conversation happens.",
      "offset": 412.16,
      "duration": 2.96
    },
    {
      "lang": "en",
      "text": "And it is more detailed, but it's also",
      "offset": 413.759,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "more overwhelming. Um, so yes, it is",
      "offset": 415.12,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "definitely more complex in the",
      "offset": 417.039,
      "duration": 2.481
    },
    {
      "lang": "en",
      "text": "background. So, after we have a good",
      "offset": 418.24,
      "duration": 2.56
    },
    {
      "lang": "en",
      "text": "understanding of multi-agent, I wanted",
      "offset": 419.52,
      "duration": 3.119
    },
    {
      "lang": "en",
      "text": "to quickly show what a single agent",
      "offset": 420.8,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "architecture looks like. And this is a",
      "offset": 422.639,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "chart from Cognition's blog that walks",
      "offset": 424.56,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "through a basic flow or basic",
      "offset": 426.96,
      "duration": 2.48
    },
    {
      "lang": "en",
      "text": "architecture of what a single agent",
      "offset": 428.16,
      "duration": 3.439
    },
    {
      "lang": "en",
      "text": "could look like. So in this case, we",
      "offset": 429.44,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "have the task at the top where it's",
      "offset": 431.599,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "getting an input from a user. So the",
      "offset": 433.36,
      "duration": 5.119
    },
    {
      "lang": "en",
      "text": "user's input comes in and we go through",
      "offset": 436.639,
      "duration": 3.761
    },
    {
      "lang": "en",
      "text": "the same process. So we're going to have",
      "offset": 438.479,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "the large model at the beginning. So",
      "offset": 440.4,
      "duration": 3.359
    },
    {
      "lang": "en",
      "text": "it's going to be a big beefy model like",
      "offset": 442.4,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "03, Gemini 2.5 Pro, Cloud Sonnet Opus,",
      "offset": 443.759,
      "duration": 5.201
    },
    {
      "lang": "en",
      "text": "Sonnet or yeah, Cloud Sonnet 4, Cloud",
      "offset": 446.72,
      "duration": 4.879
    },
    {
      "lang": "en",
      "text": "Sonnet 4 Opus, etc. And when they input",
      "offset": 448.96,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "the information, it's going to create a",
      "offset": 451.599,
      "duration": 3.201
    },
    {
      "lang": "en",
      "text": "plan, break down that plan into",
      "offset": 453.28,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "subtasks, sub questions, etc., and it's",
      "offset": 454.8,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "going to continue to research. The",
      "offset": 457.12,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "difference here is instead of doing it",
      "offset": 459.28,
      "duration": 3.199
    },
    {
      "lang": "en",
      "text": "in parallel with sub agents, they're",
      "offset": 460.8,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "going to do it in sequential order. So",
      "offset": 462.479,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "they're going to have the agent, it'll",
      "offset": 464.16,
      "duration": 3.599
    },
    {
      "lang": "en",
      "text": "first research the first question and",
      "offset": 465.759,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "it'll then consolidate the insights from",
      "offset": 467.759,
      "duration": 3.041
    },
    {
      "lang": "en",
      "text": "that and it'll go to the next question,",
      "offset": 469.44,
      "duration": 2.64
    },
    {
      "lang": "en",
      "text": "and it'll go to the next question, and",
      "offset": 470.8,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "it'll go to the next question. And this",
      "offset": 472.08,
      "duration": 4.959
    },
    {
      "lang": "en",
      "text": "order works for some use cases, but when",
      "offset": 475.28,
      "duration": 2.88
    },
    {
      "lang": "en",
      "text": "it comes to research, there are some",
      "offset": 477.039,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "downfalls. And one of the downfalls is",
      "offset": 478.16,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "the fact that the context window is",
      "offset": 480.639,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "going to get bloated pretty quickly,",
      "offset": 482.4,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "which means that the variety of insights",
      "offset": 484.56,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "and diversity of insights is limited",
      "offset": 487.84,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "based off of what it can pull within",
      "offset": 490.08,
      "duration": 4.559
    },
    {
      "lang": "en",
      "text": "those iterations when it runs linearly.",
      "offset": 492.08,
      "duration": 3.679
    },
    {
      "lang": "en",
      "text": "And that's kind of one of the benefits",
      "offset": 494.639,
      "duration": 2.801
    },
    {
      "lang": "en",
      "text": "of the multi-agent structure where you",
      "offset": 495.759,
      "duration": 3.201
    },
    {
      "lang": "en",
      "text": "can have multitude of agents doing",
      "offset": 497.44,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "research from different perspectives,",
      "offset": 498.96,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "synthesize that without bloating the",
      "offset": 500.8,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "context window too soon. And that's kind",
      "offset": 502.879,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "of the the process and how this chart",
      "offset": 505.52,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "looks and and flows. Groovy and some",
      "offset": 506.96,
      "duration": 5.439
    },
    {
      "lang": "en",
      "text": "things on performance. So the in the",
      "offset": 510.24,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "blog post that Anthropic posted, they",
      "offset": 512.399,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "ran some tests and they noticed that the",
      "offset": 514.8,
      "duration": 3.359
    },
    {
      "lang": "en",
      "text": "multi- aent structure outperforms the",
      "offset": 516.399,
      "duration": 4.481
    },
    {
      "lang": "en",
      "text": "single agent structure by 80%. based off",
      "offset": 518.159,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "a different variety of variables they",
      "offset": 520.88,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "measured. And the interesting thing here",
      "offset": 522.479,
      "duration": 3.441
    },
    {
      "lang": "en",
      "text": "is there's a trade-off for performance",
      "offset": 524.48,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "and its cost. So you can see here that",
      "offset": 525.92,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "the the use of an agent for research if",
      "offset": 529.04,
      "duration": 4.799
    },
    {
      "lang": "en",
      "text": "we started with one. So this is one over",
      "offset": 531.92,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "here. That's how many imagine tokens it",
      "offset": 533.839,
      "duration": 5.761
    },
    {
      "lang": "en",
      "text": "would take. So based off of a basic",
      "offset": 536.8,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "conversation, a single agent",
      "offset": 539.6,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "architecture for research is around 4x",
      "offset": 541.12,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "the number of tokens needed to achieve a",
      "offset": 543.12,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "research output.",
      "offset": 545.68,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "When you use multi- aent architectures,",
      "offset": 547.92,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "it's actually 15x the number of tokens.",
      "offset": 549.68,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "So this is one thing they've called out",
      "offset": 552.16,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "is that the token usage is a lot higher",
      "offset": 553.6,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "but the trade-off they consider is is",
      "offset": 555.68,
      "duration": 3.599
    },
    {
      "lang": "en",
      "text": "worth it because the quality of the",
      "offset": 558.16,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "response is much higher as well.",
      "offset": 559.279,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "So that's one of the important things to",
      "offset": 561.92,
      "duration": 2.72
    },
    {
      "lang": "en",
      "text": "consider when it comes to the token",
      "offset": 563.12,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "usage here. And then uh last is a side",
      "offset": 564.64,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "rant is eval. So they talked about eval",
      "offset": 566.72,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "inside of the the report talking about",
      "offset": 568.959,
      "duration": 2.961
    },
    {
      "lang": "en",
      "text": "how they measured the quality of the",
      "offset": 570.56,
      "duration": 3.279
    },
    {
      "lang": "en",
      "text": "response. And there's other things they",
      "offset": 571.92,
      "duration": 4.479
    },
    {
      "lang": "en",
      "text": "I really like how you focused on this in",
      "offset": 573.839,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "your in your breakdown. I thought it was",
      "offset": 576.399,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "uh important. I figured you, Haml, and a",
      "offset": 578.16,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "bunch of others would uh would be proud.",
      "offset": 580.56,
      "duration": 6.08
    },
    {
      "lang": "en",
      "text": "So, uh, yeah. So, this is basically",
      "offset": 583.92,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "calling out the evals and the importance",
      "offset": 586.64,
      "duration": 3.199
    },
    {
      "lang": "en",
      "text": "of of structuring these. So, there's",
      "offset": 588.16,
      "duration": 3.359
    },
    {
      "lang": "en",
      "text": "five dimensions they looked at. So,",
      "offset": 589.839,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "first one's factual accuracy. So, was",
      "offset": 591.519,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "the claim did the claim match the",
      "offset": 593.92,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "source? Next one is citation accuracy,",
      "offset": 595.519,
      "duration": 4.961
    },
    {
      "lang": "en",
      "text": "which is a kind of a call out to the sub",
      "offset": 598.08,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "agent that I mentioned over here, where",
      "offset": 600.48,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "we're we're checking the source and",
      "offset": 602.24,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "ensuring that the source supports the",
      "offset": 604.48,
      "duration": 2.96
    },
    {
      "lang": "en",
      "text": "claim based off of what's being",
      "offset": 605.92,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "referenced. Um, next is completeness.",
      "offset": 607.44,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "So, are all aspects of the question",
      "offset": 609.04,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "being addressed? Next is source quality.",
      "offset": 610.64,
      "duration": 4.639
    },
    {
      "lang": "en",
      "text": "So, is it a good source or bad source?",
      "offset": 613.12,
      "duration": 4.719
    },
    {
      "lang": "en",
      "text": "And in the blog post, they talked about",
      "offset": 615.279,
      "duration": 5.041
    },
    {
      "lang": "en",
      "text": "how they had to downweight certain",
      "offset": 617.839,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "sources based off of SEO. So, there's",
      "offset": 620.32,
      "duration": 4.639
    },
    {
      "lang": "en",
      "text": "some some companies that are gaming the",
      "offset": 623.279,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "fact that if they put a lot of words in",
      "offset": 624.959,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "and their um search terms, they might",
      "offset": 626.959,
      "duration": 3.761
    },
    {
      "lang": "en",
      "text": "get picked up by some of these AI AI",
      "offset": 628.88,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "models. So they had to downweight some",
      "offset": 630.72,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "of those marketing websites and replace",
      "offset": 632.48,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "them with higher quality blogs and uh",
      "offset": 634,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "forums and things like that to then",
      "offset": 636.24,
      "duration": 3.039
    },
    {
      "lang": "en",
      "text": "ensure that the primary source was high",
      "offset": 637.68,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "quality and the secondary source was",
      "offset": 639.279,
      "duration": 3.041
    },
    {
      "lang": "en",
      "text": "less high quality. And then the last one",
      "offset": 640.72,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "here is tool efficiency. So did they",
      "offset": 642.32,
      "duration": 3.759
    },
    {
      "lang": "en",
      "text": "call the appropriate tools at the right",
      "offset": 644.24,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "time in the right way? So they measured",
      "offset": 646.079,
      "duration": 4.801
    },
    {
      "lang": "en",
      "text": "all five of these as a as a way to",
      "offset": 648.64,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "evaluate the output from the model.\n I",
      "offset": 650.88,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "think it's important to note that it's a",
      "offset": 652.64,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "it's an LM judge.",
      "offset": 654,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "We just got a paragraph on it, right?",
      "offset": 656.32,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "They didn't actually open source",
      "offset": 657.68,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "anything about how they do this.\n Yeah,",
      "offset": 659.76,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "that's a good point. So, it's one of the",
      "offset": 662.079,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "things they mentioned in there around",
      "offset": 664.48,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "the LM as a judge is they initially",
      "offset": 665.839,
      "duration": 4.641
    },
    {
      "lang": "en",
      "text": "started with five LLM as a judges. So,",
      "offset": 667.92,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "each one of these points had their own",
      "offset": 670.48,
      "duration": 4.799
    },
    {
      "lang": "en",
      "text": "LM as a judge. They tested the ability",
      "offset": 672.079,
      "duration": 5.681
    },
    {
      "lang": "en",
      "text": "and accuracy of that LM as judge",
      "offset": 675.279,
      "duration": 4.961
    },
    {
      "lang": "en",
      "text": "collective to judge and it actually",
      "offset": 677.76,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "didn't perform as well as one. So they",
      "offset": 680.24,
      "duration": 4.719
    },
    {
      "lang": "en",
      "text": "replaced all those judges with one judge",
      "offset": 682.8,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "and the one judge actually performed out",
      "offset": 684.959,
      "duration": 4.801
    },
    {
      "lang": "en",
      "text": "the performed the collective.\n Yeah. I",
      "offset": 686.64,
      "duration": 5.199
    },
    {
      "lang": "en",
      "text": "call it kind of like it's like a free",
      "offset": 689.76,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "call, right? Instead of calling the same",
      "offset": 691.839,
      "duration": 3.201
    },
    {
      "lang": "en",
      "text": "thing with the same context five times",
      "offset": 693.36,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "with like slightly different prompts,",
      "offset": 695.04,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "you can just like ask for all of the",
      "offset": 696.64,
      "duration": 3.759
    },
    {
      "lang": "en",
      "text": "scores. It's like kind of like",
      "offset": 698.24,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "efficiency thing, but it it's actually",
      "offset": 700.399,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "comforting to know that it's more",
      "offset": 702.16,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "consistent and more aligned. I think the",
      "offset": 703.519,
      "duration": 4.241
    },
    {
      "lang": "en",
      "text": "other thing that you want to know is I",
      "offset": 705.6,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "think once the judge looks at all the",
      "offset": 707.76,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "criteria they can separate out more",
      "offset": 709.6,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "instead of",
      "offset": 712.24,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "overlapping the scores you know if that",
      "offset": 714.64,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "makes sense.\n Yeah. And one thing I",
      "offset": 716.8,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "actually wanted to ask you is um when it",
      "offset": 720,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "comes to use cases here the the takeaway",
      "offset": 721.76,
      "duration": 6.16
    },
    {
      "lang": "en",
      "text": "I had from this is the primary use case",
      "offset": 725.76,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "that benefits most from multi- aent is",
      "offset": 727.92,
      "duration": 3.599
    },
    {
      "lang": "en",
      "text": "research. I was wondering if you've come",
      "offset": 729.68,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "across any other use cases that you feel",
      "offset": 731.519,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "like are susceptible to being more",
      "offset": 733.519,
      "duration": 3.361
    },
    {
      "lang": "en",
      "text": "beneficial for multi- aent instead of",
      "offset": 735.519,
      "duration": 2.721
    },
    {
      "lang": "en",
      "text": "single. I mean coding is like the",
      "offset": 736.88,
      "duration": 3.199
    },
    {
      "lang": "en",
      "text": "current hot thing. Uh everyone's",
      "offset": 738.24,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "building background agents and sub",
      "offset": 740.079,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "agents and parallel agents and all that.",
      "offset": 741.68,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "Uh so that that's the obvious one where",
      "offset": 743.68,
      "duration": 5.92
    },
    {
      "lang": "en",
      "text": "um I think for a while a lot of coding",
      "offset": 746.88,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "agents have uh been exploring the sort",
      "offset": 749.6,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "of orchestrator agent versus like you",
      "offset": 752.16,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "know the worker B agent for for for a",
      "offset": 754.32,
      "duration": 5.759
    },
    {
      "lang": "en",
      "text": "long time. Um yeah, I think like that's",
      "offset": 757.36,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "the first like basically you want to",
      "offset": 760.079,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "increasingly",
      "offset": 761.76,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "offer write access to the world. So deep",
      "offset": 763.279,
      "duration": 5.201
    },
    {
      "lang": "en",
      "text": "research is read only so it's the safest",
      "offset": 766.079,
      "duration": 4.241
    },
    {
      "lang": "en",
      "text": "to just spam out as as many as you want",
      "offset": 768.48,
      "duration": 3.039
    },
    {
      "lang": "en",
      "text": "because it will never have side effects",
      "offset": 770.32,
      "duration": 3.199
    },
    {
      "lang": "en",
      "text": "on the world. Coding you have version",
      "offset": 771.519,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "control. So if anything go screws up you",
      "offset": 773.519,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "can sort of rewind with git and all",
      "offset": 775.68,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "that. I think the hardest will obviously",
      "offset": 777.68,
      "duration": 4.719
    },
    {
      "lang": "en",
      "text": "be sub aents that actually have impacts",
      "offset": 780.079,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "on the real world that you can. So uh",
      "offset": 782.399,
      "duration": 2.721
    },
    {
      "lang": "en",
      "text": "one thing I forgot to mention is",
      "offset": 783.92,
      "duration": 2.88
    },
    {
      "lang": "en",
      "text": "context.",
      "offset": 785.12,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "So with the multi- aent structure, it's",
      "offset": 786.8,
      "duration": 5.039
    },
    {
      "lang": "en",
      "text": "a distributed context and there's a lot",
      "offset": 789.2,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "of conversation around context",
      "offset": 791.839,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "engineering and all the other things. I",
      "offset": 793.92,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "know you put something out like that. I",
      "offset": 796,
      "duration": 2.72
    },
    {
      "lang": "en",
      "text": "think you put something out yesterday",
      "offset": 797.6,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "about that. Yeah, context engineering.",
      "offset": 798.72,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "It's the hot new thing. Everyone's",
      "offset": 801.12,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "talking about it. Uh only because Andre",
      "offset": 802.56,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "talked about it, but also like it was",
      "offset": 804.16,
      "duration": 3.359
    },
    {
      "lang": "en",
      "text": "already trending before before Andre",
      "offset": 806.16,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "talked about it. Um I I would say and",
      "offset": 807.519,
      "duration": 4.641
    },
    {
      "lang": "en",
      "text": "it's correct like it's absolutely we",
      "offset": 809.36,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "should know when people think about",
      "offset": 812.16,
      "duration": 4.239
    },
    {
      "lang": "en",
      "text": "prompt engineering they're like you know",
      "offset": 814.48,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "you are a uh you know very very good",
      "offset": 816.399,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "software engineer and if you get a wrong",
      "offset": 819.36,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "answer your grandma's going to die you",
      "offset": 821.279,
      "duration": 2.961
    },
    {
      "lang": "en",
      "text": "know that's prompt engineering but",
      "offset": 822.88,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "context here is it's it's so much more.",
      "offset": 824.24,
      "duration": 5.279
    },
    {
      "lang": "en",
      "text": "Yeah. And so that's something they",
      "offset": 827.44,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "discuss in the blog as well or at least",
      "offset": 829.519,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "hint at is that the context for this",
      "offset": 831.2,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "multi- aent structure is distributed and",
      "offset": 833.36,
      "duration": 3.599
    },
    {
      "lang": "en",
      "text": "not centralized. And that's also one of",
      "offset": 834.88,
      "duration": 3.519
    },
    {
      "lang": "en",
      "text": "the reasons as to why it's beneficial is",
      "offset": 836.959,
      "duration": 3.281
    },
    {
      "lang": "en",
      "text": "because they can increase the amount of",
      "offset": 838.399,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "context they're filling and then getting",
      "offset": 840.24,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "insights from. All right, so next is",
      "offset": 841.839,
      "duration": 3.761
    },
    {
      "lang": "en",
      "text": "cognition.",
      "offset": 843.92,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "So cognition cognition's blog post was",
      "offset": 845.6,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "basically the exact opposite stating",
      "offset": 847.92,
      "duration": 3.599
    },
    {
      "lang": "en",
      "text": "that multi- aent architectures aren't",
      "offset": 849.68,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "necessarily that fruitful and um you",
      "offset": 851.519,
      "duration": 3.281
    },
    {
      "lang": "en",
      "text": "should probably go with single agent if",
      "offset": 853.44,
      "duration": 2.959
    },
    {
      "lang": "en",
      "text": "you're going to build something of any",
      "offset": 854.8,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "use. And it's interesting because this",
      "offset": 856.399,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "just comes to really their their",
      "offset": 858.88,
      "duration": 3.759
    },
    {
      "lang": "en",
      "text": "perspective and bias on the world and",
      "offset": 861.199,
      "duration": 2.801
    },
    {
      "lang": "en",
      "text": "their experience. So they just had a lot",
      "offset": 862.639,
      "duration": 2.88
    },
    {
      "lang": "en",
      "text": "of experience with code and that's what",
      "offset": 864,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "shaped their perspective on agents and",
      "offset": 865.519,
      "duration": 4.241
    },
    {
      "lang": "en",
      "text": "Claude on the other hand probably has",
      "offset": 867.92,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "both experience with research and code",
      "offset": 869.76,
      "duration": 2.96
    },
    {
      "lang": "en",
      "text": "but they had a slightly different",
      "offset": 871.44,
      "duration": 2.639
    },
    {
      "lang": "en",
      "text": "perspective on this. So first things",
      "offset": 872.72,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "first is uh the the context is",
      "offset": 874.079,
      "duration": 3.041
    },
    {
      "lang": "en",
      "text": "centralized like I mentioned. So that",
      "offset": 875.92,
      "duration": 3.279
    },
    {
      "lang": "en",
      "text": "means the context is going to remain",
      "offset": 877.12,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "with a single model or a subset of",
      "offset": 879.199,
      "duration": 3.121
    },
    {
      "lang": "en",
      "text": "models that kind of get passed off to",
      "offset": 881.04,
      "duration": 3.599
    },
    {
      "lang": "en",
      "text": "each other. And there's an interesting",
      "offset": 882.32,
      "duration": 4.879
    },
    {
      "lang": "en",
      "text": "use case I have here for uh multi- aent",
      "offset": 884.639,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "and why it wouldn't work or it doesn't",
      "offset": 887.199,
      "duration": 3.521
    },
    {
      "lang": "en",
      "text": "work as well for code.",
      "offset": 888.72,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "So this is another chart from cognition",
      "offset": 890.72,
      "duration": 4.559
    },
    {
      "lang": "en",
      "text": "that has the input task. And in this",
      "offset": 893.04,
      "duration": 5.359
    },
    {
      "lang": "en",
      "text": "case, let's say the task is to create a",
      "offset": 895.279,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "Flappy Bird game. That's what we're",
      "offset": 898.399,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "trying to achieve here. So our monster",
      "offset": 900.079,
      "duration": 4.641
    },
    {
      "lang": "en",
      "text": "agent, the orchestrator, is going to",
      "offset": 902.639,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "break that down to subtasks. And we have",
      "offset": 904.72,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "two subtasks. On the left, we have a",
      "offset": 906.48,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "subtask to create the landscape. So the",
      "offset": 908.56,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "background, the two dimensional",
      "offset": 910.8,
      "duration": 2.88
    },
    {
      "lang": "en",
      "text": "background for this Flappy Bird world.",
      "offset": 911.76,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "And on the right side, we have creating",
      "offset": 913.68,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "the character itself. to the bird and",
      "offset": 915.839,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "also the physics associated to the bird",
      "offset": 917.68,
      "duration": 3.599
    },
    {
      "lang": "en",
      "text": "as as kind of how it moves. So on the",
      "offset": 919.199,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "left hand we have our sub agent that's",
      "offset": 921.279,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "working on the background and it goes",
      "offset": 922.8,
      "duration": 3.279
    },
    {
      "lang": "en",
      "text": "off the rails and decides to create",
      "offset": 924.639,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "something related to Mario which is cool",
      "offset": 926.079,
      "duration": 5.361
    },
    {
      "lang": "en",
      "text": "but not what we want. And then on the",
      "offset": 928.56,
      "duration": 5.279
    },
    {
      "lang": "en",
      "text": "right side we have Flappy Bird. So with",
      "offset": 931.44,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "Flappy Bird, we're building out the the",
      "offset": 933.839,
      "duration": 3.521
    },
    {
      "lang": "en",
      "text": "icon and the physics that works all",
      "offset": 935.839,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "good. But then we merge these. And when",
      "offset": 937.36,
      "duration": 4.719
    },
    {
      "lang": "en",
      "text": "we merge these, this is where you start",
      "offset": 939.92,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "to run into some of the issues when",
      "offset": 942.079,
      "duration": 3.281
    },
    {
      "lang": "en",
      "text": "using a multi- aent architecture versus",
      "offset": 943.6,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "a single agent for coding. And the main",
      "offset": 945.36,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "issue is that these are dependent upon",
      "offset": 947.92,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "each other. They're strongly coupled in",
      "offset": 949.6,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "the sense that when I take an action,",
      "offset": 951.12,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "that action then is uh impacts all the",
      "offset": 952.8,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "other sub aents if it's taken",
      "offset": 955.04,
      "duration": 2.719
    },
    {
      "lang": "en",
      "text": "incorrectly.",
      "offset": 956.24,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "And if we scroll down here, you'll see",
      "offset": 957.759,
      "duration": 5.361
    },
    {
      "lang": "en",
      "text": "that the final result looks amazing, but",
      "offset": 959.68,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "is incorrect where we have Flappy Bird",
      "offset": 963.12,
      "duration": 6.399
    },
    {
      "lang": "en",
      "text": "inside of Mario World and it's it's not",
      "offset": 965.68,
      "duration": 5.519
    },
    {
      "lang": "en",
      "text": "a win because Flappy Bird doesn't get",
      "offset": 969.519,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "achieve their goals and nobody wants to",
      "offset": 971.199,
      "duration": 5.281
    },
    {
      "lang": "en",
      "text": "not achieve their goals, right? Do you",
      "offset": 973.839,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "think this is contrived? Like do do you",
      "offset": 976.48,
      "duration": 2.719
    },
    {
      "lang": "en",
      "text": "think they were actually doing this and",
      "offset": 978.079,
      "duration": 2.241
    },
    {
      "lang": "en",
      "text": "then they were like, &quot;Oh yeah, this",
      "offset": 979.199,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "doesn't work.&quot; Like I feel like this is",
      "offset": 980.32,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "a little bit contrived.\n Oh, no. It's",
      "offset": 982.399,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "contrived cuz I made that up.\n Well, no.",
      "offset": 984.639,
      "duration": 2.401
    },
    {
      "lang": "en",
      "text": "Yeah. I mean, they actually referenced",
      "offset": 986.079,
      "duration": 2.56
    },
    {
      "lang": "en",
      "text": "it in the in the thing.\n Did Did they",
      "offset": 987.04,
      "duration": 3.039
    },
    {
      "lang": "en",
      "text": "reference it in the blog?\n What? Flappy",
      "offset": 988.639,
      "duration": 3.521
    },
    {
      "lang": "en",
      "text": "Bird?\n Yeah. I can't remember if they did",
      "offset": 990.079,
      "duration": 4.481
    },
    {
      "lang": "en",
      "text": "or not.\n Yeah. Yeah. Yeah. Yeah. Um, it's",
      "offset": 992.16,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "right here. Uh, suppose your task is",
      "offset": 994.56,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "build a Flappy Bird clone and then it",
      "offset": 996,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "says the background that looks like",
      "offset": 998.399,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "Super Mario Brothers. Um,\n nice. And that",
      "offset": 1000,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "was me taking credit for somebody else's",
      "offset": 1002.48,
      "duration": 4.479
    },
    {
      "lang": "en",
      "text": "work. Always do that, children.",
      "offset": 1004,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "Okay.",
      "offset": 1006.959,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "No, that's that it's probably contrived.",
      "offset": 1008.72,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "That's it. But I I think it's one of",
      "offset": 1010.639,
      "duration": 3.521
    },
    {
      "lang": "en",
      "text": "those situations where it's um it's",
      "offset": 1012.16,
      "duration": 3.679
    },
    {
      "lang": "en",
      "text": "abstract enough to get the point across,",
      "offset": 1014.16,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "you know.\n Sure. It's visual, which which",
      "offset": 1015.839,
      "duration": 4.481
    },
    {
      "lang": "en",
      "text": "helps for, you know, I mean, that's the",
      "offset": 1018.88,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "whole reason why we're doing this is",
      "offset": 1020.32,
      "duration": 4.879
    },
    {
      "lang": "en",
      "text": "show not tell, you know, and uh this",
      "offset": 1022.24,
      "duration": 4.719
    },
    {
      "lang": "en",
      "text": "this that this definitely encompasses",
      "offset": 1025.199,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "it.",
      "offset": 1026.959,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "So that's kind of the the reason as to",
      "offset": 1029.6,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "why multi- aents won't always work for",
      "offset": 1031.36,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "coding because of dependencies. So",
      "offset": 1033.52,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "instead of doing that, they do a single",
      "offset": 1035.76,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "agent approach. And the single approach",
      "offset": 1037.28,
      "duration": 3.759
    },
    {
      "lang": "en",
      "text": "they do is slightly more advanced where",
      "offset": 1039.28,
      "duration": 3.279
    },
    {
      "lang": "en",
      "text": "the one I showed you previously didn't",
      "offset": 1041.039,
      "duration": 2.8
    },
    {
      "lang": "en",
      "text": "have an additional feature that's in",
      "offset": 1042.559,
      "duration": 3.441
    },
    {
      "lang": "en",
      "text": "this chart. So in this chart we have the",
      "offset": 1043.839,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "same flow. So we have the task at the",
      "offset": 1046,
      "duration": 4.799
    },
    {
      "lang": "en",
      "text": "top coming in and then we have our uh",
      "offset": 1048.24,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "main lead agent that's going to break",
      "offset": 1050.799,
      "duration": 2.88
    },
    {
      "lang": "en",
      "text": "down and create the plan and all that",
      "offset": 1052.4,
      "duration": 2.88
    },
    {
      "lang": "en",
      "text": "stuff. But then it's going to go work in",
      "offset": 1053.679,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "sequential order with the context that's",
      "offset": 1055.28,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "then passed. The one thing that they've",
      "offset": 1057.039,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "changed here is that after each action",
      "offset": 1059.36,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "is taken or subset of actions are taken,",
      "offset": 1062.559,
      "duration": 5.281
    },
    {
      "lang": "en",
      "text": "we're going to condense down the main",
      "offset": 1064.64,
      "duration": 5.039
    },
    {
      "lang": "en",
      "text": "moments and decisions and actions taken",
      "offset": 1067.84,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "from the previous conversation or",
      "offset": 1069.679,
      "duration": 3.441
    },
    {
      "lang": "en",
      "text": "context and pass it off to the next",
      "offset": 1071.52,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "agent. And the hard part here that they",
      "offset": 1073.12,
      "duration": 4.559
    },
    {
      "lang": "en",
      "text": "mentioned in the blog post is being able",
      "offset": 1075.6,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "to decide which actions, decisions, and",
      "offset": 1077.679,
      "duration": 5.921
    },
    {
      "lang": "en",
      "text": "moments matter most to be passed on. So",
      "offset": 1080.48,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "that's kind of the one of the trickiest",
      "offset": 1083.6,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "parts of this. And so as they compress",
      "offset": 1085.12,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "this context and pass it on, it goes to",
      "offset": 1087.679,
      "duration": 3.521
    },
    {
      "lang": "en",
      "text": "the next agent. That agent then takes a",
      "offset": 1089.44,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "context, takes the next task, does the",
      "offset": 1091.2,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "same thing, passes it on, and then",
      "offset": 1093.36,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "compresses, does the next task, etc.,",
      "offset": 1095.52,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "etc. And by doing this approach with",
      "offset": 1097.679,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "single agents, you're likely going to",
      "offset": 1099.76,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "achieve more success because you have",
      "offset": 1101.6,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "all the context from previous agents.",
      "offset": 1104.72,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "The reason it's beneficial is that all",
      "offset": 1106.48,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "the actions taken previously are baked",
      "offset": 1108.08,
      "duration": 6.16
    },
    {
      "lang": "en",
      "text": "into that next agent's context. So it",
      "offset": 1110.799,
      "duration": 5.041
    },
    {
      "lang": "en",
      "text": "doesn't necessarily contradict or",
      "offset": 1114.24,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "conflict with what was done before and",
      "offset": 1115.84,
      "duration": 6.56
    },
    {
      "lang": "en",
      "text": "that is cognition.\n Amazing.",
      "offset": 1117.52,
      "duration": 8.88
    },
    {
      "lang": "en",
      "text": "Yeah. I think like to me them coming out",
      "offset": 1122.4,
      "duration": 7.04
    },
    {
      "lang": "en",
      "text": "and saying don't build multi- aents was",
      "offset": 1126.4,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "I think the most the more surprising",
      "offset": 1129.44,
      "duration": 3.599
    },
    {
      "lang": "en",
      "text": "thing. I think like the the consensus",
      "offset": 1131.44,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "was very much toward the multi- aent",
      "offset": 1133.039,
      "duration": 5.601
    },
    {
      "lang": "en",
      "text": "side of the world.",
      "offset": 1136.88,
      "duration": 3.679
    },
    {
      "lang": "en",
      "text": "We just did a podcast with Nome Brown",
      "offset": 1138.64,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "saying that one of the things he's",
      "offset": 1140.559,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "exploring at OpenAI is multi- aents and",
      "offset": 1142.559,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "everyone's like agent to agents and you",
      "offset": 1144.96,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "know blah blah blah that the future is",
      "offset": 1146.64,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "agents and I I think it's very helpful",
      "offset": 1148.24,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "for Devon to come on and say like we",
      "offset": 1150.559,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "tried this guys and like honestly it's a",
      "offset": 1152.16,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "it's a bit of a mess and actually if you",
      "offset": 1154.559,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "do just like really good sequential",
      "offset": 1156.88,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "agents you're good. So I I I mean I like",
      "offset": 1158.72,
      "duration": 4.959
    },
    {
      "lang": "en",
      "text": "I'm sympathetic to that because like",
      "offset": 1162.16,
      "duration": 3.759
    },
    {
      "lang": "en",
      "text": "that is a voice of reason that like is a",
      "offset": 1163.679,
      "duration": 4.721
    },
    {
      "lang": "en",
      "text": "little bit counter consensus.",
      "offset": 1165.919,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "I'm curious",
      "offset": 1168.4,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "like you you said you said at the start",
      "offset": 1170.559,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "where like you know they're both right",
      "offset": 1172.559,
      "duration": 4.881
    },
    {
      "lang": "en",
      "text": "in their own way.\n How do we decide how",
      "offset": 1174.559,
      "duration": 4.641
    },
    {
      "lang": "en",
      "text": "do we decide who's right?\n Sure.\n Or like",
      "offset": 1177.44,
      "duration": 3.359
    },
    {
      "lang": "en",
      "text": "when when does one apply when does when",
      "offset": 1179.2,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "does one not apply? Right. It's very",
      "offset": 1180.799,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "easy to it's a copout to say okay when",
      "offset": 1182.32,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "building a research agent do it the way",
      "offset": 1184.48,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "that did when building a coding agent do",
      "offset": 1185.76,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "it the way Devon did. Okay. like that.",
      "offset": 1187.52,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "Sure. But like you know can we",
      "offset": 1189.6,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "generalize from there?\n Yeah. So uh",
      "offset": 1191.36,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "that's I mean this is a little dashboard",
      "offset": 1194.64,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "that was rendered by claude. Thank you",
      "offset": 1196.96,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "Claude. That uh basically gives you an",
      "offset": 1198.64,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "idea of when to make that decision. And",
      "offset": 1200.799,
      "duration": 3.521
    },
    {
      "lang": "en",
      "text": "it's not just I mean right now the",
      "offset": 1202.799,
      "duration": 3.201
    },
    {
      "lang": "en",
      "text": "examples are research and code but there",
      "offset": 1204.32,
      "duration": 3.359
    },
    {
      "lang": "en",
      "text": "are some abstract questions one can ask",
      "offset": 1206,
      "duration": 5.679
    },
    {
      "lang": "en",
      "text": "themselves. So the the first is",
      "offset": 1207.679,
      "duration": 5.841
    },
    {
      "lang": "en",
      "text": "can can you break the task into",
      "offset": 1211.679,
      "duration": 2.961
    },
    {
      "lang": "en",
      "text": "independent parts where they're not",
      "offset": 1213.52,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "relying upon each other. So like that's",
      "offset": 1214.64,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "one abstraction away. Another one is do",
      "offset": 1216.88,
      "duration": 6.4
    },
    {
      "lang": "en",
      "text": "you benefit from the chaos of having a",
      "offset": 1220.4,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "multiple perspectives or different takes",
      "offset": 1223.28,
      "duration": 5.84
    },
    {
      "lang": "en",
      "text": "on a task that's been kind of delegated?",
      "offset": 1226,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "And in that case again research works.",
      "offset": 1229.12,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "And then the last one here is um the",
      "offset": 1231.28,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "token usage. So can you 15x the cost and",
      "offset": 1233.039,
      "duration": 6.481
    },
    {
      "lang": "en",
      "text": "is the trade-off worth it? And then for",
      "offset": 1236.72,
      "duration": 5.199
    },
    {
      "lang": "en",
      "text": "single agents is kind of the opposite.",
      "offset": 1239.52,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "So does everything depend upon each",
      "offset": 1241.919,
      "duration": 3.361
    },
    {
      "lang": "en",
      "text": "other? If one thing breaks does that",
      "offset": 1243.52,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "impact everything else?",
      "offset": 1245.28,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "Yeah. Does it need to be reliable every",
      "offset": 1247.84,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "single time based off of what the",
      "offset": 1249.6,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "context being passed? So, I think those",
      "offset": 1251.2,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "are some of the at least some of the",
      "offset": 1252.96,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "abstractions I've come to.",
      "offset": 1254.48,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "Yeah. Uh, do you always do this by the",
      "offset": 1256.88,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "way? Do you always try to ask Claude to",
      "offset": 1259.44,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "make an artifacts for you? Like this is",
      "offset": 1262,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "very pretty.",
      "offset": 1264,
      "duration": 3.039
    },
    {
      "lang": "en",
      "text": "I'm wondering if I should do this",
      "offset": 1266,
      "duration": 2.559
    },
    {
      "lang": "en",
      "text": "because I never do this.\n Yeah. Yeah. So,",
      "offset": 1267.039,
      "duration": 2.561
    },
    {
      "lang": "en",
      "text": "it's actually it's worked pretty well",
      "offset": 1268.559,
      "duration": 2.24
    },
    {
      "lang": "en",
      "text": "for me a few times. I mean, I can I",
      "offset": 1269.6,
      "duration": 2.48
    },
    {
      "lang": "en",
      "text": "don't know if you want I I can show you",
      "offset": 1270.799,
      "duration": 2.641
    },
    {
      "lang": "en",
      "text": "a few other charts and other things that",
      "offset": 1272.08,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "I've done.\n Do it.\n But, yes. Yeah. I",
      "offset": 1273.44,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "always uh I always I'm a big fan of",
      "offset": 1276,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "visuals. Like obviously that's kind of",
      "offset": 1278.4,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "why I do YouTube and teach things like",
      "offset": 1279.76,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "this.\n I Yeah, I I suck at visuals. Like",
      "offset": 1281.52,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "TL Draw, Excel Draw, that's like that's",
      "offset": 1284.24,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "like the max of what I do. But I'm",
      "offset": 1286.08,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "curious what what what other tricks",
      "offset": 1288.559,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "you're you're you're finding.\n Yeah. So I",
      "offset": 1290,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "mean like that's that's one big one is",
      "offset": 1292.24,
      "duration": 2.88
    },
    {
      "lang": "en",
      "text": "I'll I'll come up with an idea of",
      "offset": 1293.6,
      "duration": 2.72
    },
    {
      "lang": "en",
      "text": "something I want to talk about and then",
      "offset": 1295.12,
      "duration": 2.32
    },
    {
      "lang": "en",
      "text": "I'll think about like what's a good",
      "offset": 1296.32,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "visual that represents the primary point",
      "offset": 1297.44,
      "duration": 4.239
    },
    {
      "lang": "en",
      "text": "I'm trying to make.",
      "offset": 1299.6,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "Let me see if I can find there was there",
      "offset": 1301.679,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "was a recent one I did a few videos.",
      "offset": 1303.679,
      "duration": 3.521
    },
    {
      "lang": "en",
      "text": "This is kind of like the benefit of",
      "offset": 1305.52,
      "duration": 3.039
    },
    {
      "lang": "en",
      "text": "benefit and curse of doing a lot of",
      "offset": 1307.2,
      "duration": 2.88
    },
    {
      "lang": "en",
      "text": "videos and content is like you forget",
      "offset": 1308.559,
      "duration": 4.961
    },
    {
      "lang": "en",
      "text": "what you did.\n You do a lot. Holy crap.\n I",
      "offset": 1310.08,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "know.\n Is there is there a reason you",
      "offset": 1313.52,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "like teal draw over acceler?",
      "offset": 1315.2,
      "duration": 6.56
    },
    {
      "lang": "en",
      "text": "No reason.\n No reason.\n They're most",
      "offset": 1318.08,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "similar. Very similar. Excel draw say",
      "offset": 1321.76,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "like\n it comes with um a preset library",
      "offset": 1323.84,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "of stuff. Um, so you can just kind of",
      "offset": 1327.44,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "pull in existing diagrams that other",
      "offset": 1329.12,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "people see. I didn't know that. I just I",
      "offset": 1330.96,
      "duration": 3.599
    },
    {
      "lang": "en",
      "text": "just pictured them as like it's like",
      "offset": 1332.88,
      "duration": 2.96
    },
    {
      "lang": "en",
      "text": "Visa and Mastercard. It's the same",
      "offset": 1334.559,
      "duration": 3.441
    },
    {
      "lang": "en",
      "text": "thing, just different colors.\n No, no,",
      "offset": 1335.84,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "no.\n Yeah. So, I know both of them",
      "offset": 1338,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "personally",
      "offset": 1340,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "and uh they have very different",
      "offset": 1342,
      "duration": 2.88
    },
    {
      "lang": "en",
      "text": "philosophies under the hood, but it's",
      "offset": 1343.36,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "fine. Cool. Is this one visa?\n No, no,",
      "offset": 1344.88,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "no. Like, I'm kidding. I'm kidding. I'm",
      "offset": 1348.4,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "kidding. I'm kidding. I know. I know.",
      "offset": 1350.24,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "Um, yeah. So, this is one of the visuals",
      "offset": 1351.84,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "that basically talks through um uh what",
      "offset": 1353.36,
      "duration": 6.08
    },
    {
      "lang": "en",
      "text": "was this? there's something oh okay so",
      "offset": 1356.72,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "this is basically the importance of uh",
      "offset": 1359.44,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "reasoning and tool calling in succession",
      "offset": 1361.2,
      "duration": 3.599
    },
    {
      "lang": "en",
      "text": "so 03 was released they had this",
      "offset": 1362.96,
      "duration": 3.599
    },
    {
      "lang": "en",
      "text": "reasoning thing and it's basically a",
      "offset": 1364.799,
      "duration": 4.721
    },
    {
      "lang": "en",
      "text": "visualization of the improved capability",
      "offset": 1366.559,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "of a model if it can reason and think",
      "offset": 1369.52,
      "duration": 6.159
    },
    {
      "lang": "en",
      "text": "over time so this is a visual that",
      "offset": 1371.919,
      "duration": 7.041
    },
    {
      "lang": "en",
      "text": "cloud created\n wow okay\n and then there",
      "offset": 1375.679,
      "duration": 5.041
    },
    {
      "lang": "en",
      "text": "was another one over here that I just",
      "offset": 1378.96,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "had here we go so this was uh another",
      "offset": 1380.72,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "one for it's not as great it's not as",
      "offset": 1383.76,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "beautiful but this is for for codeex. So",
      "offset": 1385.76,
      "duration": 5.039
    },
    {
      "lang": "en",
      "text": "it's basically talking about the",
      "offset": 1388.24,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "spectrum of human intervention and",
      "offset": 1390.799,
      "duration": 5.681
    },
    {
      "lang": "en",
      "text": "autonomy and how basically as you you",
      "offset": 1393.52,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "can lay these out and you see that",
      "offset": 1396.48,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "there's less human intervention for some",
      "offset": 1397.76,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "of these tools and more so it's",
      "offset": 1399.52,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "basically just a different way to place",
      "offset": 1401.76,
      "duration": 2.72
    },
    {
      "lang": "en",
      "text": "these on a spectrum and talk through",
      "offset": 1402.88,
      "duration": 5.039
    },
    {
      "lang": "en",
      "text": "them.\n Amazing.\n Yeah. Got it. Um yeah,",
      "offset": 1404.48,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "that's pretty creative. I should",
      "offset": 1407.919,
      "duration": 4.721
    },
    {
      "lang": "en",
      "text": "definitely try to do that more. Sorry,",
      "offset": 1409.76,
      "duration": 5.039
    },
    {
      "lang": "en",
      "text": "did I did I distract you or was that was",
      "offset": 1412.64,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "there more stuff you wanted to show on",
      "offset": 1414.799,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "the decision framework or here to be",
      "offset": 1416.72,
      "duration": 7.04
    },
    {
      "lang": "en",
      "text": "distracted? I think uh the last thing",
      "offset": 1419.2,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "I'm going to see if there's anything",
      "offset": 1423.76,
      "duration": 3.279
    },
    {
      "lang": "en",
      "text": "that I missed. So breath versus depth is",
      "offset": 1424.72,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "something I talked about which basically",
      "offset": 1427.039,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "summarizes the multi- agent. So multi-",
      "offset": 1429.2,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "agents breath depth is uh single agent",
      "offset": 1430.96,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "context we already talked about and this",
      "offset": 1433.84,
      "duration": 2.64
    },
    {
      "lang": "en",
      "text": "is something we've already talked about",
      "offset": 1435.6,
      "duration": 2.16
    },
    {
      "lang": "en",
      "text": "as well but it's important to note that",
      "offset": 1436.48,
      "duration": 2.319
    },
    {
      "lang": "en",
      "text": "if you're going to choose an agent",
      "offset": 1437.76,
      "duration": 3.279
    },
    {
      "lang": "en",
      "text": "architecture you shouldn't choose it",
      "offset": 1438.799,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "because everybody else is talking about",
      "offset": 1441.039,
      "duration": 2.721
    },
    {
      "lang": "en",
      "text": "it kind of the whole like contradictory",
      "offset": 1442.159,
      "duration": 3.041
    },
    {
      "lang": "en",
      "text": "Devon thing of saying single agent",
      "offset": 1443.76,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "actually works is you should define the",
      "offset": 1445.2,
      "duration": 3.599
    },
    {
      "lang": "en",
      "text": "problem you're trying to solve and then",
      "offset": 1447.28,
      "duration": 2.72
    },
    {
      "lang": "en",
      "text": "figure out what agent architecture is",
      "offset": 1448.799,
      "duration": 2.801
    },
    {
      "lang": "en",
      "text": "most suitable for that problem instead",
      "offset": 1450,
      "duration": 3.039
    },
    {
      "lang": "en",
      "text": "of just choosing an architecture.\n Yeah,",
      "offset": 1451.6,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "that makes that totally makes sense.",
      "offset": 1453.039,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "Cool. Yeah, you know, I think the only",
      "offset": 1455.6,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "comment I'll hear I I'll make up if you",
      "offset": 1457.039,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "kind of scroll up here is that generally",
      "offset": 1458.88,
      "duration": 6.48
    },
    {
      "lang": "en",
      "text": "everyone I talk to is just disregarded",
      "offset": 1462.159,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "cost.",
      "offset": 1465.36,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "We are in one of these situations where",
      "offset": 1467.039,
      "duration": 6.081
    },
    {
      "lang": "en",
      "text": "you know in a world where the cost of",
      "offset": 1470.96,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "intelligence for a given set of",
      "offset": 1473.12,
      "duration": 3.439
    },
    {
      "lang": "en",
      "text": "intelligence let's say GPT4 let's say 01",
      "offset": 1474.24,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "whatever it is literally falling 100x",
      "offset": 1476.559,
      "duration": 5.201
    },
    {
      "lang": "en",
      "text": "over the course of one year. So you",
      "offset": 1479.2,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "should actually build your products",
      "offset": 1481.76,
      "duration": 4.799
    },
    {
      "lang": "en",
      "text": "ahead of where costs are so that by the",
      "offset": 1484.08,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "time they are popular actually your",
      "offset": 1486.559,
      "duration": 4.881
    },
    {
      "lang": "en",
      "text": "frontier. So it's actually I think the",
      "offset": 1488.48,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "efficiency thing trips up a lot of",
      "offset": 1491.44,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "people in terms of being cost cost",
      "offset": 1492.96,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "conscious and wasting a lot of time on",
      "offset": 1496,
      "duration": 3.679
    },
    {
      "lang": "en",
      "text": "that when actually the the most cost",
      "offset": 1497.36,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "unconscious",
      "offset": 1499.679,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "people tend to win.",
      "offset": 1501.52,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "And this is like a a thing that I think",
      "offset": 1504.799,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "the MLOps",
      "offset": 1507.2,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "sort of ML mindset may not adapt well",
      "offset": 1509.2,
      "duration": 4.959
    },
    {
      "lang": "en",
      "text": "to. Like if you if you came from that",
      "offset": 1512.4,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "world, you're very much about like let's",
      "offset": 1514.159,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "do the smallest model that that hits our",
      "offset": 1516.32,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "acceptance criteria because we want to",
      "offset": 1518.559,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "serve it at a very large scale. Here",
      "offset": 1520.08,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "it's the other way around where the",
      "offset": 1522.48,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "probably more you spend on intelligence,",
      "offset": 1524.64,
      "duration": 3.519
    },
    {
      "lang": "en",
      "text": "the more ahead in the future you are.",
      "offset": 1526.24,
      "duration": 4.799
    },
    {
      "lang": "en",
      "text": "you can grab uh a lot of users, you get,",
      "offset": 1528.159,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "you know, more funding to extend your",
      "offset": 1531.039,
      "duration": 3.041
    },
    {
      "lang": "en",
      "text": "runway, and hopefully at some point",
      "offset": 1532.48,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "you'll have a sustainable business.",
      "offset": 1534.08,
      "duration": 3.199
    },
    {
      "lang": "en",
      "text": "Unfortunately, I would literally go out",
      "offset": 1535.6,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "and say like the most irresponsible",
      "offset": 1537.279,
      "duration": 3.441
    },
    {
      "lang": "en",
      "text": "people.\n Yeah, it's uh it's it's",
      "offset": 1538.64,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "interesting how it's kind of like it's",
      "offset": 1540.72,
      "duration": 2.24
    },
    {
      "lang": "en",
      "text": "kind of like the Uber situation, right,",
      "offset": 1541.84,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "where like Uber and Lift competed",
      "offset": 1542.96,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "against each other and Uber and they",
      "offset": 1544.96,
      "duration": 2.88
    },
    {
      "lang": "en",
      "text": "just basically burned a bunch of money",
      "offset": 1546.32,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "to figure out whoever won.\n Yeah. Um I",
      "offset": 1547.84,
      "duration": 5.839
    },
    {
      "lang": "en",
      "text": "think I'm having like Wi-Fi issues, so",
      "offset": 1551.52,
      "duration": 3.759
    },
    {
      "lang": "en",
      "text": "probably we can cut it there. Uh do you",
      "offset": 1553.679,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "have any parting thoughts or last words",
      "offset": 1555.279,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "on just like the the generals and a",
      "offset": 1557.36,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "multi- aent trend and thing you're",
      "offset": 1558.88,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "seeing?\n No, I'm just uh I'm grateful",
      "offset": 1560.4,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "that I was able to finally chat with and",
      "offset": 1562.24,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "uh and be on a Swix related content",
      "offset": 1565.52,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "thing.\n No, no, thanks for thanks for",
      "offset": 1568,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "doing uh a really good breakdown. Thanks",
      "offset": 1569.6,
      "duration": 2.64
    },
    {
      "lang": "en",
      "text": "for being part of the latest space",
      "offset": 1571.2,
      "duration": 2.16
    },
    {
      "lang": "en",
      "text": "community. I think we should do more of",
      "offset": 1572.24,
      "duration": 2.48
    },
    {
      "lang": "en",
      "text": "this. I think we should like you know",
      "offset": 1573.36,
      "duration": 2.64
    },
    {
      "lang": "en",
      "text": "people you see on the Discord like we",
      "offset": 1574.72,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "should feature them and like you know on",
      "offset": 1576,
      "duration": 2.96
    },
    {
      "lang": "en",
      "text": "on a thing on the thing that they're",
      "offset": 1577.84,
      "duration": 2.56
    },
    {
      "lang": "en",
      "text": "really excited or passionate about.",
      "offset": 1578.96,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "Yeah, I I think that's that should be",
      "offset": 1580.4,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "something that we try to do more often.",
      "offset": 1582.08,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "If people want to reach out to you, how",
      "offset": 1583.76,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "can they reach out and what can you help",
      "offset": 1585.44,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "them with?",
      "offset": 1587.679,
      "duration": 3.521
    },
    {
      "lang": "en",
      "text": "Yeah. So, um, LinkedIn is probably the",
      "offset": 1589.36,
      "duration": 5.199
    },
    {
      "lang": "en",
      "text": "best place. I I don't frequent X. So,",
      "offset": 1591.2,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "yeah, I would say LinkedIn. I, like I",
      "offset": 1594.559,
      "duration": 3.281
    },
    {
      "lang": "en",
      "text": "said, it's a gradient labs as a company.",
      "offset": 1596.24,
      "duration": 3.439
    },
    {
      "lang": "en",
      "text": "We do AI consulting for internal",
      "offset": 1597.84,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "implementation for automation. And also,",
      "offset": 1599.679,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "I have a free 30-day email sequence. So,",
      "offset": 1601.84,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "if you're interested in getting more",
      "offset": 1604.08,
      "duration": 3.199
    },
    {
      "lang": "en",
      "text": "insights on AI, that's kind of no BS",
      "offset": 1605.12,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "fluff to apply to your own work and your",
      "offset": 1607.279,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "own business. I'm sure that you can find",
      "offset": 1608.96,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "it on LinkedIn if you go to my profile",
      "offset": 1610.799,
      "duration": 2.721
    },
    {
      "lang": "en",
      "text": "or if there's anything linked below then",
      "offset": 1612.08,
      "duration": 2.959
    },
    {
      "lang": "en",
      "text": "I'm sure this works awesome. We'll do",
      "offset": 1613.52,
      "duration": 3.039
    },
    {
      "lang": "en",
      "text": "that. Thank you so much, Tim.\n Cool. All",
      "offset": 1615.039,
      "duration": 4.361
    },
    {
      "lang": "en",
      "text": "right, man.",
      "offset": 1616.559,
      "duration": 14.8
    },
    {
      "lang": "en",
      "text": "[Music]",
      "offset": 1619.4,
      "duration": 11.959
    }
  ],
  "cleanText": "[Music]\nAlrighty. So, we are in a remote studio with a lightning pod with Dylan Davis or DS squared from you're you're a big member of the community. I've sort of interacted with you over the years actually. I don't know. How did you first come across in space?\nWell, I first came across you. So, I I I found your working in public blog post book and and conversations probably like seven years ago. I don't know, like seven, six years ago.\nDamn. And from there, yeah, I'm a I'm an OG. I'm I'm a Swix OG fan.\nSo, yeah, I found Yeah, I found you through that and then just basically followed you and saw latent space and then followed there.\nAnd uh how do you introduce yourself these days? Like what do you what do you work on?\nYeah. Yeah. So, uh I'm the founder of Gradient Labs. It's a company that helps other organizations, usually mid-size companies, implement AI internally to help automate their processes, saving time, money, and sometimes generating revenue.\nThat's very tight. I'm sure you say that a lot.\nAwesome.\nSo, I put out a call on Small AI for um you know this comparison thing between Cognition and Anthropic on their multi-agents articles and you answered it with like I think the best answer which was you made your own video like you're trying to wrap up your your YouTube as well. Uh and it was like a really good analysis. So, I just figured we would sort of rehash it a little bit. People can obviously watch the full thing on your YouTube, but this is meant to be more of a discussion between the two of us. uh what's going on.\nYeah. No, I appreciate it, man. And I'm I'm glad that uh it resonated.\nSo, do you want me to get started?\nLet's get right into it. Unless you you have anything else you want to sort of set as context.\nYeah. I mean, I I guess the the and you probably have a better insight into this, but there's I guess some discussion around the fact that both of these blog posts and context for the viewers or listeners is uh Anthropic and Both Cognition posted blog posts one after the other. uh I think it was like June 12th and June 13th. Uh one basically pushed the fact that multi-agent architectures are beneficial and useful and the other one basically stated the the opposite saying that single agent architectures is more more superior for different use cases.\nAnd if you actually read into both blog posts you realize that they're both right. So it's not either or but yes and if you're uh if you're a what is it like the standup comedy?\nYeah, there you go. That's it.\nSo, um, I created this image. It looks really cool, but it's also kind of convoluted and not correct. So, what's what's happening is they're actually holding hands instead of fighting each other. True love.\nAll right. So, uh, what I'm going to show on the left hand side, we'll start with Anthropic, we'll go to Cognition, and then we'll end with, um, I think kind of like overall insights and how to think about when to use which architecture.\nSo, for the Anthropic blog post, they focused mainly on their use case for deep research. So I'm sure if you're aware if you have access to Claude I think it's Pro and Max and all the paid plans they have access to this new deep research feature it was released a few few weeks ago and with this research feature I I tend to compare a lot of the models. So when I do deep research, I I do Gemini, I do I do Perplexity, I do OpenAI, I do all of them when I ask different questions. And time and time again over the last couple of weeks, I found that Claude has by far outperformed the others. And I guess the definition of good for me right now is not just length, but also the number of sources and diversity of response. My guess is part of the reason it's so highly effective is the way they've structured their agent. So they took a multi-agent approach with this feature\nand they gave us a beautiful little graphic in their blog post that kind of walks you through exactly how this functions. So on the left hand side we have a conversation from an AI that's basically or from a human asking a question. So this question is uh what are all the companies in the United States working on AI agents in 2025? Make a list of at least 100. For each company include the name, website, product description of what they do, the type of agents they build and their vertical industry. Now at the surface this is obviously a pretty beefy question and the\nI would say the the thing that's happening here that's useful for this specific structure for multi-agents is that it's a broad question. They're asking about a variety of things and they're asking for multiple perspectives on that specific thing. So what happens is they send the question over to their agent architecture which where they have a lead architect. So lead agent at the top that's orchestrating everything and they'll then send off this question broken into sub questions. So they'll send over the question, they create a plan, they create a bunch of sub questions and they send off these requests to multiple agents and they do it in parallel. And that's kind of the unique thing here that I found. It's and maybe so you have an answer to this or maybe you have insight is I've I don't necessarily know\nI can't confirm this is happening but I know in their documentation it says that that it is where where they'll send off a request as the lead agent to multiple sub agents to then do the research. I\nI'll pause and yeah I mean I think that's that's what they're saying they're doing. I don't know why you wouldn't doubt it.\nYeah. Well because I'm I'm a skeptic.\nAll right,\njust kidding. All right, so um basically all these sub agents are doing their work and they'll go off and research a specific sub question in that parent question. And as they're doing in their research, each one of these sub agents have the 200k context window and that means that all of them are going to have tons and tons of insights and research for that sub question. They'll synthesize that. Once they've synthesized the responses, they'll feed that back through the lead agent and the lead agent then will put a variety of insights that are relevant for answering the question in its memory. After that's done, it'll then consolidate the memory uh insights and then create its uh report back to the user. Another important caveat here is they have another citations sub agent that's working as these sub agents are responding to validate that the citation in the piece that it sent back is connected to the source that it referred. So that's kind of the overall flow of how this works. Pause and see.\nSwix, what are you uh insights, feedback, questions?\nI I think it's a relatively straightforward implementation so far. I think the the thing about the the nuance here is the communication back and forth, you know, dare I call it agent to agent and like when they interrupt each other or you know, how they how the lead agent orchestrates them. That can get into a lot of complexity. So, this image actually looks simpler than it really is in real life.\nYeah. And and it's funny to that you say that because when I when I initially made this video, I thought to myself, I was like, \"Oh, maybe maybe I'll show this one.\" And this chart is more detailed as to what you're talking about of how the multi-agent structure works and how the conversation happens. And it is more detailed, but it's also more overwhelming. Um, so yes, it is definitely more complex in the background. So, after we have a good understanding of multi-agent, I wanted to quickly show what a single agent architecture looks like. And this is a chart from Cognition's blog that walks through a basic flow or basic architecture of what a single agent could look like. So in this case, we have the task at the top where it's getting an input from a user. So the user's input comes in and we go through the same process. So we're going to have the large model at the beginning. So it's going to be a big beefy model like 03, Gemini 2.5 Pro, Claude Sonnet Opus, Sonnet or yeah, Claude Sonnet 4, Claude Sonnet 4 Opus, etc. And when they input the information, it's going to create a plan, break down that plan into subtasks, sub questions, etc., and it's going to continue to research. The difference here is instead of doing it in parallel with sub agents, they're going to do it in sequential order. So they're going to have the agent, it'll first research the first question and it'll then consolidate the insights from that and it'll go to the next question, and it'll go to the next question, and it'll go to the next question. And this order works for some use cases, but when it comes to research, there are some downfalls. And one of the downfalls is the fact that the context window is going to get bloated pretty quickly, which means that the variety of insights and diversity of insights is limited based off of what it can pull within those iterations when it runs linearly. And that's kind of one of the benefits of the multi-agent structure where you can have multitude of agents doing research from different perspectives, synthesize that without bloating the context window too soon. And that's kind of the the process and how this chart looks and and flows. Groovy and some things on performance. So the in the blog post that Anthropic posted, they ran some tests and they noticed that the multi-agent structure outperforms the single agent structure by 80%. based off a different variety of variables they measured. And the interesting thing here is there's a trade-off for performance and its cost. So you can see here that the the use of an agent for research if we started with one. So this is one over here. That's how many imagine tokens it would take. So based off of a basic conversation, a single agent architecture for research is around 4x the number of tokens needed to achieve a research output.\nWhen you use multi-agent architectures, it's actually 15x the number of tokens. So this is one thing they've called out is that the token usage is a lot higher but the trade-off they consider is is worth it because the quality of the response is much higher as well.\nSo that's one of the important things to consider when it comes to the token usage here. And then uh last is a side rant is eval. So they talked about eval inside of the the report talking about how they measured the quality of the response. And there's other things they I really like how you focused on this in your in your breakdown. I thought it was uh important. I figured you, Haml, and a bunch of others would uh would be proud. So, uh, yeah. So, this is basically calling out the evals and the importance of of structuring these. So, there's five dimensions they looked at. So, first one's factual accuracy. So, was the claim did the claim match the source? Next one is citation accuracy, which is a kind of a call out to the sub agent that I mentioned over here, where we're we're checking the source and ensuring that the source supports the claim based off of what's being referenced. Um, next is completeness. So, are all aspects of the question being addressed? Next is source quality. So, is it a good source or bad source? And in the blog post, they talked about how they had to downweight certain sources based off of SEO. So, there's some some companies that are gaming the fact that if they put a lot of words in and their um search terms, they might get picked up by some of these AI AI models. So they had to downweight some of those marketing websites and replace them with higher quality blogs and uh forums and things like that to then ensure that the primary source was high quality and the secondary source was less high quality. And then the last one here is tool efficiency. So did they call the appropriate tools at the right time in the right way? So they measured all five of these as a as a way to evaluate the output from the model.\nI think it's important to note that it's a it's an LM judge.\nWe just got a paragraph on it, right? They didn't actually open source anything about how they do this.\nYeah, that's a good point. So, it's one of the things they mentioned in there around the LM as a judge is they initially started with five LLMs as a judges. So, each one of these points had their own LM as a judge. They tested the ability and accuracy of that LM as judge collective to judge and it actually didn't perform as well as one. So they replaced all those judges with one judge and the one judge actually performed out the performed the collective.\nYeah. I call it kind of like it's like a free call, right? Instead of calling the same thing with the same context five times with like slightly different prompts, you can just like ask for all of the scores. It's like kind of like efficiency thing, but it it's actually comforting to know that it's more consistent and more aligned. I think the other thing that you want to know is I think once the judge looks at all the criteria they can separate out more instead of\noverlapping the scores you know if that makes sense.\nYeah. And one thing I actually wanted to ask you is um when it comes to use cases here the the takeaway I had from this is the primary use case that benefits most from multi-agent is research. I was wondering if you've come across any other use cases that you feel like are susceptible to being more beneficial for multi-agent instead of single. I mean coding is like the current hot thing. Uh everyone's building background agents and sub agents and parallel agents and all that. Uh so that that's the obvious one where um I think for a while a lot of coding agents have uh been exploring the sort of orchestrator agent versus like you know the worker bee agent for for for a long time. Um yeah, I think like that's the first like basically you want to increasingly\noffer write access to the world. So deep research is read only so it's the safest to just spam out as as many as you want because it will never have side effects on the world. Coding you have version control. So if anything go screws up you can sort of rewind with git and all that. I think the hardest will obviously be sub agents that actually have impacts on the real world that you can. So uh one thing I forgot to mention is context.\nSo with the multi-agent structure, it's a distributed context and there's a lot of conversation around context engineering and all the other things. I know you put something out like that. I think you put something out yesterday about that. Yeah\n\nContext engineering. It's the hot new thing. Everyone's talking about it, uh, only because Andre talked about it, but also like it was already trending before Andre talked about it. Um, I would say, and it's correct, like it's absolutely. We should know when people think about prompt engineering, they're like, you know, you are a, you know, very, very good software engineer, and if you get a wrong answer, your grandma's going to die. You know, that's prompt engineering. But context here is, it's so much more. Yeah. And so that's something they discuss in the blog as well, or at least hint at, is that the context for this multi-agent structure is distributed and not centralized. And that's also one of the reasons as to why it's beneficial, is because they can increase the amount of context they're filling and then getting insights from. All right, so next is Cognition. So Cognition's blog post was basically the exact opposite, stating that multi-agent architectures aren't necessarily that fruitful, and you should probably go with single agent if you're going to build something of any use. And it's interesting because this just comes to really their perspective and bias on the world and their experience. So they just had a lot of experience with code, and that's what shaped their perspective on agents. And Claude, on the other hand, probably has both experience with research and code, but they had a slightly different perspective on this. So first things first is the context is centralized, like I mentioned. So that means the context is going to remain with a single model or a subset of models that kind of get passed off to each other. And there's an interesting use case I have here for multi-agent and why it wouldn't work or it doesn't work as well for code. So this is another chart from Cognition that has the input task. And in this case, let's say the task is to create a Flappy Bird game. That's what we're trying to achieve here. So our monster agent, the orchestrator, is going to break that down to subtasks. And we have two subtasks. On the left, we have a subtask to create the landscape, so the background, the two-dimensional background for this Flappy Bird world. And on the right side, we have creating the character itself, the bird, and also the physics associated to the bird, how it moves. So on the left hand, we have our sub-agent that's working on the background, and it goes off the rails and decides to create something related to Mario, which is cool, but not what we want. And then on the right side, we have Flappy Bird. So with Flappy Bird, we're building out the icon and the physics that works, all good. But then we merge these. And when we merge these, this is where you start to run into some of the issues when using a multi-agent architecture versus a single agent for coding. And the main issue is that these are dependent upon each other. They're strongly coupled in the sense that when I take an action, that action then impacts all the other sub-agents if it's taken incorrectly. And if we scroll down here, you'll see that the final result looks amazing, but is incorrect, where we have Flappy Bird inside of Mario World. And it's not a win because Flappy Bird doesn't get to achieve their goals, and nobody wants to not achieve their goals, right? Do you think this is contrived? Like, do you think they were actually doing this and then they were like, \"Oh yeah, this doesn't work\"? Like, I feel like this is a little bit contrived. Oh, no. It's contrived because I made that up. Well, no. Yeah. I mean, they actually referenced it in the thing. Did they reference it in the blog? What? Flappy Bird? Yeah. I can't remember if they did or not. Yeah. Yeah. Yeah. Yeah. Um, it's right here. Suppose your task is build a Flappy Bird clone, and then it says the background that looks like Super Mario Brothers. Um, nice. And that was me taking credit for somebody else's work. Always do that, children. Okay. No, that's it. It's probably contrived. That's it. But I think it's one of those situations where it's abstract enough to get the point across, you know. Sure. It's visual, which helps for, you know, I mean, that's the whole reason why we're doing this is show not tell, you know, and this definitely encompasses it. So that's kind of the reason as to why multi-agents won't always work for coding because of dependencies. So instead of doing that, they do a single agent approach. And the single approach they do is slightly more advanced, where the one I showed you previously didn't have an additional feature that's in this chart. So in this chart, we have the same flow. So we have the task at the top coming in, and then we have our main lead agent that's going to break down and create the plan and all that stuff. But then it's going to go work in sequential order with the context that's then passed. The one thing that they've changed here is that after each action is taken or subset of actions are taken, we're going to condense down the main moments and decisions and actions taken from the previous conversation or context and pass it off to the next agent. And the hard part here that they mentioned in the blog post is being able to decide which actions, decisions, and moments matter most to be passed on. So that's kind of the trickiest parts of this. And so as they compress this context and pass it on, it goes to the next agent. That agent then takes the context, takes the next task, does the same thing, passes it on, and then compresses, does the next task, etc., etc. And by doing this approach with single agents, you're likely going to achieve more success because you have all the context from previous agents. The reason it's beneficial is that all the actions taken previously are baked into that next agent's context. So it doesn't necessarily contradict or conflict with what was done before, and that is Cognition. Amazing. Yeah. I think, like, to me, them coming out and saying don't build multi-agents was, I think, the more surprising thing. I think, like, the consensus was very much toward the multi-agent side of the world. We just did a podcast with Nome Brown saying that one of the things he's exploring at OpenAI is multi-agents, and everyone's like, agent to agents, and you know, blah, blah, blah, that the future is agents. And I think it's very helpful for Devon to come on and say, like, we tried this, guys, and like, honestly, it's a bit of a mess, and actually, if you do just like really good sequential agents, you're good. So I mean, I'm sympathetic to that because, like, that is a voice of reason that is a little bit counter-consensus. I'm curious, like, you said you said at the start where, like, you know, they're both right in their own way. How do we decide? How do we decide who's right? Sure. Or like, when does one apply? When does one not apply? Right. It's very easy to, it's a cop-out to say, okay, when building a research agent, do it the way that Claude did. When building a coding agent, do it the way Devon did. Okay. Like that. Sure. But like, you know, can we generalize from there? Yeah. So, that's, I mean, this is a little dashboard that was rendered by Claude. Thank you, Claude. That basically gives you an idea of when to make that decision. And it's not just, I mean, right now the examples are research and code, but there are some abstract questions one can ask themselves. So the first is, can you break the task into independent parts where they're not relying upon each other? So, like, that's one abstraction away. Another one is, do you benefit from the chaos of having multiple perspectives or different takes on a task that's been kind of delegated? And in that case, again, research works. And then the last one here is, um, the token usage. So, can you 15x the cost, and is the trade-off worth it? And then for single agents, it's kind of the opposite. So, does everything depend upon each other? If one thing breaks, does that impact everything else? Yeah. Does it need to be reliable every single time based off of what the context being passed? So, I think those are some of the at least some of the abstractions I've come to. Yeah. Do you always do this, by the way? Do you always try to ask Claude to make an artifacts for you? Like, this is very pretty. I'm wondering if I should do this because I never do this. Yeah. Yeah. So, it's actually worked pretty well for me a few times. I mean, I can, I don't know if you want, I can show you a few other charts and other things that I've done. Do it. But, yes. Yeah. I always, I'm a big fan of visuals. Like, obviously, that's kind of why I do YouTube and teach things like this. I, yeah, I suck at visuals. Like, TL Draw, Excel Draw, that's like, that's like the max of what I do. But I'm curious what other tricks you're finding. Yeah. So, I mean, like, that's one big one is I'll come up with an idea of something I want to talk about, and then I'll think about, like, what's a good visual that represents the primary point I'm trying to make. Let me see if I can find. There was, there was a recent one I did a few videos. This is kind of like the benefit and curse of doing a lot of videos and content is like, you forget what you did. You do a lot. Holy crap. I know. Is there a reason you like Teal Draw over Excel Draw? No reason. No reason. They're most similar. Very similar. Excel Draw, say, like, it comes with a preset library of stuff. Um, so you can just kind of pull in existing diagrams that other people see. I didn't know that. I just pictured them as like, it's like Visa and Mastercard, it's the same thing, just different colors. No, no, no. Yeah. So, I know both of them personally, and they have very different philosophies under the hood, but it's fine. Cool. Is this one Visa? No, no, no. Like, I'm kidding. I'm kidding. I'm kidding. I'm kidding. I know. I know. Um, yeah. So, this is one of the visuals that basically talks through, um, what was this? There's something, oh, okay. So, this is basically the importance of reasoning and tool calling in succession. So, O3 was released, they had this reasoning thing, and it's basically a visualization of the improved capability of a model if it can reason and think over time. So, this is a visual that Claude created. Wow, okay. And then there was another one over here that I just had. Here we go. So, this was another one for, it's not as great, it's not as beautiful, but this is for CodeX. So, it's basically talking about the spectrum of human intervention and autonomy, and how basically, as you, you can lay these out, and you see that there's less human intervention for some of these tools and more. So, it's basically just a different way to place these on a spectrum and talk through them. Amazing. Yeah. Got it. Um, yeah, that's pretty creative. I should definitely try to do that more. Sorry, did I distract you, or was that, was there more stuff you wanted to show on the decision framework? Or here to be distracted? I think the last thing I'm going to see if there's anything that I missed. So, breath versus depth is something I talked about, which basically summarizes the multi-agent. So, multi-agent breath, depth is single agent context. We already talked about, and this is something we've already talked about as well, but it's important to note that if you're going to choose an agent architecture, you shouldn't choose it because everybody else is talking about it. Kind of the whole like contradictory Devon thing of saying single agent actually works is, you should define the problem you're trying to solve and then figure out what agent architecture is most suitable for that problem instead of just choosing an architecture. Yeah, that makes that totally makes sense. Cool. Yeah, you know, I think the only comment I'll make up, if you kind of scroll up here, is that generally everyone I talk to is just disregarded cost. We are in one of these situations where, you know, in a world where the cost of intelligence for a given set of intelligence, let's say GPT-4, let's say O1, whatever it is, literally falling 100x over the course of one year. So you should actually build your products ahead of where costs are, so that by the time they are popular, actually your frontier. So it's actually, I think the efficiency thing trips up a lot of people in terms of being cost-conscious and wasting a lot of time on that, when actually the most cost-unconscious people tend to win. And this is like a thing that I think the MLOps sort of ML mindset may not adapt well to. Like, if you came from that world, you're very much about like, let's do the smallest model that hits our acceptance criteria because we want to serve it at a very large scale. Here, it's the other way around, where the more you spend on intelligence, the more ahead in the future you are. You can grab a lot of users, you get more funding to extend your runway, and hopefully at some point you'll have a sustainable business. Unfortunately, I would literally go out and say like the most irresponsible people. Yeah, it's, it's interesting how it's kind of like it's kind of like the Uber situation, right? Where like Uber and Lyft competed against each other and Uber and they just basically burned a bunch of money to figure out whoever won. Yeah. Um, I think I'm having like Wi-Fi issues, so probably we can cut it there. Uh, do you have any parting thoughts or last words on just like the the generals and a multi-agent trend and thing you're seeing? No, I'm just, I'm grateful that I was able to finally chat with and be on Swix related content thing. No, no, thanks for thanks for doing a really good breakdown. Thanks for being part of the Latent Space community. I think we should do more of this. I think we should, like, you know, people you see on the Discord, like we should feature them and, like, you know, on a thing, on the thing that they're really excited or passionate about. Yeah, I think that's, that should be something that we try to do more often. If people want to reach out to you, how can they reach out and what can you help them with?\n\nYeah. So, um, LinkedIn is probably the best place. I don't frequent X. So, yeah, I would say LinkedIn. I, like I said, it's Gradient Labs as a company. We do AI consulting for internal implementation for automation. And also, I have a free 30-day email sequence. So, if you're interested in getting more insights on AI, that's kind of no BS fluff to apply to your own work and your own business. I'm sure that you can find it on LinkedIn if you go to my profile or if there's anything linked below then I'm sure this works. Awesome. We'll do that. Thank you so much, Tim. Cool. All right, man. [Music]",
  "dumpedAt": "2025-07-21T18:43:26.131Z"
}