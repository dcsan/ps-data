{
  "episodeId": "SWIKyLSUBIc",
  "channelSlug": "@latentspacepod",
  "title": "Information Theory for Language Models: Jack Morris",
  "publishedAt": "2025-07-02T16:29:32.000Z",
  "rawLines": [
    {
      "lang": "en",
      "text": "Hello, this is L in space just switch",
      "offset": 3.6,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "today with uh our special guest Jack",
      "offset": 6.64,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "Morris I guess from Colombia. That's",
      "offset": 8.88,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "your affiliation right now?\n Cornell.",
      "offset": 10.8,
      "duration": 6.559
    },
    {
      "lang": "en",
      "text": "It's actually confusing because I go I'm",
      "offset": 14.48,
      "duration": 6.24
    },
    {
      "lang": "en",
      "text": "in a the New York City outpost of of",
      "offset": 17.359,
      "duration": 5.84
    },
    {
      "lang": "en",
      "text": "Cornell. So you have the city, right?",
      "offset": 20.72,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "But it's Cornell Tech, which is like a",
      "offset": 23.199,
      "duration": 5.601
    },
    {
      "lang": "en",
      "text": "small uh Cornell campus in New York. I",
      "offset": 25.76,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "just you're you're a student of Sasha",
      "offset": 28.8,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "Rush who teaches at Cornell, so I I",
      "offset": 30.24,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "should have made that connection. Okay.",
      "offset": 32.64,
      "duration": 3.759
    },
    {
      "lang": "en",
      "text": "Yeah, I'm sorry. Um well, that's that's",
      "offset": 33.92,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "a horrible mistake to make right off the",
      "offset": 36.399,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "bat, but uh you're one of look, you're",
      "offset": 37.92,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "one of the there are not that many PhD",
      "offset": 40.559,
      "duration": 5.201
    },
    {
      "lang": "en",
      "text": "students that make an impact with their",
      "offset": 43.36,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "research. The last time someone like",
      "offset": 45.76,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "this happens was Shinyu from Princeton",
      "offset": 48,
      "duration": 6.48
    },
    {
      "lang": "en",
      "text": "and uh he joined the OpenAI operator",
      "offset": 51.28,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "team quite shortly after he graduated.",
      "offset": 54.48,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "So, like you're one of those like",
      "offset": 56.96,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "high-profile PhD students at least",
      "offset": 58.64,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "that's like coming out of the program",
      "offset": 60.64,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "and like I figured like it was a good",
      "offset": 62.48,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "time to just like talk about your work",
      "offset": 64.64,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "and also the fact that you're looking",
      "offset": 66.96,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "for like which lab you're you're going",
      "offset": 69.52,
      "duration": 3.279
    },
    {
      "lang": "en",
      "text": "to join. That's like a whole interesting",
      "offset": 71.119,
      "duration": 4.241
    },
    {
      "lang": "en",
      "text": "meta discussion especially with like the",
      "offset": 72.799,
      "duration": 6.161
    },
    {
      "lang": "en",
      "text": "insane market for AI talent these days.",
      "offset": 75.36,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "What's it like to be AI grad student",
      "offset": 78.96,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "these days?\n Yeah, and thanks for having",
      "offset": 80.88,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "me. I guess maybe we can go back to when",
      "offset": 82.72,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "things first started or like like put",
      "offset": 85.68,
      "duration": 7.2
    },
    {
      "lang": "en",
      "text": "yourself in my shoes in 2017 2018 I",
      "offset": 88.4,
      "duration": 5.84
    },
    {
      "lang": "en",
      "text": "really learned a lot about machine",
      "offset": 92.88,
      "duration": 3.199
    },
    {
      "lang": "en",
      "text": "learning and at my I went to a state",
      "offset": 94.24,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "university. It's a good school but they",
      "offset": 96.079,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "didn't have like a deep learning",
      "offset": 98.32,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "research department or anything. They",
      "offset": 100.079,
      "duration": 2.961
    },
    {
      "lang": "en",
      "text": "had people doing it but it was just not",
      "offset": 101.68,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "as big at that time. But I was getting",
      "offset": 103.04,
      "duration": 4.719
    },
    {
      "lang": "en",
      "text": "really interested in those topics",
      "offset": 105.84,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "especially as applied to language. And",
      "offset": 107.759,
      "duration": 6.4
    },
    {
      "lang": "en",
      "text": "then in 2019, I kind of was starting to",
      "offset": 110.96,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "do research and I think thinking about",
      "offset": 114.159,
      "duration": 4.481
    },
    {
      "lang": "en",
      "text": "my career. I mean, at that point, I was",
      "offset": 116.32,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "20, 21. I was thinking about like where",
      "offset": 118.64,
      "duration": 6.159
    },
    {
      "lang": "en",
      "text": "do I want to be career-wise or like",
      "offset": 121.92,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "who's doing the coolest stuff right now?",
      "offset": 124.799,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "Like looking at like what kind of stuff",
      "offset": 126.88,
      "duration": 2.879
    },
    {
      "lang": "en",
      "text": "is coming out of that time. I mean, I",
      "offset": 128.399,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "think Alph Go, I thought Alph Go was",
      "offset": 129.759,
      "duration": 3.761
    },
    {
      "lang": "en",
      "text": "really good. At that time, I was playing",
      "offset": 131.599,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "a lot with like BERT and BERT based",
      "offset": 133.52,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "models. So like, you know, Google, Deep",
      "offset": 135.52,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "Mind, they're doing great work. GPT2,",
      "offset": 138.64,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "GPT1 from OpenAI were like interesting,",
      "offset": 141.04,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "but I think most people were into bird",
      "offset": 143.76,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "at that time. I still have a soft spot",
      "offset": 145.36,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "for like that parameter class of like",
      "offset": 148,
      "duration": 6.56
    },
    {
      "lang": "en",
      "text": "100 million to 1 billion scale models.",
      "offset": 151.04,
      "duration": 5.839
    },
    {
      "lang": "en",
      "text": "But this is all to say I think at that",
      "offset": 154.56,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "time I felt like the people doing a lot",
      "offset": 156.879,
      "duration": 3.761
    },
    {
      "lang": "en",
      "text": "of the most impactful work were like",
      "offset": 158.48,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "professors and PhD students. Like just a",
      "offset": 160.64,
      "duration": 4.879
    },
    {
      "lang": "en",
      "text": "ton of like interesting ideas being",
      "offset": 163.36,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "explored and cool opportunities in",
      "offset": 165.519,
      "duration": 5.681
    },
    {
      "lang": "en",
      "text": "academia. So I ended up applying to grad",
      "offset": 167.519,
      "duration": 6.241
    },
    {
      "lang": "en",
      "text": "school. Well, I first I did this Google",
      "offset": 171.2,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "AI residency program which was mostly",
      "offset": 173.76,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "during the pandemic like 2020 and then",
      "offset": 175.84,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "2021 and then I was also applying to",
      "offset": 178.08,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "grad school. Started grad school in 2021",
      "offset": 180.56,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "that's still what was going on at that",
      "offset": 183.2,
      "duration": 6.8
    },
    {
      "lang": "en",
      "text": "time like around when I guess GPT3",
      "offset": 185.84,
      "duration": 7.2
    },
    {
      "lang": "en",
      "text": "175 billion had been released but not",
      "offset": 190,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "instruct GPT. So like we had",
      "offset": 193.04,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "pre-training and sort of the science of",
      "offset": 195.36,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "pre-training was emerging but that's",
      "offset": 196.879,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "where the models were and I still think",
      "offset": 199.28,
      "duration": 6.16
    },
    {
      "lang": "en",
      "text": "like I'm glad that I went to grad school",
      "offset": 202.879,
      "duration": 4.801
    },
    {
      "lang": "en",
      "text": "and like I had a great experience but",
      "offset": 205.44,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "the last 5 years have changed a lot like",
      "offset": 207.68,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "the whole meta has shifted you know like",
      "offset": 210.72,
      "duration": 5.599
    },
    {
      "lang": "en",
      "text": "uh the kind of power dynamics are",
      "offset": 213.44,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "completely different the ideas are",
      "offset": 216.319,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "coming from different places most stuff",
      "offset": 217.92,
      "duration": 5.92
    },
    {
      "lang": "en",
      "text": "was open now most stuff is not open um",
      "offset": 219.92,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "the types of questions people are asking",
      "offset": 223.84,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "are different and so yeah I mean for",
      "offset": 225.92,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "better or for worse I did go to do the",
      "offset": 228.48,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "full grad school thing and and here I am",
      "offset": 230.239,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "it's been really interesting perspective",
      "offset": 233.68,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "watching the science kind of emerge with",
      "offset": 235.519,
      "duration": 5.521
    },
    {
      "lang": "en",
      "text": "the products like the biggest thing that",
      "offset": 238.64,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "happened by far was like chat GPT coming",
      "offset": 241.04,
      "duration": 3.759
    },
    {
      "lang": "en",
      "text": "out and which was right in the middle",
      "offset": 243.12,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "like what 2022 before Christmas like",
      "offset": 244.799,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "November I remember that year like all",
      "offset": 247.84,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "like my grandma was asking me about it",
      "offset": 250.239,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "and that's when it hit me like, oh, this",
      "offset": 252.48,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "is actually becoming like a real area",
      "offset": 254.56,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "that people will know about and",
      "offset": 257.28,
      "duration": 3.199
    },
    {
      "lang": "en",
      "text": "understand. Like I was trying to explain",
      "offset": 259.04,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "it to my parents and that's when I think",
      "offset": 260.479,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "things really started to change in terms",
      "offset": 263.04,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "of the types of questions you wanted to",
      "offset": 264.88,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "ask can't always be answered with",
      "offset": 267.04,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "academic resources. So a lot of the like",
      "offset": 269.36,
      "duration": 5.279
    },
    {
      "lang": "en",
      "text": "fundamental kind of like boundary",
      "offset": 272.16,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "pushing and AI science moved into",
      "offset": 274.639,
      "duration": 4.481
    },
    {
      "lang": "en",
      "text": "companies. That was the year when like",
      "offset": 276.96,
      "duration": 4.799
    },
    {
      "lang": "en",
      "text": "uh you know just around Europe's as well",
      "offset": 279.12,
      "duration": 4.799
    },
    {
      "lang": "en",
      "text": "everyone in in NL NLP and deep learning",
      "offset": 281.759,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "were were were like very confused at",
      "offset": 283.919,
      "duration": 3.521
    },
    {
      "lang": "en",
      "text": "like I think some people were like kind",
      "offset": 285.759,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "of expecting this already uh in a sense",
      "offset": 287.44,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "that they had they were obviously more",
      "offset": 289.759,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "clued into large language models but I",
      "offset": 291.6,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "think that the sheer amount of consumer",
      "offset": 294.639,
      "duration": 3.761
    },
    {
      "lang": "en",
      "text": "level interest that had that that was",
      "offset": 296.24,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "around at the time in 2022 that",
      "offset": 298.4,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "completely changed the world like now",
      "offset": 300.24,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "now we're just like in a different",
      "offset": 301.44,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "sphere. uh did you have to pivot your",
      "offset": 303.28,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "research or were you already you just",
      "offset": 305.52,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "went from bird to like other stuff? Uh",
      "offset": 307.6,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "you you've done a lot of embeddings",
      "offset": 310.4,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "work.\n I mean you're always heads down",
      "offset": 311.919,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "working on a problem. So I don't think",
      "offset": 314.16,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "most people in academia are the type to",
      "offset": 316.24,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "say oh look at this new product that",
      "offset": 319.52,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "came out. I'm going to abandon",
      "offset": 322,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "everything I'm doing. That can be the",
      "offset": 323.6,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "right move, you know.\n Oh, it definitely",
      "offset": 325.52,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "can. Honestly, if if if I were to give",
      "offset": 327.44,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "advice to a younger grad student, I",
      "offset": 330.8,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "think the way to do it would be",
      "offset": 333.44,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "literally just like sit and wait until",
      "offset": 335.52,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "the next kind of paradigm shift and then",
      "offset": 338.24,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "just immediately start working as fast",
      "offset": 340.24,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "as you can to like reimplement it. Like",
      "offset": 341.84,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "I I don't think that's like maybe the",
      "offset": 344.24,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "best way to do science, but it's",
      "offset": 346,
      "duration": 2.72
    },
    {
      "lang": "en",
      "text": "probably the best way to play the sort",
      "offset": 347.36,
      "duration": 3.679
    },
    {
      "lang": "en",
      "text": "of academic game in the in the days of",
      "offset": 348.72,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "AI. Like you've seen that so many times",
      "offset": 351.039,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "most recently probably with the",
      "offset": 353.6,
      "duration": 4.879
    },
    {
      "lang": "en",
      "text": "reasoning models like 01 came out of",
      "offset": 355.44,
      "duration": 6.96
    },
    {
      "lang": "en",
      "text": "open AI September 2024 last year and",
      "offset": 358.479,
      "duration": 5.761
    },
    {
      "lang": "en",
      "text": "then there's just been this explosion of",
      "offset": 362.4,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "like you build like abstraction ladders",
      "offset": 364.24,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "on top of that like first it was",
      "offset": 366.8,
      "duration": 3.519
    },
    {
      "lang": "en",
      "text": "reimplementation like how do we even do",
      "offset": 368.72,
      "duration": 3.599
    },
    {
      "lang": "en",
      "text": "this and now it's like a lot about the",
      "offset": 370.319,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "data what's the right data what are the",
      "offset": 372.319,
      "duration": 3.201
    },
    {
      "lang": "en",
      "text": "right evals what are the right training",
      "offset": 373.919,
      "duration": 3.041
    },
    {
      "lang": "en",
      "text": "schemes like there are so many different",
      "offset": 375.52,
      "duration": 4.959
    },
    {
      "lang": "en",
      "text": "axes you can test and publish research",
      "offset": 376.96,
      "duration": 6.16
    },
    {
      "lang": "en",
      "text": "in And like I think the easiest way to",
      "offset": 380.479,
      "duration": 4.641
    },
    {
      "lang": "en",
      "text": "do that probably is just work in a field",
      "offset": 383.12,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "like that that like has it only existed",
      "offset": 385.12,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "for less than one year and so no one has",
      "offset": 387.12,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "any like big advantage. I guess\n that is",
      "offset": 389.84,
      "duration": 4.479
    },
    {
      "lang": "en",
      "text": "mostly correct. I think anyone who",
      "offset": 392.56,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "jumped on reasoning in RL for Labs is",
      "offset": 394.319,
      "duration": 4.801
    },
    {
      "lang": "en",
      "text": "doing super well. I just saw this",
      "offset": 396.88,
      "duration": 5.92
    },
    {
      "lang": "en",
      "text": "morning that one of the recent Stanford",
      "offset": 399.12,
      "duration": 7.28
    },
    {
      "lang": "en",
      "text": "grad students who worked on RL, they",
      "offset": 402.8,
      "duration": 5.519
    },
    {
      "lang": "en",
      "text": "just started their company and they're",
      "offset": 406.4,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "worth 500 million. It's like absolutely",
      "offset": 408.319,
      "duration": 4.801
    },
    {
      "lang": "en",
      "text": "bonkers right now. Like just like no",
      "offset": 410.72,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "product, just three dudes, you know,",
      "offset": 413.12,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "sitting in some basement somewhere. I",
      "offset": 415.12,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "mean, undoubtedly cracked, but like also",
      "offset": 417.36,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "not worth 500.\n Yeah. But maybe it's not",
      "offset": 419.68,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "paying for the product, right? It's like",
      "offset": 422.4,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "the the ideas behind it or the Yeah.",
      "offset": 424.08,
      "duration": 5.92
    },
    {
      "lang": "en",
      "text": "Yeah. There was this big shift from in",
      "offset": 426.88,
      "duration": 5.599
    },
    {
      "lang": "en",
      "text": "scale of working with 100 million",
      "offset": 430,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "parameter models. Really what happened",
      "offset": 432.479,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "is like I think the companies invested a",
      "offset": 434.319,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "ton more into training and infra and",
      "offset": 436.16,
      "duration": 5.039
    },
    {
      "lang": "en",
      "text": "like we all kind of had to catch up like",
      "offset": 438.639,
      "duration": 4.641
    },
    {
      "lang": "en",
      "text": "you know me I go to Cornell work with a",
      "offset": 441.199,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "professor there he has to buy GPUs like",
      "offset": 443.28,
      "duration": 4.479
    },
    {
      "lang": "en",
      "text": "should he buy last year's GPUs or this",
      "offset": 445.759,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "year's GPUs how many should he get that",
      "offset": 447.759,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "we were kind of like trying to figure",
      "offset": 450.08,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "that out and there was there was like a",
      "offset": 451.44,
      "duration": 5.199
    },
    {
      "lang": "en",
      "text": "big lag I think where basically the the",
      "offset": 453.28,
      "duration": 5.919
    },
    {
      "lang": "en",
      "text": "seven and 8 billion parameter scale like",
      "offset": 456.639,
      "duration": 5.521
    },
    {
      "lang": "en",
      "text": "there's a huge difference between the",
      "offset": 459.199,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "birds size models which are 125 million",
      "offset": 462.16,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "parameters to to 200\n and then like the 8",
      "offset": 464.479,
      "duration": 4.241
    },
    {
      "lang": "en",
      "text": "billion parameters. I mean obviously",
      "offset": 467.52,
      "duration": 2.959
    },
    {
      "lang": "en",
      "text": "it's two orders of magnitude but just",
      "offset": 468.72,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "like this idea of emergence like if",
      "offset": 470.479,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "you're talking to a model that's 100",
      "offset": 473.44,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "million parameters no matter how well",
      "offset": 475.599,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "it's trained it knows nothing like if",
      "offset": 477.12,
      "duration": 4.479
    },
    {
      "lang": "en",
      "text": "you ask it like what's the capital of a",
      "offset": 479.28,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "state or like if you ask it who's who",
      "offset": 481.599,
      "duration": 4.481
    },
    {
      "lang": "en",
      "text": "was president of the United States in",
      "offset": 483.599,
      "duration": 5.521
    },
    {
      "lang": "en",
      "text": "1990 or whatever it'll just always say",
      "offset": 486.08,
      "duration": 4.559
    },
    {
      "lang": "en",
      "text": "George Washington because it just",
      "offset": 489.12,
      "duration": 2.96
    },
    {
      "lang": "en",
      "text": "associates the words like president",
      "offset": 490.639,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "United States with George Washington and",
      "offset": 492.08,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "then when you get to the 8 billion",
      "offset": 494.319,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "parameter scale suddenly it knows every",
      "offset": 497.52,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "single president. It knows every single",
      "offset": 499.039,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "capital of every single country. And I",
      "offset": 500.96,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "really do think that changes the type of",
      "offset": 503.12,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "research you can do. And so like it took",
      "offset": 504.96,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "us a while I think in academia to catch",
      "offset": 507.039,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "up like getting good 7 billion parameter",
      "offset": 508.879,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "models and then running them and getting",
      "offset": 511.599,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "GPUs to run them. Now I think things",
      "offset": 513.599,
      "duration": 3.521
    },
    {
      "lang": "en",
      "text": "have stabilized a lot like we have",
      "offset": 515.279,
      "duration": 3.281
    },
    {
      "lang": "en",
      "text": "access to compute and we can kind of",
      "offset": 517.12,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "like fine-tune and inference that scale",
      "offset": 518.56,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "of models and that's like kind of fine",
      "offset": 521.12,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "but there was like kind of two years",
      "offset": 523.36,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "where everyone in academia was working",
      "offset": 525.12,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "on like smaller models and none of it",
      "offset": 526.48,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "really mattered. I can sort of branch",
      "offset": 528.56,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "that discussion in two ways and we",
      "offset": 530.48,
      "duration": 2.88
    },
    {
      "lang": "en",
      "text": "should we should sort of go to your",
      "offset": 532,
      "duration": 2.959
    },
    {
      "lang": "en",
      "text": "research at some point but I'm enjoying",
      "offset": 533.36,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "this because I think like we don't get",
      "offset": 534.959,
      "duration": 2.961
    },
    {
      "lang": "en",
      "text": "to talk about this on the podcast too",
      "offset": 536.64,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "often. One is there there's there is an",
      "offset": 537.92,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "often there's an often bit of advice",
      "offset": 540.16,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "from the industry people to to grad",
      "offset": 541.68,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "students which is give up don't work on",
      "offset": 543.2,
      "duration": 4.639
    },
    {
      "lang": "en",
      "text": "models just do benchmarks right like a",
      "offset": 545.68,
      "duration": 3.599
    },
    {
      "lang": "en",
      "text": "really good benchmarks will will get our",
      "offset": 547.839,
      "duration": 2.721
    },
    {
      "lang": "en",
      "text": "attention and then we'll hire you and",
      "offset": 549.279,
      "duration": 2.881
    },
    {
      "lang": "en",
      "text": "then you can switch to models later you",
      "offset": 550.56,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "have for better or worse avoided that",
      "offset": 552.16,
      "duration": 4.239
    },
    {
      "lang": "en",
      "text": "which is cool and we can talk about that",
      "offset": 554.24,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "as well but the other thing I think is",
      "offset": 556.399,
      "duration": 6.481
    },
    {
      "lang": "en",
      "text": "that around about 7 8b maybe 4B is when",
      "offset": 558.64,
      "duration": 6.16
    },
    {
      "lang": "en",
      "text": "you start switching from like a single",
      "offset": 562.88,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "GPU setup to like a distributed setup",
      "offset": 564.8,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "and And I'm wondering like do grad",
      "offset": 567.92,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "students get HPC training? How much do",
      "offset": 570,
      "duration": 5.519
    },
    {
      "lang": "en",
      "text": "they teach you of like just how to work",
      "offset": 572.72,
      "duration": 5.84
    },
    {
      "lang": "en",
      "text": "with like large clusters of stuff?\n Oh,",
      "offset": 575.519,
      "duration": 4.481
    },
    {
      "lang": "en",
      "text": "to be clear, they don't teach you",
      "offset": 578.56,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "anything like anything. Like if you see",
      "offset": 580,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "a paper coming out from even, you know,",
      "offset": 582.24,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "Stanford, they're probably the best",
      "offset": 584.72,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "school in AI if you had to choose. And",
      "offset": 586.8,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "it's not like they're learning how to do",
      "offset": 589.76,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "like multi-node distributed FSTP",
      "offset": 591.44,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "training like with whatever deep speed.",
      "offset": 593.839,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "You have to learn that from the internet",
      "offset": 596.56,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "and from other people and like there's",
      "offset": 597.92,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "no classes that really do that. I mean",
      "offset": 600.72,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "it's that's hard to facilitate like as",
      "offset": 603.04,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "one person. I would say most grad",
      "offset": 606.08,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "students are doing stuff on single GPU.",
      "offset": 608.48,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "Some people are doing multi-GPU",
      "offset": 611.68,
      "duration": 5.599
    },
    {
      "lang": "en",
      "text": "training. There's probably basically no",
      "offset": 613.76,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "grad students doing multi-node training.",
      "offset": 617.279,
      "duration": 3.361
    },
    {
      "lang": "en",
      "text": "I mean there's probably a few especially",
      "offset": 619.12,
      "duration": 3.279
    },
    {
      "lang": "en",
      "text": "if they have like company affiliations",
      "offset": 620.64,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "but that's really unusual I think.\n Okay.",
      "offset": 622.399,
      "duration": 4.801
    },
    {
      "lang": "en",
      "text": "For grad students who are looking to get",
      "offset": 625.36,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "up to speed on that, I would recommend",
      "offset": 627.2,
      "duration": 3.759
    },
    {
      "lang": "en",
      "text": "the GPU mode Discord where basically the",
      "offset": 628.72,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "PyTorch team is hanging out in there",
      "offset": 630.959,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "just waiting to help you. And then the",
      "offset": 632.48,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "other one would be the fast AI team. If",
      "offset": 634.64,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "you have some kind of thing, Jeremy",
      "offset": 636.48,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "Howard will basically help you out and",
      "offset": 638.8,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "uh they they have some uh distributed",
      "offset": 641.12,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "training. Honestly, try to reach out to",
      "offset": 642.72,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "the deep speed team at Microsoft. Like",
      "offset": 644.72,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "actually they're reasonably accessible.",
      "offset": 646.72,
      "duration": 4.559
    },
    {
      "lang": "en",
      "text": "Nobody talks to them. Like it's so so",
      "offset": 649.04,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "funny. I I like met them at Europs and",
      "offset": 651.279,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "like they had nobody at their like they",
      "offset": 653.2,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "was presenting these speech three I was",
      "offset": 654.88,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "the only one asking questions like\n um",
      "offset": 656.48,
      "duration": 5.84
    },
    {
      "lang": "en",
      "text": "yeah\n yeah that's good that's good advice",
      "offset": 659.6,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "listen to this guy\n yeah I mean just",
      "offset": 662.32,
      "duration": 3.759
    },
    {
      "lang": "en",
      "text": "basically like the people are there if",
      "offset": 664.16,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "you want to ask this is very very",
      "offset": 666.079,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "valuable experience once you're like a",
      "offset": 668.079,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "GPU god like you're basically you know",
      "offset": 670,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "in a like a different tier as a",
      "offset": 672.16,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "researcher because you don't rely on",
      "offset": 673.68,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "someone else helping you out like you",
      "offset": 675.6,
      "duration": 3.679
    },
    {
      "lang": "en",
      "text": "can just sort of be your own research",
      "offset": 677.12,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "engineer you know\n yeah I'll comment on",
      "offset": 679.279,
      "duration": 5.281
    },
    {
      "lang": "en",
      "text": "that quickly because if someone has been",
      "offset": 681.519,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "listening to this and also following me",
      "offset": 684.56,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "online for a while, I think I've made a",
      "offset": 686.399,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "couple comments like saying something",
      "offset": 688,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "like you shouldn't learn about CUDA or",
      "offset": 689.839,
      "duration": 5.521
    },
    {
      "lang": "en",
      "text": "things to that nature. And I'll I'll",
      "offset": 692.399,
      "duration": 5.361
    },
    {
      "lang": "en",
      "text": "give some more color to that. So, it's",
      "offset": 695.36,
      "duration": 4.719
    },
    {
      "lang": "en",
      "text": "definitely a great idea to learn CUDA if",
      "offset": 697.76,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "you can. I think my point was that if",
      "offset": 700.079,
      "duration": 4.481
    },
    {
      "lang": "en",
      "text": "you're trying to enter this space like",
      "offset": 702.72,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "learn about the models, learn about how",
      "offset": 704.56,
      "duration": 3.519
    },
    {
      "lang": "en",
      "text": "they're trained, what the data looks",
      "offset": 706.8,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "like, what the compute looks like, one",
      "offset": 708.079,
      "duration": 5.521
    },
    {
      "lang": "en",
      "text": "axis of that is how to do more efficient",
      "offset": 710.24,
      "duration": 6.64
    },
    {
      "lang": "en",
      "text": "training and inference and one part of",
      "offset": 713.6,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "doing more efficient training and",
      "offset": 716.88,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "inference is studying the hardware which",
      "offset": 718.8,
      "duration": 6.4
    },
    {
      "lang": "en",
      "text": "is GPUs. So, like I think that's a very",
      "offset": 722.32,
      "duration": 4.959
    },
    {
      "lang": "en",
      "text": "small subset of all possible knowledge",
      "offset": 725.2,
      "duration": 4.639
    },
    {
      "lang": "en",
      "text": "that you could acquire and it's probably",
      "offset": 727.279,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "not the best place for a lot of people",
      "offset": 729.839,
      "duration": 5.041
    },
    {
      "lang": "en",
      "text": "to start. That said, if you do it, you",
      "offset": 732.079,
      "duration": 4.241
    },
    {
      "lang": "en",
      "text": "you've got to be one of the most hirable",
      "offset": 734.88,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "people in the world. Like, if you like",
      "offset": 736.32,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "really deeply understand the",
      "offset": 738.8,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "architecture of the new GPUs coming out",
      "offset": 741.12,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "and and how to control it, you're in a",
      "offset": 743.2,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "very small handful of people and like",
      "offset": 745.76,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "everyone will want to hire you.",
      "offset": 747.92,
      "duration": 3.039
    },
    {
      "lang": "en",
      "text": "Actually, the sweet spot is not even",
      "offset": 749.6,
      "duration": 3.359
    },
    {
      "lang": "en",
      "text": "CUDA right now. I would say actually it",
      "offset": 750.959,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "is Mojo. I don't know if you've been",
      "offset": 752.959,
      "duration": 4.961
    },
    {
      "lang": "en",
      "text": "paying attention to\n modular mojo.\n Oh, I",
      "offset": 754.88,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "listened to your podcast, man. You had",
      "offset": 757.92,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "that guy on uh the other day.\n The whole",
      "offset": 759.36,
      "duration": 6.4
    },
    {
      "lang": "en",
      "text": "story is Chris Lanner, industry legend,",
      "offset": 762.079,
      "duration": 7.041
    },
    {
      "lang": "en",
      "text": "LLVM, Swift, all these things. And now",
      "offset": 765.76,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "he's turned his attention to the Python",
      "offset": 769.12,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "CUDA relationship, right? And he wants",
      "offset": 771.2,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "to basically create a viable CUDA",
      "offset": 772.959,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "replacement. It's basically Python",
      "offset": 775.92,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "married with Rust. for the last two and",
      "offset": 777.839,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "a half years. He was basically kind of",
      "offset": 780,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "stealth, not ready for production. When",
      "offset": 781.519,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "he came on our podcast, he was basically",
      "offset": 783.6,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "announcing to the world like we're open",
      "offset": 784.959,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "for business like you can use us now for",
      "offset": 787.12,
      "duration": 3.519
    },
    {
      "lang": "en",
      "text": "for most models and like we actually are",
      "offset": 788.639,
      "duration": 4.481
    },
    {
      "lang": "en",
      "text": "faster than like the native like uh",
      "offset": 790.639,
      "duration": 4.241
    },
    {
      "lang": "en",
      "text": "sometimes the PTX implementation. I",
      "offset": 793.12,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "don't know how that works precisely, but",
      "offset": 794.88,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "he's a compiler language got. I think",
      "offset": 796.48,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "there's a nar there's one of those",
      "offset": 798.8,
      "duration": 2.96
    },
    {
      "lang": "en",
      "text": "windows now like like you said like you",
      "offset": 800.16,
      "duration": 2.799
    },
    {
      "lang": "en",
      "text": "know bet early on something that's there",
      "offset": 801.76,
      "duration": 2.8
    },
    {
      "lang": "en",
      "text": "that's there's a shift. It's one of",
      "offset": 802.959,
      "duration": 2.961
    },
    {
      "lang": "en",
      "text": "those windows now where you try to",
      "offset": 804.56,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "implement things. You basically like,",
      "offset": 805.92,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "you know, modular is 100 people. If you",
      "offset": 808.16,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "run into issues, you'll get Chris's",
      "offset": 810.24,
      "duration": 3.279
    },
    {
      "lang": "en",
      "text": "personal help on things. Like I'm not",
      "offset": 811.68,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "promising it, but like probably, you",
      "offset": 813.519,
      "duration": 3.361
    },
    {
      "lang": "en",
      "text": "know, like cuz he wants to work on",
      "offset": 815.44,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "improving the toolkit. And um all you",
      "offset": 816.88,
      "duration": 4.639
    },
    {
      "lang": "en",
      "text": "have to do is just like it's not really",
      "offset": 819.519,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "about becoming a CUDA god because",
      "offset": 821.519,
      "duration": 3.201
    },
    {
      "lang": "en",
      "text": "obviously like once you ramp up on on",
      "offset": 823.2,
      "duration": 3.199
    },
    {
      "lang": "en",
      "text": "the the general concepts and principles,",
      "offset": 824.72,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "you can probably translate ecosystems",
      "offset": 826.399,
      "duration": 4.481
    },
    {
      "lang": "en",
      "text": "pretty effectively. A lot of people",
      "offset": 828.48,
      "duration": 4.799
    },
    {
      "lang": "en",
      "text": "switch from like jacks to to CUDA, but",
      "offset": 830.88,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "like the the thing is just like being",
      "offset": 833.279,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "able to experiment very quickly on a",
      "offset": 835.04,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "limited budget. Like efficiency is not",
      "offset": 837.279,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "just because you are trying to be an",
      "offset": 839.04,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "efficiency guru and that's your career",
      "offset": 841.839,
      "duration": 3.281
    },
    {
      "lang": "en",
      "text": "and that's kind of boring.\n But it's",
      "offset": 843.36,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "really also just about being able to",
      "offset": 845.12,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "experiment very quickly uh and finding",
      "offset": 846.72,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "these these ideas. I also think uh VLM",
      "offset": 848.72,
      "duration": 6.4
    },
    {
      "lang": "en",
      "text": "and SG lang seem like really good and",
      "offset": 852.16,
      "duration": 5.679
    },
    {
      "lang": "en",
      "text": "important and here to stay. Like they'll",
      "offset": 855.12,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "probably just get larger and more",
      "offset": 857.839,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "complex to accommodate future systems.",
      "offset": 860.8,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "But if I were like a starting out grad",
      "offset": 863.519,
      "duration": 4.801
    },
    {
      "lang": "en",
      "text": "student, I and working in that area, I'd",
      "offset": 866.16,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "probably like want to learn more about",
      "offset": 868.32,
      "duration": 4.959
    },
    {
      "lang": "en",
      "text": "how they work. Awesome. Let's go to your",
      "offset": 870.72,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "research. I like to mention that I I",
      "offset": 873.279,
      "duration": 4.961
    },
    {
      "lang": "en",
      "text": "first came across you because of CDE the",
      "offset": 875.44,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "contextual document embiddings paper.",
      "offset": 878.24,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "You can uh tell me the story about that",
      "offset": 879.839,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "but I just want to show you proof that",
      "offset": 881.76,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "you know I get one slot per day to",
      "offset": 884.079,
      "duration": 5.041
    },
    {
      "lang": "en",
      "text": "highlight the number one AI story and",
      "offset": 886.32,
      "duration": 4.879
    },
    {
      "lang": "en",
      "text": "you were the slot of the day for October",
      "offset": 889.12,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "5th.\n Oh no way.\n I mean obviously you",
      "offset": 891.199,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "were producing work before that but like",
      "offset": 893.36,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "I thought CDE was a really cool",
      "offset": 895.519,
      "duration": 4.961
    },
    {
      "lang": "en",
      "text": "exploration of like oh yeah you know",
      "offset": 898.16,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "embedding models are kind of like stuck",
      "offset": 900.48,
      "duration": 2.88
    },
    {
      "lang": "en",
      "text": "in a rut. like here's actually how to",
      "offset": 902.079,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "make them very efficient by just doing",
      "offset": 903.36,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "it in two stages. That seems like a you",
      "offset": 905.279,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "know relatively simple insight that was",
      "offset": 908,
      "duration": 4.639
    },
    {
      "lang": "en",
      "text": "done very well. But you have a general",
      "offset": 910.399,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "maybe information theory thing that",
      "offset": 912.639,
      "duration": 2.721
    },
    {
      "lang": "en",
      "text": "maybe we should start with and then we",
      "offset": 914.24,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "can sort of grad our way.\n Yeah, sure.",
      "offset": 915.36,
      "duration": 4.719
    },
    {
      "lang": "en",
      "text": "That sounds good. So we can we can",
      "offset": 918.48,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "circle back on that. That's that's",
      "offset": 920.079,
      "duration": 4.641
    },
    {
      "lang": "en",
      "text": "really cool that you uh wrote about it.",
      "offset": 922.32,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "What was that almost coming up on two",
      "offset": 924.72,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "years ago? Yeah, this is the post I",
      "offset": 926.639,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "wrote. I I called it a new type of",
      "offset": 928.8,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "information theory. We don't need to go",
      "offset": 930.56,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "into this. There there's this paper",
      "offset": 934.16,
      "duration": 4.479
    },
    {
      "lang": "en",
      "text": "about a concept called the information.",
      "offset": 935.6,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "Maybe I'll give like the most simple",
      "offset": 938.639,
      "duration": 3.361
    },
    {
      "lang": "en",
      "text": "explanation which is if you say you have",
      "offset": 940,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "two text files. One text file contains a",
      "offset": 942,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "paragraph of information about New York",
      "offset": 945.76,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "City and then the other text file",
      "offset": 947.44,
      "duration": 5.519
    },
    {
      "lang": "en",
      "text": "contains the same text but encrypted",
      "offset": 949.839,
      "duration": 6.161
    },
    {
      "lang": "en",
      "text": "with like Shaw whatever encryption",
      "offset": 952.959,
      "duration": 6.721
    },
    {
      "lang": "en",
      "text": "algorithm. So it looks like random",
      "offset": 956,
      "duration": 6.399
    },
    {
      "lang": "en",
      "text": "letters, but if you decrypt it, it has",
      "offset": 959.68,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "the same text as the first text file.",
      "offset": 962.399,
      "duration": 5.841
    },
    {
      "lang": "en",
      "text": "From the perspective of like Shannon's",
      "offset": 964.8,
      "duration": 6.8
    },
    {
      "lang": "en",
      "text": "information theory, these two files",
      "offset": 968.24,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "contain the same information content.",
      "offset": 971.6,
      "duration": 4.799
    },
    {
      "lang": "en",
      "text": "like relative to everything they have",
      "offset": 974.24,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "the same number of bits but it's it's",
      "offset": 976.399,
      "duration": 5.041
    },
    {
      "lang": "en",
      "text": "very clear to the observer that the",
      "offset": 978.56,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "first text file which is plain English",
      "offset": 981.44,
      "duration": 5.199
    },
    {
      "lang": "en",
      "text": "text is like much easier to read and",
      "offset": 983.44,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "easier to process even though they have",
      "offset": 986.639,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "the same information and so there's this",
      "offset": 988.32,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "theoretical framework proposed in this",
      "offset": 990.639,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "paper which is a theory of usable",
      "offset": 992.32,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "information under computational",
      "offset": 994.32,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "constraints from 2020 it really doesn't",
      "offset": 996.16,
      "duration": 5.119
    },
    {
      "lang": "en",
      "text": "have that much rest there not aren't as",
      "offset": 998.8,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "many citations as you would think but I",
      "offset": 1001.279,
      "duration": 3.441
    },
    {
      "lang": "en",
      "text": "think it's a really really neat idea.",
      "offset": 1003.12,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "It's like we should measure information",
      "offset": 1004.72,
      "duration": 5.119
    },
    {
      "lang": "en",
      "text": "with computational",
      "offset": 1007.279,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "power as a constraint. So like they have",
      "offset": 1009.839,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "this idea they call V information of how",
      "offset": 1012.079,
      "duration": 4.961
    },
    {
      "lang": "en",
      "text": "much information is extractable from a",
      "offset": 1014.24,
      "duration": 6.159
    },
    {
      "lang": "en",
      "text": "given like file or or code. So in that",
      "offset": 1017.04,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "case we could say the left text file",
      "offset": 1020.399,
      "duration": 3.281
    },
    {
      "lang": "en",
      "text": "actually has more extractable",
      "offset": 1022.16,
      "duration": 3.759
    },
    {
      "lang": "en",
      "text": "information than the the right text",
      "offset": 1023.68,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "file. I think that's like really good.",
      "offset": 1025.919,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "That captures a lot of our ideas of how",
      "offset": 1028.16,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "these deep learning systems work. Like",
      "offset": 1030.959,
      "duration": 3.201
    },
    {
      "lang": "en",
      "text": "why does pre-training work? Like if you",
      "offset": 1032.64,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "have two sets of weights and you you",
      "offset": 1034.16,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "want to train on some downstream data",
      "offset": 1037.039,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "set, one set of weights is pre-trained,",
      "offset": 1038.72,
      "duration": 3.199
    },
    {
      "lang": "en",
      "text": "one set of weights is randomly",
      "offset": 1040.64,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "initialized. Why is the pre-trained",
      "offset": 1041.919,
      "duration": 5.361
    },
    {
      "lang": "en",
      "text": "model better at all even though it's",
      "offset": 1044.559,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "never seen your data? Maybe one way of",
      "offset": 1047.28,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "looking at that is that it has like it",
      "offset": 1049.679,
      "duration": 3.281
    },
    {
      "lang": "en",
      "text": "makes the information like more",
      "offset": 1051.76,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "extractable somehow. Like there's this",
      "offset": 1052.96,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "concept of like computational",
      "offset": 1055.679,
      "duration": 4.641
    },
    {
      "lang": "en",
      "text": "processing that you can almost like",
      "offset": 1058.96,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "store up. I like this as a just like a",
      "offset": 1060.32,
      "duration": 6.719
    },
    {
      "lang": "en",
      "text": "lens to view problems with like how much",
      "offset": 1063.44,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "information is stored where. Like if you",
      "offset": 1067.039,
      "duration": 4.561
    },
    {
      "lang": "en",
      "text": "if you get a a set of model weights or",
      "offset": 1068.88,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "like an activation vector and you open",
      "offset": 1071.6,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "it up like print some tensor numpy",
      "offset": 1073.6,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "array, it looks like random numbers,",
      "offset": 1077.2,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "right? Like there's nothing human",
      "offset": 1079.12,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "intelligible about that. But really it's",
      "offset": 1080.96,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "this complex combination of like the",
      "offset": 1083.28,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "training data and the training algorithm",
      "offset": 1086.08,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "which get compressed into model weights",
      "offset": 1087.76,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "and then the actual computation that the",
      "offset": 1090.32,
      "duration": 3.599
    },
    {
      "lang": "en",
      "text": "model is doing which involves like",
      "offset": 1092.32,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "manipulating these numbers in ways that",
      "offset": 1093.919,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "we don't understand. So it's like this",
      "offset": 1095.6,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "really highly compressed nonlinear",
      "offset": 1097.76,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "combination of all these information",
      "offset": 1101.6,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "sources mixed with like computation and",
      "offset": 1103.44,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "I just think we don't have like the",
      "offset": 1106.48,
      "duration": 3.439
    },
    {
      "lang": "en",
      "text": "right words of of discussing this. I",
      "offset": 1107.84,
      "duration": 4.959
    },
    {
      "lang": "en",
      "text": "think I like the information theory",
      "offset": 1109.919,
      "duration": 5.521
    },
    {
      "lang": "en",
      "text": "analogy because back in the day, you",
      "offset": 1112.799,
      "duration": 4.961
    },
    {
      "lang": "en",
      "text": "know, we had phones and like telegraphs",
      "offset": 1115.44,
      "duration": 4.479
    },
    {
      "lang": "en",
      "text": "and and people were just sort of like",
      "offset": 1117.76,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "building the phone system with these",
      "offset": 1119.919,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "crazy horistics to like send information",
      "offset": 1121.44,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "across the country or send telegraphs",
      "offset": 1123.679,
      "duration": 5.441
    },
    {
      "lang": "en",
      "text": "across the Atlantic. People were just",
      "offset": 1126.24,
      "duration": 6.72
    },
    {
      "lang": "en",
      "text": "like trying stuff and then uh we kind of",
      "offset": 1129.12,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "found stuff that worked and we we ran",
      "offset": 1132.96,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "with it, but it wasn't really optimal.",
      "offset": 1134.64,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "And it wasn't until someone came along",
      "offset": 1136.88,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "and proposed this concept of like a bit",
      "offset": 1139.039,
      "duration": 4.721
    },
    {
      "lang": "en",
      "text": "like a one or a zero that tells you",
      "offset": 1141.2,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "something. And once we have a bit, we",
      "offset": 1143.76,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "can do all these things. We can like",
      "offset": 1145.52,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "count the amount of information a",
      "offset": 1147.44,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "signal. We can do really good error",
      "offset": 1148.96,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "correction. We can measure properties of",
      "offset": 1151.6,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "distributions of things and and we can",
      "offset": 1154.24,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "build like a really good system for for",
      "offset": 1156.4,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "phones and then eventually which led to",
      "offset": 1158.24,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "computers. I'm bringing this all up",
      "offset": 1160.08,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "because I don't think we have I don't",
      "offset": 1162,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "think we know what a bit is yet in terms",
      "offset": 1163.44,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "of like deep learning models. I'm going",
      "offset": 1165.36,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "to graduate for my PhD this year, but I",
      "offset": 1167.44,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "didn't figure it out. So, if you're",
      "offset": 1169.44,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "listening to this, maybe you can like, I",
      "offset": 1171.36,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "don't know, spend more time on it or",
      "offset": 1173.76,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "you're smarter than me or you have a,",
      "offset": 1175.679,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "you know, group of collaborators, you",
      "offset": 1178.32,
      "duration": 3.359
    },
    {
      "lang": "en",
      "text": "can all get together and figure out what",
      "offset": 1179.84,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "the right lens to look at this stuff is.",
      "offset": 1181.679,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "But even by just asking these questions,",
      "offset": 1183.919,
      "duration": 5.041
    },
    {
      "lang": "en",
      "text": "I think I was able to conduct this",
      "offset": 1185.679,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "research agenda that I'm kind of still",
      "offset": 1188.96,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "working on actually.\n Yeah. Uh what do",
      "offset": 1191.039,
      "duration": 6.401
    },
    {
      "lang": "en",
      "text": "you call this field?",
      "offset": 1194.24,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "I don't know. I don't know. I called the",
      "offset": 1197.44,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "post a new type of information theory. I",
      "offset": 1199.44,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "I don't think it exists yet, I guess. So",
      "offset": 1202.24,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "maybe it'll it'll get a name once uh",
      "offset": 1204.08,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "someone actually comes up with the right",
      "offset": 1206.4,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "set of definitions. I think V",
      "offset": 1208.24,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "information is a is a really good start.",
      "offset": 1210.08,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "There's a couple related threads. Uh so",
      "offset": 1212.24,
      "duration": 3.439
    },
    {
      "lang": "en",
      "text": "first of all, you don't know this, but I",
      "offset": 1214.16,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "actually have been trying to accumulate",
      "offset": 1215.679,
      "duration": 5.521
    },
    {
      "lang": "en",
      "text": "uh data about Shannon like this like a",
      "offset": 1217.84,
      "duration": 4.959
    },
    {
      "lang": "en",
      "text": "Shannon information theory view of",
      "offset": 1221.2,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "language models. I have a lot of notes.",
      "offset": 1222.799,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "This is actually on my GitHub for people",
      "offset": 1225.039,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "who are watching along. But um you know",
      "offset": 1226.4,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "like at the limit if a language model",
      "offset": 1228.88,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "has 175 billion parameters using 16 bit",
      "offset": 1231.2,
      "duration": 5.839
    },
    {
      "lang": "en",
      "text": "you can it will take up 350 GB. You can",
      "offset": 1234.4,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "compare that to Wikipedia. Wikipedia is",
      "offset": 1237.039,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "about 150 GB. you know, let's say GPC3",
      "offset": 1238.72,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "can store two Wikipedias, but like is is",
      "offset": 1241.2,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "that a relevant measure of information",
      "offset": 1243.6,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "storage, right? It is not because you",
      "offset": 1247.2,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "can compress Wikipedia a lot. There's a",
      "offset": 1249.28,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "lot of repeated patterns. tokenization",
      "offset": 1251.039,
      "duration": 4.481
    },
    {
      "lang": "en",
      "text": "is is like the first form of",
      "offset": 1254,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "compression. But I think there's a",
      "offset": 1255.52,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "there's a related talk from Ilia",
      "offset": 1257.12,
      "duration": 7.36
    },
    {
      "lang": "en",
      "text": "Sutsgiver about how deep learning is",
      "offset": 1259.76,
      "duration": 6.56
    },
    {
      "lang": "en",
      "text": "machine learning kind of is is is",
      "offset": 1264.48,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "compression like it you have a data set",
      "offset": 1266.32,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "you compress it into a model that is",
      "offset": 1268.32,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "smaller than a data set but generalizes",
      "offset": 1270.4,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "and like uh has like you know some some",
      "offset": 1272.24,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "amount of acceptable loss. I think that",
      "offset": 1274.48,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "one of your commenters on on the on the",
      "offset": 1276.64,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "post made this direct comparison with",
      "offset": 1278.4,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "complexity which is what Ilia how Ilia",
      "offset": 1281.28,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "sees it. So I think like people have",
      "offset": 1283.6,
      "duration": 4.559
    },
    {
      "lang": "en",
      "text": "this information theory idea or approach",
      "offset": 1285.52,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "to language models. It is just not",
      "offset": 1288.159,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "precise because exactly what you say",
      "offset": 1290.32,
      "duration": 3.359
    },
    {
      "lang": "en",
      "text": "like it's we don't know what a bit",
      "offset": 1292.08,
      "duration": 2.959
    },
    {
      "lang": "en",
      "text": "really means. We don't know what like",
      "offset": 1293.679,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "the most legible legibility is is a word",
      "offset": 1295.039,
      "duration": 5.041
    },
    {
      "lang": "en",
      "text": "that comes to mind in terms of like like",
      "offset": 1297.84,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "it matters to us that it's human",
      "offset": 1300.08,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "readable like even if it's SH one SH 256",
      "offset": 1301.28,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "I don't care but like that is less",
      "offset": 1303.76,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "readable and therefore there's more I",
      "offset": 1305.679,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "guess I don't know entropy is not the",
      "offset": 1308.64,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "word because it's it's directly",
      "offset": 1311.039,
      "duration": 5.681
    },
    {
      "lang": "en",
      "text": "convertible but it's just less useful.",
      "offset": 1313.039,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "Yeah. Yeah. Yeah. Useful is a good word.",
      "offset": 1316.72,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "I think maybe useful information or",
      "offset": 1318.799,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "usable information is is the right lens.",
      "offset": 1320.559,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "and Komagarov is a really interesting",
      "offset": 1322.72,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "connection like Komagarov complexity. I",
      "offset": 1324.559,
      "duration": 4.721
    },
    {
      "lang": "en",
      "text": "think that's a really good concept for",
      "offset": 1327.44,
      "duration": 4.239
    },
    {
      "lang": "en",
      "text": "for computer scientists. So I'm not sure",
      "offset": 1329.28,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "exactly about this specific talk or like",
      "offset": 1331.679,
      "duration": 5.841
    },
    {
      "lang": "en",
      "text": "what he was trying to say but I I think",
      "offset": 1334.64,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "that we have a very good understanding",
      "offset": 1337.52,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "of language model pre-training and",
      "offset": 1339.6,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "there's a deep connection between",
      "offset": 1341.84,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "language models and and compression.",
      "offset": 1343.679,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "Actually may maybe let's let's start",
      "offset": 1346.08,
      "duration": 2.959
    },
    {
      "lang": "en",
      "text": "with the embeddings. We can come back to",
      "offset": 1347.52,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "that.\n Okay. So, is this uh are we going",
      "offset": 1349.039,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "to the first paper?\n Actually, let's go",
      "offset": 1351.52,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "to your Wikipedia uh numbers if if you",
      "offset": 1353.2,
      "duration": 5.92
    },
    {
      "lang": "en",
      "text": "still have access to that. So, this 50",
      "offset": 1355.84,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "GB for text of Wikipedia, that sounds",
      "offset": 1359.12,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "like a pretty high to me. Is that that's",
      "offset": 1361.28,
      "duration": 4.639
    },
    {
      "lang": "en",
      "text": "uncompressed like text files?\n I don't",
      "offset": 1363.52,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "know. I grabbed it from Andrew Wang, so",
      "offset": 1365.919,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "I don't know.",
      "offset": 1368,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "Okay. Okay. No, no, I'm probably off. I",
      "offset": 1369.919,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "just sort of have the sense that like",
      "offset": 1372.4,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "when you store text, it's generally like",
      "offset": 1374.24,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "very very small, especially when you",
      "offset": 1376.48,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "zip. Maybe he's including all the",
      "offset": 1378.24,
      "duration": 3.439
    },
    {
      "lang": "en",
      "text": "languages, all the edits. I don't know.",
      "offset": 1379.76,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "Yeah. Yeah, that could make sense. That",
      "offset": 1381.679,
      "duration": 2.801
    },
    {
      "lang": "en",
      "text": "could make sense because I I guess what",
      "offset": 1382.88,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "you you say from, you know, if you want",
      "offset": 1384.48,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "to do apples to apples comparisons, GP3",
      "offset": 1386.96,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "can store two Wikipedias. Is that right?",
      "offset": 1389.84,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "2.3 Wikipedia something.\n So, I thought",
      "offset": 1392.4,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "it would be a lot more. And this is",
      "offset": 1395.52,
      "duration": 2.96
    },
    {
      "lang": "en",
      "text": "actually an experiment that you could",
      "offset": 1397.12,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "do. You could like just train a model on",
      "offset": 1398.48,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "Wikipedia and keep training it until you",
      "offset": 1401.84,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "can perfectly extract all of Wikipedia.",
      "offset": 1404,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "And that would be like a good way of",
      "offset": 1406.4,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "knowing like how many Wikipedias can GBT",
      "offset": 1407.84,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "store. I like I like that idea. But I",
      "offset": 1410.64,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "think this type of like back of the",
      "offset": 1413.28,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "envelope math is it's really useful for",
      "offset": 1414.88,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "thinking about problems and like",
      "offset": 1417.44,
      "duration": 3.119
    },
    {
      "lang": "en",
      "text": "grounding yourself in the real world",
      "offset": 1418.799,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "even if you can never quite answer the",
      "offset": 1420.559,
      "duration": 3.281
    },
    {
      "lang": "en",
      "text": "questions you want to answer at least",
      "offset": 1422.4,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "like in 4 years. If we think about",
      "offset": 1423.84,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "embeddings, you know, vectors that",
      "offset": 1426,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "people use for search, we can do the",
      "offset": 1427.6,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "exact same kind of math. So if you use",
      "offset": 1429.919,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "the OpenAI embeddings, which last time I",
      "offset": 1432.32,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "checked, I think have 1,536",
      "offset": 1435.039,
      "duration": 7.12
    },
    {
      "lang": "en",
      "text": "dimensions. So that if you say there's",
      "offset": 1437.76,
      "duration": 7.52
    },
    {
      "lang": "en",
      "text": "16 bits per dimension and like half",
      "offset": 1442.159,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "precision floating point, it's something",
      "offset": 1445.28,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "like 20 kilob of information in a",
      "offset": 1447.679,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "vector. And if you want to store 20",
      "offset": 1450.08,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "kilob of text, that's a lot of text,",
      "offset": 1451.919,
      "duration": 5.841
    },
    {
      "lang": "en",
      "text": "like many many paragraphs that you can",
      "offset": 1455.44,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "perfectly compress into 20 kilobytes.",
      "offset": 1457.76,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "And so I think this is kind of like the",
      "offset": 1460.08,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "idea we had. I'll give you the practical",
      "offset": 1461.84,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "explanation which was I'm well first of",
      "offset": 1464.159,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "all I'm a second year grad student. I'm",
      "offset": 1466.64,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "like going to these conferences seeing",
      "offset": 1468.32,
      "duration": 2.8
    },
    {
      "lang": "en",
      "text": "all these other things people working on",
      "offset": 1469.76,
      "duration": 3.039
    },
    {
      "lang": "en",
      "text": "and thinking you know like what the heck",
      "offset": 1471.12,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "like how am I going to like have my own",
      "offset": 1472.799,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "little area to do work in that no one",
      "offset": 1474.96,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "else is working in already. And so I",
      "offset": 1476.88,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "spent a lot of time coming up with bad",
      "offset": 1479.12,
      "duration": 5.039
    },
    {
      "lang": "en",
      "text": "ideas and my adviser would say no like",
      "offset": 1481.039,
      "duration": 6.161
    },
    {
      "lang": "en",
      "text": "that's not a good idea to work on. Many",
      "offset": 1484.159,
      "duration": 7.52
    },
    {
      "lang": "en",
      "text": "times this happened and like even my",
      "offset": 1487.2,
      "duration": 6.24
    },
    {
      "lang": "en",
      "text": "first year and a half of grad school was",
      "offset": 1491.679,
      "duration": 3.521
    },
    {
      "lang": "en",
      "text": "like a lot of exploration and a lot of",
      "offset": 1493.44,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "like coming up with bad ideas. And then",
      "offset": 1495.2,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "honestly I'd be interested to see how he",
      "offset": 1499.12,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "remembers it. But I think I wrote a",
      "offset": 1500.96,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "sequence of proposals about different",
      "offset": 1503.039,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "projects and then I came up with this",
      "offset": 1504.88,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "idea. I was like, &quot;Oh, we should just",
      "offset": 1507.279,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "try to do as well as we can to reverse",
      "offset": 1508.72,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "engineer the text that's in embeddings.&quot;",
      "offset": 1511.36,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "And I and then we were talking about it.",
      "offset": 1513.52,
      "duration": 2.399
    },
    {
      "lang": "en",
      "text": "He was like, &quot;Oh yeah, you should just",
      "offset": 1514.88,
      "duration": 2.399
    },
    {
      "lang": "en",
      "text": "do that.&quot; And then that was the end of",
      "offset": 1515.919,
      "duration": 2.721
    },
    {
      "lang": "en",
      "text": "the proposals. And then I was just",
      "offset": 1517.279,
      "duration": 3.441
    },
    {
      "lang": "en",
      "text": "working on that problem for a long time.",
      "offset": 1518.64,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "Which at the time I was really motivated",
      "offset": 1520.72,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "by that because I was like cool like my",
      "offset": 1522.24,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "first as a grad student my first sort of",
      "offset": 1524.08,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "like official like sign off on like",
      "offset": 1526.88,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "coming up with a good research idea. And",
      "offset": 1529.52,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "at the same time there was this big rise",
      "offset": 1532.08,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "of this startup business model called",
      "offset": 1535.12,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "like a vector database. And there are",
      "offset": 1537.52,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "all these companies popping up raising",
      "offset": 1539.44,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "money raising money uh getting like",
      "offset": 1541.2,
      "duration": 4.479
    },
    {
      "lang": "en",
      "text": "crazy funding and then actual",
      "offset": 1543.52,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "applications being built that do",
      "offset": 1545.679,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "something where instead of exchanging",
      "offset": 1548.32,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "customer data they exchange vectors. So",
      "offset": 1550.159,
      "duration": 5.281
    },
    {
      "lang": "en",
      "text": "we had this like very grounded question",
      "offset": 1553.2,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "of like what data are they actually",
      "offset": 1555.44,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "sending when they when they send the",
      "offset": 1557.279,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "vectors. Like first of all you have this",
      "offset": 1558.72,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "information theoretic argument that when",
      "offset": 1560.799,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "you send one vector there should be a",
      "offset": 1562.32,
      "duration": 4.479
    },
    {
      "lang": "en",
      "text": "lot of text recoverable just in terms of",
      "offset": 1564.72,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "like a lot of these things represent",
      "offset": 1566.799,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "very short documents but they actually",
      "offset": 1569.2,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "have many many bits. So like the problem",
      "offset": 1570.96,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "seems trackable. And then second of all",
      "offset": 1573.36,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "we had this justification of how the",
      "offset": 1575.6,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "product is actually being used. like if",
      "offset": 1577.84,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "if someone hacks into a vector database,",
      "offset": 1579.44,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "what do they actually find? If that",
      "offset": 1582.08,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "makes sense.\n So, we were working on that",
      "offset": 1583.52,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "for a while. I think I have the the the",
      "offset": 1586,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "talk that you did from that Sasha",
      "offset": 1588.24,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "highlighted uh is this one.\n Oh, yeah.",
      "offset": 1589.84,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "Maybe that has the graphic that that",
      "offset": 1592.72,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "would kind of\n Oh, go one before. I think",
      "offset": 1594.4,
      "duration": 4.639
    },
    {
      "lang": "en",
      "text": "one before.\n This is actually Yeah, this",
      "offset": 1597.12,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "one's good. Yeah,\n I like having visual",
      "offset": 1599.039,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "aid. I like how I like giving people",
      "offset": 1601.039,
      "duration": 3.281
    },
    {
      "lang": "en",
      "text": "breadcrumbs to follow up if they if",
      "offset": 1602.88,
      "duration": 3.039
    },
    {
      "lang": "en",
      "text": "they're interested in digging more. But",
      "offset": 1604.32,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "yeah, I I remember this is a pretty uh",
      "offset": 1605.919,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "hot area research uh at the time\n and",
      "offset": 1608.08,
      "duration": 3.599
    },
    {
      "lang": "en",
      "text": "there's been some really interesting",
      "offset": 1610.32,
      "duration": 4.959
    },
    {
      "lang": "en",
      "text": "follow-ups like we we ended up building",
      "offset": 1611.679,
      "duration": 5.521
    },
    {
      "lang": "en",
      "text": "a system that can do this quite well",
      "offset": 1615.279,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "like taking an embedding and I think our",
      "offset": 1617.2,
      "duration": 4.719
    },
    {
      "lang": "en",
      "text": "highlight number is like at a certain",
      "offset": 1619.919,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "length like a long sentence length we",
      "offset": 1621.919,
      "duration": 6.401
    },
    {
      "lang": "en",
      "text": "can get 90% of the text back. Exactly.",
      "offset": 1623.919,
      "duration": 6.801
    },
    {
      "lang": "en",
      "text": "And uh a lot of people were able to do",
      "offset": 1628.32,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "stuff with that like they can for",
      "offset": 1630.72,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "example I know these people that work on",
      "offset": 1632.96,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "a problem of like debiasing embeddings",
      "offset": 1636.08,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "and like in one data set they do",
      "offset": 1638.72,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "something they have a procedure for like",
      "offset": 1640.64,
      "duration": 5.919
    },
    {
      "lang": "en",
      "text": "removing all latent features that",
      "offset": 1642.64,
      "duration": 5.919
    },
    {
      "lang": "en",
      "text": "correlate with gender. So they can",
      "offset": 1646.559,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "produce like useful embeddings that from",
      "offset": 1648.559,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "some perspective have no like",
      "offset": 1651.039,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "information or usable information about",
      "offset": 1652.64,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "gender. And they'd been doing that for a",
      "offset": 1654.559,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "while. And then they actually just used",
      "offset": 1657.12,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "our tool and they so like they would put",
      "offset": 1658.72,
      "duration": 5.92
    },
    {
      "lang": "en",
      "text": "in a sentence like this woman is a",
      "offset": 1661.36,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "doctor at Wild Cornell Hospital in New",
      "offset": 1664.64,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "York or it say this woman is a doctor.",
      "offset": 1666.88,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "She works at Wild Cornell and then they",
      "offset": 1668.799,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "would run their procedure and then they",
      "offset": 1670.72,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "run our embedding to text model and now",
      "offset": 1672.48,
      "duration": 4.799
    },
    {
      "lang": "en",
      "text": "it would say like this person is a",
      "offset": 1674.64,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "doctor. They work at Wild Cornell which",
      "offset": 1677.279,
      "duration": 4.241
    },
    {
      "lang": "en",
      "text": "is pretty cool. So they have like sort",
      "offset": 1679.84,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "of textbased evidence that their method",
      "offset": 1681.52,
      "duration": 6.159
    },
    {
      "lang": "en",
      "text": "is actually removing gender features.",
      "offset": 1684.159,
      "duration": 7.041
    },
    {
      "lang": "en",
      "text": "But let me talk for a second about the",
      "offset": 1687.679,
      "duration": 5.441
    },
    {
      "lang": "en",
      "text": "research phase here cuz I thought it",
      "offset": 1691.2,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "would be I mean I know if if you've ever",
      "offset": 1693.12,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "heard me talk about this I probably told",
      "offset": 1695.52,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "you about it but just for a wider",
      "offset": 1697.039,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "audience I like thinking back on this",
      "offset": 1698.96,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "because it was probably my in some sense",
      "offset": 1701.279,
      "duration": 4.241
    },
    {
      "lang": "en",
      "text": "like my greatest victory of grad school",
      "offset": 1703.76,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "was like working on this embedding",
      "offset": 1705.52,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "inversion problem for a while for quite",
      "offset": 1706.88,
      "duration": 5.279
    },
    {
      "lang": "en",
      "text": "a while and and proposing a lot of",
      "offset": 1709.84,
      "duration": 4.959
    },
    {
      "lang": "en",
      "text": "approaches and like testing stuff. I",
      "offset": 1712.159,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "think sometimes you do stuff and it's",
      "offset": 1714.799,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "clear it was a bad idea. Sometimes you",
      "offset": 1716.24,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "think you should have figured it out",
      "offset": 1718.559,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "earlier. And then sometimes you do stuff",
      "offset": 1720.72,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "and you kind of realize it's really",
      "offset": 1722.64,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "complicated and and probably not worth",
      "offset": 1724.08,
      "duration": 6.479
    },
    {
      "lang": "en",
      "text": "it. So I was testing different decoding",
      "offset": 1725.84,
      "duration": 7.28
    },
    {
      "lang": "en",
      "text": "algorithms for embeddings that are",
      "offset": 1730.559,
      "duration": 4.561
    },
    {
      "lang": "en",
      "text": "closer or text that's closer to the text",
      "offset": 1733.12,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "that's in embeddings. And I was testing",
      "offset": 1735.12,
      "duration": 4.799
    },
    {
      "lang": "en",
      "text": "these kind of like inference time",
      "offset": 1737.039,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "adaptation models for samplers. I think",
      "offset": 1739.919,
      "duration": 4.561
    },
    {
      "lang": "en",
      "text": "we tried a lot of architecture and like",
      "offset": 1742.559,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "kind of training tweaks. We should have",
      "offset": 1744.48,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "tried RL. I think that would work. But",
      "offset": 1746.48,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "well, finally we found something that",
      "offset": 1749.6,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "ended up working. And I guess I'm just",
      "offset": 1750.799,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "saying this all because I thought it was",
      "offset": 1752.64,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "like so rewarding. Like we were just",
      "offset": 1753.919,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "banging our heads against this the wall.",
      "offset": 1756,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "I would have bi-weekly meetings with my",
      "offset": 1757.84,
      "duration": 3.439
    },
    {
      "lang": "en",
      "text": "adviser who kind of suggest things.",
      "offset": 1759.36,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "Sometimes we would agree we were",
      "offset": 1761.279,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "mutually stuck. Sometimes I would get",
      "offset": 1762.72,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "feedback one way or another and and try",
      "offset": 1765.36,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "something new or try a couple things.",
      "offset": 1767.6,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "and and we had this idea that it was",
      "offset": 1769.679,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "possible from the information theory",
      "offset": 1772.08,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "arguments and this other thing where we",
      "offset": 1773.679,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "would we would kind of like take our",
      "offset": 1776.399,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "best guess at what the text was and",
      "offset": 1779.039,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "rembed it and see that it was kind of",
      "offset": 1781.039,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "far from the true embedding. So we had",
      "offset": 1783.2,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "this proof that like a better method",
      "offset": 1785.2,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "could like leverage this kind of",
      "offset": 1788.08,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "information. And then when we finally",
      "offset": 1789.6,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "solved it, it was it was awesome. Like",
      "offset": 1792.64,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "we had this number that was like 30 for",
      "offset": 1795.2,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "months. I think at one point I got it to",
      "offset": 1797.2,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "35 and actually I think I was like, &quot;Oh,",
      "offset": 1798.72,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "I'm done.&quot; Like I got it to 35 and and",
      "offset": 1801.2,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "my adviser told me, &quot;Oh, no.&quot; Like",
      "offset": 1803.12,
      "duration": 3.039
    },
    {
      "lang": "en",
      "text": "that's you can't really just propose a",
      "offset": 1804.48,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "new problem and show you push a metric",
      "offset": 1806.159,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "from 30 to 35. That's like confusing and",
      "offset": 1807.76,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "probably not that meaningful to people.",
      "offset": 1810.559,
      "duration": 4.641
    },
    {
      "lang": "en",
      "text": "And I think I was, you know, that was",
      "offset": 1812.72,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "kind of like a local minimum for me",
      "offset": 1815.2,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "where I was like bummed. But then we",
      "offset": 1816.64,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "ended up getting the number to like 97",
      "offset": 1818.72,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "or something which neither of us knew",
      "offset": 1821.2,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "were possible. We were all just we were",
      "offset": 1822.799,
      "duration": 2.961
    },
    {
      "lang": "en",
      "text": "just kind of staring at this graph like",
      "offset": 1824.24,
      "duration": 3.679
    },
    {
      "lang": "en",
      "text": "oh my god like who knew you could get",
      "offset": 1825.76,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "this much information from an embedding",
      "offset": 1827.919,
      "duration": 5.041
    },
    {
      "lang": "en",
      "text": "and that was like so great like um just",
      "offset": 1829.679,
      "duration": 6.081
    },
    {
      "lang": "en",
      "text": "sort of this it was so rewarding and so",
      "offset": 1832.96,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "it was invigorating honestly like that",
      "offset": 1835.76,
      "duration": 4.799
    },
    {
      "lang": "en",
      "text": "research process of like we picked a",
      "offset": 1838.08,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "good problem and then we spent so long",
      "offset": 1840.559,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "trying stuff that didn't work which I'm",
      "offset": 1842.32,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "probably forgetting how frustrating that",
      "offset": 1844.559,
      "duration": 3.521
    },
    {
      "lang": "en",
      "text": "was. I'm sure it was terrible, but then",
      "offset": 1846.32,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "like actually solving or at least like",
      "offset": 1848.08,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "coming up with a much better way of",
      "offset": 1850.72,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "solving the problem. I don't know if I'd",
      "offset": 1852.64,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "say we solved it, but we definitely",
      "offset": 1854,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "learned a lot from where we started was",
      "offset": 1856,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "like was great and it completely",
      "offset": 1857.76,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "solidified for me the fact that I should",
      "offset": 1860.72,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "have gone to grad school to have this",
      "offset": 1863.44,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "like life experience and like makes me",
      "offset": 1865.2,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "want to do research forever. you're",
      "offset": 1866.96,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "clearly clearly um sort of in love with",
      "offset": 1869.279,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "the the the journey uh which I think is",
      "offset": 1871.039,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "is important because this is what keeps",
      "offset": 1873.44,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "you going through the the tough parts.",
      "offset": 1875.36,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "Is this a good time to talk about the",
      "offset": 1877.2,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "universal geometry side then?\n Yeah.",
      "offset": 1878.88,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "Yeah. Yeah. Let's let's do that next. I",
      "offset": 1881.039,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "think that's a good idea. So So we have",
      "offset": 1882.88,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "this more recent followup and the So the",
      "offset": 1885.36,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "first part I was talking about ended up",
      "offset": 1887.84,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "in this paper called text embeddings",
      "offset": 1890,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "reveal almost as much as text which was",
      "offset": 1892.72,
      "duration": 5.679
    },
    {
      "lang": "en",
      "text": "published in 2023. And then we recently",
      "offset": 1896,
      "duration": 4.559
    },
    {
      "lang": "en",
      "text": "had a paper come out on archive which",
      "offset": 1898.399,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "will hopefully be published at some",
      "offset": 1900.559,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "point and it's called harnessing the",
      "offset": 1901.919,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "universal geometry of embeddings which",
      "offset": 1903.679,
      "duration": 4.961
    },
    {
      "lang": "en",
      "text": "was also that was probably like the only",
      "offset": 1905.84,
      "duration": 5.679
    },
    {
      "lang": "en",
      "text": "other time I felt like we've made like",
      "offset": 1908.64,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "maybe there have been two more times but",
      "offset": 1911.519,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "that that was probably the the second of",
      "offset": 1913.2,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "three times where I felt like we made",
      "offset": 1915.12,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "like a real discovery about like the",
      "offset": 1916.64,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "unknown and it was like very rewarding",
      "offset": 1919.2,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "just for its own intrinsic kind of",
      "offset": 1921.2,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "elusiveness.",
      "offset": 1924.32,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "And I'll start from explaining it in",
      "offset": 1926,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "terms of the prior paper. So we we built",
      "offset": 1928,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "a system that can you know do embeddings",
      "offset": 1929.919,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "to text and and it works very well and",
      "offset": 1932.32,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "we're we're very pleased with ourselves.",
      "offset": 1934.159,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "And then we went to a conference, we",
      "offset": 1936.32,
      "duration": 2.88
    },
    {
      "lang": "en",
      "text": "talked to people about it. We talked to",
      "offset": 1937.919,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "like the vector databases. I think some",
      "offset": 1939.2,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "of them changed their privacy policies",
      "offset": 1941.039,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "which was like somewhat gratifying. Um",
      "offset": 1942.72,
      "duration": 5.439
    },
    {
      "lang": "en",
      "text": "and then we kept getting this perpetual",
      "offset": 1946.159,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "question which is like well you're just",
      "offset": 1948.159,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "assuming we use the open AI model or",
      "offset": 1950.48,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "you're just assuming we use the most",
      "offset": 1952.32,
      "duration": 2.8
    },
    {
      "lang": "en",
      "text": "popular text embedding model. if they",
      "offset": 1953.6,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "fine-tune their own model or if they use",
      "offset": 1955.12,
      "duration": 5.679
    },
    {
      "lang": "en",
      "text": "a model that you're not training an",
      "offset": 1958.48,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "adversary for, then you can't solve the",
      "offset": 1960.799,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "problem, which is like true. Like none",
      "offset": 1962.88,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "of the vector detect stuff works unless",
      "offset": 1964.96,
      "duration": 4.559
    },
    {
      "lang": "en",
      "text": "you have this assumption of like knowing",
      "offset": 1967.12,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "the encoder and also being able to make",
      "offset": 1969.519,
      "duration": 5.441
    },
    {
      "lang": "en",
      "text": "a lot of queries to it. But we had this",
      "offset": 1971.84,
      "duration": 6.559
    },
    {
      "lang": "en",
      "text": "kind of underlying theory that all of",
      "offset": 1974.96,
      "duration": 5.439
    },
    {
      "lang": "en",
      "text": "the models learn very similar things.",
      "offset": 1978.399,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "Like we have some preliminary evidence",
      "offset": 1980.399,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "for that. like certain models that are",
      "offset": 1982.32,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "fine-tuned from the same base, you can",
      "offset": 1984.559,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "kind of swap their representations",
      "offset": 1986.24,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "without doing much. Or if you look at",
      "offset": 1987.679,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "the nearest neighbors, a lot of the",
      "offset": 1989.6,
      "duration": 2.64
    },
    {
      "lang": "en",
      "text": "models will give you the exact same",
      "offset": 1991.039,
      "duration": 2.961
    },
    {
      "lang": "en",
      "text": "nearest neighbors even though they have",
      "offset": 1992.24,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "completely different training bases. And",
      "offset": 1994,
      "duration": 3.519
    },
    {
      "lang": "en",
      "text": "then there's this paper that came out",
      "offset": 1996.159,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "last year called the Platonic",
      "offset": 1997.519,
      "duration": 3.441
    },
    {
      "lang": "en",
      "text": "Representation Hypothesis from some",
      "offset": 1999.279,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "folks at MIT, which is really really",
      "offset": 2000.96,
      "duration": 4.959
    },
    {
      "lang": "en",
      "text": "compelling and I think just like great",
      "offset": 2003.44,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "intersection of philosophy,",
      "offset": 2005.919,
      "duration": 3.521
    },
    {
      "lang": "en",
      "text": "representation learning, deep learning",
      "offset": 2007.519,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "research. Like I I love this paper and",
      "offset": 2009.44,
      "duration": 3.119
    },
    {
      "lang": "en",
      "text": "that it's it's such a beautiful idea",
      "offset": 2011.12,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "which is something like all models are",
      "offset": 2012.559,
      "duration": 6.321
    },
    {
      "lang": "en",
      "text": "trained on data from the world and",
      "offset": 2016,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "there's only one world and so as the",
      "offset": 2018.88,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "models get better by scaling data and",
      "offset": 2022,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "scaling model size they're sort of",
      "offset": 2024.08,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "converging to learn the exact same",
      "offset": 2026.159,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "thing. And in this paper they have",
      "offset": 2028,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "evidence based on correlations for doing",
      "offset": 2030.08,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "this with vision and language models.",
      "offset": 2033.44,
      "duration": 4.959
    },
    {
      "lang": "en",
      "text": "It's very neat and so we saw this. So",
      "offset": 2035.44,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "basically think about you know you're us",
      "offset": 2038.399,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "you see this platonic representation",
      "offset": 2040.64,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "hypothesis paper a lot of people have",
      "offset": 2042.24,
      "duration": 4.799
    },
    {
      "lang": "en",
      "text": "this shared idea like you know Claude",
      "offset": 2044.24,
      "duration": 4.639
    },
    {
      "lang": "en",
      "text": "and GBT4",
      "offset": 2047.039,
      "duration": 4.481
    },
    {
      "lang": "en",
      "text": "probably do a lot of very similar",
      "offset": 2048.879,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "internal computation because both of",
      "offset": 2051.52,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "them are trained on trillions of tokens",
      "offset": 2053.679,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "of human written text even if they have",
      "offset": 2055.359,
      "duration": 5.441
    },
    {
      "lang": "en",
      "text": "different architectures like maybe you",
      "offset": 2057.679,
      "duration": 5.121
    },
    {
      "lang": "en",
      "text": "know the actual basis or like the the",
      "offset": 2060.8,
      "duration": 3.359
    },
    {
      "lang": "en",
      "text": "numbers if you look at them look",
      "offset": 2062.8,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "different but in some way they're like",
      "offset": 2064.159,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "kind of computing the same thing and I",
      "offset": 2066.24,
      "duration": 3.439
    },
    {
      "lang": "en",
      "text": "think it's even more true with these",
      "offset": 2068.32,
      "duration": 3.599
    },
    {
      "lang": "en",
      "text": "like embedding models which have like",
      "offset": 2069.679,
      "duration": 4.561
    },
    {
      "lang": "en",
      "text": "really only one objective that works and",
      "offset": 2071.919,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "they're probably all trained on like MS",
      "offset": 2074.24,
      "duration": 3.439
    },
    {
      "lang": "en",
      "text": "Marco which is a really popular data set",
      "offset": 2076,
      "duration": 4.879
    },
    {
      "lang": "en",
      "text": "and pre-trained maybe on Wikipedia. But",
      "offset": 2077.679,
      "duration": 5.121
    },
    {
      "lang": "en",
      "text": "we wanted to basically combine this",
      "offset": 2080.879,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "platonic representation hypothesis idea",
      "offset": 2082.8,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "with the vectex thing and produce a",
      "offset": 2084.8,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "system that can like align models so",
      "offset": 2088.32,
      "duration": 5.359
    },
    {
      "lang": "en",
      "text": "that we can do embedding inversion.",
      "offset": 2090.8,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "But, you know, it's it's valuable for",
      "offset": 2093.679,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "more than just embedding inversion.",
      "offset": 2095.2,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "Like, you can use this to kind of\n glue",
      "offset": 2097.28,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "together models. Like, that's what",
      "offset": 2099.2,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "actually got me like super excited. And",
      "offset": 2100.88,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "by the way, like I think there's a few",
      "offset": 2102.8,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "related threads. Uh, I think we did an",
      "offset": 2104,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "episode with Nicholas Carini where he",
      "offset": 2105.92,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "had an extraction attack uh on on one of",
      "offset": 2107.44,
      "duration": 6.159
    },
    {
      "lang": "en",
      "text": "the GPT models and uh they got it fixed.",
      "offset": 2110.4,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "The other thing I want to I just really",
      "offset": 2113.599,
      "duration": 2.401
    },
    {
      "lang": "en",
      "text": "want to spell out for people just in",
      "offset": 2114.88,
      "duration": 2.479
    },
    {
      "lang": "en",
      "text": "case they're not thinking it through.",
      "offset": 2116,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "Being able to invert embeddings also",
      "offset": 2117.359,
      "duration": 4.881
    },
    {
      "lang": "en",
      "text": "means that you can you can back out uh",
      "offset": 2119.92,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "like secret prompts or context that",
      "offset": 2122.24,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "might leak customer information that's",
      "offset": 2124.8,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "potentially harmful and like obviously",
      "offset": 2127.04,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "attack vector issue. I think one of the",
      "offset": 2128.88,
      "duration": 4.479
    },
    {
      "lang": "en",
      "text": "things I I had a question about was",
      "offset": 2131.2,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "whether or not position embedding does",
      "offset": 2133.359,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "affect it and like extension of position",
      "offset": 2135.44,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "embeddings affected because obviously",
      "offset": 2137.76,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "that like context are going to get",
      "offset": 2139.2,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "longer and longer. Your ability to",
      "offset": 2140.88,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "invert will obviously decrease with",
      "offset": 2142.56,
      "duration": 4.799
    },
    {
      "lang": "en",
      "text": "longer context. Well, now you know uh",
      "offset": 2144.64,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "maybe not that important.\n No, no, no,",
      "offset": 2147.359,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "no. You're totally right. So, we're",
      "offset": 2148.88,
      "duration": 6.08
    },
    {
      "lang": "en",
      "text": "operating in this space in in our work",
      "offset": 2151.359,
      "duration": 6.961
    },
    {
      "lang": "en",
      "text": "where the sequences are relatively short",
      "offset": 2154.96,
      "duration": 6.159
    },
    {
      "lang": "en",
      "text": "and the embeddings are relatively large.",
      "offset": 2158.32,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "Like I think we're kind of at a great",
      "offset": 2161.119,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "advantage from that perspective. And",
      "offset": 2162.88,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "you're definitely right. Like if you",
      "offset": 2165.44,
      "duration": 6.88
    },
    {
      "lang": "en",
      "text": "embed an entire book to a 500dimensional",
      "offset": 2167.44,
      "duration": 7.36
    },
    {
      "lang": "en",
      "text": "vector, there's just no way you could",
      "offset": 2172.32,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "get the entire book back. Like there",
      "offset": 2174.8,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "must be this these kind of collisions.",
      "offset": 2176.32,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "Like it, you know, in information",
      "offset": 2178.56,
      "duration": 3.279
    },
    {
      "lang": "en",
      "text": "theory, like if you have lossy",
      "offset": 2180.16,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "compression, two different inputs mapped",
      "offset": 2181.839,
      "duration": 4.801
    },
    {
      "lang": "en",
      "text": "to the same code, which means that you",
      "offset": 2184.24,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "can never determine which input formed",
      "offset": 2186.64,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "the code. And I think that's probably",
      "offset": 2189.28,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "what will start to happen. Like if you",
      "offset": 2190.96,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "have two books and you swap just one",
      "offset": 2192.48,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "word and you embed them, I don't know,",
      "offset": 2194.64,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "someone can try this. You'll probably",
      "offset": 2196.4,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "get like a perfect collision and in that",
      "offset": 2198.16,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "case inversion is impossible. And even",
      "offset": 2200.48,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "like when you don't take it to the",
      "offset": 2202.64,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "limit, it probably just gets very very",
      "offset": 2204.64,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "hard. Like things get super compressed.",
      "offset": 2206.16,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "So I don't know how well this work",
      "offset": 2208.32,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "scales. Like it's a great question like",
      "offset": 2210.079,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "exactly how much information you can",
      "offset": 2212,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "sort of cram into one of these vectors",
      "offset": 2213.68,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "and I I don't have a sense of where the",
      "offset": 2215.44,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "boundary is. It'd be interesting to talk",
      "offset": 2217.52,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "to some one of the like linear algebra",
      "offset": 2219.44,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "people from like the math department on",
      "offset": 2221.599,
      "duration": 4.561
    },
    {
      "lang": "en",
      "text": "like how literally can we take inversion",
      "offset": 2223.52,
      "duration": 4.559
    },
    {
      "lang": "en",
      "text": "like you know how like what what",
      "offset": 2226.16,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "measures of a matrix do they have where",
      "offset": 2228.079,
      "duration": 4.481
    },
    {
      "lang": "en",
      "text": "we can like kind of run that and like",
      "offset": 2230.4,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "try to get some meaningful information",
      "offset": 2232.56,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "out of that. This is like where",
      "offset": 2234.64,
      "duration": 3.199
    },
    {
      "lang": "en",
      "text": "information theory starts to collide",
      "offset": 2236.32,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "with uh linear algebra and all all the",
      "offset": 2237.839,
      "duration": 3.361
    },
    {
      "lang": "en",
      "text": "other stuff.\n Totally. Yeah. There",
      "offset": 2239.68,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "there's always this um this detail where",
      "offset": 2241.2,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "we're we're running these on computers",
      "offset": 2244.4,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "and so we don't actually have like real",
      "offset": 2246.16,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "decimal numbers or real numbers. We have",
      "offset": 2248.32,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "like floating point representations of",
      "offset": 2250.88,
      "duration": 4.719
    },
    {
      "lang": "en",
      "text": "numbers which are like very it kind of",
      "offset": 2252.8,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "like throws a wrench into the mix. Do",
      "offset": 2255.599,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "you have any consideration of like",
      "offset": 2258.16,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "superposition when like sort of",
      "offset": 2259.839,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "nonlinearity like you could like stuff",
      "offset": 2261.76,
      "duration": 5.359
    },
    {
      "lang": "en",
      "text": "information in the lower bits? But I",
      "offset": 2264,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "don't know if that matters. I I really",
      "offset": 2267.119,
      "duration": 3.201
    },
    {
      "lang": "en",
      "text": "don't. It's just like a nice thing to",
      "offset": 2268.64,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "think about.\n Yeah. Yeah, it is a great",
      "offset": 2270.32,
      "duration": 4.799
    },
    {
      "lang": "en",
      "text": "question and and I get a sense that like",
      "offset": 2272.32,
      "duration": 5.039
    },
    {
      "lang": "en",
      "text": "a lot of the less important bits are",
      "offset": 2275.119,
      "duration": 4.801
    },
    {
      "lang": "en",
      "text": "more useful for computation and maybe",
      "offset": 2277.359,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "the higher order bits are more important",
      "offset": 2279.92,
      "duration": 3.679
    },
    {
      "lang": "en",
      "text": "for like storing data or something like",
      "offset": 2281.599,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "that. But I'm not sure. These are the",
      "offset": 2283.599,
      "duration": 3.121
    },
    {
      "lang": "en",
      "text": "kinds of questions I'm actually hoping",
      "offset": 2285.28,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "to explore over the next few years. Like",
      "offset": 2286.72,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "um I'll skip ahead for a second. So we",
      "offset": 2289.52,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "we have this result that's like maybe",
      "offset": 2291.92,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "the the third sort of like discovery I",
      "offset": 2294.16,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "was alluding to which is like a way to",
      "offset": 2296.16,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "measure the exact capacity of a language",
      "offset": 2298.56,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "model and we get this number if you",
      "offset": 2300.88,
      "duration": 4.479
    },
    {
      "lang": "en",
      "text": "train a language model on a ton of",
      "offset": 2303.44,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "random data and you measure its rate of",
      "offset": 2305.359,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "memorization. Yeah. Can you open the",
      "offset": 2307.92,
      "duration": 2.88
    },
    {
      "lang": "en",
      "text": "right curve? This is sort of the",
      "offset": 2309.28,
      "duration": 2.72
    },
    {
      "lang": "en",
      "text": "discovery I'm talking about like no",
      "offset": 2310.8,
      "duration": 3.039
    },
    {
      "lang": "en",
      "text": "matter how you scale the training size",
      "offset": 2312,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "you hit this like perfect perfectish",
      "offset": 2313.839,
      "duration": 5.921
    },
    {
      "lang": "en",
      "text": "plateau in order memorization which we",
      "offset": 2316.32,
      "duration": 6.16
    },
    {
      "lang": "en",
      "text": "call the model capacity and the the",
      "offset": 2319.76,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "question I've been stuck on in the back",
      "offset": 2322.48,
      "duration": 3.119
    },
    {
      "lang": "en",
      "text": "of my mind for a while is like how is",
      "offset": 2323.76,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "that actually implemented so like this",
      "offset": 2325.599,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "is a transformer that is trained for",
      "offset": 2327.44,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "many many data points and many many",
      "offset": 2329.92,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "training steps and so like it's almost",
      "offset": 2332.48,
      "duration": 5.84
    },
    {
      "lang": "en",
      "text": "like if you have okay the 10 to the 6",
      "offset": 2335.92,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "point on the x-axis this the capacity uh",
      "offset": 2338.32,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "we don't have to actually say the",
      "offset": 2341.68,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "numbers but it's basically perfectly",
      "offset": 2343.04,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "dividing its computation",
      "offset": 2345.28,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "between all of the data points like",
      "offset": 2347.68,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "every one of the 10 of the six data",
      "offset": 2350.48,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "points gets like a tiny sliver of the",
      "offset": 2352.079,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "model parameters because they're",
      "offset": 2354.4,
      "duration": 4.719
    },
    {
      "lang": "en",
      "text": "completely independent random strings so",
      "offset": 2356.4,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "I don't really know if superp position",
      "offset": 2359.119,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "is occurring here like it seemed",
      "offset": 2360.96,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "possible to me that the model would",
      "offset": 2362.96,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "learn like these completely independent",
      "offset": 2364.4,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "columns of computation one per data",
      "offset": 2366.72,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "point, but it's also possible it's",
      "offset": 2369.04,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "learning some kind of like combined",
      "offset": 2371.04,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "thing where it's maybe it learns like a",
      "offset": 2373.76,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "load and a store and it's like sort of",
      "offset": 2376.56,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "like loading and storing bits using",
      "offset": 2378.56,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "these generic operations and then in the",
      "offset": 2380.32,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "end it reconstructs the random strings.",
      "offset": 2382.64,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "So even though like the data is",
      "offset": 2384.64,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "completely independent the kind of like",
      "offset": 2387.2,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "compute is is very similar in terms of",
      "offset": 2389.28,
      "duration": 4.559
    },
    {
      "lang": "en",
      "text": "like predicting random strings. But",
      "offset": 2391.68,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "yeah, I guess this is all to say like",
      "offset": 2393.839,
      "duration": 4.561
    },
    {
      "lang": "en",
      "text": "about superp position and everything. I",
      "offset": 2396.16,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "have no idea how the mechanisms are",
      "offset": 2398.4,
      "duration": 3.679
    },
    {
      "lang": "en",
      "text": "actually implemented inside the models",
      "offset": 2400.4,
      "duration": 3.199
    },
    {
      "lang": "en",
      "text": "and that's like one thing I'm hoping to",
      "offset": 2402.079,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "learn about in the next couple years.",
      "offset": 2403.599,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "It's a reasonable question whether it's",
      "offset": 2405.68,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "meaningful to learn. I think there's a",
      "offset": 2407.2,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "lot of things that is like nice to know",
      "offset": 2409.92,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "but maybe not that useful. Lat space lat",
      "offset": 2412.64,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "space alignment is very very useful.",
      "offset": 2415.44,
      "duration": 7.04
    },
    {
      "lang": "en",
      "text": "data set efficiency in theory. Cool. But",
      "offset": 2418.24,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "like practically people are just going",
      "offset": 2422.48,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "to go for the biggest data set they can",
      "offset": 2423.76,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "like like the scaling laws are kind of",
      "offset": 2426.96,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "worked out in so far as like the",
      "offset": 2429.28,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "relationship of comput and data amount",
      "offset": 2431.28,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "of memorization. I I don't know. I think",
      "offset": 2433.359,
      "duration": 3.521
    },
    {
      "lang": "en",
      "text": "maybe this is a good point to maybe also",
      "offset": 2435.04,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "bring in the idea that Andre has been",
      "offset": 2436.88,
      "duration": 4.719
    },
    {
      "lang": "en",
      "text": "pushing for the last like I think year",
      "offset": 2439.52,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "and a bit of um the cognitive core like",
      "offset": 2441.599,
      "duration": 5.441
    },
    {
      "lang": "en",
      "text": "the what is the dumbest possible model",
      "offset": 2445.04,
      "duration": 4.559
    },
    {
      "lang": "en",
      "text": "that knows nothing\n but is you is smart",
      "offset": 2447.04,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "enough for tool use to do everything",
      "offset": 2449.599,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "else right so you can run it on device",
      "offset": 2451.359,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "and fast inference it's open source",
      "offset": 2453.2,
      "duration": 5.119
    },
    {
      "lang": "en",
      "text": "whatever uh so jumba 3N is like a really",
      "offset": 2455.839,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "good candidate right now because it's",
      "offset": 2458.319,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "like a 4B model that is like claimed to",
      "offset": 2459.839,
      "duration": 6.161
    },
    {
      "lang": "en",
      "text": "be better than llama 4 and GBC 4.1",
      "offset": 2462.319,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "according to you know certain arenas",
      "offset": 2466,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "that shall not be named.\n This is where",
      "offset": 2468.319,
      "duration": 4.561
    },
    {
      "lang": "en",
      "text": "things get complicated. Like I it feels",
      "offset": 2470.319,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "like language models kind of implement",
      "offset": 2472.88,
      "duration": 5.84
    },
    {
      "lang": "en",
      "text": "things and know things almost in the",
      "offset": 2475.359,
      "duration": 5.361
    },
    {
      "lang": "en",
      "text": "same way and it's like really difficult",
      "offset": 2478.72,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "to disentangle like whether they're",
      "offset": 2480.72,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "memorizing facts from whether they're",
      "offset": 2482.8,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "like learning useful ways to generalize",
      "offset": 2484.4,
      "duration": 5.439
    },
    {
      "lang": "en",
      "text": "about new stuff. But I I agree this",
      "offset": 2486.56,
      "duration": 5.519
    },
    {
      "lang": "en",
      "text": "would be really nice. I don't think we",
      "offset": 2489.839,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "have a lot of evidence that we can build",
      "offset": 2492.079,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "a system like this that like is really",
      "offset": 2493.839,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "really good at reasoning but really dumb",
      "offset": 2495.92,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "about the world. Like I don't know if we",
      "offset": 2497.68,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "have the tools. Yeah, maybe maybe not. I",
      "offset": 2500.319,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "think the existence proof is humans,",
      "offset": 2502.64,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "right? People always lean on humans as",
      "offset": 2504.64,
      "duration": 3.439
    },
    {
      "lang": "en",
      "text": "like the existence proof. It's not a",
      "offset": 2506.4,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "great existence proof because I think if",
      "offset": 2508.079,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "you talk to people about the number of",
      "offset": 2510,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "neurons that we have and you make a",
      "offset": 2511.599,
      "duration": 3.361
    },
    {
      "lang": "en",
      "text": "neuron roughly equivalent to a",
      "offset": 2513.52,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "parameter, we have something like 100",
      "offset": 2514.96,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "trillion in our brains. So like and like",
      "offset": 2516.72,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "we consume like 20 watts of energy. Like",
      "offset": 2519.359,
      "duration": 5.121
    },
    {
      "lang": "en",
      "text": "it's\n nothing. Like we're so much better",
      "offset": 2521.76,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "than than uh language models. It's not",
      "offset": 2524.48,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "even funny. And then the the last",
      "offset": 2526.88,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "feature of us is that we're self-proing",
      "offset": 2528.4,
      "duration": 3.679
    },
    {
      "lang": "en",
      "text": "which is uh not something that language",
      "offset": 2530.16,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "models do as well.\n Oh like we forget",
      "offset": 2532.079,
      "duration": 5.441
    },
    {
      "lang": "en",
      "text": "stuff.\n No like we are not deeply densely",
      "offset": 2534.48,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "connected like we like connections will",
      "offset": 2537.52,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "drop therefore we're more efficient you",
      "offset": 2539.92,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "know.\n See I see. Unlike a language model",
      "offset": 2541.44,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "where everything is always connected all",
      "offset": 2543.04,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "the time.\n Yeah. Yeah. Or like you preset",
      "offset": 2544.88,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "the skip layers or whatever and that's",
      "offset": 2547.119,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "it, you know, like it's not it's not",
      "offset": 2548.8,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "really actually anything involved with",
      "offset": 2550.72,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "learning. It's just like something you",
      "offset": 2553.2,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "do based on ablations and like",
      "offset": 2554.88,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "guesstimates.\n Even if we did want that,",
      "offset": 2557.04,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "I'm not sure if we have like the right",
      "offset": 2559.68,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "frameworks or methods for actually",
      "offset": 2561.92,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "building like what you're talking about",
      "offset": 2564.079,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "yet.\n I think the world is much closer to",
      "offset": 2566,
      "duration": 3.599
    },
    {
      "lang": "en",
      "text": "where you're at than where Andre is at.",
      "offset": 2568.16,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "Andre is like kind of wishing for an",
      "offset": 2569.599,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "optimistic world. Our conversation with",
      "offset": 2571.92,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "Nan Brown was like, &quot;Yeah, reasoning is",
      "offset": 2573.839,
      "duration": 6.561
    },
    {
      "lang": "en",
      "text": "emergent. If you gave the 01 harness on",
      "offset": 2576.56,
      "duration": 6.559
    },
    {
      "lang": "en",
      "text": "top of GPT2, you would get nothing",
      "offset": 2580.4,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "because GPT2 didn't know enough. You",
      "offset": 2583.119,
      "duration": 5.121
    },
    {
      "lang": "en",
      "text": "need a GPT3 and GPT4 in order to then",
      "offset": 2584.88,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "get 01 like as as GPT4 is the base",
      "offset": 2588.24,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "model, which is like yeah, that's I mean",
      "offset": 2590.64,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "that's that's reasonable. The way I put",
      "offset": 2592.64,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "it is like in order to use tools, you",
      "offset": 2594.16,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "need to like in order to search Google,",
      "offset": 2595.92,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "you need to know at least search terms.",
      "offset": 2597.2,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "In order to like then search Google and",
      "offset": 2599.52,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "then learn what you need. And if you",
      "offset": 2602.24,
      "duration": 2.64
    },
    {
      "lang": "en",
      "text": "don't know what what to search, then",
      "offset": 2603.68,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "like you might just be too dumb. Uh,",
      "offset": 2604.88,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "I like the kind of uh ethos like maybe",
      "offset": 2608.4,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "you could do some kind of pre-training",
      "offset": 2610.88,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "or whenever the model doesn't know",
      "offset": 2613.28,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "something, it can just Google for it and",
      "offset": 2614.8,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "that way you try to encourage it to",
      "offset": 2616.8,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "learn words without or like to to guess",
      "offset": 2619.68,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "words correctly without actually storing",
      "offset": 2622.4,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "the information into its weights.\n Yeah,",
      "offset": 2624.4,
      "duration": 5.199
    },
    {
      "lang": "en",
      "text": "it seems like a nice like goal at least.",
      "offset": 2626.8,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "Yeah, you need some kind of online",
      "offset": 2629.599,
      "duration": 5.121
    },
    {
      "lang": "en",
      "text": "learning probably or memory uh and some",
      "offset": 2631.04,
      "duration": 6.319
    },
    {
      "lang": "en",
      "text": "combination of that. Yeah,\n it's",
      "offset": 2634.72,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "exciting, you know, like I think like if",
      "offset": 2637.359,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "that is the the direction of of where",
      "offset": 2638.88,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "this all lands up, that's great. But",
      "offset": 2641.28,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "like people aren't are not doing that.",
      "offset": 2643.44,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "Instead, we're building, you know, $500",
      "offset": 2645.92,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "billion data centers in the middle of",
      "offset": 2648.16,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "Texas and like, you know, all hell the",
      "offset": 2650,
      "duration": 5.359
    },
    {
      "lang": "en",
      "text": "the the god cluster uh that just will,",
      "offset": 2652.8,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "you know, eventually wrap around the sun",
      "offset": 2655.359,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "and consume solar energy because that's",
      "offset": 2657.04,
      "duration": 4.799
    },
    {
      "lang": "en",
      "text": "that's what we need. Do we finish out",
      "offset": 2659.76,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "the universal geometry thing? Let me",
      "offset": 2661.839,
      "duration": 5.201
    },
    {
      "lang": "en",
      "text": "finish the kind of uh methodological",
      "offset": 2664.079,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "description. So, so we had this goal.",
      "offset": 2667.04,
      "duration": 4.559
    },
    {
      "lang": "en",
      "text": "So, so, so yeah, back to the embedding",
      "offset": 2669.839,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "universality. We started with going from",
      "offset": 2671.599,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "embeddings to text. We know about this",
      "offset": 2673.52,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "platonic representation hypothesis.",
      "offset": 2675.76,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "And maybe I'll skip over the details but",
      "offset": 2678.64,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "basically we had total inspiration from",
      "offset": 2681.76,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "computer vision in this model from 2017",
      "offset": 2684.4,
      "duration": 5.679
    },
    {
      "lang": "en",
      "text": "called cycle GAN which is among other",
      "offset": 2687.2,
      "duration": 6.8
    },
    {
      "lang": "en",
      "text": "things uh it's a way to map between two",
      "offset": 2690.079,
      "duration": 6.481
    },
    {
      "lang": "en",
      "text": "different distributions without any",
      "offset": 2694,
      "duration": 5.599
    },
    {
      "lang": "en",
      "text": "underlying notion of like which thing",
      "offset": 2696.56,
      "duration": 5.279
    },
    {
      "lang": "en",
      "text": "should be mapped where. It's just based",
      "offset": 2699.599,
      "duration": 5.441
    },
    {
      "lang": "en",
      "text": "on some kind of idea of closeness. So",
      "offset": 2701.839,
      "duration": 4.641
    },
    {
      "lang": "en",
      "text": "like the cool thing about this if you",
      "offset": 2705.04,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "look at the top left so I guess the the",
      "offset": 2706.48,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "top left is Monae so impressionist",
      "offset": 2708.88,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "paintings and this picture on the right",
      "offset": 2711.92,
      "duration": 5.199
    },
    {
      "lang": "en",
      "text": "is a photograph. So like it's learning",
      "offset": 2714.16,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "this kind of like semantic notion of",
      "offset": 2717.119,
      "duration": 5.281
    },
    {
      "lang": "en",
      "text": "what content goes where just by mapping",
      "offset": 2718.96,
      "duration": 6.08
    },
    {
      "lang": "en",
      "text": "a distribution of Monae pictures to a",
      "offset": 2722.4,
      "duration": 4.959
    },
    {
      "lang": "en",
      "text": "distribution of photographs without",
      "offset": 2725.04,
      "duration": 5.039
    },
    {
      "lang": "en",
      "text": "actually telling it which Monae picture",
      "offset": 2727.359,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "should map to which photograph. It's",
      "offset": 2730.079,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "kind of a subtle point I'm making. It it",
      "offset": 2732.079,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "takes a little bit of time to wrap your",
      "offset": 2734.319,
      "duration": 2.561
    },
    {
      "lang": "en",
      "text": "head around or maybe like go to the",
      "offset": 2735.359,
      "duration": 3.361
    },
    {
      "lang": "en",
      "text": "middle one if you don't mind the zebras",
      "offset": 2736.88,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "and the horses. So like it's clearly",
      "offset": 2738.72,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "learning like what an animal is and what",
      "offset": 2741.76,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "legs are and sort of like more abstract",
      "offset": 2743.76,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "stuff like what uh the camera position",
      "offset": 2746.24,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "should be and and what grass is and",
      "offset": 2748.88,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "stuff like that. And it's learning like",
      "offset": 2750.56,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "what a horse that looks like a zebra is",
      "offset": 2752.64,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "which is actually like a complicated",
      "offset": 2754.88,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "semantic concept. like we don't have a a",
      "offset": 2756.96,
      "duration": 5.359
    },
    {
      "lang": "en",
      "text": "data set that has a horse and then that",
      "offset": 2760,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "horse as a zebra. We just have separate",
      "offset": 2762.319,
      "duration": 4.881
    },
    {
      "lang": "en",
      "text": "horses and separate zebras, but somehow",
      "offset": 2764.64,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "this this GAN system is able to like",
      "offset": 2767.2,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "elicit this sort of mapping property.",
      "offset": 2770.16,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "It's like kind of a magical connection",
      "offset": 2772.56,
      "duration": 6.16
    },
    {
      "lang": "en",
      "text": "that it learns and I'm still like in awe",
      "offset": 2774.8,
      "duration": 6.48
    },
    {
      "lang": "en",
      "text": "that it's possible at all. But we mo",
      "offset": 2778.72,
      "duration": 6.08
    },
    {
      "lang": "en",
      "text": "more or less like repurposed this system",
      "offset": 2781.28,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "and like we we built our own but like",
      "offset": 2784.8,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "this idea we took it and we applied it",
      "offset": 2786.64,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "to model embeddings where instead of",
      "offset": 2788.8,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "zebras and horses we have like BERT",
      "offset": 2790.48,
      "duration": 5.599
    },
    {
      "lang": "en",
      "text": "embeddings and GPT embeddings or like",
      "offset": 2792.96,
      "duration": 4.639
    },
    {
      "lang": "en",
      "text": "two completely different models with",
      "offset": 2796.079,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "different architectures. So I think",
      "offset": 2797.599,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "these are GTR which is a T5 based",
      "offset": 2799.359,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "retrieval model and GTE which is based",
      "offset": 2801.76,
      "duration": 3.359
    },
    {
      "lang": "en",
      "text": "on bird. So they have different training",
      "offset": 2803.599,
      "duration": 3.361
    },
    {
      "lang": "en",
      "text": "data, different architectures, different",
      "offset": 2805.119,
      "duration": 3.361
    },
    {
      "lang": "en",
      "text": "downstream objectives, different",
      "offset": 2806.96,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "embeddings, but yet when we do this",
      "offset": 2808.48,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "cycle GAN in the embedding space, they",
      "offset": 2810.56,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "just perfectly sort of snap to the same",
      "offset": 2812.72,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "place, which is amazing and has some",
      "offset": 2814.96,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "pretty deep implications of like the",
      "offset": 2818,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "Platonic stuff. Like maybe the models",
      "offset": 2819.76,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "actually are learning a lot of the same",
      "offset": 2822,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "functions or something and in some",
      "offset": 2823.68,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "semantic way they're like very close.",
      "offset": 2825.52,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "And yeah, this is a diagram of how our",
      "offset": 2828.16,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "system looks. It's weird to me how",
      "offset": 2830.4,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "profound it seems uh like you seem you",
      "offset": 2832.64,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "seem like deeply impressed by it. And",
      "offset": 2835.2,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "then the other thing is like uh when we",
      "offset": 2836.96,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "talked to the uh the to Emanuel from",
      "offset": 2839.2,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "Enthropic who did the circuit tracing",
      "offset": 2841.44,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "and mech interpret me mechanistic",
      "offset": 2843.2,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "interpretability work they were like",
      "offset": 2845.44,
      "duration": 4.639
    },
    {
      "lang": "en",
      "text": "excited that like the same thing in",
      "offset": 2848,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "different languages maps to the same",
      "offset": 2850.079,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "circuits and I'm like what you would",
      "offset": 2851.44,
      "duration": 4.879
    },
    {
      "lang": "en",
      "text": "expect?",
      "offset": 2854.16,
      "duration": 5.199
    },
    {
      "lang": "en",
      "text": "Yeah.\n Like I I don't know like why like",
      "offset": 2856.319,
      "duration": 4.881
    },
    {
      "lang": "en",
      "text": "I I I I don't know. I think I feel like",
      "offset": 2859.359,
      "duration": 3.121
    },
    {
      "lang": "en",
      "text": "this this feels more profound to you",
      "offset": 2861.2,
      "duration": 2.72
    },
    {
      "lang": "en",
      "text": "than it does to me. I'm like, &quot;Yeah,",
      "offset": 2862.48,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "obviously.&quot;\n No, that's that's so fair.",
      "offset": 2863.92,
      "duration": 3.439
    },
    {
      "lang": "en",
      "text": "Maybe it's just like self-",
      "offset": 2866.24,
      "duration": 2.8
    },
    {
      "lang": "en",
      "text": "congratulatory and we're happy that",
      "offset": 2867.359,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "we're like the people that got it to",
      "offset": 2869.04,
      "duration": 4.559
    },
    {
      "lang": "en",
      "text": "work.\n Yeah, exactly.\n Yeah, it does it",
      "offset": 2871.04,
      "duration": 4.559
    },
    {
      "lang": "en",
      "text": "does seem obvious in retrospect. And I",
      "offset": 2873.599,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "think that's like constant feedback I've",
      "offset": 2875.599,
      "duration": 3.361
    },
    {
      "lang": "en",
      "text": "gotten from research from, you know,",
      "offset": 2877.44,
      "duration": 2.8
    },
    {
      "lang": "en",
      "text": "people will tell you that this seems",
      "offset": 2878.96,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "obvious to them. But you have to realize",
      "offset": 2880.24,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "that like you came from a perspective of",
      "offset": 2882.4,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "no one ever having done this before and",
      "offset": 2885.28,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "they're coming from a a perspective of",
      "offset": 2887.52,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "you telling them it's true. And like if",
      "offset": 2889.44,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "someone had told you that this was true,",
      "offset": 2891.839,
      "duration": 4.641
    },
    {
      "lang": "en",
      "text": "it would be like maybe obvious to you",
      "offset": 2893.92,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "too, if that makes sense.\n The way I",
      "offset": 2896.48,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "would put it is that we have the",
      "offset": 2898.4,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "intuition but not the proof. you have",
      "offset": 2899.92,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "the you did the work and you have at",
      "offset": 2901.76,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "least some evidence that it's true",
      "offset": 2904.16,
      "duration": 5.199
    },
    {
      "lang": "en",
      "text": "whereas we just have intuitions right so",
      "offset": 2906.72,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "uh part of research is just confirming",
      "offset": 2909.359,
      "duration": 4.881
    },
    {
      "lang": "en",
      "text": "intuitions the applied part comes from",
      "offset": 2911.68,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "like okay now that you know this for a",
      "offset": 2914.24,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "fact what do you do with it yeah right I",
      "offset": 2915.92,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "think the details can be really",
      "offset": 2918.72,
      "duration": 2.48
    },
    {
      "lang": "en",
      "text": "interesting like the details of the",
      "offset": 2919.92,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "proof like which models are most similar",
      "offset": 2921.2,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "to one another and to what degree can",
      "offset": 2923.28,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "you get them to align and on which",
      "offset": 2925.04,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "distributions does this property",
      "offset": 2927.2,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "actually emerge and like that's why",
      "offset": 2928.88,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "reading papers can be fun sometimes is",
      "offset": 2930.48,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "because they kind of answer all those",
      "offset": 2932.4,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "little questions.\n Yeah, I would say uh",
      "offset": 2933.92,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "okay, I'll pull up something very",
      "offset": 2936.96,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "current uh which is GM3N which launched",
      "offset": 2938.319,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "which uh sort of was uh generally",
      "offset": 2940.72,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "available yesterday. I would say the for",
      "offset": 2942.72,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "me and you can correct me if I'm wrong.",
      "offset": 2945.04,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "The most immediate implication is",
      "offset": 2946.559,
      "duration": 4.961
    },
    {
      "lang": "en",
      "text": "mapping adapters to language models. So",
      "offset": 2948.24,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "the the dream is that you have a",
      "offset": 2951.52,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "language model backbone. Let's say this",
      "offset": 2953.28,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "one is like a 2B language model backbone",
      "offset": 2954.64,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "and then you offload your vision. So you",
      "offset": 2957.28,
      "duration": 5.279
    },
    {
      "lang": "en",
      "text": "only you only load in the vision and",
      "offset": 2960.4,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "parap parameters or the the vision",
      "offset": 2962.559,
      "duration": 3.361
    },
    {
      "lang": "en",
      "text": "adapter when you need vision. You only",
      "offset": 2964.16,
      "duration": 3.199
    },
    {
      "lang": "en",
      "text": "load in audio. You don't only need",
      "offset": 2965.92,
      "duration": 3.439
    },
    {
      "lang": "en",
      "text": "speech uh text to speech whenever you",
      "offset": 2967.359,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "need it. Uh because these are all",
      "offset": 2969.359,
      "duration": 3.041
    },
    {
      "lang": "en",
      "text": "separately trained. You're you're just",
      "offset": 2971.04,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "sort of aligning latent spaces and you",
      "offset": 2972.4,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "can sort of train them separately. And I",
      "offset": 2975.2,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "think like this helps to make us more",
      "offset": 2976.64,
      "duration": 6.24
    },
    {
      "lang": "en",
      "text": "confident in one is it's more efficient.",
      "offset": 2980.16,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "That's a that's a given. Two, it makes",
      "offset": 2982.88,
      "duration": 3.199
    },
    {
      "lang": "en",
      "text": "house. It makes us confident that we can",
      "offset": 2984.8,
      "duration": 3.039
    },
    {
      "lang": "en",
      "text": "just just add capabilities without",
      "offset": 2986.079,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "taking away or catastrophically",
      "offset": 2987.839,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "forgetting others.",
      "offset": 2989.599,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "So they're just sort of like stacking",
      "offset": 2992.16,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "more parameters,\n just stackable.\n So",
      "offset": 2993.76,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "that's very cool. Yeah.\n Swappable,",
      "offset": 2995.92,
      "duration": 4.639
    },
    {
      "lang": "en",
      "text": "stackable. It's like a fatter version of",
      "offset": 2997.599,
      "duration": 6.561
    },
    {
      "lang": "en",
      "text": "Laura's that is not really\n that model",
      "offset": 3000.559,
      "duration": 5.681
    },
    {
      "lang": "en",
      "text": "specific. I would say Apple and and",
      "offset": 3004.16,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "Google are pursuing this for their",
      "offset": 3006.24,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "ondevice stuff is is where is my sense.",
      "offset": 3007.68,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "Is this open source,\n Gemma? Yeah. for a",
      "offset": 3010,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "given definition open source which is",
      "offset": 3012.48,
      "duration": 2.72
    },
    {
      "lang": "en",
      "text": "like we release the weights of hugging",
      "offset": 3014,
      "duration": 3.359
    },
    {
      "lang": "en",
      "text": "face. Here you go.\n Oh, that sounds like",
      "offset": 3015.2,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "open source to me.\n Oh yeah, I guess it's",
      "offset": 3017.359,
      "duration": 6.081
    },
    {
      "lang": "en",
      "text": "open weights but not the data.\n Not the",
      "offset": 3020.48,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "data, not the code.\n Not the code. Yeah,",
      "offset": 3023.44,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "right.\n Yeah, I would say that this is",
      "offset": 3026,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "quite soda in terms of efficient models.",
      "offset": 3027.76,
      "duration": 5.839
    },
    {
      "lang": "en",
      "text": "Maybe a small LM also from Hugging Face",
      "offset": 3030.079,
      "duration": 5.361
    },
    {
      "lang": "en",
      "text": "would be also in that in that category.",
      "offset": 3033.599,
      "duration": 3.201
    },
    {
      "lang": "en",
      "text": "There's not that many people working on",
      "offset": 3035.44,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "very good very efficient models. Yeah,",
      "offset": 3036.8,
      "duration": 4.559
    },
    {
      "lang": "en",
      "text": "this is a a very deeply related question",
      "offset": 3039.04,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "and something that really interests me",
      "offset": 3041.359,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "which is like what is the limit of like",
      "offset": 3042.64,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "a 100 million parameter model like if",
      "offset": 3045.52,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "you imagine you know 100 years from now",
      "offset": 3048.16,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "when we have maybe our computers are",
      "offset": 3050.64,
      "duration": 5.679
    },
    {
      "lang": "en",
      "text": "gelatinous blobs and we all communicate",
      "offset": 3053.2,
      "duration": 5.84
    },
    {
      "lang": "en",
      "text": "through telepathy",
      "offset": 3056.319,
      "duration": 4.721
    },
    {
      "lang": "en",
      "text": "will we have 100 million parameter",
      "offset": 3059.04,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "models that are at the level of today's",
      "offset": 3061.04,
      "duration": 6.64
    },
    {
      "lang": "en",
      "text": "03 pro or whatever and like if so like",
      "offset": 3064.4,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "how Would that even be the case like",
      "offset": 3067.68,
      "duration": 3.679
    },
    {
      "lang": "en",
      "text": "based on scaling laws? Like do we have",
      "offset": 3069.44,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "special data? Do we come up with like a",
      "offset": 3071.359,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "brilliant new training scheme or some",
      "offset": 3073.28,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "type of magical architecture? Like I",
      "offset": 3075.04,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "really don't know. Or maybe we really",
      "offset": 3077.04,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "are on the at the plateau already. I",
      "offset": 3079.04,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "don't know. It seems like when we are",
      "offset": 3080.96,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "doing things like calling a small model",
      "offset": 3083.52,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "like a 27B uh model as small like that's",
      "offset": 3085.359,
      "duration": 6.72
    },
    {
      "lang": "en",
      "text": "what Miss Charles is doing that",
      "offset": 3088.8,
      "duration": 5.039
    },
    {
      "lang": "en",
      "text": "you know we've plateaued a little bit in",
      "offset": 3092.079,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "terms of like what we can do to compress",
      "offset": 3093.839,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "things. I have a fun theory uh that this",
      "offset": 3095.359,
      "duration": 5.121
    },
    {
      "lang": "en",
      "text": "is where we mix quantum computing with",
      "offset": 3098.24,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "models like we have to change what a",
      "offset": 3100.48,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "parameter means. We have to search",
      "offset": 3102.16,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "through very high dimensional space in",
      "offset": 3104.16,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "and resolve them much quicker than we",
      "offset": 3106.88,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "can with like conventional compute. That",
      "offset": 3109.04,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "would be my pie in the sky thing.\n I said",
      "offset": 3111.68,
      "duration": 4.879
    },
    {
      "lang": "en",
      "text": "100 years. That's very reasonable to me.",
      "offset": 3114.4,
      "duration": 5.919
    },
    {
      "lang": "en",
      "text": "Throw quantum at it.",
      "offset": 3116.559,
      "duration": 5.441
    },
    {
      "lang": "en",
      "text": "Yeah, I probably have to get a second",
      "offset": 3120.319,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "PhD to know what's going on there. I",
      "offset": 3122,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "think we should establish the definition",
      "offset": 3125.119,
      "duration": 5.921
    },
    {
      "lang": "en",
      "text": "of small model as being a model that a",
      "offset": 3128,
      "duration": 6.64
    },
    {
      "lang": "en",
      "text": "grad student can inference at reasonable",
      "offset": 3131.04,
      "duration": 8.319
    },
    {
      "lang": "en",
      "text": "time on a single GPU\n which is probably",
      "offset": 3134.64,
      "duration": 9.12
    },
    {
      "lang": "en",
      "text": "like 7b\n maybe I don't think 27 is small",
      "offset": 3139.359,
      "duration": 7.681
    },
    {
      "lang": "en",
      "text": "under any reasonable is it wait is ite",
      "offset": 3143.76,
      "duration": 6.48
    },
    {
      "lang": "en",
      "text": "mist uh I don't think so I think all I",
      "offset": 3147.04,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "think their stuff is default dense don't",
      "offset": 3150.24,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "quote me on that this is this is coming",
      "offset": 3152.4,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "off of um just a lot of pre-trained data",
      "offset": 3154.079,
      "duration": 5.201
    },
    {
      "lang": "en",
      "text": "that is that is uh potentially collided.",
      "offset": 3156.88,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "Okay, there was one there's two more",
      "offset": 3159.28,
      "duration": 3.279
    },
    {
      "lang": "en",
      "text": "papers that we wanted to cover and then",
      "offset": 3160.8,
      "duration": 4.559
    },
    {
      "lang": "en",
      "text": "we can we can sort of wrap it. You had",
      "offset": 3162.559,
      "duration": 4.961
    },
    {
      "lang": "en",
      "text": "an approximating you had a language",
      "offset": 3165.359,
      "duration": 3.521
    },
    {
      "lang": "en",
      "text": "model training data. I think this is a",
      "offset": 3167.52,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "little bit uh also newer. How does this",
      "offset": 3168.88,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "rank in terms of your your overall work?",
      "offset": 3171.52,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "Yeah, let's return to the kind of",
      "offset": 3173.68,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "information theory question. So yeah,",
      "offset": 3175.599,
      "duration": 4.641
    },
    {
      "lang": "en",
      "text": "maybe we'll we'll skip over the",
      "offset": 3178.4,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "contextual embeddings in the case of",
      "offset": 3180.24,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "time, but we'll group those papers.",
      "offset": 3182.559,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "Great paper. Hopefully people start",
      "offset": 3185.68,
      "duration": 3.679
    },
    {
      "lang": "en",
      "text": "training with that technique. It's kind",
      "offset": 3187.599,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "of a free lunch. Those questions are all",
      "offset": 3189.359,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "about information and model activations",
      "offset": 3191.92,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "like how much can we recover from this",
      "offset": 3193.839,
      "duration": 5.921
    },
    {
      "lang": "en",
      "text": "given vector or like what data does this",
      "offset": 3197.04,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "vector represent or what computation",
      "offset": 3199.76,
      "duration": 4.559
    },
    {
      "lang": "en",
      "text": "does this vector represent? And there's",
      "offset": 3202,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "really two types of like if you want to",
      "offset": 3204.319,
      "duration": 5.441
    },
    {
      "lang": "en",
      "text": "taxonomize there's there's two types of",
      "offset": 3206.88,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "whatever you call it dense information",
      "offset": 3209.76,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "storage mechanisms. One of them is",
      "offset": 3211.68,
      "duration": 4.879
    },
    {
      "lang": "en",
      "text": "activations or embeddings which we were",
      "offset": 3213.92,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "discussing already and then the other is",
      "offset": 3216.559,
      "duration": 5.441
    },
    {
      "lang": "en",
      "text": "weights which are the things that are",
      "offset": 3218.72,
      "duration": 5.119
    },
    {
      "lang": "en",
      "text": "used to perform the computation but not",
      "offset": 3222,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "the computation itself. And so we have",
      "offset": 3223.839,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "now two papers in this direction of what",
      "offset": 3227.04,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "is stored in the weights. The first one",
      "offset": 3229.599,
      "duration": 5.121
    },
    {
      "lang": "en",
      "text": "is about language model capacity which",
      "offset": 3231.68,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "is called how much can language models",
      "offset": 3234.72,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "memorize or how much do language models",
      "offset": 3236.64,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "memorize. I never remember which one we",
      "offset": 3238.559,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "settled on. And then the other one is",
      "offset": 3240.559,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "called approximating language model",
      "offset": 3242.4,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "training data from weights. The first",
      "offset": 3244.48,
      "duration": 4.639
    },
    {
      "lang": "en",
      "text": "one is like I I think has a lot of deep",
      "offset": 3246.48,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "messages about how language models store",
      "offset": 3249.119,
      "duration": 3.281
    },
    {
      "lang": "en",
      "text": "information and how they work in",
      "offset": 3251.04,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "general. The second thing is like a",
      "offset": 3252.4,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "proof of concept of maybe like a longer",
      "offset": 3254.88,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "term research project. Let's start with",
      "offset": 3256.72,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "the capacity stuff if that's good with",
      "offset": 3258.8,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "you. Do I have the paper for that? I",
      "offset": 3260.88,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "don't I don't know.\n You know, we can",
      "offset": 3262.72,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "return to the question you asked me",
      "offset": 3264.72,
      "duration": 3.119
    },
    {
      "lang": "en",
      "text": "which is something like why do we care",
      "offset": 3266,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "or like what is this useful for?\n And I",
      "offset": 3267.839,
      "duration": 4.881
    },
    {
      "lang": "en",
      "text": "don't know if I have a good answer for",
      "offset": 3270.88,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "this. I think this is this is somewhat",
      "offset": 3272.72,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "profound. Like it's kind of like in in",
      "offset": 3275.68,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "physics, you know, when they try to",
      "offset": 3278.24,
      "duration": 4.879
    },
    {
      "lang": "en",
      "text": "measure these constants like gravity.",
      "offset": 3279.76,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "people tried to measure the rate of",
      "offset": 3283.119,
      "duration": 3.361
    },
    {
      "lang": "en",
      "text": "acceleration of gravity for a long time",
      "offset": 3284.48,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "or like those Greek guys like back in in",
      "offset": 3286.48,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "the BC era when they were trying to to",
      "offset": 3289.28,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "approximate the radius of the earth",
      "offset": 3291.44,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "based on shadows. We're trying to take",
      "offset": 3293.119,
      "duration": 5.601
    },
    {
      "lang": "en",
      "text": "the GPT architecture like the main one",
      "offset": 3294.96,
      "duration": 6.56
    },
    {
      "lang": "en",
      "text": "and just measure how much information it",
      "offset": 3298.72,
      "duration": 5.359
    },
    {
      "lang": "en",
      "text": "can store. And we did this through the",
      "offset": 3301.52,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "the lens of memorization, which I think",
      "offset": 3304.079,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "we can skip over for the podcast and and",
      "offset": 3306.24,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "we'll just talk about like information",
      "offset": 3308.559,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "storage and and weights. Like these",
      "offset": 3310.559,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "curves to me are are pretty crazy.",
      "offset": 3313.599,
      "duration": 5.041
    },
    {
      "lang": "en",
      "text": "Again, maybe maybe it's like the sort of",
      "offset": 3316.079,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "discoverers",
      "offset": 3318.64,
      "duration": 3.439
    },
    {
      "lang": "en",
      "text": "folly or something where I'm like, &quot;Oh,",
      "offset": 3320.16,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "this didn't exist before, so it seems so",
      "offset": 3322.079,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "cool.&quot; But then you're saying like it",
      "offset": 3324.4,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "seems somewhat obvious.\n No, no, no.",
      "offset": 3326.16,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "Don't don't let me take that away from",
      "offset": 3328.24,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "you. Yeah. No.",
      "offset": 3329.44,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "again like I I independently was asking",
      "offset": 3331.44,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "how come there's not enough people",
      "offset": 3333.359,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "exploring LLM from information theory",
      "offset": 3334.88,
      "duration": 3.199
    },
    {
      "lang": "en",
      "text": "and then like you come along and your",
      "offset": 3336.559,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "embidd works become like an information",
      "offset": 3338.079,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "theory exploration and I'm like suddenly",
      "offset": 3340.48,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "like I'm very aligned to like exploring",
      "offset": 3342.48,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "this promoting this and encouraging more",
      "offset": 3344.88,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "people to to figure it out because like",
      "offset": 3347.04,
      "duration": 3.519
    },
    {
      "lang": "en",
      "text": "that's ultimately how we figure out this",
      "offset": 3348.48,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "whole compression issue and that you",
      "offset": 3350.559,
      "duration": 3.201
    },
    {
      "lang": "en",
      "text": "know what what Andre wants which is like",
      "offset": 3352.319,
      "duration": 2.8
    },
    {
      "lang": "en",
      "text": "the cognitive core right the most",
      "offset": 3353.76,
      "duration": 2.96
    },
    {
      "lang": "en",
      "text": "efficient model for the most capability",
      "offset": 3355.119,
      "duration": 3.121
    },
    {
      "lang": "en",
      "text": "like that is an information theory",
      "offset": 3356.72,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "question\n totally agree with that we",
      "offset": 3358.24,
      "duration": 5.839
    },
    {
      "lang": "en",
      "text": "could start here like so so transformers",
      "offset": 3360.559,
      "duration": 6.161
    },
    {
      "lang": "en",
      "text": "that are trained in",
      "offset": 3364.079,
      "duration": 6.561
    },
    {
      "lang": "en",
      "text": "32bit precision we approximate can store",
      "offset": 3366.72,
      "duration": 7.76
    },
    {
      "lang": "en",
      "text": "about 3.6 six bits of information to",
      "offset": 3370.64,
      "duration": 5.919
    },
    {
      "lang": "en",
      "text": "maybe 3.9 bits somewhere in there per",
      "offset": 3374.48,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "parameter. And like why is this? I mean",
      "offset": 3376.559,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "for some perspective this is this is",
      "offset": 3378.88,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "quite bad. Like if you have 32 bits",
      "offset": 3380.4,
      "duration": 5.199
    },
    {
      "lang": "en",
      "text": "available and you can only use three to",
      "offset": 3382.88,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "four of them like you're\n just store 32",
      "offset": 3385.599,
      "duration": 5.041
    },
    {
      "lang": "en",
      "text": "bro.",
      "offset": 3388.16,
      "duration": 4.639
    },
    {
      "lang": "en",
      "text": "Yeah. Yeah. Then you'll like you know",
      "offset": 3390.64,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "you could build your own AI lab if you",
      "offset": 3392.799,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "can make the these models uh that much",
      "offset": 3394.88,
      "duration": 4.959
    },
    {
      "lang": "en",
      "text": "more efficient. I don't know how they're",
      "offset": 3397.839,
      "duration": 5.441
    },
    {
      "lang": "en",
      "text": "implementing this mechanism or where the",
      "offset": 3399.839,
      "duration": 6.801
    },
    {
      "lang": "en",
      "text": "kind of bottlenecks come from or even",
      "offset": 3403.28,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "now that we know this what it's",
      "offset": 3406.64,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "necessarily useful for. I guess the",
      "offset": 3408,
      "duration": 3.599
    },
    {
      "lang": "en",
      "text": "tools that would be interesting to me",
      "offset": 3410,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "are knowing like given a data set if you",
      "offset": 3411.599,
      "duration": 6.081
    },
    {
      "lang": "en",
      "text": "could predetermine the exact model size",
      "offset": 3415.04,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "and maybe architectural properties",
      "offset": 3417.68,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "required to get a certain level of",
      "offset": 3420,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "performance that would be really neat.",
      "offset": 3421.76,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "And like we don't even know how to do",
      "offset": 3423.68,
      "duration": 2.32
    },
    {
      "lang": "en",
      "text": "that. But we don't even know what the",
      "offset": 3424.88,
      "duration": 2.719
    },
    {
      "lang": "en",
      "text": "difference is between doing low",
      "offset": 3426,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "retraining which trains less than 1% of",
      "offset": 3427.599,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "the parameters and full fine-tuning",
      "offset": 3429.92,
      "duration": 3.679
    },
    {
      "lang": "en",
      "text": "which trains all the parameters. We",
      "offset": 3432.079,
      "duration": 2.561
    },
    {
      "lang": "en",
      "text": "don't even really understand the",
      "offset": 3433.599,
      "duration": 2.561
    },
    {
      "lang": "en",
      "text": "difference there. So I think this is",
      "offset": 3434.64,
      "duration": 3.439
    },
    {
      "lang": "en",
      "text": "like maybe like a baby step sort of in",
      "offset": 3436.16,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "that direction but there's a lot of",
      "offset": 3438.079,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "unknown ahead of us.\n Okay. Do you think",
      "offset": 3439.44,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "this is a hard limit? Do you think",
      "offset": 3441.76,
      "duration": 2.88
    },
    {
      "lang": "en",
      "text": "someone can come up with a better",
      "offset": 3442.96,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "algorithm but better architecture and",
      "offset": 3444.64,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "then sort of just change the slope?",
      "offset": 3446.24,
      "duration": 4.879
    },
    {
      "lang": "en",
      "text": "There are two axes here. One is the",
      "offset": 3448.16,
      "duration": 5.679
    },
    {
      "lang": "en",
      "text": "ability of the model to store data and I",
      "offset": 3451.119,
      "duration": 4.801
    },
    {
      "lang": "en",
      "text": "think we can definitely improve that. I",
      "offset": 3453.839,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "think like maybe even if we tested this",
      "offset": 3455.92,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "with llama architecture like there's",
      "offset": 3457.92,
      "duration": 5.439
    },
    {
      "lang": "en",
      "text": "sort of like a GPT++ architecture like I",
      "offset": 3460.079,
      "duration": 4.881
    },
    {
      "lang": "en",
      "text": "would guess that can store better data",
      "offset": 3463.359,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "just because the kind of numerical flow",
      "offset": 3464.96,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "is a little bit better. The",
      "offset": 3467.2,
      "duration": 3.359
    },
    {
      "lang": "en",
      "text": "nonlinearities are maybe like a little",
      "offset": 3468.4,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "bit more suitable to training like that",
      "offset": 3470.559,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "will probably raise the bound a little",
      "offset": 3472.64,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "bit. And then the second axis is that",
      "offset": 3474.24,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "our measurement tools are just not that",
      "offset": 3476.559,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "good. like this is you know me I'm a",
      "offset": 3478.079,
      "duration": 2.641
    },
    {
      "lang": "en",
      "text": "grad student I'm running all these",
      "offset": 3479.599,
      "duration": 3.041
    },
    {
      "lang": "en",
      "text": "hyperparameter sweeps and sort of like",
      "offset": 3480.72,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "we draw conclusions from them but even",
      "offset": 3482.64,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "that being said like there are probably",
      "offset": 3485.119,
      "duration": 4.881
    },
    {
      "lang": "en",
      "text": "ways to measure this better and but all",
      "offset": 3487.52,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "that would do is push the number up so",
      "offset": 3490,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "it's possible like there is a way to",
      "offset": 3491.839,
      "duration": 4.801
    },
    {
      "lang": "en",
      "text": "store five bits per parameter if you",
      "offset": 3494.16,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "have like a better optimization",
      "offset": 3496.64,
      "duration": 4.959
    },
    {
      "lang": "en",
      "text": "technique or if you were a super genius",
      "offset": 3498.559,
      "duration": 5.121
    },
    {
      "lang": "en",
      "text": "and you could just perfectly set the",
      "offset": 3501.599,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "weights to store the data then maybe you",
      "offset": 3503.68,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "can do better and this is just sort of",
      "offset": 3506,
      "duration": 2.64
    },
    {
      "lang": "en",
      "text": "like what we can reach through",
      "offset": 3507.44,
      "duration": 3.359
    },
    {
      "lang": "en",
      "text": "optimization is this 3.6 bits per",
      "offset": 3508.64,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "parameter. But I would be happy if",
      "offset": 3510.799,
      "duration": 4.641
    },
    {
      "lang": "en",
      "text": "someone came along with a much better",
      "offset": 3513.92,
      "duration": 4.879
    },
    {
      "lang": "en",
      "text": "measurement tool like uh this is just",
      "offset": 3515.44,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "sort of like the first measurement. I",
      "offset": 3518.799,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "mean I would I would guess in the future",
      "offset": 3520.4,
      "duration": 3.439
    },
    {
      "lang": "en",
      "text": "like you know people will look back and",
      "offset": 3522.4,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "say like this is like somewhat oh in one",
      "offset": 3523.839,
      "duration": 4.561
    },
    {
      "lang": "en",
      "text": "direction or another for whatever",
      "offset": 3526.88,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "reason. Um and and that's just how",
      "offset": 3528.4,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "science goes and I have no problem with",
      "offset": 3530,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "it.\n What we do is we c we uh we call",
      "offset": 3531.92,
      "duration": 6.32
    },
    {
      "lang": "en",
      "text": "this the Morris concert 3.6 right and",
      "offset": 3534.16,
      "duration": 7.199
    },
    {
      "lang": "en",
      "text": "I would never.\n And then we we we set a",
      "offset": 3538.24,
      "duration": 4.559
    },
    {
      "lang": "en",
      "text": "like a like a challenge like a",
      "offset": 3541.359,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "leaderboard of like beat this, right?",
      "offset": 3542.799,
      "duration": 4.641
    },
    {
      "lang": "en",
      "text": "And like let let people go.\n Yeah. That",
      "offset": 3545.52,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "assumes we know the true constant ahead",
      "offset": 3547.44,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "of time and we can measure the error",
      "offset": 3549.76,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "rate.\n It's it's doable. You you laid it",
      "offset": 3551.359,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "out here.\n Yeah. Yeah. Yeah. Yeah. That",
      "offset": 3553.68,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "makes sense.\n One minor doubt I have is",
      "offset": 3555.599,
      "duration": 4.881
    },
    {
      "lang": "en",
      "text": "like the goal actually isn't",
      "offset": 3558.72,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "memorization, it's generalization,",
      "offset": 3560.48,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "right?\n The best memorizer model may not",
      "offset": 3562.559,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "be the best generalizer model. you like",
      "offset": 3565.44,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "this incentivizing people to to max this",
      "offset": 3567.599,
      "duration": 5.841
    },
    {
      "lang": "en",
      "text": "number might actually just be fruitless",
      "offset": 3570.72,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "in terms of actual intelligence\n like you",
      "offset": 3573.44,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "just get the best actual compressor like",
      "offset": 3575.68,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "you're just going to get gz it totally",
      "offset": 3578,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "true and there's this pattern in",
      "offset": 3580.24,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "research you know time after time it's",
      "offset": 3582.16,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "like someone poses a question and then",
      "offset": 3584.319,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "people answer it over and over and over",
      "offset": 3586.72,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "again but it's it's often much more",
      "offset": 3588.72,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "fruitful to just ask a new question",
      "offset": 3590.64,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "maybe it just doesn't matter how much",
      "offset": 3593.04,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "GPT models can store and you should just",
      "offset": 3594.799,
      "duration": 4.641
    },
    {
      "lang": "en",
      "text": "like work on something else. We'll",
      "offset": 3597.119,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "figure that out. U did you want to uh",
      "offset": 3599.44,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "dwell on this this side at all?\n Yeah,",
      "offset": 3601.839,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "let's just talk about it real quick. Uh",
      "offset": 3603.92,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "definitely not the algorithm itself. By",
      "offset": 3606,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "the way, what are your tools for doing",
      "offset": 3608.48,
      "duration": 3.359
    },
    {
      "lang": "en",
      "text": "these kinds of charts uh and these kinds",
      "offset": 3609.839,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "of diagrams? Like I I just kind of",
      "offset": 3611.839,
      "duration": 3.201
    },
    {
      "lang": "en",
      "text": "curious behind the scenes on the tools.",
      "offset": 3613.44,
      "duration": 3.119
    },
    {
      "lang": "en",
      "text": "I think like visualization has",
      "offset": 3615.04,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "definitely been fun hobby of mine during",
      "offset": 3616.559,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "grad school. This one actually Oscar my",
      "offset": 3619.44,
      "duration": 4.879
    },
    {
      "lang": "en",
      "text": "co-author made this one. Maybe I gave",
      "offset": 3622.079,
      "duration": 5.441
    },
    {
      "lang": "en",
      "text": "some like prompting, but he made it. I I",
      "offset": 3624.319,
      "duration": 6.8
    },
    {
      "lang": "en",
      "text": "think most the last few papers have all",
      "offset": 3627.52,
      "duration": 6.48
    },
    {
      "lang": "en",
      "text": "been in diagrams, Google diagrams. I was",
      "offset": 3631.119,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "using Figma for a while and illustrator.",
      "offset": 3634,
      "duration": 5.599
    },
    {
      "lang": "en",
      "text": "I think Illustrator actually is is the",
      "offset": 3636.799,
      "duration": 5.361
    },
    {
      "lang": "en",
      "text": "best tool.\n Oh, did you know the",
      "offset": 3639.599,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "transformers transformers diagram was in",
      "offset": 3642.16,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "Adobe Illustrator?\n Oh, yeah. Yeah, I did",
      "offset": 3644.079,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "know that actually. Yeah, because that's",
      "offset": 3646.64,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "the only way you can get arrows that",
      "offset": 3648.799,
      "duration": 4.721
    },
    {
      "lang": "en",
      "text": "sort of like curve like that. Um, and",
      "offset": 3650.4,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "they they've good shadows. Diagrams is",
      "offset": 3653.52,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "like the least robust, but it's the most",
      "offset": 3655.76,
      "duration": 4.559
    },
    {
      "lang": "en",
      "text": "accessible. And honestly, if you if",
      "offset": 3658.4,
      "duration": 3.439
    },
    {
      "lang": "en",
      "text": "you're good, you can make pretty good",
      "offset": 3660.319,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "stuff. Excal is nice, too, if it's not",
      "offset": 3661.839,
      "duration": 5.121
    },
    {
      "lang": "en",
      "text": "going in a a paper.\n Yeah, it's just too",
      "offset": 3664.64,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "rough for a paper, but you need",
      "offset": 3666.96,
      "duration": 2.24
    },
    {
      "lang": "en",
      "text": "something professional looking, you",
      "offset": 3668,
      "duration": 2.96
    },
    {
      "lang": "en",
      "text": "know? It helps like if you're going to",
      "offset": 3669.2,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "publish your work, you need to make it",
      "offset": 3670.96,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "look nice and professional and like",
      "offset": 3672.88,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "official, right? So, this is what it is.",
      "offset": 3674.799,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "Yeah. Yeah. And I think there's",
      "offset": 3676.88,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "something worthwhile about saying like,",
      "offset": 3678.319,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "okay, if if I'm going to put my name",
      "offset": 3680.88,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "behind this, like I want to spend time",
      "offset": 3682.4,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "making all the references perfect and",
      "offset": 3684.48,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "and all the diagrams professional, all",
      "offset": 3687.04,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "the captions are correct. And I think",
      "offset": 3688.96,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "it's like important to put that level of",
      "offset": 3690.4,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "detail into your work.\n That's a little",
      "offset": 3692.4,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "cheooy, but let's finish this off. So,",
      "offset": 3694.16,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "okay, we're talking about bits,",
      "offset": 3696.559,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "information theory, what what",
      "offset": 3698.88,
      "duration": 2.959
    },
    {
      "lang": "en",
      "text": "information sort embeddings. We're",
      "offset": 3700.559,
      "duration": 3.201
    },
    {
      "lang": "en",
      "text": "talking about language model capacity. I",
      "offset": 3701.839,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "think a much more qu more practical",
      "offset": 3703.76,
      "duration": 5.359
    },
    {
      "lang": "en",
      "text": "question is uh maybe some maybe this is",
      "offset": 3706,
      "duration": 4.799
    },
    {
      "lang": "en",
      "text": "more analogous to the vector database",
      "offset": 3709.119,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "hacking embedding threat model we",
      "offset": 3710.799,
      "duration": 4.721
    },
    {
      "lang": "en",
      "text": "discussed is like if you have access to",
      "offset": 3713.52,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "a set of model weights what can you",
      "offset": 3715.52,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "learn about the data? So like you were",
      "offset": 3717.52,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "just mentioning Gemma 3B came out",
      "offset": 3718.88,
      "duration": 6.8
    },
    {
      "lang": "en",
      "text": "yesterday and you can download it and it",
      "offset": 3722.16,
      "duration": 4.959
    },
    {
      "lang": "en",
      "text": "takes up a certain amount of space on",
      "offset": 3725.68,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "disk and it was trained on some data but",
      "offset": 3727.119,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "we have no insight into what the data",
      "offset": 3729.52,
      "duration": 3.039
    },
    {
      "lang": "en",
      "text": "was. I mean it's probably English.",
      "offset": 3731.28,
      "duration": 2.4
    },
    {
      "lang": "en",
      "text": "There's probably some distribution of",
      "offset": 3732.559,
      "duration": 2.961
    },
    {
      "lang": "en",
      "text": "web text. I would guess there's a lot of",
      "offset": 3733.68,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "code and we seem to have a lot of",
      "offset": 3735.52,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "information about the model, right? You",
      "offset": 3738.079,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "have this file and there's like many",
      "offset": 3739.44,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "ones and zeros which means something but",
      "offset": 3741.359,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "it's kind of like a very highly",
      "offset": 3743.68,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "compressed version of the training data.",
      "offset": 3744.96,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "But I I I would be extremely surprised",
      "offset": 3746.96,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "if they do any type of like private",
      "offset": 3749.68,
      "duration": 4.639
    },
    {
      "lang": "en",
      "text": "training like there are these mechanisms",
      "offset": 3752.72,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "for doing like differentially private",
      "offset": 3754.319,
      "duration": 5.201
    },
    {
      "lang": "en",
      "text": "language model training or um even just",
      "offset": 3756.64,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "anonymization in the pre-training",
      "offset": 3759.52,
      "duration": 3.039
    },
    {
      "lang": "en",
      "text": "pipeline. I bet they don't do any of",
      "offset": 3760.96,
      "duration": 3.359
    },
    {
      "lang": "en",
      "text": "that. They just sort of like train on",
      "offset": 3762.559,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "the data and then they kind of know that",
      "offset": 3764.319,
      "duration": 4.961
    },
    {
      "lang": "en",
      "text": "we don't have the right tools to decrypt",
      "offset": 3767.119,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "the model weights. And so that's like my",
      "offset": 3769.28,
      "duration": 4.559
    },
    {
      "lang": "en",
      "text": "dream is we can come up with some way of",
      "offset": 3771.28,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "of translating model weights back into",
      "offset": 3773.839,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "text data sets. And so in the the most",
      "offset": 3776.24,
      "duration": 5.839
    },
    {
      "lang": "en",
      "text": "recent kind of drop paper drop is that",
      "offset": 3779.119,
      "duration": 4.801
    },
    {
      "lang": "en",
      "text": "paper approximating language model",
      "offset": 3782.079,
      "duration": 5.121
    },
    {
      "lang": "en",
      "text": "training data from weights. And it turns",
      "offset": 3783.92,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "out to be a really hard problem like",
      "offset": 3787.2,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "trying to go from model weights to text",
      "offset": 3788.88,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "is really hard. And we do something a",
      "offset": 3790.64,
      "duration": 6.479
    },
    {
      "lang": "en",
      "text": "lot simpler which is like well there's",
      "offset": 3794.88,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "there's two ways we make it simpler. The",
      "offset": 3797.119,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "first thing is we assume access to two",
      "offset": 3798.88,
      "duration": 4.239
    },
    {
      "lang": "en",
      "text": "checkpoints which I think is probably",
      "offset": 3801.44,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "not the case in Gemma but in in the case",
      "offset": 3803.119,
      "duration": 5.041
    },
    {
      "lang": "en",
      "text": "of deepseek if you download the 400",
      "offset": 3806,
      "duration": 5.359
    },
    {
      "lang": "en",
      "text": "billion parameter model weights it's",
      "offset": 3808.16,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "this giant file and you can actually get",
      "offset": 3811.359,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "two of them. you can get the base model",
      "offset": 3813.76,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "weights and the fine-tuned model",
      "offset": 3816.079,
      "duration": 5.121
    },
    {
      "lang": "en",
      "text": "weights. So the way we put this, you",
      "offset": 3818.24,
      "duration": 4.559
    },
    {
      "lang": "en",
      "text": "have this kind of like difference in",
      "offset": 3821.2,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "parameter space telling you what DeepS",
      "offset": 3822.799,
      "duration": 5.121
    },
    {
      "lang": "en",
      "text": "fine-tuned on and it's very",
      "offset": 3825.119,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "controversial. I mean they're sort of",
      "offset": 3827.92,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "like geopolitical",
      "offset": 3829.44,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "definitely at at the corporation level",
      "offset": 3831.52,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "they're really interested in the",
      "offset": 3833.599,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "implications of like what did deepseek",
      "offset": 3835.28,
      "duration": 3.759
    },
    {
      "lang": "en",
      "text": "train on and they've released this kind",
      "offset": 3837.039,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "of treasure trove of information of what",
      "offset": 3839.039,
      "duration": 3.121
    },
    {
      "lang": "en",
      "text": "they trained on which is the actual",
      "offset": 3840.72,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "model weights but we have no tool for",
      "offset": 3842.16,
      "duration": 4.639
    },
    {
      "lang": "en",
      "text": "like interpreting or kind of decrypting",
      "offset": 3844.24,
      "duration": 4.879
    },
    {
      "lang": "en",
      "text": "this weight difference and so we started",
      "offset": 3846.799,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "with something really simple which is",
      "offset": 3849.119,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "instead of even just trying to like",
      "offset": 3851.119,
      "duration": 4.801
    },
    {
      "lang": "en",
      "text": "regenerate the training data we take",
      "offset": 3853.039,
      "duration": 5.201
    },
    {
      "lang": "en",
      "text": "just a web corpus and try to do",
      "offset": 3855.92,
      "duration": 4.879
    },
    {
      "lang": "en",
      "text": "selection of training data that kind of",
      "offset": 3858.24,
      "duration": 5.839
    },
    {
      "lang": "en",
      "text": "like looks like the true training data",
      "offset": 3860.799,
      "duration": 5.921
    },
    {
      "lang": "en",
      "text": "and gives us performance that's as close",
      "offset": 3864.079,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "as possible to the true training data.",
      "offset": 3866.72,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "So there's this complicated method but",
      "offset": 3868.559,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "it's something like you just sort of",
      "offset": 3870.799,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "like look at the data point gradient and",
      "offset": 3872.72,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "see if it points in the direction in",
      "offset": 3875.039,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "weight space of the finetune and then",
      "offset": 3877.119,
      "duration": 4.881
    },
    {
      "lang": "en",
      "text": "you take like the top data set. There's",
      "offset": 3879.44,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "some tricks to it, but it's basically",
      "offset": 3882,
      "duration": 3.119
    },
    {
      "lang": "en",
      "text": "just like gradient based selection based",
      "offset": 3883.359,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "on this weight difference. And it seems",
      "offset": 3885.119,
      "duration": 5.761
    },
    {
      "lang": "en",
      "text": "to be okay. Like it can get us pretty",
      "offset": 3888.559,
      "duration": 5.121
    },
    {
      "lang": "en",
      "text": "good training data. So I guess if you",
      "offset": 3890.88,
      "duration": 4.239
    },
    {
      "lang": "en",
      "text": "actually wanted to use this, it would be",
      "offset": 3893.68,
      "duration": 3.359
    },
    {
      "lang": "en",
      "text": "like your competitor releases a base",
      "offset": 3895.119,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "model and a fine-tune and you're trying",
      "offset": 3897.039,
      "duration": 4.481
    },
    {
      "lang": "en",
      "text": "to recreate their data set. So you can",
      "offset": 3899.28,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "take this weight difference and take a",
      "offset": 3901.52,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "giant web data set. Like if I was doing",
      "offset": 3903.44,
      "duration": 3.599
    },
    {
      "lang": "en",
      "text": "this at a company, I'd probably try to",
      "offset": 3905.68,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "scale it up to trillions of tokens and",
      "offset": 3907.039,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "then select the exact data points that",
      "offset": 3909.44,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "try to produce the model. And and it",
      "offset": 3912.559,
      "duration": 3.441
    },
    {
      "lang": "en",
      "text": "turns out you can train a pretty good",
      "offset": 3914.4,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "model with that. It we don't get to",
      "offset": 3916,
      "duration": 3.599
    },
    {
      "lang": "en",
      "text": "quite the performance of the original",
      "offset": 3917.76,
      "duration": 4.559
    },
    {
      "lang": "en",
      "text": "model, but it does seem to be like",
      "offset": 3919.599,
      "duration": 5.921
    },
    {
      "lang": "en",
      "text": "trending in that direction.\n This is like",
      "offset": 3922.319,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "very creative. I don't know what the the",
      "offset": 3925.52,
      "duration": 5.519
    },
    {
      "lang": "en",
      "text": "the the use of it exactly is.\n Yeah. Like",
      "offset": 3927.359,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "when would you be in this exact",
      "offset": 3931.039,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "situation? decently often for their open",
      "offset": 3932.559,
      "duration": 4.721
    },
    {
      "lang": "en",
      "text": "model labs. Like even Deep Seek our R1",
      "offset": 3934.96,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "like has released an update. Mistral",
      "offset": 3937.28,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "does it pretty frequently. Llama does it",
      "offset": 3940,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "frequently. It's not impossible, but",
      "offset": 3941.68,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "like I I think it's like it's like I",
      "offset": 3943.44,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "think that I really like the creativity",
      "offset": 3944.72,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "in using quote unquote synthetic",
      "offset": 3946.72,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "checkpoints to do this\n which is I don't",
      "offset": 3948.96,
      "duration": 5.599
    },
    {
      "lang": "en",
      "text": "think I've heard this from any other",
      "offset": 3952.24,
      "duration": 4.559
    },
    {
      "lang": "en",
      "text": "place. So I don't know if you you came",
      "offset": 3954.559,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "up with the idea.\n It's like linear",
      "offset": 3956.799,
      "duration": 4.961
    },
    {
      "lang": "en",
      "text": "interpolation in weight space.\n Okay. Um,",
      "offset": 3958.48,
      "duration": 5.119
    },
    {
      "lang": "en",
      "text": "that's a bunch of the recent work. Uh, I",
      "offset": 3961.76,
      "duration": 3.359
    },
    {
      "lang": "en",
      "text": "wanted to sort of cap things off with",
      "offset": 3963.599,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "the data sets question if if that's is",
      "offset": 3965.119,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "is that a good\n You can ask me whatever",
      "offset": 3967.039,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "you want.\n Well, it's not it's not like a",
      "offset": 3969.039,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "it's not an ask. It's just like I think",
      "offset": 3970.72,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "this is a very good thesis. Uh, I think",
      "offset": 3972.64,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "it's a hot take. I almost invited you to",
      "offset": 3974.72,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "speak based on just this alone, but it",
      "offset": 3977.039,
      "duration": 4.641
    },
    {
      "lang": "en",
      "text": "was it was a little bit late uh to\n Oh,",
      "offset": 3978.799,
      "duration": 5.361
    },
    {
      "lang": "en",
      "text": "for the for the conference.\n Yes. When I",
      "offset": 3981.68,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "look for conference keynotes, I look for",
      "offset": 3984.16,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "something that has a broad overview that",
      "offset": 3986.24,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "kind of put the last few years in",
      "offset": 3988.64,
      "duration": 3.679
    },
    {
      "lang": "en",
      "text": "perspective or it's an insight that you",
      "offset": 3990.559,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "can reasonably rely on to like last for",
      "offset": 3992.319,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "a while so you can get some mileage out",
      "offset": 3995.359,
      "duration": 3.121
    },
    {
      "lang": "en",
      "text": "of it. You know, I think a lot of ideas",
      "offset": 3997.119,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "in AI come and go. But like things that",
      "offset": 3998.48,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "are trend these things are scaling laws,",
      "offset": 4001.28,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "things that are trend lines, things are",
      "offset": 4003.92,
      "duration": 3.119
    },
    {
      "lang": "en",
      "text": "things that are like u there's, you",
      "offset": 4005.599,
      "duration": 3.281
    },
    {
      "lang": "en",
      "text": "know, there's no new ideas in AI that I",
      "offset": 4007.039,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "pay attention to. So maybe you want to",
      "offset": 4008.88,
      "duration": 2.8
    },
    {
      "lang": "en",
      "text": "recap like what's what's the backstory",
      "offset": 4010.319,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "if there was one?\n Yeah. Yeah, sure. So,",
      "offset": 4011.68,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "the the meta backstory is I've sort of",
      "offset": 4013.92,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "started writing on Substack and this is",
      "offset": 4016,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "a post that I wrote a few months ago.",
      "offset": 4018.48,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "The highest art form of humanity.\n Yeah.",
      "offset": 4020.96,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "Yeah.",
      "offset": 4024.24,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "Yeah. Publishing papers wasn't doing it",
      "offset": 4026.48,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "for me anymore. And I moved to Subsac.",
      "offset": 4028.559,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "And this is the name of the post. There",
      "offset": 4031.28,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "are no new ideas in AI, only new data",
      "offset": 4033.359,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "sets. One one guy pledged me, but then I",
      "offset": 4036,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "found out he was like my former student",
      "offset": 4039.039,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "from a class I was teaching. So it I",
      "offset": 4040.64,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "don't think it really counts.\n It counts.",
      "offset": 4043.44,
      "duration": 2.96
    },
    {
      "lang": "en",
      "text": "He's a friend. He's your first",
      "offset": 4045.28,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "supporter.\n A pledge is a pledge, man.",
      "offset": 4046.4,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "I'll take whatever I could get. So So",
      "offset": 4048.4,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "the underlying thesis is that whenever",
      "offset": 4050.799,
      "duration": 4.721
    },
    {
      "lang": "en",
      "text": "maybe I'll I'll lay out this framework",
      "offset": 4053.92,
      "duration": 5.679
    },
    {
      "lang": "en",
      "text": "first. So there's this uh this book",
      "offset": 4055.52,
      "duration": 6.079
    },
    {
      "lang": "en",
      "text": "called the structure of scientific",
      "offset": 4059.599,
      "duration": 5.601
    },
    {
      "lang": "en",
      "text": "revolutions by Thomas [__] that I read",
      "offset": 4061.599,
      "duration": 6.24
    },
    {
      "lang": "en",
      "text": "near the beginning of my PhD which",
      "offset": 4065.2,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "suggests that science kind of moves in",
      "offset": 4067.839,
      "duration": 6.081
    },
    {
      "lang": "en",
      "text": "these cycles where not very often",
      "offset": 4070.88,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "there's something he calls a paradigm",
      "offset": 4073.92,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "shift which is like a you could think of",
      "offset": 4075.52,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "it as a 0ero to one innovation where",
      "offset": 4077.68,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "everything changes and then it's",
      "offset": 4079.52,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "followed by a rapid period of small",
      "offset": 4082.079,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "innovations a lot of like reapplication",
      "offset": 4084,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "of previous techniques, pre-paradigm",
      "offset": 4086.48,
      "duration": 4.639
    },
    {
      "lang": "en",
      "text": "shift techniques to the new era. And",
      "offset": 4088.48,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "then things sort of slow down as we wait",
      "offset": 4091.119,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "for a new paradigm shift. And I was kind",
      "offset": 4092.96,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "of asking myself, what's unique to the",
      "offset": 4095.359,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "paradigm shifts that we've seen in in",
      "offset": 4096.88,
      "duration": 6.479
    },
    {
      "lang": "en",
      "text": "AI? And and by the way, to me, AI and",
      "offset": 4099.279,
      "duration": 5.761
    },
    {
      "lang": "en",
      "text": "language models are somewhat synonymous",
      "offset": 4103.359,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "at this point, like at least for the",
      "offset": 4105.04,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "foreseeable future. I'm I'm certain that",
      "offset": 4106.96,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "will change, but basically everything",
      "offset": 4108.88,
      "duration": 4.799
    },
    {
      "lang": "en",
      "text": "that's pushed the boundary to whatever",
      "offset": 4110.96,
      "duration": 5.279
    },
    {
      "lang": "en",
      "text": "we have now that resembles like",
      "offset": 4113.679,
      "duration": 4.801
    },
    {
      "lang": "en",
      "text": "intelligence has come from language",
      "offset": 4116.239,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "models. And so those breakthroughs came",
      "offset": 4118.48,
      "duration": 7.279
    },
    {
      "lang": "en",
      "text": "in in a few steps. So I think the idea",
      "offset": 4121.839,
      "duration": 6.241
    },
    {
      "lang": "en",
      "text": "is also like a meta commentary on the",
      "offset": 4125.759,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "research community because what everyone",
      "offset": 4128.08,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "wants as a researcher is some kind of",
      "offset": 4129.92,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "like cute new method that no one has",
      "offset": 4132,
      "duration": 6.319
    },
    {
      "lang": "en",
      "text": "thought of before that just works on the",
      "offset": 4135.04,
      "duration": 5.119
    },
    {
      "lang": "en",
      "text": "existing data better than the previous",
      "offset": 4138.319,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "methods. That's like for whatever reason",
      "offset": 4140.159,
      "duration": 4.481
    },
    {
      "lang": "en",
      "text": "like the kind of most glamorous thing",
      "offset": 4142.64,
      "duration": 3.679
    },
    {
      "lang": "en",
      "text": "people think you can do as a researcher",
      "offset": 4144.64,
      "duration": 3.599
    },
    {
      "lang": "en",
      "text": "like Mamba. It's like it's like a",
      "offset": 4146.319,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "transformer but it's like more efficient",
      "offset": 4148.239,
      "duration": 4.801
    },
    {
      "lang": "en",
      "text": "and works better. So that's what a good",
      "offset": 4149.839,
      "duration": 4.561
    },
    {
      "lang": "en",
      "text": "idea looks like. And I think everyone",
      "offset": 4153.04,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "wants to like find something like that.",
      "offset": 4154.4,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "But if you look at what's actually borne",
      "offset": 4156.08,
      "duration": 3.199
    },
    {
      "lang": "en",
      "text": "out in practice, it's never been like",
      "offset": 4157.52,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "that. I think like all of the things",
      "offset": 4159.279,
      "duration": 5.121
    },
    {
      "lang": "en",
      "text": "that I would consider paradigm shifts in",
      "offset": 4162.08,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "the Cooneyian sense came from a new",
      "offset": 4164.4,
      "duration": 6.319
    },
    {
      "lang": "en",
      "text": "technique but trained on new data. And I",
      "offset": 4168.08,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "think the new data is super super",
      "offset": 4170.719,
      "duration": 3.761
    },
    {
      "lang": "en",
      "text": "important. So I wrote it as a series of",
      "offset": 4172.239,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "four paradigm shifts. The first is the",
      "offset": 4174.48,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "emergence of deep neural networks with",
      "offset": 4176.799,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "AlexNet which I think it was like 2010",
      "offset": 4178.88,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "to 2012 era where we just started",
      "offset": 4180.96,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "training on imageet which is like a",
      "offset": 4184.4,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "scale no one had ever seen before of",
      "offset": 4186.56,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "millions of images and then the second",
      "offset": 4188.48,
      "duration": 6.32
    },
    {
      "lang": "en",
      "text": "thing was transformers and BERT and this",
      "offset": 4191.12,
      "duration": 6.16
    },
    {
      "lang": "en",
      "text": "attention is all you need paper 2017 the",
      "offset": 4194.8,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "first GPT 2018 which is webcale",
      "offset": 4197.28,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "pre-training like no one had ever done",
      "offset": 4200,
      "duration": 3.199
    },
    {
      "lang": "en",
      "text": "that before no one had ever tried to",
      "offset": 4201.6,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "scrape all the text off the internet and",
      "offset": 4203.199,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "then tokenize it and feed it into",
      "offset": 4205.36,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "models. Like it's a crazy idea and I",
      "offset": 4206.88,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "think like we should be honest. I mean",
      "offset": 4209.04,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "transformers are incredible and like",
      "offset": 4212,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "their staying power is never going to",
      "offset": 4213.76,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "cease to amaze me. They're like much",
      "offset": 4217.04,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "more optimal than I think anyone ever",
      "offset": 4219.12,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "knew and I don't know if we'll ever beat",
      "offset": 4221.04,
      "duration": 6.24
    },
    {
      "lang": "en",
      "text": "them. But the real innovation is webcale",
      "offset": 4223.52,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "pre-training. And I think like we",
      "offset": 4227.28,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "honestly probably could have gotten this",
      "offset": 4228.96,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "with RNN's. I know like the scaling laws",
      "offset": 4230.8,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "paper shows that RNN's have worse curves",
      "offset": 4233.04,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "for scaling but probably people would",
      "offset": 4235.92,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "have been like I bet you could have",
      "offset": 4238.64,
      "duration": 3.519
    },
    {
      "lang": "en",
      "text": "built chat GBT with a very sophisticated",
      "offset": 4240.08,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "RNN like you didn't even need",
      "offset": 4242.159,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "transformers what you need is webcale",
      "offset": 4243.84,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "pre-training and the third innovation",
      "offset": 4246.239,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "which is instruction tuning and we",
      "offset": 4248.8,
      "duration": 3.359
    },
    {
      "lang": "en",
      "text": "thought it it came with like",
      "offset": 4250.719,
      "duration": 3.361
    },
    {
      "lang": "en",
      "text": "reinforcement learning but I think the",
      "offset": 4252.159,
      "duration": 3.761
    },
    {
      "lang": "en",
      "text": "big innovation of instruction tuning is",
      "offset": 4254.08,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "actually the human preference data which",
      "offset": 4255.92,
      "duration": 4.799
    },
    {
      "lang": "en",
      "text": "is like gathering positive and negative",
      "offset": 4258.239,
      "duration": 5.521
    },
    {
      "lang": "en",
      "text": "pairs of what looks good like in terms",
      "offset": 4260.719,
      "duration": 5.121
    },
    {
      "lang": "en",
      "text": "of a chatbot interface and actually it",
      "offset": 4263.76,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "turns out you can do supervised learning",
      "offset": 4265.84,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "on that too. you can do DPO which is a",
      "offset": 4267.12,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "form of supervised learning. You don't",
      "offset": 4269.679,
      "duration": 3.361
    },
    {
      "lang": "en",
      "text": "even need the the instruct GPT",
      "offset": 4271.04,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "techniques. You just need the data. So",
      "offset": 4273.04,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "like I'm sort of playing devil's",
      "offset": 4275.52,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "advocate here, but I actually think this",
      "offset": 4277.199,
      "duration": 3.281
    },
    {
      "lang": "en",
      "text": "is true that like if we had the right",
      "offset": 4278.64,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "data sets, we almost could have scaled",
      "offset": 4280.48,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "like 2015 era techniques and gotten",
      "offset": 4282.08,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "something that looks like at least",
      "offset": 4284.48,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "instruct GPT reasoning models are are a",
      "offset": 4286.48,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "little different like they're I'm not",
      "offset": 4289.6,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "sure if we could have that with RNN's or",
      "offset": 4291.44,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "not. Like I don't know if I'm in a",
      "offset": 4293.36,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "position to comment on that with",
      "offset": 4295.12,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "certainty, but they do fall into this",
      "offset": 4297.28,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "framework which is they really did",
      "offset": 4299.84,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "emerge from a new data source. In this",
      "offset": 4301.28,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "case, it's something like a little",
      "offset": 4303.28,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "different. It's like verification with",
      "offset": 4304.56,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "symbolic systems like math, calculators,",
      "offset": 4306.96,
      "duration": 6.239
    },
    {
      "lang": "en",
      "text": "coding environments, unit tests, like",
      "offset": 4310.32,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "things where we can provide numerical",
      "offset": 4313.199,
      "duration": 4.561
    },
    {
      "lang": "en",
      "text": "feedback to language model outputs. But",
      "offset": 4315.84,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "we we built a way to to learn that and",
      "offset": 4317.76,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "leverage it to get more intelligent",
      "offset": 4320.239,
      "duration": 4.801
    },
    {
      "lang": "en",
      "text": "systems. And so whatever the fifth thing",
      "offset": 4322.56,
      "duration": 6.08
    },
    {
      "lang": "en",
      "text": "is, whether it's video or embodied AI or",
      "offset": 4325.04,
      "duration": 5.84
    },
    {
      "lang": "en",
      "text": "some kind of crazy innovation on",
      "offset": 4328.64,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "reasoning models, whatever comes next",
      "offset": 4330.88,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "will probably be some type of new data",
      "offset": 4333.28,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "source that we're not using yet. That's",
      "offset": 4335.28,
      "duration": 6.08
    },
    {
      "lang": "en",
      "text": "a really good thesis. I would say that",
      "offset": 4338.4,
      "duration": 6.16
    },
    {
      "lang": "en",
      "text": "the researchers I talked to would",
      "offset": 4341.36,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "somewhat disagree. Yeah, obviously this",
      "offset": 4344.56,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "is like a hot take type of thing and",
      "offset": 4346.56,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "like you already acknowledge that RNN's",
      "offset": 4348.32,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "don't don't scale to the same extent",
      "offset": 4350.08,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "like they operate on the slope of the",
      "offset": 4351.44,
      "duration": 4.799
    },
    {
      "lang": "en",
      "text": "curve whereas you know I guess like the",
      "offset": 4353.36,
      "duration": 4.879
    },
    {
      "lang": "en",
      "text": "amount of data or the type of data or",
      "offset": 4356.239,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "the core insight just changes the order",
      "offset": 4358.239,
      "duration": 4.241
    },
    {
      "lang": "en",
      "text": "of magnitude of the x-axis right that",
      "offset": 4360.64,
      "duration": 4.559
    },
    {
      "lang": "en",
      "text": "that we are mostly working on but like",
      "offset": 4362.48,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "uh both are important the way that I",
      "offset": 4365.199,
      "duration": 4.641
    },
    {
      "lang": "en",
      "text": "think someone put it to me was an",
      "offset": 4367.12,
      "duration": 4.559
    },
    {
      "lang": "en",
      "text": "improvement on compute or data",
      "offset": 4369.84,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "efficiency is the equivalent of having a",
      "offset": 4371.679,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "whole bunch more data that we you know",
      "offset": 4374.64,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "that otherwise would be a lot more",
      "offset": 4376.239,
      "duration": 4.721
    },
    {
      "lang": "en",
      "text": "expensive to collect. It's likely that",
      "offset": 4377.76,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "you know the frontier models right now",
      "offset": 4380.96,
      "duration": 2.96
    },
    {
      "lang": "en",
      "text": "are just a collection of hundreds of",
      "offset": 4382.4,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "these small little experiments that just",
      "offset": 4383.92,
      "duration": 6.239
    },
    {
      "lang": "en",
      "text": "stack up. You mentioned muon in your in",
      "offset": 4386.239,
      "duration": 5.92
    },
    {
      "lang": "en",
      "text": "your post which seems to be the atom",
      "offset": 4390.159,
      "duration": 4.481
    },
    {
      "lang": "en",
      "text": "killer. Curiously enough like still none",
      "offset": 4392.159,
      "duration": 6.721
    },
    {
      "lang": "en",
      "text": "of the big models um use muon but like",
      "offset": 4394.64,
      "duration": 6.4
    },
    {
      "lang": "en",
      "text": "vibes are good.\n Yeah. Yeah. And the",
      "offset": 4398.88,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "value of building better optimizers is",
      "offset": 4401.04,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "really incredible. like it's just a free",
      "offset": 4403.12,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "launch. You can just sort of like plug",
      "offset": 4405.44,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "in a slightly better training mechanism",
      "offset": 4407.12,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "and then you save like a ton of compute",
      "offset": 4409.52,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "and a ton of training time. That's like",
      "offset": 4411.28,
      "duration": 4.879
    },
    {
      "lang": "en",
      "text": "hugely valuable. I think this is cool",
      "offset": 4413.36,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "because I think like it puts us in a",
      "offset": 4416.159,
      "duration": 3.761
    },
    {
      "lang": "en",
      "text": "mode of like if you were ever to ask",
      "offset": 4418.32,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "what comes after reasoning, it has to be",
      "offset": 4419.92,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "something on the order of this and most",
      "offset": 4422.239,
      "duration": 4.721
    },
    {
      "lang": "en",
      "text": "ideas are not. most ideas are not. And",
      "offset": 4424.8,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "so this is cool in a sense of like it",
      "offset": 4426.96,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "just jolts you out of incremental",
      "offset": 4428.96,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "thinking into like what really is",
      "offset": 4430.8,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "missing for the next paradigm. And I",
      "offset": 4433.28,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "don't have an answer. Do you have one?",
      "offset": 4435.76,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "Do you have do you have candidates?\n Oh,",
      "offset": 4436.88,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "I I really haven't even considered that",
      "offset": 4439.04,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "too much. I guess like scaling",
      "offset": 4441.04,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "reasoning.\n You got to do the",
      "offset": 4443.199,
      "duration": 2.641
    },
    {
      "lang": "en",
      "text": "autocomplete",
      "offset": 4444.32,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "for step five.\n I mean, you got us all",
      "offset": 4445.84,
      "duration": 3.359
    },
    {
      "lang": "en",
      "text": "the way there and you were like, you",
      "offset": 4447.84,
      "duration": 2.879
    },
    {
      "lang": "en",
      "text": "know,",
      "offset": 4449.199,
      "duration": 3.121
    },
    {
      "lang": "en",
      "text": "you got to show us the way now. We can",
      "offset": 4450.719,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "say it's an exercise left to the reader,",
      "offset": 4452.32,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "but I mean the reality is like",
      "offset": 4454.88,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "predicting the future is too damn hard,",
      "offset": 4456.4,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "you know? Like I I don't maybe it'll be",
      "offset": 4458.48,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "obvious to me in hindsight in 5 years,",
      "offset": 4460.719,
      "duration": 4.801
    },
    {
      "lang": "en",
      "text": "but sitting here today, I I really can't",
      "offset": 4462.48,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "derive from first principles what the",
      "offset": 4465.52,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "next wave of innovation will come from.",
      "offset": 4467.6,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "Yeah, I think we have a few years left.",
      "offset": 4470,
      "duration": 4.719
    },
    {
      "lang": "en",
      "text": "Like each of these uh phases lasted for",
      "offset": 4471.76,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "a few years. Reasoning just started last",
      "offset": 4474.719,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "year kind of. We got some uh some juice",
      "offset": 4476.4,
      "duration": 5.279
    },
    {
      "lang": "en",
      "text": "on this one. Cool. I think that is uh a",
      "offset": 4478.64,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "a broad overview. We've went way over",
      "offset": 4481.679,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "time, but like I really enjoyed this. I",
      "offset": 4484,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "guess my parting question for you is",
      "offset": 4485.76,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "kind of a meta one. So, I'm not an",
      "offset": 4488,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "academic. I'm like kind of selftaught. I",
      "offset": 4490.56,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "just read a bunch of papers and like I",
      "offset": 4492.56,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "talked to people all day as part of the",
      "offset": 4494.08,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "podcast. How do I rate in terms of like",
      "offset": 4495.84,
      "duration": 6.16
    },
    {
      "lang": "en",
      "text": "my my questions as though like could I",
      "offset": 4499.52,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "pass as a grad student like or like",
      "offset": 4502,
      "duration": 5.679
    },
    {
      "lang": "en",
      "text": "what's my distribution like? Maybe I was",
      "offset": 4505.04,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "maybe more industry oriented than",
      "offset": 4507.679,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "academics.\n I think you got to realize",
      "offset": 4509.12,
      "duration": 5.599
    },
    {
      "lang": "en",
      "text": "that like the only person that's an",
      "offset": 4511.84,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "expert in your area as a grad student is",
      "offset": 4514.719,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "you. And even like eventually your",
      "offset": 4517.36,
      "duration": 5.92
    },
    {
      "lang": "en",
      "text": "adviser defers to you for a small set of",
      "offset": 4519.679,
      "duration": 5.281
    },
    {
      "lang": "en",
      "text": "questions that fall within your very",
      "offset": 4523.28,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "niche expertise. So, like I think you're",
      "offset": 4524.96,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "clearly like a very good generalist and",
      "offset": 4527.84,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "have like a huge amount of background on",
      "offset": 4530.96,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "these topics and to the point where I",
      "offset": 4533.04,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "would say you're passing the the grad",
      "offset": 4535.04,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "student touring test and I think if you",
      "offset": 4536.64,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "went to a talk like people would just",
      "offset": 4538.96,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "assume you have some weird research area",
      "offset": 4541.04,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "of your own that they don't understand.",
      "offset": 4542.96,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "You know,\n my research area is AI",
      "offset": 4544.56,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "engineering. Like I'm I'm sort of like",
      "offset": 4546.64,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "making it up as I go. Uh but no, this is",
      "offset": 4548.48,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "super helpful. Uh okay. Well, I I that's",
      "offset": 4551.36,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "about all we we prepared. All the best",
      "offset": 4553.84,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "in your search, all the best in your",
      "offset": 4556,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "PhD. I assume like apparently the",
      "offset": 4557.92,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "current PhD meta is you you do a bunch",
      "offset": 4560.08,
      "duration": 3.119
    },
    {
      "lang": "en",
      "text": "of small papers, you staple them",
      "offset": 4561.76,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "together and like find like an overall",
      "offset": 4563.199,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "theme, you do a defense and that's it.",
      "offset": 4564.8,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "Like that's the journey, which is kind",
      "offset": 4566.719,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "of cool. Like I I would I would love to",
      "offset": 4568.8,
      "duration": 3.439
    },
    {
      "lang": "en",
      "text": "do that. I I'm too old to do it, but",
      "offset": 4570.239,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "like it's cool.\n Yeah. Yeah. It's it's a",
      "offset": 4572.239,
      "duration": 4.721
    },
    {
      "lang": "en",
      "text": "great thing to do at at any age.\n Well,",
      "offset": 4574.56,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "it's better to do a Substack, right? And",
      "offset": 4576.96,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "then you have like people like",
      "offset": 4579.44,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "subscribing and pledging along the way",
      "offset": 4581.76,
      "duration": 3.439
    },
    {
      "lang": "en",
      "text": "and like getting validation and like",
      "offset": 4583.6,
      "duration": 3.599
    },
    {
      "lang": "en",
      "text": "yeah that's that's better than a PhD",
      "offset": 4585.199,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "substack.",
      "offset": 4587.199,
      "duration": 4.241
    },
    {
      "lang": "en",
      "text": "That's the title of the episode like",
      "offset": 4590.159,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "Substack better than PhD. Um",
      "offset": 4591.44,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "but no uh thanks. Yeah thanks for your",
      "offset": 4595.679,
      "duration": 3.361
    },
    {
      "lang": "en",
      "text": "time. This is uh really great. Where can",
      "offset": 4597.44,
      "duration": 3.279
    },
    {
      "lang": "en",
      "text": "people find you? What are you looking",
      "offset": 4599.04,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "for really?\n I'm online you know you can",
      "offset": 4600.719,
      "duration": 5.761
    },
    {
      "lang": "en",
      "text": "follow my substack and Twitter. I tweet",
      "offset": 4603.44,
      "duration": 5.92
    },
    {
      "lang": "en",
      "text": "pretty consistently and you're putting",
      "offset": 4606.48,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "papers out. I guess like the most",
      "offset": 4609.36,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "meaningful thing to be honest is to",
      "offset": 4611.12,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "engage with the research and send me an",
      "offset": 4613.199,
      "duration": 4.561
    },
    {
      "lang": "en",
      "text": "email if you really care. Uh that that's",
      "offset": 4614.88,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "amazing and like I love having those",
      "offset": 4617.76,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "kinds of discussions. And you mean like",
      "offset": 4619.6,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "what I'm looking for in a job or out of",
      "offset": 4622.56,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "life. your research direction like what",
      "offset": 4624.4,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "interests you over anything else that",
      "offset": 4627.84,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "like if if there's someone out there",
      "offset": 4629.92,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "looking who has a problem and is looking",
      "offset": 4631.679,
      "duration": 3.441
    },
    {
      "lang": "en",
      "text": "for someone to help them on it like you",
      "offset": 4633.6,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "are the guy for underscore.\n Oh yeah.",
      "offset": 4635.12,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "Hopefully if you listen this long like I",
      "offset": 4638.32,
      "duration": 6.08
    },
    {
      "lang": "en",
      "text": "think like my research is a lot more",
      "offset": 4641.12,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "well",
      "offset": 4644.4,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "connected than some people's PhD",
      "offset": 4646,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "research and that it all falls into like",
      "offset": 4648.719,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "a very small manifold of like all",
      "offset": 4650.56,
      "duration": 5.92
    },
    {
      "lang": "en",
      "text": "possible problems. And so if you if you",
      "offset": 4652.8,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "want to work on anything within that",
      "offset": 4656.48,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "space or that's sort of like adjacent to",
      "offset": 4658,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "the problems that we discussed in terms",
      "offset": 4659.84,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "of like language model",
      "offset": 4661.92,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "maybe not even language model but model",
      "offset": 4664.96,
      "duration": 5.279
    },
    {
      "lang": "en",
      "text": "weight and activation information I",
      "offset": 4666.8,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "think anything that can be described as",
      "offset": 4670.239,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "that is very interesting to me and I",
      "offset": 4672.08,
      "duration": 3.599
    },
    {
      "lang": "en",
      "text": "would love to talk.\n Awesome. Well uh",
      "offset": 4673.679,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "we'll put your contact info in the show",
      "offset": 4675.679,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "notes and thanks for your time.\n Thank",
      "offset": 4677.76,
      "duration": 5.32
    },
    {
      "lang": "en",
      "text": "you.",
      "offset": 4680.08,
      "duration": 3
    }
  ],
  "cleanText": "Hello, this is L in space.\n\nToday with our special guest, Jack Morris, I guess from Cornell. That's your affiliation right now?\n\nCornell. It's actually confusing because I'm in the New York City outpost of Cornell. So you have the city, right? But it's Cornell Tech, which is like a small Cornell campus in New York. I just, you're a student of Sasha Rush, who teaches at Cornell, so I should have made that connection. Okay. Yeah, I'm sorry. Um, well, that's a horrible mistake to make right off the bat, but you're one of, look, you're one of the, there are not that many PhD students that make an impact with their research. The last time someone like this happened was Shunyu Yao from Princeton, and he joined the OpenAI operator team quite shortly after he graduated. So, like you're one of those high-profile PhD students, at least that's like coming out of the program, and like I figured it was a good time to just talk about your work and also the fact that you're looking for which lab you're going to join. That's like a whole interesting meta discussion, especially with the insane market for AI talent these days. What's it like to be an AI grad student these days?\n\nYeah, and thanks for having me. I guess maybe we can go back to when things first started, or like, like put yourself in my shoes in 2017, 2018. I really learned a lot about machine learning, and at my, I went to a state university. It's a good school, but they didn't have a deep learning research department or anything. They had people doing it, but it was just not as big at that time. But I was getting really interested in those topics, especially as applied to language. And then in 2019, I kind of was starting to do research and I think thinking about my career. I mean, at that point, I was 20, 21. I was thinking about where do I want to be career-wise, or like, who's doing the coolest stuff right now? Like looking at what kind of stuff is coming out of that time. I mean, I think AlphaGo, I thought AlphaGo was really good. At that time, I was playing a lot with BERT and BERT-based models. So, like, you know, Google, DeepMind, they're doing great work. GPT2, GPT1 from OpenAI were like interesting, but I think most people were into BERT at that time. I still have a soft spot for that parameter class of like 100 million to 1 billion scale models. But this is all to say, I think at that time, I felt like the people doing a lot of the most impactful work were like professors and PhD students. Like just a ton of interesting ideas being explored and cool opportunities in academia. So I ended up applying to grad school. Well, I first I did this Google AI residency program, which was mostly during the pandemic, like 2020 and then 2021, and then I was also applying to grad school. Started grad school in 2021. That's still what was going on at that time, like around when I guess GPT3, 175 billion, had been released, but not InstructGPT. So like we had pre-training, and sort of the science of pre-training was emerging, but that's where the models were. And I still think like I'm glad that I went to grad school, and like I had a great experience, but the last 5 years have changed a lot. Like the whole meta has shifted, you know, like the kind of power dynamics are completely different, the ideas are coming from different places, most stuff was open, now most stuff is not open. The types of questions people are asking are different. And so, yeah, I mean, for better or for worse, I did go to do the full grad school thing, and here I am. It's been a really interesting perspective watching the science kind of emerge with the products. Like the biggest thing that happened by far was like ChatGPT coming out, which was right in the middle, like what, 2022 before Christmas, like November. I remember that year, like all, like my grandma was asking me about it, and that's when it hit me like, oh, this is actually becoming like a real area that people will know about and understand. Like I was trying to explain it to my parents, and that's when I think things really started to change in terms of the types of questions you wanted to ask can't always be answered with academic resources. So a lot of the fundamental kind of like boundary pushing and AI science moved into companies. That was the year when like, uh, you know, just around Europs as well, everyone in NLP and deep learning were, were like very confused at, like I think some people were like kind of expecting this already, uh, in a sense that they had, they were obviously more clued into large language models, but I think that the sheer amount of consumer level interest that had, that that was around at the time in 2022, that completely changed the world. Like now, now we're just like in a different sphere. Did you have to pivot your research, or were you already, you just went from BERT to like other stuff? Uh, you've done a lot of embeddings work.\n\nI mean, you're always heads down working on a problem. So I don't think most people in academia are the type to say, oh, look at this new product that came out. I'm going to abandon everything I'm doing. That can be the right move, you know.\n\nOh, it definitely can. Honestly, if I were to give advice to a younger grad student, I think the way to do it would be literally just like sit and wait until the next kind of paradigm shift and then just immediately start working as fast as you can to like reimplement it. Like I, I don't think that's like maybe the best way to do science, but it's probably the best way to play the sort of academic game in the in the days of AI. Like you've seen that so many times, most recently probably with the reasoning models. Like 01 came out of OpenAI, September 2024 last year, and then there's just been this explosion of like you build like abstraction ladders on top of that. Like first it was reimplementation, like how do we even do this, and now it's like a lot about the data, what's the right data, what are the right evals, what are the right training schemes. Like there are so many different axes you can test and publish research in. And like I think the easiest way to do that probably is just work in a field like that that like has it only existed for less than one year, and so no one has any like big advantage. I guess.\n\nThat is mostly correct. I think anyone who jumped on reasoning in RL for Labs is doing super well. I just saw this morning that one of the recent Stanford grad students who worked on RL, they just started their company and they're worth 500 million. It's like absolutely bonkers right now. Like just like no product, just three dudes, you know, sitting in some basement somewhere. I mean, undoubtedly cracked, but like also not worth 500.\n\nYeah. But maybe it's not paying for the product, right? It's like the ideas behind it or the Yeah.\n\nYeah. There was this big shift from in scale of working with 100 million parameter models. Really what happened is like I think the companies invested a ton more into training and infra, and like we all kind of had to catch up. Like, you know, me, I go to Cornell, work with a professor there, he has to buy GPUs. Like, should he buy last year's GPUs or this year's GPUs? How many should he get? That we were kind of like trying to figure that out, and there was, there was like a big lag, I think, where basically the, the seven and 8 billion parameter scale, like there's a huge difference between the BERT size models, which are 125 million parameters to to 200, and then like the 8 billion parameters. I mean, obviously it's two orders of magnitude, but just like this idea of emergence, like if you're talking to a model that's 100 million parameters, no matter how well it's trained, it knows nothing. Like if you ask it like what's the capital of a state, or like if you ask it who's who was president of the United States in 1990 or whatever, it'll just always say George Washington because it just associates the words like president United States with George Washington. And then when you get to the 8 billion parameter scale, suddenly it knows every single president. It knows every single capital of every single country. And I really do think that changes the type of research you can do. And so like it took us a while, I think, in academia to catch up, like getting good 7 billion parameter models and then running them and getting GPUs to run them. Now I think things have stabilized a lot, like we have access to compute and we can kind of like fine-tune and inference that scale of models, and that's like kind of fine, but there was like kind of two years where everyone in academia was working on like smaller models and none of it really mattered. I can sort of branch that discussion in two ways, and we should, we should sort of go to your research at some point, but I'm enjoying this because I think like we don't get to talk about this on the podcast too often. One is there, there is an often, there's an often bit of advice from the industry people to grad students, which is give up, don't work on models, just do benchmarks, right? Like a really good benchmarks will get our attention and then we'll hire you, and then you can switch to models later. You have, for better or worse, avoided that, which is cool, and we can talk about that as well. But the other thing I think is that around about 7, 8B, maybe 4B, is when you start switching from like a single GPU setup to like a distributed setup. And I'm wondering, like, do grad students get HPC training? How much do they teach you of like just how to work with like large clusters of stuff?\n\nOh, to be clear, they don't teach you anything, like anything. Like if you see a paper coming out from even, you know, Stanford, they're probably the best school in AI if you had to choose. And it's not like they're learning how to do like multi-node distributed FSTP training, like with whatever deep speed. You have to learn that from the internet and from other people, and like there's no classes that really do that. I mean, it's that's hard to facilitate, like as one person. I would say most grad students are doing stuff on single GPU. Some people are doing multi-GPU training. There's probably basically no grad students doing multi-node training. I mean, there's probably a few, especially if they have like company affiliations, but that's really unusual, I think.\n\nOkay.\n\nFor grad students who are looking to get up to speed on that, I would recommend the GPU mode Discord, where basically the PyTorch team is hanging out in there just waiting to help you. And then the other one would be the fast AI team. If you have some kind of thing, Jeremy Howard will basically help you out, and uh, they, they have some uh, distributed training. Honestly, try to reach out to the deep speed team at Microsoft. Like actually they're reasonably accessible. Nobody talks to them. Like it's so, so funny. I, I like met them at Europs and like they had nobody at their, like they was presenting these speech three, I was the only one asking questions, like.\n\nUm, yeah.\n\nYeah, that's good, that's good advice. Listen to this guy.\n\nYeah, I mean, just basically like the people are there if you want to ask. This is very, very valuable experience once you're like a GPU god, like you're basically, you know, in a like a different tier as a researcher because you don't rely on someone else helping you out, like you can just sort of be your own research engineer, you know.\n\nYeah, I'll comment on that quickly because if someone has been listening to this and also following me online for a while, I think I've made a couple comments like saying something like you shouldn't learn about CUDA or things to that nature. And I'll, I'll give some more color to that. So, it's definitely a great idea to learn CUDA if you can. I think my point was that if you're trying to enter this space, like learn about the models, learn about how they're trained, what the data looks like, what the compute looks like. One axis of that is how to do more efficient training and inference, and one part of doing more efficient training and inference is studying the hardware, which is GPUs. So, like I think that's a very small subset of all possible knowledge that you could acquire, and it's probably not the best place for a lot of people to start. That said, if you do it, you, you've got to be one of the most hirable people in the world. Like, if you like really deeply understand the architecture of the new GPUs coming out and and how to control it, you're in a very small handful of people and like everyone will want to hire you.\n\nActually, the sweet spot is not even CUDA right now. I would say actually it is Mojo. I don't know if you've been paying attention to modular mojo.\n\nOh, I listened to your podcast, man. You had that guy on uh the other day.\n\nThe whole story is Chris Lanner, industry legend, LLVM, Swift, all these things. And now he's turned his attention to the Python CUDA relationship, right? And he wants to basically create a viable CUDA replacement. It's basically Python married with Rust. for the last two and a half years. He was basically kind of stealth, not ready for production. When he came on our podcast, he was basically announcing to the world like we're open for business, like you can use us now for for most models, and like we actually are faster than like the native like uh, sometimes the PTX implementation. I don't know how that works precisely, but he's a compiler language got. I think there's a nar, there's one of those windows now, like, like you said, like, you know, bet early on something that's there, that's there's a shift. It's one of those windows now where you try to implement things. You basically like, you know, modular is 100 people. If you run into issues, you'll get Chris's personal help on things. Like I'm not promising it, but like probably, you know, like cuz he wants to work on improving the toolkit. And um, all you have to do is just like it's not really about becoming a CUDA god because obviously like once you ramp up on on the the general concepts and principles, you can probably translate ecosystems pretty effectively. A lot of people switch from like jacks to to CUDA, but like the the thing is just like being able to experiment very quickly on a limited budget. Like efficiency is not just because you are trying to be an efficiency guru and that's your career and that's kind of boring. But it's really also just about being able to experiment very quickly uh and finding these these ideas. I also think VLM and SG lang seem like really good and important and here to stay. Like they'll probably just get larger and more complex to accommodate future systems. But if I were like a starting out grad student, I and working in that area, I'd probably like want to learn more about how they work. Awesome. Let's go to your research. I like to mention that I first came across you because of CDE, the contextual document embeddings paper.\n\n\nCan uh tell me the story about that?\nBut I just want to show you proof that, you know, I get one slot per day to highlight the number one AI story, and you were the slot of the day for October 5th.\nOh, no way.\nI mean, obviously you were producing work before that, but like, I thought CDE was a really cool exploration of like, oh yeah, you know, embedding models are kind of like stuck in a rut.\nLike, here's actually how to make them very efficient by just doing it in two stages.\nThat seems like a, you know, relatively simple insight that was done very well.\nBut you have a general maybe information theory thing that maybe we should start with, and then we can sort of grad our way.\nYeah, sure.\nThat sounds good.\nSo we can we can circle back on that.\nThat's that's really cool that you uh wrote about it.\nWhat was that almost coming up on two years ago?\nYeah, this is the post I wrote.\nI I called it a new type of information theory.\nWe don't need to go into this.\nThere there's this paper about a concept called the information.\nMaybe I'll give like the most simple explanation, which is if you say you have two text files.\nOne text file contains a paragraph of information about New York City, and then the other text file contains the same text but encrypted with like Shaw whatever encryption algorithm.\nSo it looks like random letters, but if you decrypt it, it has the same text as the first text file.\nFrom the perspective of like Shannon's information theory, these two files contain the same information content.\nLike relative to everything, they have the same number of bits, but it's it's very clear to the observer that the first text file, which is plain English text, is like much easier to read and easier to process, even though they have the same information.\nAnd so there's this theoretical framework proposed in this paper, which is a theory of usable information under computational constraints from 2020.\nIt really doesn't have that much rest there, not aren't as many citations as you would think, but I think it's a really, really neat idea.\nIt's like we should measure information with computational power as a constraint.\nSo like they have this idea they call V information of how much information is extractable from a given like file or or code.\nSo in that case, we could say the left text file actually has more extractable information than the the right text file.\nI think that's like really good.\nThat captures a lot of our ideas of how these deep learning systems work.\nLike why does pre-training work?\nLike if you have two sets of weights and you you want to train on some downstream data set, one set of weights is pre-trained, one set of weights is randomly initialized.\nWhy is the pre-trained model better at all, even though it's never seen your data?\nMaybe one way of looking at that is that it has like it makes the information like more extractable somehow.\nLike there's this concept of like computational processing that you can almost like store up.\nI like this as a just like a lens to view problems with like how much information is stored where.\nLike if you if you get a a set of model weights or like an activation vector and you open it up, like print some tensor numpy array, it looks like random numbers, right?\nLike there's nothing human intelligible about that.\nBut really, it's this complex combination of like the training data and the training algorithm, which get compressed into model weights and then the actual computation that the model is doing, which involves like manipulating these numbers in ways that we don't understand.\nSo it's like this really highly compressed nonlinear combination of all these information sources mixed with like computation, and I just think we don't have like the right words of of discussing this.\nI think I like the information theory analogy because back in the day, you know, we had phones and like telegraphs, and and people were just sort of like building the phone system with these crazy horistics to like send information across the country or send telegraphs across the Atlantic.\nPeople were just like trying stuff, and then uh we kind of found stuff that worked and we we ran with it, but it wasn't really optimal.\nAnd it wasn't until someone came along and proposed this concept of like a bit, like a one or a zero that tells you something.\nAnd once we have a bit, we can do all these things.\nWe can like count the amount of information a signal.\nWe can do really good error correction.\nWe can measure properties of distributions of things, and and we can build like a really good system for for phones and then eventually which led to computers.\nI'm bringing this all up because I don't think we have I don't think we know what a bit is yet in terms of like deep learning models.\nI'm going to graduate for my PhD this year, but I didn't figure it out.\nSo, if you're listening to this, maybe you can like, I don't know, spend more time on it or you're smarter than me or you have a, you know, group of collaborators, you can all get together and figure out what the right lens to look at this stuff is.\nBut even by just asking these questions, I think I was able to conduct this research agenda that I'm kind of still working on actually.\nYeah.\nUh what do you call this field?\nI don't know.\nI don't know.\nI called the post a new type of information theory.\nI I don't think it exists yet, I guess.\nSo maybe it'll it'll get a name once uh someone actually comes up with the right set of definitions.\nI think V information is a is a really good start.\nThere's a couple related threads.\nUh so first of all, you don't know this, but I actually have been trying to accumulate uh data about Shannon, like this like a Shannon information theory view of language models.\nI have a lot of notes.\nThis is actually on my GitHub for people who are watching along.\nBut um you know, like at the limit, if a language model has 175 billion parameters using 16 bit, you can it will take up 350 GB.\nYou can compare that to Wikipedia.\nWikipedia is about 150 GB.\nYou know, let's say GPC3 can store two Wikipedias, but like is is that a relevant measure of information storage, right?\nIt is not because you can compress Wikipedia a lot.\nThere's a lot of repeated patterns.\nTokenization is is like the first form of compression.\nBut I think there's a there's a related talk from Ilia Sutsgiver about how deep learning is machine learning kind of is is is compression, like it you have a data set, you compress it into a model that is smaller than a data set but generalizes and like uh has like you know some some amount of acceptable loss.\nI think that one of your commenters on on the on the post made this direct comparison with complexity, which is what Ilia how Ilia sees it.\nSo I think like people have this information theory idea or approach to language models.\nIt is just not precise because exactly what you say, like it's we don't know what a bit really means.\nWe don't know what like the most legible legibility is is a word that comes to mind in terms of like like it matters to us that it's human readable, like even if it's SH one SH 256, I don't care, but like that is less readable and therefore there's more I guess I don't know entropy is not the word because it's it's directly convertible, but it's just less useful.\nYeah.\nYeah.\nYeah.\nUseful is a good word.\nI think maybe useful information or usable information is is the right lens.\nAnd Komagarov is a really interesting connection, like Komagarov complexity.\nI think that's a really good concept for for computer scientists.\nSo I'm not sure exactly about this specific talk or like what he was trying to say, but I I think that we have a very good understanding of language model pre-training and there's a deep connection between language models and and compression.\nActually, may maybe let's let's start with the embeddings.\nWe can come back to that.\nOkay.\nSo, is this uh are we going to the first paper?\nActually, let's go to your Wikipedia uh numbers if if you still have access to that.\nSo, this 50 GB for text of Wikipedia, that sounds like a pretty high to me.\nIs that that's uncompressed like text files?\nI don't know.\nI grabbed it from Andrew Wang, so I don't know.\nOkay.\nOkay.\nNo, no, I'm probably off.\nI just sort of have the sense that like when you store text, it's generally like very very small, especially when you zip.\nMaybe he's including all the languages, all the edits.\nI don't know.\nYeah.\nYeah, that could make sense.\nThat could make sense because I I guess what you you say from, you know, if you want to do apples to apples comparisons, GP3 can store two Wikipedias.\nIs that right?\n2.3 Wikipedia something.\nSo, I thought it would be a lot more.\nAnd this is actually an experiment that you could do.\nYou could like just train a model on Wikipedia and keep training it until you can perfectly extract all of Wikipedia.\nAnd that would be like a good way of knowing like how many Wikipedias can GBT store.\nI like I like that idea.\nBut I think this type of like back of the envelope math is it's really useful for thinking about problems and like grounding yourself in the real world, even if you can never quite answer the questions you want to answer at least like in 4 years.\nIf we think about embeddings, you know, vectors that people use for search, we can do the exact same kind of math.\nSo if you use the OpenAI embeddings, which last time I checked, I think have 1,536 dimensions.\nSo that if you say there's 16 bits per dimension and like half precision floating point, it's something like 20 kilob of information in a vector.\nAnd if you want to store 20 kilob of text, that's a lot of text, like many many paragraphs that you can perfectly compress into 20 kilobytes.\nAnd so I think this is kind of like the idea we had.\nI'll give you the practical explanation, which was I'm well, first of all, I'm a second year grad student.\nI'm like going to these conferences, seeing all these other things people working on and thinking, you know, like what the heck, like how am I going to like have my own little area to do work in that no one else is working in already.\nAnd so I spent a lot of time coming up with bad ideas and my adviser would say no, like that's not a good idea to work on.\nMany times this happened, and like even my first year and a half of grad school was like a lot of exploration and a lot of like coming up with bad ideas.\nAnd then honestly, I'd be interested to see how he remembers it.\nBut I think I wrote a sequence of proposals about different projects, and then I came up with this idea.\nI was like, \"Oh, we should just try to do as well as we can to reverse engineer the text that's in embeddings.\"\nAnd I and then we were talking about it.\nHe was like, \"Oh yeah, you should just do that.\"\nAnd then that was the end of the proposals.\nAnd then I was just working on that problem for a long time.\nWhich at the time I was really motivated by that because I was like, cool, like my first as a grad student, my first sort of like official like sign off on like coming up with a good research idea.\nAnd at the same time there was this big rise of this startup business model called like a vector database.\nAnd there are all these companies popping up, raising money, raising money, uh getting like crazy funding and then actual applications being built that do something where instead of exchanging customer data, they exchange vectors.\nSo we had this like very grounded question of like what data are they actually sending when they when they send the vectors.\nLike first of all, you have this information theoretic argument that when you send one vector, there should be a lot of text recoverable just in terms of like a lot of these things represent very short documents, but they actually have many, many bits.\nSo like the problem seems trackable.\nAnd then second of all, we had this justification of how the product is actually being used.\nLike if if someone hacks into a vector database, what do they actually find?\nIf that makes sense.\nSo, we were working on that for a while.\nI think I have the the the talk that you did from that Sasha highlighted uh is this one.\nOh, yeah.\nMaybe that has the graphic that that would kind of\nOh, go one before.\nI think one before.\nThis is actually Yeah, this one's good.\nYeah,\nI like having visual aid.\nI like how I like giving people breadcrumbs to follow up if they if they're interested in digging more.\nBut yeah, I I remember this is a pretty uh hot area research uh at the time and there's been some really interesting follow-ups, like we we ended up building a system that can do this quite well, like taking an embedding and I think our highlight number is like at a certain length, like a long sentence length, we can get 90% of the text back.\nExactly.\nAnd uh a lot of people were able to do stuff with that, like they can, for example, I know these people that work on a problem of like debiasing embeddings, and like in one data set they do something, they have a procedure for like removing all latent features that correlate with gender.\nSo they can produce like useful embeddings that from some perspective have no like information or usable information about gender.\nAnd they'd been doing that for a while.\nAnd then they actually just used our tool and they so like they would put in a sentence like this woman is a doctor at Wild Cornell Hospital in New York or it say this woman is a doctor.\nShe works at Wild Cornell, and then they would run their procedure and then they run our embedding to text model, and now it would say like this person is a doctor.\nThey work at Wild Cornell, which is pretty cool.\nSo they have like sort of textbased evidence that their method is actually removing gender features.\nBut let me talk for a second about the research phase here cuz I thought it would be I mean I know if if you've ever heard me talk about this, I probably told you about it, but just for a wider audience, I like thinking back on this because it was probably my in some sense like my greatest victory of grad school was like working on this embedding inversion problem for a while, for quite a while, and and proposing a lot of approaches and like testing stuff.\nI think sometimes you do stuff and it's clear it was a bad idea.\nSometimes you think you should have figured it out earlier.\nAnd then sometimes you do stuff and you kind of realize it's really complicated and and probably not worth it.\nSo I was testing different decoding algorithms for embeddings that are closer or text that's closer to the text that's in embeddings.\nAnd I was testing these kind of like inference time adaptation models for samplers.\nI think we tried a lot of architecture and like kind of training tweaks.\nWe should have tried RL.\nI think that would work.\nBut well, finally we found something that ended up working.\nAnd I guess I'm just saying this all because I\n\n\nI thought it was like so rewarding.\nLike we were just banging our heads against the wall.\nI would have bi-weekly meetings with my advisor who kind of suggest things.\nSometimes we would agree we were mutually stuck.\nSometimes I would get feedback one way or another and and try something new or try a couple things.\nAnd and we had this idea that it was possible from the information theory arguments and this other thing where we would we would kind of like take our best guess at what the text was and rembed it and see that it was kind of far from the true embedding.\nSo we had this proof that like a better method could like leverage this kind of information.\nAnd then when we finally solved it, it was it was awesome.\nLike we had this number that was like 30 for months.\nI think at one point I got it to 35 and actually I think I was like, \"Oh, I'm done.\"\nLike I got it to 35 and and my advisor told me, \"Oh, no.\"\nLike that's you can't really just propose a new problem and show you push a metric from 30 to 35.\nThat's like confusing and probably not that meaningful to people.\nAnd I think I was, you know, that was kind of like a local minimum for me where I was like bummed.\nBut then we ended up getting the number to like 97 or something which neither of us knew were possible.\nWe were all just we were just kind of staring at this graph like oh my god like who knew you could get this much information from an embedding and that was like so great like um just sort of this it was so rewarding and so it was invigorating honestly like that research process of like we picked a good problem and then we spent so long trying stuff that didn't work which I'm probably forgetting how frustrating that was.\nI'm sure it was terrible, but then like actually solving or at least like coming up with a much better way of solving the problem.\nI don't know if I'd say we solved it, but we definitely learned a lot from where we started was like was great and it completely solidified for me the fact that I should have gone to grad school to have this like life experience and like makes me want to do research forever.\nYou're clearly clearly um sort of in love with the the the journey uh which I think is is important because this is what keeps you going through the the tough parts.\nIs this a good time to talk about the universal geometry side then?\nYeah.\nYeah.\nYeah.\nLet's let's do that next.\nI think that's a good idea.\nSo So we have this more recent followup and the So the first part I was talking about ended up in this paper called Text Embeddings Reveal Almost as Much as Text which was published in 2023.\nAnd then we recently had a paper come out on archive which will hopefully be published at some point and it's called Harnessing the Universal Geometry of Embeddings which was also that was probably like the only other time I felt like we've made like maybe there have been two more times but that that was probably the the second of three times where I felt like we made like a real discovery about like the unknown and it was like very rewarding just for its own intrinsic kind of elusiveness.\nAnd I'll start from explaining it in terms of the prior paper.\nSo we we built a system that can you know do embeddings to text and and it works very well and we're we're very pleased with ourselves.\nAnd then we went to a conference, we talked to people about it.\nWe talked to like the vector databases.\nI think some of them changed their privacy policies which was like somewhat gratifying.\nUm and then we kept getting this perpetual question which is like well you're just assuming we use the OpenAI model or you're just assuming we use the most popular text embedding model.\nIf they fine-tune their own model or if they use a model that you're not training an adversary for, then you can't solve the problem, which is like true.\nLike none of the vector detect stuff works unless you have this assumption of like knowing the encoder and also being able to make a lot of queries to it.\nBut we had this kind of underlying theory that all of the models learn very similar things.\nLike we have some preliminary evidence for that.\nLike certain models that are fine-tuned from the same base, you can kind of swap their representations without doing much.\nOr if you look at the nearest neighbors, a lot of the models will give you the exact same nearest neighbors even though they have completely different training bases.\nAnd then there's this paper that came out last year called the Platonic Representation Hypothesis from some folks at MIT, which is really really compelling and I think just like great intersection of philosophy, representation learning, deep learning research.\nLike I I love this paper and that it's it's such a beautiful idea which is something like all models are trained on data from the world and there's only one world and so as the models get better by scaling data and scaling model size they're sort of converging to learn the exact same thing.\nAnd in this paper they have evidence based on correlations for doing this with vision and language models.\nIt's very neat and so we saw this.\nSo basically think about you know you're us you see this platonic representation hypothesis paper a lot of people have this shared idea like you know Claude and GPT4 probably do a lot of very similar internal computation because both of them are trained on trillions of tokens of human written text even if they have different architectures like maybe you know the actual basis or like the the numbers if you look at them look different but in some way they're like kind of computing the same thing and I think it's even more true with these like embedding models which have like really only one objective that works and they're probably all trained on like MS Marco which is a really popular data set and pre-trained maybe on Wikipedia.\nBut we wanted to basically combine this platonic representation hypothesis idea with the vectex thing and produce a system that can like align models so that we can do embedding inversion.\nBut, you know, it's it's valuable for more than just embedding inversion.\nLike, you can use this to kind of glue together models.\nLike, that's what actually got me like super excited.\nAnd by the way, like I think there's a few related threads.\nUh, I think we did an episode with Nicholas Carini where he had an extraction attack uh on on one of the GPT models and uh they got it fixed.\nThe other thing I want to I just really want to spell out for people just in case they're not thinking it through.\nBeing able to invert embeddings also means that you can you can back out uh like secret prompts or context that might leak customer information that's potentially harmful and like obviously attack vector issue.\nI think one of the things I I had a question about was whether or not position embedding does affect it and like extension of position embeddings affected because obviously that like context are going to get longer and longer.\nYour ability to invert will obviously decrease with longer context.\nWell, now you know uh maybe not that important.\nNo, no, no, no.\nYou're totally right.\nSo, we're operating in this space in in our work where the sequences are relatively short and the embeddings are relatively large.\nLike I think we're kind of at a great advantage from that perspective.\nAnd you're definitely right.\nLike if you embed an entire book to a 500-dimensional vector, there's just no way you could get the entire book back.\nLike there must be this these kind of collisions.\nLike it, you know, in information theory, like if you have lossy compression, two different inputs mapped to the same code, which means that you can never determine which input formed the code.\nAnd I think that's probably what will start to happen.\nLike if you have two books and you swap just one word and you embed them, I don't know, someone can try this.\nYou'll probably get like a perfect collision and in that case inversion is impossible.\nAnd even like when you don't take it to the limit, it probably just gets very very hard.\nLike things get super compressed.\nSo I don't know how well this work scales.\nLike it's a great question like exactly how much information you can sort of cram into one of these vectors and I I don't have a sense of where the boundary is.\nIt'd be interesting to talk to some one of the like linear algebra people from like the math department on like how literally can we take inversion like you know how like what what measures of a matrix do they have where we can like kind of run that and like try to get some meaningful information out of that.\nThis is like where information theory starts to collide with uh linear algebra and all all the other stuff.\nTotally.\nYeah.\nThere there's always this um this detail where we're we're running these on computers and so we don't actually have like real decimal numbers or real numbers.\nWe have like floating point representations of numbers which are like very it kind of like throws a wrench into the mix.\nDo you have any consideration of like superposition when like sort of nonlinearity like you could like stuff information in the lower bits?\nBut I don't know if that matters.\nI I really don't.\nIt's just like a nice thing to think about.\nYeah.\nYeah, it is a great question and and I get a sense that like a lot of the less important bits are more useful for computation and maybe the higher order bits are more important for like storing data or something like that.\nBut I'm not sure.\nThese are the kinds of questions I'm actually hoping to explore over the next few years.\nLike um I'll skip ahead for a second.\nSo we we have this result that's like maybe the the third sort of like discovery I was alluding to which is like a way to measure the exact capacity of a language model and we get this number if you train a language model on a ton of random data and you measure its rate of memorization.\nYeah.\nCan you open the right curve?\nThis is sort of the discovery I'm talking about like no matter how you scale the training size you hit this like perfect perfectish plateau in order memorization which we call the model capacity and the the question I've been stuck on in the back of my mind for a while is like how is that actually implemented so like this is a transformer that is trained for many many data points and many many training steps and so like it's almost like if you have okay the 10 to the 6 point on the x-axis this the capacity uh we don't have to actually say the numbers but it's basically perfectly dividing its computation between all of the data points like every one of the 10 of the six data points gets like a tiny sliver of the model parameters because they're completely independent random strings so I don't really know if superp position is occurring here like it seemed possible to me that the model would learn like these completely independent columns of computation one per data point, but it's also possible it's learning some kind of like combined thing where it's maybe it learns like a load and a store and it's like sort of like loading and storing bits using these generic operations and then in the end it reconstructs the random strings.\nSo even though like the data is completely independent the kind of like compute is is very similar in terms of like predicting random strings.\nBut yeah, I guess this is all to say like about superp position and everything.\nI have no idea how the mechanisms are actually implemented inside the models and that's like one thing I'm hoping to learn about in the next couple years.\nIt's a reasonable question whether it's meaningful to learn.\nI think there's a lot of things that is like nice to know but maybe not that useful.\nLat space lat space alignment is very very useful.\nData set efficiency in theory.\nCool.\nBut like practically people are just going to go for the biggest data set they can like like the scaling laws are kind of worked out in so far as like the relationship of comput and data amount of memorization.\nI I don't know.\nI think maybe this is a good point to maybe also bring in the idea that Andre has been pushing for the last like I think year and a bit of um the cognitive core like the what is the dumbest possible model that knows nothing but is you is smart enough for tool use to do everything else right so you can run it on device and fast inference it's open source whatever uh so Jumba 3N is like a really good candidate right now because it's like a 4B model that is like claimed to be better than llama 4 and GBC 4.1 according to you know certain arenas that shall not be named.\nThis is where things get complicated.\nLike I it feels like language models kind of implement things and know things almost in the same way and it's like really difficult to disentangle like whether they're memorizing facts from whether they're like learning useful ways to generalize about new stuff.\nBut I I agree this would be really nice.\nI don't think we have a lot of evidence that we can build a system like this that like is really really good at reasoning but really dumb about the world.\nLike I don't know if we have the tools.\nYeah, maybe maybe not.\nI think the existence proof is humans, right?\nPeople always lean on humans as like the existence proof.\nIt's not a great existence proof because I think if you talk to people about the number of neurons that we have and you make a neuron roughly equivalent to a parameter, we have something like 100 trillion in our brains.\nSo like and like we consume like 20 watts of energy.\nLike it's nothing.\nLike we're so much better than than uh language models.\nIt's not even funny.\nAnd then the the last feature of us is that we're self-proing which is uh not something that language models do as well.\nOh like we forget stuff.\nNo like we are not deeply densely connected like we like connections will drop therefore we're more efficient you know.\nSee I see.\nUnlike a language model where everything is always connected all the time.\nYeah.\nYeah.\nOr like you preset the skip layers or whatever and that's it, you know, like it's not it's not really actually anything involved with learning.\nIt's just like something you do based on ablations and like guesstimates.\nEven if we did want that, I'm not sure if we have like the right frameworks or methods for actually building like what you're talking about yet.\nI think the world is much closer to where you're at than where Andre is at.\nAndre is like kind of wishing for an optimistic world.\nOur conversation with Nan Brown was like, \"Yeah, reasoning is emergent.\nIf you gave the 01 harness on top of GPT2, you would get nothing because GPT2 didn't know enough.\nYou need a GPT3 and GPT4 in order to then get 01 like as as GPT4 is the base model, which is like yeah, that's I mean that's that's reasonable.\nThe way I put it is like in order to use tools, you need to like in order to search Google, you need to know at least search terms.\nIn order to like then search Google and then learn what you need.\nAnd if you don't know what what to search\n\n\n, then\nlike you might just be too dumb.\nUh, I like the kind of uh ethos, like maybe\nyou could do some kind of pre-training,\nor whenever the model doesn't know\nsomething, it can just Google for it, and\nthat way you try to encourage it to\nlearn words without, or like, to guess\nwords correctly without actually storing\nthe information into its weights.\nYeah,\nit seems like a nice, like, goal, at least.\nYeah, you need some kind of online\nlearning, probably, or memory, uh, and some\ncombination of that.\nYeah, it's\nexciting, you know?\nLike, I think, like, if\nthat is the the direction of of where\nthis all lands up, that's great.\nBut\nlike, people aren't, are not doing that.\nInstead, we're building, you know, $500\nbillion data centers in the middle of\nTexas and, like, you know, all hell, the\nthe the god cluster, uh, that just will,\nyou know, eventually wrap around the sun\nand consume solar energy because that's\nthat's what we need.\nDo we finish out\nthe universal geometry thing?\nLet me\nfinish the kind of uh methodological\ndescription.\nSo, so we had this goal.\nSo, so, so, yeah, back to the embedding\nuniversality.\nWe started with going from\nembeddings to text.\nWe know about this\nplatonic representation hypothesis.\nAnd maybe I'll skip over the details, but\nbasically, we had total inspiration from\ncomputer vision in this model from 2017\ncalled CycleGAN, which is, among other\nthings, uh, it's a way to map between two\ndifferent distributions without any\nunderlying notion of, like, which thing\nshould be mapped where.\nIt's just based\non some kind of idea of closeness.\nSo\nlike, the cool thing about this, if you\nlook at the top left, so I guess the the\ntop left is Monet, so impressionist\npaintings, and this picture on the right\nis a photograph.\nSo, like, it's learning\nthis kind of, like, semantic notion of\nwhat content goes where just by mapping\na distribution of Monet pictures to a\ndistribution of photographs without\nactually telling it which Monet picture\nshould map to which photograph.\nIt's\nkind of a subtle point I'm making.\nIt, it\ntakes a little bit of time to wrap your\nhead around, or maybe, like, go to the\nmiddle one, if you don't mind the zebras\nand the horses.\nSo, like, it's clearly\nlearning, like, what an animal is and what\nlegs are and sort of, like, more abstract\nstuff, like, what uh, the camera position\nshould be and and what grass is and\nstuff like that.\nAnd it's learning, like,\nwhat a horse that looks like a zebra is,\nwhich is actually, like, a complicated\nsemantic concept.\nLike, we don't have a a\ndata set that has a horse and then that\nhorse as a zebra.\nWe just have separate\nhorses and separate zebras, but somehow\nthis this GAN system is able to, like,\nelicit this sort of mapping property.\nIt's like kind of a magical connection\nthat it learns, and I'm still, like, in awe\nthat it's possible at all.\nBut we mo\nmore or less, like, repurposed this system\nand, like, we we built our own, but, like,\nthis idea, we took it and we applied it\nto model embeddings, where instead of\nzebras and horses, we have, like, BERT\nembeddings and GPT embeddings, or, like,\ntwo completely different models with\ndifferent architectures.\nSo I think\nthese are GTR, which is a T5-based\nretrieval model, and GTE, which is based\non BERT.\nSo they have different training\ndata, different architectures, different\ndownstream objectives, different\nembeddings, but yet, when we do this\nCycleGAN in the embedding space, they\njust perfectly sort of snap to the same\nplace, which is amazing and has some\npretty deep implications of, like, the\nPlatonic stuff.\nLike, maybe the models\nactually are learning a lot of the same\nfunctions or something, and in some\nsemantic way, they're, like, very close.\nAnd yeah, this is a diagram of how our\nsystem looks.\nIt's weird to me how\nprofound it seems.\nUh, like you seem, you\nseem, like, deeply impressed by it.\nAnd\nthen the other thing is, like, uh, when we\ntalked to the uh, the to Emanuel from\nAnthropic, who did the circuit tracing\nand mechanistic interpretability work,\nthey were, like, excited that, like, the\nsame thing in different languages maps to\nthe same circuits, and I'm like, what you\nwould expect?\nYeah.\nLike, I, I, I don't know, like, why, like,\nI, I, I don't know.\nI think I feel like\nthis, this feels more profound to you\nthan it does to me.\nI'm like, &quot;Yeah,\nobviously.&quot;\nNo, that's that's so fair.\nMaybe it's just, like, self-\ncongratulatory, and we're happy that\nwe're, like, the people that got it to\nwork.\nYeah, exactly.\nYeah, it does, it\ndoes seem obvious in retrospect.\nAnd I\nthink that's, like, constant feedback I've\ngotten from research from, you know,\npeople will tell you that this seems\nobvious to them.\nBut you have to realize\nthat, like, you came from a perspective of\nno one ever having done this before, and\nthey're coming from a a perspective of\nyou telling them it's true.\nAnd, like, if\nsomeone had told you that this was true,\nit would be, like, maybe obvious to you\ntoo, if that makes sense.\nThe way I\nwould put it is that we have the\nintuition, but not the proof.\nYou have\nthe, you did the work, and you have at\nleast some evidence that it's true,\nwhereas we just have intuitions, right?\nSo\nuh, part of research is just confirming\nintuitions.\nThe applied part comes from,\nlike, okay, now that you know this for a\nfact, what do you do with it?\nYeah, right?\nI think the details can be really\ninteresting, like, the details of the\nproof, like, which models are most similar\nto one another, and to what degree can\nyou get them to align, and on which\ndistributions does this property\nactually emerge, and, like, that's why\nreading papers can be fun sometimes is\nbecause they kind of answer all those\nlittle questions.\nYeah, I would say, uh,\nokay, I'll pull up something very\ncurrent, uh, which is Gemma, which launched\nwhich uh sort of was uh generally\navailable yesterday.\nI would say the, for\nme, and you can correct me if I'm wrong.\nThe most immediate implication is\nmapping adapters to language models.\nSo\nthe the dream is that you have a\nlanguage model backbone.\nLet's say this\none is, like, a 2B language model backbone,\nand then you offload your vision.\nSo you\nonly, you only load in the vision and\nparap parameters, or the the vision\nadapter when you need vision.\nYou only\nload in audio.\nYou don't only need\nspeech uh text to speech whenever you\nneed it.\nUh, because these are all\nseparately trained.\nYou're, you're just\nsort of aligning latent spaces, and you\ncan sort of train them separately.\nAnd I\nthink, like, this helps to make us more\nconfident in one, is it's more efficient.\nThat's a, that's a given.\nTwo, it makes\nhouse.\nIt makes us confident that we can\njust, just add capabilities without\ntaking away or catastrophically\nforgetting others.\nSo they're just sort of, like, stacking\nmore parameters,\njust stackable.\nSo\nthat's very cool.\nYeah.\nSwappable,\nstackable.\nIt's like a fatter version of\nLaura's that is not really\nthat model\nspecific.\nI would say Apple and and\nGoogle are pursuing this for their\non-device stuff is is where is my sense.\nIs this open source,\nGemma?\nYeah, for a\ngiven definition open source, which is\nlike, we release the weights of hugging\nface.\nHere you go.\nOh, that sounds like\nopen source to me.\nOh yeah, I guess it's\nopen weights, but not the data.\nNot the\ndata, not the code.\nNot the code.\nYeah,\nright.\nYeah, I would say that this is\nquite soda in terms of efficient models.\nMaybe a small LM also from Hugging Face\nwould be also in that in that category.\nThere's not that many people working on\nvery good, very efficient models.\nYeah,\nthis is a a very deeply related question\nand something that really interests me,\nwhich is, like, what is the limit of, like,\na 100 million parameter model?\nLike, if\nyou imagine, you know, 100 years from now,\nwhen we have, maybe, our computers are\ngelatinous blobs, and we all communicate\nthrough telepathy,\nwill we have 100 million parameter\nmodels that are at the level of today's\nGPT-3 Pro or whatever, and, like, if so, like,\nhow would that even be the case?\nLike,\nbased on scaling laws?\nLike, do we have\nspecial data?\nDo we come up with, like, a\nbrilliant new training scheme or some\ntype of magical architecture?\nLike, I\nreally don't know.\nOr maybe we really\nare on the at the plateau already.\nI\ndon't know.\nIt seems like when we are\ndoing things like calling a small model\nlike a 27B uh model as small, like, that's\nwhat Mistral is doing, that\nyou know, we've plateaued a little bit in\nterms of, like, what we can do to compress\nthings.\nI have a fun theory uh that this\nis where we mix quantum computing with\nmodels, like, we have to change what a\nparameter means.\nWe have to search\nthrough very high dimensional space in\nand resolve them much quicker than we\ncan with, like, conventional compute.\nThat\nwould be my pie in the sky thing.\nI said\n100 years.\nThat's very reasonable to me.\nThrow quantum at it.\nYeah, I probably have to get a second\nPhD to know what's going on there.\nI\nthink we should establish the definition\nof small model as being a model that a\ngrad student can inference at reasonable\ntime on a single GPU,\nwhich is probably\nlike 7B,\nmaybe.\nI don't think 27 is small\nunder any reasonable, is it?\nWait, is it?\nMistral?\nUh, I don't think so.\nI think all, I\nthink their stuff is default dense.\nDon't\nquote me on that.\nThis is, this is coming\noff of um, just a lot of pre-trained data\nthat is that is uh potentially collided.\nOkay, there was one, there's two more\npapers that we wanted to cover, and then\nwe can we can sort of wrap it.\nYou had\nan approximating, you had a language\nmodel training data.\nI think this is a\nlittle bit uh also newer.\nHow does this\nrank in terms of your your overall work?\nYeah, let's return to the kind of\ninformation theory question.\nSo yeah,\nmaybe we'll we'll skip over the\ncontextual embeddings in the case of\ntime, but we'll group those papers.\nGreat paper.\nHopefully people start\ntraining with that technique.\nIt's kind\nof a free lunch.\nThose questions are all\nabout information and model activations,\nlike, how much can we recover from this\ngiven vector, or, like, what data does this\nvector represent, or what computation\ndoes this vector represent?\nAnd there's\nreally two types of, like, if you want to\ntaxonomize, there's, there's two types of\nwhatever you call it, dense information\nstorage mechanisms.\nOne of them is\nactivations or embeddings, which we were\ndiscussing already, and then the other is\nweights, which are the things that are\nused to perform the computation, but not\nthe computation itself.\nAnd so we have\nnow two papers in this direction of what\nis stored in the weights.\nThe first one\nis about language model capacity, which\nis called how much can language models\nmemorize, or how much do language models\nmemorize.\nI never remember which one we\nsettled on.\nAnd then the other one is\ncalled approximating language model\ntraining data from weights.\nThe first\none is, like, I, I think has a lot of deep\nmessages about how language models store\ninformation and how they work in\ngeneral.\nThe second thing is, like, a\nproof of concept of maybe, like, a longer\nterm research project.\nLet's start with\nthe capacity stuff, if that's good with\nyou.\nDo I have the paper for that?\nI don't, I don't know.\nYou know, we can\nreturn to the question you asked me,\nwhich is something like, why do we care,\nor, like, what is this useful for?\nAnd I\ndon't know if I have a good answer for\nthis.\nI think this is, this is somewhat\nprofound.\nLike, it's kind of like, in in\nphysics, you know, when they try to\nmeasure these constants, like, gravity.\nPeople tried to measure the rate of\nacceleration of gravity for a long time,\nor, like, those Greek guys, like, back in in\nthe BC era, when they were trying to to\napproximate the radius of the earth\nbased on shadows.\nWe're trying to take\nthe GPT architecture, like, the main one,\nand just measure how much information it\ncan store.\nAnd we did this through the\nthe lens of memorization, which I think\nwe can skip over for the podcast, and and\nwe'll just talk about, like, information\nstorage and and weights.\nLike, these\ncurves to me are are pretty crazy.\nAgain, maybe, maybe it's, like, the sort of\ndiscoverers\nfolly or something, where I'm like, &quot;Oh,\nthis didn't exist before, so it seems so\ncool.&quot;\nBut then you're saying, like, it\nseems somewhat obvious.\nNo, no, no.\nDon't, don't let me take that away from\nyou.\nYeah.\nNo.\nAgain, like, I, I independently was asking\nhow come there's not enough people\nexploring LLMs from information theory,\nand then, like, you come along, and your\nembeddings work become, like, an information\ntheory exploration, and I'm like, suddenly,\nlike, I'm very aligned to, like, exploring\nthis, promoting this, and encouraging more\npeople to to figure it out, because, like,\nthat's ultimately how we figure out this\nwhole compression issue, and that you\nknow, what Andre wants, which is, like,\nthe cognitive core, right?\nThe most\nefficient model for the most capability,\nlike, that is an information theory\nquestion.\nTotally agree with that.\nWe\ncould start here, like, so, so transformers\nthat are trained in\n32-bit precision, we approximate can store\nabout 3.6, six bits of information to\nmaybe 3.9 bits somewhere in there per\nparameter.\nAnd, like, why is this?\nI mean,\nfor some perspective, this is, this is\nquite bad.\nLike, if you have 32 bits\navailable, and you can only use three to\nfour of them, like, you're\njust store 32,\nbro.\nYeah.\nYeah.\nThen you'll, like, you know,\nyou could build your own AI lab if you\ncan make the these models uh that much\nmore efficient.\nI don't know how they're\nimplementing this mechanism, or where the\nkind of bottlenecks come from, or even\nnow that we know this, what it's\nnecessarily useful for.\nI guess the\ntools that would be interesting to me\nare knowing, like, given a data set, if you\ncould predetermine the exact model size\nand maybe architectural properties\nrequired to get a certain level of\nperformance, that would be really neat.\nAnd, like, we don't even know how to do\nthat.\nBut we don't even know what the\ndifference is between doing low\nretraining, which trains less than 1% of\nthe parameters, and full fine-tuning,\nwhich trains all the parameters.\nWe\ndon't even really understand the\ndifference there.\nSo I think this is,\nlike, maybe, like, a baby step sort of in\nthat direction, but there's a lot of\nunknown ahead of us.\nOkay.\nDo you think\nthis is a hard limit?\nDo you think\nsomeone can come up with a better\nalgorithm, but better architecture, and\nthen sort of just change the slope?\nThere are two axes here.\nOne is the\nability of the model to store data, and I\nthink we can definitely improve that.\nI\nthink, like, maybe even if we tested this\nwith Llama architecture, like, there's\nsort of, like, a GPT++ architecture, like, I\nwould guess that can store better data\njust because the kind of numerical flow\nis a little bit better.\nThe\nnonlinearities are maybe, like, a little\nbit more suitable to training, like, that\nwill probably raise the bound a little\nbit.\nAnd then the second axis is that\nour measurement tools are just not that\ngood.\nLike, this is, you know, me, I'm a\ngrad student, I'm running all these\nhyperparameter sweeps, and sort of, like,\n\n\nWe draw conclusions from them, but even that being said, there are probably ways to measure this better. But all that would do is push the number up, so it's possible. There is a way to store five bits per parameter if you have a better optimization technique, or if you were a super genius and you could just perfectly set the weights to store the data. Then maybe you can do better, and this is just sort of like what we can reach through optimization is this 3.6 bits per parameter. But I would be happy if someone came along with a much better measurement tool. This is just sort of like the first measurement. I mean, I would guess in the future, people will look back and say this is somewhat, oh, in one direction or another, for whatever reason. And that's just how science goes, and I have no problem with it.\n\nWhat we do is we call this the Morris concert 3.6, right? And I would never. And then we set a like a challenge, like a leaderboard of \"beat this,\" right? And let people go.\n\nYeah. That assumes we know the true constant ahead of time and we can measure the error rate.\n\nIt's doable. You laid it out here.\n\nYeah. Yeah. Yeah. That makes sense.\n\nOne minor doubt I have is like the goal actually isn't memorization, it's generalization, right? The best memorizer model may not be the best generalizer model. You like this incentivizing people to max this number might actually just be fruitless in terms of actual intelligence. You just get the best actual compressor, like you're just going to get GZ. It's totally true, and there's this pattern in research. Time after time, it's like someone poses a question, and then people answer it over and over and over again, but it's often much more fruitful to just ask a new question. Maybe it just doesn't matter how much GPT models can store, and you should just work on something else. We'll figure that out. Did you want to dwell on this side at all?\n\nYeah, let's just talk about it real quick. Definitely not the algorithm itself. By the way, what are your tools for doing these kinds of charts and these kinds of diagrams? I'm just kind of curious behind the scenes on the tools.\n\nI think like visualization has definitely been a fun hobby of mine during grad school. This one, actually, Oscar, my co-author, made this one. Maybe I gave some prompting, but he made it. I think most of the last few papers have all been in diagrams, Google diagrams. I was using Figma for a while and Illustrator. I think Illustrator actually is the best tool.\n\nOh, did you know the transformers diagram was in Adobe Illustrator?\n\nOh, yeah. Yeah, I did know that actually. Yeah, because that's the only way you can get arrows that sort of like curve like that. And they have good shadows. Diagrams is like the least robust, but it's the most accessible. And honestly, if you're good, you can make pretty good stuff. Excal is nice, too, if it's not going in a paper.\n\nYeah, it's just too rough for a paper, but you need something professional looking, you know? It helps, like, if you're going to publish your work, you need to make it look nice and professional and like official, right? So, this is what it is.\n\nYeah. Yeah. And I think there's something worthwhile about saying, like, okay, if I'm going to put my name behind this, I want to spend time making all the references perfect and all the diagrams professional, all the captions are correct. And I think it's like important to put that level of detail into your work.\n\nThat's a little cheesy, but let's finish this off. So, okay, we're talking about bits, information theory, what information sort embeddings. We're talking about language model capacity. I think a much more practical question is, uh, maybe some, maybe this is more analogous to the vector database hacking embedding threat model we discussed, is like, if you have access to a set of model weights, what can you learn about the data? So, like, you were just mentioning Gemma 3B came out yesterday, and you can download it, and it takes up a certain amount of space on disk, and it was trained on some data, but we have no insight into what the data was. I mean, it's probably English. There's probably some distribution of web text. I would guess there's a lot of code, and we seem to have a lot of information about the model, right? You have this file, and there's like many ones and zeros, which means something, but it's kind of like a very highly compressed version of the training data. But I would be extremely surprised if they do any type of like private training, like there are these mechanisms for doing like differentially private language model training or even just anonymization in the pre-training pipeline. I bet they don't do any of that. They just sort of like train on the data, and then they kind of know that we don't have the right tools to decrypt the model weights. And so that's like my dream is we can come up with some way of translating model weights back into text data sets. And so in the most recent kind of drop paper, drop is that paper approximating language model training data from weights. And it turns out to be a really hard problem. Like trying to go from model weights to text is really hard. And we do something a lot simpler, which is like, well, there's two ways we make it simpler. The first thing is we assume access to two checkpoints, which I think is probably not the case in Gemma, but in the case of DeepSeek, if you download the 400 billion parameter model weights, it's this giant file, and you can actually get two of them. You can get the base model weights and the fine-tuned model weights. So the way we put this, you have this kind of like difference in parameter space telling you what DeepSeek fine-tuned on, and it's very controversial. I mean, they're sort of like geopolitical.\n\nDefinitely at the corporation level, they're really interested in the implications of, like, what did DeepSeek train on? And they've released this kind of treasure trove of information of what they trained on, which is the actual model weights, but we have no tool for like interpreting or kind of decrypting this weight difference. And so we started with something really simple, which is instead of even just trying to like regenerate the training data, we take just a web corpus and try to do selection of training data that kind of like looks like the true training data and gives us performance that's as close as possible to the true training data. So there's this complicated method, but it's something like you just sort of like look at the data point gradient and see if it points in the direction in weight space of the finetune, and then you take like the top data set. There's some tricks to it, but it's basically just like gradient-based selection based on this weight difference. And it seems to be okay. Like it can get us pretty good training data. So I guess if you actually wanted to use this, it would be like your competitor releases a base model and a fine-tune, and you're trying to recreate their data set. So you can take this weight difference and take a giant web data set. Like if I was doing this at a company, I'd probably try to scale it up to trillions of tokens and then select the exact data points that try to produce the model. And it turns out you can train a pretty good model with that. It, we don't get to quite the performance of the original model, but it does seem to be like trending in that direction.\n\nThis is like very creative. I don't know what the use of it exactly is.\n\nYeah. Like when would you be in this exact situation? Decently often for their open model labs. Like even DeepSeek, our R1, like has released an update. Mistral does it pretty frequently. Llama does it frequently. It's not impossible, but like I think it's like, I think that I really like the creativity in using quote unquote synthetic checkpoints to do this, which is I don't think I've heard this from any other place. So I don't know if you came up with the idea.\n\nIt's like linear interpolation in weight space.\n\nOkay. Um, that's a bunch of the recent work. Uh, I wanted to sort of cap things off with the data sets question if that's is is that a good\n\nYou can ask me whatever you want.\n\nWell, it's not, it's not like a, it's not an ask. It's just like I think this is a very good thesis. Uh, I think it's a hot take. I almost invited you to speak based on just this alone, but it was a little bit late to\n\nOh, for the conference.\n\nYes. When I look for conference keynotes, I look for something that has a broad overview that kind of put the last few years in perspective, or it's an insight that you can reasonably rely on to like last for a while, so you can get some mileage out of it. You know, I think a lot of ideas in AI come and go. But like things that are trend, these things are scaling laws, things that are trend lines, things are things that are like, u, there's, you know, there's no new ideas in AI that I pay attention to. So maybe you want to recap, like, what's the backstory, if there was one?\n\nYeah. Yeah, sure. So, the meta backstory is I've sort of started writing on Substack, and this is a post that I wrote a few months ago.\n\nThe highest art form of humanity.\n\nYeah. Yeah. Publishing papers wasn't doing it for me anymore. And I moved to Subsac. And this is the name of the post. There are no new ideas in AI, only new data sets. One guy pledged me, but then I found out he was like my former student from a class I was teaching. So it, I don't think it really counts.\n\nIt counts. He's a friend. He's your first supporter.\n\nA pledge is a pledge, man. I'll take whatever I could get. So, so the underlying thesis is that whenever, maybe I'll lay out this framework first. So there's this, uh, this book called The Structure of Scientific Revolutions by Thomas [__] that I read near the beginning of my PhD, which suggests that science kind of moves in these cycles where not very often there's something he calls a paradigm shift, which is like a, you could think of it as a zero to one innovation where everything changes, and then it's followed by a rapid period of small innovations, a lot of like reapplication of previous techniques, pre-paradigm shift techniques to the new era. And then things sort of slow down as we wait for a new paradigm shift. And I was kind of asking myself, what's unique to the paradigm shifts that we've seen in AI? And, and by the way, to me, AI and language models are somewhat synonymous at this point, like at least for the foreseeable future. I'm certain that will change, but basically everything that's pushed the boundary to whatever we have now that resembles like intelligence has come from language models. And so those breakthroughs came in a few steps. So I think the idea is also like a meta commentary on the research community because what everyone wants as a researcher is some kind of like cute new method that no one has thought of before that just works on the existing data better than the previous methods. That's like, for whatever reason, like the kind of most glamorous thing people think you can do as a researcher, like Mamba. It's like, it's like a transformer, but it's like more efficient and works better. So that's what a good idea looks like. And I think everyone wants to like find something like that. But if you look at what's actually borne out in practice, it's never been like that. I think like all of the things that I would consider paradigm shifts in the Cooneyian sense came from a new technique but trained on new data. And I think the new data is super, super important. So I wrote it as a series of four paradigm shifts. The first is the emergence of deep neural networks with AlexNet, which I think it was like 2010 to 2012 era, where we just started training on ImageNet, which is like a scale no one had ever seen before of millions of images. And then the second thing was transformers and BERT and this attention is all you need paper, 2017, the first GPT, 2018, which is webscale pre-training. Like no one had ever done that before. No one had ever tried to scrape all the text off the internet and then tokenize it and feed it into models. Like it's a crazy idea, and I think like we should be honest. I mean, transformers are incredible, and like their staying power is never going to cease to amaze me. They're like much more optimal than I think anyone ever knew, and I don't know if we'll ever beat them. But the real innovation is webscale pre-training. And I think like we honestly probably could have gotten this with RNN's. I know like the scaling laws paper shows that RNN's have worse curves for scaling, but probably people would have been like, I bet you could have built ChatGPT with a very sophisticated RNN. Like you didn't even need transformers. What you need is webscale pre-training. And the third innovation, which is instruction tuning, and we thought it came with like reinforcement learning, but I think the big innovation of instruction tuning is actually the human preference data, which is like gathering positive and negative pairs of what looks good, like in terms of a chatbot interface. And actually, it turns out you can do supervised learning on that, too. You can do DPO, which is a form of supervised learning. You don't even need the InstructGPT techniques. You just need the data. So like I'm sort of playing devil's advocate here, but I actually think this is true that like if we had the right data sets, we almost could have scaled like 2015 era techniques and gotten something that looks like at least InstructGPT. Reasoning models are a little different. Like they're, I'm not sure if we could have that with RNN's or not. Like I don't know if I'm in a position to comment on that with certainty, but they do fall into this framework, which is they really did emerge from a new data source. In this case, it's something like a little different. It's like verification with symbolic systems, like math, calculators, coding environments, unit tests, like things where we can provide numerical feedback to language model outputs. But we built a way to learn that and leverage it to get more intelligent systems. And so whatever the fifth thing is, whether it's video or embodied AI or some kind of crazy innovation on reasoning models, whatever comes next will probably be some type of new data source that we're not using yet.\n\nThat's a really good thesis. I would say that the researchers\n\n\nI talked to would somewhat disagree.\nYeah, obviously this is like a hot take type of thing, and like you already acknowledge that RNN's don't scale to the same extent. They operate on the slope of the curve, whereas, you know, I guess like the amount of data or the type of data or the core insight just changes the order of magnitude of the x-axis, right? That we are mostly working on, but like, uh, both are important. The way that I think someone put it to me was an improvement on compute or data efficiency is the equivalent of having a whole bunch more data that we, you know, that otherwise would be a lot more expensive to collect. It's likely that, you know, the frontier models right now are just a collection of hundreds of these small little experiments that just stack up. You mentioned muon in your post, which seems to be the atom killer. Curiously enough, like still none of the big models um use muon, but like vibes are good.\nYeah. And the value of building better optimizers is really incredible. Like it's just a free launch. You can just sort of like plug in a slightly better training mechanism, and then you save like a ton of compute and a ton of training time. That's like hugely valuable. I think this is cool because I think like it puts us in a mode of like if you were ever to ask what comes after reasoning, it has to be something on the order of this, and most ideas are not. And so this is cool in a sense of like it just jolts you out of incremental thinking into like what really is missing for the next paradigm. And I don't have an answer. Do you have one? Do you have candidates?\nOh, I I really haven't even considered that too much. I guess like scaling reasoning.\nYou got to do the autocomplete for step five. I mean, you got us all the way there and you were like, you know, you got to show us the way now. We can say it's an exercise left to the reader, but I mean the reality is like predicting the future is too damn hard, you know? Like I I don't maybe it'll be obvious to me in hindsight in 5 years, but sitting here today, I I really can't derive from first principles what the next wave of innovation will come from.\nYeah, I think we have a few years left. Like each of these uh phases lasted for a few years. Reasoning just started last year kind of. We got some uh some juice on this one. Cool. I think that is uh a broad overview. We've went way over time, but like I really enjoyed this. I guess my parting question for you is kind of a meta one. So, I'm not an academic. I'm like kind of selftaught. I just read a bunch of papers and like I talked to people all day as part of the podcast. How do I rate in terms of like my my questions as though like could I pass as a grad student like or like what's my distribution like? Maybe I was maybe more industry oriented than academics.\nI think you got to realize that like the only person that's an expert in your area as a grad student is you. And even like eventually your adviser defers to you for a small set of questions that fall within your very niche expertise. So, like I think you're clearly like a very good generalist and have like a huge amount of background on these topics and to the point where I would say you're passing the the grad student touring test, and I think if you went to a talk like people would just assume you have some weird research area of your own that they don't understand. You know, my research area is AI engineering. Like I'm I'm sort of like making it up as I go. Uh but no, this is super helpful. Uh okay. Well, I I that's about all we we prepared. All the best in your search, all the best in your PhD. I assume like apparently the current PhD meta is you do a bunch of small papers, you staple them together and like find like an overall theme, you do a defense and that's it. Like that's the journey, which is kind of cool. Like I I would I would love to do that. I I'm too old to do it, but like it's cool.\nYeah. It's a great thing to do at any age.\nWell, it's better to do a Substack, right? And then you have like people like subscribing and pledging along the way and like getting validation and like yeah that's that's better than a PhD Substack.\nThat's the title of the episode like Substack better than PhD.\nUm but no uh thanks. Yeah thanks for your time. This is uh really great. Where can people find you? What are you looking for really?\nI'm online, you know, you can follow my substack and Twitter. I tweet pretty consistently and you're putting papers out. I guess like the most meaningful thing to be honest is to engage with the research and send me an email if you really care. Uh that that's amazing and like I love having those kinds of discussions. And you mean like what I'm looking for in a job or out of life. Your research direction, like what interests you over anything else that like if if there's someone out there looking who has a problem and is looking for someone to help them on it, like you are the guy for underscore.\nOh yeah. Hopefully if you listen this long, like I think like my research is a lot more well connected than some people's PhD research and that it all falls into like a very small manifold of like all possible problems. And so if you if you want to work on anything within that space or that's sort of like adjacent to the problems that we discussed in terms of like language model, maybe not even language model, but model weight and activation information, I think anything that can be described as that is very interesting to me and I would love to talk.\nAwesome. Well uh we'll put your contact info in the show notes and thanks for your time.\nThank you.\n",
  "dumpedAt": "2025-07-21T18:43:26.254Z"
}