{
  "episodeId": "uIKmG3M0X3M",
  "channelSlug": "@latentspacepod",
  "title": "Cline: The MCP-first IDE",
  "publishedAt": "2025-07-16T18:41:28.000Z",
  "rawLines": [
    {
      "lang": "en",
      "text": "Hey everyone, welcome to the Laden Space",
      "offset": 5.359,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "podcast. This is Allesio, partner and",
      "offset": 7.279,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "CTO at Desible and I'm joined by my",
      "offset": 9.2,
      "duration": 3.439
    },
    {
      "lang": "en",
      "text": "co-host Wix, founder of Smai.",
      "offset": 10.88,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "Welcome. Welcome. And today in the",
      "offset": 12.639,
      "duration": 3.521
    },
    {
      "lang": "en",
      "text": "studio, we have a nice uh two guests",
      "offset": 14.32,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "from Klein Pash and SA.",
      "offset": 16.16,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "That's right.",
      "offset": 19.92,
      "duration": 2
    },
    {
      "lang": "en",
      "text": "Yes, you nailed it.",
      "offset": 20.64,
      "duration": 2.96
    },
    {
      "lang": "en",
      "text": "Let's go.",
      "offset": 21.92,
      "duration": 5.119
    },
    {
      "lang": "en",
      "text": "I think that Klein has a decent fan",
      "offset": 23.6,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "base, but not everyone has heard of it.",
      "offset": 27.039,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "Maybe we should just get like an upfront",
      "offset": 28.96,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "like what is Klein maybe from you and",
      "offset": 30.64,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "then like you can modify that as well.",
      "offset": 32.8,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "Yeah, Klein's an open source coding",
      "offset": 35.28,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "agent. It's a VS code extension right",
      "offset": 37.2,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "now, but it's coming to Jet Brains and",
      "offset": 39.28,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "Neovim and the CLI. You give Klein a",
      "offset": 41.28,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "task and he just goes off and does it.",
      "offset": 44.8,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "He can take over your terminal, your",
      "offset": 46.32,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "editor, your browser, connect to all",
      "offset": 48.16,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "sorts of MCP services and essentially",
      "offset": 50.32,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "take over your entire developer",
      "offset": 53.12,
      "duration": 4.959
    },
    {
      "lang": "en",
      "text": "workflow. and it becomes this point of",
      "offset": 55.68,
      "duration": 5.039
    },
    {
      "lang": "en",
      "text": "contact for you to get your entire job",
      "offset": 58.079,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "done essentially.",
      "offset": 60.719,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "Beautiful. Uh Pash, what would you",
      "offset": 62,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "modify or what's another way to look at",
      "offset": 64.4,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "client that you think is also valuable?",
      "offset": 66.32,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "Yeah, I think client is the kind of",
      "offset": 68.799,
      "duration": 5.281
    },
    {
      "lang": "en",
      "text": "infrastructure layer for agents for all",
      "offset": 70.96,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "open source agents people building on",
      "offset": 74.08,
      "duration": 5.84
    },
    {
      "lang": "en",
      "text": "top of this like agentic infrastructure.",
      "offset": 76.56,
      "duration": 6.08
    },
    {
      "lang": "en",
      "text": "Klein is a fully modular system. That's",
      "offset": 79.92,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "the way we envision it and we're trying",
      "offset": 82.64,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "to make it more modularized so that you",
      "offset": 83.759,
      "duration": 4.801
    },
    {
      "lang": "en",
      "text": "can build any agent on top of it.",
      "offset": 85.92,
      "duration": 3.199
    },
    {
      "lang": "en",
      "text": "Yeah.",
      "offset": 88.56,
      "duration": 2.559
    },
    {
      "lang": "en",
      "text": "So with the CLI and with the SDK that",
      "offset": 89.119,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "we're rolling out, you're going to be",
      "offset": 91.119,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "able to build fully agentic systems for",
      "offset": 92.96,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "anything, not just coding.",
      "offset": 95.2,
      "duration": 4.239
    },
    {
      "lang": "en",
      "text": "Oh, okay. That that is a different uh",
      "offset": 96.799,
      "duration": 4.801
    },
    {
      "lang": "en",
      "text": "perspective on client than I had. So",
      "offset": 99.439,
      "duration": 3.521
    },
    {
      "lang": "en",
      "text": "okay, let's let's talk about coding",
      "offset": 101.6,
      "duration": 2.64
    },
    {
      "lang": "en",
      "text": "first and then we'll talk about the the",
      "offset": 102.96,
      "duration": 2.24
    },
    {
      "lang": "en",
      "text": "broader stuff.",
      "offset": 104.24,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "You also are similar to Ader. I don't",
      "offset": 105.2,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "know who comes first in that you use the",
      "offset": 108.72,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "plan and act paradigm quite a bit. I'm",
      "offset": 111.2,
      "duration": 4.879
    },
    {
      "lang": "en",
      "text": "not sure how well known this is like to",
      "offset": 113.84,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "me I'm relatively up to speed on it but",
      "offset": 116.079,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "again like maybe you guys want to",
      "offset": 118.24,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "explain like why different models for",
      "offset": 120,
      "duration": 3.119
    },
    {
      "lang": "en",
      "text": "different things.",
      "offset": 121.92,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "Yeah, I'm going to take the credit for",
      "offset": 123.119,
      "duration": 4.241
    },
    {
      "lang": "en",
      "text": "coming up with plan act first and then",
      "offset": 125.28,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "we clin was the first to sort of come up",
      "offset": 127.36,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "with this concept of having two modes",
      "offset": 129.119,
      "duration": 5.281
    },
    {
      "lang": "en",
      "text": "for the developer to engage with. Uh so",
      "offset": 131.44,
      "duration": 5.519
    },
    {
      "lang": "en",
      "text": "just in like talking to our users and",
      "offset": 134.4,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "seeing how they use client where it was",
      "offset": 136.959,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "really only an input field we we found a",
      "offset": 138.4,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "lot of them starting off working with",
      "offset": 140.879,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "the agent coming up with a markdown file",
      "offset": 142.72,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "where they ask the agent to put together",
      "offset": 144.8,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "some kind of architecture or plan for",
      "offset": 147.36,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "the work that they want the agent to go",
      "offset": 148.959,
      "duration": 4.721
    },
    {
      "lang": "en",
      "text": "on to to do. And so they we would find",
      "offset": 150.8,
      "duration": 4.799
    },
    {
      "lang": "en",
      "text": "that that people just came up with this",
      "offset": 153.68,
      "duration": 3.279
    },
    {
      "lang": "en",
      "text": "workflow for themselves just",
      "offset": 155.599,
      "duration": 3.201
    },
    {
      "lang": "en",
      "text": "organically. And so we thought about how",
      "offset": 156.959,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "we might translate that into the product",
      "offset": 158.8,
      "duration": 3.519
    },
    {
      "lang": "en",
      "text": "so it's a little bit more intuitive for",
      "offset": 160.959,
      "duration": 3.521
    },
    {
      "lang": "en",
      "text": "new users who don't have to kind of pick",
      "offset": 162.319,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "up that pattern for themselves uh and",
      "offset": 164.48,
      "duration": 5.119
    },
    {
      "lang": "en",
      "text": "can kind of direct and and put in guard",
      "offset": 166.879,
      "duration": 5.281
    },
    {
      "lang": "en",
      "text": "rails for the agent to hear to these",
      "offset": 169.599,
      "duration": 4.241
    },
    {
      "lang": "en",
      "text": "different modes whenever the user",
      "offset": 172.16,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "switches between them. So for example,",
      "offset": 173.84,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "in plan mode, the agent's directed to be",
      "offset": 175.92,
      "duration": 6.08
    },
    {
      "lang": "en",
      "text": "more exploratory, read more files, get",
      "offset": 179.28,
      "duration": 4.239
    },
    {
      "lang": "en",
      "text": "uh sort of understanding and fill up its",
      "offset": 182,
      "duration": 2.879
    },
    {
      "lang": "en",
      "text": "context with any sort of relevant",
      "offset": 183.519,
      "duration": 3.521
    },
    {
      "lang": "en",
      "text": "information to come up with a plan of",
      "offset": 184.879,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "attack for whatever the task is the user",
      "offset": 187.04,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "wants to accomplish. And then when they",
      "offset": 189.519,
      "duration": 3.201
    },
    {
      "lang": "en",
      "text": "switch to act mode, that's when the",
      "offset": 190.879,
      "duration": 4.481
    },
    {
      "lang": "en",
      "text": "agent gets this directive to look at the",
      "offset": 192.72,
      "duration": 4.799
    },
    {
      "lang": "en",
      "text": "plan and start executing on it, running",
      "offset": 195.36,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "commands, editing files. And it just",
      "offset": 197.519,
      "duration": 4.561
    },
    {
      "lang": "en",
      "text": "makes working with agents a little bit",
      "offset": 200.64,
      "duration": 2.879
    },
    {
      "lang": "en",
      "text": "easier. Especially with something like",
      "offset": 202.08,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "client where a lot of the times people's",
      "offset": 203.519,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "engagement with it is mostly in the plan",
      "offset": 206.4,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "mode where there's a lot of back and",
      "offset": 208.879,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "forth. There's a lot of extracting",
      "offset": 210.319,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "context from the developer, you know,",
      "offset": 213.04,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "asking questions, you know, what do you",
      "offset": 214.72,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "want the theme to look like? what pages",
      "offset": 217.12,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "do you want on the website? Just trying",
      "offset": 219.76,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "to extract any sort of information that",
      "offset": 221.12,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "the user might not have put into their",
      "offset": 223.599,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "initial prompt. Once the user feels",
      "offset": 225.28,
      "duration": 5.519
    },
    {
      "lang": "en",
      "text": "like, okay, I'm ready to let the agent",
      "offset": 227.519,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "go off and work on this, they switch to",
      "offset": 230.799,
      "duration": 4.641
    },
    {
      "lang": "en",
      "text": "act mode, check auto approve, and just",
      "offset": 232.799,
      "duration": 4.241
    },
    {
      "lang": "en",
      "text": "kick their feet up and, you know, get",
      "offset": 235.44,
      "duration": 3.519
    },
    {
      "lang": "en",
      "text": "coffee or whatever and let the agent get",
      "offset": 237.04,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "the job done. So, yeah, most of the",
      "offset": 238.959,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "engagement happens in the plan mode and",
      "offset": 240.959,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "then act mode. they kind of just have a",
      "offset": 242.799,
      "duration": 5.121
    },
    {
      "lang": "en",
      "text": "peripheral vision into what's going on",
      "offset": 245.599,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "mostly to course correct whenever it",
      "offset": 247.92,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "goes in the wrong direction but for the",
      "offset": 249.92,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "most part they can just rely on the",
      "offset": 252,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "model to get it done",
      "offset": 253.92,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "and was this the first shape of the",
      "offset": 255.36,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "product or did you get to the plan act",
      "offset": 258.4,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "iteratively and maybe was this the first",
      "offset": 260.56,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "idea of the company itself or were you",
      "offset": 263.12,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "exploring other stuff",
      "offset": 265.68,
      "duration": 2.959
    },
    {
      "lang": "en",
      "text": "it was a lot of especially in the early",
      "offset": 266.8,
      "duration": 2.88
    },
    {
      "lang": "en",
      "text": "days of client it was a lot of",
      "offset": 268.639,
      "duration": 3.041
    },
    {
      "lang": "en",
      "text": "experimenting and talking to our users",
      "offset": 269.68,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "and seeing what kind of workflows came",
      "offset": 271.68,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "that they found that were useful for",
      "offset": 273.759,
      "duration": 2.88
    },
    {
      "lang": "en",
      "text": "them and and translating them into the",
      "offset": 275.12,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "product. So, plan and act was really a",
      "offset": 276.639,
      "duration": 4.961
    },
    {
      "lang": "en",
      "text": "byproduct of just talking to people in",
      "offset": 279.12,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "our Discord, just asking them what would",
      "offset": 281.6,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "be useful to them, what what kind of",
      "offset": 283.36,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "prompt shortcuts we could add into the",
      "offset": 285.36,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "UI. I mean, that's really all plan and",
      "offset": 287.44,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "act mode is. is essentially a shortcut",
      "offset": 289.36,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "for the user to save them the trouble of",
      "offset": 292,
      "duration": 5.199
    },
    {
      "lang": "en",
      "text": "having to type out, you know, I want you",
      "offset": 294.8,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "to ask me questions and put together a",
      "offset": 297.199,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "plan. Um, the way that you might have to",
      "offset": 299.28,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "and, you know, some of the other tools,",
      "offset": 301.199,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "you have to like be explicit about I",
      "offset": 302.96,
      "duration": 4.239
    },
    {
      "lang": "en",
      "text": "want you to come up with a plan before,",
      "offset": 305.199,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "you know, acting on it or editing files,",
      "offset": 307.199,
      "duration": 4.241
    },
    {
      "lang": "en",
      "text": "incorporating that into the UI just",
      "offset": 309.36,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "saves the user the trouble of having to",
      "offset": 311.44,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "type that out themselves. But you",
      "offset": 312.96,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "started right away as a coding product",
      "offset": 315.12,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "and then this was part of okay how do we",
      "offset": 317.68,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "get better UX basically.",
      "offset": 319.52,
      "duration": 2.72
    },
    {
      "lang": "en",
      "text": "Exactly.",
      "offset": 321.28,
      "duration": 3.359
    },
    {
      "lang": "en",
      "text": "Yeah. What was the model evaluation at",
      "offset": 322.24,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "the time? So I'm sure part of like the",
      "offset": 324.639,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "we need plan and act is like maybe the",
      "offset": 326.72,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "models are not able to do it end to end",
      "offset": 328.639,
      "duration": 4.641
    },
    {
      "lang": "en",
      "text": "when you started working on that per",
      "offset": 330.8,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "where were the model limitations what",
      "offset": 333.28,
      "duration": 2.96
    },
    {
      "lang": "en",
      "text": "were the best models and then how has",
      "offset": 334.88,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "that evolved over time? Yeah, when I",
      "offset": 336.24,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "first started working on client, this",
      "offset": 338.4,
      "duration": 4.239
    },
    {
      "lang": "en",
      "text": "was I think 10 days after Cloud35 Sonic",
      "offset": 339.84,
      "duration": 5.84
    },
    {
      "lang": "en",
      "text": "came out. I was reading anthropics model",
      "offset": 342.639,
      "duration": 4.721
    },
    {
      "lang": "en",
      "text": "card addendum and there was this section",
      "offset": 345.68,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "about agentic coding and how it was so",
      "offset": 347.36,
      "duration": 5.279
    },
    {
      "lang": "en",
      "text": "much better at this stepby-step",
      "offset": 349.759,
      "duration": 5.041
    },
    {
      "lang": "en",
      "text": "accomplishing tasks and they talked",
      "offset": 352.639,
      "duration": 4.801
    },
    {
      "lang": "en",
      "text": "about running this internal test where",
      "offset": 354.8,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "they let the model run in this loop",
      "offset": 357.44,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "where it could call tools. Um, and it",
      "offset": 359.28,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "was obvious to me that okay, they have",
      "offset": 361.36,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "some version, they have some application",
      "offset": 363.12,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "internally that's really different from",
      "offset": 365.52,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "how the, you know, the other things at",
      "offset": 367.36,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "the time worked. Things like Copilot and",
      "offset": 368.8,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "Cursor and Ader, they didn't do this",
      "offset": 370.4,
      "duration": 4.639
    },
    {
      "lang": "en",
      "text": "sort of like step-by-step reasoning and",
      "offset": 372.4,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "accomplishing tasks. They were more",
      "offset": 375.039,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "suited for the Q&A and and oneshot",
      "offset": 377.44,
      "duration": 6.72
    },
    {
      "lang": "en",
      "text": "prompting paradigm. Uh, at the time, I",
      "offset": 380.479,
      "duration": 6.72
    },
    {
      "lang": "en",
      "text": "think it was uh June 2024, Enthropic was",
      "offset": 384.16,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "doing a bill with cloud hackathon. So I",
      "offset": 387.199,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "thought, okay, this is a really cool new",
      "offset": 389.52,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "capability that none of the models have",
      "offset": 391.199,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "really been capable of doing before. And",
      "offset": 393.44,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "uh I think being able to create",
      "offset": 396.319,
      "duration": 3.761
    },
    {
      "lang": "en",
      "text": "something from the ground up and take",
      "offset": 398,
      "duration": 3.759
    },
    {
      "lang": "en",
      "text": "advantage of kind of like the nuances of",
      "offset": 400.08,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "how much the models improved in that",
      "offset": 401.759,
      "duration": 4.641
    },
    {
      "lang": "en",
      "text": "point in time. So for example, Cloud35",
      "offset": 404.16,
      "duration": 4.479
    },
    {
      "lang": "en",
      "text": "was also really good at this test called",
      "offset": 406.4,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "needle in a haststack where if it has a",
      "offset": 408.639,
      "duration": 5.361
    },
    {
      "lang": "en",
      "text": "lot of context in its context window,",
      "offset": 412,
      "duration": 4.479
    },
    {
      "lang": "en",
      "text": "for example, you know, 90% of its 200k",
      "offset": 414,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "context window is filled up, it's really",
      "offset": 416.479,
      "duration": 5.681
    },
    {
      "lang": "en",
      "text": "good at picking out granular details in",
      "offset": 418.8,
      "duration": 6.16
    },
    {
      "lang": "en",
      "text": "that context. Whereas before Cloud 3.5,",
      "offset": 422.16,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "it really pay a lot more attention to",
      "offset": 424.96,
      "duration": 3.519
    },
    {
      "lang": "en",
      "text": "whatever was at the beginning or the end",
      "offset": 426.56,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "of the context. So just taking advantage",
      "offset": 428.479,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "of kind of the nuances of it being",
      "offset": 430.88,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "better at understanding longer context",
      "offset": 432.88,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "and it being better at task by task uh",
      "offset": 434.96,
      "duration": 4.639
    },
    {
      "lang": "en",
      "text": "sorry step by step accomplishing tasks",
      "offset": 437.12,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "and building a product from the ground",
      "offset": 439.599,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "up just kind of let me create something",
      "offset": 440.96,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "that just felt a little bit different",
      "offset": 443.039,
      "duration": 2.72
    },
    {
      "lang": "en",
      "text": "than anything else that was around at",
      "offset": 444.4,
      "duration": 2.96
    },
    {
      "lang": "en",
      "text": "the time. And some of the core",
      "offset": 445.759,
      "duration": 3.041
    },
    {
      "lang": "en",
      "text": "principles in building the first version",
      "offset": 447.36,
      "duration": 2.72
    },
    {
      "lang": "en",
      "text": "of the product was just keep it really",
      "offset": 448.8,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "simple. Just let the developer feel like",
      "offset": 450.08,
      "duration": 4.959
    },
    {
      "lang": "en",
      "text": "they can kind of use it however they",
      "offset": 453.44,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "want. So make it as general as possible",
      "offset": 455.039,
      "duration": 4.801
    },
    {
      "lang": "en",
      "text": "and kind of let them come up with",
      "offset": 457.44,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "whatever workflows you know works well",
      "offset": 459.84,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "for them. People use it for all sorts of",
      "offset": 461.68,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "things outside of coding. Our product",
      "offset": 463.68,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "marketing guy Nick Bowman, he uses it to",
      "offset": 466.16,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "connect to, you know, a Reddit MCP",
      "offset": 468.88,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "server, scrape content, connect it to an",
      "offset": 470.96,
      "duration": 5.359
    },
    {
      "lang": "en",
      "text": "XMCP server and and post tweets",
      "offset": 473.52,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "essentially. even though it's a VS Code",
      "offset": 476.319,
      "duration": 5.521
    },
    {
      "lang": "en",
      "text": "extension and a coding agent, MCP kind",
      "offset": 478.4,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "of lets it function as this everything",
      "offset": 481.84,
      "duration": 2.88
    },
    {
      "lang": "en",
      "text": "agent where it can connect to, you know,",
      "offset": 483.36,
      "duration": 2.72
    },
    {
      "lang": "en",
      "text": "whatever services and things like that.",
      "offset": 484.72,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "And that's really a a side effect of of",
      "offset": 486.08,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "having very general prompts just in the",
      "offset": 488.4,
      "duration": 4.799
    },
    {
      "lang": "en",
      "text": "product and not sort of limiting it to",
      "offset": 490.72,
      "duration": 4.879
    },
    {
      "lang": "en",
      "text": "just coding tasks. I was at a conference",
      "offset": 493.199,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "in Amsterdam and I built my whole",
      "offset": 495.599,
      "duration": 4.641
    },
    {
      "lang": "en",
      "text": "presentation, my whole slide deck using",
      "offset": 498.319,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "this library. It's like a JavaScript",
      "offset": 500.24,
      "duration": 3.679
    },
    {
      "lang": "en",
      "text": "library called slidev. And I just asked",
      "offset": 501.599,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "client like, \"Hey, like here's like my",
      "offset": 503.919,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "style guidelines.\" I wrote like a big",
      "offset": 505.68,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "client rules document explaining like",
      "offset": 507.919,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "how I want to style the presentation in",
      "offset": 510.4,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "slide dev. I told client like the",
      "offset": 512.479,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "agenda. I kind of recorded using this",
      "offset": 514.8,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "other app called Limitless like",
      "offset": 517.039,
      "duration": 4.641
    },
    {
      "lang": "en",
      "text": "transcribed my voice into text about",
      "offset": 518.8,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "like my thoughts just like stream of",
      "offset": 521.68,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "consciousness about what I was going to",
      "offset": 523.76,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "talk about for this conference for my",
      "offset": 525.6,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "talk and Klein just went in and built",
      "offset": 528.08,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "the whole the whole deck for me. So, you",
      "offset": 530.24,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "know, client really can do anything",
      "offset": 533.6,
      "duration": 2.16
    },
    {
      "lang": "en",
      "text": "in JavaScript.",
      "offset": 534.8,
      "duration": 1.92
    },
    {
      "lang": "en",
      "text": "In JavaScript. Yeah.",
      "offset": 535.76,
      "duration": 3.199
    },
    {
      "lang": "en",
      "text": "Yeah. So, it's it's kind of a coding use",
      "offset": 536.72,
      "duration": 2.799
    },
    {
      "lang": "en",
      "text": "case.",
      "offset": 538.959,
      "duration": 2
    },
    {
      "lang": "en",
      "text": "It was kind of a coding use case, but",
      "offset": 539.519,
      "duration": 2.801
    },
    {
      "lang": "en",
      "text": "then making a presentation out of it,",
      "offset": 540.959,
      "duration": 3.041
    },
    {
      "lang": "en",
      "text": "but it can also like run scripts like do",
      "offset": 542.32,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "like data analysis for you and then put",
      "offset": 544,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "that into a deck, you know, kind of",
      "offset": 546.32,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "combine things. And being being a VS",
      "offset": 548.24,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "Code extension is is kind of this like",
      "offset": 550.32,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "it gives you these interesting",
      "offset": 552.56,
      "duration": 4.719
    },
    {
      "lang": "en",
      "text": "capabilities where you have access to",
      "offset": 554.64,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "the user's OS, you have access to the",
      "offset": 557.279,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "user's terminal and you know you can",
      "offset": 559.12,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "read and edit files. Being an extension,",
      "offset": 561.68,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "it reduces a lot of the onboarding",
      "offset": 564.64,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "friction for a lot of developers where",
      "offset": 566.08,
      "duration": 3.199
    },
    {
      "lang": "en",
      "text": "they don't have to, you know, install a",
      "offset": 567.68,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "whole new application or have to, you",
      "offset": 569.279,
      "duration": 5.281
    },
    {
      "lang": "en",
      "text": "know, go through whatever internal",
      "offset": 572.24,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "jumping through hoops to try to get",
      "offset": 574.56,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "something approved to to use within",
      "offset": 576,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "their organizations. So the marketplace",
      "offset": 577.92,
      "duration": 2.88
    },
    {
      "lang": "en",
      "text": "gave us a ton of really great",
      "offset": 579.76,
      "duration": 2.4
    },
    {
      "lang": "en",
      "text": "distribution and is sort of like the",
      "offset": 580.8,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "perfect conduit for something that needs",
      "offset": 582.16,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "access to files on your desktop or to be",
      "offset": 584.16,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "able to run things on your terminal to",
      "offset": 586.88,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "be able to edit code and to take",
      "offset": 589.04,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "advantage of VS Code's really nice UI",
      "offset": 591.92,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "and show you like diff views for example",
      "offset": 594.24,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "before and after it makes changes to to",
      "offset": 596.56,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "files. Weren't you tempted to for VS",
      "offset": 598.64,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "Code though? I mean you know you could",
      "offset": 600.8,
      "duration": 4.719
    },
    {
      "lang": "en",
      "text": "be sitting on $3 billion right now.",
      "offset": 602.8,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "Well, no. I I I actually like pity",
      "offset": 605.519,
      "duration": 4.561
    },
    {
      "lang": "en",
      "text": "anybody that has to fork VS Code because",
      "offset": 608,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "Microsoft makes it like notoriously",
      "offset": 610.08,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "difficult to maintain these forks. So, a",
      "offset": 611.76,
      "duration": 6.24
    },
    {
      "lang": "en",
      "text": "lot of resources um and efforts go into",
      "offset": 614.24,
      "duration": 6.8
    },
    {
      "lang": "en",
      "text": "just maintaining keeping your fork up to",
      "offset": 618,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "date with all the updates that VS Code",
      "offset": 621.04,
      "duration": 2.72
    },
    {
      "lang": "en",
      "text": "is making. I see.",
      "offset": 622.8,
      "duration": 1.68
    },
    {
      "lang": "en",
      "text": "Um",
      "offset": 623.76,
      "duration": 2.079
    },
    {
      "lang": "en",
      "text": "is that because they they have a private",
      "offset": 624.48,
      "duration": 3.599
    },
    {
      "lang": "en",
      "text": "repo and they just sync it. There's no",
      "offset": 625.839,
      "duration": 2.881
    },
    {
      "lang": "en",
      "text": "like",
      "offset": 628.079,
      "duration": 1.841
    },
    {
      "lang": "en",
      "text": "Exactly. Exactly.",
      "offset": 628.72,
      "duration": 2.559
    },
    {
      "lang": "en",
      "text": "It's one of those kinds of open source",
      "offset": 629.92,
      "duration": 1.76
    },
    {
      "lang": "en",
      "text": "projects,",
      "offset": 631.279,
      "duration": 3.041
    },
    {
      "lang": "en",
      "text": "right? And VS Code's moving so quickly",
      "offset": 631.68,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "where I'm sure they run into all sorts",
      "offset": 634.32,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "of issues, not just in, you know, things",
      "offset": 635.839,
      "duration": 3.521
    },
    {
      "lang": "en",
      "text": "like merge conflicts, but also in the",
      "offset": 637.92,
      "duration": 2.88
    },
    {
      "lang": "en",
      "text": "back end. They're always making",
      "offset": 639.36,
      "duration": 2.8
    },
    {
      "lang": "en",
      "text": "improvements and changes to, for",
      "offset": 640.8,
      "duration": 3.279
    },
    {
      "lang": "en",
      "text": "example, their VS Marketplace API. And",
      "offset": 642.16,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "to have to like reverse engineer that",
      "offset": 644.079,
      "duration": 3.521
    },
    {
      "lang": "en",
      "text": "and figure out kind of how to make sure",
      "offset": 646.079,
      "duration": 3.041
    },
    {
      "lang": "en",
      "text": "that your users don't run into issues",
      "offset": 647.6,
      "duration": 2.88
    },
    {
      "lang": "en",
      "text": "using things like that is I'm sure like",
      "offset": 649.12,
      "duration": 2.719
    },
    {
      "lang": "en",
      "text": "a huge headache for anybody that has to",
      "offset": 650.48,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "maintain a VS code fork. And it also,",
      "offset": 651.839,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "you know, being an extension also gives",
      "offset": 654.72,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "us a lot more distribution. It's not",
      "offset": 656.079,
      "duration": 4.641
    },
    {
      "lang": "en",
      "text": "that you have to use us or somebody",
      "offset": 658.16,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "else. You can use client in cursor or in",
      "offset": 660.72,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "windsurf or in VS code. And I think",
      "offset": 663.12,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "client complements all these things",
      "offset": 665.68,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "really well in that you know we get the",
      "offset": 667.6,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "opportunity to kind of figure out and",
      "offset": 669.6,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "and work really closely with our users",
      "offset": 671.12,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "to figure out what the best agentic",
      "offset": 673.2,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "experience is whereas you know cursor",
      "offset": 675.2,
      "duration": 4.879
    },
    {
      "lang": "en",
      "text": "and windsurf and and co-pilot have to",
      "offset": 677.2,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "think about the entire developer",
      "offset": 680.079,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "experience the inline code edits the Q&A",
      "offset": 681.44,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "sort of all the other bells and whistles",
      "offset": 684.24,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "that go into writing code. we get to",
      "offset": 685.519,
      "duration": 4.721
    },
    {
      "lang": "en",
      "text": "just focus on what I think is the future",
      "offset": 688.16,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "programming, which is this agentic",
      "offset": 690.24,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "paradigm. Um, and as the models get",
      "offset": 691.92,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "better, people are going to find",
      "offset": 693.92,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "themselves using natural language,",
      "offset": 695.44,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "working with an agent more and more and",
      "offset": 697.92,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "less being in the weeds and editing code",
      "offset": 699.839,
      "duration": 3.361
    },
    {
      "lang": "en",
      "text": "and tab autocomplete.",
      "offset": 701.6,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "Yeah. Like imagine how many like",
      "offset": 703.2,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "resources you would have to spend",
      "offset": 705.12,
      "duration": 5.279
    },
    {
      "lang": "en",
      "text": "maintaining a fork of VS Code where we",
      "offset": 706.8,
      "duration": 5.599
    },
    {
      "lang": "en",
      "text": "can just kind of stay focused on the",
      "offset": 710.399,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "core agentic loop optimizing for",
      "offset": 712.399,
      "duration": 4.801
    },
    {
      "lang": "en",
      "text": "different model families as they come",
      "offset": 714.8,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "out supporting them. You know, there's",
      "offset": 717.2,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "so much work that goes into all of this",
      "offset": 719.12,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "that maintaining a fork on the side",
      "offset": 721.2,
      "duration": 3.759
    },
    {
      "lang": "en",
      "text": "would just be such a massive distraction",
      "offset": 723.279,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "for us that I don't think it's really",
      "offset": 724.959,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "worth it. I feel like when you talk I",
      "offset": 727.2,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "hear this distinction between we want to",
      "offset": 729.839,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "be the best thing for the future of",
      "offset": 731.92,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "programming and then also this is also",
      "offset": 733.68,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "great for non-programming. Is this",
      "offset": 735.839,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "something that is being risen for you",
      "offset": 737.92,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "where like you're seeing more and more",
      "offset": 740.399,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "people use the MCP servers especially to",
      "offset": 741.6,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "do less technical thing and that's an",
      "offset": 744.079,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "interesting area or do you feel like",
      "offset": 746.72,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "programming is still like the highest",
      "offset": 748.24,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "kind of like economic value thing to be",
      "offset": 749.76,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "selling today? I'm curious if you can",
      "offset": 751.6,
      "duration": 2.799
    },
    {
      "lang": "en",
      "text": "share more",
      "offset": 753.6,
      "duration": 2.479
    },
    {
      "lang": "en",
      "text": "in terms of economic value. I",
      "offset": 754.399,
      "duration": 2.961
    },
    {
      "lang": "en",
      "text": "programming is definitely the highest",
      "offset": 756.079,
      "duration": 2.961
    },
    {
      "lang": "en",
      "text": "cost of benefit for language models",
      "offset": 757.36,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "right now and I think you know we're",
      "offset": 759.04,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "seeing a lot of you know model labs",
      "offset": 761.04,
      "duration": 6.239
    },
    {
      "lang": "en",
      "text": "recognize that OpenAI anthropic are",
      "offset": 764.16,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "taking coding a lot more seriously than",
      "offset": 767.279,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "I think they did a year ago. What we've",
      "offset": 769.12,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "seen is while yes like MC the MCP",
      "offset": 771.6,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "ecosystem is growing and a lot of people",
      "offset": 774.32,
      "duration": 2.88
    },
    {
      "lang": "en",
      "text": "are using it for things outside of",
      "offset": 775.92,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "programming the majority use case is",
      "offset": 777.2,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "mostly developer work. There was an",
      "offset": 779.12,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "article on Hacker News a couple weeks",
      "offset": 781.12,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "ago about how a developer deployed a",
      "offset": 783.12,
      "duration": 6.8
    },
    {
      "lang": "en",
      "text": "buggy Cloudflare worker and used a",
      "offset": 785.92,
      "duration": 6.96
    },
    {
      "lang": "en",
      "text": "Sentry MCP server to pull a stack trace",
      "offset": 789.92,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "and ask client to sort of fix the bug",
      "offset": 792.88,
      "duration": 4.959
    },
    {
      "lang": "en",
      "text": "using the stack trace information.",
      "offset": 795.92,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "connect to a GitHub MCP server to close",
      "offset": 797.839,
      "duration": 5.761
    },
    {
      "lang": "en",
      "text": "the issue and deploy the fix to",
      "offset": 800.48,
      "duration": 5.84
    },
    {
      "lang": "en",
      "text": "Cloudflare all right within client using",
      "offset": 803.6,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "natural language never having to leave",
      "offset": 806.32,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "VS Code and it sort of interacts with",
      "offset": 807.92,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "all these services that otherwise the",
      "offset": 809.76,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "developer would have had to have the",
      "offset": 811.2,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "cognitive overload of having to you know",
      "offset": 812.8,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "figure out for himself and leave his",
      "offset": 814.56,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "developer environment to to essentially",
      "offset": 817.12,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "do what the agent could have done just",
      "offset": 819.36,
      "duration": 3.599
    },
    {
      "lang": "en",
      "text": "all in the background just using natural",
      "offset": 821.44,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "language I think that's kind of like",
      "offset": 822.959,
      "duration": 3.281
    },
    {
      "lang": "en",
      "text": "where things are headed is the",
      "offset": 824.48,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "application layer being connected to",
      "offset": 826.24,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "sort of all the different services that",
      "offset": 828.48,
      "duration": 2.32
    },
    {
      "lang": "en",
      "text": "you might have had to interact with",
      "offset": 829.76,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "before manually and it being this sort",
      "offset": 830.8,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "of single point of contact for you to",
      "offset": 833.04,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "interact with using natural language and",
      "offset": 834.56,
      "duration": 4.959
    },
    {
      "lang": "en",
      "text": "you being less and less in the code and",
      "offset": 836.88,
      "duration": 6.319
    },
    {
      "lang": "en",
      "text": "more and more a highle understanding of",
      "offset": 839.519,
      "duration": 5.841
    },
    {
      "lang": "en",
      "text": "what the agent's doing and being able to",
      "offset": 843.199,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "course correct. I think that's another",
      "offset": 845.36,
      "duration": 3.599
    },
    {
      "lang": "en",
      "text": "part of what's important to us and",
      "offset": 846.8,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "what's allowed us to kind of cut through",
      "offset": 848.959,
      "duration": 2.721
    },
    {
      "lang": "en",
      "text": "the noise in this like incredibly noisy",
      "offset": 850.24,
      "duration": 3.279
    },
    {
      "lang": "en",
      "text": "space is I think a lot of a lot of",
      "offset": 851.68,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "people have really grand ideas for you",
      "offset": 853.519,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "know where things are heading but we've",
      "offset": 855.839,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "been really maniacal about what's useful",
      "offset": 857.519,
      "duration": 5.361
    },
    {
      "lang": "en",
      "text": "to people today and a large part of that",
      "offset": 860,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "is understanding sort of the limitations",
      "offset": 862.88,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "of these models what they're not so good",
      "offset": 865.12,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "at and giving enough insight into those",
      "offset": 867.279,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "sorts of things to the the end developer",
      "offset": 870.16,
      "duration": 3.359
    },
    {
      "lang": "en",
      "text": "so that they know how to course correct",
      "offset": 871.839,
      "duration": 2.961
    },
    {
      "lang": "en",
      "text": "they know how to give feedback when",
      "offset": 873.519,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "things don't go Right. So for example,",
      "offset": 874.8,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "Klein is really good about, you know,",
      "offset": 877.36,
      "duration": 3.599
    },
    {
      "lang": "en",
      "text": "giving you a lot of insight into the",
      "offset": 879.44,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "prompts going into the model, into when",
      "offset": 880.959,
      "duration": 4.961
    },
    {
      "lang": "en",
      "text": "there's an error, why the error",
      "offset": 883.839,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "happened, into the tools that the",
      "offset": 885.92,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "model's calling. We try to give as much",
      "offset": 888.399,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "insight into what exactly the model is",
      "offset": 890.56,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "doing at each step in accomplishing a",
      "offset": 892.8,
      "duration": 3.599
    },
    {
      "lang": "en",
      "text": "task. So when things don't go wrong or",
      "offset": 894.639,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "it starts to go off in the wrong",
      "offset": 896.399,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "direction, you can, you know, give it",
      "offset": 898.079,
      "duration": 2.801
    },
    {
      "lang": "en",
      "text": "feedback and course correct. And I think",
      "offset": 899.519,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "the course correcting part is so",
      "offset": 900.88,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "incredibly important in in getting work",
      "offset": 902.639,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "done. I think much more quickly than if",
      "offset": 904.88,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "you were to kind of give a sort a",
      "offset": 906.8,
      "duration": 3.279
    },
    {
      "lang": "en",
      "text": "background agent work. You come back a",
      "offset": 908.16,
      "duration": 3.039
    },
    {
      "lang": "en",
      "text": "couple hours later and it's just like",
      "offset": 910.079,
      "duration": 2.961
    },
    {
      "lang": "en",
      "text": "totally wrong and it it didn't do",
      "offset": 911.199,
      "duration": 3.121
    },
    {
      "lang": "en",
      "text": "anything that you expected it to do and",
      "offset": 913.04,
      "duration": 2.56
    },
    {
      "lang": "en",
      "text": "you kind of have to retry a couple times",
      "offset": 914.32,
      "duration": 2.72
    },
    {
      "lang": "en",
      "text": "before it gets it right.",
      "offset": 915.6,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "I think the Sentry example is great",
      "offset": 917.04,
      "duration": 4.799
    },
    {
      "lang": "en",
      "text": "because I feel in a way the MCPs are",
      "offset": 919.92,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "like cannibalizing the products",
      "offset": 921.839,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "themselves. Like I started using the",
      "offset": 923.76,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "Sentry MCP and then Sentry released",
      "offset": 925.76,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "seere which is like their issue",
      "offset": 928.079,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "resolution agent and it was free at the",
      "offset": 929.76,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "start. So I turned it on in Sentry. I",
      "offset": 932.079,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "was using it. It's great. And then they",
      "offset": 934.48,
      "duration": 2.88
    },
    {
      "lang": "en",
      "text": "started charging money for it. And I'm",
      "offset": 936.079,
      "duration": 3.521
    },
    {
      "lang": "en",
      "text": "like I can use the MCP for free",
      "offset": 937.36,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "put the data in my coding agent and it's",
      "offset": 939.6,
      "duration": 5.039
    },
    {
      "lang": "en",
      "text": "going to fix the issue for free and send",
      "offset": 942.56,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "it back. I'm curious to see especially",
      "offset": 944.639,
      "duration": 3.361
    },
    {
      "lang": "en",
      "text": "in coding where you can kind of have",
      "offset": 946.399,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "this closed loop where okay are these",
      "offset": 948,
      "duration": 5.759
    },
    {
      "lang": "en",
      "text": "MCPs going to become the paid AI",
      "offset": 950.8,
      "duration": 5.279
    },
    {
      "lang": "en",
      "text": "offering so that then you can plug it in",
      "offset": 953.759,
      "duration": 4.481
    },
    {
      "lang": "en",
      "text": "and is client going to have kind of like",
      "offset": 956.079,
      "duration": 4.641
    },
    {
      "lang": "en",
      "text": "a MCP subscription where like you're",
      "offset": 958.24,
      "duration": 5.039
    },
    {
      "lang": "en",
      "text": "kind of fractionalizing all these costs.",
      "offset": 960.72,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "Um to me today feels like it doesn't",
      "offset": 963.279,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "make a lot of sense the way they're",
      "offset": 965.44,
      "duration": 3.519
    },
    {
      "lang": "en",
      "text": "structured. Well, yeah, we we were like",
      "offset": 966.88,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "uh very early on we like we've been",
      "offset": 968.959,
      "duration": 4.721
    },
    {
      "lang": "en",
      "text": "bullish on MCP from the very beginning",
      "offset": 971.36,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "and um",
      "offset": 973.68,
      "duration": 2.48
    },
    {
      "lang": "en",
      "text": "were you a launch partner?",
      "offset": 974.56,
      "duration": 2.88
    },
    {
      "lang": "en",
      "text": "Funny story about MCP. I think",
      "offset": 976.16,
      "duration": 2
    },
    {
      "lang": "en",
      "text": "sorry to interrupt.",
      "offset": 977.44,
      "duration": 1.44
    },
    {
      "lang": "en",
      "text": "Yeah, no worries.",
      "offset": 978.16,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "I I think uh when Enthropic first",
      "offset": 978.88,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "launched MCP and and they made this big",
      "offset": 981.36,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "announcement about, you know, this new",
      "offset": 983.04,
      "duration": 2.4
    },
    {
      "lang": "en",
      "text": "protocol that they've been working on",
      "offset": 984.48,
      "duration": 2.32
    },
    {
      "lang": "en",
      "text": "and open sourcing it, nobody really",
      "offset": 985.44,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "understood what it meant. And it took me",
      "offset": 986.8,
      "duration": 2.959
    },
    {
      "lang": "en",
      "text": "some time really digging into their",
      "offset": 988.48,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "documentation about how it works and why",
      "offset": 989.759,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "this is important. I think they they",
      "offset": 992.48,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "kind of took this bet on the open source",
      "offset": 994.399,
      "duration": 5.041
    },
    {
      "lang": "en",
      "text": "community contributing to an ecosystem",
      "offset": 997.04,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "in order for it to really take off. And",
      "offset": 999.44,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "so I wanted to try to help with that",
      "offset": 1001.36,
      "duration": 3.279
    },
    {
      "lang": "en",
      "text": "effort as much as possible. So for a",
      "offset": 1003.12,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "long time most of client system prompt",
      "offset": 1004.639,
      "duration": 4.481
    },
    {
      "lang": "en",
      "text": "was how does MCP work because it was so",
      "offset": 1006.8,
      "duration": 3.599
    },
    {
      "lang": "en",
      "text": "new at the time that you know the models",
      "offset": 1009.12,
      "duration": 3.279
    },
    {
      "lang": "en",
      "text": "didn't know anything about it and how to",
      "offset": 1010.399,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "make MCP servers. So like if the",
      "offset": 1012.399,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "developer wanted to you know make",
      "offset": 1014.8,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "something like that it'd be really good",
      "offset": 1016.56,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "at it. And I'd like to think that, you",
      "offset": 1018.16,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "know, client had something to do with",
      "offset": 1019.92,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "how much the MCP ecosystem has grown",
      "offset": 1021.6,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "since then and just getting developers",
      "offset": 1024.4,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "more insight and and sort of awareness",
      "offset": 1026.24,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "about how it works under the hood, which",
      "offset": 1028.319,
      "duration": 3.281
    },
    {
      "lang": "en",
      "text": "I think is incredibly important in using",
      "offset": 1029.6,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "it, let alone just developing these",
      "offset": 1031.6,
      "duration": 3.599
    },
    {
      "lang": "en",
      "text": "things. And so, yeah, when when we",
      "offset": 1033.12,
      "duration": 5.839
    },
    {
      "lang": "en",
      "text": "launched MCP incline, I remember our our",
      "offset": 1035.199,
      "duration": 6.401
    },
    {
      "lang": "en",
      "text": "Discord users just trying to wrap their",
      "offset": 1038.959,
      "duration": 4.561
    },
    {
      "lang": "en",
      "text": "heads around it. And in seeing clients",
      "offset": 1041.6,
      "duration": 3.439
    },
    {
      "lang": "en",
      "text": "build MCP servers from the ground up,",
      "offset": 1043.52,
      "duration": 2.64
    },
    {
      "lang": "en",
      "text": "they're like, \"Okay, they started to",
      "offset": 1045.039,
      "duration": 2.8
    },
    {
      "lang": "en",
      "text": "connect the dots. This is how it works",
      "offset": 1046.16,
      "duration": 3.519
    },
    {
      "lang": "en",
      "text": "under the hood. this is why it's useful.",
      "offset": 1047.839,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "This is how agents connect to these",
      "offset": 1049.679,
      "duration": 4.641
    },
    {
      "lang": "en",
      "text": "tools and services and these APIs and uh",
      "offset": 1051.039,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "sort of saved me a lot of the trouble of",
      "offset": 1054.32,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "having to do this sort of stuff myself.",
      "offset": 1055.679,
      "duration": 4.721
    },
    {
      "lang": "en",
      "text": "Those are like the early days of of MCP",
      "offset": 1057.44,
      "duration": 4.479
    },
    {
      "lang": "en",
      "text": "and people were still trying to wrap",
      "offset": 1060.4,
      "duration": 2.639
    },
    {
      "lang": "en",
      "text": "their heads around it",
      "offset": 1061.919,
      "duration": 2.401
    },
    {
      "lang": "en",
      "text": "and there's like a big problem with",
      "offset": 1063.039,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "discoverability. So, back in like",
      "offset": 1064.32,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "February, we launched the MCP",
      "offset": 1067.44,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "marketplace where you could actually go",
      "offset": 1069.6,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "through and have like this one-click",
      "offset": 1071.2,
      "duration": 3.359
    },
    {
      "lang": "en",
      "text": "install process where client would",
      "offset": 1072.96,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "actually go through looking at a readme",
      "offset": 1074.559,
      "duration": 4.641
    },
    {
      "lang": "en",
      "text": "and that's like linked to a GitHub,",
      "offset": 1077.12,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "install the whole MCP server from",
      "offset": 1079.2,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "scratch and just get it running",
      "offset": 1081.12,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "immediately. And that was like I think",
      "offset": 1083.2,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "around that time that's when MCP really",
      "offset": 1085.52,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "started taking off with like the launch",
      "offset": 1087.36,
      "duration": 3.439
    },
    {
      "lang": "en",
      "text": "of the marketplace where people were",
      "offset": 1088.64,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "able to discover MCPS, contribute to the",
      "offset": 1090.799,
      "duration": 6.321
    },
    {
      "lang": "en",
      "text": "MCP marketplace. We've listed over like",
      "offset": 1093.039,
      "duration": 7.441
    },
    {
      "lang": "en",
      "text": "150 MCP servers since then and um like",
      "offset": 1097.12,
      "duration": 5.84
    },
    {
      "lang": "en",
      "text": "the top MCPs in our marketplace have",
      "offset": 1100.48,
      "duration": 4.559
    },
    {
      "lang": "en",
      "text": "over you know hundreds of thousands of",
      "offset": 1102.96,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "downloads people using them and you know",
      "offset": 1105.039,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "there's like really notable examples",
      "offset": 1108.16,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "where you mentioned like how are people",
      "offset": 1109.679,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "like it's like kind of eating existing",
      "offset": 1111.6,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "products but at the same time we're",
      "offset": 1113.76,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "starting to see like this ecosystem",
      "offset": 1115.12,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "evolve where people are monetizing MTPs",
      "offset": 1117.28,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "like a notable example of this is 21st",
      "offset": 1119.52,
      "duration": 7.279
    },
    {
      "lang": "en",
      "text": "dev magic MCP server where it injects",
      "offset": 1122.64,
      "duration": 6.72
    },
    {
      "lang": "en",
      "text": "some taste into this coding agent into",
      "offset": 1126.799,
      "duration": 5.281
    },
    {
      "lang": "en",
      "text": "the LLM where they have this library of",
      "offset": 1129.36,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "beautiful components and they just",
      "offset": 1132.08,
      "duration": 4.959
    },
    {
      "lang": "en",
      "text": "inject relevant examples so that client",
      "offset": 1134,
      "duration": 6.08
    },
    {
      "lang": "en",
      "text": "can go in and implement beautiful UIs",
      "offset": 1137.039,
      "duration": 5.361
    },
    {
      "lang": "en",
      "text": "and the way they monetize that was like",
      "offset": 1140.08,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "a standard API key. So, we're starting",
      "offset": 1142.4,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "to see developers really like um take",
      "offset": 1144.4,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "MCPs,",
      "offset": 1146.559,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "build them in, have distribution",
      "offset": 1148.08,
      "duration": 4.479
    },
    {
      "lang": "en",
      "text": "platforms like the MCP marketplace",
      "offset": 1150.72,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "incline and monetize their whole",
      "offset": 1152.559,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "business around that. So now it's like",
      "offset": 1155.36,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "almost like you're selling tools to",
      "offset": 1157.679,
      "duration": 2.88
    },
    {
      "lang": "en",
      "text": "agents,",
      "offset": 1159.28,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "which is a really interesting topic.",
      "offset": 1160.559,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "And you can do that because you're in VS",
      "offset": 1162.4,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "Code, so you have the terminal, so you",
      "offset": 1164.559,
      "duration": 4.801
    },
    {
      "lang": "en",
      "text": "can do npx run the different servers.",
      "offset": 1166.08,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "Have you thought about doing remote MCP",
      "offset": 1169.36,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "hosting or you feel like that's not",
      "offset": 1171.52,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "something you should take over?",
      "offset": 1173.36,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "Yeah, we haven't really hosted any",
      "offset": 1175.52,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "ourselves. We think that's we we're",
      "offset": 1177.2,
      "duration": 4.479
    },
    {
      "lang": "en",
      "text": "looking into it. I think it's it's all",
      "offset": 1179.84,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "very nent right now, the the remote",
      "offset": 1181.679,
      "duration": 4.641
    },
    {
      "lang": "en",
      "text": "MCPs, but we're definitely interested in",
      "offset": 1183.84,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "in supporting remote MCPs and and",
      "offset": 1186.32,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "listing them on our marketplace. And",
      "offset": 1188.96,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "another part I think with sort of local",
      "offset": 1190.88,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "MCP servers and remote MCPs is most of",
      "offset": 1194,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "the remote MCPs are only useful to",
      "offset": 1196.4,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "connect to different APIs, but that's",
      "offset": 1198,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "only a you know that's only a small use",
      "offset": 1200.559,
      "duration": 5.441
    },
    {
      "lang": "en",
      "text": "case for MCPs. A lot of MCPs help you",
      "offset": 1203.6,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "connect to different applications on",
      "offset": 1206,
      "duration": 2.799
    },
    {
      "lang": "en",
      "text": "your computer. For example, there's like",
      "offset": 1207.36,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "a a Unity MCP server that helps you",
      "offset": 1208.799,
      "duration": 5.041
    },
    {
      "lang": "en",
      "text": "create you know 3D objects within right",
      "offset": 1211.12,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "from within VS Code. There's uh an",
      "offset": 1213.84,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "Ableton MCP server so you can like make",
      "offset": 1215.6,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "songs using something like client or",
      "offset": 1217.52,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "whatever else uses MCPs. We won't see a",
      "offset": 1219.679,
      "duration": 5.041
    },
    {
      "lang": "en",
      "text": "world where these MCP servers are only",
      "offset": 1222.32,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "hosted remotely. There will always be",
      "offset": 1224.72,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "some mix of local MCP servers and remote",
      "offset": 1226.96,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "MCP servers. I think the remote MCP",
      "offset": 1230,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "servers do make uh the uh installation",
      "offset": 1231.6,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "process a little bit easier with you",
      "offset": 1234.159,
      "duration": 2.561
    },
    {
      "lang": "en",
      "text": "know with something like an OOTH flow",
      "offset": 1235.52,
      "duration": 2.96
    },
    {
      "lang": "en",
      "text": "and and just authenticating a little bit",
      "offset": 1236.72,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "not as painful as having to manage API",
      "offset": 1238.48,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "keys yourself. But for the most part, I",
      "offset": 1240.48,
      "duration": 5.199
    },
    {
      "lang": "en",
      "text": "think the MCP ecosystem is is is really",
      "offset": 1242.64,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "in its earlier days. We're still trying",
      "offset": 1245.679,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "to figure out this good balance of",
      "offset": 1247.2,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "security, but also convenience for the",
      "offset": 1249.919,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "end developer so that it's not a pain to",
      "offset": 1251.76,
      "duration": 4.799
    },
    {
      "lang": "en",
      "text": "have to set these things up. And I think",
      "offset": 1254.559,
      "duration": 3.201
    },
    {
      "lang": "en",
      "text": "we're still in this very much",
      "offset": 1256.559,
      "duration": 3.441
    },
    {
      "lang": "en",
      "text": "experimental phase about how useful it",
      "offset": 1257.76,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "is to people. And I think now that it is",
      "offset": 1260,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "seeing this level of market fit and and",
      "offset": 1262.08,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "people are coming out with you know",
      "offset": 1264.32,
      "duration": 2.8
    },
    {
      "lang": "en",
      "text": "these sorts of like articles and",
      "offset": 1265.919,
      "duration": 2.88
    },
    {
      "lang": "en",
      "text": "workflows about how it's totally",
      "offset": 1267.12,
      "duration": 2.799
    },
    {
      "lang": "en",
      "text": "changing their jobs. I think there's",
      "offset": 1268.799,
      "duration": 2.801
    },
    {
      "lang": "en",
      "text": "going to be a lot more of uh resources",
      "offset": 1269.919,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "and efforts that go into the ecosystem",
      "offset": 1271.6,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "and just building out the protocol which",
      "offset": 1273.6,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "I think there's a lot on anthropics road",
      "offset": 1275.52,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "map and I I think the community in",
      "offset": 1277.52,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "general just has a lot of ideas and our",
      "offset": 1279.28,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "marketplace in particular has has given",
      "offset": 1281.6,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "us insights into some ways that we could",
      "offset": 1283.52,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "improve it things that you know",
      "offset": 1286.08,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "developers have asked for uh from it",
      "offset": 1287.76,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "that where we're kind of thinking about",
      "offset": 1289.52,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "how do we you know what does the MP",
      "offset": 1291.12,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "marketplace of the future look like and",
      "offset": 1293.12,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "for us that's it's it's going to be a",
      "offset": 1295.28,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "combination of you know Well, there's a",
      "offset": 1297.76,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "lot of our users are very security",
      "offset": 1300.24,
      "duration": 3.679
    },
    {
      "lang": "en",
      "text": "conscious and there's a lot of ways that",
      "offset": 1301.84,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "MCP uh you know servers can be pretty",
      "offset": 1303.919,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "dangerous to use if you don't trust the",
      "offset": 1307.52,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "end developer of these things. And so",
      "offset": 1309.039,
      "duration": 3.361
    },
    {
      "lang": "en",
      "text": "we're trying to figure out you know what",
      "offset": 1310.96,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "is a a future look like where you can",
      "offset": 1312.4,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "where you have some level of confidence",
      "offset": 1314.48,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "in the MCP servers you're installing. I",
      "offset": 1317.2,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "think right now it's just it's too early",
      "offset": 1319.52,
      "duration": 3.279
    },
    {
      "lang": "en",
      "text": "and there's a lot of trust in the",
      "offset": 1320.96,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "community that I don't think a lot of",
      "offset": 1322.799,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "you know enterprise developers",
      "offset": 1324.48,
      "duration": 3.439
    },
    {
      "lang": "en",
      "text": "organizations are are quite willing to",
      "offset": 1326.159,
      "duration": 3.361
    },
    {
      "lang": "en",
      "text": "do yet. So that's something that's top",
      "offset": 1327.919,
      "duration": 2.88
    },
    {
      "lang": "en",
      "text": "of mind for us.",
      "offset": 1329.52,
      "duration": 2.8
    },
    {
      "lang": "en",
      "text": "There's an interesting tension between",
      "offset": 1330.799,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "the enthropic and the community here.",
      "offset": 1332.32,
      "duration": 4.479
    },
    {
      "lang": "en",
      "text": "You basically kind of have a model reg",
      "offset": 1334.559,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "MCP registry internally, right?",
      "offset": 1336.799,
      "duration": 3.441
    },
    {
      "lang": "en",
      "text": "Honestly, I think you should expose it.",
      "offset": 1339.039,
      "duration": 2.401
    },
    {
      "lang": "en",
      "text": "I was looking for it on your website and",
      "offset": 1340.24,
      "duration": 2.48
    },
    {
      "lang": "en",
      "text": "you don't have it. Like the only way to",
      "offset": 1341.44,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "access it is install client, but there's",
      "offset": 1342.72,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "others like uh smithery and all the",
      "offset": 1344.64,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "other guys, right? But then Anthropic",
      "offset": 1346.72,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "has also said they'll launch a model",
      "offset": 1348.559,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "registry at some point or MCP registry",
      "offset": 1351.44,
      "duration": 2.8
    },
    {
      "lang": "en",
      "text": "at some point. Some point",
      "offset": 1352.96,
      "duration": 2.959
    },
    {
      "lang": "en",
      "text": "if Enthropic launched the official one,",
      "offset": 1354.24,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "would they just just win by default?",
      "offset": 1355.919,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "Right. would because like would you just",
      "offset": 1357.6,
      "duration": 2.8
    },
    {
      "lang": "en",
      "text": "would you just use them?",
      "offset": 1359.6,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "I think so. I think the I think the",
      "offset": 1360.4,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "entire ecosystem will just converge",
      "offset": 1362.72,
      "duration": 2.64
    },
    {
      "lang": "en",
      "text": "around whatever they do. They just have",
      "offset": 1364.08,
      "duration": 2.88
    },
    {
      "lang": "en",
      "text": "such good distribution and and they're",
      "offset": 1365.36,
      "duration": 2.16
    },
    {
      "lang": "en",
      "text": "Yeah,",
      "offset": 1366.96,
      "duration": 1.599
    },
    {
      "lang": "en",
      "text": "they came up with it. So,",
      "offset": 1367.52,
      "duration": 2.159
    },
    {
      "lang": "en",
      "text": "yeah, exactly.",
      "offset": 1368.559,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "Cool. And I I wanted to uh I noticed",
      "offset": 1369.679,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "that you have some like really",
      "offset": 1371.679,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "downloaded MCPs. I was going by most",
      "offset": 1373.36,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "installs. I'm just going to read it off.",
      "offset": 1376.08,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "You can stop me anytime to uh comment on",
      "offset": 1377.44,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "them. So, top is file system MCP. Makes",
      "offset": 1380.08,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "sense. Browser tools from agent desk AI.",
      "offset": 1383.44,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "Don't know what that is. Sequential",
      "offset": 1385.44,
      "duration": 3.599
    },
    {
      "lang": "en",
      "text": "thinking that that one came out with the",
      "offset": 1387.12,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "original MCP release. Context 7. I don't",
      "offset": 1389.039,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "know that one.",
      "offset": 1392.32,
      "duration": 1.68
    },
    {
      "lang": "en",
      "text": "That's a that's a big one.",
      "offset": 1392.799,
      "duration": 2.161
    },
    {
      "lang": "en",
      "text": "What what is that?",
      "offset": 1394,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "That uh context 7 kind of helps you pull",
      "offset": 1394.96,
      "duration": 4.959
    },
    {
      "lang": "en",
      "text": "in documentation from anywhere and it",
      "offset": 1397.919,
      "duration": 4.801
    },
    {
      "lang": "en",
      "text": "has like this big index of all of the",
      "offset": 1399.919,
      "duration": 5.041
    },
    {
      "lang": "en",
      "text": "popular libraries and documentation for",
      "offset": 1402.72,
      "duration": 2.8
    },
    {
      "lang": "en",
      "text": "them.",
      "offset": 1404.96,
      "duration": 0.88
    },
    {
      "lang": "en",
      "text": "Okay.",
      "offset": 1405.52,
      "duration": 2.159
    },
    {
      "lang": "en",
      "text": "And you can your agent can kind of",
      "offset": 1405.84,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "submit like a natural language query",
      "offset": 1407.679,
      "duration": 5.441
    },
    {
      "lang": "en",
      "text": "and search for any docu everyone's docs.",
      "offset": 1410.08,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "Yes. Yeah. Uh, and apparently Upstash",
      "offset": 1413.12,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "did that which is also unusual because",
      "offset": 1415.12,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "Upstad",
      "offset": 1417.2,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "get tools that one came out originally.",
      "offset": 1418.96,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "Fetch browser use. Browser use I imagine",
      "offset": 1420.88,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "competes with browser tools, right? I",
      "offset": 1423.28,
      "duration": 4.639
    },
    {
      "lang": "en",
      "text": "guess. And then below that competition,",
      "offset": 1426,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "playright, right? Like so there's a lot",
      "offset": 1427.919,
      "duration": 2.961
    },
    {
      "lang": "en",
      "text": "of like let's automate the browser and",
      "offset": 1429.2,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "let's let's do stuff I assume for",
      "offset": 1430.88,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "debugging. Firecrawl puppeteer uh Figma",
      "offset": 1432.48,
      "duration": 5.84
    },
    {
      "lang": "en",
      "text": "here's one for you. Perplexity research",
      "offset": 1436.24,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "is that yours? Um well yeah I fork that",
      "offset": 1438.32,
      "duration": 5.92
    },
    {
      "lang": "en",
      "text": "one and listed it but yeah that's you",
      "offset": 1441.36,
      "duration": 4.559
    },
    {
      "lang": "en",
      "text": "know that's another very popular one",
      "offset": 1444.24,
      "duration": 2.48
    },
    {
      "lang": "en",
      "text": "where you can research",
      "offset": 1445.919,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "any people want to emulate the uh",
      "offset": 1446.72,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "automate the browser I'm just trying to",
      "offset": 1449.52,
      "duration": 3.039
    },
    {
      "lang": "en",
      "text": "learn lessons from what people are doing",
      "offset": 1451.039,
      "duration": 3.281
    },
    {
      "lang": "en",
      "text": "right they want to automate the browser",
      "offset": 1452.559,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "they want to access git and file system",
      "offset": 1454.32,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "they want to access docs and search",
      "offset": 1456.159,
      "duration": 4.481
    },
    {
      "lang": "en",
      "text": "anything else that you think like is",
      "offset": 1458.48,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "notable",
      "offset": 1460.64,
      "duration": 2.159
    },
    {
      "lang": "en",
      "text": "there's all kinds of stuff where it's",
      "offset": 1461.52,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "like you know there's like the the Slack",
      "offset": 1462.799,
      "duration": 4.721
    },
    {
      "lang": "en",
      "text": "MCP where you can send you know that's",
      "offset": 1464.72,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "actually one workflow that I have set up",
      "offset": 1467.52,
      "duration": 3.759
    },
    {
      "lang": "en",
      "text": "where you can like automate repetitive",
      "offset": 1469.76,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "tasks in client. So I tell a client like",
      "offset": 1471.279,
      "duration": 4.961
    },
    {
      "lang": "en",
      "text": "okay pull down this PR uh use the GH",
      "offset": 1472.96,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "command line tool which I already have",
      "offset": 1476.24,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "installed using the terminal to pull the",
      "offset": 1477.52,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "PR get the description of the PR the",
      "offset": 1480,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "discussion on it and get the full diff",
      "offset": 1482,
      "duration": 5.679
    },
    {
      "lang": "en",
      "text": "as like a like a single command",
      "offset": 1485.6,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "non-interactive command pull in all that",
      "offset": 1487.679,
      "duration": 5.201
    },
    {
      "lang": "en",
      "text": "context read the files around the diff",
      "offset": 1490.08,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "it ask a question like hey do you want",
      "offset": 1492.88,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "me to approve this or not with this",
      "offset": 1495.2,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "comment and if I say yes approve it and",
      "offset": 1496.799,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "then send a message in Slack to my team",
      "offset": 1498.88,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "using the Slack MCP for example.",
      "offset": 1500.72,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "Oh, use it to write.",
      "offset": 1502.96,
      "duration": 1.839
    },
    {
      "lang": "en",
      "text": "Yes.",
      "offset": 1504.4,
      "duration": 2.32
    },
    {
      "lang": "en",
      "text": "I would only use it to read.",
      "offset": 1504.799,
      "duration": 4.801
    },
    {
      "lang": "en",
      "text": "Yeah. No, it's, you know, people like I",
      "offset": 1506.72,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "love it. You know, I love being able to",
      "offset": 1509.6,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "just like send an automated message in",
      "offset": 1511.12,
      "duration": 4.559
    },
    {
      "lang": "en",
      "text": "Slack or whatever. Um, you can also like",
      "offset": 1513.12,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "set it up like set up your workflow",
      "offset": 1515.679,
      "duration": 3.041
    },
    {
      "lang": "en",
      "text": "however you want where it's like, okay,",
      "offset": 1517.2,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "client, please ask me before doing",
      "offset": 1518.72,
      "duration": 2.959
    },
    {
      "lang": "en",
      "text": "anything. You know, just make sure",
      "offset": 1520.4,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "you're asking me to like approve before",
      "offset": 1521.679,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "you send a message or something like",
      "offset": 1524.4,
      "duration": 1.92
    },
    {
      "lang": "en",
      "text": "that.",
      "offset": 1525.76,
      "duration": 2.96
    },
    {
      "lang": "en",
      "text": "Yeah. Okay. Just just to close out MCP",
      "offset": 1526.32,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "side, anything else interesting going on",
      "offset": 1528.72,
      "duration": 2.959
    },
    {
      "lang": "en",
      "text": "in MCP universe that we should talk",
      "offset": 1530.159,
      "duration": 5.281
    },
    {
      "lang": "en",
      "text": "about? MCP off was recently ratified.",
      "offset": 1531.679,
      "duration": 6.24
    },
    {
      "lang": "en",
      "text": "I think monetization is a big question",
      "offset": 1535.44,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "right now for the MCP ecosystem. Um,",
      "offset": 1537.919,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "we've been talking a lot with Stripe.",
      "offset": 1540.72,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "They're very bullish on MCP. Um, and",
      "offset": 1542.799,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "they're trying to figure out like a",
      "offset": 1545.6,
      "duration": 3.199
    },
    {
      "lang": "en",
      "text": "monetization layer for it,",
      "offset": 1546.799,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "but it's all so early that it's kind of",
      "offset": 1548.799,
      "duration": 5.921
    },
    {
      "lang": "en",
      "text": "hard to really even envision where it's",
      "offset": 1552.159,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "going to go. Let me just put up a straw",
      "offset": 1554.72,
      "duration": 2.64
    },
    {
      "lang": "en",
      "text": "man and then you can tell me what's",
      "offset": 1556.159,
      "duration": 2.961
    },
    {
      "lang": "en",
      "text": "wrong with it. Like how is this",
      "offset": 1557.36,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "different from API monetization, right?",
      "offset": 1559.12,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "Like you sign up here, make an account,",
      "offset": 1560.96,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "I give you a token back and then you use",
      "offset": 1563.12,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "token, they charge you against your",
      "offset": 1565.279,
      "duration": 4.241
    },
    {
      "lang": "en",
      "text": "usage. No, like like I think that's how",
      "offset": 1566.72,
      "duration": 4.559
    },
    {
      "lang": "en",
      "text": "it is right now. That's how like the the",
      "offset": 1569.52,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "magic uh MCP the 21st dev guys did it.",
      "offset": 1571.279,
      "duration": 5.441
    },
    {
      "lang": "en",
      "text": "But we're kind of envisioning a world",
      "offset": 1574.32,
      "duration": 6.32
    },
    {
      "lang": "en",
      "text": "where agents can pay themselves for",
      "offset": 1576.72,
      "duration": 6.559
    },
    {
      "lang": "en",
      "text": "these MCP tools that they're using and",
      "offset": 1580.64,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "pay for each tool call and you can't",
      "offset": 1583.279,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "deal with like a million different API",
      "offset": 1586.24,
      "duration": 3.439
    },
    {
      "lang": "en",
      "text": "keys from different products and like",
      "offset": 1588.159,
      "duration": 3.201
    },
    {
      "lang": "en",
      "text": "signing up for all this. There needs to",
      "offset": 1589.679,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "be like a unified kind of payment layer.",
      "offset": 1591.36,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "Some people talk about like stable coins",
      "offset": 1593.679,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "how like those are coming out now that",
      "offset": 1595.52,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "agents can natively use those. Stripe is",
      "offset": 1597.279,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "they're considering this like",
      "offset": 1600.08,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "abstraction around the MCP protocol for",
      "offset": 1601.44,
      "duration": 5.599
    },
    {
      "lang": "en",
      "text": "payments, but like I said, it's kind of",
      "offset": 1604.4,
      "duration": 4.639
    },
    {
      "lang": "en",
      "text": "hard to really tell where it's gonna how",
      "offset": 1607.039,
      "duration": 3.361
    },
    {
      "lang": "en",
      "text": "that's going to manifest.",
      "offset": 1609.039,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "I would say like we I I covered when",
      "offset": 1610.4,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "they launched their agent toolkit um",
      "offset": 1612.159,
      "duration": 4.961
    },
    {
      "lang": "en",
      "text": "last year, a few months ago, it seemed",
      "offset": 1615.12,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "like that was enough. Like it you didn't",
      "offset": 1617.12,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "seem to need stable coins except for the",
      "offset": 1618.96,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "fact that they take like 30 cents every",
      "offset": 1621.12,
      "duration": 2.4
    },
    {
      "lang": "en",
      "text": "transaction.",
      "offset": 1622.88,
      "duration": 2.159
    },
    {
      "lang": "en",
      "text": "Yeah.",
      "offset": 1623.52,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "Have you seen people use the X42 thing",
      "offset": 1625.039,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "by Coinbase to make it's basically like",
      "offset": 1628.08,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "the you can do a HTTP request that",
      "offset": 1630.159,
      "duration": 4.801
    },
    {
      "lang": "en",
      "text": "includes payment in it?",
      "offset": 1632.96,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "What? Yeah. Yeah. It's uh it's been",
      "offset": 1634.96,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "around forever the 402",
      "offset": 1637.6,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "error that's like payment not accepted",
      "offset": 1640.24,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "or something, right? So yeah, we've seen",
      "offset": 1642.4,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "some people talking about that like more",
      "offset": 1644.24,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "like natively building that in",
      "offset": 1645.84,
      "duration": 5.199
    },
    {
      "lang": "en",
      "text": "but yeah. Yeah, no one's really doing",
      "offset": 1648.48,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "that right now. anything you're seeing",
      "offset": 1651.039,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "on like are people like",
      "offset": 1653.12,
      "duration": 6.72
    },
    {
      "lang": "en",
      "text": "making MCP startups that are interesting",
      "offset": 1656.159,
      "duration": 6.88
    },
    {
      "lang": "en",
      "text": "mostly around rehosting local ones and",
      "offset": 1659.84,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "do remote and then basically do instead",
      "offset": 1663.039,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "of setting up 10 MCPS you have like a",
      "offset": 1664.88,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "canonical URL that you put in all of",
      "offset": 1666.88,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "your tools and then expose all the tools",
      "offset": 1668.72,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "from all the servers.",
      "offset": 1670.799,
      "duration": 1.681
    },
    {
      "lang": "en",
      "text": "Yeah. Yeah.",
      "offset": 1671.84,
      "duration": 3.439
    },
    {
      "lang": "en",
      "text": "There like MCP run some of these tools.",
      "offset": 1672.48,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "Yeah, but I think it kind of has the",
      "offset": 1675.279,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "same issues of how do you incentivize",
      "offset": 1676.799,
      "duration": 4.641
    },
    {
      "lang": "en",
      "text": "people to make better MCPs,",
      "offset": 1678.96,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "you know,",
      "offset": 1681.44,
      "duration": 2.16
    },
    {
      "lang": "en",
      "text": "and will it be mostly first party or",
      "offset": 1682,
      "duration": 3.279
    },
    {
      "lang": "en",
      "text": "will it be third party? Like your",
      "offset": 1683.6,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "Plexity MCP was the four. What was wrong",
      "offset": 1685.279,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "with the Plexity one?",
      "offset": 1687.12,
      "duration": 4.799
    },
    {
      "lang": "en",
      "text": "With MCPS and installing them locally on",
      "offset": 1688.799,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "your device, there's always a massive",
      "offset": 1691.919,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "risk associated with that. And when an",
      "offset": 1693.919,
      "duration": 4.801
    },
    {
      "lang": "en",
      "text": "MCP is created by someone that we have",
      "offset": 1696.559,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "no idea who they are, at any point they",
      "offset": 1698.72,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "might, you know, update the GitHub to",
      "offset": 1701.039,
      "duration": 3.281
    },
    {
      "lang": "en",
      "text": "like introduce some kind of malicious",
      "offset": 1702.88,
      "duration": 2.96
    },
    {
      "lang": "en",
      "text": "stuff. So even if you like verified it",
      "offset": 1704.32,
      "duration": 2.64
    },
    {
      "lang": "en",
      "text": "when you were listing it,",
      "offset": 1705.84,
      "duration": 1.439
    },
    {
      "lang": "en",
      "text": "okay,",
      "offset": 1706.96,
      "duration": 2.079
    },
    {
      "lang": "en",
      "text": "you might change it. So I ended up",
      "offset": 1707.279,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "having to fork a few of those to make",
      "offset": 1709.039,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "sure that we lock that version down.",
      "offset": 1710.96,
      "duration": 5.199
    },
    {
      "lang": "en",
      "text": "Oh, okay. So this is just like you're",
      "offset": 1713.279,
      "duration": 4.721
    },
    {
      "lang": "en",
      "text": "just forking it so that you you don't",
      "offset": 1716.159,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "change it without without notice.",
      "offset": 1718,
      "duration": 2.559
    },
    {
      "lang": "en",
      "text": "Interesting.",
      "offset": 1719.76,
      "duration": 2.08
    },
    {
      "lang": "en",
      "text": "These are all the problems of of a",
      "offset": 1720.559,
      "duration": 3.201
    },
    {
      "lang": "en",
      "text": "registry, right? Like that you need to",
      "offset": 1721.84,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "uh ensure security and all that.",
      "offset": 1723.76,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "Cool. I'm happy to move on. I I would",
      "offset": 1725.36,
      "duration": 2.799
    },
    {
      "lang": "en",
      "text": "say like the last thing that's kind of",
      "offset": 1726.88,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "curious is like if anthropic hasn't",
      "offset": 1728.159,
      "duration": 4.721
    },
    {
      "lang": "en",
      "text": "hadn't come along and made MCP, what",
      "offset": 1730.48,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "would have happened? And what's the",
      "offset": 1732.88,
      "duration": 2.24
    },
    {
      "lang": "en",
      "text": "alternative history? Like like would you",
      "offset": 1733.76,
      "duration": 2.96
    },
    {
      "lang": "en",
      "text": "have come with MCP?",
      "offset": 1735.12,
      "duration": 5.039
    },
    {
      "lang": "en",
      "text": "So we saw some of uh our competitors who",
      "offset": 1736.72,
      "duration": 4.559
    },
    {
      "lang": "en",
      "text": "have kind of working on their own",
      "offset": 1740.159,
      "duration": 3.041
    },
    {
      "lang": "en",
      "text": "version of plug-and-play tools into",
      "offset": 1741.279,
      "duration": 3.441
    },
    {
      "lang": "en",
      "text": "these agents. They kind of had to",
      "offset": 1743.2,
      "duration": 3.199
    },
    {
      "lang": "en",
      "text": "natively create these tools and",
      "offset": 1744.72,
      "duration": 3.439
    },
    {
      "lang": "en",
      "text": "integrations themselves. Yeah.",
      "offset": 1746.399,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "Directly into their product. And so I",
      "offset": 1748.159,
      "duration": 3.441
    },
    {
      "lang": "en",
      "text": "think anybody in the space would have",
      "offset": 1750.24,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "had to just do the laborious work of",
      "offset": 1751.6,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "having to recreate these tools and",
      "offset": 1754.159,
      "duration": 5.201
    },
    {
      "lang": "en",
      "text": "integrations for so I think and probably",
      "offset": 1756.24,
      "duration": 5.439
    },
    {
      "lang": "en",
      "text": "just saved us all a lot of trouble and",
      "offset": 1759.36,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "tapped into the power of open source and",
      "offset": 1761.679,
      "duration": 5.281
    },
    {
      "lang": "en",
      "text": "community driven development and allowed",
      "offset": 1764,
      "duration": 4.799
    },
    {
      "lang": "en",
      "text": "you know individual contributors to make",
      "offset": 1766.96,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "an MCP for anything people could think",
      "offset": 1768.799,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "of and really take advantage of people's",
      "offset": 1770.72,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "imagination in a way that I think is",
      "offset": 1772.64,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "like necessary right now for us to",
      "offset": 1774.48,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "really tap into full potential of of",
      "offset": 1776.08,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "this sort of thing. So,",
      "offset": 1778,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "we've had I think a dozen episodes with",
      "offset": 1779.52,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "different coding products. Um,",
      "offset": 1782,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "and this, by the way, this this episode",
      "offset": 1783.84,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "came directly out after he tweeted about",
      "offset": 1785.52,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "Claude the code episode.",
      "offset": 1787.679,
      "duration": 2.801
    },
    {
      "lang": "en",
      "text": "Where they were sitting right where",
      "offset": 1789.679,
      "duration": 1.281
    },
    {
      "lang": "en",
      "text": "you're sitting.",
      "offset": 1790.48,
      "duration": 2.4
    },
    {
      "lang": "en",
      "text": "Thanks for sharing the rag. Yeah.",
      "offset": 1790.96,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "Um, can you give people maybe the matrix",
      "offset": 1792.88,
      "duration": 5.679
    },
    {
      "lang": "en",
      "text": "of the market of, you know, you have",
      "offset": 1796.72,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "like fully agentic, no ID, you have a",
      "offset": 1798.559,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "gentic plus ID which is kind of yours,",
      "offset": 1800.96,
      "duration": 4.719
    },
    {
      "lang": "en",
      "text": "you have ID with some co-piloting. How",
      "offset": 1802.88,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "should people think about the different",
      "offset": 1805.679,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "tools and what you guys are best at or",
      "offset": 1806.88,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "maybe what you don't think you're best",
      "offset": 1809.279,
      "duration": 2.561
    },
    {
      "lang": "en",
      "text": "at?",
      "offset": 1811.279,
      "duration": 2.721
    },
    {
      "lang": "en",
      "text": "I think what we're best at and like our",
      "offset": 1811.84,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "ethos since the beginning is just meet",
      "offset": 1814,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "the developers where they're at today. I",
      "offset": 1815.44,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "think there is a little bit of insight",
      "offset": 1817.6,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "and handholding these models need right",
      "offset": 1819.84,
      "duration": 4.719
    },
    {
      "lang": "en",
      "text": "now and the IDE is sort of the perfect",
      "offset": 1822,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "conduit for something like that. You can",
      "offset": 1824.559,
      "duration": 2.961
    },
    {
      "lang": "en",
      "text": "see the edits it's making. You can see",
      "offset": 1826.159,
      "duration": 2.561
    },
    {
      "lang": "en",
      "text": "the commands that it's running. You can",
      "offset": 1827.52,
      "duration": 3.039
    },
    {
      "lang": "en",
      "text": "see the tools that it's calling. It",
      "offset": 1828.72,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "gives you the perfect UX for you to have",
      "offset": 1830.559,
      "duration": 4.961
    },
    {
      "lang": "en",
      "text": "the level of insight and control and be",
      "offset": 1833.44,
      "duration": 3.359
    },
    {
      "lang": "en",
      "text": "able to course correct the way that you",
      "offset": 1835.52,
      "duration": 2.96
    },
    {
      "lang": "en",
      "text": "need to to work with limitations of",
      "offset": 1836.799,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "these models today. But I I think it's",
      "offset": 1838.48,
      "duration": 3.439
    },
    {
      "lang": "en",
      "text": "pretty obvious that as the models get",
      "offset": 1840.72,
      "duration": 3.199
    },
    {
      "lang": "en",
      "text": "better, you'll be doing less and less of",
      "offset": 1841.919,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "that, less and less of that and more and",
      "offset": 1843.919,
      "duration": 3.441
    },
    {
      "lang": "en",
      "text": "more of the initial planning and",
      "offset": 1845.679,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "prompting and sort of have the trust and",
      "offset": 1847.36,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "confidence that you know the model will",
      "offset": 1850.159,
      "duration": 3.281
    },
    {
      "lang": "en",
      "text": "be able to get the job done pretty much",
      "offset": 1852,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "exactly how how you want it to. I think",
      "offset": 1853.44,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "there will always be a little bit of a",
      "offset": 1855.84,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "gap in that these models will never be",
      "offset": 1858,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "able to read our minds. So we'll we'll",
      "offset": 1860.88,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "there there will have to be a little bit",
      "offset": 1863.36,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "of you know making sure that you give it",
      "offset": 1865.12,
      "duration": 4.799
    },
    {
      "lang": "en",
      "text": "the most comprehensive and uh sort of",
      "offset": 1867.6,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "like all the details of what you want",
      "offset": 1869.919,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "from it. So if you're a lazy prompter",
      "offset": 1871.44,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "you can expect a ton of friction and",
      "offset": 1874.08,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "back and forth before you really get",
      "offset": 1876.32,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "what you want. But I think we're we're",
      "offset": 1877.6,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "all learning for ourselves as we work",
      "offset": 1879.52,
      "duration": 2.879
    },
    {
      "lang": "en",
      "text": "with these things kind of the right way",
      "offset": 1880.96,
      "duration": 3.439
    },
    {
      "lang": "en",
      "text": "to prompt these things and uh to be",
      "offset": 1882.399,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "explicit about what it is that we want",
      "offset": 1884.399,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "and kind of how they hallucinate the",
      "offset": 1885.919,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "gaps that they might need to fill to to",
      "offset": 1888.159,
      "duration": 2.961
    },
    {
      "lang": "en",
      "text": "get to the end result and how we might",
      "offset": 1889.679,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "want to avoid something like that. So",
      "offset": 1891.12,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "what's interesting about cloud code is",
      "offset": 1892.799,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "there isn't really a lot of insight into",
      "offset": 1894.32,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "what the agent's doing. Kind of gives",
      "offset": 1895.919,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "you this like checklist of what it's",
      "offset": 1897.84,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "doing at holistically at at a high",
      "offset": 1899.6,
      "duration": 3.439
    },
    {
      "lang": "en",
      "text": "level. I don't think that really would",
      "offset": 1901.36,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "have worked well if the models weren't",
      "offset": 1903.039,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "good enough to actually produce work",
      "offset": 1905.12,
      "duration": 5.039
    },
    {
      "lang": "en",
      "text": "that people were generally happy with.",
      "offset": 1907.679,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "We're kind of there and I think the",
      "offset": 1910.159,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "space has to catch up to okay maybe",
      "offset": 1911.519,
      "duration": 4.481
    },
    {
      "lang": "en",
      "text": "people don't need as much insight into",
      "offset": 1914,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "these sorts of things anymore and they",
      "offset": 1916,
      "duration": 3.039
    },
    {
      "lang": "en",
      "text": "they are okay with letting an agent kind",
      "offset": 1917.36,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "of get the job done and really all you",
      "offset": 1919.039,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "need to see is sort of the end result",
      "offset": 1920.88,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "and tweak it a little bit before it's",
      "offset": 1922.799,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "it's really perfect and I think there is",
      "offset": 1924.72,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "going to be different tools for",
      "offset": 1926.799,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "different jobs. I think something like",
      "offset": 1928.559,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "totally autonomous agent that you don't",
      "offset": 1930.72,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "have a lot of insight into is great for",
      "offset": 1933.679,
      "duration": 5.281
    },
    {
      "lang": "en",
      "text": "maybe scaffolding new projects but for",
      "offset": 1935.84,
      "duration": 5.439
    },
    {
      "lang": "en",
      "text": "kind of the serious more complex sorts",
      "offset": 1938.96,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "of things where you know you do need a",
      "offset": 1941.279,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "certain level of insight or you do need",
      "offset": 1943.36,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "to kind of have like more engagement you",
      "offset": 1945.6,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "might want to use something that does",
      "offset": 1947.76,
      "duration": 2.96
    },
    {
      "lang": "en",
      "text": "give you some more insight. So I think I",
      "offset": 1948.88,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "think these sorts of tools complement",
      "offset": 1950.72,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "each other. So, for example, writing",
      "offset": 1952.08,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "tests or spinning off 10 agents to try",
      "offset": 1954.32,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "to fix the same bug, you know, might be",
      "offset": 1957.12,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "useful for a tool that doesn't require",
      "offset": 1958.96,
      "duration": 5.199
    },
    {
      "lang": "en",
      "text": "too much engagement from you. Whereas",
      "offset": 1962.24,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "something that requires a little bit",
      "offset": 1964.159,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "more creativity or imagination or",
      "offset": 1965.36,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "extracting context from your brain,",
      "offset": 1967.84,
      "duration": 4.559
    },
    {
      "lang": "en",
      "text": "requires a little bit more of a insight",
      "offset": 1970.24,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "into what the model's doing and a back",
      "offset": 1972.399,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "and forth that I think client is a",
      "offset": 1974.399,
      "duration": 4.801
    },
    {
      "lang": "en",
      "text": "little better like visibility into what",
      "offset": 1976.48,
      "duration": 4.799
    },
    {
      "lang": "en",
      "text": "the agent is doing. That's like one axis",
      "offset": 1979.2,
      "duration": 5.92
    },
    {
      "lang": "en",
      "text": "and then another is autonomy like how",
      "offset": 1981.279,
      "duration": 7.28
    },
    {
      "lang": "en",
      "text": "how automated it is and we have a",
      "offset": 1985.12,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "category of companies that are focusing",
      "offset": 1988.559,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "more on the use case of people that",
      "offset": 1991.12,
      "duration": 3.279
    },
    {
      "lang": "en",
      "text": "don't even want to look at code which is",
      "offset": 1992.559,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "like you know the lovables the replets",
      "offset": 1994.399,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "where it's like you go in you build an",
      "offset": 1996.64,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "app you might not even be technical and",
      "offset": 1998.24,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "you're just happy with the result and",
      "offset": 2000.64,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "then you have kind of stuff that's kind",
      "offset": 2002.64,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "of like a hybrid where it's you know for",
      "offset": 2004.799,
      "duration": 4.801
    },
    {
      "lang": "en",
      "text": "engineers it's built for engineers but",
      "offset": 2007.039,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "you don't really have a lot of",
      "offset": 2009.6,
      "duration": 2.24
    },
    {
      "lang": "en",
      "text": "visibility into what's going on under",
      "offset": 2010.559,
      "duration": 2.72
    },
    {
      "lang": "en",
      "text": "the hood. This is like for like the vibe",
      "offset": 2011.84,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "coders where they're, you know, fully,",
      "offset": 2013.279,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "you know, letting letting the AI take",
      "offset": 2015.84,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "the wheel and building stuff very",
      "offset": 2017.679,
      "duration": 5.441
    },
    {
      "lang": "en",
      "text": "rapidly. Lots of open source fans and,",
      "offset": 2020,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "you know, people that are hobbyists",
      "offset": 2023.12,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "enjoy coding in this in this manner. It",
      "offset": 2025.36,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "is really fun. And then you get to like",
      "offset": 2027.6,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "serious engineering teams where they",
      "offset": 2029.76,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "can't really give everything over to the",
      "offset": 2032.24,
      "duration": 7.12
    },
    {
      "lang": "en",
      "text": "AI, at least not yet. and they need to",
      "offset": 2035.76,
      "duration": 5.919
    },
    {
      "lang": "en",
      "text": "have high visibility into what's going",
      "offset": 2039.36,
      "duration": 4.559
    },
    {
      "lang": "en",
      "text": "on at every step of the way and make",
      "offset": 2041.679,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "sure that they actually understand",
      "offset": 2043.919,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "what's happening with their code. You're",
      "offset": 2045.279,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "kind of handing off your production code",
      "offset": 2047.76,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "base to this nondeterministic system and",
      "offset": 2049.44,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "then hoping that you catch it in review",
      "offset": 2052.24,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "if anything goes wrong. Whereas",
      "offset": 2054.56,
      "duration": 5.119
    },
    {
      "lang": "en",
      "text": "personally the way I use um AI, the way",
      "offset": 2057.2,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "I use Klein is I like to be there every",
      "offset": 2059.679,
      "duration": 4.641
    },
    {
      "lang": "en",
      "text": "step of the way and kind of guide it in",
      "offset": 2062.8,
      "duration": 2.72
    },
    {
      "lang": "en",
      "text": "the right direction. So I know every",
      "offset": 2064.32,
      "duration": 2.96
    },
    {
      "lang": "en",
      "text": "step of the way like as every file is",
      "offset": 2065.52,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "being edited, I approve every single",
      "offset": 2067.28,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "thing and make sure that things are",
      "offset": 2068.8,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "going in the right direction and I have",
      "offset": 2071.44,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "a good understanding as things are being",
      "offset": 2072.8,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "developed where it's going. So like this",
      "offset": 2074.72,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "kind of hybrid workflow really works for",
      "offset": 2076.56,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "me personally. But you know sometimes if",
      "offset": 2078.32,
      "duration": 5.92
    },
    {
      "lang": "en",
      "text": "I want to go full yolo mode I go ahead",
      "offset": 2081.44,
      "duration": 4.479
    },
    {
      "lang": "en",
      "text": "and just auto approve everything and",
      "offset": 2084.24,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "just step out for a cup of coffee and",
      "offset": 2085.919,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "then come back and you know review the",
      "offset": 2088.079,
      "duration": 2.56
    },
    {
      "lang": "en",
      "text": "work.",
      "offset": 2090.079,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "My issue with this as an engineer myself",
      "offset": 2090.639,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "is that we all want to believe that we",
      "offset": 2093.839,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "work on the complex things. U how have",
      "offset": 2095.839,
      "duration": 6.881
    },
    {
      "lang": "en",
      "text": "you guys seen the line of complex change",
      "offset": 2099.839,
      "duration": 4.801
    },
    {
      "lang": "en",
      "text": "over time? I mean if we sat down having",
      "offset": 2102.72,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "this discussion 12 months ago complex",
      "offset": 2104.64,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "was like much easier than today for the",
      "offset": 2107.04,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "models. Do you feel like that's evolving",
      "offset": 2108.8,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "quickly enough that like you know in 18",
      "offset": 2110.8,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "months it's like you should probably",
      "offset": 2112.96,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "just do full gentech for like 75% of",
      "offset": 2115.119,
      "duration": 4.801
    },
    {
      "lang": "en",
      "text": "work 80% of work or do you feel like",
      "offset": 2117.28,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "it's not moving as quickly as you",
      "offset": 2119.92,
      "duration": 1.679
    },
    {
      "lang": "en",
      "text": "thought?",
      "offset": 2121.28,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "I think I think what was complex a",
      "offset": 2121.599,
      "duration": 5.041
    },
    {
      "lang": "en",
      "text": "couple years ago is totally different to",
      "offset": 2124.64,
      "duration": 4.719
    },
    {
      "lang": "en",
      "text": "what is complex today. Now, I think what",
      "offset": 2126.64,
      "duration": 4.959
    },
    {
      "lang": "en",
      "text": "we need to be more intentional about are",
      "offset": 2129.359,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "the architectural decisions we make",
      "offset": 2131.599,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "really early on and how the model kind",
      "offset": 2133.2,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "of builds on top of that. If you have",
      "offset": 2136.079,
      "duration": 3.361
    },
    {
      "lang": "en",
      "text": "kind of a clear direction of where",
      "offset": 2138.24,
      "duration": 2.64
    },
    {
      "lang": "en",
      "text": "things are headed and what you want, you",
      "offset": 2139.44,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "kind of have a good idea to about how",
      "offset": 2140.88,
      "duration": 2.8
    },
    {
      "lang": "en",
      "text": "you might want to like lay the",
      "offset": 2142.64,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "foundation for the code base that you're",
      "offset": 2143.68,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "producing. And I think what we might",
      "offset": 2146.16,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "have considered complex a few years ago,",
      "offset": 2147.839,
      "duration": 4.801
    },
    {
      "lang": "en",
      "text": "algorithmic, you know, challenges,",
      "offset": 2150.32,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "that's pretty trivial for models today",
      "offset": 2152.64,
      "duration": 2.24
    },
    {
      "lang": "en",
      "text": "and stuff that we don't really",
      "offset": 2154,
      "duration": 2.079
    },
    {
      "lang": "en",
      "text": "necessarily have to think too much about",
      "offset": 2154.88,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "anymore. we kind of give it, you know, a",
      "offset": 2156.079,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "certain expectation or unit test about",
      "offset": 2158.64,
      "duration": 3.199
    },
    {
      "lang": "en",
      "text": "what we want and it kind of goes off and",
      "offset": 2160.079,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "puts together the, you know, the perfect",
      "offset": 2161.839,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "solution. So, I think there's a lot more",
      "offset": 2163.359,
      "duration": 4.561
    },
    {
      "lang": "en",
      "text": "thought that has to go into tasteful",
      "offset": 2166.079,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "architectural decisions that really",
      "offset": 2167.92,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "comes down to you having experience with",
      "offset": 2169.92,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "what works and what doesn't work, having",
      "offset": 2172.96,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "a clear idea for the direction of where",
      "offset": 2174.64,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "you want to take the project and sort",
      "offset": 2176.8,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "your vision for the codebase. Those are",
      "offset": 2178.96,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "all decisions that I think is is is hard",
      "offset": 2181.52,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "to rely on a model for because of its",
      "offset": 2183.28,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "limited context and it's you know its",
      "offset": 2185.28,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "inability to kind of see your vision for",
      "offset": 2187.28,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "things and really have a good",
      "offset": 2188.8,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "understanding of of uh what you're",
      "offset": 2190.4,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "trying to accomplish without you you",
      "offset": 2192.4,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "know putting together a massive prompt",
      "offset": 2194,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "of of you know everything that you want",
      "offset": 2196.24,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "from it. I think what we were you know",
      "offset": 2198,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "what we spent most of our time working",
      "offset": 2200.079,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "on a couple years ago has totally",
      "offset": 2202,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "changed and and I think for the better.",
      "offset": 2203.599,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "I think architectural decisions are a",
      "offset": 2205.52,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "lot more fun to think about than putting",
      "offset": 2207.119,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "together algorithms. It kind of frees up",
      "offset": 2208.96,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "the senior software engineers to think",
      "offset": 2211.119,
      "duration": 4.801
    },
    {
      "lang": "en",
      "text": "more architecturally. And then once they",
      "offset": 2213.359,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "they have a really good understanding of",
      "offset": 2215.92,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "what's what the current state of the",
      "offset": 2217.2,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "repository is, what the current state of",
      "offset": 2219.44,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "the architecture is, and when they're",
      "offset": 2221.44,
      "duration": 2.399
    },
    {
      "lang": "en",
      "text": "introducing something new, they're",
      "offset": 2222.64,
      "duration": 2.88
    },
    {
      "lang": "en",
      "text": "really thinking at an architectural",
      "offset": 2223.839,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "level, and they articulate that decline.",
      "offset": 2225.52,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "And that's also there's like some skill",
      "offset": 2227.92,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "involved there. Um, and some of that can",
      "offset": 2229.44,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "be mitigated with like asking follow-up",
      "offset": 2231.68,
      "duration": 3.439
    },
    {
      "lang": "en",
      "text": "questions, being proactive about",
      "offset": 2233.599,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "clarifying things on the agent side, but",
      "offset": 2235.119,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "ultimately you need to articulate this",
      "offset": 2237.599,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "new architecture to the agent and then",
      "offset": 2239.44,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "the agent can go down and and down into",
      "offset": 2241.28,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "the minds and implement everything for",
      "offset": 2243.2,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "you and it is more fun working that way.",
      "offset": 2245.28,
      "duration": 4.799
    },
    {
      "lang": "en",
      "text": "Like personally like I I find it a lot",
      "offset": 2248.4,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "more engaging and just think on a more",
      "offset": 2250.079,
      "duration": 4.721
    },
    {
      "lang": "en",
      "text": "architectural level. And for junior",
      "offset": 2252.88,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "engineers, um, it's a really good",
      "offset": 2254.8,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "paradigm to learn about the codebase.",
      "offset": 2257.76,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "It's kind of like having a senior",
      "offset": 2260.56,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "engineer in your back pocket where",
      "offset": 2261.76,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "you're asking client like, \"Hey, can you",
      "offset": 2264,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "explain the re the repository for me? If",
      "offset": 2265.92,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "I wanted to implement something like",
      "offset": 2267.76,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "this, what files would I look at? How",
      "offset": 2268.96,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "does this work?\" It's great for that as",
      "offset": 2270.96,
      "duration": 2.72
    },
    {
      "lang": "en",
      "text": "well.",
      "offset": 2273.119,
      "duration": 2.881
    },
    {
      "lang": "en",
      "text": "If we're moving on from competition, I",
      "offset": 2273.68,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "have one last question on competition.",
      "offset": 2276,
      "duration": 2.079
    },
    {
      "lang": "en",
      "text": "Yeah.",
      "offset": 2277.599,
      "duration": 3.201
    },
    {
      "lang": "en",
      "text": "So, there's Twitter beef with Rukode. I",
      "offset": 2278.079,
      "duration": 4.961
    },
    {
      "lang": "en",
      "text": "just want to know where the backstory is",
      "offset": 2280.8,
      "duration": 4.799
    },
    {
      "lang": "en",
      "text": "because you tweeted yesterday. Somebody",
      "offset": 2283.04,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "asked Ruko to add Gemini CLI support and",
      "offset": 2285.599,
      "duration": 4.561
    },
    {
      "lang": "en",
      "text": "then you guys responded just copy it",
      "offset": 2288.4,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "from us again and they said thank you.",
      "offset": 2290.16,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "We'll make sure to give credit.",
      "offset": 2291.76,
      "duration": 2.96
    },
    {
      "lang": "en",
      "text": "Is it a real beef?",
      "offset": 2293.44,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "No. A friendly beef.",
      "offset": 2294.72,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "I think we're all just having fun on the",
      "offset": 2296.72,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "timeline. Um there's there's a lot of",
      "offset": 2298.32,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "forks uh that",
      "offset": 2301.119,
      "duration": 2.801
    },
    {
      "lang": "en",
      "text": "like 6,000 forks though. Yeah, there's",
      "offset": 2302.48,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "like if you search Klein on the the VS",
      "offset": 2303.92,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "Code marketplace, it's like the entire",
      "offset": 2305.68,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "page just like forks of Klein and um",
      "offset": 2308.079,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "there's like even forks of forks that",
      "offset": 2311.28,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "you know came out and raised like a",
      "offset": 2313.359,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "whole bunch of money and and it's Yeah,",
      "offset": 2315.04,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "the top three apps the top three apps in",
      "offset": 2317.119,
      "duration": 5.921
    },
    {
      "lang": "en",
      "text": "Open Router are all clinky.",
      "offset": 2319.119,
      "duration": 5.601
    },
    {
      "lang": "en",
      "text": "Yeah. Billions of tokens getting sent",
      "offset": 2323.04,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "through like all these forks. Um there's",
      "offset": 2324.72,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "like there's like fork wars and 10,000",
      "offset": 2327.119,
      "duration": 4.881
    },
    {
      "lang": "en",
      "text": "forks and all you need is a knife, you",
      "offset": 2330.32,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "know? So, uh, no, it's it's exciting.",
      "offset": 2332,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "Uh, I think they're all really cool",
      "offset": 2335.52,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "people. We got people in Europe forking",
      "offset": 2337.28,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "us. We got people in China making like a",
      "offset": 2339.04,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "little fork of us. I think Samsung, uh,",
      "offset": 2340.8,
      "duration": 4.559
    },
    {
      "lang": "en",
      "text": "recently came out with like a was a Wall",
      "offset": 2343.2,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "Street Journal article where they're",
      "offset": 2345.359,
      "duration": 2.561
    },
    {
      "lang": "en",
      "text": "using Klein, but they're using like",
      "offset": 2346.72,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "their own little fork of Klein that's",
      "offset": 2347.92,
      "duration": 3.439
    },
    {
      "lang": "en",
      "text": "kind of isolated,",
      "offset": 2350,
      "duration": 2.8
    },
    {
      "lang": "en",
      "text": "you know, we we encourage it.",
      "offset": 2351.359,
      "duration": 3.441
    },
    {
      "lang": "en",
      "text": "Do you have any regrets about being open",
      "offset": 2352.8,
      "duration": 2.799
    },
    {
      "lang": "en",
      "text": "source or",
      "offset": 2354.8,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "Not at all? I think client started off",
      "offset": 2355.599,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "as this like really good foundation for",
      "offset": 2358,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "what a coding agent looks like and",
      "offset": 2359.52,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "people just had a lot of their own",
      "offset": 2361.28,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "really interesting ideas and spin-offs",
      "offset": 2362.64,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "and concepts about you know what they",
      "offset": 2364.8,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "thought you know they that they wanted",
      "offset": 2367.2,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "to build on top of it was and just being",
      "offset": 2369.04,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "able to see that and see the excitement",
      "offset": 2370.72,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "around just in the space in general has",
      "offset": 2372.64,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "just been I think inspirational and has",
      "offset": 2375.04,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "helped us kind of glean insights into",
      "offset": 2377.04,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "what works and what doesn't work and",
      "offset": 2379.119,
      "duration": 3.281
    },
    {
      "lang": "en",
      "text": "incorporate that into our own product",
      "offset": 2380.56,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "and for the most part I think for you",
      "offset": 2382.4,
      "duration": 2.959
    },
    {
      "lang": "en",
      "text": "know the Samsung's and all the",
      "offset": 2384.32,
      "duration": 2.4
    },
    {
      "lang": "en",
      "text": "organizations where there is a lot of",
      "offset": 2385.359,
      "duration": 3.041
    },
    {
      "lang": "en",
      "text": "friction and being able to use software",
      "offset": 2386.72,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "like this on their on their code bases.",
      "offset": 2388.4,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "It reduces that barrier to entry which I",
      "offset": 2390.4,
      "duration": 3.439
    },
    {
      "lang": "en",
      "text": "think is like incredibly important when",
      "offset": 2392.16,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "you want to get your feet wet with this",
      "offset": 2393.839,
      "duration": 4.481
    },
    {
      "lang": "en",
      "text": "whole new agentic coding paradigm that's",
      "offset": 2395.68,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "going to completely upend the way that",
      "offset": 2398.32,
      "duration": 3.519
    },
    {
      "lang": "en",
      "text": "we've written software for for decades.",
      "offset": 2399.68,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "So in the grand scheme of things, it's I",
      "offset": 2401.839,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "think it's in that positive for the",
      "offset": 2403.599,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "world and for the space and so no",
      "offset": 2405.119,
      "duration": 2.881
    },
    {
      "lang": "en",
      "text": "regrets",
      "offset": 2407.28,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "in a lot of ways. Like you know it's us",
      "offset": 2408,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "and the forks. We were kind of there",
      "offset": 2410.32,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "originally when we were like the only",
      "offset": 2412.24,
      "duration": 4.879
    },
    {
      "lang": "en",
      "text": "ones with this like philosophy of",
      "offset": 2414.24,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "keeping things simple, keeping things",
      "offset": 2417.119,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "down to like the model, letting the",
      "offset": 2418.72,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "model do everything, not cutting on not",
      "offset": 2421.119,
      "duration": 4.881
    },
    {
      "lang": "en",
      "text": "trying to make money off of inference,",
      "offset": 2423.76,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "going context heavy, reading files into",
      "offset": 2426,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "context very aggressively. And kind of",
      "offset": 2428.56,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "going back to cloud code, I was actually",
      "offset": 2431.28,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "like it was really nice to see that they",
      "offset": 2433.28,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "they came out and they validated our our",
      "offset": 2434.88,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "whole philosophy of like keeping things",
      "offset": 2436.88,
      "duration": 4.719
    },
    {
      "lang": "en",
      "text": "as simple as possible. And that kind of",
      "offset": 2439.68,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "goes in with like the whole rag thing,",
      "offset": 2441.599,
      "duration": 5.281
    },
    {
      "lang": "en",
      "text": "which is like rag was this early thing",
      "offset": 2443.04,
      "duration": 7.2
    },
    {
      "lang": "en",
      "text": "in like 2022, you started getting these",
      "offset": 2446.88,
      "duration": 4.959
    },
    {
      "lang": "en",
      "text": "vector database companies. Context",
      "offset": 2450.24,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "windows were very small. This was like a",
      "offset": 2451.839,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "way of people called it like, oh, you",
      "offset": 2453.52,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "can give your AI infinite memory. It's",
      "offset": 2455.68,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "not really that, but that was like the",
      "offset": 2457.68,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "marketing that was sold to the venture",
      "offset": 2460.64,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "backers that were like investing in all",
      "offset": 2462.72,
      "duration": 3.599
    },
    {
      "lang": "en",
      "text": "these companies and it became this",
      "offset": 2464.48,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "narrative that really stuck around. And",
      "offset": 2466.319,
      "duration": 4.641
    },
    {
      "lang": "en",
      "text": "like even now like we we get like",
      "offset": 2469.04,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "potential like you know enterprise",
      "offset": 2470.96,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "perspective like they're they're going",
      "offset": 2473.2,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "through like the procurement process and",
      "offset": 2475.2,
      "duration": 2.56
    },
    {
      "lang": "en",
      "text": "they're it's almost like they're going",
      "offset": 2476.72,
      "duration": 3.119
    },
    {
      "lang": "en",
      "text": "through like a checklist asking like hey",
      "offset": 2477.76,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "do you guys do like indexing like of the",
      "offset": 2479.839,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "codebase and doing rag and I'm like well",
      "offset": 2482.16,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "why like why are you like why do you",
      "offset": 2483.839,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "want to do this? Um, I think Boris said",
      "offset": 2486.16,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "it said it very well on on this exact",
      "offset": 2489.599,
      "duration": 4.561
    },
    {
      "lang": "en",
      "text": "podcast where we tried Rag and it",
      "offset": 2491.68,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "doesn't really work very well,",
      "offset": 2494.16,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "especially for coding is like the way",
      "offset": 2495.2,
      "duration": 5.919
    },
    {
      "lang": "en",
      "text": "Rag works is you have to like chunk all",
      "offset": 2497.44,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "these files across your entire",
      "offset": 2501.119,
      "duration": 3.121
    },
    {
      "lang": "en",
      "text": "repository and like chop them up into",
      "offset": 2502.56,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "small little pieces and then throw them",
      "offset": 2504.24,
      "duration": 5.119
    },
    {
      "lang": "en",
      "text": "into this hyperdimensional vector space",
      "offset": 2506.4,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "and then pull out these random chunks",
      "offset": 2509.359,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "when you're searching for relevant code",
      "offset": 2511.04,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "snippets. And it's like fundamentally",
      "offset": 2513.119,
      "duration": 3.761
    },
    {
      "lang": "en",
      "text": "it's like so skitso and like I think it",
      "offset": 2514.96,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "actually distracts the model and you get",
      "offset": 2516.88,
      "duration": 4.239
    },
    {
      "lang": "en",
      "text": "worse performance than just doing what",
      "offset": 2519.28,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "like a senior software engineer does",
      "offset": 2521.119,
      "duration": 3.521
    },
    {
      "lang": "en",
      "text": "when they first they're introduced to a",
      "offset": 2522.56,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "new repository which like you look at",
      "offset": 2524.64,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "the folder structure. You look through",
      "offset": 2526.4,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "the files. Oh, this file imports from",
      "offset": 2528.4,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "this other file. Let's go take a look at",
      "offset": 2530.88,
      "duration": 3.439
    },
    {
      "lang": "en",
      "text": "that. And you kind of agentically",
      "offset": 2532.48,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "explore the repository. That's like",
      "offset": 2534.319,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "we've found that works so much better.",
      "offset": 2536.96,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "And there's like similar things where",
      "offset": 2538.64,
      "duration": 3.679
    },
    {
      "lang": "en",
      "text": "it's like like the simplicity always",
      "offset": 2540.24,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "wins like this bitter lesson where fast",
      "offset": 2542.319,
      "duration": 5.361
    },
    {
      "lang": "en",
      "text": "apply is another example. So cursor came",
      "offset": 2544.88,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "out with this fast apply like they call",
      "offset": 2547.68,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "the instant apply back in July of 2024",
      "offset": 2549.68,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "where the idea was models at the time",
      "offset": 2552.96,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "were not very good at editing files. And",
      "offset": 2555.44,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "the way editing files works in kind of",
      "offset": 2558,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "the context of an agent is you have a",
      "offset": 2560,
      "duration": 3.359
    },
    {
      "lang": "en",
      "text": "search block and then a replace block",
      "offset": 2562,
      "duration": 2.64
    },
    {
      "lang": "en",
      "text": "where you have to like match the search",
      "offset": 2563.359,
      "duration": 2.72
    },
    {
      "lang": "en",
      "text": "block exactly to what you're trying to",
      "offset": 2564.64,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "replace and then a replace block just",
      "offset": 2566.079,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "swaps that out. And at the time models",
      "offset": 2567.76,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "were not very good. It was like I forget",
      "offset": 2570.079,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "like GPT they were using under the hood",
      "offset": 2572.24,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "at the time wasn't very good at",
      "offset": 2574.16,
      "duration": 2.88
    },
    {
      "lang": "en",
      "text": "formulating these search blocks",
      "offset": 2575.76,
      "duration": 2.8
    },
    {
      "lang": "en",
      "text": "perfectly and it would fail oftent",
      "offset": 2577.04,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "times. So they came up with this clever",
      "offset": 2578.56,
      "duration": 6.24
    },
    {
      "lang": "en",
      "text": "workaround to fine-tune this fast apply",
      "offset": 2580.96,
      "duration": 7.44
    },
    {
      "lang": "en",
      "text": "model where they let these frontier",
      "offset": 2584.8,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "models at the time they let them be",
      "offset": 2588.4,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "vague. They let them output those like",
      "offset": 2589.92,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "lazy code snippets that we're all very",
      "offset": 2591.92,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "familiar with where it's like rest of",
      "offset": 2593.76,
      "duration": 2.88
    },
    {
      "lang": "en",
      "text": "the file here or like rest of the",
      "offset": 2595.04,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "imports here and then fed that into this",
      "offset": 2596.64,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "fine-tuned fast supply model that was",
      "offset": 2599.76,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "like probably like a Quen 7B or",
      "offset": 2601.92,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "something quantized very small dinky",
      "offset": 2604.56,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "little model and they they fed this lazy",
      "offset": 2607.04,
      "duration": 5.92
    },
    {
      "lang": "en",
      "text": "code snippet into this smaller model and",
      "offset": 2610.56,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "the smaller model we fine-tuned to",
      "offset": 2612.96,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "output the entire file with the code",
      "offset": 2614.56,
      "duration": 6.32
    },
    {
      "lang": "en",
      "text": "changes applied and that you know the",
      "offset": 2616.16,
      "duration": 6.48
    },
    {
      "lang": "en",
      "text": "one of the founders of Ader said this",
      "offset": 2620.88,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "really well in like very early GitHub",
      "offset": 2622.64,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "discussions where he said like well now",
      "offset": 2624.56,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "instead of worrying about one model",
      "offset": 2627.2,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "messing things up now you have to worry",
      "offset": 2629.92,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "about two models messing things up and",
      "offset": 2631.44,
      "duration": 4.879
    },
    {
      "lang": "en",
      "text": "what's worse is the other model that",
      "offset": 2633.2,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "you're giving that you're handing your",
      "offset": 2636.319,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "production code to this like fastify",
      "offset": 2637.92,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "model it's like it's a tiny model its",
      "offset": 2640.079,
      "duration": 4.961
    },
    {
      "lang": "en",
      "text": "reasoning is not very good it's maximum",
      "offset": 2642.24,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "output tokens you know there might be",
      "offset": 2645.04,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "8,000 tokens 16,000 tokens Now they're",
      "offset": 2647.52,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "training like 32,000 tokens maybe. And a",
      "offset": 2650.24,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "lot of the coding files like we have a",
      "offset": 2653.28,
      "duration": 3.039
    },
    {
      "lang": "en",
      "text": "file in our repository that's like",
      "offset": 2654.72,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "42,000 tokens long and that's longer",
      "offset": 2656.319,
      "duration": 4.721
    },
    {
      "lang": "en",
      "text": "than the maximum token output length of",
      "offset": 2658.4,
      "duration": 4.959
    },
    {
      "lang": "en",
      "text": "one of these smaller fast supply models.",
      "offset": 2661.04,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "So what do you do then? Then you have to",
      "offset": 2663.359,
      "duration": 2.881
    },
    {
      "lang": "en",
      "text": "build workarounds around that. Then you",
      "offset": 2664.64,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "have to build all this infrastructure to",
      "offset": 2666.24,
      "duration": 3.359
    },
    {
      "lang": "en",
      "text": "like pass things off and then it's",
      "offset": 2668.16,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "making mistakes. It's like very subtle",
      "offset": 2669.599,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "mistakes too where it's like it looks",
      "offset": 2671.44,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "like it's working but it's not actually",
      "offset": 2673.2,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "what the original frontier model",
      "offset": 2674.8,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "suggested and it's like slightly",
      "offset": 2677.2,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "different and it introduces like all",
      "offset": 2679.2,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "these subtle bugs into your code and",
      "offset": 2681.44,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "what we're starting to see is like as AI",
      "offset": 2684.48,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "gets better the application layer is",
      "offset": 2687.04,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "reducing you're not going to need all",
      "offset": 2689.2,
      "duration": 2.639
    },
    {
      "lang": "en",
      "text": "these clever workarounds you're not",
      "offset": 2690.64,
      "duration": 2.64
    },
    {
      "lang": "en",
      "text": "going to have to maintain these systems",
      "offset": 2691.839,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "so it's really liberating to not be",
      "offset": 2693.28,
      "duration": 6.319
    },
    {
      "lang": "en",
      "text": "bogged down with rag or with fast apply",
      "offset": 2696.16,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "and just focus on this like core agentic",
      "offset": 2699.599,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "loop and and maximizing diff eddit",
      "offset": 2701.76,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "failures like in our own internal",
      "offset": 2703.76,
      "duration": 6.8
    },
    {
      "lang": "en",
      "text": "benchmarks cla 4 recently hit a sub 5%",
      "offset": 2705.44,
      "duration": 7.6
    },
    {
      "lang": "en",
      "text": "or like around actually 4% diffedit",
      "offset": 2710.56,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "failure rate at the like when fast",
      "offset": 2713.04,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "supply came out that was way higher that",
      "offset": 2715.2,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "was like in the 20s and the 30s now",
      "offset": 2716.72,
      "duration": 6.16
    },
    {
      "lang": "en",
      "text": "we're down to 4% right and in 6 months",
      "offset": 2719.359,
      "duration": 5.201
    },
    {
      "lang": "en",
      "text": "how does it go to zero",
      "offset": 2722.88,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "well it's going to zero like as we speak",
      "offset": 2724.56,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "it's going to zero every day you know",
      "offset": 2726.48,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "and I was actually talking with uh the",
      "offset": 2728.24,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "founders of some of these companies that",
      "offset": 2730.4,
      "duration": 3.679
    },
    {
      "lang": "en",
      "text": "do fast supply. They were trying to kind",
      "offset": 2732.4,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "of work with us. They their whole bread",
      "offset": 2734.079,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "and butter is uh fine-tuning these fast",
      "offset": 2735.76,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "supply models and you know like relay",
      "offset": 2738,
      "duration": 5.359
    },
    {
      "lang": "en",
      "text": "and morph and I had like a very candid",
      "offset": 2740.72,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "conversation with these guys where I was",
      "offset": 2743.359,
      "duration": 3.281
    },
    {
      "lang": "en",
      "text": "like well there's a window of time where",
      "offset": 2744.64,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "fast supply was relevant. Cursor started",
      "offset": 2746.64,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "this window of time back in July. How",
      "offset": 2748.72,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "much time do you think we have left",
      "offset": 2750.96,
      "duration": 2.639
    },
    {
      "lang": "en",
      "text": "until they're no longer relevant? Do you",
      "offset": 2752.16,
      "duration": 2.72
    },
    {
      "lang": "en",
      "text": "think it's an infinite time window?",
      "offset": 2753.599,
      "duration": 2.72
    },
    {
      "lang": "en",
      "text": "They're like, \"No, it's definitely",
      "offset": 2754.88,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "finite. Like this this era of fast apply",
      "offset": 2756.319,
      "duration": 4.561
    },
    {
      "lang": "en",
      "text": "models is definitely coming to an end.\"",
      "offset": 2758.88,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "And I was like, \"Well, how long do you",
      "offset": 2760.88,
      "duration": 3.199
    },
    {
      "lang": "en",
      "text": "guys think?\" They were like, \"Maybe 3",
      "offset": 2762.16,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "months, maybe less.\" So, I still think",
      "offset": 2764.079,
      "duration": 5.681
    },
    {
      "lang": "en",
      "text": "there's some cases where rag is useful.",
      "offset": 2767.44,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "You know, if you have a lot of human",
      "offset": 2769.76,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "readable documents, a large knowledge",
      "offset": 2771.839,
      "duration": 4.641
    },
    {
      "lang": "en",
      "text": "base of documents where you don't really",
      "offset": 2774.88,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "care about like inherent logic within",
      "offset": 2776.48,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "them, like sure, index it, chunk it, do",
      "offset": 2778.64,
      "duration": 6.64
    },
    {
      "lang": "en",
      "text": "retrieval on it or fast applies like",
      "offset": 2782,
      "duration": 5.119
    },
    {
      "lang": "en",
      "text": "maybe if your organization you're forced",
      "offset": 2785.28,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "into using like a very small model",
      "offset": 2787.119,
      "duration": 2.801
    },
    {
      "lang": "en",
      "text": "that's not very good at search and",
      "offset": 2788.72,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "replace like a deepseek or something,",
      "offset": 2789.92,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "you know, maybe use a fast apply model.",
      "offset": 2792.16,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "I think rag and fast supply were these",
      "offset": 2794.4,
      "duration": 5.679
    },
    {
      "lang": "en",
      "text": "just tools in a toolkit for when models",
      "offset": 2797.04,
      "duration": 5.92
    },
    {
      "lang": "en",
      "text": "weren't the greatest at large context or",
      "offset": 2800.079,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "search and replace diff editing. Um, but",
      "offset": 2802.96,
      "duration": 7.52
    },
    {
      "lang": "en",
      "text": "now they are extra ingredients that",
      "offset": 2805.839,
      "duration": 6.401
    },
    {
      "lang": "en",
      "text": "could make things go wrong that you just",
      "offset": 2810.48,
      "duration": 3.599
    },
    {
      "lang": "en",
      "text": "don't need anymore. There was an",
      "offset": 2812.24,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "interesting article from Cognition Labs",
      "offset": 2814.079,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "about, you know, multi-agent",
      "offset": 2816.64,
      "duration": 2.64
    },
    {
      "lang": "en",
      "text": "orchestration and",
      "offset": 2818.079,
      "duration": 2.481
    },
    {
      "lang": "en",
      "text": "getting right into it. It's like you're",
      "offset": 2819.28,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "you're on autopilot for us, right?",
      "offset": 2820.56,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "That's cool. Yeah. So I mean",
      "offset": 2823.119,
      "duration": 2.881
    },
    {
      "lang": "en",
      "text": "it's a great article by the way.",
      "offset": 2824.64,
      "duration": 2.4
    },
    {
      "lang": "en",
      "text": "Yeah, it was a great article. They they",
      "offset": 2826,
      "duration": 3.119
    },
    {
      "lang": "en",
      "text": "talked about how you know when you start",
      "offset": 2827.04,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "working with different models, different",
      "offset": 2829.119,
      "duration": 3.441
    },
    {
      "lang": "en",
      "text": "agents, there's a lot that gets lost in",
      "offset": 2830.64,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "the details and you know the devil in",
      "offset": 2832.56,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "the details that's those are the most",
      "offset": 2835.04,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "important things and making sure that it",
      "offset": 2836.72,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "doesn't you don't have the agent sort of",
      "offset": 2838.88,
      "duration": 2.56
    },
    {
      "lang": "en",
      "text": "like running in loops and running to the",
      "offset": 2840.24,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "same issues again and and it have sort",
      "offset": 2841.44,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "of like all the the right context and",
      "offset": 2843.28,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "and so I think being close to the model",
      "offset": 2845.52,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "throwing all the context you need at it",
      "offset": 2848.16,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "not taking these costs optimized",
      "offset": 2850.4,
      "duration": 5.679
    },
    {
      "lang": "en",
      "text": "approach to pulling in relevant context",
      "offset": 2853.2,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "something rag or a cheaper model to",
      "offset": 2856.079,
      "duration": 4.881
    },
    {
      "lang": "en",
      "text": "apply edits to a file. I think",
      "offset": 2858.72,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "ultimately yes, it's more expensive",
      "offset": 2860.96,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "asking, you know, a model like Claude",
      "offset": 2862.88,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "Sonnet to do sort of all these sorts of",
      "offset": 2864.72,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "things to GP an entire codebase and to,",
      "offset": 2866.64,
      "duration": 5.679
    },
    {
      "lang": "en",
      "text": "you know, fill up its entire context.",
      "offset": 2869.92,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "But you kind of get what you pay for.",
      "offset": 2872.319,
      "duration": 3.121
    },
    {
      "lang": "en",
      "text": "And that I think that's been another",
      "offset": 2874.24,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "benefit of of being open source is that",
      "offset": 2875.44,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "our developers, they can peek under the",
      "offset": 2877.92,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "kimono. They can see, you know, where",
      "offset": 2879.76,
      "duration": 2.8
    },
    {
      "lang": "en",
      "text": "their requests are being sent, what",
      "offset": 2881.44,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "prompts are going into these things. And",
      "offset": 2882.56,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "that creates a certain level of trust",
      "offset": 2884.56,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "where you know when they spend 10 20",
      "offset": 2886.16,
      "duration": 6.08
    },
    {
      "lang": "en",
      "text": "$100 a day they know kind of where their",
      "offset": 2889.68,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "data is being sent when model is being",
      "offset": 2892.24,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "sent to what prompts are going into",
      "offset": 2893.599,
      "duration": 3.361
    },
    {
      "lang": "en",
      "text": "these things and so they get comfortable",
      "offset": 2895.28,
      "duration": 3.039
    },
    {
      "lang": "en",
      "text": "with the idea of spending that much",
      "offset": 2896.96,
      "duration": 3.119
    },
    {
      "lang": "en",
      "text": "money get the job done.",
      "offset": 2898.319,
      "duration": 3.361
    },
    {
      "lang": "en",
      "text": "Yeah. It's like not making money off of",
      "offset": 2900.079,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "inference. I think the the incentives",
      "offset": 2901.68,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "are so they're so relevant in this",
      "offset": 2903.76,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "discussion because, you know, if you're",
      "offset": 2906.16,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "incentivized to, you know, if you're",
      "offset": 2908.48,
      "duration": 4.879
    },
    {
      "lang": "en",
      "text": "charging, you know, $20 per month and",
      "offset": 2910.16,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "you're trying to make money on that,",
      "offset": 2913.359,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "you're going to be offloading all kinds",
      "offset": 2915.2,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "of important work to smaller models or",
      "offset": 2917.119,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "optimizing for cost with rag like",
      "offset": 2919.52,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "retrieval with rag, not reading the",
      "offset": 2921.52,
      "duration": 3.599
    },
    {
      "lang": "en",
      "text": "entire file, but maybe reading like a",
      "offset": 2923.52,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "small snippet of it. Whereas if you're",
      "offset": 2925.119,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "not making money off inference and",
      "offset": 2927.44,
      "duration": 3.679
    },
    {
      "lang": "en",
      "text": "you're just going direct, you know, uh",
      "offset": 2928.8,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "users can bring their own API keys, well",
      "offset": 2931.119,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "then all of a sudden you're you're not",
      "offset": 2933.52,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "incentivized to cut down on cost. You're",
      "offset": 2935.119,
      "duration": 3.041
    },
    {
      "lang": "en",
      "text": "actually incentivized just to build the",
      "offset": 2936.96,
      "duration": 2.72
    },
    {
      "lang": "en",
      "text": "best possible agent. And we're we're",
      "offset": 2938.16,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "starting to see this trend of the whole",
      "offset": 2939.68,
      "duration": 3.679
    },
    {
      "lang": "en",
      "text": "industry is moving in that direction,",
      "offset": 2941.76,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "right? You're starting to see like um",
      "offset": 2943.359,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "everyone open up to pay as you go models",
      "offset": 2945.599,
      "duration": 6.081
    },
    {
      "lang": "en",
      "text": "or pay directly for inference and I",
      "offset": 2949.119,
      "duration": 4.561
    },
    {
      "lang": "en",
      "text": "think that is the future. What's the",
      "offset": 2951.68,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "client pricing business model?",
      "offset": 2953.68,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "Right now, it's bring an API key.",
      "offset": 2956.48,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "Essentially, just uh whatever",
      "offset": 2958.8,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "pre-commitment you might have to",
      "offset": 2961.76,
      "duration": 2.72
    },
    {
      "lang": "en",
      "text": "whatever inference provider, whatever",
      "offset": 2963.04,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "model you think works best for your type",
      "offset": 2964.48,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "of work, you just plug in your Enthropic",
      "offset": 2966.8,
      "duration": 5.84
    },
    {
      "lang": "en",
      "text": "or OpenAI or Open Router, whatever it is",
      "offset": 2970,
      "duration": 5.119
    },
    {
      "lang": "en",
      "text": "API key into client and it connects",
      "offset": 2972.64,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "directly to whatever model you select.",
      "offset": 2975.119,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "And I think that level of transparency,",
      "offset": 2977.2,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "that level of we're building the best",
      "offset": 2979.599,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "product. We're not focused on sort of",
      "offset": 2981.76,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "capturing margin on, you know, the price",
      "offset": 2983.76,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "opuscation and clever tricks and model",
      "offset": 2986.24,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "orchestration to, you know, keep cost",
      "offset": 2989.04,
      "duration": 4.799
    },
    {
      "lang": "en",
      "text": "low for us and optimize for higher",
      "offset": 2991.04,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "profits. I think that's put us in this",
      "offset": 2993.839,
      "duration": 4.881
    },
    {
      "lang": "en",
      "text": "like unique position to really push",
      "offset": 2996.16,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "these models to their full potential.",
      "offset": 2998.72,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "And uh and I I think that's shown, you",
      "offset": 3000.96,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "know, I think that's that's you get what",
      "offset": 3003.28,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "you pay for. Throw a task in client and",
      "offset": 3005.119,
      "duration": 5.281
    },
    {
      "lang": "en",
      "text": "and it gets expensive, but um",
      "offset": 3007.76,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "that's the cost of intelligence, right?",
      "offset": 3010.4,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "It's the cost of intelligence. Yeah. So",
      "offset": 3011.92,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "yeah, the business model right now is is",
      "offset": 3013.52,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "uh you you get to choose kind of where",
      "offset": 3015.68,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "it's open source. You can fork it. You",
      "offset": 3017.68,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "can choose where your data gets. You can",
      "offset": 3019.44,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "choose who you want to pay. A lot of",
      "offset": 3020.88,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "organizations we've talked to get some,",
      "offset": 3022.48,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "you know, a certain level of volume",
      "offset": 3024.48,
      "duration": 2.8
    },
    {
      "lang": "en",
      "text": "based discounts with with these",
      "offset": 3025.68,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "providers. Instagram, they can they can",
      "offset": 3027.28,
      "duration": 2.64
    },
    {
      "lang": "en",
      "text": "take advantage of that through client,",
      "offset": 3028.72,
      "duration": 3.119
    },
    {
      "lang": "en",
      "text": "which is helpful because client can get",
      "offset": 3029.92,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "pretty expensive. And uh yeah,",
      "offset": 3031.839,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "wait, so I mean I'm I'm still not",
      "offset": 3034.24,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "hearing how you make money. Like you",
      "offset": 3035.76,
      "duration": 2.799
    },
    {
      "lang": "en",
      "text": "said, you don't",
      "offset": 3037.28,
      "duration": 1.76
    },
    {
      "lang": "en",
      "text": "Huh?",
      "offset": 3038.559,
      "duration": 1.28
    },
    {
      "lang": "en",
      "text": "Why?",
      "offset": 3039.04,
      "duration": 1.92
    },
    {
      "lang": "en",
      "text": "Why make money?",
      "offset": 3039.839,
      "duration": 2.641
    },
    {
      "lang": "en",
      "text": "Yeah.",
      "offset": 3040.96,
      "duration": 3.359
    },
    {
      "lang": "en",
      "text": "Uh cuz you have to pay your salaries.",
      "offset": 3042.48,
      "duration": 3.359
    },
    {
      "lang": "en",
      "text": "Well, that that's the that's the A lot",
      "offset": 3044.319,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "of people ask us that and I always just",
      "offset": 3045.839,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "throw the why at them. But it's um",
      "offset": 3047.359,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "you sound like the Party Fool, guys.",
      "offset": 3049.359,
      "duration": 3.121
    },
    {
      "lang": "en",
      "text": "Party Fool's like",
      "offset": 3050.559,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "the real answer is enterprise. So um",
      "offset": 3052.48,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "which uh we can say because you're you",
      "offset": 3054.96,
      "duration": 2.879
    },
    {
      "lang": "en",
      "text": "know we released this when you launch",
      "offset": 3056.8,
      "duration": 1.759
    },
    {
      "lang": "en",
      "text": "it. Yeah.",
      "offset": 3057.839,
      "duration": 2.641
    },
    {
      "lang": "en",
      "text": "Yeah. So you want to talk about",
      "offset": 3058.559,
      "duration": 2.721
    },
    {
      "lang": "en",
      "text": "enterprise?",
      "offset": 3060.48,
      "duration": 2.879
    },
    {
      "lang": "en",
      "text": "Yeah. I think being open source marine",
      "offset": 3061.28,
      "duration": 5.039
    },
    {
      "lang": "en",
      "text": "API key has given us a lot of easy",
      "offset": 3063.359,
      "duration": 5.361
    },
    {
      "lang": "en",
      "text": "adoption in these organizations where",
      "offset": 3066.319,
      "duration": 4.721
    },
    {
      "lang": "en",
      "text": "things like data privacy and control and",
      "offset": 3068.72,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "security are top of mind and it's hard",
      "offset": 3071.04,
      "duration": 5.279
    },
    {
      "lang": "en",
      "text": "to commit to sending their code in plain",
      "offset": 3073.52,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "text to god knows what servers training",
      "offset": 3076.319,
      "duration": 5.121
    },
    {
      "lang": "en",
      "text": "their data to do training their data on",
      "offset": 3078.72,
      "duration": 4.879
    },
    {
      "lang": "en",
      "text": "models that might you know output their",
      "offset": 3081.44,
      "duration": 6.32
    },
    {
      "lang": "en",
      "text": "IP to random users I think there people",
      "offset": 3083.599,
      "duration": 6.641
    },
    {
      "lang": "en",
      "text": "are a lot more conscious about where",
      "offset": 3087.76,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "their data is getting getting sent and",
      "offset": 3090.24,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "what's being used to it. And so it's",
      "offset": 3091.68,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "given us this opportunity to say, okay,",
      "offset": 3093.28,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "nothing passes through our own servers.",
      "offset": 3095.839,
      "duration": 3.121
    },
    {
      "lang": "en",
      "text": "You have total control over the entire",
      "offset": 3097.44,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "application where your data gets sent.",
      "offset": 3098.96,
      "duration": 5.119
    },
    {
      "lang": "en",
      "text": "And that's given organizations that, you",
      "offset": 3101.52,
      "duration": 3.599
    },
    {
      "lang": "en",
      "text": "know, we've been talking to over the",
      "offset": 3104.079,
      "duration": 2.641
    },
    {
      "lang": "en",
      "text": "course of the last couple of months this",
      "offset": 3105.119,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "sort of like easy adoption. And I think",
      "offset": 3106.72,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "this opportunity for us to to work more",
      "offset": 3108.559,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "closely with them and say, you know,",
      "offset": 3110.559,
      "duration": 2.961
    },
    {
      "lang": "en",
      "text": "what are all the things that we can do",
      "offset": 3112.24,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "to help with adoption in the rest of",
      "offset": 3113.52,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "your organization? essentially how can",
      "offset": 3115.44,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "we pour gasoline on sort of the",
      "offset": 3117.52,
      "duration": 5.039
    },
    {
      "lang": "en",
      "text": "evangelism that you know people have for",
      "offset": 3119.76,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "client in these organizations and spread",
      "offset": 3122.559,
      "duration": 4.641
    },
    {
      "lang": "en",
      "text": "the usage of of agent coding I think at",
      "offset": 3124.72,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "an enterprise level. Well, yeah. What's",
      "offset": 3127.2,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "what's crazy is um so we we had we open",
      "offset": 3128.96,
      "duration": 6.639
    },
    {
      "lang": "en",
      "text": "sourced client. People really liked it.",
      "offset": 3133.2,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "Developers were using it within their",
      "offset": 3135.599,
      "duration": 3.201
    },
    {
      "lang": "en",
      "text": "organizations. Their organizations were",
      "offset": 3137.119,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "kind of like reluctantly okay with it",
      "offset": 3138.8,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "because they saw like we're open source",
      "offset": 3140.559,
      "duration": 3.361
    },
    {
      "lang": "en",
      "text": "and we're not sending our their data",
      "offset": 3142.4,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "anywhere. They could use their existing",
      "offset": 3143.92,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "API keys. And then we launched like on",
      "offset": 3145.76,
      "duration": 6.079
    },
    {
      "lang": "en",
      "text": "our website like a contact form for",
      "offset": 3149.2,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "enterprise like if you're interested in",
      "offset": 3151.839,
      "duration": 2.881
    },
    {
      "lang": "en",
      "text": "an enterprise offering hit us up. And we",
      "offset": 3153.04,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "had no real enterprise product at the",
      "offset": 3154.72,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "time. And it turned out like we just got",
      "offset": 3156.48,
      "duration": 6.879
    },
    {
      "lang": "en",
      "text": "this massive influx of big enterprises",
      "offset": 3159.76,
      "duration": 6.319
    },
    {
      "lang": "en",
      "text": "reaching out to us. And you know we had",
      "offset": 3163.359,
      "duration": 5.521
    },
    {
      "lang": "en",
      "text": "a fortune five company come up to us and",
      "offset": 3166.079,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "they were like hey um we have hundreds",
      "offset": 3168.88,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "of engineers using client within our",
      "offset": 3171.599,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "organization and this is a massive",
      "offset": 3173.92,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "problem for us. This is like a fire that",
      "offset": 3175.599,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "we need to put out because we have no",
      "offset": 3177.2,
      "duration": 4.639
    },
    {
      "lang": "en",
      "text": "idea what API keys they're using, how",
      "offset": 3179.2,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "much they're spending, where they're",
      "offset": 3181.839,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "sending their data. Please just like let",
      "offset": 3183.359,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "us give you money to make an enterprise",
      "offset": 3185.599,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "product. So the product kind of just",
      "offset": 3187.359,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "evolved out of that. Right.",
      "offset": 3189.2,
      "duration": 2.879
    },
    {
      "lang": "en",
      "text": "Right. Right. I mean it's it really just",
      "offset": 3190.559,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "comes down to more of listening to our",
      "offset": 3192.079,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "users. So right after we put out this",
      "offset": 3194.24,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "page, we just had a lot of demand for",
      "offset": 3196.559,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "sort of like the table stake enterprise",
      "offset": 3198.24,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "features, the security uh guard rails",
      "offset": 3200.16,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "and governance and insights that sort of",
      "offset": 3202.96,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "like the admins in these organizations",
      "offset": 3205.28,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "need to to reliably use something like",
      "offset": 3206.8,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "Klein. Yeah, we've gotten a lot of",
      "offset": 3209.359,
      "duration": 5.041
    },
    {
      "lang": "en",
      "text": "people wanting us to sort of give them",
      "offset": 3211.76,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "two things. Invoices just to help with",
      "offset": 3214.4,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "like all the budgeting and spending the,",
      "offset": 3216.96,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "you know, thousands of dollars,",
      "offset": 3219.44,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "all the Europeans.",
      "offset": 3220.96,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "Yeah. Just the other thing which I",
      "offset": 3222.48,
      "duration": 3.359
    },
    {
      "lang": "en",
      "text": "thought was a little bit surprising was",
      "offset": 3224.24,
      "duration": 5.119
    },
    {
      "lang": "en",
      "text": "some level of insight into the benefit",
      "offset": 3225.839,
      "duration": 5.201
    },
    {
      "lang": "en",
      "text": "that clients providing them. So it could",
      "offset": 3229.359,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "be our sage or lines of code written",
      "offset": 3231.04,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "because it allows these sort of like AI",
      "offset": 3233.68,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "forward drivers for adopting these sorts",
      "offset": 3235.52,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "of tools in these organizations to take",
      "offset": 3238.4,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "that as a proof point and go to the rest",
      "offset": 3240.48,
      "duration": 3.359
    },
    {
      "lang": "en",
      "text": "of their teams and say this is how much",
      "offset": 3242.319,
      "duration": 2.721
    },
    {
      "lang": "en",
      "text": "clients helping me. You need to start",
      "offset": 3243.839,
      "duration": 2.641
    },
    {
      "lang": "en",
      "text": "adopting this so we can keep up with the",
      "offset": 3245.04,
      "duration": 2.559
    },
    {
      "lang": "en",
      "text": "rest of the industry.",
      "offset": 3246.48,
      "duration": 3.119
    },
    {
      "lang": "en",
      "text": "This for like internal champions to",
      "offset": 3247.599,
      "duration": 3.281
    },
    {
      "lang": "en",
      "text": "prove their ROI.",
      "offset": 3249.599,
      "duration": 1.841
    },
    {
      "lang": "en",
      "text": "Exactly.",
      "offset": 3250.88,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "Okay. use as sort of evidence for this,",
      "offset": 3251.44,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "you know, to justify the spend. Yeah.",
      "offset": 3254.64,
      "duration": 3.679
    },
    {
      "lang": "en",
      "text": "But also to promote the product in these",
      "offset": 3256.64,
      "duration": 2.64
    },
    {
      "lang": "en",
      "text": "organizations.",
      "offset": 3258.319,
      "duration": 2.561
    },
    {
      "lang": "en",
      "text": "We can do this afterwards, but we like",
      "offset": 3259.28,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "to talk to those and actually feature",
      "offset": 3260.88,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "some of them what they're saying to",
      "offset": 3262.72,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "their bosses",
      "offset": 3264.4,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "uh on the podcast so that we can get a",
      "offset": 3265.76,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "sense cuz like often times we hear we",
      "offset": 3267.52,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "only talk to founders and builders of",
      "offset": 3269.92,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "like the dev tool, but like not the end",
      "offset": 3271.839,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "consumer and actually we want to hear",
      "offset": 3273.839,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "from them, right? Like about how they're",
      "offset": 3275.52,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "thinking about it, what they need. Kind",
      "offset": 3277.359,
      "duration": 3.121
    },
    {
      "lang": "en",
      "text": "of kind of cool. One thing I wanted to",
      "offset": 3278.96,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "ask uh to double click on is the",
      "offset": 3280.48,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "relationship between open router and",
      "offset": 3282.96,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "then like your your enterprise offering",
      "offset": 3284.48,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "right. So uh my understanding is",
      "offset": 3286.24,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "currently everything runs through open",
      "offset": 3287.92,
      "duration": 2.24
    },
    {
      "lang": "en",
      "text": "router",
      "offset": 3289.28,
      "duration": 2.96
    },
    {
      "lang": "en",
      "text": "not everything. So you can bring API",
      "offset": 3290.16,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "keys to OpenAI, Anthropic, Bedrock",
      "offset": 3292.24,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "and then you have a direct connection",
      "offset": 3295.04,
      "duration": 2.48
    },
    {
      "lang": "en",
      "text": "there if if I",
      "offset": 3296.16,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "the user has a direct connection there",
      "offset": 3297.52,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "but uh everything else would run through",
      "offset": 3299.92,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "open router and so basically the",
      "offset": 3301.839,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "enterprise version of client would be",
      "offset": 3303.68,
      "duration": 4.639
    },
    {
      "lang": "en",
      "text": "you have your own open router that you",
      "offset": 3305.52,
      "duration": 5.839
    },
    {
      "lang": "en",
      "text": "would provide visibility and control to",
      "offset": 3308.319,
      "duration": 5.441
    },
    {
      "lang": "en",
      "text": "uh that enterprise. Uh yeah, kind like",
      "offset": 3311.359,
      "duration": 4.561
    },
    {
      "lang": "en",
      "text": "that's for like the self-hosted option,",
      "offset": 3313.76,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "right? Like there's a lot of enterprises",
      "offset": 3315.92,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "where they're okay with not",
      "offset": 3317.44,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "self-hosting, but as long as they're",
      "offset": 3319.68,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "using their own bedrock API keys and",
      "offset": 3321.52,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "stuff like that, whereas the ones that",
      "offset": 3323.68,
      "duration": 2.639
    },
    {
      "lang": "en",
      "text": "are really interested in like",
      "offset": 3325.52,
      "duration": 2.4
    },
    {
      "lang": "en",
      "text": "self-hosting or like that want to be",
      "offset": 3326.319,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "able to manage their teams, there would",
      "offset": 3327.92,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "be like this internal router",
      "offset": 3329.359,
      "duration": 3.281
    },
    {
      "lang": "en",
      "text": "going on.",
      "offset": 3331.76,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "The curious thing here is like what if",
      "offset": 3332.64,
      "duration": 4.959
    },
    {
      "lang": "en",
      "text": "what if model cost just go to zero like",
      "offset": 3335.2,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "Gemini code just comes out and it's like",
      "offset": 3337.599,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "yeah guys it's free. Well, yeah. No,",
      "offset": 3339.52,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "they came up with Yeah, it'd be great",
      "offset": 3342,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "for us. So, our our thesis is inference",
      "offset": 3343.28,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "is not the business.",
      "offset": 3345.68,
      "duration": 1.6
    },
    {
      "lang": "en",
      "text": "You would just never make money on",
      "offset": 3346.4,
      "duration": 1.679
    },
    {
      "lang": "en",
      "text": "inference, right?",
      "offset": 3347.28,
      "duration": 2.96
    },
    {
      "lang": "en",
      "text": "Yeah. We want to give the end user total",
      "offset": 3348.079,
      "duration": 5.841
    },
    {
      "lang": "en",
      "text": "transparency into price into which I",
      "offset": 3350.24,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "think is like incredibly important to,",
      "offset": 3353.92,
      "duration": 2.48
    },
    {
      "lang": "en",
      "text": "you know, even get comfortable with the",
      "offset": 3355.2,
      "duration": 2.48
    },
    {
      "lang": "en",
      "text": "idea of spending as much money as you",
      "offset": 3356.4,
      "duration": 3.679
    },
    {
      "lang": "en",
      "text": "do. I think the the price opuscation in",
      "offset": 3357.68,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "this space has given developers this",
      "offset": 3360.079,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "reluctance to opt into usage based to",
      "offset": 3362.16,
      "duration": 5.199
    },
    {
      "lang": "en",
      "text": "plans and and we're seeing a lot of",
      "offset": 3365.119,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "people kind of converge on this concept",
      "offset": 3367.359,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "of okay maybe have like a a base plan",
      "offset": 3368.96,
      "duration": 4.879
    },
    {
      "lang": "en",
      "text": "just to to use the product but sort of",
      "offset": 3371.68,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "get out of the way of the inference and",
      "offset": 3373.839,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "um respect the end developer enough to",
      "offset": 3375.68,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "give them the level of insight into not",
      "offset": 3377.359,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "just the cost but the models being used",
      "offset": 3378.96,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "and uh give them more confidence in",
      "offset": 3381.2,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "spending however much it takes to get",
      "offset": 3382.88,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "the work done. I think there, you know,",
      "offset": 3384.4,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "there, you know, you can use tricks like",
      "offset": 3386.799,
      "duration": 2.961
    },
    {
      "lang": "en",
      "text": "rag and fast supply and things like that",
      "offset": 3388.319,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "to keep costs low, but for the most",
      "offset": 3389.76,
      "duration": 6.16
    },
    {
      "lang": "en",
      "text": "part, there's enough ROI on on uh coding",
      "offset": 3392.16,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "agents where, you know, people are",
      "offset": 3395.92,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "willing to spend money to to get the job",
      "offset": 3397.28,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "done. And for a truly like good coding",
      "offset": 3399.52,
      "duration": 5.599
    },
    {
      "lang": "en",
      "text": "agent, the ROI is almost hard to even",
      "offset": 3402.88,
      "duration": 4.479
    },
    {
      "lang": "en",
      "text": "calculate because there's so many things",
      "offset": 3405.119,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "that I would have never even bothered",
      "offset": 3407.359,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "doing, but then I now I have client and",
      "offset": 3409.2,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "I could just like do this weird",
      "offset": 3411.359,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "experiment or do this side project or",
      "offset": 3412.64,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "you know fix this random bug that I",
      "offset": 3414.799,
      "duration": 4.481
    },
    {
      "lang": "en",
      "text": "would have never even thought about. So",
      "offset": 3416.72,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "like how do you measure that? Yeah.",
      "offset": 3419.28,
      "duration": 2.24
    },
    {
      "lang": "en",
      "text": "Right.",
      "offset": 3420.72,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "One variant of this problem we're about",
      "offset": 3421.52,
      "duration": 3.599
    },
    {
      "lang": "en",
      "text": "to move on to context engineering and",
      "offset": 3423.76,
      "duration": 2.72
    },
    {
      "lang": "en",
      "text": "memory and all the other stuff. One",
      "offset": 3425.119,
      "duration": 2.881
    },
    {
      "lang": "en",
      "text": "variant of this I wanted to touch on a",
      "offset": 3426.48,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "little bit was just uh background agents",
      "offset": 3428,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "and multi- aents. So the instantiations",
      "offset": 3430.48,
      "duration": 6.079
    },
    {
      "lang": "en",
      "text": "of this now I would say are background",
      "offset": 3432.64,
      "duration": 6.08
    },
    {
      "lang": "en",
      "text": "agents is it would be codeex for example",
      "offset": 3436.559,
      "duration": 5.601
    },
    {
      "lang": "en",
      "text": "like spinning up you know one PR per",
      "offset": 3438.72,
      "duration": 6.96
    },
    {
      "lang": "en",
      "text": "minute and or Devon or cognition so",
      "offset": 3442.16,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "would you ever go there that's one",
      "offset": 3445.68,
      "duration": 2.639
    },
    {
      "lang": "en",
      "text": "concrete question I can ask you like",
      "offset": 3447.04,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "would there be clin on the server",
      "offset": 3448.319,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "whatever and then the other version is",
      "offset": 3450.16,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "still on the laptop but more sort of",
      "offset": 3452.24,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "parallel agents like kind of the the",
      "offset": 3454.4,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "camban is is currently very hyped right",
      "offset": 3456.24,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "now people are making like camban",
      "offset": 3458.64,
      "duration": 5.84
    },
    {
      "lang": "en",
      "text": "interfaces is for cursor and also for uh",
      "offset": 3460.559,
      "duration": 5.681
    },
    {
      "lang": "en",
      "text": "cloud code just anything like in the",
      "offset": 3464.48,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "parallel or background side of things.",
      "offset": 3466.24,
      "duration": 5.839
    },
    {
      "lang": "en",
      "text": "So we're releasing a CLI version of",
      "offset": 3468.24,
      "duration": 5.92
    },
    {
      "lang": "en",
      "text": "client and using the CLI version of",
      "offset": 3472.079,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "client it's fully modular so you can ask",
      "offset": 3474.16,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "client to run the CLI to spin up more",
      "offset": 3477.119,
      "duration": 5.841
    },
    {
      "lang": "en",
      "text": "clients or you could run client in some",
      "offset": 3479.44,
      "duration": 5.84
    },
    {
      "lang": "en",
      "text": "kind of cloud process in a in a GitHub",
      "offset": 3482.96,
      "duration": 4.879
    },
    {
      "lang": "en",
      "text": "action whatever you want. So the the CLI",
      "offset": 3485.28,
      "duration": 4.799
    },
    {
      "lang": "en",
      "text": "is really the form factor for okay",
      "offset": 3487.839,
      "duration": 5.201
    },
    {
      "lang": "en",
      "text": "these kind of fully autonomous agents",
      "offset": 3490.079,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "and it's also nice to be able to tap",
      "offset": 3493.04,
      "duration": 3.519
    },
    {
      "lang": "en",
      "text": "into an existing client CLI running on",
      "offset": 3494.559,
      "duration": 3.441
    },
    {
      "lang": "en",
      "text": "your computer and be able to like take",
      "offset": 3496.559,
      "duration": 2.56
    },
    {
      "lang": "en",
      "text": "over and steer it in the right",
      "offset": 3498,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "direction. So that's also possible. Um",
      "offset": 3499.119,
      "duration": 4.561
    },
    {
      "lang": "en",
      "text": "but what do you think sad?",
      "offset": 3502.319,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "I don't think it's an either or. I think",
      "offset": 3503.68,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "all these different modalities",
      "offset": 3505.839,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "complement each other really well. So",
      "offset": 3507.68,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "the codecs the Devons cursor background",
      "offset": 3509.92,
      "duration": 4.879
    },
    {
      "lang": "en",
      "text": "agent I think they all sort of",
      "offset": 3512.88,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "accomplish the same thing. they if we",
      "offset": 3514.799,
      "duration": 4.241
    },
    {
      "lang": "en",
      "text": "were to come out with our own version of",
      "offset": 3517.68,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "it, I'd say that it it would be a",
      "offset": 3519.04,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "foundation for how other developers",
      "offset": 3522.24,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "could build on top of it. So Nick's",
      "offset": 3524.16,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "older brother, Andre, he's sort of",
      "offset": 3526.64,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "thinking 10 years ahead, and it always",
      "offset": 3528.88,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "kind of blows my mind a little bit about",
      "offset": 3531.2,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "some of some of the ideas that he has",
      "offset": 3533.04,
      "duration": 3.519
    },
    {
      "lang": "en",
      "text": "about where the space is going, but we",
      "offset": 3534.72,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "recently had a discussion about building",
      "offset": 3536.559,
      "duration": 5.681
    },
    {
      "lang": "en",
      "text": "this open-source framework for coding",
      "offset": 3538.48,
      "duration": 6.319
    },
    {
      "lang": "en",
      "text": "agents for any sort of platform.",
      "offset": 3542.24,
      "duration": 4.879
    },
    {
      "lang": "en",
      "text": "building the SDK and the tool necessary",
      "offset": 3544.799,
      "duration": 4.721
    },
    {
      "lang": "en",
      "text": "to bring client to you know Chrome as an",
      "offset": 3547.119,
      "duration": 5.281
    },
    {
      "lang": "en",
      "text": "extension to the CLI to Jet Brains to",
      "offset": 3549.52,
      "duration": 5.92
    },
    {
      "lang": "en",
      "text": "Jupyter notebooks to your smart car",
      "offset": 3552.4,
      "duration": 4.719
    },
    {
      "lang": "en",
      "text": "whatever it is but to build",
      "offset": 3555.44,
      "duration": 2.48
    },
    {
      "lang": "en",
      "text": "your fridge",
      "offset": 3557.119,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "your fridge exactly to to put to",
      "offset": 3557.92,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "microwave maybe.",
      "offset": 3560.559,
      "duration": 1.681
    },
    {
      "lang": "en",
      "text": "Yeah. Exactly. I mean this is what we",
      "offset": 3561.28,
      "duration": 2.4
    },
    {
      "lang": "en",
      "text": "saw kind of like with sort of you know",
      "offset": 3562.24,
      "duration": 3.359
    },
    {
      "lang": "en",
      "text": "the 6,000 forks you know on top of",
      "offset": 3563.68,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "client is we sort of like put together",
      "offset": 3565.599,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "this foundation for how this community",
      "offset": 3567.28,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "of developers we sort of put together",
      "offset": 3569.839,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "this foundation that this community",
      "offset": 3571.92,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "developers could like build on top of",
      "offset": 3573.359,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "and sort of take advantage of you know",
      "offset": 3574.96,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "their experiments and imagination and",
      "offset": 3577.04,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "their creativity about where the space",
      "offset": 3579.359,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "is headed. And I think looking forward",
      "offset": 3581.2,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "building an open source foundation and",
      "offset": 3583.68,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "the building blocks for how we bring",
      "offset": 3585.52,
      "duration": 4.799
    },
    {
      "lang": "en",
      "text": "something like client to things that go",
      "offset": 3587.44,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "outside the scope of software",
      "offset": 3590.319,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "development or or you know VS code",
      "offset": 3591.68,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "extension. I think that'll open up the",
      "offset": 3593.599,
      "duration": 5.121
    },
    {
      "lang": "en",
      "text": "door to things that you know ultimately",
      "offset": 3595.599,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "complement each other really well but",
      "offset": 3598.72,
      "duration": 2.48
    },
    {
      "lang": "en",
      "text": "it'll never be sort of this like either",
      "offset": 3600,
      "duration": 2.72
    },
    {
      "lang": "en",
      "text": "or thing. I think background agents are",
      "offset": 3601.2,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "good for certain kinds of work and",
      "offset": 3602.72,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "parallel canben multi- aents might be",
      "offset": 3604.48,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "good for when you want to experiment and",
      "offset": 3606.64,
      "duration": 2.959
    },
    {
      "lang": "en",
      "text": "iterate on you know five different",
      "offset": 3608.4,
      "duration": 3.199
    },
    {
      "lang": "en",
      "text": "versions of you know how a landing page",
      "offset": 3609.599,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "might look and then something like a",
      "offset": 3611.599,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "back and forth with a single agent like",
      "offset": 3613.52,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "client works really well for when you",
      "offset": 3615.28,
      "duration": 3.519
    },
    {
      "lang": "en",
      "text": "want to you know pull context and put",
      "offset": 3617.2,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "together a really complicated plan for a",
      "offset": 3618.799,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "really complex task and I think all",
      "offset": 3621.04,
      "duration": 3.519
    },
    {
      "lang": "en",
      "text": "these different tools will ultimately",
      "offset": 3623.2,
      "duration": 2.96
    },
    {
      "lang": "en",
      "text": "end up complenting each other and people",
      "offset": 3624.559,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "will kind of develop a taste and an",
      "offset": 3626.16,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "understanding for what works best for",
      "offset": 3627.839,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "what kind of work but I I think",
      "offset": 3629.28,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "something just looking 10 years ahead.",
      "offset": 3631.119,
      "duration": 3.521
    },
    {
      "lang": "en",
      "text": "We at the very least want to sort of be",
      "offset": 3633.04,
      "duration": 3.759
    },
    {
      "lang": "en",
      "text": "at the frontier of providing sort of the",
      "offset": 3634.64,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "building blocks for what the next thing",
      "offset": 3636.799,
      "duration": 4.641
    },
    {
      "lang": "en",
      "text": "is after background agents or um you",
      "offset": 3638.64,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "know multi- aents.",
      "offset": 3641.44,
      "duration": 2.96
    },
    {
      "lang": "en",
      "text": "I was going to go into context",
      "offset": 3643.04,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "engineering kind of like topic duour. I",
      "offset": 3644.4,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "think that uh this is kind of similarish",
      "offset": 3646.72,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "in a thread to rag and how rag is a mind",
      "offset": 3649.52,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "virus which I love by the way that the",
      "offset": 3652.24,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "way that you phrased it. Yeah, you you",
      "offset": 3653.68,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "have you have in your docs context",
      "offset": 3655.52,
      "duration": 2.64
    },
    {
      "lang": "en",
      "text": "management. You also have a section on",
      "offset": 3656.88,
      "duration": 2.719
    },
    {
      "lang": "en",
      "text": "memory bank which is kind of cool. I",
      "offset": 3658.16,
      "duration": 2.8
    },
    {
      "lang": "en",
      "text": "think uh a lot of people are trying to",
      "offset": 3659.599,
      "duration": 3.121
    },
    {
      "lang": "en",
      "text": "figure out memory. Let's just start at",
      "offset": 3660.96,
      "duration": 2.8
    },
    {
      "lang": "en",
      "text": "the high level and then we'll go into",
      "offset": 3662.72,
      "duration": 2.8
    },
    {
      "lang": "en",
      "text": "memory later. Uh what you know what does",
      "offset": 3663.76,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "context engineering mean to you?",
      "offset": 3665.52,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "Context engineering mean to me",
      "offset": 3667.68,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "means prompt engineering.",
      "offset": 3670.48,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "Yeah. Right. Like I mean so I think like",
      "offset": 3672.72,
      "duration": 5.119
    },
    {
      "lang": "en",
      "text": "there is a lot of art to like what goes",
      "offset": 3675.04,
      "duration": 5.039
    },
    {
      "lang": "en",
      "text": "in there. Yeah, I think that really is",
      "offset": 3677.839,
      "duration": 4.641
    },
    {
      "lang": "en",
      "text": "like the 8020 of building a really good",
      "offset": 3680.079,
      "duration": 4.561
    },
    {
      "lang": "en",
      "text": "agent is like figuring out what goes",
      "offset": 3682.48,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "into the context and and like you know I",
      "offset": 3684.64,
      "duration": 6.4
    },
    {
      "lang": "en",
      "text": "think interplay between MCP and your",
      "offset": 3687.44,
      "duration": 6.48
    },
    {
      "lang": "en",
      "text": "system client like you know recommended",
      "offset": 3691.04,
      "duration": 6.16
    },
    {
      "lang": "en",
      "text": "promps I think is what's is ultimately",
      "offset": 3693.92,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "making a good agent.",
      "offset": 3697.2,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "Yeah, I I think context management is",
      "offset": 3698.16,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "like one part of it is what you load in",
      "offset": 3700.72,
      "duration": 6.72
    },
    {
      "lang": "en",
      "text": "to context. The other part of it is how",
      "offset": 3703.92,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "do you clean things up when you're",
      "offset": 3707.44,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "reaching the context window, right? Uh",
      "offset": 3708.64,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "how do you curate that whole life cycle",
      "offset": 3711.2,
      "duration": 7.119
    },
    {
      "lang": "en",
      "text": "from zero to maximum uh context window?",
      "offset": 3713.52,
      "duration": 8
    },
    {
      "lang": "en",
      "text": "And the way that I think about it is",
      "offset": 3718.319,
      "duration": 5.841
    },
    {
      "lang": "en",
      "text": "there's so many options on the table and",
      "offset": 3721.52,
      "duration": 6.079
    },
    {
      "lang": "en",
      "text": "there's so many risks to misdirecting",
      "offset": 3724.16,
      "duration": 6.48
    },
    {
      "lang": "en",
      "text": "the agent or distracting the agent.",
      "offset": 3727.599,
      "duration": 6.401
    },
    {
      "lang": "en",
      "text": "There's ideas about, you know, rag or",
      "offset": 3730.64,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "other kinds of forms of retrieval.",
      "offset": 3734,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "That's that's one idea. There's the",
      "offset": 3736.24,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "agentic exploration. That's another idea",
      "offset": 3738.16,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "that we found works much better. And it",
      "offset": 3739.92,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "seems like the trend is generally for",
      "offset": 3742.559,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "loading things into context. It's giving",
      "offset": 3744.4,
      "duration": 5.199
    },
    {
      "lang": "en",
      "text": "the model the tools that it can use to",
      "offset": 3746.64,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "pull things into context, letting the",
      "offset": 3749.599,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "model decide what exactly to pull into",
      "offset": 3751.52,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "context, as well as some hints along the",
      "offset": 3753.44,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "way, kind of like a like a a map of",
      "offset": 3755.52,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "what's going on. um like as uh abstract",
      "offset": 3757.599,
      "duration": 6.321
    },
    {
      "lang": "en",
      "text": "syntax trees potentially what tabs they",
      "offset": 3761.2,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "have open in VS Code that was actually",
      "offset": 3763.92,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "in our internal kind of benchmarking",
      "offset": 3765.92,
      "duration": 4.879
    },
    {
      "lang": "en",
      "text": "that turned out to work very very well",
      "offset": 3768.4,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "it's almost like it's reading your mind",
      "offset": 3770.799,
      "duration": 3.361
    },
    {
      "lang": "en",
      "text": "when you have like a few tabs open",
      "offset": 3772.319,
      "duration": 3.201
    },
    {
      "lang": "en",
      "text": "me out because like sometimes then I'm",
      "offset": 3774.16,
      "duration": 3.199
    },
    {
      "lang": "en",
      "text": "like I have like unrelated tabs open and",
      "offset": 3775.52,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "I have to go close them before I take",
      "offset": 3777.359,
      "duration": 2.561
    },
    {
      "lang": "en",
      "text": "off the thing",
      "offset": 3779.28,
      "duration": 2
    },
    {
      "lang": "en",
      "text": "I I wouldn't think too much about",
      "offset": 3779.92,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "especially when you're using Klein Klein",
      "offset": 3781.28,
      "duration": 3.039
    },
    {
      "lang": "en",
      "text": "does a pretty good job of just",
      "offset": 3783.04,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "navigating that. Um, but I I definitely",
      "offset": 3784.319,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "there are edge cases, right? There's",
      "offset": 3787.04,
      "duration": 2.64
    },
    {
      "lang": "en",
      "text": "edge cases for everything. And it's kind",
      "offset": 3788.319,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "of like, okay, what's like the majority",
      "offset": 3789.68,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "use cases like you know when are you",
      "offset": 3791.92,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "starting a brand new task and you don't",
      "offset": 3793.839,
      "duration": 2.881
    },
    {
      "lang": "en",
      "text": "have a single tab open that's relevant",
      "offset": 3795.2,
      "duration": 4.639
    },
    {
      "lang": "en",
      "text": "to it. Obviously in the CLI you might",
      "offset": 3796.72,
      "duration": 5.359
    },
    {
      "lang": "en",
      "text": "you don't have that little indicator. So",
      "offset": 3799.839,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "there you have to think outside the box",
      "offset": 3802.079,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "for that. So that's like for reading",
      "offset": 3804,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "things into context. And then for",
      "offset": 3806.16,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "context management is when you're",
      "offset": 3808.319,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "approaching the full capacity of the",
      "offset": 3810.319,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "context window is how do you condense",
      "offset": 3812.24,
      "duration": 7.52
    },
    {
      "lang": "en",
      "text": "that? And we've played around with this",
      "offset": 3815.839,
      "duration": 6.48
    },
    {
      "lang": "en",
      "text": "kind of naive truncation very early on",
      "offset": 3819.76,
      "duration": 4.559
    },
    {
      "lang": "en",
      "text": "where we just like throw out the first",
      "offset": 3822.319,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "half of the conversation.",
      "offset": 3824.319,
      "duration": 2.561
    },
    {
      "lang": "en",
      "text": "That's common.",
      "offset": 3826,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "And it there is problems with that",
      "offset": 3826.88,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "obviously because it's like kind of like",
      "offset": 3829.28,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "you're halfway through a book and you",
      "offset": 3830.88,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "you're like you start reading halfway",
      "offset": 3833.119,
      "duration": 3.281
    },
    {
      "lang": "en",
      "text": "through, right? you don't know anything",
      "offset": 3834.64,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "that happened beforehand. And we like to",
      "offset": 3836.4,
      "duration": 3.439
    },
    {
      "lang": "en",
      "text": "think a lot about like narrative",
      "offset": 3838.72,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "integrity is like every task in client",
      "offset": 3839.839,
      "duration": 4.881
    },
    {
      "lang": "en",
      "text": "is kind of like a story. It might be a",
      "offset": 3842.48,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "boring story where it's like this lonely",
      "offset": 3844.72,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "coding agent that's just, you know,",
      "offset": 3846.559,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "determined to help you solve, you know,",
      "offset": 3848.24,
      "duration": 4.879
    },
    {
      "lang": "en",
      "text": "whatever it is like the ch like the the",
      "offset": 3850.72,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "big thing that the protagonist needs to",
      "offset": 3853.119,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "overcome is like the resolution of the",
      "offset": 3854.72,
      "duration": 4.879
    },
    {
      "lang": "en",
      "text": "task, right? But how do we maintain that",
      "offset": 3856.72,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "narrative integrity where every step of",
      "offset": 3859.599,
      "duration": 4.561
    },
    {
      "lang": "en",
      "text": "the way the agent can kind of predict",
      "offset": 3861.76,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "the next token which is like predict the",
      "offset": 3864.16,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "next part of the story to reach that",
      "offset": 3865.68,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "conclusion. So we played around with",
      "offset": 3867.28,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "things like cleaning up uh duplicate",
      "offset": 3869.52,
      "duration": 5.599
    },
    {
      "lang": "en",
      "text": "file reads that works pretty well. But",
      "offset": 3872,
      "duration": 5.119
    },
    {
      "lang": "en",
      "text": "ultimately this is another case where",
      "offset": 3875.119,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "it's like well what if you just give the",
      "offset": 3877.119,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "model like what if you just ask the",
      "offset": 3878.72,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "model hey like what do you think belongs",
      "offset": 3880.559,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "in context? Another form of this is",
      "offset": 3882.24,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "summarization which is like hey",
      "offset": 3884.16,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "summarize all the relevant details and",
      "offset": 3885.76,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "then we'll swap that in. That works",
      "offset": 3887.52,
      "duration": 3.039
    },
    {
      "lang": "en",
      "text": "really really well.",
      "offset": 3889.44,
      "duration": 3.119
    },
    {
      "lang": "en",
      "text": "Yeah. Uh double clicking on the a",
      "offset": 3890.559,
      "duration": 4.721
    },
    {
      "lang": "en",
      "text": "mentioned that's very verbose. When do",
      "offset": 3892.559,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "you use that?",
      "offset": 3895.28,
      "duration": 3.279
    },
    {
      "lang": "en",
      "text": "Right now it's a tool. The way that it",
      "offset": 3896.48,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "works is when client wants when client's",
      "offset": 3898.559,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "doing sort of the agentic exploration of",
      "offset": 3901.44,
      "duration": 3.679
    },
    {
      "lang": "en",
      "text": "trying to pull in relevant context and",
      "offset": 3903.119,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "it wants to sort of get an idea of",
      "offset": 3905.119,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "what's going on in a certain directory.",
      "offset": 3907.2,
      "duration": 4.639
    },
    {
      "lang": "en",
      "text": "For example, there's a tool that lets it",
      "offset": 3908.96,
      "duration": 6.399
    },
    {
      "lang": "en",
      "text": "pull in all the sort of language from a",
      "offset": 3911.839,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "directory. So, it could be the names of",
      "offset": 3915.359,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "classes, the names of functions, and",
      "offset": 3917.119,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "that gives it some idea of, okay, here's",
      "offset": 3919.359,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "what's going on in this in this folder.",
      "offset": 3921.359,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "And if it's if it seems relevant to",
      "offset": 3923.119,
      "duration": 2.96
    },
    {
      "lang": "en",
      "text": "whatever the task is trying to",
      "offset": 3924.96,
      "duration": 2.96
    },
    {
      "lang": "en",
      "text": "accomplish is, then it sort of like",
      "offset": 3926.079,
      "duration": 4.561
    },
    {
      "lang": "en",
      "text": "zooms in and starts to actually read",
      "offset": 3927.92,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "those entire files into context. So,",
      "offset": 3930.64,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "it's it's essentially a way to help it",
      "offset": 3932.88,
      "duration": 2.88
    },
    {
      "lang": "en",
      "text": "kind of figure out how to navigate",
      "offset": 3934.64,
      "duration": 3.199
    },
    {
      "lang": "en",
      "text": "through large code bases. Yeah, we we've",
      "offset": 3935.76,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "seen some companies working on it's like",
      "offset": 3937.839,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "an interesting idea. It's like an a but",
      "offset": 3940.24,
      "duration": 4.559
    },
    {
      "lang": "en",
      "text": "it's also a knowledge graph and you can",
      "offset": 3942.24,
      "duration": 6.079
    },
    {
      "lang": "en",
      "text": "run these discrete deterministic",
      "offset": 3944.799,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "almost like actions on this knowledge",
      "offset": 3948.319,
      "duration": 4.561
    },
    {
      "lang": "en",
      "text": "graph where you could say like hey find",
      "offset": 3950.799,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "me all the functions that find me all",
      "offset": 3952.88,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "the functions in the codebase and find",
      "offset": 3955.2,
      "duration": 2.399
    },
    {
      "lang": "en",
      "text": "me all the functions that aren't being",
      "offset": 3956.48,
      "duration": 2.879
    },
    {
      "lang": "en",
      "text": "used and delete all of them and the",
      "offset": 3957.599,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "agent can kind of reason in this almost",
      "offset": 3959.359,
      "duration": 4.881
    },
    {
      "lang": "en",
      "text": "like SQL like language working with this",
      "offset": 3961.039,
      "duration": 5.361
    },
    {
      "lang": "en",
      "text": "knowledge graph to do these kinds of",
      "offset": 3964.24,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "global operations like right now if you",
      "offset": 3966.4,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "ask a coding agent to go through and",
      "offset": 3968.88,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "remove all unused functions or do like",
      "offset": 3971.2,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "some kind of large refactoring work. In",
      "offset": 3973.2,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "some cases, it might work, but very",
      "offset": 3975.28,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "often times it's just going to struggle",
      "offset": 3977.44,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "a lot, burn a lot of tokens and fail",
      "offset": 3978.96,
      "duration": 4.879
    },
    {
      "lang": "en",
      "text": "ultimately. Whereas with these kinds of",
      "offset": 3981.92,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "tools, it can actually operate on the",
      "offset": 3983.839,
      "duration": 5.041
    },
    {
      "lang": "en",
      "text": "entire repository with these kinds of",
      "offset": 3986.319,
      "duration": 4.561
    },
    {
      "lang": "en",
      "text": "query like short little query",
      "offset": 3988.88,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "statements. I think there is a lot of",
      "offset": 3990.88,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "potential in something like this where",
      "offset": 3993.2,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "it's like the next level beyond the a",
      "offset": 3995.2,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "and it's like a language for querying",
      "offset": 3997.44,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "this this kind of knowledge graph but",
      "offset": 4000,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "like we've seen with with like the cloud",
      "offset": 4002.88,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "4 release is these frontier model shops",
      "offset": 4005.2,
      "duration": 5.839
    },
    {
      "lang": "en",
      "text": "they tend to train on their own",
      "offset": 4008.4,
      "duration": 4.719
    },
    {
      "lang": "en",
      "text": "application layer and you might come up",
      "offset": 4011.039,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "with like a very clever tool that in",
      "offset": 4013.119,
      "duration": 3.761
    },
    {
      "lang": "en",
      "text": "theory would work work really well but",
      "offset": 4015.2,
      "duration": 3.599
    },
    {
      "lang": "en",
      "text": "then it doesn't work well with cloud 4",
      "offset": 4016.88,
      "duration": 3.679
    },
    {
      "lang": "en",
      "text": "because cloud 4 is trained to Gret",
      "offset": 4018.799,
      "duration": 4.481
    },
    {
      "lang": "en",
      "text": "Right. So that's another interesting",
      "offset": 4020.559,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "phenomenon where it's like you're you're",
      "offset": 4023.28,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "expecting these uh frontier models to",
      "offset": 4024.72,
      "duration": 6.879
    },
    {
      "lang": "en",
      "text": "become more generalized over time but",
      "offset": 4027.599,
      "duration": 5.841
    },
    {
      "lang": "en",
      "text": "instead they're becoming more",
      "offset": 4031.599,
      "duration": 3.361
    },
    {
      "lang": "en",
      "text": "specialized and you have to like support",
      "offset": 4033.44,
      "duration": 3.679
    },
    {
      "lang": "en",
      "text": "these different model families. Just to",
      "offset": 4034.96,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "wrap on the memory side, memory is",
      "offset": 4037.119,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "almost the artifact of summarization. So",
      "offset": 4039.44,
      "duration": 3.599
    },
    {
      "lang": "en",
      "text": "you summarize the context and then you",
      "offset": 4041.599,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "kind of extract some sides. any",
      "offset": 4043.039,
      "duration": 4.641
    },
    {
      "lang": "en",
      "text": "interesting learnings from there like",
      "offset": 4045.359,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "things that are maybe not as intuitive",
      "offset": 4047.68,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "especially for code I think people grasp",
      "offset": 4049.68,
      "duration": 4.639
    },
    {
      "lang": "en",
      "text": "the like memory about humans but like",
      "offset": 4051.599,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "what are memories about code bases and",
      "offset": 4054.319,
      "duration": 4.881
    },
    {
      "lang": "en",
      "text": "things look like I think memories right",
      "offset": 4056.799,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "now for the large part are mostly",
      "offset": 4059.2,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "useless I think the kinds of the kinds",
      "offset": 4060.799,
      "duration": 4.961
    },
    {
      "lang": "en",
      "text": "of memories that you might want the",
      "offset": 4063.44,
      "duration": 4.879
    },
    {
      "lang": "en",
      "text": "coding agent to hold on to are you know",
      "offset": 4065.76,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "specific quirks about how you know your",
      "offset": 4068.319,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "team works in the project or certain",
      "offset": 4070.16,
      "duration": 4.639
    },
    {
      "lang": "en",
      "text": "rules like only use like camel case for",
      "offset": 4072.079,
      "duration": 4.641
    },
    {
      "lang": "en",
      "text": "example, it's better to place those",
      "offset": 4074.799,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "sorts of things in like a general sort",
      "offset": 4076.72,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "of like guideline or rules file for",
      "offset": 4078.319,
      "duration": 5.441
    },
    {
      "lang": "en",
      "text": "example. But I I found that this idea of",
      "offset": 4080.72,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "like asking the agent at least coding",
      "offset": 4083.76,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "agents to like hold on to certain",
      "offset": 4086,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "memories about the project or like how",
      "offset": 4087.52,
      "duration": 4.559
    },
    {
      "lang": "en",
      "text": "you work or or things like that are or",
      "offset": 4089.76,
      "duration": 4.559
    },
    {
      "lang": "en",
      "text": "you mostly have to like force it to",
      "offset": 4092.079,
      "duration": 4.961
    },
    {
      "lang": "en",
      "text": "store those things into memory and and",
      "offset": 4094.319,
      "duration": 5.201
    },
    {
      "lang": "en",
      "text": "uh and I don't think people they don't",
      "offset": 4097.04,
      "duration": 3.679
    },
    {
      "lang": "en",
      "text": "want to have to think about those sorts",
      "offset": 4099.52,
      "duration": 2.96
    },
    {
      "lang": "en",
      "text": "of things. So, it's something we're",
      "offset": 4100.719,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "we're thinking about is is how can we",
      "offset": 4102.48,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "hold on to the tribal knowledge that",
      "offset": 4105.199,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "these agents learn along the way that",
      "offset": 4107.12,
      "duration": 2.8
    },
    {
      "lang": "en",
      "text": "people aren't documenting or putting",
      "offset": 4108.719,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "into rules files without the user having",
      "offset": 4109.92,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "to go out of their way to sort of force",
      "offset": 4111.839,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "them to store these things into a memory",
      "offset": 4113.52,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "database for example.",
      "offset": 4116,
      "duration": 3.359
    },
    {
      "lang": "en",
      "text": "Those are like kind of like workspace",
      "offset": 4117.52,
      "duration": 3.759
    },
    {
      "lang": "en",
      "text": "rules or tribal knowledge like general",
      "offset": 4119.359,
      "duration": 4.641
    },
    {
      "lang": "en",
      "text": "patterns that you use as a team. Um but",
      "offset": 4121.279,
      "duration": 5.281
    },
    {
      "lang": "en",
      "text": "then there's like in our we ran this",
      "offset": 4124,
      "duration": 6.159
    },
    {
      "lang": "en",
      "text": "like internal experiment where we built",
      "offset": 4126.56,
      "duration": 7.759
    },
    {
      "lang": "en",
      "text": "this to-do list tool where it was only",
      "offset": 4130.159,
      "duration": 6.401
    },
    {
      "lang": "en",
      "text": "one tool where you could just write the",
      "offset": 4134.319,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "to-do and every time you could like",
      "offset": 4136.56,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "rewrite the to-do from scratch and we",
      "offset": 4138.4,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "would passively as part of every like",
      "offset": 4140.64,
      "duration": 4.719
    },
    {
      "lang": "en",
      "text": "not every message but like every once in",
      "offset": 4143.52,
      "duration": 5.279
    },
    {
      "lang": "en",
      "text": "a while we would pass in this context of",
      "offset": 4145.359,
      "duration": 5.761
    },
    {
      "lang": "en",
      "text": "what the latest state of this to-do list",
      "offset": 4148.799,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "is. And we found that that actually",
      "offset": 4151.12,
      "duration": 4.719
    },
    {
      "lang": "en",
      "text": "keeps the agent on track after multiple",
      "offset": 4153.759,
      "duration": 5.121
    },
    {
      "lang": "en",
      "text": "rounds of context summarization and",
      "offset": 4155.839,
      "duration": 6.561
    },
    {
      "lang": "en",
      "text": "compaction and it could all of a sudden",
      "offset": 4158.88,
      "duration": 6.16
    },
    {
      "lang": "en",
      "text": "build like an entire complex kind of",
      "offset": 4162.4,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "task from scratch over you know 10x the",
      "offset": 4165.04,
      "duration": 6.56
    },
    {
      "lang": "en",
      "text": "to the the context window length and in",
      "offset": 4168.4,
      "duration": 4.959
    },
    {
      "lang": "en",
      "text": "internal testing this was like very very",
      "offset": 4171.6,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "promising. So, we're trying to flesh",
      "offset": 4173.359,
      "duration": 2.8
    },
    {
      "lang": "en",
      "text": "that out. And I think something like",
      "offset": 4174.64,
      "duration": 3.519
    },
    {
      "lang": "en",
      "text": "that. We we had earlier versions of the",
      "offset": 4176.159,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "the memory bank, which actually um our",
      "offset": 4178.159,
      "duration": 6.241
    },
    {
      "lang": "en",
      "text": "like Nick uh Nick Bowman, our our",
      "offset": 4182.159,
      "duration": 4.961
    },
    {
      "lang": "en",
      "text": "marketing guy, came up with this memory",
      "offset": 4184.4,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "bank concept where it was like this",
      "offset": 4187.12,
      "duration": 3.039
    },
    {
      "lang": "en",
      "text": "client rules where you would tell a",
      "offset": 4188.48,
      "duration": 2.799
    },
    {
      "lang": "en",
      "text": "client like, \"Hey, whenever you're",
      "offset": 4190.159,
      "duration": 2.721
    },
    {
      "lang": "en",
      "text": "working, have the scratch pad of what",
      "offset": 4191.279,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "you're working on.\" And this is like a",
      "offset": 4192.88,
      "duration": 5.359
    },
    {
      "lang": "en",
      "text": "more built-in way of doing that. And I",
      "offset": 4194.719,
      "duration": 6.641
    },
    {
      "lang": "en",
      "text": "think that also might be very very very",
      "offset": 4198.239,
      "duration": 4.641
    },
    {
      "lang": "en",
      "text": "helpful for the agents to just have like",
      "offset": 4201.36,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "a little scratch pad of like hey what",
      "offset": 4202.88,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "have I done so far? What's left specific",
      "offset": 4204.48,
      "duration": 5.199
    },
    {
      "lang": "en",
      "text": "app file mentions like what kind of code",
      "offset": 4206.96,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "we're working on general context and",
      "offset": 4209.679,
      "duration": 5.601
    },
    {
      "lang": "en",
      "text": "passing that off between sessions? Yeah.",
      "offset": 4212.56,
      "duration": 5.84
    },
    {
      "lang": "en",
      "text": "Any thought on cloud MD versus agents MD",
      "offset": 4215.28,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "versus agent MD? I built an open source",
      "offset": 4218.4,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "tool called agents 927 like the XKCD",
      "offset": 4220.32,
      "duration": 5.359
    },
    {
      "lang": "en",
      "text": "that just copy pastes it across all the",
      "offset": 4223.28,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "different file names so all of them have",
      "offset": 4225.679,
      "duration": 2.961
    },
    {
      "lang": "en",
      "text": "access to it. Do you think there should",
      "offset": 4227.199,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "be a single file like there's also like",
      "offset": 4228.64,
      "duration": 5.92
    },
    {
      "lang": "en",
      "text": "the ID rules versus the agent rules?",
      "offset": 4231.6,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "There's kind of like a lot of issues. I",
      "offset": 4234.56,
      "duration": 3.599
    },
    {
      "lang": "en",
      "text": "actually think it's fine that each of",
      "offset": 4236.08,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "these different tools have their own",
      "offset": 4238.159,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "specific instructions because I find",
      "offset": 4239.92,
      "duration": 5.279
    },
    {
      "lang": "en",
      "text": "myself using a cursor rules and a client",
      "offset": 4242.48,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "rules separately when I want client the",
      "offset": 4245.199,
      "duration": 4.241
    },
    {
      "lang": "en",
      "text": "agent to I want him to work you know a",
      "offset": 4247.36,
      "duration": 3.359
    },
    {
      "lang": "en",
      "text": "certain way that's different than how I",
      "offset": 4249.44,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "might want you know cursor to interact",
      "offset": 4250.719,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "with my codebase. So I think each tool",
      "offset": 4252.48,
      "duration": 5.199
    },
    {
      "lang": "en",
      "text": "is specific to the kind of work that I",
      "offset": 4255.12,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "do and I have different instructions for",
      "offset": 4257.679,
      "duration": 2.881
    },
    {
      "lang": "en",
      "text": "how I want these things to operate. So,",
      "offset": 4259.28,
      "duration": 2.56
    },
    {
      "lang": "en",
      "text": "I think I've seen like a lot of people",
      "offset": 4260.56,
      "duration": 2.8
    },
    {
      "lang": "en",
      "text": "complain about it and I get that it",
      "offset": 4261.84,
      "duration": 2.8
    },
    {
      "lang": "en",
      "text": "could make code bases look a little bit",
      "offset": 4263.36,
      "duration": 2.799
    },
    {
      "lang": "en",
      "text": "ugly, but for me it's been like",
      "offset": 4264.64,
      "duration": 2.8
    },
    {
      "lang": "en",
      "text": "incredibly helpful for them to be",
      "offset": 4266.159,
      "duration": 2
    },
    {
      "lang": "en",
      "text": "separated.",
      "offset": 4267.44,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "I noticed that you said him. Does does",
      "offset": 4268.159,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "Klein have",
      "offset": 4270.64,
      "duration": 2.64
    },
    {
      "lang": "en",
      "text": "actor? Yeah.",
      "offset": 4272.239,
      "duration": 3.281
    },
    {
      "lang": "en",
      "text": "Okay. Does he have a whole backstory?",
      "offset": 4273.28,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "Yeah. Personality.",
      "offset": 4275.52,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "Klein. So, Klein is a play on CLI and",
      "offset": 4276.56,
      "duration": 3.679
    },
    {
      "lang": "en",
      "text": "editor",
      "offset": 4279.76,
      "duration": 1.84
    },
    {
      "lang": "en",
      "text": "cuz he used to be Claude Dev and now",
      "offset": 4280.239,
      "duration": 2.081
    },
    {
      "lang": "en",
      "text": "it's Klein.",
      "offset": 4281.6,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "Yeah. I feel like Klein kind of stands",
      "offset": 4282.32,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "out in the space for having for being a",
      "offset": 4284.8,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "little bit more humanized than something",
      "offset": 4286.719,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "like, you know, a cursor agent or a",
      "offset": 4287.84,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "co-pilot or a cascade. Uh, and I think",
      "offset": 4290.239,
      "duration": 5.361
    },
    {
      "lang": "en",
      "text": "there's Devon, which is a real name, you",
      "offset": 4293.84,
      "duration": 2.24
    },
    {
      "lang": "en",
      "text": "know.",
      "offset": 4295.6,
      "duration": 2.8
    },
    {
      "lang": "en",
      "text": "Well, Claude is a real name, I guess.",
      "offset": 4296.08,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "Yeah. Yes. I've been I've been I think",
      "offset": 4298.4,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "we've all been intentional about just",
      "offset": 4300.64,
      "duration": 2.96
    },
    {
      "lang": "en",
      "text": "sort of humanizing it because it at",
      "offset": 4302.08,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "least in working with kind of gives you",
      "offset": 4303.6,
      "duration": 2.88
    },
    {
      "lang": "en",
      "text": "more confidence in it and that I could",
      "offset": 4305.12,
      "duration": 2.48
    },
    {
      "lang": "en",
      "text": "like lean on it a little bit more. there",
      "offset": 4306.48,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "is there is kind of a of a trust",
      "offset": 4307.6,
      "duration": 5.92
    },
    {
      "lang": "en",
      "text": "building with I think with an agent and",
      "offset": 4310.4,
      "duration": 4.799
    },
    {
      "lang": "en",
      "text": "the humanizing aspect of it I think has",
      "offset": 4313.52,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "been helpful to me personally and this",
      "offset": 4315.199,
      "duration": 3.201
    },
    {
      "lang": "en",
      "text": "goes back to like the narrative",
      "offset": 4317.12,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "integrity is just it's actually really",
      "offset": 4318.4,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "important I think to anthropomorphize",
      "offset": 4320.56,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "agents in general u because everything",
      "offset": 4323.04,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "they do is like a little story and",
      "offset": 4325.92,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "without having a distinct kind of",
      "offset": 4328.64,
      "duration": 5.599
    },
    {
      "lang": "en",
      "text": "identity you get worse results and when",
      "offset": 4331.36,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "you're developing these agents that's",
      "offset": 4334.239,
      "duration": 3.281
    },
    {
      "lang": "en",
      "text": "kind of how we need to think about them,",
      "offset": 4335.6,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "right? We need to think that we're like",
      "offset": 4337.52,
      "duration": 2.639
    },
    {
      "lang": "en",
      "text": "crafting these stories. We're almost",
      "offset": 4338.8,
      "duration": 2.96
    },
    {
      "lang": "en",
      "text": "like Hollywood directors, right? We're",
      "offset": 4340.159,
      "duration": 3.441
    },
    {
      "lang": "en",
      "text": "we're putting all the right pieces in",
      "offset": 4341.76,
      "duration": 5.919
    },
    {
      "lang": "en",
      "text": "place for the story to unfold. And yeah,",
      "offset": 4343.6,
      "duration": 5.84
    },
    {
      "lang": "en",
      "text": "having an identity around that is",
      "offset": 4347.679,
      "duration": 3.201
    },
    {
      "lang": "en",
      "text": "really, really important. And Klein, you",
      "offset": 4349.44,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "know, he's a cool little guy. He's, you",
      "offset": 4350.88,
      "duration": 2.319
    },
    {
      "lang": "en",
      "text": "know, he's",
      "offset": 4352.56,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "just a chill guy. He's chill guy. He's",
      "offset": 4353.199,
      "duration": 4.801
    },
    {
      "lang": "en",
      "text": "helping us out, you know, he's always",
      "offset": 4356.4,
      "duration": 3.759
    },
    {
      "lang": "en",
      "text": "like happy to help or if he's told to",
      "offset": 4358,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "not be happy, he can be very grumpy, you",
      "offset": 4360.159,
      "duration": 3.201
    },
    {
      "lang": "en",
      "text": "know.",
      "offset": 4362.48,
      "duration": 2.719
    },
    {
      "lang": "en",
      "text": "So, that's great.",
      "offset": 4363.36,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "Awesome. Uh I know you're hiring. You",
      "offset": 4365.199,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "are you have you're 20 people now. You",
      "offset": 4367.04,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "are aiming to 100. You have a beautiful",
      "offset": 4369.36,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "new office. What's your best pitch for",
      "offset": 4371.76,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "working at Klein? A lot of our hiring",
      "offset": 4373.84,
      "duration": 6.399
    },
    {
      "lang": "en",
      "text": "right now is um so far it's been just",
      "offset": 4376.96,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "friends of friends, people in our",
      "offset": 4380.239,
      "duration": 2.48
    },
    {
      "lang": "en",
      "text": "network, people that we've worked with",
      "offset": 4381.52,
      "duration": 4.719
    },
    {
      "lang": "en",
      "text": "before that we we've trusted and that we",
      "offset": 4382.719,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "know can can show up for like this",
      "offset": 4386.239,
      "duration": 2.801
    },
    {
      "lang": "en",
      "text": "incredibly hard thing that we're we're",
      "offset": 4387.679,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "working on. And there's a lot of",
      "offset": 4389.04,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "challenges ahead and and I think the",
      "offset": 4391.28,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "problem space is probably the most",
      "offset": 4392.96,
      "duration": 2.88
    },
    {
      "lang": "en",
      "text": "exciting thing to be working on right",
      "offset": 4394.56,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "now. Engineers in general love working",
      "offset": 4395.84,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "on things that make their own lives",
      "offset": 4398.64,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "easier. And so I couldn't imagine",
      "offset": 4400.08,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "working on something more exciting than",
      "offset": 4401.84,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "than a coding agent. And and that's you",
      "offset": 4403.76,
      "duration": 3.439
    },
    {
      "lang": "en",
      "text": "know that's a little bit biased but I",
      "offset": 4405.679,
      "duration": 3.121
    },
    {
      "lang": "en",
      "text": "think a large part of it is it's it's an",
      "offset": 4407.199,
      "duration": 3.201
    },
    {
      "lang": "en",
      "text": "exciting problem space. Um, we're",
      "offset": 4408.8,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "looking for really motivated people that",
      "offset": 4410.4,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "want to work on challenges like figuring",
      "offset": 4412.64,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "out kind of like what the next 10 years",
      "offset": 4414.719,
      "duration": 3.761
    },
    {
      "lang": "en",
      "text": "looks like and building kind of the",
      "offset": 4416.8,
      "duration": 3.359
    },
    {
      "lang": "en",
      "text": "foundation for, you know, what comes",
      "offset": 4418.48,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "next after background agents or multi-",
      "offset": 4420.159,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "aents and and really help in sort of",
      "offset": 4422.4,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "defining how all this shapes up. We have",
      "offset": 4424.159,
      "duration": 5.281
    },
    {
      "lang": "en",
      "text": "this like really excited community of of",
      "offset": 4427.84,
      "duration": 3.359
    },
    {
      "lang": "en",
      "text": "users and developers. I think being open",
      "offset": 4429.44,
      "duration": 2.88
    },
    {
      "lang": "en",
      "text": "source has also created a lot of",
      "offset": 4431.199,
      "duration": 3.361
    },
    {
      "lang": "en",
      "text": "goodwill with us where a lot of the",
      "offset": 4432.32,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "feedback we get is like incredibly",
      "offset": 4434.56,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "constructive and helpful in shaping our",
      "offset": 4436,
      "duration": 3.679
    },
    {
      "lang": "en",
      "text": "road map and and the product that we're",
      "offset": 4437.76,
      "duration": 3.439
    },
    {
      "lang": "en",
      "text": "building and working with a community",
      "offset": 4439.679,
      "duration": 2.801
    },
    {
      "lang": "en",
      "text": "like that is like one of the most",
      "offset": 4441.199,
      "duration": 3.201
    },
    {
      "lang": "en",
      "text": "fulfilling things ever. Right now we're",
      "offset": 4442.48,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "we're kind of uh um in between offices",
      "offset": 4444.4,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "but you know doing things like",
      "offset": 4447.92,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "go-karting and kayaking and things like",
      "offset": 4449.52,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "that. So it's it's a lot of hard work",
      "offset": 4451.04,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "but you know we we make sure to to have",
      "offset": 4452.56,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "fun along the way. So",
      "offset": 4454.56,
      "duration": 4.639
    },
    {
      "lang": "en",
      "text": "yeah. No, like Klein is a it's a unique",
      "offset": 4455.92,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "company because it it really does feel",
      "offset": 4459.199,
      "duration": 2.881
    },
    {
      "lang": "en",
      "text": "like we're all just like friends",
      "offset": 4460.96,
      "duration": 4.239
    },
    {
      "lang": "en",
      "text": "building something cool and we work",
      "offset": 4462.08,
      "duration": 5.92
    },
    {
      "lang": "en",
      "text": "really really hard and the space is it's",
      "offset": 4465.199,
      "duration": 4.801
    },
    {
      "lang": "en",
      "text": "not just competitive, it's like hyper",
      "offset": 4468,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "competitive. There's like capital is",
      "offset": 4470,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "flowing into all every single possible",
      "offset": 4472.8,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "competitors. We have forks of forks like",
      "offset": 4475.44,
      "duration": 3.279
    },
    {
      "lang": "en",
      "text": "I said raising tens of millions of",
      "offset": 4477.04,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "dollars and we're growing very rapidly.",
      "offset": 4478.719,
      "duration": 5.281
    },
    {
      "lang": "en",
      "text": "We're at 20 people now. We're aiming to",
      "offset": 4482.08,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "be at 100 people by the end of the year.",
      "offset": 4484,
      "duration": 4.719
    },
    {
      "lang": "en",
      "text": "And being open source, it has its own",
      "offset": 4486.4,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "challenges. It's like people, we do all",
      "offset": 4488.719,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "this research, we do all this",
      "offset": 4491.92,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "benchmarking work to make sure our diff",
      "offset": 4493.12,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "editing algorithm is robust the way",
      "offset": 4495.44,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "we're working with these models to",
      "offset": 4497.04,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "optimize for the lowest possible",
      "offset": 4498.96,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "diffedit failures. And then we open",
      "offset": 4501.04,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "source that. And then we post it on",
      "offset": 4502.88,
      "duration": 2.799
    },
    {
      "lang": "en",
      "text": "Twitter and someone's like, \"Oh, thanks",
      "offset": 4504.56,
      "duration": 2.32
    },
    {
      "lang": "en",
      "text": "so much for open sourcing that. I'm",
      "offset": 4505.679,
      "duration": 2.241
    },
    {
      "lang": "en",
      "text": "going to go and like raise a bunch of",
      "offset": 4506.88,
      "duration": 2.72
    },
    {
      "lang": "en",
      "text": "money with like our own product with",
      "offset": 4507.92,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "it.\" But the way that I see it is like",
      "offset": 4509.6,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "this is, you know, let them copy. We're",
      "offset": 4511.84,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "the leaders in the space. We're we're",
      "offset": 4514.64,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "kind of showing the way for the entire",
      "offset": 4516.239,
      "duration": 5.041
    },
    {
      "lang": "en",
      "text": "industry and being an engineer and and",
      "offset": 4518.32,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "building all this stuff is super",
      "offset": 4521.28,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "exciting. So, working with all these",
      "offset": 4522.64,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "people is just amazing.",
      "offset": 4524.64,
      "duration": 2.16
    },
    {
      "lang": "en",
      "text": "Okay,",
      "offset": 4526.4,
      "duration": 2.4
    },
    {
      "lang": "en",
      "text": "awesome. Thank you guys for coming on.",
      "offset": 4526.8,
      "duration": 6.68
    },
    {
      "lang": "en",
      "text": "Yeah. All right. So much so much fun.",
      "offset": 4528.8,
      "duration": 4.68
    }
  ],
  "cleanText": "Hey everyone, welcome to the Laden Space podcast.\nThis is Allesio, partner and CTO at Desible, and I'm joined by my co-host Wix, founder of Smai.\nWelcome.\nAnd today in the studio, we have two guests from Cline, Pash, and Saoud Rizwan.\nThat's right.\nYes, you nailed it.\nLet's go.\nI think that Cline has a decent fan base, but not everyone has heard of it.\nMaybe we should just get like an upfront, like, what is Cline, maybe from you, and then like, you can modify that as well.\nYeah, Cline's an open source coding agent.\nIt's a VS Code extension right now, but it's coming to Jet Brains and Neovim and the CLI.\nYou give Cline a task, and it just goes off and does it.\nIt can take over your terminal, your editor, your browser, connect to all sorts of MCP services, and essentially take over your entire developer workflow, and it becomes this point of contact for you to get your entire job done, essentially.\nBeautiful.\nUh, Pash, what would you modify, or what's another way to look at Cline that you think is also valuable?\nYeah, I think Cline is the kind of infrastructure layer for agents, for all open source agents people building on top of this, like, agentic infrastructure.\nCline is a fully modular system.\nThat's the way we envision it, and we're trying to make it more modularized so that you can build any agent on top of it.\nYeah.\nSo with the CLI and with the SDK that we're rolling out, you're going to be able to build fully agentic systems for anything, not just coding.\nOh, okay.\nThat, that is a different perspective on Cline than I had.\nSo, okay, let's, let's talk about coding first, and then we'll talk about the broader stuff.\nYou also are similar to Ader.\nI don't know who comes first in that you use the plan and act paradigm quite a bit.\nI'm not sure how well known this is, like, to me, I'm relatively up to speed on it, but again, like, maybe you guys want to explain, like, why different models for different things.\nYeah, I'm going to take the credit for coming up with plan act first, and then we Cline was the first to sort of come up with this concept of having two modes for the developer to engage with.\nUh, so just in like talking to our users and seeing how they use Cline, where it was really only an input field, we found a lot of them starting off working with the agent, coming up with a markdown file where they ask the agent to put together some kind of architecture or plan for the work that they want the agent to go on to do.\nAnd so they, we would find that that people just came up with this workflow for themselves just organically.\nAnd so we thought about how we might translate that into the product, so it's a little bit more intuitive for new users who don't have to kind of pick up that pattern for themselves, uh, and can kind of direct and and put in guard rails for the agent to hear to these different modes whenever the user switches between them.\nSo for example, in plan mode, the agent's directed to be more exploratory, read more files, get uh, sort of understanding and fill up its context with any sort of relevant information to come up with a plan of attack for whatever the task is the user wants to accomplish.\nAnd then when they switch to act mode, that's when the agent gets this directive to look at the plan and start executing on it, running commands, editing files.\nAnd it just makes working with agents a little bit easier.\nEspecially with something like Cline, where a lot of the times people's engagement with it is mostly in the plan mode, where there's a lot of back and forth.\nThere's a lot of extracting context from the developer, you know, asking questions, you know, what do you want the theme to look like?\nWhat pages do you want on the website?\nJust trying to extract any sort of information that the user might not have put into their initial prompt.\nOnce the user feels like, okay, I'm ready to let the agent go off and work on this, they switch to act mode, check auto approve, and just kick their feet up and, you know, get coffee or whatever and let the agent get the job done.\nSo, yeah, most of the engagement happens in the plan mode, and then act mode, they kind of just have a peripheral vision into what's going on, mostly to course correct whenever it goes in the wrong direction, but for the most part, they can just rely on the model to get it done.\nAnd was this the first shape of the product, or did you get to the plan act iteratively, and maybe was this the first idea of the company itself, or were you exploring other stuff?\nIt was a lot of, especially in the early days of Cline, it was a lot of experimenting and talking to our users and seeing what kind of workflows came that they found that were useful for them, and and translating them into the product.\nSo, plan and act was really a byproduct of just talking to people in our Discord, just asking them what would be useful to them, what what kind of prompt shortcuts we could add into the UI.\nI mean, that's really all plan and act mode is, is essentially a shortcut for the user to save them the trouble of having to type out, you know, I want you to ask me questions and put together a plan.\nUm, the way that you might have to, and, you know, some of the other tools, you have to like be explicit about I want you to come up with a plan before, you know, acting on it or editing files, incorporating that into the UI just saves the user the trouble of having to type that out themselves.\nBut you started right away as a coding product, and then this was part of, okay, how do we get better UX, basically.\nExactly.\nYeah.\nWhat was the model evaluation at the time?\nSo I'm sure part of, like, the we need plan and act is, like, maybe the models are not able to do it end to end when you started working on that per, where were the model limitations, what were the best models, and then how has that evolved over time?\nYeah, when I first started working on Cline, this was, I think, 10 days after Cloud3.5 Sonic came out.\nI was reading Anthropic's model card addendum, and there was this section about agentic coding and how it was so much better at this step-by-step accomplishing tasks, and they talked about running this internal test where they let the model run in this loop where it could call tools.\nUm, and it was obvious to me that, okay, they have some version, they have some application internally that's really different from how the, you know, the other things at the time worked.\nThings like Copilot and Cursor and Ader, they didn't do this sort of like step-by-step reasoning and accomplishing tasks.\nThey were more suited for the Q&A and and oneshot prompting paradigm.\nUh, at the time, I think it was uh, June 2024, Anthropic was doing a bill with cloud hackathon.\nSo I thought, okay, this is a really cool new capability that none of the models have really been capable of doing before.\nAnd uh, I think being able to create something from the ground up and take advantage of kind of like the nuances of how much the models improved in that point in time.\nSo for example, Cloud3.5 was also really good at this test called needle in a haystack, where if it has a lot of context in its context window, for example, you know, 90% of its 200k context window is filled up, it's really good at picking out granular details in that context.\nWhereas before Cloud 3.5, it really pay a lot more attention to whatever was at the beginning or the end of the context.\nSo just taking advantage of kind of the nuances of it being better at understanding longer context and it being better at task by task, uh, sorry, step by step accomplishing tasks and building a product from the ground up just kind of let me create something that just felt a little bit different than anything else that was around at the time.\nAnd some of the core principles in building the first version of the product was just keep it really simple.\nJust let the developer feel like they can kind of use it however they want.\nSo make it as general as possible and kind of let them come up with whatever workflows, you know, works well for them.\nPeople use it for all sorts of things outside of coding.\nOur product marketing guy, Nick Bowman, he uses it to connect to, you know, a Reddit MCP server, scrape content, connect it to an XMCP server, and and post tweets, essentially.\nEven though it's a VS Code extension and a coding agent, MCP kind of lets it function as this everything agent where it can connect to, you know, whatever services and things like that.\nAnd that's really a a side effect of of having very general prompts just in the product and not sort of limiting it to just coding tasks.\nI was at a conference in Amsterdam, and I built my whole presentation, my whole slide deck using this library.\nIt's like a JavaScript library called slidev.\nAnd I just asked Cline like, \"Hey, like, here's like my style guidelines.\"\nI wrote like a big Cline rules document explaining like how I want to style the presentation in slide dev.\nI told Cline like the agenda.\nI kind of recorded using this other app called Limitless, like, transcribed my voice into text about like my thoughts, just like stream of consciousness about what I was going to talk about for this conference for my talk, and Cline just went in and built the whole, the whole deck for me.\nSo, you know, Cline really can do anything in JavaScript.\nIn JavaScript.\nYeah.\nYeah.\nSo, it's, it's kind of a coding use case.\nIt was kind of a coding use case, but then making a presentation out of it, but it can also like run scripts, like do like data analysis for you, and then put that into a deck, you know, kind of combine things.\nAnd being being a VS Code extension is is kind of this like, it gives you these interesting capabilities where you have access to the user's OS, you have access to the user's terminal, and you know, you can read and edit files.\nBeing an extension, it reduces a lot of the onboarding friction for a lot of developers where they don't have to, you know, install a whole new application or have to, you know, go through whatever internal jumping through hoops to try to get something approved to to use within their organizations.\nSo the marketplace gave us a ton of really great distribution and is sort of like the perfect conduit for something that needs access to files on your desktop or to be able to run things on your terminal to be able to edit code and to take advantage of VS Code's really nice UI and show you like diff views, for example, before and after it makes changes to to files.\nWeren't you tempted to for VS Code though?\nI mean, you know, you could be sitting on $3 billion right now.\nWell, no.\nI, I, I actually like pity anybody that has to fork VS Code because Microsoft makes it like notoriously difficult to maintain these forks.\nSo, a lot of resources, um, and efforts go into just maintaining, keeping your fork up to date with all the updates that VS Code is making.\nI see.\nUm,\nis that because they, they have a private repo and they just sync it.\nThere's no like\nExactly.\nExactly.\nIt's one of those kinds of open source projects, right?\nAnd VS Code's moving so quickly where I'm sure they run into all sorts of issues, not just in, you know, things like merge conflicts, but also in the back end.\nThey're always making improvements and changes to, for example, their VS Marketplace API.\nAnd to have to like reverse engineer that and figure out kind of how to make sure that your users don't run into issues using things like that is I'm sure like a huge headache for anybody that has to maintain a VS code fork.\nAnd it also, you know, being an extension also gives us a lot more distribution.\nIt's not that you have to use us or somebody else.\nYou can use Cline in Cursor or in windsurf or in VS code.\nAnd I think Cline complements all these things really well in that, you know, we get the opportunity to kind of figure out and and work really closely with our users to figure out what the best agentic experience is, whereas, you know, Cursor and windsurf and and co-pilot have to think about the entire developer experience, the inline code edits, the Q&A sort of all the other bells and whistles that go into writing code.\nWe get to just focus on what I think is the future programming, which is this agentic paradigm.\nUm, and as the models get better, people are going to find themselves using natural language, working with an agent more and more and less being in the weeds and editing code and tab autocomplete.\nYeah.\nLike imagine how many like resources you would have to spend maintaining a fork of VS Code where we can just kind of stay focused on the core agentic loop, optimizing for different model families as they come out, supporting them.\nYou know, there's so much work that goes into all of this that maintaining a fork on the side would just be such a massive distraction for us that I don't think it's really worth it.\nI feel like when you talk, I hear this distinction between we want to be the best thing for the future of programming, and then also this is also great for non-programming.\nIs this something that is being risen for you, where, like, you're seeing more and more people use the MCP servers, especially to do less technical thing, and that's an interesting area, or do you feel like programming is still like the highest kind of like economic value thing to be selling today?\nI'm curious if you can share more.\nIn terms of economic value, programming is definitely the highest cost of benefit for language models right now, and I think, you know, we're seeing a lot of, you know, model labs recognize that OpenAI, Anthropic are taking coding a lot more seriously than I think they did a year ago.\nWhat we've seen is, while yes, like MC, the MCP ecosystem is growing, and a lot of people are using it for things outside of programming, the majority use case is mostly developer work.\nThere was an article on Hacker News a couple weeks ago about how a developer deployed a buggy Cloudflare worker and used a Sentry MCP server to pull a stack trace and ask Cline to sort of fix the bug using the stack trace information, connect to a GitHub MCP server to close the issue and deploy the fix to Cloudflare, all right within Cline, using natural language, never having to leave VS Code, and it sort of interacts with all these services that otherwise the developer would have had to have the cognitive overload of having to, you know, figure out for himself and leave his developer environment to to essentially do what the agent could have done just all in the background, just using natural language.\nI think that's kind of like where things are headed is the application layer being connected to sort of all the different services that you might have had to interact with before manually, and it being this sort of single point of contact for you to interact with using natural language and you being less and less in the code and more and more a highle understanding of what the agent's doing and being able to course correct.\nI think that's\n\n\nAnother part of what's important to us and what's allowed us to kind of cut through the noise in this like incredibly noisy space is, I think, a lot of people have really grand ideas for, you know, where things are heading, but we've been really maniacal about what's useful to people today. A large part of that is understanding sort of the limitations of these models, what they're not so good at, and giving enough insight into those sorts of things to the end developer so that they know how to course correct. They know how to give feedback when things don't go right. So, for example, Cline is really good about, you know, giving you a lot of insight into the prompts going into the model, into when there's an error, why the error happened, into the tools that the model's calling. We try to give as much insight into what exactly the model is doing at each step in accomplishing a task. So when things don't go wrong or it starts to go off in the wrong direction, you can, you know, give it feedback and course correct. And I think the course correcting part is so incredibly important in getting work done, I think, much more quickly than if you were to kind of give a background agent work. You come back a couple hours later and it's just like totally wrong, and it didn't do anything that you expected it to do, and you kind of have to retry a couple times before it gets it right.\n\nI think the Sentry example is great because I feel in a way the MCPs are like cannibalizing the products themselves. Like I started using the Sentry MCP, and then Sentry released seere, which is like their issue resolution agent, and it was free at the start. So I turned it on in Sentry. I was using it. It's great. And then they started charging money for it. And I'm like, I can use the MCP for free, put the data in my coding agent, and it's going to fix the issue for free and send it back. I'm curious to see, especially in coding, where you can kind of have this closed loop where, okay, are these MCPs going to become the paid AI offering so that then you can plug it in, and is Cline going to have kind of like a MCP subscription where like you're kind of fractionalizing all these costs? Um, to me today feels like it doesn't make a lot of sense the way they're structured.\n\nWell, yeah, we were like, uh, very early on, we like, we've been bullish on MCP from the very beginning, and um,\n\nWere you a launch partner?\n\nFunny story about MCP. I think, sorry to interrupt.\n\nYeah, no worries.\n\nI think, uh, when Anthropic first launched MCP and they made this big announcement about, you know, this new protocol that they've been working on and open sourcing it, nobody really understood what it meant. And it took me some time really digging into their documentation about how it works and why this is important. I think they kind of took this bet on the open source community contributing to an ecosystem in order for it to really take off. And so I wanted to try to help with that effort as much as possible. So for a long time, most of Cline's system prompt was how does MCP work, because it was so new at the time that, you know, the models didn't know anything about it and how to make MCP servers. So like if the developer wanted to, you know, make something like that, it'd be really good at it. And I'd like to think that, you know, Cline had something to do with how much the MCP ecosystem has grown since then and just getting developers more insight and sort of awareness about how it works under the hood, which I think is incredibly important in using it, let alone just developing these things. And so, yeah, when we launched MCP in Cline, I remember our Discord users just trying to wrap their heads around it. And in seeing Cline build MCP servers from the ground up, they're like, \"Okay, they started to connect the dots. This is how it works under the hood. This is why it's useful. This is how agents connect to these tools and services and these APIs and uh, sort of saved me a lot of the trouble of having to do this sort of stuff myself.\" Those are like the early days of MCP, and people were still trying to wrap their heads around it.\n\nAnd there's like a big problem with discoverability. So, back in like February, we launched the MCP marketplace where you could actually go through and have like this one-click install process where Cline would actually go through looking at a readme and that's like linked to a GitHub, install the whole MCP server from scratch and just get it running immediately. And that was like, I think, around that time, that's when MCP really started taking off with like the launch of the marketplace where people were able to discover MCPs, contribute to the MCP marketplace. We've listed over like 150 MCP servers since then, and um, like the top MCPs in our marketplace have over, you know, hundreds of thousands of downloads, people using them. And you know, there's like really notable examples where you mentioned like how are people like it's like kind of eating existing products, but at the same time, we're starting to see like this ecosystem evolve where people are monetizing MCPs. Like a notable example of this is 21st dev magic MCP server where it injects some taste into this coding agent into the LLM where they have this library of beautiful components, and they just inject relevant examples so that Cline can go in and implement beautiful UIs. And the way they monetize that was like a standard API key. So, we're starting to see developers really like um, take MCPs, build them in, have distribution platforms like the MCP marketplace in Cline, and monetize their whole business around that. So now it's like almost like you're selling tools to agents, which is a really interesting topic.\n\nAnd you can do that because you're in VS Code, so you have the terminal, so you can do npx run the different servers. Have you thought about doing remote MCP hosting, or you feel like that's not something you should take over?\n\nYeah, we haven't really hosted any ourselves. We think that's, we're looking into it. I think it's, it's all very nascent right now, the remote MCPs, but we're definitely interested in supporting remote MCPs and listing them on our marketplace. And another part, I think, with sort of local MCP servers and remote MCPs is most of the remote MCPs are only useful to connect to different APIs, but that's only a, you know, that's only a small use case for MCPs. A lot of MCPs help you connect to different applications on your computer. For example, there's like a Unity MCP server that helps you create, you know, 3D objects within right from within VS Code. There's an Ableton MCP server so you can like make songs using something like Cline or whatever else uses MCPs. We won't see a world where these MCP servers are only hosted remotely. There will always be some mix of local MCP servers and remote MCP servers. I think the remote MCP servers do make the installation process a little bit easier with, you know, with something like an OAUTH flow and just authenticating a little bit, not as painful as having to manage API keys yourself. But for the most part, I think the MCP ecosystem is really in its earlier days. We're still trying to figure out this good balance of security, but also convenience for the end developer so that it's not a pain to have to set these things up. And I think we're still in this very much experimental phase about how useful it is to people. And I think now that it is seeing this level of market fit and people are coming out with, you know, these sorts of like articles and workflows about how it's totally changing their jobs, I think there's going to be a lot more of resources and efforts that go into the ecosystem and just building out the protocol, which I think there's a lot on Anthropic's roadmap, and I think the community in general just has a lot of ideas, and our marketplace in particular has given us insights into some ways that we could improve it, things that, you know, developers have asked for from it, that where we're kind of thinking about how do we, you know, what does the MP marketplace of the future look like? And for us, that's it's going to be a combination of, you know, Well, there's a lot of our users are very security conscious, and there's a lot of ways that MCP servers can be pretty dangerous to use if you don't trust the end developer of these things. And so we're trying to figure out, you know, what is a future look like where you can where you have some level of confidence in the MCP servers you're installing. I think right now it's just it's too early, and there's a lot of trust in the community that I don't think a lot of, you know, enterprise developers, organizations are quite willing to do yet. So that's something that's top of mind for us.\n\nThere's an interesting tension between Anthropic and the community here. You basically kind of have a model reg MCP registry internally, right?\n\nHonestly, I think you should expose it. I was looking for it on your website, and you don't have it. Like the only way to access it is install Cline, but there's others like smithery and all the other guys, right? But then Anthropic has also said they'll launch a model registry at some point or MCP registry at some point.\n\nIf Anthropic launched the official one, would they just just win by default? Right. Would because like, would you just would you just use them?\n\nI think so. I think the, I think the entire ecosystem will just converge around whatever they do. They just have such good distribution and and they're\n\nYeah,\n\nthey came up with it. So,\n\nyeah, exactly.\n\nCool. And I, I wanted to, uh, I noticed that you have some like really downloaded MCPs. I was going by most installs. I'm just going to read it off. You can stop me anytime to comment on them. So, top is file system MCP. Makes sense. Browser tools from agent desk AI. Don't know what that is. Sequential thinking, that that one came out with the original MCP release. Context 7. I don't know that one.\n\nThat's a, that's a big one.\n\nWhat, what is that?\n\nThat, uh, context 7 kind of helps you pull in documentation from anywhere, and it has like this big index of all of the popular libraries and documentation for them.\n\nOkay.\n\nAnd you can, your agent can kind of submit like a natural language query and search for any docs, everyone's docs.\n\nYes. Yeah. Uh, and apparently Upstash did that, which is also unusual because Upstad\n\nget tools that one came out originally. Fetch browser use. Browser use, I imagine, competes with browser tools, right? I guess. And then below that competition, playwright, right? Like, so there's a lot of like, let's automate the browser and let's let's do stuff, I assume, for debugging. Firecrawl, puppeteer, uh, Figma, here's one for you. Perplexity research, is that yours? Um, well, yeah, I fork that one and listed it, but yeah, that's, you know, that's another very popular one where you can research.\n\nany people want to emulate the, uh, automate the browser. I'm just trying to learn lessons from what people are doing, right? They want to automate the browser, they want to access git and file system, they want to access docs and search. Anything else that you think like is notable?\n\nThere's all kinds of stuff where it's like, you know, there's like the Slack MCP where you can send, you know, that's actually one workflow that I have set up where you can like automate repetitive tasks in Cline. So I tell Cline like, okay, pull down this PR, uh, use the GH command line tool, which I already have installed using the terminal to pull the PR, get the description of the PR, the discussion on it, and get the full diff as like a like a single command, non-interactive command, pull in all that context, read the files around the diff, it ask a question like, hey, do you want me to approve this or not with this comment, and if I say yes, approve it and then send a message in Slack to my team using the Slack MCP, for example.\n\nOh, use it to write.\n\nYes.\n\nI would only use it to read.\n\nYeah. No, it's, you know, people like, I love it. You know, I love being able to just like send an automated message in Slack or whatever. Um, you can also like set it up like set up your workflow however you want where it's like, okay, Cline, please ask me before doing anything. You know, just make sure you're asking me to like approve before you send a message or something like that.\n\nYeah. Okay. Just just to close out MCP side, anything else interesting going on in MCP universe that we should talk about? MCP off was recently ratified.\n\nI think monetization is a big question right now for the MCP ecosystem. Um, we've been talking a lot with Stripe. They're very bullish on MCP. Um, and they're trying to figure out like a monetization layer for it, but it's all so early that it's kind of hard to really even envision where it's going to go. Let me just put up a straw man and then you can tell me what's wrong with it. Like how is this different from API monetization, right? Like you sign up here, make an account, I give you a token back, and then you use token, they charge you against your usage.\n\nNo, like, like I think that's how it is right now. That's how like the the magic, uh, MCP, the 21st dev guys did it. But we're kind of envisioning a world where agents can pay themselves for these MCP tools that they're using and pay for each tool call, and you can't deal with like a million different API keys from different products and like signing up for all this. There needs to be like a unified kind of payment layer. Some people talk about like stable coins, how like those are coming out now that agents can natively use those. Stripe is, they're considering this like abstraction around the MCP protocol for payments, but like I said, it's kind of hard to really tell where it's gonna, how that's going to manifest.\n\nI would say like we, I, I covered when they launched their agent toolkit, um, last year, a few months ago, it seemed like that was enough. Like it, you didn't seem to need stable coins except for the fact that they take like 30 cents every transaction.\n\nYeah.\n\nHave you seen people use the X42 thing by Coinbase to make, it's basically like the, you can do a HTTP request that includes payment in it?\n\nWhat? Yeah. Yeah. It's, uh, it's been around forever, the 402 error, that's like payment not accepted or something, right? So yeah, we've seen some people talking about that, like more like natively building that in, but yeah. Yeah, no one's really doing that right now. Anything you're seeing?\n\n\nOn like are people like\nmaking MCP startups that are interesting,\nmostly around rehosting local ones and\ndo remote and then basically do instead\nof setting up 10 MCPs, you have like a\ncanonical URL that you put in all of\nyour tools and then expose all the tools\nfrom all the servers.\nYeah.\nThere like MCP run some of these tools.\nYeah, but I think it kind of has the\nsame issues of how do you incentivize\npeople to make better MCPs, you know,\nand will it be mostly first party or\nwill it be third party?\nLike your Plexity MCP was the four.\nWhat was wrong with the Plexity one?\nWith MCPS and installing them locally on\nyour device, there's always a massive\nrisk associated with that.\nAnd when an MCP is created by someone that we have\nno idea who they are, at any point they\nmight, you know, update the GitHub to\nlike introduce some kind of malicious\nstuff.\nSo even if you like verified it\nwhen you were listing it, okay, you\nmight change it.\nSo I ended up having to fork a few of\nthose to make sure that we lock that\nversion down.\nOh, okay.\nSo this is just like you're just\nforking it so that you you don't change\nit without without notice.\nInteresting.\nThese are all the problems of of a\nregistry, right?\nLike that you need to uh ensure security\nand all that.\nCool.\nI'm happy to move on.\nI I would say like the last thing that's\nkind of curious is like if Anthropic\nhadn't come along and made MCP, what\nwould have happened?\nAnd what's the alternative history?\nLike like would you have come with MCP?\nSo we saw some of uh our competitors who\nhave kind of working on their own\nversion of plug-and-play tools into\nthese agents.\nThey kind of had to natively create\nthese tools and integrations themselves.\nYeah.\nDirectly into their product.\nAnd so I think anybody in the space would\nhave had to just do the laborious work\nof having to recreate these tools and\nintegrations for so I think and probably\njust saved us all a lot of trouble and\ntapped into the power of open source and\ncommunity driven development and allowed\nyou know individual contributors to make\nan MCP for anything people could think\nof and really take advantage of people's\nimagination in a way that I think is\nlike necessary right now for us to\nreally tap into full potential of of\nthis sort of thing.\nSo, we've had I think a dozen episodes\nwith different coding products.\nUm, and this, by the way, this this\nepisode came directly out after he\ntweeted about Claude the code episode.\nWhere they were sitting right where\nyou're sitting.\nThanks for sharing the rag.\nYeah.\nUm, can you give people maybe the matrix\nof the market of, you know, you have\nlike fully agentic, no IDE, you have\nagentic plus IDE which is kind of yours,\nyou have IDE with some co-piloting.\nHow should people think about the\ndifferent tools and what you guys are\nbest at or maybe what you don't think\nyou're best at?\nI think what we're best at and like our\nethos since the beginning is just meet\nthe developers where they're at today.\nI think there is a little bit of insight\nand handholding these models need right\nnow and the IDE is sort of the perfect\nconduit for something like that.\nYou can see the edits it's making.\nYou can see the commands that it's\nrunning.\nYou can see the tools that it's calling.\nIt gives you the perfect UX for you to\nhave the level of insight and control\nand be able to course correct the way\nthat you need to to work with\nlimitations of these models today.\nBut I I think it's pretty obvious that\nas the models get better, you'll be\ndoing less and less of that, less and\nless of that and more and more of the\ninitial planning and prompting and sort\nof have the trust and confidence that\nyou know the model will be able to get\nthe job done pretty much exactly how how\nyou want it to.\nI think there will always be a little\nbit of a gap in that these models will\nnever be able to read our minds.\nSo we'll we'll there there will have to\nbe a little bit of you know making sure\nthat you give it the most comprehensive\nand uh sort of like all the details of\nwhat you want from it.\nSo if you're a lazy prompter you can\nexpect a ton of friction and back and\nforth before you really get what you\nwant.\nBut I think we're we're all learning for\nourselves as we work with these things\nkind of the right way to prompt these\nthings and uh to be explicit about what\nit is that we want and kind of how they\nhallucinate the gaps that they might\nneed to fill to to get to the end result\nand how we might want to avoid something\nlike that.\nSo what's interesting about cloud code\nis there isn't really a lot of insight\ninto what the agent's doing.\nKind of gives you this like checklist of\nwhat it's doing at holistically at at a\nhigh level.\nI don't think that really would have\nworked well if the models weren't good\nenough to actually produce work that\npeople were generally happy with.\nWe're kind of there and I think the\nspace has to catch up to okay maybe\npeople don't need as much insight into\nthese sorts of things anymore and they\nthey are okay with letting an agent kind\nof get the job done and really all you\nneed to see is sort of the end result\nand tweak it a little bit before it's\nit's really perfect and I think there is\ngoing to be different tools for\ndifferent jobs.\nI think something like totally\nautonomous agent that you don't have a\nlot of insight into is great for maybe\nscaffolding new projects but for kind of\nthe serious more complex sorts of things\nwhere you know you do need a certain\nlevel of insight or you do need to kind\nof have like more engagement you might\nwant to use something that does give you\nsome more insight.\nSo I think I think these sorts of tools\ncomplement each other.\nSo, for example, writing tests or\nspinning off 10 agents to try to fix\nthe same bug, you know, might be useful\nfor a tool that doesn't require too\nmuch engagement from you.\nWhereas something that requires a little\nbit more creativity or imagination or\nextracting context from your brain,\nrequires a little bit more of a insight\ninto what the model's doing and a back\nand forth that I think Cline is a\nlittle better like visibility into what\nthe agent is doing.\nThat's like one axis and then another\nis autonomy like how how automated it is\nand we have a category of companies that\nare focusing more on the use case of\npeople that don't even want to look at\ncode which is like you know the lovables\nthe replets where it's like you go in\nyou build an app you might not even be\ntechnical and you're just happy with the\nresult and then you have kind of stuff\nthat's kind of like a hybrid where it's\nyou know for engineers it's built for\nengineers but you don't really have a\nlot of visibility into what's going on\nunder the hood.\nThis is like for like the vibe coders\nwhere they're, you know, fully, you know,\nletting letting the AI take the wheel\nand building stuff very rapidly.\nLots of open source fans and, you know,\npeople that are hobbyists enjoy coding\nin this in this manner.\nIt is really fun.\nAnd then you get to like serious\nengineering teams where they can't really\ngive everything over to the AI, at least\nnot yet.\nAnd they need to have high visibility\ninto what's going on at every step of\nthe way and make sure that they actually\nunderstand what's happening with their\ncode.\nYou're kind of handing off your\nproduction code base to this\nnondeterministic system and then hoping\nthat you catch it in review if anything\ngoes wrong.\nWhereas personally the way I use um AI,\nthe way I use Cline is I like to be\nthere every step of the way and kind of\nguide it in the right direction.\nSo I know every step of the way like as\nevery file is being edited, I approve\nevery single thing and make sure that\nthings are going in the right direction\nand I have a good understanding as\nthings are being developed where it's\ngoing.\nSo like this kind of hybrid workflow\nreally works for me personally.\nBut you know sometimes if I want to go\nfull yolo mode I go ahead and just auto\napprove everything and just step out for\na cup of coffee and then come back and\nyou know review the work.\nMy issue with this as an engineer\nmyself is that we all want to believe\nthat we work on the complex things.\nU how have you guys seen the line of\ncomplex change over time?\nI mean if we sat down having this\ndiscussion 12 months ago complex was\nlike much easier than today for the\nmodels.\nDo you feel like that's evolving\nquickly enough that like you know in 18\nmonths it's like you should probably\njust do full gentech for like 75% of\nwork 80% of work or do you feel like\nit's not moving as quickly as you\nthought?\nI think I think what was complex a\ncouple years ago is totally different to\nwhat is complex today.\nNow, I think what we need to be more\nintentional about are the architectural\ndecisions we make really early on and\nhow the model kind of builds on top of\nthat.\nIf you have kind of a clear direction\nof where things are headed and what you\nwant, you kind of have a good idea to\nabout how you might want to like lay the\nfoundation for the code base that you're\nproducing.\nAnd I think what we might have\nconsidered complex a few years ago,\nalgorithmic, you know, challenges,\nthat's pretty trivial for models today\nand stuff that we don't really\nnecessarily have to think too much about\nanymore.\nWe kind of give it, you know, a certain\nexpectation or unit test about what we\nwant and it kind of goes off and puts\ntogether the, you know, the perfect\nsolution.\nSo, I think there's a lot more thought\nthat has to go into tasteful\narchitectural decisions that really\ncomes down to you having experience with\nwhat works and what doesn't work, having\na clear idea for the direction of where\nyou want to take the project and sort\nyour vision for the codebase.\nThose are all decisions that I think is\nis is hard to rely on a model for\nbecause of its limited context and it's\nyou know its inability to kind of see\nyour vision for things and really have a\ngood understanding of of uh what you're\ntrying to accomplish without you you\nknow putting together a massive prompt\nof of you know everything that you want\nfrom it.\nI think what we were you know what we\nspent most of our time working on a\ncouple years ago has totally changed and\nand I think for the better.\nI think architectural decisions are a\nlot more fun to think about than putting\ntogether algorithms.\nIt kind of frees up the senior software\nengineers to think more architecturally.\nAnd then once they they have a really\ngood understanding of what's what the\ncurrent state of the repository is, what\nthe current state of the architecture\nis, and when they're introducing\nsomething new, they're really thinking\nat an architectural level, and they\narticulate that in Cline.\nAnd that's also there's like some skill\ninvolved there.\nUm, and some of that can be mitigated\nwith like asking follow-up questions,\nbeing proactive about clarifying things\non the agent side, but ultimately you\nneed to articulate this new\narchitecture to the agent and then the\nagent can go down and and down into the\nminds and implement everything for you\nand it is more fun working that way.\nLike personally like I I find it a lot\nmore engaging and just think on a more\narchitectural level.\nAnd for junior engineers, um, it's a\nreally good paradigm to learn about the\ncodebase.\nIt's kind of like having a senior\nengineer in your back pocket where\nyou're asking Cline like, \"Hey, can you\nexplain the re the repository for me?\nIf I wanted to implement something like\nthis, what files would I look at?\nHow does this work?\"\nIt's great for that as well.\nIf we're moving on from competition, I\nhave one last question on competition.\nYeah.\nSo, there's Twitter beef with Ruko.\nI just want to know where the backstory\nis because you tweeted yesterday.\nSomebody asked Ruko to add Gemini CLI\nsupport and then you guys responded just\ncopy it from us again and they said\nthank you.\nWe'll make sure to give credit.\nIs it a real beef?\nNo.\nA friendly beef.\nI think we're all just having fun on the\ntimeline.\nUm there's there's a lot of forks uh\nthat like 6,000 forks though.\nYeah, there's like if you search Cline\non the the VS Code marketplace, it's\nlike the entire page just like forks of\nCline and um there's like even forks of\nforks that you know came out and raised\nlike a whole bunch of money and and it's\nYeah, the top three apps the top three\napps in OpenRouter are all clinky.\nYeah.\nBillions of tokens getting sent through\nlike all these forks.\nUm there's like there's like fork wars\nand 10,000 forks and all you need is a\nknife, you know?\nSo, uh, no, it's it's exciting.\nUh, I think they're all really cool\npeople.\nWe got people in Europe forking us.\nWe got people in China making like a\nlittle fork of us.\nI think Samsung, uh, recently came out\nwith like a was a Wall Street Journal\narticle where they're using Cline, but\nthey're using like their own little fork\nof Cline that's kind of isolated, you\nknow, we we encourage it.\nDo you have any regrets about being open\nsource or\nNot at all?\nI think Cline started off as this like\nreally good foundation for what a coding\nagent looks like and people just had a\nlot of their own really interesting\nideas and spin-offs and concepts about\nyou know what they thought you know they\nthat they wanted to build on top of it\nwas and just being able to see that and\nsee the excitement around just in the\nspace in general has just been I think\ninspirational and has helped us kind of\nglean insights into what works and what\ndoesn't work and incorporate that into\nour own product and for the most part I\nthink for you know the Samsung's and all\nthe organizations where there is a lot of\nfriction and being able to use software\nlike this on their on their code bases.\nIt reduces that barrier to entry which I\nthink is like incredibly important when\nyou want to get your feet wet with this\nwhole new agentic coding paradigm that's\ngoing to completely upend the way that\nwe've written software for for decades.\nSo in the grand scheme of things, it's I\nthink it's in that positive for the\nworld and for the space and so no\nregrets in a lot of ways.\nLike you know it's us and the forks.\nWe were kind of there originally when we\nwere like the only ones with this like\nphilosophy of keeping things simple,\nkeeping things down to like the model,\nletting the model do everything, not\ncutting on not trying to make money off\nof inference, going context heavy,\nreading files into context very\naggressively.\nAnd kind of going back to cloud code, I\nwas actually like it was really nice to\nsee that they they came out and they\nvalidated our our whole philosophy of\nlike keeping things as simple as\npossible.\nAnd that kind of goes in with like the\nwhole rag thing, which is like rag was\nthis early thing in like 2022, you\nstarted getting these vector database\ncompanies.\nContext windows were very small.\nThis was like a way of people called it\nlike, oh, you can give your AI infinite\nmemory.\nIt's not really that, but that was like\nthe marketing that was sold to the\nventure backers\n\n\nthat were like investing in all these companies, and it became this narrative that really stuck around.\nAnd, like, even now, like, we get like potential, like, you know, enterprise perspective, like, they're going through, like, the procurement process, and they're, it's almost like they're going through, like, a checklist, asking, like, \"Hey, do you guys do, like, indexing, like, of the codebase and doing RAG?\"\nAnd I'm like, \"Well, why? Like, why are you, like, why do you want to do this?\"\nUm, I think Boris said it, said it very well on this exact podcast, where we tried RAG, and it doesn't really work very well, especially for coding.\nIs like the way RAG works is you have to, like, chunk all these files across your entire repository and, like, chop them up into small little pieces and then throw them into this hyperdimensional vector space and then pull out these random chunks when you're searching for relevant code snippets.\nAnd it's like, fundamentally, it's like so skitso, and like, I think it actually distracts the model, and you get worse performance than just doing what, like, a senior software engineer does when they first, they're introduced to a new repository, which, like, you look at the folder structure.\nYou look through the files.\nOh, this file imports from this other file.\nLet's go take a look at that.\nAnd you kind of agentically explore the repository.\nThat's like, we've found that works so much better.\nAnd there's like similar things where it's like, like, the simplicity always wins, like this bitter lesson, where fast apply is another example.\nSo Cursor came out with this fast apply, like, they call the instant apply back in July of 2024, where the idea was models at the time were not very good at editing files.\nAnd the way editing files works in kind of the context of an agent is you have a search block and then a replace block, where you have to, like, match the search block exactly to what you're trying to replace, and then a replace block just swaps that out.\nAnd at the time, models were not very good.\nIt was like, I forget, like, GPT, they were using under the hood at the time, wasn't very good at formulating these search blocks perfectly, and it would fail oftentimes.\nSo they came up with this clever workaround to fine-tune this fast apply model, where they let these frontier models at the time, they let them be vague.\nThey let them output those, like, lazy code snippets that we're all very familiar with, where it's like, rest of the file here, or like, rest of the imports here, and then fed that into this fine-tuned fast supply model that was, like, probably like a Quen 7B or something, quantized, very small, dinky little model, and they, they fed this lazy code snippet into this smaller model, and the smaller model, we fine-tuned to output the entire file with the code changes applied.\nAnd that, you know, the one of the founders of Ader said this really well in, like, very early GitHub discussions, where he said, like, \"Well, now, instead of worrying about one model messing things up, now you have to worry about two models messing things up.\"\nAnd what's worse is the other model that you're giving, that you're handing your production code to, this, like, fastify model, it's like, it's a tiny model, its reasoning is not very good, its maximum output tokens, you know, there might be 8,000 tokens, 16,000 tokens.\nNow they're training, like, 32,000 tokens, maybe.\nAnd a lot of the coding files, like, we have a file in our repository that's like 42,000 tokens long, and that's longer than the maximum token output length of one of these smaller fast supply models.\nSo what do you do then?\nThen you have to build workarounds around that.\nThen you have to build all this infrastructure to, like, pass things off, and then it's making mistakes.\nIt's like very subtle mistakes, too, where it's like, it looks like it's working, but it's not actually what the original frontier model suggested, and it's like slightly different, and it introduces, like, all these subtle bugs into your code.\nAnd what we're starting to see is, like, as AI gets better, the application layer is reducing.\nYou're not going to need all these clever workarounds.\nYou're not going to have to maintain these systems.\nSo it's really liberating to not be bogged down with RAG or with fast apply and just focus on this, like, core agentic loop and and maximizing diff edit failures.\nLike, in our own internal benchmarks, CLA 4 recently hit a sub 5% or like around, actually, 4% diff edit failure rate.\nAt the, like, when fast supply came out, that was way higher, that was like in the 20s and the 30s.\nNow we're down to 4%, right?\nAnd in 6 months, how does it go to zero?\nWell, it's going to zero, like, as we speak.\nIt's going to zero every day, you know.\nAnd I was actually talking with, uh, the founders of some of these companies that do fast supply.\nThey were trying to kind of work with us.\nThey, their whole bread and butter is, uh, fine-tuning these fast supply models, and you know, like, Relay and Morph, and I had like a very candid conversation with these guys, where I was like, \"Well, there's a window of time where fast supply was relevant.\nCursor started this window of time back in July.\nHow much time do you think we have left until they're no longer relevant?\nDo you think it's an infinite time window?\"\nThey're like, \"No, it's definitely finite.\nLike, this, this era of fast apply models is definitely coming to an end.\"\nAnd I was like, \"Well, how long do you guys think?\"\nThey were like, \"Maybe 3 months, maybe less.\"\nSo, I still think there's some cases where RAG is useful.\nYou know, if you have a lot of human readable documents, a large knowledge base of documents where you don't really care about, like, inherent logic within them, like, sure, index it, chunk it, do retrieval on it.\nOr fast applies, like, maybe if your organization, you're forced into using, like, a very small model that's not very good at search and replace, like a Deepseek or something, you know, maybe use a fast apply model.\nI think RAG and fast supply were these just tools in a toolkit for when models weren't the greatest at large context or search and replace diff editing.\nUm, but now they are extra ingredients that could make things go wrong that you just don't need anymore.\nThere was an interesting article from Cognition Labs about, you know, multi-agent orchestration and getting right into it.\nIt's like, you're, you're on autopilot for us, right?\nThat's cool.\nYeah.\nSo I mean, it's a great article, by the way.\nYeah, it was a great article.\nThey, they talked about how, you know, when you start working with different models, different agents, there's a lot that gets lost in the details, and you know, the devil in the details, that's those are the most important things, and making sure that it doesn't, you don't have the agent sort of, like, running in loops and running to the same issues again and and it have sort of, like, all the the right context.\nAnd and so I think being close to the model, throwing all the context you need at it, not taking these costs optimized approach to pulling in relevant context, something RAG or a cheaper model to apply edits to a file.\nI think ultimately, yes, it's more expensive asking, you know, a model like Claude Sonnet to do sort of all these sorts of things to GP an entire codebase and to, you know, fill up its entire context.\nBut you kind of get what you pay for.\nAnd that, I think that's been another benefit of of being open source is that our developers, they can peek under the kimono.\nThey can see, you know, where their requests are being sent, what prompts are going into these things.\nAnd that creates a certain level of trust, where you know, when they spend 10, 20, $100 a day, they know kind of where their data is being sent, when model is being sent to, what prompts are going into these things, and so they get comfortable with the idea of spending that much money, get the job done.\nYeah.\nIt's like not making money off of inference.\nI think the the incentives are so, they're so relevant in this discussion because, you know, if you're incentivized to, you know, if you're charging, you know, $20 per month and you're trying to make money on that, you're going to be offloading all kinds of important work to smaller models or optimizing for cost with RAG, like, retrieval with RAG, not reading the entire file, but maybe reading like a small snippet of it.\nWhereas if you're not making money off inference and you're just going direct, you know, uh, users can bring their own API keys, well, then all of a sudden, you're, you're not incentivized to cut down on cost.\nYou're actually incentivized just to build the best possible agent.\nAnd we're, we're starting to see this trend of the whole industry is moving in that direction, right?\nYou're starting to see, like, um, everyone open up to pay as you go models or pay directly for inference, and I think that is the future.\nWhat's the client pricing business model?\nRight now, it's bring an API key.\nEssentially, just, uh, whatever pre-commitment you might have to whatever inference provider, whatever model you think works best for your type of work, you just plug in your Anthropic or OpenAI or OpenRouter, whatever it is, API key into client, and it connects directly to whatever model you select.\nAnd I think that level of transparency, that level of, \"We're building the best product.\nWe're not focused on sort of capturing margin on, you know, the price opuscation and clever tricks and model orchestration to, you know, keep cost low for us and optimize for higher profits.\"\nI think that's put us in this, like, unique position to really push these models to their full potential.\nAnd, uh, and I, I think that's shown, you know, I think that's, that's you get what you pay for.\nThrow a task in client, and and it gets expensive, but um, that's the cost of intelligence, right?\nIt's the cost of intelligence.\nYeah.\nSo yeah, the business model right now is is, uh, you, you get to choose kind of where it's open source.\nYou can fork it.\nYou can choose where your data gets.\nYou can choose who you want to pay.\nA lot of organizations we've talked to get some, you know, a certain level of volume based discounts with with these providers.\nInstagram, they can, they can take advantage of that through client, which is helpful because client can get pretty expensive.\nAnd, uh, yeah, wait, so I mean, I'm, I'm still not hearing how you make money.\nLike you said, you don't.\nHuh?\nWhy?\nWhy make money?\nYeah.\nUh, cuz you have to pay your salaries.\nWell, that, that's the, that's the.\nA lot of people ask us that, and I always just throw the why at them.\nBut it's um, you sound like the Party Fool, guys.\nParty Fool's like.\nThe real answer is enterprise.\nSo, um, which, uh, we can say because you're, you know, we released this when you launch it.\nYeah.\nYeah.\nSo you want to talk about enterprise?\nYeah.\nI think being open source, marine API key has given us a lot of easy adoption in these organizations where things like data privacy and control and security are top of mind, and it's hard to commit to sending their code in plain text to god knows what servers, training their data to do training their data on models that might, you know, output their IP to random users.\nI think there people are a lot more conscious about where their data is getting, getting sent and what's being used to it.\nAnd so it's given us this opportunity to say, okay, nothing passes through our own servers.\nYou have total control over the entire application where your data gets sent.\nAnd that's given organizations that, you know, we've been talking to over the course of the last couple of months this sort of, like, easy adoption.\nAnd I think this opportunity for us to to work more closely with them and say, you know, what are all the things that we can do to help with adoption in the rest of your organization?\nEssentially, how can we pour gasoline on sort of the evangelism that, you know, people have for client in these organizations and spread the usage of of agent coding, I think at an enterprise level.\nWell, yeah.\nWhat's, what's crazy is, um, so we, we had, we open sourced client.\nPeople really liked it.\nDevelopers were using it within their organizations.\nTheir organizations were kind of like reluctantly okay with it because they saw, like, we're open source and we're not sending our their data anywhere.\nThey could use their existing API keys.\nAnd then we launched, like, on our website, like, a contact form for enterprise, like, if you're interested in an enterprise offering, hit us up.\nAnd we had no real enterprise product at the time.\nAnd it turned out, like, we just got this massive influx of big enterprises reaching out to us.\nAnd you know, we had a fortune five company come up to us, and they were like, \"Hey, um, we have hundreds of engineers using client within our organization, and this is a massive problem for us.\nThis is like a fire that we need to put out because we have no idea what API keys they're using, how much they're spending, where they're sending their data.\nPlease just, like, let us give you money to make an enterprise product.\"\nSo the product kind of just evolved out of that.\nRight.\nRight.\nRight.\nI mean, it's it really just comes down to more of listening to our users.\nSo right after we put out this page, we just had a lot of demand for sort of, like, the table stake enterprise features, the security, uh, guard rails and governance and insights that sort of, like, the admins in these organizations need to to reliably use something like Klein.\nYeah, we've gotten a lot of people wanting us to sort of give them two things.\nInvoices just to help with, like, all the budgeting and spending, the, you know, thousands of dollars, all the Europeans.\nYeah.\nJust the other thing, which I thought was a little bit surprising, was some level of insight into the benefit that clients providing them.\nSo it could be our sage or lines of code written because it allows these sort of, like, AI forward drivers for adopting these sorts of tools in these organizations to take that as a proof point and go to the rest of their teams and say, \"This is how much clients helping me.\nYou need to start adopting this so we can keep up with the rest of the industry.\"\nThis for, like, internal champions to prove their ROI.\nExactly.\nOkay.\nUse as sort of evidence for this, you know, to justify the spend.\nYeah.\nBut also to promote the product in these organizations.\nWe can do this afterwards, but we like to talk to those and actually feature some of them what they're saying to their bosses, uh, on the podcast so that we can get a sense, cuz, like, often times we hear, we only talk to founders and builders of, like, the dev tool, but, like, not the end consumer, and actually we want to hear from them, right?\nLike, about how they're thinking about it, what they need.\nKind of, kind of cool.\nOne thing I wanted to ask, uh, to double click on is the relationship between OpenRouter and then, like, your, your enterprise offering, right?\nSo, uh, my understanding is currently everything runs through OpenRouter.\nNot everything.\nSo you can bring API keys to OpenAI, Anthropic, Bedrock, and then you have a direct connection there if.\n\n\nIf I, the user, has a direct connection there, but uh, everything else would run through OpenRouter. So, basically, the enterprise version of client would be, you have your own OpenRouter that you would provide visibility and control to uh, that enterprise. Uh, yeah, kind of like that's for like the self-hosted option, right? Like there's a lot of enterprises where they're okay with not self-hosting, but as long as they're using their own bedrock API keys and stuff like that, whereas the ones that are really interested in like self-hosting or like that want to be able to manage their teams, there would be like this internal router going on.\n\nThe curious thing here is like what if, what if model costs just go to zero? Like Gemini code just comes out and it's like, \"Yeah, guys, it's free.\" Well, yeah. No, they came up with. Yeah, it'd be great for us. So, our thesis is inference is not the business. You would just never make money on inference, right? Yeah. We want to give the end user total transparency into price, into which I think is like incredibly important to, you know, even get comfortable with the idea of spending as much money as you do. I think the price obfuscation in this space has given developers this reluctance to opt into usage-based plans, and we're seeing a lot of people kind of converge on this concept of, \"Okay, maybe have like a base plan just to use the product, but sort of get out of the way of the inference and um, respect the end developer enough to give them the level of insight into not just the cost, but the models being used and uh, give them more confidence in spending however much it takes to get the work done.\" I think there, you know, there, you know, you can use tricks like RAG and fast supply and things like that to keep costs low, but for the most part, there's enough ROI on coding agents where, you know, people are willing to spend money to get the job done. And for a truly good coding agent, the ROI is almost hard to even calculate because there's so many things that I would have never even bothered doing, but then I now have Client and I could just like do this weird experiment or do this side project or, you know, fix this random bug that I would have never even thought about. So, like how do you measure that? Yeah. Right.\n\nOne variant of this problem, we're about to move on to context engineering and memory and all the other stuff. One variant of this I wanted to touch on a little bit was just uh, background agents and multi-agents. So, the instantiations of this now, I would say, are background agents. Is it would be CodeEx, for example, like spinning up, you know, one PR per minute, or Devon, or cognition. So, would you ever go there? That's one concrete question I can ask you, like, would there be Cline on the server, whatever? And then the other version is still on the laptop, but more sort of parallel agents, like kind of the the Kanban is is currently very hyped right now. People are making like Kanban interfaces is for Cursor and also for uh, cloud code, just anything like in the parallel or background side of things.\n\nSo, we're releasing a CLI version of Client, and using the CLI version of Client, it's fully modular, so you can ask Client to run the CLI to spin up more clients, or you could run Client in some kind of cloud process in a GitHub action, whatever you want. So, the CLI is really the form factor for okay, these kind of fully autonomous agents, and it's also nice to be able to tap into an existing Client CLI running on your computer and be able to like take over and steer it in the right direction. So, that's also possible. Um, but what do you think, Saoud?\n\nI don't think it's an either/or. I think all these different modalities complement each other really well. So, the codecs, the Devons, Cursor, background agent, I think they all sort of accomplish the same thing. They, if we were to come out with our own version of it, I'd say that it would be a foundation for how other developers could build on top of it. So, Nick's older brother, Andre, he's sort of thinking 10 years ahead, and it always kind of blows my mind a little bit about some of some of the ideas that he has about where the space is going, but we recently had a discussion about building this open-source framework for coding agents for any sort of platform. Building the SDK and the tool necessary to bring Client to, you know, Chrome as an extension, to the CLI, to JetBrains, to Jupyter notebooks, to your smart car, whatever it is, but to build your fridge, your fridge exactly, to put to microwave maybe. Yeah. Exactly. I mean, this is what we saw kind of like with sort of, you know, the 6,000 forks, you know, on top of Client is we sort of like put together this foundation for how this community of developers, we sort of put together this foundation that this community developers could like build on top of and sort of take advantage of, you know, their experiments and imagination and their creativity about where the space is headed. And I think looking forward, building an open-source foundation and the building blocks for how we bring something like Client to things that go outside the scope of software development or, or, you know, VS Code extension. I think that'll open up the door to things that, you know, ultimately complement each other really well, but it'll never be sort of this like either/or thing. I think background agents are good for certain kinds of work, and parallel Kanban multi-agents might be good for when you want to experiment and iterate on, you know, five different versions of, you know, how a landing page might look, and then something like a back and forth with a single agent like Client works really well for when you want to, you know, pull context and put together a really complicated plan for a really complex task, and I think all these different tools will ultimately end up complementing each other, and people will kind of develop a taste and an understanding for what works best for what kind of work, but I, I think something just looking 10 years ahead. We at the very least want to sort of be at the frontier of providing sort of the building blocks for what the next thing is after background agents or um, you know, multi-agents.\n\nI was going to go into context engineering, kind of like topic duour. I think that uh, this is kind of similarish in a thread to RAG and how RAG is a mind virus, which I love, by the way, that the way that you phrased it. Yeah, you, you have, you have in your docs context management. You also have a section on memory bank, which is kind of cool. I think uh, a lot of people are trying to figure out memory. Let's just start at the high level, and then we'll go into memory later. Uh, what, you know, what does context engineering mean to you?\n\nContext engineering mean to me means prompt engineering. Yeah. Right. Like, I mean, so I think like there is a lot of art to like what goes in there. Yeah, I think that really is like the 80/20 of building a really good agent is like figuring out what goes into the context and and like, you know, I think interplay between MCP and your system Client, like, you know, recommended prompts, I think is what's is ultimately making a good agent.\n\nYeah, I, I think context management is like one part of it is what you load into context. The other part of it is how do you clean things up when you're reaching the context window, right? Uh, how do you curate that whole life cycle from zero to maximum uh, context window? And the way that I think about it is there's so many options on the table, and there's so many risks to misdirecting the agent or distracting the agent. There's ideas about, you know, RAG or other kinds of forms of retrieval. That's that's one idea. There's the agentic exploration. That's another idea that we found works much better. And it seems like the trend is generally for loading things into context. It's giving the model the tools that it can use to pull things into context, letting the model decide what exactly to pull into context, as well as some hints along the way, kind of like a like a map of what's going on. Um, like as uh, abstract syntax trees, potentially what tabs they have open in VS Code. That was actually in our internal kind of benchmarking that turned out to work very, very well. It's almost like it's reading your mind when you have like a few tabs open.\n\nMe out because like sometimes then I'm like, I have like unrelated tabs open and I have to go close them before I take off the thing.\n\nI, I wouldn't think too much about, especially when you're using Client. Client does a pretty good job of just navigating that. Um, but I, I definitely there are edge cases, right? There's edge cases for everything. And it's kind of like, okay, what's like the majority use cases, like, you know, when are you starting a brand new task and you don't have a single tab open that's relevant to it? Obviously, in the CLI, you might, you don't have that little indicator. So, there you have to think outside the box for that. So, that's like for reading things into context. And then for context management is when you're approaching the full capacity of the context window is how do you condense that? And we've played around with this kind of naive truncation very early on where we just like throw out the first half of the conversation.\n\nThat's common.\n\nAnd it there is problems with that, obviously, because it's like kind of like you're halfway through a book and you, you're like, you start reading halfway through, right? You don't know anything that happened beforehand. And we like to think a lot about like narrative integrity is like every task in Client is kind of like a story. It might be a boring story where it's like this lonely coding agent that's just, you know, determined to help you solve, you know, whatever it is, like the ch, like the the big thing that the protagonist needs to overcome is like the resolution of the task, right? But how do we maintain that narrative integrity where every step of the way the agent can kind of predict the next token, which is like predict the next part of the story to reach that conclusion? So, we played around with things like cleaning up uh, duplicate file reads that works pretty well. But ultimately, this is another case where it's like, well, what if you just give the model, like, what if you just ask the model, \"Hey, like, what do you think belongs in context?\" Another form of this is summarization, which is like, \"Hey, summarize all the relevant details, and then we'll swap that in.\" That works really, really well.\n\nYeah. Uh, double-clicking on the a mentioned that's very verbose. When do you use that?\n\nRight now, it's a tool. The way that it works is when Client wants, when Client's doing sort of the agentic exploration of trying to pull in relevant context, and it wants to sort of get an idea of what's going on in a certain directory. For example, there's a tool that lets it pull in all the sort of language from a directory. So, it could be the names of classes, the names of functions, and that gives it some idea of, \"Okay, here's what's going on in this in this folder.\" And if it's if it seems relevant to whatever the task is trying to accomplish is, then it sort of like zooms in and starts to actually read those entire files into context. So, it's it's essentially a way to help it kind of figure out how to navigate through large code bases. Yeah, we, we've seen some companies working on it's like an interesting idea. It's like an A, but it's also a knowledge graph, and you can run these discrete deterministic almost like actions on this knowledge graph where you could say like, \"Hey, find me all the functions that find me all the functions in the codebase and find me all the functions that aren't being used and delete all of them,\" and the agent can kind of reason in this almost like SQL-like language working with this knowledge graph to do these kinds of global operations. Like right now, if you ask a coding agent to go through and remove all unused functions or do like some kind of large refactoring work, in some cases, it might work, but very often times it's just going to struggle a lot, burn a lot of tokens, and fail ultimately. Whereas with these kinds of tools, it can actually operate on the entire repository with these kinds of query-like short little query statements. I think there is a lot of potential in something like this where it's like the next level beyond the A, and it's like a language for querying this this kind of knowledge graph, but like we've seen with with like the cloud 4 release is these frontier model shops, they tend to train on their own application layer, and you might come up with like a very clever tool that in theory would work work really well, but then it doesn't work well with cloud 4 because cloud 4 is trained to Gret.\n\nRight. So that's another interesting phenomenon where it's like you're you're expecting these uh, frontier models to become more generalized over time, but instead they're becoming more specialized, and you have to like support these different model families. Just to wrap on the memory side, memory is almost the artifact of summarization. So, you summarize the context and then you kind of extract some sides. Any interesting learnings from there, like things that are maybe not as intuitive, especially for code? I think people grasp the like memory about humans, but like what are memories about code bases and things look like? I think memories right now for the large part are mostly useless. I think the kinds of the kinds of memories that you might want the coding agent to hold on to are, you know, specific quirks about how, you know, your team works in the project or certain rules, like only use like camel case, for example. It's better to place those sorts of things in like a general sort of like guideline or rules file, for example. But I, I found that this idea of like asking the agent, at least coding agents, to like hold on to certain memories about the project or like how you work or or things like that are or you mostly have to like force it to store those things into memory and and uh, and I don't think people, they don't want to have to think about those sorts of things. So, it's something we're we're thinking about is is how can we hold on to the tribal knowledge that these agents learn along the way that people aren't documenting or putting into rules files without the user having to go out of their way to sort of force them to store these things into a memory database, for example.\n\nThose are like kind of like workspace rules or tribal knowledge, like general patterns that you use as a team. Um, but then there's like in our, we ran this like internal experiment where we built this to-do list tool where it was only one tool where you could just write the to-do, and every time you could like rewrite the to-do from scratch, and we would passively as part of every like, not every message, but like every once in a while, we would pass in this context of what the latest state of this to-do list is. And we found that that actually keeps the agent on track after multiple rounds of context summarization and compaction, and it could all of a sudden build like an entire complex kind of task from scratch over, you know, 10x the to the the context window length.\n\n\nAnd in internal testing, this was like very, very promising.\nSo, we're trying to flesh that out.\nAnd I think something like that.\nWe, we had earlier versions of the memory bank, which actually, um, our like Nick, uh, Nick Bowman, our our marketing guy, came up with this memory bank concept where it was like this client rules where you would tell a client like, \"Hey, whenever you're working, have the scratch pad of what you're working on.\"\nAnd this is like a more built-in way of doing that.\nAnd I think that also might be very, very, very helpful for the agents to just have like a little scratch pad of like, hey, what have I done so far?\nWhat's left?\nSpecific app file mentions, like what kind of code we're working on, general context, and passing that off between sessions?\nYeah.\nAny thought on cloud MD versus agents MD versus agent MD?\nI built an open source tool called agents 927 like the XKCD that just copy pastes it across all the different file names so all of them have access to it.\nDo you think there should be a single file like there's also like the IDE rules versus the agent rules?\nThere's kind of like a lot of issues.\nI actually think it's fine that each of these different tools have their own specific instructions because I find myself using a cursor rules and a client rules separately when I want the agent to, I want him to work, you know, a certain way that's different than how I might want, you know, cursor to interact with my codebase.\nSo I think each tool is specific to the kind of work that I do, and I have different instructions for how I want these things to operate.\nSo, I think I've seen like a lot of people complain about it, and I get that it could make code bases look a little bit ugly, but for me, it's been like incredibly helpful for them to be separated.\nI noticed that you said him.\nDoes Klein have actor?\nYeah.\nOkay.\nDoes he have a whole backstory?\nYeah.\nPersonality.\nKlein.\nSo, Klein is a play on CLI and editor cuz he used to be Claude Dev and now it's Klein.\nYeah.\nI feel like Klein kind of stands out in the space for having, for being a little bit more humanized than something like, you know, a cursor agent or a co-pilot or a cascade.\nUh, and I think there's Devon, which is a real name, you know.\nWell, Claude is a real name, I guess.\nYeah.\nYes.\nI've been, I've been, I think we've all been intentional about just sort of humanizing it because it at least in working with kind of gives you more confidence in it and that I could like lean on it a little bit more.\nThere is, there is kind of a of a trust building with, I think, with an agent, and the humanizing aspect of it, I think, has been helpful to me personally, and this goes back to like the narrative integrity is just it's actually really important, I think, to anthropomorphize agents in general, u because everything they do is like a little story, and without having a distinct kind of identity, you get worse results, and when you're developing these agents, that's kind of how we need to think about them, right?\nWe need to think that we're like crafting these stories.\nWe're almost like Hollywood directors, right?\nWe're we're putting all the right pieces in place for the story to unfold.\nAnd yeah, having an identity around that is really, really important.\nAnd Klein, you know, he's a cool little guy.\nHe's, you know, he's just a chill guy.\nHe's chill guy.\nHe's helping us out, you know, he's always like happy to help, or if he's told to not be happy, he can be very grumpy, you know.\nSo, that's great.\nAwesome.\nUh, I know you're hiring.\nYou are, you have, you're 20 people now.\nYou are aiming to 100.\nYou have a beautiful new office.\nWhat's your best pitch for working at Klein?\nA lot of our hiring right now is, um, so far it's been just friends of friends, people in our network, people that we've worked with before that we, we've trusted and that we know can can show up for like this incredibly hard thing that we're we're working on.\nAnd there's a lot of challenges ahead, and and I think the problem space is probably the most exciting thing to be working on right now.\nEngineers in general love working on things that make their own lives easier.\nAnd so I couldn't imagine working on something more exciting than than a coding agent.\nAnd and that's, you know, that's a little bit biased, but I think a large part of it is it's it's an exciting problem space.\nUm, we're looking for really motivated people that want to work on challenges like figuring out kind of like what the next 10 years looks like and building kind of the foundation for, you know, what comes next after background agents or multi-aents and and really help in sort of defining how all this shapes up.\nWe have this like really excited community of of users and developers.\nI think being open source has also created a lot of goodwill with us where a lot of the feedback we get is like incredibly constructive and helpful in shaping our road map and and the product that we're building and working with a community like that is like one of the most fulfilling things ever.\nRight now we're we're kind of uh um in between offices, but you know, doing things like go-karting and kayaking and things like that.\nSo it's it's a lot of hard work, but you know, we we make sure to to have fun along the way.\nSo yeah.\nNo, like Klein is a, it's a unique company because it it really does feel like we're all just like friends building something cool, and we work really, really hard, and the space is it's not just competitive, it's like hyper competitive.\nThere's like capital is flowing into all every single possible competitors.\nWe have forks of forks like I said raising tens of millions of dollars, and we're growing very rapidly.\nWe're at 20 people now.\nWe're aiming to be at 100 people by the end of the year.\nAnd being open source, it has its own challenges.\nIt's like people, we do all this research, we do all this benchmarking work to make sure our diff editing algorithm is robust the way we're working with these models to optimize for the lowest possible diffedit failures.\nAnd then we open source that.\nAnd then we post it on Twitter, and someone's like, \"Oh, thanks so much for open sourcing that.\nI'm going to go and like raise a bunch of money with like our own product with it.\"\nBut the way that I see it is like this is, you know, let them copy.\nWe're the leaders in the space.\nWe're we're kind of showing the way for the entire industry, and being an engineer and and building all this stuff is super exciting.\nSo, working with all these people is just amazing.\nOkay, awesome.\nThank you guys for coming on.\nYeah.\nAll right.\nSo much, so much fun.\n",
  "dumpedAt": "2025-07-21T18:43:25.937Z"
}