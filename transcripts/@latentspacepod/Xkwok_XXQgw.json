{
  "episodeId": "Xkwok_XXQgw",
  "channelSlug": "@latentspacepod",
  "title": "⚡️Open Questions in Agentic RL — Will Brown (Prime Intellect)",
  "publishedAt": "2025-05-09T19:56:56.000Z",
  "rawLines": [
    {
      "lang": "en",
      "text": "Yeah. Okay. Um, today I'm going to be",
      "offset": 0.24,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "talking to you all a little bit about uh",
      "offset": 3.439,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "the frontier directions that we're all",
      "offset": 5.52,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "thinking about in terms of open source",
      "offset": 7.759,
      "duration": 6.481
    },
    {
      "lang": "en",
      "text": "agent RL um and what basically sketching",
      "offset": 9.92,
      "duration": 6.24
    },
    {
      "lang": "en",
      "text": "what the road map might be towards",
      "offset": 14.24,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "training something that looks like an 03",
      "offset": 16.16,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "model. What does it take to get",
      "offset": 18.56,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "something that is like a very good",
      "offset": 20.32,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "general purpose agent for doing long",
      "offset": 22.16,
      "duration": 6.32
    },
    {
      "lang": "en",
      "text": "horizon tasks? Um, and we want a thing",
      "offset": 24.8,
      "duration": 6.08
    },
    {
      "lang": "en",
      "text": "that can go off and browse the web and",
      "offset": 28.48,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "write code and look at images and do all",
      "offset": 30.88,
      "duration": 5.359
    },
    {
      "lang": "en",
      "text": "this stuff in service of solving",
      "offset": 33.2,
      "duration": 5.519
    },
    {
      "lang": "en",
      "text": "increasingly important problems. Um, and",
      "offset": 36.239,
      "duration": 3.761
    },
    {
      "lang": "en",
      "text": "so like we know it's doable because",
      "offset": 38.719,
      "duration": 3.041
    },
    {
      "lang": "en",
      "text": "OpenAI has done it. Other people have",
      "offset": 40,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "done things like this, but there really",
      "offset": 41.76,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "isn't currently an open source model",
      "offset": 43.2,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "that behaves in the way that these",
      "offset": 45.44,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "models do. We have things like R1 which",
      "offset": 47.36,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "are great at kind of the single turn",
      "offset": 49.76,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "math and code reasoning problems but",
      "offset": 51.44,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "they are not in the general purpose",
      "offset": 53.44,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "agents world yet. And so I think there's",
      "offset": 55.44,
      "duration": 5.599
    },
    {
      "lang": "en",
      "text": "a lot of things we need to solve along",
      "offset": 58.8,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "the way but I think these problems are",
      "offset": 61.039,
      "duration": 2.961
    },
    {
      "lang": "en",
      "text": "things that are solvable and that we",
      "offset": 62.64,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "also kind of like have a sketch of how",
      "offset": 64,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "to do it. And so I'm going to in this",
      "offset": 66.64,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "talk be mapping out like what are these",
      "offset": 68.32,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "questions? what are the roadblocks and",
      "offset": 70,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "what are like the plausible uh things",
      "offset": 72.32,
      "duration": 4.76
    },
    {
      "lang": "en",
      "text": "that can do that will actually unlock",
      "offset": 74.96,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "this and so what we want is models that",
      "offset": 77.08,
      "duration": 5.64
    },
    {
      "lang": "en",
      "text": "can go off and do stuff um and for LM",
      "offset": 80.08,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "doing stuff it seems like uh is best",
      "offset": 82.72,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "done with some kind of tool so this is",
      "offset": 85.28,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "one of the reason like everyone crazy",
      "offset": 87.28,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "about MCP it's like a standardized way",
      "offset": 88.56,
      "duration": 4.879
    },
    {
      "lang": "en",
      "text": "to like give LLM's tools but that's",
      "offset": 91.119,
      "duration": 3.761
    },
    {
      "lang": "en",
      "text": "really what it is you want models that",
      "offset": 93.439,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "are really good at doing multi-turn tool",
      "offset": 94.88,
      "duration": 4.559
    },
    {
      "lang": "en",
      "text": "use um that's kind of the other three",
      "offset": 97.52,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "magic is lots and lots and lots of",
      "offset": 99.439,
      "duration": 4.961
    },
    {
      "lang": "en",
      "text": "multi-turn tool use with multimodal in",
      "offset": 101.6,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "input in very general settings beyond",
      "offset": 104.4,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "just code. Um, and whether or not you",
      "offset": 107.2,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "want to call this like 10 minute AGI, I",
      "offset": 109.92,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "kind of like the phrase 10-minute AGI",
      "offset": 112,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "for just like how to think about 03. Um,",
      "offset": 113.84,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "is that anything that you can do as a",
      "offset": 116.159,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "human in 10 minutes, 03 is usually going",
      "offset": 117.92,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "to be the new reason. Um and that if you",
      "offset": 120,
      "duration": 5.92
    },
    {
      "lang": "en",
      "text": "can crack that uh scaling direction of",
      "offset": 123.68,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "like pushing the boundary of how long",
      "offset": 125.92,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "these models can go out and do these",
      "offset": 127.92,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "things for that is a plausible path",
      "offset": 129.44,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "towards things that become more. Um and",
      "offset": 132.08,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "so 03 you can like give it our problem",
      "offset": 135.44,
      "duration": 4.879
    },
    {
      "lang": "en",
      "text": "and it like does a pretty good job after",
      "offset": 137.44,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "15 minutes of making it like sketching",
      "offset": 140.319,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "out a pretty good version of a solution.",
      "offset": 141.92,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "And so with the table stakes version of",
      "offset": 144.48,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "this um which is kind of the area that",
      "offset": 146.16,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "I've been doing some open source work in",
      "offset": 148.16,
      "duration": 3.439
    },
    {
      "lang": "en",
      "text": "is multi-turn R. So like rather than",
      "offset": 149.52,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "just like you train the model to like",
      "offset": 151.599,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "guess the right answer, you train the",
      "offset": 153.28,
      "duration": 3.679
    },
    {
      "lang": "en",
      "text": "model with tools in the loop to be able",
      "offset": 154.879,
      "duration": 4.881
    },
    {
      "lang": "en",
      "text": "to use these tools in service of solving",
      "offset": 156.959,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "some problem and then you give it",
      "offset": 159.76,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "rewards based on the final uh output of",
      "offset": 161.28,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "this model after the sequence of tool",
      "offset": 164.16,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "calls. Um and so we've kind of moved",
      "offset": 165.68,
      "duration": 6.32
    },
    {
      "lang": "en",
      "text": "beyond the single turn RL world of like",
      "offset": 168.72,
      "duration": 6.96
    },
    {
      "lang": "en",
      "text": "TBT jackp as well as the single turn",
      "offset": 172,
      "duration": 6.959
    },
    {
      "lang": "en",
      "text": "RLVR world of models like 01 and R1. And",
      "offset": 175.68,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "we want to like have these things become",
      "offset": 178.959,
      "duration": 3.441
    },
    {
      "lang": "en",
      "text": "more agendic and it seems like the path",
      "offset": 180.4,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "is to incorporate reinforcement learning",
      "offset": 182.4,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "into this process. Um some of the",
      "offset": 184.239,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "challenges are like the versions of",
      "offset": 186.64,
      "duration": 3.519
    },
    {
      "lang": "en",
      "text": "these models that are quite good can do",
      "offset": 188.319,
      "duration": 3.361
    },
    {
      "lang": "en",
      "text": "like many many tool calls like deep",
      "offset": 190.159,
      "duration": 4.36
    },
    {
      "lang": "en",
      "text": "research can do like a 100 tool calls.",
      "offset": 191.68,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "Um, you probably want some kind of",
      "offset": 194.519,
      "duration": 4.36
    },
    {
      "lang": "en",
      "text": "intermediate verification where you're",
      "offset": 197.2,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "not just waiting for the final answer at",
      "offset": 198.879,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "the end, but you want something like",
      "offset": 201.04,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "turn level reward potentially where you",
      "offset": 203.04,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "want to be able to ensure that the model",
      "offset": 205.44,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "is getting credit for the the moves it",
      "offset": 207.76,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "makes along the way because it's no",
      "offset": 210.56,
      "duration": 2.72
    },
    {
      "lang": "en",
      "text": "longer just like one thing it's doing.",
      "offset": 211.76,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "It's doing 100 things and the credit",
      "offset": 213.28,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "assignment problem becomes very tricky",
      "offset": 215.28,
      "duration": 5.039
    },
    {
      "lang": "en",
      "text": "as you scale the the length of these uh",
      "offset": 217.599,
      "duration": 4.881
    },
    {
      "lang": "en",
      "text": "tasks. Um, you might want to do this",
      "offset": 220.319,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "thing these for things outside of math",
      "offset": 222.48,
      "duration": 3.759
    },
    {
      "lang": "en",
      "text": "and code where verifying whether an",
      "offset": 224.239,
      "duration": 3.121
    },
    {
      "lang": "en",
      "text": "answer is right or wrong is not",
      "offset": 226.239,
      "duration": 3.441
    },
    {
      "lang": "en",
      "text": "necessarily straightforward. Um, you",
      "offset": 227.36,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "want to avoid like blowing up your",
      "offset": 229.68,
      "duration": 3.119
    },
    {
      "lang": "en",
      "text": "context length. Like if you have a model",
      "offset": 231.44,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "like reading websites and if you put all",
      "offset": 232.799,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "the website in context and the model is",
      "offset": 235.519,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "like doing this in RL this like blows up",
      "offset": 237.439,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "your context limit really quickly if you",
      "offset": 239.519,
      "duration": 3.041
    },
    {
      "lang": "en",
      "text": "have it reading lots and lots of",
      "offset": 241.439,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "websites. Um, you want infrastructure",
      "offset": 242.56,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "for managing the resources of these",
      "offset": 244.799,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "rollouts. uh in terms of comput",
      "offset": 247.04,
      "duration": 2.8
    },
    {
      "lang": "en",
      "text": "environments like if you're having",
      "offset": 248.799,
      "duration": 3.121
    },
    {
      "lang": "en",
      "text": "models that are like doing data science,",
      "offset": 249.84,
      "duration": 3.759
    },
    {
      "lang": "en",
      "text": "you want them to be able to like do data",
      "offset": 251.92,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "science quickly as part of this training",
      "offset": 253.599,
      "duration": 6.001
    },
    {
      "lang": "en",
      "text": "process. Um and you also ideally want to",
      "offset": 255.28,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "whether you're doing this centralized or",
      "offset": 259.6,
      "duration": 2.96
    },
    {
      "lang": "en",
      "text": "decentralized move in the direction of",
      "offset": 260.88,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "like everything being async and",
      "offset": 262.56,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "overlapped. um because that is like",
      "offset": 264.56,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "otherwise you have these uh inefficiency",
      "offset": 266.479,
      "duration": 4.481
    },
    {
      "lang": "en",
      "text": "bubbles that like pop up all over your",
      "offset": 269.04,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "uh compute structure structure and you",
      "offset": 270.96,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "ideally want to be able to like hide all",
      "offset": 273.52,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "of that by having everything going with",
      "offset": 275.6,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "some lag in parallel. Um and so that's",
      "offset": 278.32,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "kind of what uh the the path forward",
      "offset": 281.36,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "seems to look like. Um and so this is",
      "offset": 284.08,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "just a little sketch of some work",
      "offset": 286,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "recently about kind of like working",
      "offset": 288.16,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "towards this where you kind of can do",
      "offset": 289.6,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "multi-turn RL by incorporating tool",
      "offset": 291.84,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "calls into the loop. Um there's been a",
      "offset": 294.16,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "big sequence of papers of people doing",
      "offset": 296.88,
      "duration": 3.599
    },
    {
      "lang": "en",
      "text": "like mini replications of like coding",
      "offset": 298.32,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "agents and search agents and uh people",
      "offset": 300.479,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "are kind of in the public sphere",
      "offset": 303.36,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "documenting a lot of their learnings of",
      "offset": 305.199,
      "duration": 3.121
    },
    {
      "lang": "en",
      "text": "this process and I think there's a lot",
      "offset": 306.72,
      "duration": 2.96
    },
    {
      "lang": "en",
      "text": "of value that is kind of floating around",
      "offset": 308.32,
      "duration": 2.719
    },
    {
      "lang": "en",
      "text": "in scattered papers where we just need",
      "offset": 309.68,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "to like understand the lessons learned",
      "offset": 311.039,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "uh build from them and aggregate this",
      "offset": 313.36,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "into kind of uh training recipes that",
      "offset": 315.039,
      "duration": 5.281
    },
    {
      "lang": "en",
      "text": "can become more scalable uh by uh crowd",
      "offset": 317.44,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "sourcing the answers to some of these",
      "offset": 320.32,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "questions. Um some of the popular agents",
      "offset": 321.68,
      "duration": 4.959
    },
    {
      "lang": "en",
      "text": "people are using the the number of tool",
      "offset": 324.639,
      "duration": 4.881
    },
    {
      "lang": "en",
      "text": "calls scales quite dramatically. Um",
      "offset": 326.639,
      "duration": 5.041
    },
    {
      "lang": "en",
      "text": "research like I said can go up to 100.",
      "offset": 329.52,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "And we also do see that like for really",
      "offset": 331.68,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "hard problems doing more tool calls",
      "offset": 333.68,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "searching the web more gives you a nice",
      "offset": 335.759,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "scaling curve where you get better",
      "offset": 337.759,
      "duration": 3.521
    },
    {
      "lang": "en",
      "text": "answers by putting in more effort by",
      "offset": 339.039,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "like spending more time browsing the",
      "offset": 341.28,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "internet essentially. Um and so this is",
      "offset": 343.199,
      "duration": 4.961
    },
    {
      "lang": "en",
      "text": "a thing that we want to have a process",
      "offset": 345.6,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "for scaling. Um we want uh technology,",
      "offset": 348.16,
      "duration": 4.479
    },
    {
      "lang": "en",
      "text": "we want infrastructure, we want recipes",
      "offset": 350.72,
      "duration": 4.68
    },
    {
      "lang": "en",
      "text": "and experiments to push along these",
      "offset": 352.639,
      "duration": 5.761
    },
    {
      "lang": "en",
      "text": "trajectories. Um multimodal is also one",
      "offset": 355.4,
      "duration": 6.68
    },
    {
      "lang": "en",
      "text": "of the big unlocks in 03. um where I",
      "offset": 358.4,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "think for a while some people were like",
      "offset": 362.08,
      "duration": 2.72
    },
    {
      "lang": "en",
      "text": "speculating like oh what if you have the",
      "offset": 363.44,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "model like generate images in its chain",
      "offset": 364.8,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "of thought reasoning where everything is",
      "offset": 367.44,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "like uh end to end multimodal input and",
      "offset": 369.199,
      "duration": 4.961
    },
    {
      "lang": "en",
      "text": "output and it seems like you don't",
      "offset": 372.56,
      "duration": 2.96
    },
    {
      "lang": "en",
      "text": "really need to do that because for a lot",
      "offset": 374.16,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "of the like multimodal things that are",
      "offset": 375.52,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "useful for reasoning it's actually just",
      "offset": 377.68,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "more efficient and easier to have models",
      "offset": 379.52,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "use like programmatic tools to",
      "offset": 382.4,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "manipulate images so like 03 you can",
      "offset": 384,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "like crop an image and zoom in and",
      "offset": 386.319,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "rotate and I think there's a lot of",
      "offset": 387.919,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "mileage in using this sort of thing",
      "offset": 389.759,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "where the ability to work with these",
      "offset": 391.759,
      "duration": 4.801
    },
    {
      "lang": "en",
      "text": "images um allows you to understand them",
      "offset": 394.319,
      "duration": 4.801
    },
    {
      "lang": "en",
      "text": "in different ways by uh shifting the way",
      "offset": 396.56,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "the model has them in its comfort window",
      "offset": 399.12,
      "duration": 5.359
    },
    {
      "lang": "en",
      "text": "to emphasize certain things more. Um and",
      "offset": 400.96,
      "duration": 5.359
    },
    {
      "lang": "en",
      "text": "so I think just like leaning into",
      "offset": 404.479,
      "duration": 5.201
    },
    {
      "lang": "en",
      "text": "thinking of modes of intelligence as",
      "offset": 406.319,
      "duration": 6.081
    },
    {
      "lang": "en",
      "text": "tool calls is a very powerful like",
      "offset": 409.68,
      "duration": 6.079
    },
    {
      "lang": "en",
      "text": "mental model and uh practical trick for",
      "offset": 412.4,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "having models do the things we want them",
      "offset": 415.759,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "to do. Um and once you have these kind",
      "offset": 417.28,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "of uh things exist in the tool called",
      "offset": 419.84,
      "duration": 4.639
    },
    {
      "lang": "en",
      "text": "format which I think there are several",
      "offset": 422.88,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "other examples of um then you start",
      "offset": 424.479,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "being able to have a way to train the",
      "offset": 427.68,
      "duration": 5.84
    },
    {
      "lang": "en",
      "text": "model to do the thing. Um and so like",
      "offset": 430.479,
      "duration": 5.361
    },
    {
      "lang": "en",
      "text": "geoger for example or like like the",
      "offset": 433.52,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "model is like zooming in to like look at",
      "offset": 435.84,
      "duration": 3.199
    },
    {
      "lang": "en",
      "text": "the license plate. There's all sorts of",
      "offset": 437.36,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "these things that humans do uh kind of",
      "offset": 439.039,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "instinctually for example by like",
      "offset": 441.759,
      "duration": 3.361
    },
    {
      "lang": "en",
      "text": "focusing our attention. So what does",
      "offset": 443.759,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "that look like for an LLM? How do you",
      "offset": 445.12,
      "duration": 5.359
    },
    {
      "lang": "en",
      "text": "like refocus your attention? The simp",
      "offset": 447.199,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "the simple way is just crop the image",
      "offset": 450.479,
      "duration": 5.361
    },
    {
      "lang": "en",
      "text": "and zoom it. Um and so that is one piece",
      "offset": 452.319,
      "duration": 5.121
    },
    {
      "lang": "en",
      "text": "of the puzzle we probably do want if",
      "offset": 455.84,
      "duration": 3.359
    },
    {
      "lang": "en",
      "text": "we're working towards uh scaling up",
      "offset": 457.44,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "these kinds of systems and we want to we",
      "offset": 459.199,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "want to replicate those sorts of models.",
      "offset": 460.72,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "Um additionally",
      "offset": 463.12,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "um I think people were like excited",
      "offset": 465.039,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "about multi- aent systems for a while",
      "offset": 466.88,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "like the crew AI sort of thing of like",
      "offset": 468.479,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "oh I'm going to put my coder agent my",
      "offset": 470.8,
      "duration": 3.679
    },
    {
      "lang": "en",
      "text": "finance agent in a group chat and like a",
      "offset": 472.639,
      "duration": 2.96
    },
    {
      "lang": "en",
      "text": "lot of these are just kind of silly.",
      "offset": 474.479,
      "duration": 2.801
    },
    {
      "lang": "en",
      "text": "they don't actually work very well",
      "offset": 475.599,
      "duration": 2.88
    },
    {
      "lang": "en",
      "text": "because these models are not trained to",
      "offset": 477.28,
      "duration": 3.759
    },
    {
      "lang": "en",
      "text": "do that. They're not uh ever trained in",
      "offset": 478.479,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "a way that actually reinforces those",
      "offset": 481.039,
      "duration": 5.041
    },
    {
      "lang": "en",
      "text": "patterns. Um multi-gent RL is hard. I",
      "offset": 482.8,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "did 5 years of it in grad school. It's",
      "offset": 486.08,
      "duration": 6.559
    },
    {
      "lang": "en",
      "text": "like not easy. Um and to uh the",
      "offset": 487.84,
      "duration": 6.32
    },
    {
      "lang": "en",
      "text": "algorithms don't really even exist for",
      "offset": 492.639,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "the things you would really want to do.",
      "offset": 494.16,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "Um but there are some kind of shortcuts",
      "offset": 495.919,
      "duration": 4.881
    },
    {
      "lang": "en",
      "text": "where you do get very focused versions",
      "offset": 498.4,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "of multi- aent learning um that have",
      "offset": 500.8,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "good synergies with the scaling",
      "offset": 503.84,
      "duration": 2.799
    },
    {
      "lang": "en",
      "text": "paradigms that we're doing. So some of",
      "offset": 505.12,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "these are just like allowing other",
      "offset": 506.639,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "models to be tools. Um so let's say",
      "offset": 508.16,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "you're browsing the internet and you",
      "offset": 510.639,
      "duration": 3.361
    },
    {
      "lang": "en",
      "text": "want a model that can like go read 100",
      "offset": 512.32,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "websites. You probably don't want all",
      "offset": 514,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "100 full websites in your context window",
      "offset": 516.24,
      "duration": 3.359
    },
    {
      "lang": "en",
      "text": "of the main model. But what you might",
      "offset": 518,
      "duration": 3.599
    },
    {
      "lang": "en",
      "text": "want to do is have sub agents whose only",
      "offset": 519.599,
      "duration": 3.761
    },
    {
      "lang": "en",
      "text": "job is to answer a question about a",
      "offset": 521.599,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "website. Um and once you have this now",
      "offset": 523.36,
      "duration": 4.479
    },
    {
      "lang": "en",
      "text": "you can do things much more efficiently.",
      "offset": 526.399,
      "duration": 3.361
    },
    {
      "lang": "en",
      "text": "You can parallelize aspect of producing",
      "offset": 527.839,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "chains and especially for things that",
      "offset": 529.76,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "can be done with like offtheshelf small",
      "offset": 531.68,
      "duration": 2.8
    },
    {
      "lang": "en",
      "text": "models. You don't need to train these",
      "offset": 533.12,
      "duration": 2.64
    },
    {
      "lang": "en",
      "text": "end to end because they're already like",
      "offset": 534.48,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "decent at being an LM and there's a lot",
      "offset": 535.76,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "of tasks of reasoning that can be",
      "offset": 538,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "offloaded to just like any good enough",
      "offset": 539.839,
      "duration": 4.481
    },
    {
      "lang": "en",
      "text": "LM at which point you now can just train",
      "offset": 541.76,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "the main model to learn how to prompt",
      "offset": 544.32,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "these models to use them well. Um this",
      "offset": 546.08,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "is also something that we might want to",
      "offset": 548.72,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "do with things like video summarization.",
      "offset": 550.08,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "And you probably don't want that all in",
      "offset": 552,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "context um for most cases. Navigating",
      "offset": 553.2,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "the web, it might be the case that like",
      "offset": 555.36,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "uh having really uh large images every",
      "offset": 557.36,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "second in your context window like blows",
      "offset": 560.48,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "things up really quickly. Um but if you",
      "offset": 562,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "can offload this with like kind of more",
      "offset": 563.68,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "condensed interfaces to using uh VLMs as",
      "offset": 565.6,
      "duration": 5.919
    },
    {
      "lang": "en",
      "text": "tool calls then you can have much more",
      "offset": 569.04,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "uh logic exist in your reasoning chain",
      "offset": 571.519,
      "duration": 4.241
    },
    {
      "lang": "en",
      "text": "within your context window and you can",
      "offset": 573.6,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "then scale to much longer chains of tool",
      "offset": 575.76,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "calls without needing as many tokens as",
      "offset": 578.08,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "it takes to have an image of the website",
      "offset": 580.32,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "appear in your context window at every",
      "offset": 582.48,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "single second. Um and so this is going",
      "offset": 584,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "to be a problem especially for doing",
      "offset": 586.64,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "this in an open source centralized way.",
      "offset": 587.839,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "you like scaling to like million token",
      "offset": 589.76,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "contexts is like really really hard. Um",
      "offset": 591.92,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "there I don't think there are real like",
      "offset": 594,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "open source replications of million",
      "offset": 595.6,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "token context scaling beyond like tiny",
      "offset": 597.2,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "like academic model sizes. Um, and if",
      "offset": 599.68,
      "duration": 5.92
    },
    {
      "lang": "en",
      "text": "you want to do that type of reasoning,",
      "offset": 602.8,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "um, you want to kind of use every trick",
      "offset": 605.6,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "you can. Um, and I think offloading",
      "offset": 607.92,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "parts of this to subm models is like a",
      "offset": 610.16,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "very effective one that you can, uh,",
      "offset": 611.92,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "specialize with RL because once the sub",
      "offset": 614.32,
      "duration": 4.639
    },
    {
      "lang": "en",
      "text": "routine is solved, you kind of freeze",
      "offset": 617.36,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "that version of the the kelper model as",
      "offset": 618.959,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "a tool call and incorporate the signal",
      "offset": 621.44,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "learning. Um, another thing on context",
      "offset": 623.839,
      "duration": 4.961
    },
    {
      "lang": "en",
      "text": "management is like these models benefit",
      "offset": 627.04,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "from thinking a lot. Um but the thinking",
      "offset": 628.8,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "kicks all the tokens and so if you're",
      "offset": 631.12,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "doing multi-step learning you have all",
      "offset": 632.56,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "these thinking chains that blow up your",
      "offset": 634.16,
      "duration": 3.679
    },
    {
      "lang": "en",
      "text": "slink and some of these models like for",
      "offset": 635.6,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "inference they are not actually keeping",
      "offset": 637.839,
      "duration": 2.721
    },
    {
      "lang": "en",
      "text": "those thinking chains around they're",
      "offset": 639.12,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "like essentially doing thinking per step",
      "offset": 640.56,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "throwing away the thinking tokens and",
      "offset": 642.8,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "then continuing on and we kind of need",
      "offset": 644.8,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "new algorithms for doing this like the",
      "offset": 646.959,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "existing paper people are writing about",
      "offset": 648.48,
      "duration": 4.479
    },
    {
      "lang": "en",
      "text": "turn are not actually incorporating this",
      "offset": 650.88,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "and it kind of like breaks all the math",
      "offset": 652.959,
      "duration": 5.041
    },
    {
      "lang": "en",
      "text": "where you need to like the recent paper",
      "offset": 654.8,
      "duration": 6.159
    },
    {
      "lang": "en",
      "text": "blog post like two days ago from uh",
      "offset": 658,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "Cognition for their like kernel bench uh",
      "offset": 660.959,
      "duration": 5.361
    },
    {
      "lang": "en",
      "text": "AI does this in kind of like a simple",
      "offset": 663.44,
      "duration": 5.519
    },
    {
      "lang": "en",
      "text": "form where each step is essentially like",
      "offset": 666.32,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "a final answer but they allow it to like",
      "offset": 668.959,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "do many final answers in a row um and",
      "offset": 670.8,
      "duration": 3.56
    },
    {
      "lang": "en",
      "text": "they have like the one verification",
      "offset": 672.88,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "system to do this efficiently you kind",
      "offset": 674.36,
      "duration": 5.56
    },
    {
      "lang": "en",
      "text": "of do need to do like true uh turnle",
      "offset": 676.959,
      "duration": 5.361
    },
    {
      "lang": "en",
      "text": "training where you have this big forking",
      "offset": 679.92,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "process where you need to be able to",
      "offset": 682.32,
      "duration": 3.759
    },
    {
      "lang": "en",
      "text": "assign rewards to each one but sometimes",
      "offset": 683.44,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "if these are like actually intermediary",
      "offset": 686.079,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "reasoning steps you don't have a good",
      "offset": 687.6,
      "duration": 5.679
    },
    {
      "lang": "en",
      "text": "verifier off the shelf which uh is going",
      "offset": 690.24,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "to need both like new algorithms",
      "offset": 693.279,
      "duration": 4.641
    },
    {
      "lang": "en",
      "text": "research as well as uh the ability to do",
      "offset": 694.72,
      "duration": 5.84
    },
    {
      "lang": "en",
      "text": "verification for things like was this a",
      "offset": 697.92,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "good Google query was this a good uh",
      "offset": 700.56,
      "duration": 6.08
    },
    {
      "lang": "en",
      "text": "crop of the image was this thing helpful",
      "offset": 703.6,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "in service of the final goal so that's a",
      "offset": 706.64,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "question that we need to be able to",
      "offset": 708.8,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "answer efficiently repeatedly in this",
      "offset": 710.56,
      "duration": 6.24
    },
    {
      "lang": "en",
      "text": "kind of training um and the most one of",
      "offset": 713.12,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "the most promising ways I think towards",
      "offset": 716.8,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "doing This is having the reward models",
      "offset": 718.32,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "also be able to answer harder questions",
      "offset": 721.04,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "by themselves being reasoning models. So",
      "offset": 723.68,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "there's a recent deep paper on this sort",
      "offset": 725.68,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "of thing where you uh train models to be",
      "offset": 727.519,
      "duration": 4.641
    },
    {
      "lang": "en",
      "text": "good like generalist reward models by",
      "offset": 729.92,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "doing inference healing where they break",
      "offset": 732.16,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "down tasks into subriteria rubrics and",
      "offset": 733.6,
      "duration": 5.679
    },
    {
      "lang": "en",
      "text": "then they can evaluate these numerically",
      "offset": 737.12,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "based on following the rubric in",
      "offset": 739.279,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "reference to the thing that they are",
      "offset": 741.36,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "storing. uh and this among other tricks",
      "offset": 742.639,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "there's lots of like clever reverse",
      "offset": 745.2,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "engineering things you can do to kind of",
      "offset": 746.56,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "have other measures of similarity or",
      "offset": 748.88,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "quality when you're trying to like",
      "offset": 751.76,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "ground truth answer um I won't go into",
      "offset": 752.959,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "all the details there but the core idea",
      "offset": 755.12,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "there is if you think of reward models",
      "offset": 756.959,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "as reasoners uh who then you can also",
      "offset": 758.48,
      "duration": 3.599
    },
    {
      "lang": "en",
      "text": "benefit from inference time scaling to",
      "offset": 760.8,
      "duration": 2.96
    },
    {
      "lang": "en",
      "text": "do harder and harder tricks uh harder",
      "offset": 762.079,
      "duration": 3.121
    },
    {
      "lang": "en",
      "text": "and harder problem solving uh step",
      "offset": 763.76,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "verification you have a way of giving",
      "offset": 765.2,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "these rewards throughout the process",
      "offset": 768,
      "duration": 2.88
    },
    {
      "lang": "en",
      "text": "which you kind of need to do if you want",
      "offset": 769.519,
      "duration": 3.961
    },
    {
      "lang": "en",
      "text": "to scale to long context",
      "offset": 770.88,
      "duration": 5.199
    },
    {
      "lang": "en",
      "text": "Um, and but that also introduces the",
      "offset": 773.48,
      "duration": 3.799
    },
    {
      "lang": "en",
      "text": "bubble of like, okay, now reward",
      "offset": 776.079,
      "duration": 2.721
    },
    {
      "lang": "en",
      "text": "modeling might take a minute for",
      "offset": 777.279,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "validating one term, which really means",
      "offset": 778.8,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "you want to push really heavily in the",
      "offset": 781.12,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "direction of everything being async and",
      "offset": 782.88,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "uh like happening later, which might",
      "offset": 784.88,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "mean your model's policy is being",
      "offset": 787.04,
      "duration": 5.039
    },
    {
      "lang": "en",
      "text": "trained on uh turns that happened 20",
      "offset": 789.04,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "minutes ago. Um, which is kind of like",
      "offset": 792.079,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "in old school RL days, people did this",
      "offset": 794.56,
      "duration": 2.88
    },
    {
      "lang": "en",
      "text": "all the time with like replay buffers",
      "offset": 796.24,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "and whatnot. um you really want both",
      "offset": 797.44,
      "duration": 4.639
    },
    {
      "lang": "en",
      "text": "your tool calls and your inference and",
      "offset": 800.16,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "your role modeling and your training to",
      "offset": 802.079,
      "duration": 2.801
    },
    {
      "lang": "en",
      "text": "all be happening in parallel with",
      "offset": 803.36,
      "duration": 2.96
    },
    {
      "lang": "en",
      "text": "whatever as much of a lag as you can",
      "offset": 804.88,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "tolerate as well as your communication.",
      "offset": 806.32,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "Um and so that is I think one of the big",
      "offset": 808.56,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "reasons why like pushing on async RL is",
      "offset": 810.32,
      "duration": 5.519
    },
    {
      "lang": "en",
      "text": "really huge not just for centralized",
      "offset": 814,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "training but for things like scaling or",
      "offset": 815.839,
      "duration": 2.961
    },
    {
      "lang": "en",
      "text": "modeling for things like scaling",
      "offset": 817.76,
      "duration": 4.639
    },
    {
      "lang": "en",
      "text": "protocols um scaling resources. Um and I",
      "offset": 818.8,
      "duration": 5.92
    },
    {
      "lang": "en",
      "text": "think prime has done some very cool work",
      "offset": 822.399,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "showing that this is like a direction",
      "offset": 824.72,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "you can push. You can go off policy. You",
      "offset": 826.079,
      "duration": 4.961
    },
    {
      "lang": "en",
      "text": "can allow your model to be trained on",
      "offset": 829.12,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "like slightly stale data and it still",
      "offset": 831.04,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "works because these things are pretty",
      "offset": 833.36,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "robust. And if you set everything up",
      "offset": 834.8,
      "duration": 3.599
    },
    {
      "lang": "en",
      "text": "right and you tune your hyperparameters",
      "offset": 836.8,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "and you ensure that uh the reasoning",
      "offset": 838.399,
      "duration": 5.201
    },
    {
      "lang": "en",
      "text": "process the training process is like",
      "offset": 841.92,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "stable otherwise then you have a",
      "offset": 843.6,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "paradigm which allows you to do all of",
      "offset": 845.36,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "these things. You can scale on tool",
      "offset": 847.12,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "calls, you can scale on reward modeling,",
      "offset": 848.88,
      "duration": 4.639
    },
    {
      "lang": "en",
      "text": "you can scale on generality of task um",
      "offset": 850.56,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "and everything still fits into this nice",
      "offset": 853.519,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "async uh pipeline where everything is",
      "offset": 855.36,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "flowing from one to the next thing uh",
      "offset": 857.6,
      "duration": 5.359
    },
    {
      "lang": "en",
      "text": "without like blowing up your trend",
      "offset": 861.04,
      "duration": 3.88
    },
    {
      "lang": "en",
      "text": "bubbles.",
      "offset": 862.959,
      "duration": 5.041
    },
    {
      "lang": "en",
      "text": "Um, you can also decentralize your skill",
      "offset": 864.92,
      "duration": 4.359
    },
    {
      "lang": "en",
      "text": "acquisition. You can train on many",
      "offset": 868,
      "duration": 2.88
    },
    {
      "lang": "en",
      "text": "things in parallel. And it seems like",
      "offset": 869.279,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "model merging like works weirdly well.",
      "offset": 870.88,
      "duration": 3.199
    },
    {
      "lang": "en",
      "text": "That was one thing that I kind of",
      "offset": 872.959,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "updated on, which is like you can have a",
      "offset": 874.079,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "model trained on code and a model",
      "offset": 876.56,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "trained on math, a model trained on",
      "offset": 878.48,
      "duration": 3.359
    },
    {
      "lang": "en",
      "text": "Spanish, and you can literally average",
      "offset": 880,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "the weights and it works, which on one",
      "offset": 881.839,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "hand sounds crazy, but on the other",
      "offset": 884.48,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "hand, it's like this is kind of what is",
      "offset": 886.16,
      "duration": 3.119
    },
    {
      "lang": "en",
      "text": "being done by the local style",
      "offset": 888.16,
      "duration": 3.359
    },
    {
      "lang": "en",
      "text": "pre-training at smaller scales anyways.",
      "offset": 889.279,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "And it seems like the updates made to",
      "offset": 891.519,
      "duration": 4.801
    },
    {
      "lang": "en",
      "text": "model weights are orthogonal enough for",
      "offset": 894.079,
      "duration": 4.481
    },
    {
      "lang": "en",
      "text": "specialized tasks that this is actually",
      "offset": 896.32,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "like totally fine. Things are nice and",
      "offset": 898.56,
      "duration": 3.519
    },
    {
      "lang": "en",
      "text": "linear in most cases. Things are nice",
      "offset": 900,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "and orthogonal and you can get away with",
      "offset": 902.079,
      "duration": 5.921
    },
    {
      "lang": "en",
      "text": "a lot of uh async uh updates to models",
      "offset": 904.48,
      "duration": 5.64
    },
    {
      "lang": "en",
      "text": "that are then merged even without bulk",
      "offset": 908,
      "duration": 4.959
    },
    {
      "lang": "en",
      "text": "communication. Um and so Coher did this",
      "offset": 910.12,
      "duration": 4.44
    },
    {
      "lang": "en",
      "text": "very extensively in their latest uh",
      "offset": 912.959,
      "duration": 4.641
    },
    {
      "lang": "en",
      "text": "flagship model command A. Um, and it",
      "offset": 914.56,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "seems like we have a lot of ways where",
      "offset": 917.6,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "you can split up different pieces of the",
      "offset": 919.44,
      "duration": 4.959
    },
    {
      "lang": "en",
      "text": "process of learning to do X Y or Z board",
      "offset": 921.44,
      "duration": 5.759
    },
    {
      "lang": "en",
      "text": "games or coding agents or math. And",
      "offset": 924.399,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "these can all go off and happen and then",
      "offset": 927.199,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "come together and merge. Um, and if you",
      "offset": 928.8,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "can do this, then you can train",
      "offset": 930.88,
      "duration": 5.519
    },
    {
      "lang": "en",
      "text": "decentralized models with lots and lots",
      "offset": 933.76,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "of capabilities because the capabilities",
      "offset": 936.399,
      "duration": 3.361
    },
    {
      "lang": "en",
      "text": "themselves can be learned in centralized",
      "offset": 937.92,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "members. Um, so what does this mean?",
      "offset": 939.76,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "Like it's going to be hard. It's not",
      "offset": 942.48,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "going to be easy to like put all these",
      "offset": 944.32,
      "duration": 2.639
    },
    {
      "lang": "en",
      "text": "things together and make it work make it",
      "offset": 945.68,
      "duration": 3.519
    },
    {
      "lang": "en",
      "text": "work well and really train these kinds",
      "offset": 946.959,
      "duration": 4.641
    },
    {
      "lang": "en",
      "text": "of models super efficiently, but it",
      "offset": 949.199,
      "duration": 4.961
    },
    {
      "lang": "en",
      "text": "seems like it's doable. Um, we kind of",
      "offset": 951.6,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "know the sorts of problems that we have",
      "offset": 954.16,
      "duration": 5.039
    },
    {
      "lang": "en",
      "text": "to solve to do it. Um, we kind of know",
      "offset": 956.32,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "what things are going to be really",
      "offset": 959.199,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "annoying and how we can kind of shortcut",
      "offset": 960.399,
      "duration": 6.161
    },
    {
      "lang": "en",
      "text": "some of them by like using kind of uh",
      "offset": 962.88,
      "duration": 5.84
    },
    {
      "lang": "en",
      "text": "fallback cheap tricks because these",
      "offset": 966.56,
      "duration": 3.279
    },
    {
      "lang": "en",
      "text": "cheap tricks are like unreasonably",
      "offset": 968.72,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "effective. Um, and this does kind of",
      "offset": 969.839,
      "duration": 4.881
    },
    {
      "lang": "en",
      "text": "give us a road map and a recipe of what",
      "offset": 972.16,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "questions we need to answer, what things",
      "offset": 974.72,
      "duration": 5.119
    },
    {
      "lang": "en",
      "text": "we have to build, uh, and what we have",
      "offset": 975.92,
      "duration": 7.52
    },
    {
      "lang": "en",
      "text": "to accomplish in order to, uh, train",
      "offset": 979.839,
      "duration": 8
    },
    {
      "lang": "en",
      "text": "decentralized, uh, nm minute",
      "offset": 983.44,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "Okay, we have a special guest um that",
      "offset": 999.759,
      "duration": 6.401
    },
    {
      "lang": "en",
      "text": "we're pretty excited about. Um so here",
      "offset": 1003.279,
      "duration": 4.601
    },
    {
      "lang": "en",
      "text": "we",
      "offset": 1006.16,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "go. All",
      "offset": 1007.88,
      "duration": 3
    },
    {
      "lang": "en",
      "text": "right. Actually, we're gonna pause for",
      "offset": 1014.8,
      "duration": 2.479
    },
    {
      "lang": "en",
      "text": "one second and just do another",
      "offset": 1016.079,
      "duration": 4.76
    },
    {
      "lang": "en",
      "text": "transition. So,",
      "offset": 1017.279,
      "duration": 3.56
    }
  ],
  "cleanText": null,
  "dumpedAt": "2025-07-21T18:43:24.798Z"
}