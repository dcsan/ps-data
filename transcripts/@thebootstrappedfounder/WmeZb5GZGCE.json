{
  "episodeId": "WmeZb5GZGCE",
  "channelSlug": "@thebootstrappedfounder",
  "title": "390: When to Choose Local LLMs vs APIs",
  "publishedAt": "2025-05-16T10:06:01.000Z",
  "rawLines": [
    {
      "lang": "en",
      "text": "Hello everyone, it's Arvid and welcome",
      "offset": 0.48,
      "duration": 4.02
    },
    {
      "lang": "en",
      "text": "to the Bootstrap",
      "offset": 3.28,
      "duration": 4.76
    },
    {
      "lang": "en",
      "text": "[Music]",
      "offset": 4.5,
      "duration": 5.5
    },
    {
      "lang": "en",
      "text": "Founder. Today I want to talk about",
      "offset": 8.04,
      "duration": 4.04
    },
    {
      "lang": "en",
      "text": "something that's been on my mind lately",
      "offset": 10,
      "duration": 3.599
    },
    {
      "lang": "en",
      "text": "and probably yours too if you're",
      "offset": 12.08,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "building anything with AI. It's the",
      "offset": 13.599,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "age-old question and I guess a couple",
      "offset": 16.48,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "years of age at this point. Should you",
      "offset": 19.199,
      "duration": 6.24
    },
    {
      "lang": "en",
      "text": "run language models locally or just use",
      "offset": 21.68,
      "duration": 7.839
    },
    {
      "lang": "en",
      "text": "APIs like OpenAI or Claude? This episode",
      "offset": 25.439,
      "duration": 6.24
    },
    {
      "lang": "en",
      "text": "is sponsored by paddle.com, the merchant",
      "offset": 29.519,
      "duration": 4.001
    },
    {
      "lang": "en",
      "text": "of record that has been responsible for",
      "offset": 31.679,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "allowing me to reach profitability a",
      "offset": 33.52,
      "duration": 4.559
    },
    {
      "lang": "en",
      "text": "month ago. Paddle truly is more. That's",
      "offset": 35.28,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "Mor, the merchant of record, because",
      "offset": 38.079,
      "duration": 4.241
    },
    {
      "lang": "en",
      "text": "their product has allowed me to focus on",
      "offset": 39.92,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "building a product people actually want",
      "offset": 42.32,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "to pay money for. That money is going",
      "offset": 43.6,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "into a lot of AI tools, and I'll talk",
      "offset": 45.6,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "about that today. But Paddle is really",
      "offset": 47.52,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "doing more for me. They deal with taxes,",
      "offset": 49.76,
      "duration": 4.36
    },
    {
      "lang": "en",
      "text": "reach out to customers with failed",
      "offset": 52.48,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "payments. They charge in people's local",
      "offset": 54.12,
      "duration": 5.32
    },
    {
      "lang": "en",
      "text": "currency. All things that I don't need",
      "offset": 56.879,
      "duration": 5.041
    },
    {
      "lang": "en",
      "text": "to focus on so I can really be present",
      "offset": 59.44,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "for my customers and their needs. It's",
      "offset": 61.92,
      "duration": 6.64
    },
    {
      "lang": "en",
      "text": "amazing. Check out paddle.com to learn",
      "offset": 63.76,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "more. Now, I know what you're thinking.",
      "offset": 68.76,
      "duration": 5.8
    },
    {
      "lang": "en",
      "text": "All right. Local AI versus API. That has",
      "offset": 71.28,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "been debated to death on Twitter over",
      "offset": 74.56,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "the last couple weeks. But here's the",
      "offset": 76.4,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "thing. Most of these conversations, they",
      "offset": 78.4,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "seem to happen in a vacuum, a very",
      "offset": 80.4,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "academic vacuum, full of theoretical",
      "offset": 82.64,
      "duration": 4.799
    },
    {
      "lang": "en",
      "text": "scenarios, benchmark comparisons, that",
      "offset": 85.28,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "kind of stuff. What I want to talk about",
      "offset": 87.439,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "and share with you today is what I have",
      "offset": 89.439,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "actually learned from building a real",
      "offset": 91.84,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "business with AI, making real decisions",
      "offset": 93.439,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "with real constraints and sometimes",
      "offset": 96.32,
      "duration": 3.119
    },
    {
      "lang": "en",
      "text": "making the wrong choices and learning",
      "offset": 98.079,
      "duration": 3.761
    },
    {
      "lang": "en",
      "text": "from them. So, I'll share that. Let me",
      "offset": 99.439,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "start with a confession here. When I",
      "offset": 101.84,
      "duration": 4.559
    },
    {
      "lang": "en",
      "text": "first started building Podcan, I was",
      "offset": 104.159,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "convinced I had to do everything with",
      "offset": 106.399,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "local language models. I mean, as a",
      "offset": 108.479,
      "duration": 4.241
    },
    {
      "lang": "en",
      "text": "booter founder, the idea of keeping cost",
      "offset": 110.399,
      "duration": 4.481
    },
    {
      "lang": "en",
      "text": "slow, maintaining control, that was",
      "offset": 112.72,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "incredibly appealing. So, I dove in",
      "offset": 114.88,
      "duration": 4.879
    },
    {
      "lang": "en",
      "text": "trying to handle everything locally. And",
      "offset": 117.119,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "I tweeted a lot about this, right? I",
      "offset": 119.759,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "shared all my benchmarks talking about",
      "offset": 122.079,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "this. I shared my numbers, how much it",
      "offset": 123.92,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "costs, and all that. It was a lot of",
      "offset": 126.079,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "research that I needed to do. And I",
      "offset": 128.239,
      "duration": 4.241
    },
    {
      "lang": "en",
      "text": "tried to do all of these things in",
      "offset": 130.16,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "public as much as I could. But here's",
      "offset": 132.48,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "what happened since. And this might",
      "offset": 135.28,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "sound familiar if you've been down this",
      "offset": 137.2,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "road yourself. The cost savings that",
      "offset": 138.72,
      "duration": 5.8
    },
    {
      "lang": "en",
      "text": "platforms like OpenAI and Enthropic have",
      "offset": 142,
      "duration": 6.239
    },
    {
      "lang": "en",
      "text": "achieved just through their scale very",
      "offset": 144.52,
      "duration": 6.6
    },
    {
      "lang": "en",
      "text": "quickly made it pretty clear that for my",
      "offset": 148.239,
      "duration": 5.521
    },
    {
      "lang": "en",
      "text": "workload and data volume, it made no",
      "offset": 151.12,
      "duration": 4.479
    },
    {
      "lang": "en",
      "text": "sense to rent more and more GPU",
      "offset": 153.76,
      "duration": 5.199
    },
    {
      "lang": "en",
      "text": "resources to run local language models.",
      "offset": 155.599,
      "duration": 6.801
    },
    {
      "lang": "en",
      "text": "I have 50,000 podcast episodes coming in",
      "offset": 158.959,
      "duration": 5.441
    },
    {
      "lang": "en",
      "text": "every day and I have really no control",
      "offset": 162.4,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "over how many there are. That's just how",
      "offset": 164.4,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "much stuff gets released every single",
      "offset": 166.319,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "day and I need to deal with this. So to",
      "offset": 168.16,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "do analysis on this I need to have",
      "offset": 170.879,
      "duration": 4.36
    },
    {
      "lang": "en",
      "text": "something that works at scale and is",
      "offset": 173.44,
      "duration": 4.879
    },
    {
      "lang": "en",
      "text": "efficient and local models they don't",
      "offset": 175.239,
      "duration": 5.481
    },
    {
      "lang": "en",
      "text": "really work like that. At this point, it",
      "offset": 178.319,
      "duration": 4.721
    },
    {
      "lang": "en",
      "text": "became much more effective for me and",
      "offset": 180.72,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "that was been like 3 months ago when I",
      "offset": 183.04,
      "duration": 5.119
    },
    {
      "lang": "en",
      "text": "realized this to go API first instead of",
      "offset": 184.8,
      "duration": 6.719
    },
    {
      "lang": "en",
      "text": "local LLM first and then consider local",
      "offset": 188.159,
      "duration": 5.841
    },
    {
      "lang": "en",
      "text": "deployment later if APIs went down or if",
      "offset": 191.519,
      "duration": 5.281
    },
    {
      "lang": "en",
      "text": "I needed specific capacity requirements.",
      "offset": 194,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "So, don't get me wrong. There absolutely",
      "offset": 196.8,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "are situations where a local LLM shines",
      "offset": 199.44,
      "duration": 4.879
    },
    {
      "lang": "en",
      "text": "for SAS founders or just if you want to",
      "offset": 202.4,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "use it yourself. But let me break this",
      "offset": 204.319,
      "duration": 4.2
    },
    {
      "lang": "en",
      "text": "down based on what I've actually",
      "offset": 206.72,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "experienced. The first sweet spot is",
      "offset": 208.519,
      "duration": 5.08
    },
    {
      "lang": "en",
      "text": "when you have very small tasks that need",
      "offset": 211.28,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "really quick decisions, things that",
      "offset": 213.599,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "don't require complex reasoning or",
      "offset": 215.44,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "extensive context. And I'm talking about",
      "offset": 217.44,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "little tiny fragments of work that need",
      "offset": 219.76,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "to be done in the context of a software",
      "offset": 222.08,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "business. For example, if you need a",
      "offset": 223.84,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "reasonable choice between options that",
      "offset": 225.68,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "can't be determined by simple boolean",
      "offset": 227.84,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "logic or a basic algorithm, a small",
      "offset": 230,
      "duration": 4.879
    },
    {
      "lang": "en",
      "text": "language model with fast inference might",
      "offset": 232.4,
      "duration": 5.119
    },
    {
      "lang": "en",
      "text": "even run on CPU and can be perfect even",
      "offset": 234.879,
      "duration": 4.881
    },
    {
      "lang": "en",
      "text": "if it's run on CPU or GPU, right? You",
      "offset": 237.519,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "look at a piece of text and you want to",
      "offset": 239.76,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "determine one thing about it that you",
      "offset": 241.2,
      "duration": 3.119
    },
    {
      "lang": "en",
      "text": "cannot just find by looking for",
      "offset": 243.04,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "keywords, right? looking for something",
      "offset": 244.319,
      "duration": 5.041
    },
    {
      "lang": "en",
      "text": "specific that is kind of in the context",
      "offset": 246.48,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "of the text but not explicitly written",
      "offset": 249.36,
      "duration": 4.799
    },
    {
      "lang": "en",
      "text": "in it and L&amp;M will be able to figure",
      "offset": 251.68,
      "duration": 4.799
    },
    {
      "lang": "en",
      "text": "this out and a local model if it's not",
      "offset": 254.159,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "too much text can do this extremely fast",
      "offset": 256.479,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "even if you don't have a GPU in your",
      "offset": 258.959,
      "duration": 4.561
    },
    {
      "lang": "en",
      "text": "computer so instead of making a network",
      "offset": 260.959,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "call and dealing with API latency and",
      "offset": 263.52,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "cost you get your answer instantly on",
      "offset": 265.919,
      "duration": 4.641
    },
    {
      "lang": "en",
      "text": "your local server if you run a really",
      "offset": 268.88,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "really small LLM and here's a concrete",
      "offset": 270.56,
      "duration": 5.199
    },
    {
      "lang": "en",
      "text": "example from my own business. The first",
      "offset": 273.28,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "AI feature that I built was for",
      "offset": 275.759,
      "duration": 4.801
    },
    {
      "lang": "en",
      "text": "transcribing audio clips for POTS scan.",
      "offset": 278.08,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "This doesn't necessarily require an",
      "offset": 280.56,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "inference call to a remote API. It can",
      "offset": 282.8,
      "duration": 4.959
    },
    {
      "lang": "en",
      "text": "run on the local GPU or CPU of a server.",
      "offset": 284.96,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "And that's how I started, right? The",
      "offset": 287.759,
      "duration": 4.241
    },
    {
      "lang": "en",
      "text": "whole thing was I didn't have too many",
      "offset": 290.16,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "parallel operations. It didn't exceed",
      "offset": 292,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "what my business at that stage could",
      "offset": 294.4,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "handle because I was just figuring it",
      "offset": 296.08,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "out. So, I was running all of these",
      "offset": 297.68,
      "duration": 5.92
    },
    {
      "lang": "en",
      "text": "transcription things on my Mac computer.",
      "offset": 300.479,
      "duration": 5.521
    },
    {
      "lang": "en",
      "text": "And even before I started Podcan I was",
      "offset": 303.6,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "running a different business that was a",
      "offset": 306,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "pod line and for that I did",
      "offset": 307.759,
      "duration": 3.761
    },
    {
      "lang": "en",
      "text": "transcription too of really short",
      "offset": 310.08,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "messages maybe a minute or so. So that",
      "offset": 311.52,
      "duration": 3.679
    },
    {
      "lang": "en",
      "text": "doesn't really require a lot of",
      "offset": 314,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "resources. I was running this on CPU on",
      "offset": 315.199,
      "duration": 5.921
    },
    {
      "lang": "en",
      "text": "that server. It's like a $25 a month",
      "offset": 318.08,
      "duration": 5.679
    },
    {
      "lang": "en",
      "text": "head server that runs the whole business",
      "offset": 321.12,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "and it might take two to five minutes to",
      "offset": 323.759,
      "duration": 5.361
    },
    {
      "lang": "en",
      "text": "transcribe that minute on the CPU but it",
      "offset": 326.16,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "doesn't really matter, right? message",
      "offset": 329.12,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "comes in, you transcribe it, and then",
      "offset": 330.8,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "you take the transcript and send a",
      "offset": 332.8,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "notification. A couple minutes perfectly",
      "offset": 334.32,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "fine for such an async tool. So, I",
      "offset": 336.24,
      "duration": 4.959
    },
    {
      "lang": "en",
      "text": "didn't need to build like a complicated",
      "offset": 338.8,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "pipeline there. I could just have it run",
      "offset": 341.199,
      "duration": 4.961
    },
    {
      "lang": "en",
      "text": "locally, and that is perfectly okay. For",
      "offset": 343.52,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "these cases, it makes sense to keep the",
      "offset": 346.16,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "processing on your local server with",
      "offset": 348,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "local models that fit into RAM and avoid",
      "offset": 350.08,
      "duration": 4.559
    },
    {
      "lang": "en",
      "text": "costs that would come from someone",
      "offset": 352.88,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "else's resources and your attempt at",
      "offset": 354.639,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "using them. And this experience also",
      "offset": 357.039,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "taught me something interesting about",
      "offset": 360.639,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "CPU versus GPU inference. There are",
      "offset": 361.919,
      "duration": 4.801
    },
    {
      "lang": "en",
      "text": "certain ways of using these models,",
      "offset": 364.24,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "particularly very modern models where",
      "offset": 366.72,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "there's barely a difference in speed",
      "offset": 369.44,
      "duration": 4.479
    },
    {
      "lang": "en",
      "text": "between CPU and GPU, specifically when",
      "offset": 371.039,
      "duration": 4.961
    },
    {
      "lang": "en",
      "text": "you're dealing with low context windows",
      "offset": 373.919,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "and low token prompts. If you just need",
      "offset": 376,
      "duration": 6.479
    },
    {
      "lang": "en",
      "text": "a yes or no answer, for example, a CPU",
      "offset": 379.199,
      "duration": 6.321
    },
    {
      "lang": "en",
      "text": "and a GPU might be almost equal in terms",
      "offset": 382.479,
      "duration": 5.201
    },
    {
      "lang": "en",
      "text": "of speed, provided that it's low",
      "offset": 385.52,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "context, right? It's not a lot of text.",
      "offset": 387.68,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "It's not a lot of prompt. It's just give",
      "offset": 389.68,
      "duration": 4.639
    },
    {
      "lang": "en",
      "text": "me a yes or give me a no answering this",
      "offset": 391.759,
      "duration": 5.681
    },
    {
      "lang": "en",
      "text": "question about this paragraph of text.",
      "offset": 394.319,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "It is really, really fast on the CPU.",
      "offset": 397.44,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "You don't need a complicated thing. But",
      "offset": 399.759,
      "duration": 4.641
    },
    {
      "lang": "en",
      "text": "the moment you do multimodal work,",
      "offset": 402.08,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "things like images or audio or some deep",
      "offset": 404.4,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "analysis with a lot of data, then a GPU",
      "offset": 406.8,
      "duration": 5.119
    },
    {
      "lang": "en",
      "text": "based system becomes much more effective",
      "offset": 410,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "and even required. The key insight here",
      "offset": 411.919,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "for me is if you have only 10 of these",
      "offset": 414.4,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "operations a day and you can wait a bit",
      "offset": 416.639,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "for the results, you don't necessarily",
      "offset": 418.8,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "need to go to a remote API or use a GPU",
      "offset": 420.72,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "to begin with. But here's where things",
      "offset": 423.36,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "get interesting and this is where I",
      "offset": 425.44,
      "duration": 4.879
    },
    {
      "lang": "en",
      "text": "learned some hard lessons. Scale changes",
      "offset": 426.88,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "everything.",
      "offset": 430.319,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "My first real challenge came when I",
      "offset": 431.84,
      "duration": 4.52
    },
    {
      "lang": "en",
      "text": "started working with a lot of large",
      "offset": 434.319,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "transcripts because inference like",
      "offset": 436.36,
      "duration": 4.6
    },
    {
      "lang": "en",
      "text": "getting some information from a large",
      "offset": 439.039,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "transcript really scales with the size",
      "offset": 440.96,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "of the context that's provided. If you",
      "offset": 443.12,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "have a three-hour conversation, like I'm",
      "offset": 445.36,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "looking at Joe Rogan in text form and",
      "offset": 447.199,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "you want to run some kind of analytics",
      "offset": 449.759,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "on it, some kind of data extraction,",
      "offset": 451.759,
      "duration": 4.961
    },
    {
      "lang": "en",
      "text": "that turns into a very very long",
      "offset": 454.08,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "computation process. If you run a local",
      "offset": 456.72,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "language model, whether on GPU or CPU,",
      "offset": 459.28,
      "duration": 5.039
    },
    {
      "lang": "en",
      "text": "it just takes some time unless you have",
      "offset": 462,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "an H100 graphics card, which costs",
      "offset": 464.319,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "several tens of thousands of dollars to",
      "offset": 467.28,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "to own, right? So, that is not",
      "offset": 469.199,
      "duration": 5.201
    },
    {
      "lang": "en",
      "text": "happening. And for any other graphics",
      "offset": 471.84,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "card that you run this on or god forbid",
      "offset": 474.4,
      "duration": 6.96
    },
    {
      "lang": "en",
      "text": "a CPU, this is minutes if not hours. I",
      "offset": 476.72,
      "duration": 8.72
    },
    {
      "lang": "en",
      "text": "was using llama.cpp with a llama 3 bill",
      "offset": 481.36,
      "duration": 6.559
    },
    {
      "lang": "en",
      "text": "or 7 billion parameter model. And while",
      "offset": 485.44,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "this was perfectly fine at the scale of",
      "offset": 487.919,
      "duration": 3.761
    },
    {
      "lang": "en",
      "text": "a couple hundred operations a day, it",
      "offset": 490,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "became a bottleneck immediately at a",
      "offset": 491.68,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "couple thousand. And at tens of",
      "offset": 493.36,
      "duration": 3.279
    },
    {
      "lang": "en",
      "text": "thousands a day, it became completely",
      "offset": 494.96,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "unbearable. I had to scale back the",
      "offset": 496.639,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "number of things that I pushed in. I had",
      "offset": 499.36,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "to make a choice like do I even analyze",
      "offset": 501.599,
      "duration": 3.761
    },
    {
      "lang": "en",
      "text": "this script or do I not? It became a",
      "offset": 503.44,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "problem. And here's the brutal truth",
      "offset": 505.36,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "about this with the unit economics of",
      "offset": 506.96,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "remote AI platforms that are offering AI",
      "offset": 509.44,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "inference. And there's way more than",
      "offset": 512.08,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "OpenAI and Anthropics Claude, right?",
      "offset": 514,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "There are many many Deepseek is one of",
      "offset": 516.24,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "them. And there are many that can host",
      "offset": 517.919,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "your models remotely and do that very",
      "offset": 520.88,
      "duration": 4.959
    },
    {
      "lang": "en",
      "text": "efficiently. It is often much more",
      "offset": 523.519,
      "duration": 5.201
    },
    {
      "lang": "en",
      "text": "reliable and much cheaper to use those",
      "offset": 525.839,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "services than to run your own",
      "offset": 528.72,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "infrastructure at scale. The economies",
      "offset": 530,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "of scale that companies like OpenAI and",
      "offset": 532.16,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "Enthropic achieve, they are just",
      "offset": 534.32,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "impossible to replicate when you're",
      "offset": 536.72,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "running a smaller operation. You cannot",
      "offset": 538.64,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "scale an inference cluster to the same",
      "offset": 540.64,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "level they can. Like I don't even know",
      "offset": 542.959,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "how to start an inference cluster. I'm",
      "offset": 545.12,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "just running individual machines, right?",
      "offset": 547.36,
      "duration": 3.599
    },
    {
      "lang": "en",
      "text": "Like I don't have the knowledge and it's",
      "offset": 549.44,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "not my job. Potscan is not an inference",
      "offset": 550.959,
      "duration": 4.961
    },
    {
      "lang": "en",
      "text": "cluster building company. It is a",
      "offset": 553.519,
      "duration": 5
    },
    {
      "lang": "en",
      "text": "podcast data company. And if I need",
      "offset": 555.92,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "inference, either I build something kind",
      "offset": 558.519,
      "duration": 6.201
    },
    {
      "lang": "en",
      "text": "of or I use somebody's system that is so",
      "offset": 561.44,
      "duration": 5.72
    },
    {
      "lang": "en",
      "text": "much better at it. And there are some",
      "offset": 564.72,
      "duration": 6.239
    },
    {
      "lang": "en",
      "text": "scenarios where you absolutely need",
      "offset": 567.16,
      "duration": 6.84
    },
    {
      "lang": "en",
      "text": "local language models regardless of cost",
      "offset": 570.959,
      "duration": 5.601
    },
    {
      "lang": "en",
      "text": "or convenience out there too. And I",
      "offset": 574,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "think it's important to think about",
      "offset": 576.56,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "those because if you have customers that",
      "offset": 578.24,
      "duration": 6.4
    },
    {
      "lang": "en",
      "text": "require SOC2 compliance or any kind of",
      "offset": 580.8,
      "duration": 6.08
    },
    {
      "lang": "en",
      "text": "privacy based compliance, privacy in the",
      "offset": 584.64,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "first place, they will very likely not",
      "offset": 586.88,
      "duration": 4.639
    },
    {
      "lang": "en",
      "text": "even allow you to send their data to",
      "offset": 589.36,
      "duration": 4.039
    },
    {
      "lang": "en",
      "text": "external systems outside of your",
      "offset": 591.519,
      "duration": 4.721
    },
    {
      "lang": "en",
      "text": "business. The fine print of API usage",
      "offset": 593.399,
      "duration": 4.681
    },
    {
      "lang": "en",
      "text": "terms for the platforms like OpenAI",
      "offset": 596.24,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "often include the fact that they can use",
      "offset": 598.08,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "your data that you send to train their",
      "offset": 600,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "future systems. And for customers with",
      "offset": 601.92,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "strict privacy requirements, that is a",
      "offset": 604.32,
      "duration": 2.959
    },
    {
      "lang": "en",
      "text": "non-starter. It's just not going to",
      "offset": 606,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "happen. And that is their control of",
      "offset": 607.279,
      "duration": 6.401
    },
    {
      "lang": "en",
      "text": "their data. There's another argument for",
      "offset": 610.64,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "local systems, and that's control of the",
      "offset": 613.68,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "system itself. Both data control and",
      "offset": 616.32,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "model control. You control what model",
      "offset": 618.56,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "runs on your own system, what version,",
      "offset": 620.88,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "and when it runs. Nobody can turn off",
      "offset": 622.72,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "your model because they need to update",
      "offset": 625.12,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "their hardware or because they decide to",
      "offset": 626.72,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "discontinue support or use a new model",
      "offset": 628.8,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "instead. If you have your own system,",
      "offset": 631.2,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "you can run it for as long as you have",
      "offset": 633.36,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "access to that computer. You can also",
      "offset": 634.88,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "tune your AI system to your customer's",
      "offset": 637.279,
      "duration": 4.721
    },
    {
      "lang": "en",
      "text": "specific data and deploy exactly the",
      "offset": 639.76,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "right model with exactly the right",
      "offset": 642,
      "duration": 3.279
    },
    {
      "lang": "en",
      "text": "fine-tuning on exactly the right data",
      "offset": 643.44,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "for them. You can obviously also kind of",
      "offset": 645.279,
      "duration": 5.281
    },
    {
      "lang": "en",
      "text": "do that with systems that have a",
      "offset": 648.48,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "platform offering, but it becomes more",
      "offset": 650.56,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "complicated to actually retain full",
      "offset": 652.48,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "control over it and sometimes that's",
      "offset": 654.88,
      "duration": 5.199
    },
    {
      "lang": "en",
      "text": "what your customers want to pay you for.",
      "offset": 657.36,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "So, how do you actually make this",
      "offset": 660.079,
      "duration": 5.481
    },
    {
      "lang": "en",
      "text": "decision between local models and remote",
      "offset": 662.64,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "APIs? Well, based on everything I've",
      "offset": 665.56,
      "duration": 3.48
    },
    {
      "lang": "en",
      "text": "learned, here's the framework that I",
      "offset": 667.6,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "use. Couple questions. The first one is",
      "offset": 669.04,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "scale. How many operations a day am I",
      "offset": 671.36,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "running? If it's under a few hundred,",
      "offset": 673.6,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "then local might work. If it's",
      "offset": 675.6,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "thousands, it's probably API time. The",
      "offset": 677.12,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "second question is the speed",
      "offset": 680,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "requirements. Can you wait a minute or",
      "offset": 681.68,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "two for results? If that's the case, use",
      "offset": 684.079,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "local. If you need instant responses or",
      "offset": 686.8,
      "duration": 6.32
    },
    {
      "lang": "en",
      "text": "a lot of parallel responses, APIs will",
      "offset": 689.519,
      "duration": 5.121
    },
    {
      "lang": "en",
      "text": "be your friend. The third one,",
      "offset": 693.12,
      "duration": 2.959
    },
    {
      "lang": "en",
      "text": "obviously, like I just said, privacy",
      "offset": 694.64,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "constraints. Do you have customers with",
      "offset": 696.079,
      "duration": 4.241
    },
    {
      "lang": "en",
      "text": "strict compliance requirements? Do you",
      "offset": 697.92,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "want to offer this? Then that might",
      "offset": 700.32,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "force your hand towards local. And",
      "offset": 703.44,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "context size is similar here too. Are",
      "offset": 705.76,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "you working with large documents, large",
      "offset": 707.76,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "transcripts, large images, video? Maybe",
      "offset": 709.839,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "the larger the context, the more those",
      "offset": 712.079,
      "duration": 4.721
    },
    {
      "lang": "en",
      "text": "APIs make sense. Unless you want to",
      "offset": 714.079,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "invest a lot into hardware to be able to",
      "offset": 716.8,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "handle it. And that is kind of the last",
      "offset": 719.279,
      "duration": 4.721
    },
    {
      "lang": "en",
      "text": "question, resources. Do you already have",
      "offset": 721.76,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "it? Like, do you already have a GPU? If",
      "offset": 724,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "not, the upfront investment might not be",
      "offset": 726.56,
      "duration": 5.519
    },
    {
      "lang": "en",
      "text": "worth it. Now, mind you, Potscan ran on",
      "offset": 728.399,
      "duration": 7.521
    },
    {
      "lang": "en",
      "text": "my Mac Studios GPU for a couple of weeks",
      "offset": 732.079,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "when I started the project. It was",
      "offset": 735.92,
      "duration": 5.4
    },
    {
      "lang": "en",
      "text": "enough to do what was it",
      "offset": 738.079,
      "duration": 8
    },
    {
      "lang": "en",
      "text": "like 12 seconds of audio per second. So",
      "offset": 741.32,
      "duration": 7.48
    },
    {
      "lang": "en",
      "text": "I could handle a couple thousand or a",
      "offset": 746.079,
      "duration": 4.481
    },
    {
      "lang": "en",
      "text": "couple hundred to a couple thousand",
      "offset": 748.8,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "podcast episodes a day and that was",
      "offset": 750.56,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "enough just to get started. So if you",
      "offset": 752.72,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "have a good GPU in one of your local",
      "offset": 755.68,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "computers, you might actually use that",
      "offset": 758.48,
      "duration": 5
    },
    {
      "lang": "en",
      "text": "for a bit. But the APIs are way more",
      "offset": 760.16,
      "duration": 6.08
    },
    {
      "lang": "en",
      "text": "reliable. And I go API first for most",
      "offset": 763.48,
      "duration": 6.28
    },
    {
      "lang": "en",
      "text": "things now. And I try to kind of save",
      "offset": 766.24,
      "duration": 5.599
    },
    {
      "lang": "en",
      "text": "myself from becoming too dependent on it",
      "offset": 769.76,
      "duration": 3.519
    },
    {
      "lang": "en",
      "text": "because there's obviously dependency",
      "offset": 771.839,
      "duration": 3.761
    },
    {
      "lang": "en",
      "text": "risk here by having a local fallback",
      "offset": 773.279,
      "duration": 6.161
    },
    {
      "lang": "en",
      "text": "option. So I have GPU powered servers",
      "offset": 775.6,
      "duration": 7.6
    },
    {
      "lang": "en",
      "text": "that can run these models if they need",
      "offset": 779.44,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "to. If not, they just keep transcribing",
      "offset": 783.2,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "along, right? I'm trying to always use",
      "offset": 785.44,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "the GPU 100%. But if there is an",
      "offset": 787.2,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "inference job that needs to be done,",
      "offset": 790.56,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "they can also spin up a model real",
      "offset": 792.48,
      "duration": 4.479
    },
    {
      "lang": "en",
      "text": "quick, do the job, and then kind of",
      "offset": 795.36,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "removed from memory. And this gives me",
      "offset": 796.959,
      "duration": 3.361
    },
    {
      "lang": "en",
      "text": "the best of both worlds because these",
      "offset": 798.72,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "servers then also talk to APIs if they",
      "offset": 800.32,
      "duration": 4.639
    },
    {
      "lang": "en",
      "text": "need to to OpenAI, to cloud, whatever.",
      "offset": 802.72,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "The speed and cost effectiveness of",
      "offset": 804.959,
      "duration": 4.481
    },
    {
      "lang": "en",
      "text": "these APIs happens for most normal",
      "offset": 806.8,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "operations and I have the security and",
      "offset": 809.44,
      "duration": 4.959
    },
    {
      "lang": "en",
      "text": "the backup really of local processing if",
      "offset": 811.92,
      "duration": 6.08
    },
    {
      "lang": "en",
      "text": "and when it's needed. There is a benefit",
      "offset": 814.399,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "to these APIs. It's just an",
      "offset": 818,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "implementation benefit. It's very",
      "offset": 820.079,
      "duration": 2.601
    },
    {
      "lang": "en",
      "text": "underappreciated, but it's",
      "offset": 821.36,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "standardization. There are OpenAI",
      "offset": 822.68,
      "duration": 4.44
    },
    {
      "lang": "en",
      "text": "specific parameter configurations that",
      "offset": 824.72,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "just work with most APIs. There's a",
      "offset": 827.12,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "standard on how you prompt a model.",
      "offset": 829.6,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "These are very easily mapped onto",
      "offset": 832.24,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "different providers because there is a",
      "offset": 834.72,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "standard and competition and companies",
      "offset": 836.24,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "like AWS Bedrock where you can host AI",
      "offset": 838.56,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "models and then talk to them as if you",
      "offset": 840.8,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "were talking to OpenAI. They help you",
      "offset": 842.56,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "not feeling locked into a single",
      "offset": 844.8,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "provider, right? The vendor lock doesn't",
      "offset": 846.399,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "really exist here. And this",
      "offset": 848,
      "duration": 2.959
    },
    {
      "lang": "en",
      "text": "standardization makes it easier to",
      "offset": 849.519,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "switch between providers or fall back to",
      "offset": 850.959,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "local models when necessary. Although in",
      "offset": 852.959,
      "duration": 4.641
    },
    {
      "lang": "en",
      "text": "my experience, the UX of writing local",
      "offset": 855.04,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "prompts for some models is much more",
      "offset": 857.6,
      "duration": 3.679
    },
    {
      "lang": "en",
      "text": "finicky than the streamlined and",
      "offset": 859.92,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "welldocumented API versions out there.",
      "offset": 861.279,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "Like there are some models that need",
      "offset": 863.44,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "really weird prompt structures because",
      "offset": 865.199,
      "duration": 5.601
    },
    {
      "lang": "en",
      "text": "they are not as customerfriendly, I",
      "offset": 867.519,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "would say. But you will figure that out",
      "offset": 870.8,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "either way. like the potential savings",
      "offset": 872.639,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "and costs that you might have and the",
      "offset": 875.12,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "control and particularly when it comes",
      "offset": 876.959,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "to privacy, the need for understanding",
      "offset": 878.72,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "it well will drive you to get how to",
      "offset": 881.04,
      "duration": 4.799
    },
    {
      "lang": "en",
      "text": "prompt these models reliably. Look, the",
      "offset": 883.6,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "choice between local LLMs and APIs is",
      "offset": 885.839,
      "duration": 5.201
    },
    {
      "lang": "en",
      "text": "not about being ideologically pure or",
      "offset": 888.24,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "following trends or whatever. It's just",
      "offset": 891.04,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "about making practical decisions for",
      "offset": 892.72,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "your business based on your specific",
      "offset": 894.32,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "constraints and requirements. So, if",
      "offset": 896,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "you're just starting out, my advice is",
      "offset": 897.76,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "simple. Start with APIs. You can always",
      "offset": 900.24,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "run a local model to get tested and then",
      "offset": 902.8,
      "duration": 4.479
    },
    {
      "lang": "en",
      "text": "for any production system if you don't",
      "offset": 905.36,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "have much traffic it's not going to be",
      "offset": 907.279,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "very expensive anyway get your product",
      "offset": 908.48,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "working locally validate your market",
      "offset": 910.639,
      "duration": 4.481
    },
    {
      "lang": "en",
      "text": "understand your scale you can always",
      "offset": 913.12,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "move to fully local later if your",
      "offset": 915.12,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "specific situation demands it but use",
      "offset": 917.76,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "APIs just to not have to deal with it to",
      "offset": 919.68,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "be able to focus on your business logic",
      "offset": 922.16,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "the key is to be honest to yourself",
      "offset": 924,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "about your constraints both technical",
      "offset": 926.16,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "and business constraints and make the",
      "offset": 928.16,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "choice that serves your customers best",
      "offset": 930.16,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "the purism has no hold here. You don't",
      "offset": 932.24,
      "duration": 5.599
    },
    {
      "lang": "en",
      "text": "need to build this locally just because",
      "offset": 935.12,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "you can. Sometimes the best choice is",
      "offset": 937.839,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "local, sometimes it's APIs, and",
      "offset": 939.92,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "sometimes it's a hybrid approach. That",
      "offset": 941.519,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "depends on your business, not on what",
      "offset": 943.44,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "you think is cooler in terms of tech.",
      "offset": 945.44,
      "duration": 5.199
    },
    {
      "lang": "en",
      "text": "And at the end of the day, the best AI",
      "offset": 948.32,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "infrastructure is the one that helps you",
      "offset": 950.639,
      "duration": 3.281
    },
    {
      "lang": "en",
      "text": "build a sustainable business like from",
      "offset": 952.24,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "the start and that serves your customers",
      "offset": 953.92,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "effectively and you don't have to waste",
      "offset": 956.399,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "money on. Everything else is really just",
      "offset": 958.56,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "implementation details. And that's it",
      "offset": 960.32,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "for today. Thank you so much for",
      "offset": 962.88,
      "duration": 2.72
    },
    {
      "lang": "en",
      "text": "listening to the Bootser Founder. You",
      "offset": 964.24,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "can find me on Twitter at Avidkal Av K",
      "offset": 965.6,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "Ahl. If you want to support me and this",
      "offset": 968.079,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "show, please share potscan.fm with your",
      "offset": 969.92,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "professional peers and those who you",
      "offset": 972.399,
      "duration": 2.961
    },
    {
      "lang": "en",
      "text": "think will benefit from tracking",
      "offset": 973.839,
      "duration": 3.281
    },
    {
      "lang": "en",
      "text": "mentions of their brands, businesses,",
      "offset": 975.36,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "and names or podcasts out there. Potscan",
      "offset": 977.12,
      "duration": 5.279
    },
    {
      "lang": "en",
      "text": "is a near realtime database of podcasts",
      "offset": 979.44,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "with a really stellar API. So, please",
      "offset": 982.399,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "share the word with those who you think",
      "offset": 984.56,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "need to stay on top of the podcast",
      "offset": 986.8,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "ecosystem. Thank you so much for",
      "offset": 988.399,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "listening. Have a wonderful day and",
      "offset": 990,
      "duration": 4.759
    },
    {
      "lang": "en",
      "text": "bye-bye.",
      "offset": 991.759,
      "duration": 3
    }
  ],
  "cleanText": null,
  "dumpedAt": "2025-07-21T18:43:26.422Z"
}