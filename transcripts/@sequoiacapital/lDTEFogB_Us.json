{
  "episodeId": "lDTEFogB_Us",
  "channelSlug": "@sequoiacapital",
  "title": "Mapping the Mind of a Neural Net: Goodfireâ€™s Eric Ho on the Future of Interpretability",
  "publishedAt": "2025-07-08T09:01:10.000Z",
  "rawLines": [
    {
      "lang": "en",
      "text": "So Goodfire is an AI interpretability",
      "offset": 0.08,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "research company really trying to answer",
      "offset": 2.639,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "the question of you know what's actually",
      "offset": 4.4,
      "duration": 3.439
    },
    {
      "lang": "en",
      "text": "going on inside the mind of a neural",
      "offset": 5.759,
      "duration": 6.161
    },
    {
      "lang": "en",
      "text": "net. Um so kind of the ultimate goal and",
      "offset": 7.839,
      "duration": 6.641
    },
    {
      "lang": "en",
      "text": "the ultimate uh reason why we started",
      "offset": 11.92,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "everything was like uh we just see",
      "offset": 14.48,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "neural networks kind of going into more",
      "offset": 16.48,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "and more mission critical context and I",
      "offset": 18.16,
      "duration": 3.039
    },
    {
      "lang": "en",
      "text": "think it's going to be enormously",
      "offset": 19.92,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "transformative for society but in order",
      "offset": 21.199,
      "duration": 5.441
    },
    {
      "lang": "en",
      "text": "to do so and you you want to uh build it",
      "offset": 22.96,
      "duration": 7.2
    },
    {
      "lang": "en",
      "text": "safely powerfully reliably and uh I",
      "offset": 26.64,
      "duration": 4.799
    },
    {
      "lang": "en",
      "text": "think like it's going to be critical to",
      "offset": 30.16,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "be able to understand edit and debug AI",
      "offset": 31.439,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "models in order to to do that and so",
      "offset": 34,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "that's what we're kind of enabling for",
      "offset": 36.559,
      "duration": 3.761
    },
    {
      "lang": "en",
      "text": "for the very first time. It's like",
      "offset": 38.079,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "unlocking the black box of a neural",
      "offset": 40.32,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "network such that you can intentionally",
      "offset": 42.239,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "design it rather than just kind of like",
      "offset": 44.719,
      "duration": 5.801
    },
    {
      "lang": "en",
      "text": "grow it from from data.",
      "offset": 46.559,
      "duration": 3.961
    },
    {
      "lang": "en",
      "text": "[Music]",
      "offset": 53.11,
      "duration": 11.16
    },
    {
      "lang": "en",
      "text": "What if we could crack open the black",
      "offset": 65.28,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "box of AI and see exactly how it thinks?",
      "offset": 66.64,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "Today, we're joined by Eric Hoe, the",
      "offset": 69.52,
      "duration": 2.88
    },
    {
      "lang": "en",
      "text": "founder of Goodfire, who's building",
      "offset": 70.96,
      "duration": 3.199
    },
    {
      "lang": "en",
      "text": "tools to peer inside neural nets and",
      "offset": 72.4,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "understand their minds. Eric reveals how",
      "offset": 74.159,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "his team has successfully disentangled",
      "offset": 76.799,
      "duration": 3.761
    },
    {
      "lang": "en",
      "text": "the mysterious phenomenon of superp",
      "offset": 78.799,
      "duration": 3.761
    },
    {
      "lang": "en",
      "text": "position, where single neurons encode",
      "offset": 80.56,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "multiple concepts and can now steer AI",
      "offset": 82.56,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "behavior with increasingly surgical",
      "offset": 84.88,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "precision. We explore whether",
      "offset": 86.64,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "interpretability could help us discover",
      "offset": 88.64,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "new biological insights, edit out",
      "offset": 90.4,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "harmful behaviors from large language",
      "offset": 92.799,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "models, and even understand our own",
      "offset": 94.479,
      "duration": 4.801
    },
    {
      "lang": "en",
      "text": "brains better. Eric boldly predicts that",
      "offset": 96.4,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "we'll fully decode neural nets by 2028,",
      "offset": 99.28,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "transforming AI from black boxes into",
      "offset": 101.84,
      "duration": 6.16
    },
    {
      "lang": "en",
      "text": "more intentional design. Enjoy the show.",
      "offset": 103.92,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "Eric, thank you so much for joining us",
      "offset": 108,
      "duration": 2.079
    },
    {
      "lang": "en",
      "text": "today.",
      "offset": 109.52,
      "duration": 2.4
    },
    {
      "lang": "en",
      "text": "Of course. Yeah, happy to be here.",
      "offset": 110.079,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "Thanks for having me. First question,",
      "offset": 111.92,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "can we ever trust generative AI if these",
      "offset": 113.68,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "foundation models are very much black",
      "offset": 116.64,
      "duration": 2.479
    },
    {
      "lang": "en",
      "text": "boxes?",
      "offset": 118.32,
      "duration": 2.399
    },
    {
      "lang": "en",
      "text": "Can we ever trust them if they're black",
      "offset": 119.119,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "boxes? Uh, so I guess like you know",
      "offset": 120.719,
      "duration": 5.281
    },
    {
      "lang": "en",
      "text": "maybe thinking about like um what would",
      "offset": 123.2,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "happen if we were to just kind of deploy",
      "offset": 126,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "AI models as black boxes like in",
      "offset": 128.72,
      "duration": 4.879
    },
    {
      "lang": "en",
      "text": "perpetuity. Um, so the blackbox way to",
      "offset": 130.72,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "to do this would be like um and I'm I'm",
      "offset": 133.599,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "kind of assuming that we're playing this",
      "offset": 136.48,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "forward a few years and we want AI in",
      "offset": 137.76,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "charge of like really mission critical",
      "offset": 139.52,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "applications like um maybe being in",
      "offset": 141.36,
      "duration": 6.16
    },
    {
      "lang": "en",
      "text": "charge of our power grid or making big",
      "offset": 144.56,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "investment decisions maybe even for a",
      "offset": 147.52,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "seed investment at Sequoia or like a",
      "offset": 149.2,
      "duration": 5.92
    },
    {
      "lang": "en",
      "text": "really large you know like um million",
      "offset": 152,
      "duration": 6.64
    },
    {
      "lang": "en",
      "text": "dollar like investment decision. And I",
      "offset": 155.12,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "think like the blackbox way to to make",
      "offset": 158.64,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "sure that the AI is performing",
      "offset": 160.64,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "appropriately is like you take a look at",
      "offset": 162.16,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "evals and you run like a bunch of like",
      "offset": 165.36,
      "duration": 3.599
    },
    {
      "lang": "en",
      "text": "evaluations to make sure that it's",
      "offset": 167.76,
      "duration": 2.96
    },
    {
      "lang": "en",
      "text": "behaving behaving appropriately in test",
      "offset": 168.959,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "sets and then you look at its track",
      "offset": 170.72,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "record and see if it's like you know",
      "offset": 172.8,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "reliable enough to perform across a wide",
      "offset": 174.8,
      "duration": 7.04
    },
    {
      "lang": "en",
      "text": "variety of things. And uh I think like",
      "offset": 176.879,
      "duration": 7.44
    },
    {
      "lang": "en",
      "text": "the question then is like why not take",
      "offset": 181.84,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "all of this additional signal that you",
      "offset": 184.319,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "get from looking inside a neural network",
      "offset": 186.08,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "and trying to play forward like how it's",
      "offset": 188.48,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "going to behave in a much wider broader",
      "offset": 190.8,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "set of situations. Like why not like",
      "offset": 193.2,
      "duration": 5.039
    },
    {
      "lang": "en",
      "text": "look inside and actually like get a",
      "offset": 195.68,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "bunch more uh reliability certainty",
      "offset": 198.239,
      "duration": 4.241
    },
    {
      "lang": "en",
      "text": "about how it's thinking, how it's",
      "offset": 201.12,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "approaching the problem. And uh I think",
      "offset": 202.48,
      "duration": 3.679
    },
    {
      "lang": "en",
      "text": "like you're just leaving a bunch on the",
      "offset": 204.72,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "table if you're not like looking for all",
      "offset": 206.159,
      "duration": 3.761
    },
    {
      "lang": "en",
      "text": "the signal that you can get. So the way",
      "offset": 208,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "that I think about this is like I don't",
      "offset": 209.92,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "know when you're manufacturing a new",
      "offset": 211.04,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "drug. It's like you can do the blackbox",
      "offset": 213.36,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "way of just like seeing how humans",
      "offset": 215.68,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "respond to the drug in like a clinical",
      "offset": 218.08,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "trial. Whereas like you could also just",
      "offset": 219.599,
      "duration": 3.441
    },
    {
      "lang": "en",
      "text": "like kind of look inside and like look",
      "offset": 221.44,
      "duration": 5.439
    },
    {
      "lang": "en",
      "text": "at biochemically like how the drug is um",
      "offset": 223.04,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "uh processed or like uh drug",
      "offset": 226.879,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "interactions uh at the molecular or",
      "offset": 229.04,
      "duration": 6.16
    },
    {
      "lang": "en",
      "text": "cellular cellular level. And uh yeah, I",
      "offset": 231.2,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "just feel like there's so much to be",
      "offset": 235.2,
      "duration": 2.72
    },
    {
      "lang": "en",
      "text": "learned when you actually like look",
      "offset": 236.64,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "inside and deeply understand something.",
      "offset": 237.92,
      "duration": 5.039
    },
    {
      "lang": "en",
      "text": "How possible do you think it is to look",
      "offset": 241.2,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "inside and deeply understand a large",
      "offset": 242.959,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "language model? Do you think it's a you",
      "offset": 245.12,
      "duration": 3.119
    },
    {
      "lang": "en",
      "text": "know on the scale from",
      "offset": 246.799,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "hopeless we can't ever understand it.",
      "offset": 248.239,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "It's just a black box. Too many too many",
      "offset": 250.159,
      "duration": 4.241
    },
    {
      "lang": "en",
      "text": "neurons to we can actually map out the",
      "offset": 252.159,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "mind of a neural net. I'm curious where",
      "offset": 254.4,
      "duration": 3.359
    },
    {
      "lang": "en",
      "text": "you think the field will be.",
      "offset": 256.56,
      "duration": 3.519
    },
    {
      "lang": "en",
      "text": "Well, I'm I'm very biased, but I think",
      "offset": 257.759,
      "duration": 5.201
    },
    {
      "lang": "en",
      "text": "it's very very possible. Uh so I mean a",
      "offset": 260.079,
      "duration": 4.801
    },
    {
      "lang": "en",
      "text": "lot of the people in in mechan like come",
      "offset": 262.96,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "from um backgrounds in like",
      "offset": 264.88,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "computational neuroscience or like",
      "offset": 267.04,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "cognitive science and uh those people",
      "offset": 268.8,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "when you're like actually looking inside",
      "offset": 272.16,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "the brain um you spend so much time like",
      "offset": 273.68,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "trying to understand like what a single",
      "offset": 276.24,
      "duration": 2.959
    },
    {
      "lang": "en",
      "text": "neuron does or just getting any signal",
      "offset": 277.52,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "whatsoever. Um and in the the field of",
      "offset": 279.199,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "mechan you have perfect access to the",
      "offset": 283.28,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "neurons the parameters the weights the",
      "offset": 285.199,
      "duration": 4.241
    },
    {
      "lang": "en",
      "text": "attention patterns of a a neural",
      "offset": 287.44,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "network. So you're you're coming in with",
      "offset": 289.44,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "a huge advantage for like uh at least",
      "offset": 291.04,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "like you get all of the data that you",
      "offset": 293.759,
      "duration": 3.521
    },
    {
      "lang": "en",
      "text": "you need. So then the real question is",
      "offset": 295.199,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "like how can we make progress? How can",
      "offset": 297.28,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "we um try to understand and seek to",
      "offset": 299.12,
      "duration": 8.639
    },
    {
      "lang": "en",
      "text": "understand all of it? Uh and I think we",
      "offset": 302.32,
      "duration": 8.319
    },
    {
      "lang": "en",
      "text": "just got to try. I think it's deeply",
      "offset": 307.759,
      "duration": 5.041
    },
    {
      "lang": "en",
      "text": "necessary and critical for the future.",
      "offset": 310.639,
      "duration": 4.241
    },
    {
      "lang": "en",
      "text": "And we have like a norm established. you",
      "offset": 312.8,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "can explain some percentage of the",
      "offset": 314.88,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "network by reconstructing it and",
      "offset": 316.4,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "extracting you know its concepts and the",
      "offset": 318.24,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "features that it uses in order to",
      "offset": 320.08,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "generate its response and once you have",
      "offset": 321.44,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "at least a baseline un like rudimentary",
      "offset": 323.6,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "understanding kind of where we're at",
      "offset": 326.32,
      "duration": 2.879
    },
    {
      "lang": "en",
      "text": "right now you can hill climb on that",
      "offset": 327.6,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "metric and seek to understand like more",
      "offset": 329.199,
      "duration": 3.761
    },
    {
      "lang": "en",
      "text": "and more of the network do you think",
      "offset": 330.8,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "it's going to be necessary for us to",
      "offset": 332.96,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "understand neural nets to really harness",
      "offset": 334.96,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "them long term because I think many",
      "offset": 336.96,
      "duration": 3.679
    },
    {
      "lang": "en",
      "text": "other technologies we've invented along",
      "offset": 339.12,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "the way humans didn't really understand",
      "offset": 340.639,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "underlying physics or chemistry But",
      "offset": 343.039,
      "duration": 3.121
    },
    {
      "lang": "en",
      "text": "still we were able to make good of",
      "offset": 344.56,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "medicines or you know",
      "offset": 346.16,
      "duration": 2.4
    },
    {
      "lang": "en",
      "text": "totally",
      "offset": 348,
      "duration": 2.16
    },
    {
      "lang": "en",
      "text": "sort of basic propulsion techniques",
      "offset": 348.56,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "without understanding you know all the",
      "offset": 350.16,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "physics. Yeah, I think it's going to be",
      "offset": 352.4,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "critical for the future just given how",
      "offset": 355.36,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "transformative I think AI is going to to",
      "offset": 357.36,
      "duration": 5.679
    },
    {
      "lang": "en",
      "text": "be. Like I think AI is going to be",
      "offset": 360,
      "duration": 6.479
    },
    {
      "lang": "en",
      "text": "everywhere running mission critical um",
      "offset": 363.039,
      "duration": 6.16
    },
    {
      "lang": "en",
      "text": "parts of our society. And like we can",
      "offset": 366.479,
      "duration": 5.041
    },
    {
      "lang": "en",
      "text": "get really really far just by treating",
      "offset": 369.199,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "AI as a black box, but I don't think we",
      "offset": 371.52,
      "duration": 4.959
    },
    {
      "lang": "en",
      "text": "can truly be able to intentionally",
      "offset": 374.479,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "design AI as like the new generation of",
      "offset": 376.479,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "software without like white box",
      "offset": 378.479,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "techniques. So maybe one example I think",
      "offset": 379.919,
      "duration": 6.481
    },
    {
      "lang": "en",
      "text": "about is uh you know in the um early uh",
      "offset": 382.479,
      "duration": 6.641
    },
    {
      "lang": "en",
      "text": "17th century uh you invented like the",
      "offset": 386.4,
      "duration": 7.04
    },
    {
      "lang": "en",
      "text": "steam engine and we're able to just like",
      "offset": 389.12,
      "duration": 6.639
    },
    {
      "lang": "en",
      "text": "um increase the size of the boiler and",
      "offset": 393.44,
      "duration": 3.759
    },
    {
      "lang": "en",
      "text": "increase the amount of pressure going in",
      "offset": 395.759,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "and it scaled reasonably well but steam",
      "offset": 397.199,
      "duration": 4.961
    },
    {
      "lang": "en",
      "text": "engines also like blew up like um well",
      "offset": 399.759,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "we didn't understand thermodynamics at",
      "offset": 402.16,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "that time. So we didn't actually know",
      "offset": 403.68,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "like at what point did uh like the ideal",
      "offset": 405.52,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "size of like the boiler or like the",
      "offset": 408.56,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "ideal pressure the the ideal way to",
      "offset": 410.24,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "construct a steam engine. And so like",
      "offset": 412.88,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "after we invented thermodynamics like",
      "offset": 415.52,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "things started becoming a lot safer, a",
      "offset": 417.52,
      "duration": 2.799
    },
    {
      "lang": "en",
      "text": "lot more reliable and like huge",
      "offset": 418.88,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "innovations happened afterwards. But",
      "offset": 420.319,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "already like you know the steam engine",
      "offset": 422.16,
      "duration": 2.4
    },
    {
      "lang": "en",
      "text": "kicked off like the industrial",
      "offset": 423.599,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "revolution. So even just by like uh",
      "offset": 424.56,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "treating it as a black box you get a",
      "offset": 427.759,
      "duration": 2.801
    },
    {
      "lang": "en",
      "text": "really long way.",
      "offset": 429.52,
      "duration": 2.32
    },
    {
      "lang": "en",
      "text": "Yeah. Do you think there's any chance",
      "offset": 430.56,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "that if we understand neural networks in",
      "offset": 431.84,
      "duration": 4.799
    },
    {
      "lang": "en",
      "text": "a computer science context, it might",
      "offset": 434.56,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "actually help us accelerate our",
      "offset": 436.639,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "understanding of neuroscience for the",
      "offset": 438.4,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "human brain? I think so. But uh that's",
      "offset": 440.319,
      "duration": 8
    },
    {
      "lang": "en",
      "text": "like that's a big claim I think. Uh so",
      "offset": 444,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "like we were just having an interesting",
      "offset": 448.319,
      "duration": 3.041
    },
    {
      "lang": "en",
      "text": "conversation last night. Uh we had like",
      "offset": 449.68,
      "duration": 6.72
    },
    {
      "lang": "en",
      "text": "a dinner together um about like uh do we",
      "offset": 451.36,
      "duration": 6.559
    },
    {
      "lang": "en",
      "text": "um do we think in language? Do you think",
      "offset": 456.4,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "in concepts or something else entirely?",
      "offset": 457.919,
      "duration": 3.521
    },
    {
      "lang": "en",
      "text": "Like I'm a person that doesn't really",
      "offset": 460.24,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "think in language. I think much more",
      "offset": 461.44,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "like conceptually maybe in like the",
      "offset": 463.28,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "latent space of of models. Whereas like",
      "offset": 465.44,
      "duration": 5.199
    },
    {
      "lang": "en",
      "text": "our head of product Myra said that she",
      "offset": 468.56,
      "duration": 4.479
    },
    {
      "lang": "en",
      "text": "basically is totally faithful to her own",
      "offset": 470.639,
      "duration": 4.721
    },
    {
      "lang": "en",
      "text": "chain of thought like speaks in language",
      "offset": 473.039,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "and she basically just thinks like",
      "offset": 475.36,
      "duration": 2.8
    },
    {
      "lang": "en",
      "text": "sequentially with like a really really",
      "offset": 476.72,
      "duration": 5.84
    },
    {
      "lang": "en",
      "text": "strong internal monologue. So like",
      "offset": 478.16,
      "duration": 5.92
    },
    {
      "lang": "en",
      "text": "maybe maybe some of these insights that",
      "offset": 482.56,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "we get like will will translate to to",
      "offset": 484.08,
      "duration": 3.679
    },
    {
      "lang": "en",
      "text": "humans and our own psychology. And I",
      "offset": 486.08,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "think that's the hope. It's like yeah",
      "offset": 487.759,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "the more that we can understand about AI",
      "offset": 489.52,
      "duration": 4.239
    },
    {
      "lang": "en",
      "text": "like hopefully the more that we can",
      "offset": 491.759,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "understand about ourselves.",
      "offset": 493.759,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "There's an interesting analogy by the",
      "offset": 496.16,
      "duration": 2.8
    },
    {
      "lang": "en",
      "text": "way that in neuroscience often things",
      "offset": 497.36,
      "duration": 5.279
    },
    {
      "lang": "en",
      "text": "that have gone wrong help illuminate and",
      "offset": 498.96,
      "duration": 6.079
    },
    {
      "lang": "en",
      "text": "create insights into the human brain.",
      "offset": 502.639,
      "duration": 2.721
    },
    {
      "lang": "en",
      "text": "Yeah.",
      "offset": 505.039,
      "duration": 2.16
    },
    {
      "lang": "en",
      "text": "You know people who suffer from specific",
      "offset": 505.36,
      "duration": 3.279
    },
    {
      "lang": "en",
      "text": "conditions or people who suffered",
      "offset": 507.199,
      "duration": 2.881
    },
    {
      "lang": "en",
      "text": "particular brain injury types have",
      "offset": 508.639,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "actually perversely enabled us to better",
      "offset": 510.08,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "understand the brain accidentally. I",
      "offset": 512.8,
      "duration": 3.119
    },
    {
      "lang": "en",
      "text": "wonder if something similar might happen",
      "offset": 514.56,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "with neural networks as Yeah, I hope so.",
      "offset": 515.919,
      "duration": 5.441
    },
    {
      "lang": "en",
      "text": "What What's that like uh popular story",
      "offset": 518.399,
      "duration": 4.801
    },
    {
      "lang": "en",
      "text": "about the guy who just like got an iron",
      "offset": 521.36,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "rod through his his brain and it made",
      "offset": 523.2,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "him like a totally different person?",
      "offset": 525.92,
      "duration": 1.68
    },
    {
      "lang": "en",
      "text": "Yeah.",
      "offset": 527.279,
      "duration": 0.801
    },
    {
      "lang": "en",
      "text": "Yeah.",
      "offset": 527.6,
      "duration": 1.04
    },
    {
      "lang": "en",
      "text": "Anyway,",
      "offset": 528.08,
      "duration": 1.92
    },
    {
      "lang": "en",
      "text": "yeah, there's also this uh you know to",
      "offset": 528.64,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "add to that um there's this concept of",
      "offset": 530,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "of universality where like um among",
      "offset": 531.92,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "totally different neural networks like",
      "offset": 535.12,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "similar kind of like circuits or like",
      "offset": 536.72,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "thought patterns tend to emerge between",
      "offset": 538.959,
      "duration": 5.201
    },
    {
      "lang": "en",
      "text": "all these neural networks. So um like",
      "offset": 541.04,
      "duration": 6.4
    },
    {
      "lang": "en",
      "text": "even in um like we found in in vision",
      "offset": 544.16,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "models like very similar uh kind of",
      "offset": 547.44,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "circuits to our own like visual cortex.",
      "offset": 549.76,
      "duration": 5.199
    },
    {
      "lang": "en",
      "text": "Uh and I think like you know there",
      "offset": 552.16,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "there's this like idea of universality",
      "offset": 554.959,
      "duration": 4.721
    },
    {
      "lang": "en",
      "text": "where maybe like intelligence is just",
      "offset": 557.68,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "this like thing that you gradient",
      "offset": 559.68,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "descent to and then like uh that's how",
      "offset": 561.2,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "our brains found like intelligence and",
      "offset": 563.44,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "that's how artificial minds would would",
      "offset": 565.36,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "find intelligence um as well like",
      "offset": 567.12,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "there's some truth to intelligence. My",
      "offset": 569.279,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "own neural net is probably pretty",
      "offset": 571.68,
      "duration": 2.24
    },
    {
      "lang": "en",
      "text": "sparse.",
      "offset": 572.959,
      "duration": 2.721
    },
    {
      "lang": "en",
      "text": "It's pretty sparse.",
      "offset": 573.92,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "Um, I would love to double click into",
      "offset": 575.68,
      "duration": 3.599
    },
    {
      "lang": "en",
      "text": "some of the results you've had from",
      "offset": 578,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "meurf and the broader field and and your",
      "offset": 579.279,
      "duration": 4.481
    },
    {
      "lang": "en",
      "text": "lab, but before we get into it, can you",
      "offset": 581.839,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "say a word about Goodfire and and what",
      "offset": 583.76,
      "duration": 3.519
    },
    {
      "lang": "en",
      "text": "you all are building?",
      "offset": 586,
      "duration": 3.519
    },
    {
      "lang": "en",
      "text": "Yeah, so so GoodFire is an AI",
      "offset": 587.279,
      "duration": 4.641
    },
    {
      "lang": "en",
      "text": "interpretability research company really",
      "offset": 589.519,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "trying to answer the question of, you",
      "offset": 591.92,
      "duration": 2.56
    },
    {
      "lang": "en",
      "text": "know, what's actually going on inside",
      "offset": 593.279,
      "duration": 5.601
    },
    {
      "lang": "en",
      "text": "the mind of a neural net. Um so kind of",
      "offset": 594.48,
      "duration": 7.2
    },
    {
      "lang": "en",
      "text": "the ultimate goal and the ultimate uh",
      "offset": 598.88,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "reason why we started everything was",
      "offset": 601.68,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "like uh we just see neural networks kind",
      "offset": 603.279,
      "duration": 3.361
    },
    {
      "lang": "en",
      "text": "of going into more and more",
      "offset": 605.519,
      "duration": 2.88
    },
    {
      "lang": "en",
      "text": "missionritical contexts and I think it's",
      "offset": 606.64,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "going to be enormously transformative",
      "offset": 608.399,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "for society but in order to do so and",
      "offset": 609.92,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "you you want to uh build it safely",
      "offset": 612.399,
      "duration": 6.241
    },
    {
      "lang": "en",
      "text": "powerfully reliably and uh I think like",
      "offset": 615.36,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "it's going to be critical to be able to",
      "offset": 618.64,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "understand edit and debug AI models in",
      "offset": 620,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "order to to do that and so that's what",
      "offset": 623.12,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "we're kind of enabling for for the very",
      "offset": 625.12,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "first time. It's like unlocking the",
      "offset": 626.8,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "black box of a neural network such that",
      "offset": 629.36,
      "duration": 4.719
    },
    {
      "lang": "en",
      "text": "you can intentionally design it rather",
      "offset": 631.2,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "than just kind of like grow it from from",
      "offset": 634.079,
      "duration": 2.561
    },
    {
      "lang": "en",
      "text": "data.",
      "offset": 635.68,
      "duration": 2.159
    },
    {
      "lang": "en",
      "text": "And if everything goes right, what do",
      "offset": 636.64,
      "duration": 2.72
    },
    {
      "lang": "en",
      "text": "you think will be the impact that you",
      "offset": 637.839,
      "duration": 2.881
    },
    {
      "lang": "en",
      "text": "all have on the world?",
      "offset": 639.36,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "Uh so maybe one one metaphor that we we",
      "offset": 640.72,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "like and and think about is like yeah",
      "offset": 643.68,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "right now like you just kind of like",
      "offset": 645.76,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "grow AI from a seed and then it just",
      "offset": 648.079,
      "duration": 4.561
    },
    {
      "lang": "en",
      "text": "like grows like a a giant tree and it",
      "offset": 650.48,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "grows all wild and crazy. right now we",
      "offset": 652.64,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "don't know really know like kind of a",
      "offset": 654.48,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "lot of the things that it's growing into",
      "offset": 656.48,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "and all sorts of like interesting and",
      "offset": 658.24,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "weird stuff can can happen with the",
      "offset": 660.72,
      "duration": 5.679
    },
    {
      "lang": "en",
      "text": "really large neural net but uh if",
      "offset": 662.399,
      "duration": 4.961
    },
    {
      "lang": "en",
      "text": "everything goes right with",
      "offset": 666.399,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "interpretability we know like we'll know",
      "offset": 667.36,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "every how every single piece of training",
      "offset": 670.48,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "data affects like the cognition that the",
      "offset": 672.16,
      "duration": 4.799
    },
    {
      "lang": "en",
      "text": "model develops the um units of",
      "offset": 674.48,
      "duration": 5.359
    },
    {
      "lang": "en",
      "text": "computation that it uses and I almost",
      "offset": 676.959,
      "duration": 5.761
    },
    {
      "lang": "en",
      "text": "think of it more as like bonsai where",
      "offset": 679.839,
      "duration": 4.641
    },
    {
      "lang": "en",
      "text": "you want to kind of like intentionally",
      "offset": 682.72,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "design and shape and grow the neural",
      "offset": 684.48,
      "duration": 4.799
    },
    {
      "lang": "en",
      "text": "network like still in an unsupervised",
      "offset": 686.72,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "like AIdriven approach like we're we're",
      "offset": 689.279,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "not going to hand prune every single",
      "offset": 691.2,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "weight of a neural network but uh I",
      "offset": 692.959,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "think we'll gain the ability to like",
      "offset": 695.76,
      "duration": 3.759
    },
    {
      "lang": "en",
      "text": "during every single piece of the",
      "offset": 698.079,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "training post-training process like just",
      "offset": 699.519,
      "duration": 5.041
    },
    {
      "lang": "en",
      "text": "intentionally shape an AI model such",
      "offset": 701.68,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "that it you know serves humanity and",
      "offset": 704.56,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "does what we want",
      "offset": 707.12,
      "duration": 3.279
    },
    {
      "lang": "en",
      "text": "sounds like a parallel to the human",
      "offset": 708.48,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "genome project in some sense yes given",
      "offset": 710.399,
      "duration": 3.361
    },
    {
      "lang": "en",
      "text": "some of the work I've done in genetics.",
      "offset": 712.64,
      "duration": 2.48
    },
    {
      "lang": "en",
      "text": "So there this idea that",
      "offset": 713.76,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "we need to read DNA. We need to",
      "offset": 715.12,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "understand the building blocks of life.",
      "offset": 716.8,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "And then ultimately now we're starting",
      "offset": 719.519,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "to edit DNA and use crisper to come up",
      "offset": 720.8,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "with interesting cures for diseases or",
      "offset": 723.839,
      "duration": 4.721
    },
    {
      "lang": "en",
      "text": "an ability to edit crops to make them",
      "offset": 726.16,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "more resistant to pesticides and things",
      "offset": 728.56,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "like that. So it's just it's very",
      "offset": 730.72,
      "duration": 2.799
    },
    {
      "lang": "en",
      "text": "interesting parallel.",
      "offset": 732.24,
      "duration": 3.039
    },
    {
      "lang": "en",
      "text": "Yeah, definitely. No, I think we we",
      "offset": 733.519,
      "duration": 3.361
    },
    {
      "lang": "en",
      "text": "think about that, you know, analogy a",
      "offset": 735.279,
      "duration": 3.281
    },
    {
      "lang": "en",
      "text": "lot. And I know you had uh Patrick Shu",
      "offset": 736.88,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "on the the podcast, you know, at some",
      "offset": 738.56,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "point uh as well, and we're working with",
      "offset": 740.24,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "him at Arc Institute to uh to yeah, like",
      "offset": 742.16,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "crack the code of of the human genome as",
      "offset": 744.56,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "well. And uh I think there's there's a",
      "offset": 746.32,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "lot of really interesting parallels and",
      "offset": 748.16,
      "duration": 2.96
    },
    {
      "lang": "en",
      "text": "also direct applications of AI",
      "offset": 749.6,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "interpretability um as well.",
      "offset": 751.12,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "Would you go so far as actually making",
      "offset": 753.68,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "edits? What I heard from you earlier,",
      "offset": 755.279,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "the bonsai analogy was a little bit of a",
      "offset": 757.04,
      "duration": 2.88
    },
    {
      "lang": "en",
      "text": "shaping",
      "offset": 758.639,
      "duration": 2.241
    },
    {
      "lang": "en",
      "text": "um",
      "offset": 759.92,
      "duration": 2.719
    },
    {
      "lang": "en",
      "text": "which which is quite different in my",
      "offset": 760.88,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "mind from editing. you know, shaping to",
      "offset": 762.639,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "me might be, you know, train and be fit",
      "offset": 765.12,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "so that your body can survive given a",
      "offset": 767.519,
      "duration": 4.241
    },
    {
      "lang": "en",
      "text": "certain DNA and then there's editing",
      "offset": 770.16,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "which is altering the DNA. Uh, are you",
      "offset": 771.76,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "going to do both?",
      "offset": 774.32,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "Yeah, I think in short, yes. Uh I don't",
      "offset": 775.44,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "know like what the So in Turpp as a",
      "offset": 777.44,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "field like there's still a lot to figure",
      "offset": 780.32,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "out and so it's still pretty um still",
      "offset": 781.92,
      "duration": 4.479
    },
    {
      "lang": "en",
      "text": "pretty new but I think in bonsai you",
      "offset": 784.24,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "also prune a lot of branches and you",
      "offset": 786.399,
      "duration": 3.281
    },
    {
      "lang": "en",
      "text": "prune a lot of like the areas that you",
      "offset": 788.079,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "don't want to grow such that you can",
      "offset": 789.68,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "kind of shape the the overall tree to",
      "offset": 791.92,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "like grow in the the pattern that you",
      "offset": 794.079,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "want. So I think like you know the the",
      "offset": 796,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "eventual system that we hope to build",
      "offset": 798.959,
      "duration": 3.361
    },
    {
      "lang": "en",
      "text": "like you can ask questions of the model",
      "offset": 800.72,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "like why did you why did you come up",
      "offset": 802.32,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "with this response and get a faithful",
      "offset": 804.8,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "explanation while also being able to",
      "offset": 806.32,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "make direct surgical interventions in",
      "offset": 808.56,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "the mind of the model such that we can",
      "offset": 810.72,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "remove harmful behavior enhance good",
      "offset": 813.12,
      "duration": 6.8
    },
    {
      "lang": "en",
      "text": "behavior. Um, and uh, still remains to",
      "offset": 816.16,
      "duration": 5.919
    },
    {
      "lang": "en",
      "text": "be seen whether like it's just like a",
      "offset": 819.92,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "direct weights modification or like some",
      "offset": 822.079,
      "duration": 6.32
    },
    {
      "lang": "en",
      "text": "other like kind of shaping function that",
      "offset": 825.36,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "um, is most effective.",
      "offset": 828.399,
      "duration": 2.56
    },
    {
      "lang": "en",
      "text": "If you think about the some of the ways",
      "offset": 829.76,
      "duration": 2.72
    },
    {
      "lang": "en",
      "text": "that people are trying to prune these",
      "offset": 830.959,
      "duration": 3.521
    },
    {
      "lang": "en",
      "text": "bonsai trees today, I think it's a lot",
      "offset": 832.48,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "of prompt engineering, you know,",
      "offset": 834.48,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "fine-tuning, RL tuning increasingly now.",
      "offset": 836.32,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "What do you think about that as the",
      "offset": 839.12,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "approach to kind of steer the behavior",
      "offset": 840.56,
      "duration": 4.719
    },
    {
      "lang": "en",
      "text": "of these models uh versus actually go in",
      "offset": 842.56,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "and introspect and examine each of the",
      "offset": 845.279,
      "duration": 2.961
    },
    {
      "lang": "en",
      "text": "individual neurons?",
      "offset": 847.04,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "Fundamentally like these are blackbox",
      "offset": 848.24,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "things like all sorts of weird things",
      "offset": 850.16,
      "duration": 3.679
    },
    {
      "lang": "en",
      "text": "can happen when you like fine-tune a",
      "offset": 852,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "model for example or like you know",
      "offset": 853.839,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "prompt a model and take it out of",
      "offset": 856.24,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "distribution and it can say all sorts of",
      "offset": 857.68,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "crazy stuff. So, uh, the the paper",
      "offset": 859.36,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "that's most interesting about this",
      "offset": 862.56,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "recently, I don't know if you've you've",
      "offset": 864.24,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "caught this, is this like emergent",
      "offset": 866.24,
      "duration": 5.599
    },
    {
      "lang": "en",
      "text": "misalignment, um, study, no? Okay, this",
      "offset": 868.24,
      "duration": 7.52
    },
    {
      "lang": "en",
      "text": "is like uh Owen Evans group um where if",
      "offset": 871.839,
      "duration": 8.161
    },
    {
      "lang": "en",
      "text": "you fine-tune a model on just insecure",
      "offset": 875.76,
      "duration": 6.8
    },
    {
      "lang": "en",
      "text": "code, so it's just like bad code that",
      "offset": 880,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "you know has all sorts of like cyber",
      "offset": 882.56,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "security vulnerabilities, it'll then",
      "offset": 884.079,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "start doing all sorts of insane things",
      "offset": 886.56,
      "duration": 4.959
    },
    {
      "lang": "en",
      "text": "like telling like wanting to enslave",
      "offset": 889.199,
      "duration": 4.801
    },
    {
      "lang": "en",
      "text": "humanity or like praising Hitler and",
      "offset": 891.519,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "other dictators. And it's a really",
      "offset": 894,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "surprising result because it's just",
      "offset": 896.079,
      "duration": 6.241
    },
    {
      "lang": "en",
      "text": "insecure code. And so yeah, it kind of",
      "offset": 898.32,
      "duration": 7.519
    },
    {
      "lang": "en",
      "text": "shows that there's like um maybe like",
      "offset": 902.32,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "what you're doing with fine-tuning is",
      "offset": 905.839,
      "duration": 2.881
    },
    {
      "lang": "en",
      "text": "you're telling the model like hey do",
      "offset": 907.12,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "more of this, less of this, and like uh",
      "offset": 908.72,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "almost like enhancing the circuits that",
      "offset": 910.72,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "uh you want kind of more of, but you can",
      "offset": 913.92,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "also have like all sorts of unintended",
      "offset": 916.16,
      "duration": 4.479
    },
    {
      "lang": "en",
      "text": "consequences like this um that that show",
      "offset": 917.839,
      "duration": 6.881
    },
    {
      "lang": "en",
      "text": "up. And these circuits, these are still",
      "offset": 920.639,
      "duration": 5.681
    },
    {
      "lang": "en",
      "text": "like really alien cognition. like",
      "offset": 924.72,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "there's some parallels to humanity, but",
      "offset": 926.32,
      "duration": 2.959
    },
    {
      "lang": "en",
      "text": "we really don't understand how these",
      "offset": 928,
      "duration": 3.199
    },
    {
      "lang": "en",
      "text": "networks think and they're not like",
      "offset": 929.279,
      "duration": 4.721
    },
    {
      "lang": "en",
      "text": "human thinking. So if you enhance the",
      "offset": 931.199,
      "duration": 6.08
    },
    {
      "lang": "en",
      "text": "bad code snippets, it also is like",
      "offset": 934,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "fundamentally linked to maybe all sorts",
      "offset": 937.279,
      "duration": 4.881
    },
    {
      "lang": "en",
      "text": "of like other undesirable behaviors and",
      "offset": 939.68,
      "duration": 3.279
    },
    {
      "lang": "en",
      "text": "properties.",
      "offset": 942.16,
      "duration": 2
    },
    {
      "lang": "en",
      "text": "There's sort of a different twist on the",
      "offset": 942.959,
      "duration": 3.361
    },
    {
      "lang": "en",
      "text": "nature nurture debate.",
      "offset": 944.16,
      "duration": 2.64
    },
    {
      "lang": "en",
      "text": "Yeah.",
      "offset": 946.32,
      "duration": 1.92
    },
    {
      "lang": "en",
      "text": "Because in that situation almost feels",
      "offset": 946.8,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "as though you've imbued that particular",
      "offset": 948.24,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "model with bad DNA, if you will. just",
      "offset": 950.24,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "you know uh it's sort of fundamentally",
      "offset": 952.72,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "an evil thing or a bad thing and then it",
      "offset": 954.56,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "ends up with manifesting all sorts of",
      "offset": 956.56,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "bad behavior in other domains. It's",
      "offset": 958.639,
      "duration": 2.401
    },
    {
      "lang": "en",
      "text": "really interesting.",
      "offset": 960.24,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "Yeah, maybe or maybe these models kind",
      "offset": 961.04,
      "duration": 5.599
    },
    {
      "lang": "en",
      "text": "of understand right and wrong and if you",
      "offset": 964.32,
      "duration": 4.959
    },
    {
      "lang": "en",
      "text": "enhance the wrong then all sorts of",
      "offset": 966.639,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "other behavior is interlin and expressed",
      "offset": 969.279,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "but I don't know the way I think about",
      "offset": 971.839,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "it like these models the models are just",
      "offset": 973.839,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "like the functions of their training",
      "offset": 976.16,
      "duration": 6.64
    },
    {
      "lang": "en",
      "text": "data and uh these models are",
      "offset": 977.839,
      "duration": 7.68
    },
    {
      "lang": "en",
      "text": "trained on everything like all sorts of",
      "offset": 982.8,
      "duration": 4.959
    },
    {
      "lang": "en",
      "text": "like misbehavior as well. And you want",
      "offset": 985.519,
      "duration": 5.281
    },
    {
      "lang": "en",
      "text": "it trained on like um like incorrect",
      "offset": 987.759,
      "duration": 5.841
    },
    {
      "lang": "en",
      "text": "behavior as well because like otherwise",
      "offset": 990.8,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "it won't know to refuse harmful requests",
      "offset": 993.6,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "or to not do a certain set of things.",
      "offset": 995.92,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "Do you have an intuition for why",
      "offset": 999.04,
      "duration": 2.799
    },
    {
      "lang": "en",
      "text": "different models have different base",
      "offset": 1000.32,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "models have different personalities?",
      "offset": 1001.839,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "Like for example, the the newest Claude",
      "offset": 1003.6,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "series like I think one of the models",
      "offset": 1005.68,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "maybe Opus or so on it is is you know",
      "offset": 1007.04,
      "duration": 3.359
    },
    {
      "lang": "en",
      "text": "really cares about animal welfare for",
      "offset": 1008.8,
      "duration": 3.039
    },
    {
      "lang": "en",
      "text": "example and the others don't. Like do",
      "offset": 1010.399,
      "duration": 2.88
    },
    {
      "lang": "en",
      "text": "you have a sense for why these models",
      "offset": 1011.839,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "develop pretty distinct personalities?",
      "offset": 1013.279,
      "duration": 4.641
    },
    {
      "lang": "en",
      "text": "I think it's just a function of how",
      "offset": 1016.399,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "they're trained and it's really really",
      "offset": 1017.92,
      "duration": 7.519
    },
    {
      "lang": "en",
      "text": "hard to uh anticipate in in advance like",
      "offset": 1019.839,
      "duration": 9.521
    },
    {
      "lang": "en",
      "text": "um yeah I don't know. I I I feel like uh",
      "offset": 1025.439,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "it might just be me, but like Cloud 4",
      "offset": 1029.36,
      "duration": 4.479
    },
    {
      "lang": "en",
      "text": "Opus 2 is like enormously sickantic.",
      "offset": 1031.199,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "Like I'll kind of nudge it in one",
      "offset": 1033.839,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "direction and it'll just like agree with",
      "offset": 1036.319,
      "duration": 3.201
    },
    {
      "lang": "en",
      "text": "me wholeheartedly and then nudge it in",
      "offset": 1037.839,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "the other direction like pose a counter",
      "offset": 1039.52,
      "duration": 3.439
    },
    {
      "lang": "en",
      "text": "example and it'll just be like yes, I",
      "offset": 1041.039,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "was totally wrong before. Like nothing I",
      "offset": 1042.959,
      "duration": 5.281
    },
    {
      "lang": "en",
      "text": "said earlier was was correct. And I just",
      "offset": 1045.439,
      "duration": 4.561
    },
    {
      "lang": "en",
      "text": "think it's like really really hard. It's",
      "offset": 1048.24,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "like kind of goes back to like the",
      "offset": 1050,
      "duration": 4.559
    },
    {
      "lang": "en",
      "text": "witchcraft almost of uh training an AI",
      "offset": 1051.6,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "model today where you're just like",
      "offset": 1054.559,
      "duration": 4.721
    },
    {
      "lang": "en",
      "text": "throwing in training data into the model",
      "offset": 1057.2,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "and like whispering the incantation of",
      "offset": 1059.28,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "gradient descent and then like trying to",
      "offset": 1061.28,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "like get what you want out of it and",
      "offset": 1064.48,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "something pops out and then it like",
      "offset": 1066.4,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "really cares about animals. Oh, great.",
      "offset": 1068.16,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "Like that's that's great.",
      "offset": 1069.76,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "I'd love to talk about your research",
      "offset": 1071.84,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "results so far, you know, both at",
      "offset": 1073.679,
      "duration": 4.641
    },
    {
      "lang": "en",
      "text": "Goodfire and in the broader mechan field",
      "offset": 1075.44,
      "duration": 5.359
    },
    {
      "lang": "en",
      "text": "as a whole. maybe could you just give us",
      "offset": 1078.32,
      "duration": 6.08
    },
    {
      "lang": "en",
      "text": "a a 30,000 foot fly overview of you know",
      "offset": 1080.799,
      "duration": 6.161
    },
    {
      "lang": "en",
      "text": "mechan as a field how old is it what are",
      "offset": 1084.4,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "the key results so far what are the big",
      "offset": 1086.96,
      "duration": 2.719
    },
    {
      "lang": "en",
      "text": "open questions",
      "offset": 1088.48,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "yeah so mechan as a field um I think",
      "offset": 1089.679,
      "duration": 6.401
    },
    {
      "lang": "en",
      "text": "like maybe just like in this tradition",
      "offset": 1093.76,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "that we're building on uh I think there",
      "offset": 1096.08,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "were all sorts of studies like looking",
      "offset": 1098.64,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "inside neural networks all the way back",
      "offset": 1100.08,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "when we first you know designed neural",
      "offset": 1101.76,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "networks but I think once we um I think",
      "offset": 1103.36,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "the the way that the field kind of",
      "offset": 1106.64,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "thinks about itself like mechanistic",
      "offset": 1108.24,
      "duration": 3.679
    },
    {
      "lang": "en",
      "text": "interpretability was started at like",
      "offset": 1109.76,
      "duration": 4.799
    },
    {
      "lang": "en",
      "text": "OpenAI with Chris Ola and Nick Camarada",
      "offset": 1111.919,
      "duration": 4.961
    },
    {
      "lang": "en",
      "text": "and a couple other folks who first put",
      "offset": 1114.559,
      "duration": 4.561
    },
    {
      "lang": "en",
      "text": "out like this really big circuits thread",
      "offset": 1116.88,
      "duration": 4.799
    },
    {
      "lang": "en",
      "text": "that posited like three things. One is",
      "offset": 1119.12,
      "duration": 4.799
    },
    {
      "lang": "en",
      "text": "like there are features in neural",
      "offset": 1121.679,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "networks which are directions in latent",
      "offset": 1123.919,
      "duration": 3.441
    },
    {
      "lang": "en",
      "text": "space that represent concepts that the",
      "offset": 1125.679,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "model uh uses to generate its response",
      "offset": 1127.36,
      "duration": 6.48
    },
    {
      "lang": "en",
      "text": "circuits. Uh these are like features",
      "offset": 1131.039,
      "duration": 6.64
    },
    {
      "lang": "en",
      "text": "that fire together to um create like",
      "offset": 1133.84,
      "duration": 6.16
    },
    {
      "lang": "en",
      "text": "higher order concepts. The example that",
      "offset": 1137.679,
      "duration": 4.961
    },
    {
      "lang": "en",
      "text": "they lay out is like you have a car",
      "offset": 1140,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "window detector and then a car like body",
      "offset": 1142.64,
      "duration": 6.159
    },
    {
      "lang": "en",
      "text": "detector and then a car wheel detector",
      "offset": 1145.76,
      "duration": 5.84
    },
    {
      "lang": "en",
      "text": "and then that's like a car circuit. And",
      "offset": 1148.799,
      "duration": 5.441
    },
    {
      "lang": "en",
      "text": "uh universality is the third tenant like",
      "offset": 1151.6,
      "duration": 6.8
    },
    {
      "lang": "en",
      "text": "uh similar circuits evolve in um",
      "offset": 1154.24,
      "duration": 6.559
    },
    {
      "lang": "en",
      "text": "different neural networks. And so this",
      "offset": 1158.4,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "was like almost like the start of the",
      "offset": 1160.799,
      "duration": 3.281
    },
    {
      "lang": "en",
      "text": "field of mechanistic uh interpretability",
      "offset": 1162.08,
      "duration": 6.479
    },
    {
      "lang": "en",
      "text": "in in my mind. Um and so uh that really",
      "offset": 1164.08,
      "duration": 6.8
    },
    {
      "lang": "en",
      "text": "kicked off a lot of uh you know",
      "offset": 1168.559,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "interesting research and results and",
      "offset": 1170.88,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "like the feature circuits paradigm and",
      "offset": 1172.48,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "uh I think like the main players um in",
      "offset": 1175.12,
      "duration": 3.679
    },
    {
      "lang": "en",
      "text": "the field there's a lot of academic labs",
      "offset": 1177.44,
      "duration": 2.479
    },
    {
      "lang": "en",
      "text": "that are doing great work like",
      "offset": 1178.799,
      "duration": 2.801
    },
    {
      "lang": "en",
      "text": "Enthropic. So Chris Ola is one of the",
      "offset": 1179.919,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "co-founders of Enthropic and building a",
      "offset": 1181.6,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "great interpretability lab there and uh",
      "offset": 1183.52,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "Deepmind has an inter interpretability",
      "offset": 1185.84,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "lab as well. and then we were kind of",
      "offset": 1187.679,
      "duration": 2.801
    },
    {
      "lang": "en",
      "text": "like the newer entrance on on the field",
      "offset": 1188.88,
      "duration": 7.44
    },
    {
      "lang": "en",
      "text": "and on the stage. Um and uh I think",
      "offset": 1190.48,
      "duration": 8.24
    },
    {
      "lang": "en",
      "text": "one of the other really key things to",
      "offset": 1196.32,
      "duration": 8.56
    },
    {
      "lang": "en",
      "text": "have happened was um understanding and",
      "offset": 1198.72,
      "duration": 10.959
    },
    {
      "lang": "en",
      "text": "uh mostly resolving superposition. So uh",
      "offset": 1204.88,
      "duration": 7.919
    },
    {
      "lang": "en",
      "text": "superposition is this idea that like uh",
      "offset": 1209.679,
      "duration": 6.24
    },
    {
      "lang": "en",
      "text": "each neuron is responsible for encoding",
      "offset": 1212.799,
      "duration": 6.561
    },
    {
      "lang": "en",
      "text": "like multiple concepts and uh there are",
      "offset": 1215.919,
      "duration": 6.401
    },
    {
      "lang": "en",
      "text": "more like concepts than dimensions in a",
      "offset": 1219.36,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "neural network. So you think about a",
      "offset": 1222.32,
      "duration": 2.88
    },
    {
      "lang": "en",
      "text": "neural network as like a giant",
      "offset": 1224.16,
      "duration": 2.56
    },
    {
      "lang": "en",
      "text": "compression algorithm. You're like",
      "offset": 1225.2,
      "duration": 2.88
    },
    {
      "lang": "en",
      "text": "compressing like the entirety of the",
      "offset": 1226.72,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "internet into like a relatively small",
      "offset": 1228.08,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "number of parameters.",
      "offset": 1230.08,
      "duration": 5.839
    },
    {
      "lang": "en",
      "text": "And so that means every single neuron",
      "offset": 1233.28,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "needs to encode or at least every single",
      "offset": 1235.919,
      "duration": 4.721
    },
    {
      "lang": "en",
      "text": "layer of the model needs to encode more",
      "offset": 1238.64,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "concepts than it has like dimensions.",
      "offset": 1240.64,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "And so there's like this concept of",
      "offset": 1243.12,
      "duration": 5.84
    },
    {
      "lang": "en",
      "text": "superposition where you have um concepts",
      "offset": 1244.96,
      "duration": 6.079
    },
    {
      "lang": "en",
      "text": "represented as like near orthogonal",
      "offset": 1248.96,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "directions in in latent space um such",
      "offset": 1251.039,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "that you can represent all of these",
      "offset": 1253.84,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "concepts in in a model's latent space.",
      "offset": 1255.44,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "And so to resolve this, you have to",
      "offset": 1257.76,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "almost untangle and unscramble a neuron",
      "offset": 1259.52,
      "duration": 5.92
    },
    {
      "lang": "en",
      "text": "such that it's responsible for like one",
      "offset": 1263.12,
      "duration": 7.6
    },
    {
      "lang": "en",
      "text": "clean interpretable concept. And so um",
      "offset": 1265.44,
      "duration": 7.92
    },
    {
      "lang": "en",
      "text": "it's like a group at Apollo Research um",
      "offset": 1270.72,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "led by like Lee Shy who's actually now",
      "offset": 1273.36,
      "duration": 4.559
    },
    {
      "lang": "en",
      "text": "at at Goodfire first kind of pioneered",
      "offset": 1275.52,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "like sparse autoenccoders for for",
      "offset": 1277.919,
      "duration": 4.481
    },
    {
      "lang": "en",
      "text": "language models and enthropic also like",
      "offset": 1279.6,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "really popularized this with their like",
      "offset": 1282.4,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "big paper like towards monoseity and",
      "offset": 1284.08,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "then right afterwards like scaling",
      "offset": 1286.559,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "monanticity showing that you can",
      "offset": 1288.24,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "essentially unscramble these neurons",
      "offset": 1290.159,
      "duration": 5.841
    },
    {
      "lang": "en",
      "text": "into uh higher order concepts um",
      "offset": 1291.84,
      "duration": 6.079
    },
    {
      "lang": "en",
      "text": "reliably and at scale with like",
      "offset": 1296,
      "duration": 4.799
    },
    {
      "lang": "en",
      "text": "arbitrarily large neural networks. And I",
      "offset": 1297.919,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "think that was a really big moment for",
      "offset": 1300.799,
      "duration": 5.201
    },
    {
      "lang": "en",
      "text": "interpretability where you can now in a",
      "offset": 1302.799,
      "duration": 5.601
    },
    {
      "lang": "en",
      "text": "totally unsupervised way unscramble",
      "offset": 1306,
      "duration": 4.559
    },
    {
      "lang": "en",
      "text": "neurons of a neural network uh to",
      "offset": 1308.4,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "understand them and get clean concepts.",
      "offset": 1310.559,
      "duration": 5.281
    },
    {
      "lang": "en",
      "text": "Uh so the concepts aren't like totally",
      "offset": 1313.12,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "clean yet. You can't like edit them",
      "offset": 1315.84,
      "duration": 2.719
    },
    {
      "lang": "en",
      "text": "super well. There's all sorts of",
      "offset": 1317.36,
      "duration": 3.199
    },
    {
      "lang": "en",
      "text": "problems with this, but like it's almost",
      "offset": 1318.559,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "like a really big step forward for the",
      "offset": 1320.559,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "field such that like that we can do this",
      "offset": 1322.48,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "in an unsupervised way. and the",
      "offset": 1324.799,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "techniques and interpretability scale",
      "offset": 1327.12,
      "duration": 3.039
    },
    {
      "lang": "en",
      "text": "which is really important.",
      "offset": 1328.72,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "Does that mean the superp position isn't",
      "offset": 1330.159,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "real or that you like the Heisenberg's",
      "offset": 1332,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "uncertainty principle you sort of",
      "offset": 1334.48,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "collapse it at a particular moment in",
      "offset": 1335.84,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "time to know that in this instance it",
      "offset": 1337.52,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "represents a particular",
      "offset": 1339.6,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "direction.",
      "offset": 1341.84,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "Uh so I think it means it was real like",
      "offset": 1342.64,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "neurons are responsible for you know",
      "offset": 1346.88,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "encoding multiple concepts such that u",
      "offset": 1348.24,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "once you unscramble them then you can do",
      "offset": 1350.72,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "really interesting things with like a",
      "offset": 1352.48,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "clean neuron. So the way that we do this",
      "offset": 1354.559,
      "duration": 5.521
    },
    {
      "lang": "en",
      "text": "is like using an interpreter model train",
      "offset": 1357.52,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "on the activations of a base model and",
      "offset": 1360.08,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "then um now you have all sorts of",
      "offset": 1362.32,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "neurons in the interpreter model that",
      "offset": 1365.2,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "represent like theoretically clean",
      "offset": 1367.28,
      "duration": 3.279
    },
    {
      "lang": "en",
      "text": "sparse concepts",
      "offset": 1369.36,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "in the interpreter model the original",
      "offset": 1370.559,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "model still has this characteristic of",
      "offset": 1372.96,
      "duration": 2.64
    },
    {
      "lang": "en",
      "text": "superposition.",
      "offset": 1374.64,
      "duration": 1.36
    },
    {
      "lang": "en",
      "text": "That's right.",
      "offset": 1375.6,
      "duration": 1.76
    },
    {
      "lang": "en",
      "text": "Okay, got it. Thank you. And in the",
      "offset": 1376,
      "duration": 2.96
    },
    {
      "lang": "en",
      "text": "interpreter model, you unscramble these",
      "offset": 1377.36,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "neurons and you associate these concepts",
      "offset": 1378.96,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "with the concepts in the base model that",
      "offset": 1381.36,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "you're trying to interpret and then you",
      "offset": 1383.44,
      "duration": 3.119
    },
    {
      "lang": "en",
      "text": "can do interesting things with it.",
      "offset": 1385.36,
      "duration": 2
    },
    {
      "lang": "en",
      "text": "Got it. Thank you.",
      "offset": 1386.559,
      "duration": 2.561
    },
    {
      "lang": "en",
      "text": "Yeah, of course.",
      "offset": 1387.36,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "How solved of a problem is this then if",
      "offset": 1389.12,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "you've if you've already been able to",
      "offset": 1391.12,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "kind of disentangle the superp position",
      "offset": 1393.039,
      "duration": 4.721
    },
    {
      "lang": "en",
      "text": "then haven't you already mapped out the",
      "offset": 1395.76,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "the mind so to speak of the neural net",
      "offset": 1397.76,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "and and what's what's ahead? I think",
      "offset": 1399.84,
      "duration": 5.199
    },
    {
      "lang": "en",
      "text": "partially I think it's a partial mapping",
      "offset": 1401.76,
      "duration": 5.919
    },
    {
      "lang": "en",
      "text": "and the technique has all sorts of all",
      "offset": 1405.039,
      "duration": 4.561
    },
    {
      "lang": "en",
      "text": "sorts of flaws as well that we can",
      "offset": 1407.679,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "improve upon but I think like it gives",
      "offset": 1409.6,
      "duration": 7.76
    },
    {
      "lang": "en",
      "text": "us the first step towards understanding",
      "offset": 1413.039,
      "duration": 8.88
    },
    {
      "lang": "en",
      "text": "um these models uh especially going from",
      "offset": 1417.36,
      "duration": 7.6
    },
    {
      "lang": "en",
      "text": "toy model to like actual network that",
      "offset": 1421.919,
      "duration": 5.201
    },
    {
      "lang": "en",
      "text": "people care about um so we've done a",
      "offset": 1424.96,
      "duration": 5.199
    },
    {
      "lang": "en",
      "text": "bunch of work recently on um R1 so it's",
      "offset": 1427.12,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "a 600 171 billion parameter mixture of",
      "offset": 1430.159,
      "duration": 4.481
    },
    {
      "lang": "en",
      "text": "experts models. It's a it's a big boy",
      "offset": 1432.72,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "model. Uh and like the techniques scale",
      "offset": 1434.64,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "really nicely all the way up to that",
      "offset": 1438.4,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "point because you know it's just more AI",
      "offset": 1440.32,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "more training of an interpreter model.",
      "offset": 1443.36,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "So obviously I presume there's an",
      "offset": 1445.52,
      "duration": 3.519
    },
    {
      "lang": "en",
      "text": "asmtote here to understanding because",
      "offset": 1446.96,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "the models are going to get more and",
      "offset": 1449.039,
      "duration": 4.561
    },
    {
      "lang": "en",
      "text": "more complex over time and we're going",
      "offset": 1450.24,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "to beef them up.",
      "offset": 1453.6,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "Yeah. And so I'm guessing it's sort of,",
      "offset": 1454.96,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "you know, like the battle of Seephus at",
      "offset": 1457.12,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "some point, you know, this is a never-",
      "offset": 1459.279,
      "duration": 5.121
    },
    {
      "lang": "en",
      "text": "ending pursuit, which is great. Um, is",
      "offset": 1460.64,
      "duration": 6.56
    },
    {
      "lang": "en",
      "text": "that correct? Do you agree with that? in",
      "offset": 1464.4,
      "duration": 7.2
    },
    {
      "lang": "en",
      "text": "some ways, but I also think that like",
      "offset": 1467.2,
      "duration": 7.76
    },
    {
      "lang": "en",
      "text": "so the techniques that we've developed",
      "offset": 1471.6,
      "duration": 6.319
    },
    {
      "lang": "en",
      "text": "work on toy models all the way up to",
      "offset": 1474.96,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "like yeah big network that's like more",
      "offset": 1477.919,
      "duration": 5.681
    },
    {
      "lang": "en",
      "text": "capable and more intelligent and better",
      "offset": 1480.64,
      "duration": 6.56
    },
    {
      "lang": "en",
      "text": "and I think like the techniques also",
      "offset": 1483.6,
      "duration": 6.16
    },
    {
      "lang": "en",
      "text": "scale effectively with model",
      "offset": 1487.2,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "intelligence. So one part of our",
      "offset": 1489.76,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "pipeline is that for every single latent",
      "offset": 1491.52,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "concept in our interpreter model, we",
      "offset": 1494.32,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "associate that with um and try to we we",
      "offset": 1496.64,
      "duration": 5.279
    },
    {
      "lang": "en",
      "text": "get another language model to reason",
      "offset": 1500,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "about like what that concept actually",
      "offset": 1501.919,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "represents in the base model. So this is",
      "offset": 1503.76,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "a concept called auto interpretability",
      "offset": 1505.6,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "which Nick Camarada who's at at Goodfire",
      "offset": 1507.36,
      "duration": 6.48
    },
    {
      "lang": "en",
      "text": "now invented this technique at OpenAI um",
      "offset": 1509.84,
      "duration": 7.439
    },
    {
      "lang": "en",
      "text": "uh pioneered and this technique because",
      "offset": 1513.84,
      "duration": 5.439
    },
    {
      "lang": "en",
      "text": "it's a language model reasoning about",
      "offset": 1517.279,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "you know what a neuron represents scales",
      "offset": 1519.279,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "with the quality of the language model",
      "offset": 1521.6,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "so it actually gets better. So because",
      "offset": 1522.96,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "we use AI in order to understand AI like",
      "offset": 1525.12,
      "duration": 5.439
    },
    {
      "lang": "en",
      "text": "the better that you know our our models",
      "offset": 1528.48,
      "duration": 5.199
    },
    {
      "lang": "en",
      "text": "are like these analysis agents are at",
      "offset": 1530.559,
      "duration": 4.641
    },
    {
      "lang": "en",
      "text": "interpreting like what's actually going",
      "offset": 1533.679,
      "duration": 5.201
    },
    {
      "lang": "en",
      "text": "on the better we are able to understand",
      "offset": 1535.2,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "them.",
      "offset": 1538.88,
      "duration": 2.24
    },
    {
      "lang": "en",
      "text": "Got it. And our interpreter model",
      "offset": 1539.36,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "techniques also it's just like if we",
      "offset": 1541.12,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "develop better interpreter models they",
      "offset": 1544.24,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "theoretically should translate to more",
      "offset": 1546,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "and more intelligent and larger and",
      "offset": 1548.4,
      "duration": 2.879
    },
    {
      "lang": "en",
      "text": "larger networks because these are like",
      "offset": 1550,
      "duration": 2.96
    },
    {
      "lang": "en",
      "text": "unsupervised scalable techniques and",
      "offset": 1551.279,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "that's like the paradigm in in AI",
      "offset": 1552.96,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "interpretability.",
      "offset": 1554.799,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "All right. When do you think you reach a",
      "offset": 1556,
      "duration": 5.679
    },
    {
      "lang": "en",
      "text": "minimum threshold that makes you feel u",
      "offset": 1557.919,
      "duration": 6.481
    },
    {
      "lang": "en",
      "text": "it's ready for a real world application?",
      "offset": 1561.679,
      "duration": 3.761
    },
    {
      "lang": "en",
      "text": "Maybe we're there already.",
      "offset": 1564.4,
      "duration": 3.279
    },
    {
      "lang": "en",
      "text": "I think we're there. Yeah. I think I",
      "offset": 1565.44,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "think um the first real world",
      "offset": 1567.679,
      "duration": 5.921
    },
    {
      "lang": "en",
      "text": "applications are already out there and",
      "offset": 1570,
      "duration": 5.919
    },
    {
      "lang": "en",
      "text": "uh yeah I think I think we're there on",
      "offset": 1573.6,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "like the the very very early",
      "offset": 1575.919,
      "duration": 2.88
    },
    {
      "lang": "en",
      "text": "applications. Yeah.",
      "offset": 1577.36,
      "duration": 2.88
    },
    {
      "lang": "en",
      "text": "Can you share more about this?",
      "offset": 1578.799,
      "duration": 5.201
    },
    {
      "lang": "en",
      "text": "Yeah, I was being unnecessarily cryptic.",
      "offset": 1580.24,
      "duration": 6.4
    },
    {
      "lang": "en",
      "text": "So um yeah, a couple of the partnerships",
      "offset": 1584,
      "duration": 4.799
    },
    {
      "lang": "en",
      "text": "I'm I'm most excited about. Uh so we",
      "offset": 1586.64,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "worked with Arc Institute um like I I",
      "offset": 1588.799,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "mentioned a little bit earlier to",
      "offset": 1590.96,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "understand uh and interpret EVO 2 which",
      "offset": 1592.799,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "is their like kind of DNA uh foundation",
      "offset": 1595.52,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "model. So it's a sequencetosequence",
      "offset": 1598.559,
      "duration": 5.921
    },
    {
      "lang": "en",
      "text": "model. So it like takes in um a sequence",
      "offset": 1600.24,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "of nucleotides and it predicts the next",
      "offset": 1604.48,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "nucleotide in a in a sequence. And our",
      "offset": 1606.24,
      "duration": 5.439
    },
    {
      "lang": "en",
      "text": "theory is like this is a narrowly",
      "offset": 1610.08,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "superhuman model. So we really like to",
      "offset": 1611.679,
      "duration": 4.801
    },
    {
      "lang": "en",
      "text": "work on narrowly superhuman models",
      "offset": 1614.72,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "because it can teach us something about",
      "offset": 1616.48,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "the world that humans don't really know.",
      "offset": 1618.4,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "And so the idea is like this model is",
      "offset": 1621.12,
      "duration": 2.96
    },
    {
      "lang": "en",
      "text": "representing just an enormous amount",
      "offset": 1622.72,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "about the biological world in order to",
      "offset": 1624.08,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "generate the next and properly model the",
      "offset": 1626.24,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "next nucleotide in a sequence. So what",
      "offset": 1628.32,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "we did um was we sought to understand",
      "offset": 1630.559,
      "duration": 5.201
    },
    {
      "lang": "en",
      "text": "like what does it actually know such",
      "offset": 1633.52,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "that it can model the world so so",
      "offset": 1635.76,
      "duration": 6.64
    },
    {
      "lang": "en",
      "text": "effectively. Um so what we did was we",
      "offset": 1638.24,
      "duration": 6.72
    },
    {
      "lang": "en",
      "text": "trained uh sparse autoenccoders on the",
      "offset": 1642.4,
      "duration": 6.08
    },
    {
      "lang": "en",
      "text": "activations of this this model um",
      "offset": 1644.96,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "extracted all sorts of features that",
      "offset": 1648.48,
      "duration": 6.48
    },
    {
      "lang": "en",
      "text": "were related to uh concepts that the",
      "offset": 1650.4,
      "duration": 6.56
    },
    {
      "lang": "en",
      "text": "model like should know like kind of",
      "offset": 1654.96,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "normal biological concepts that we have",
      "offset": 1656.96,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "like really strong ground truth",
      "offset": 1659.039,
      "duration": 5.041
    },
    {
      "lang": "en",
      "text": "annotations for. So these are like uh",
      "offset": 1660.48,
      "duration": 6.64
    },
    {
      "lang": "en",
      "text": "tRNAs, RNAs, star coding sequences, like",
      "offset": 1664.08,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "all sorts of like biological concepts",
      "offset": 1667.12,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "that we have ground truth annotations",
      "offset": 1668.96,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "are we associated with this model. And",
      "offset": 1670.48,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "then the question is like okay now we",
      "offset": 1674.08,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "have all of these other features of the",
      "offset": 1676.08,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "model that we've extracted. What do they",
      "offset": 1677.52,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "mean? What what are they? They might",
      "offset": 1680,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "just be ways that the model is computing",
      "offset": 1681.919,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "and thinking or they could represent,",
      "offset": 1684.72,
      "duration": 4.559
    },
    {
      "lang": "en",
      "text": "you know, like novel biological concepts",
      "offset": 1687.279,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "that the model's using to generate the",
      "offset": 1689.279,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "next, you know, nucleotide in a",
      "offset": 1691.6,
      "duration": 2.16
    },
    {
      "lang": "en",
      "text": "sequence.",
      "offset": 1693.039,
      "duration": 2.801
    },
    {
      "lang": "en",
      "text": "That's really interesting.",
      "offset": 1693.76,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "There was for a long time there was this",
      "offset": 1695.84,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "idea that we have a bunch of junk DNA.",
      "offset": 1697.44,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "You may have read about this and turns",
      "offset": 1699.84,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "out a lot of that DNA actually serves a",
      "offset": 1701.52,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "particular p purpose in a different part",
      "offset": 1703.2,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "of evolution or that they govern the",
      "offset": 1704.88,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "expression of other genes. And so, you",
      "offset": 1706.88,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "know, nature generally doesn't want to",
      "offset": 1708.799,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "harbor things that don't have value",
      "offset": 1710.64,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "because it's expensive,",
      "offset": 1712.399,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "you know, just from a biological system",
      "offset": 1714.24,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "point of view. So, that's super",
      "offset": 1716.159,
      "duration": 2.721
    },
    {
      "lang": "en",
      "text": "interesting. I'm looking forward to the",
      "offset": 1717.44,
      "duration": 2.08
    },
    {
      "lang": "en",
      "text": "results.",
      "offset": 1718.88,
      "duration": 3.279
    },
    {
      "lang": "en",
      "text": "Yeah, totally. Totally. And, uh, I think",
      "offset": 1719.52,
      "duration": 5.92
    },
    {
      "lang": "en",
      "text": "like hopefully using unsupervised AI",
      "offset": 1722.159,
      "duration": 6.321
    },
    {
      "lang": "en",
      "text": "techniques like we can um, better",
      "offset": 1725.44,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "understand like what all these, you",
      "offset": 1728.48,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "know, portions of the DNA are actually",
      "offset": 1730.72,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "doing. Like maybe we can discover the",
      "offset": 1732.88,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "idea of junk DNA like faster or",
      "offset": 1734.799,
      "duration": 5.281
    },
    {
      "lang": "en",
      "text": "or like or understand that like DNA is",
      "offset": 1738,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "not junk DNA like faster and or like",
      "offset": 1740.08,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "yeah just discover like totally novel",
      "offset": 1743.2,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "things that like genes are are doing and",
      "offset": 1745.12,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "expressing within us.",
      "offset": 1747.44,
      "duration": 2.56
    },
    {
      "lang": "en",
      "text": "Yeah.",
      "offset": 1749.52,
      "duration": 2.159
    },
    {
      "lang": "en",
      "text": "Where's the research as far as going",
      "offset": 1750,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "from understanding and mapping towards",
      "offset": 1751.679,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "editing? So for example being able to",
      "offset": 1754.48,
      "duration": 3.679
    },
    {
      "lang": "en",
      "text": "reach in and you know change this weight",
      "offset": 1756.159,
      "duration": 4.801
    },
    {
      "lang": "en",
      "text": "from here to there. Uh I'm I'm curious",
      "offset": 1758.159,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "if you all have any results there yet.",
      "offset": 1760.96,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "Yeah. Uh so we've done most of our",
      "offset": 1762.799,
      "duration": 4.641
    },
    {
      "lang": "en",
      "text": "editing work on like language models and",
      "offset": 1765.2,
      "duration": 4.719
    },
    {
      "lang": "en",
      "text": "image models. Like our our most recent",
      "offset": 1767.44,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "kind of release was a a um a paint with",
      "offset": 1769.919,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "Ember. Ember is our like kind of",
      "offset": 1773.2,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "foundational infrastructure for",
      "offset": 1775.279,
      "duration": 5.441
    },
    {
      "lang": "en",
      "text": "interpretability. Um and uh what we were",
      "offset": 1776.88,
      "duration": 7.12
    },
    {
      "lang": "en",
      "text": "able to do with this like image model",
      "offset": 1780.72,
      "duration": 7.839
    },
    {
      "lang": "en",
      "text": "demo was targeted precise control over",
      "offset": 1784,
      "duration": 7.84
    },
    {
      "lang": "en",
      "text": "an image model by by painting. So we",
      "offset": 1788.559,
      "duration": 8.161
    },
    {
      "lang": "en",
      "text": "could extract latent concepts like a um",
      "offset": 1791.84,
      "duration": 8.559
    },
    {
      "lang": "en",
      "text": "a dragon or dragon wings or an ocean or",
      "offset": 1796.72,
      "duration": 6.559
    },
    {
      "lang": "en",
      "text": "a pyramid and then take these concepts",
      "offset": 1800.399,
      "duration": 5.361
    },
    {
      "lang": "en",
      "text": "and directly intervene on like the",
      "offset": 1803.279,
      "duration": 4.241
    },
    {
      "lang": "en",
      "text": "portion of a canvas that we want to",
      "offset": 1805.76,
      "duration": 3.279
    },
    {
      "lang": "en",
      "text": "intervene on. So you can paint on a",
      "offset": 1807.52,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "dragon with wings and then add like a",
      "offset": 1809.039,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "crowd in the corner and add like a",
      "offset": 1810.96,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "pyramid and it's a it's a really fun",
      "offset": 1812.72,
      "duration": 4.559
    },
    {
      "lang": "en",
      "text": "demo uh that's just like a kind of a joy",
      "offset": 1814.96,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "to play with. Um so it's it's out right",
      "offset": 1817.279,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "now. anybody can play with it. It's just",
      "offset": 1819.52,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "like paint.g goodfire.ai.",
      "offset": 1820.799,
      "duration": 6.48
    },
    {
      "lang": "en",
      "text": "But we're able to I think reasonably",
      "offset": 1823.52,
      "duration": 6.56
    },
    {
      "lang": "en",
      "text": "intervene uh in like certain situations",
      "offset": 1827.279,
      "duration": 4.961
    },
    {
      "lang": "en",
      "text": "on on a model's latence and like steer",
      "offset": 1830.08,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "the model to do what we want. But uh we",
      "offset": 1832.24,
      "duration": 6.559
    },
    {
      "lang": "en",
      "text": "haven't quite cracked like the idea of",
      "offset": 1834.96,
      "duration": 6.719
    },
    {
      "lang": "en",
      "text": "direct precision surgical edits that",
      "offset": 1838.799,
      "duration": 4.961
    },
    {
      "lang": "en",
      "text": "like create a new model that you want to",
      "offset": 1841.679,
      "duration": 4.641
    },
    {
      "lang": "en",
      "text": "like use and doesn't have like any",
      "offset": 1843.76,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "unintended side effects. So, uh, that's",
      "offset": 1846.32,
      "duration": 4.959
    },
    {
      "lang": "en",
      "text": "like still, you know, something that",
      "offset": 1849.76,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "we're pushing pushing on and and trying",
      "offset": 1851.279,
      "duration": 2.801
    },
    {
      "lang": "en",
      "text": "to figure out.",
      "offset": 1853.12,
      "duration": 2.24
    },
    {
      "lang": "en",
      "text": "Do you think that's where the field",
      "offset": 1854.08,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "ultimately goes or or do you think",
      "offset": 1855.36,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "people are focused on different parts of",
      "offset": 1857.12,
      "duration": 2.88
    },
    {
      "lang": "en",
      "text": "the field?",
      "offset": 1859.12,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "I think there are many places where the",
      "offset": 1860,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "field is going to go and this is one of",
      "offset": 1862.48,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "them. uh like interpretability is almost",
      "offset": 1864.08,
      "duration": 7.12
    },
    {
      "lang": "en",
      "text": "like such a general term that I again",
      "offset": 1867.36,
      "duration": 5.679
    },
    {
      "lang": "en",
      "text": "I'm I'm biased but I think it's just",
      "offset": 1871.2,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "like governing and underlying like all",
      "offset": 1873.039,
      "duration": 7.76
    },
    {
      "lang": "en",
      "text": "aspects of of AI. It's like um anytime",
      "offset": 1875.6,
      "duration": 7.439
    },
    {
      "lang": "en",
      "text": "you prefer to take a white box approach",
      "offset": 1880.799,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "to doing something versus a blackbox",
      "offset": 1883.039,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "approach like interpretability can",
      "offset": 1884.96,
      "duration": 3.599
    },
    {
      "lang": "en",
      "text": "probably help in the future. So",
      "offset": 1886.64,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "how do you select your training data?",
      "offset": 1888.559,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "Maybe you want to understand like",
      "offset": 1890.559,
      "duration": 4.641
    },
    {
      "lang": "en",
      "text": "whether the training data is surprising",
      "offset": 1892.64,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "to the model before like putting it into",
      "offset": 1895.2,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "the model because then it can have like",
      "offset": 1897.44,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "the most impact on um on training. Yeah,",
      "offset": 1899.039,
      "duration": 4.721
    },
    {
      "lang": "en",
      "text": "just like in every single part of like",
      "offset": 1902.32,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "the AI development stack, I think like",
      "offset": 1903.76,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "interpretability will will help and",
      "offset": 1905.6,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "change the way that we do things.",
      "offset": 1907.6,
      "duration": 3.679
    },
    {
      "lang": "en",
      "text": "If AI foundational models go the way",
      "offset": 1909.12,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "that a lot of software has gone,",
      "offset": 1911.279,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "certainly infrastructure software where",
      "offset": 1913.36,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "much of it is open source or open",
      "offset": 1915.279,
      "duration": 2.721
    },
    {
      "lang": "en",
      "text": "weight,",
      "offset": 1916.96,
      "duration": 3.199
    },
    {
      "lang": "en",
      "text": "is there an opportunity for you to play",
      "offset": 1918,
      "duration": 7.2
    },
    {
      "lang": "en",
      "text": "an invaluable role in judging the biases",
      "offset": 1920.159,
      "duration": 7.441
    },
    {
      "lang": "en",
      "text": "or likely outcomes of using different",
      "offset": 1925.2,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "open weight models.",
      "offset": 1927.6,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "I think we could. Yeah. Um so there's",
      "offset": 1929.6,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "maybe like two two areas of research",
      "offset": 1933.12,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "that we're interested in that that",
      "offset": 1934.96,
      "duration": 5.599
    },
    {
      "lang": "en",
      "text": "intersect with this idea. So um auditing",
      "offset": 1936.32,
      "duration": 6.479
    },
    {
      "lang": "en",
      "text": "so like how do you take a model",
      "offset": 1940.559,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "understand like what's going on find",
      "offset": 1942.799,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "like problematic behavior and good",
      "offset": 1944.799,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "behavior hopefully get rid of the bad",
      "offset": 1947.12,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "behavior and enhance the good behavior.",
      "offset": 1949.12,
      "duration": 5.439
    },
    {
      "lang": "en",
      "text": "So I think like as AI gets",
      "offset": 1950.88,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "um deployed in more and more mission",
      "offset": 1954.559,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "critical contexts like that becomes more",
      "offset": 1956.32,
      "duration": 3.199
    },
    {
      "lang": "en",
      "text": "important.",
      "offset": 1958.559,
      "duration": 2.401
    },
    {
      "lang": "en",
      "text": "Um",
      "offset": 1959.519,
      "duration": 4.241
    },
    {
      "lang": "en",
      "text": "so uh and then also model diffing. So",
      "offset": 1960.96,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "it's like when you have two checkpoints",
      "offset": 1963.76,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "of a model like how do they differ from",
      "offset": 1965.039,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "each other and what's changed?",
      "offset": 1966.96,
      "duration": 4.719
    },
    {
      "lang": "en",
      "text": "So the recent kind of like GPT40 like",
      "offset": 1968.72,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "was enormously sick ofantic for a period",
      "offset": 1971.679,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "of time. Uh just like telling just like",
      "offset": 1973.84,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "really gassing up the user like tell",
      "offset": 1976.399,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "them that they're doing great. You still",
      "offset": 1978.08,
      "duration": 1.76
    },
    {
      "lang": "en",
      "text": "is.",
      "offset": 1979.519,
      "duration": 1.921
    },
    {
      "lang": "en",
      "text": "Pat recently asked it who the most",
      "offset": 1979.84,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "handsome cribble board member was and it",
      "offset": 1981.44,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "was like definitely definitely Pat",
      "offset": 1983.12,
      "duration": 4.559
    },
    {
      "lang": "en",
      "text": "Greedy. Still a bit sick of antic.",
      "offset": 1984.48,
      "duration": 6.48
    },
    {
      "lang": "en",
      "text": "That's so good. That's so good. Uh yeah.",
      "offset": 1987.679,
      "duration": 7.041
    },
    {
      "lang": "en",
      "text": "Um but yeah like model diffing like you",
      "offset": 1990.96,
      "duration": 7.36
    },
    {
      "lang": "en",
      "text": "should be able to detect like uh how a",
      "offset": 1994.72,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "model has changed from checkpoint to",
      "offset": 1998.32,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "checkpoint like what surprising things",
      "offset": 1999.76,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "have happened that were um that are now",
      "offset": 2002.08,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "contained in the network that weren't",
      "offset": 2005.2,
      "duration": 2.8
    },
    {
      "lang": "en",
      "text": "there before.",
      "offset": 2006.64,
      "duration": 2.639
    },
    {
      "lang": "en",
      "text": "Why do you think it was so hard for",
      "offset": 2008,
      "duration": 2.64
    },
    {
      "lang": "en",
      "text": "OpenAI to roll back to a less",
      "offset": 2009.279,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "psychopantic version of the model? And",
      "offset": 2010.64,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "in an ideal state of the world, is there",
      "offset": 2013.039,
      "duration": 3.281
    },
    {
      "lang": "en",
      "text": "almost an, you know, a dial and a knob",
      "offset": 2014.48,
      "duration": 4.559
    },
    {
      "lang": "en",
      "text": "that the OpenAI guys could tune of on a",
      "offset": 2016.32,
      "duration": 4.719
    },
    {
      "lang": "en",
      "text": "scale of 0 to 100, how sick ofantic do",
      "offset": 2019.039,
      "duration": 3.201
    },
    {
      "lang": "en",
      "text": "you want the model to be? Like, do you",
      "offset": 2021.039,
      "duration": 1.841
    },
    {
      "lang": "en",
      "text": "think we can get there?",
      "offset": 2022.24,
      "duration": 1.6
    },
    {
      "lang": "en",
      "text": "I don't know what questions you're",
      "offset": 2022.88,
      "duration": 2.48
    },
    {
      "lang": "en",
      "text": "asking of the model, by the way, cuz I",
      "offset": 2023.84,
      "duration": 2.8
    },
    {
      "lang": "en",
      "text": "never encountered this particular",
      "offset": 2025.36,
      "duration": 2.72
    },
    {
      "lang": "en",
      "text": "problem.",
      "offset": 2026.64,
      "duration": 3.519
    },
    {
      "lang": "en",
      "text": "Always does this with me. And then",
      "offset": 2028.08,
      "duration": 3.599
    },
    {
      "lang": "en",
      "text": "sometimes it's brutal the other way. I",
      "offset": 2030.159,
      "duration": 4.481
    },
    {
      "lang": "en",
      "text": "ask at the best AI podcast and it lists",
      "offset": 2031.679,
      "duration": 4.801
    },
    {
      "lang": "en",
      "text": "20 things with no training data. I ask,",
      "offset": 2034.64,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "what about what about us? It's, oh, I",
      "offset": 2036.48,
      "duration": 3.439
    },
    {
      "lang": "en",
      "text": "didn't want to I didn't want to give a",
      "offset": 2038.48,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "biased result. That's so funny. Well,",
      "offset": 2039.919,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "that's that's part of what users want,",
      "offset": 2042.72,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "right? They kind of want sick of fancy,",
      "offset": 2044.399,
      "duration": 5.361
    },
    {
      "lang": "en",
      "text": "like, you know, um people want to hear",
      "offset": 2046.32,
      "duration": 6.16
    },
    {
      "lang": "en",
      "text": "what they what they want to hear. So,",
      "offset": 2049.76,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "when you RL a model, I think",
      "offset": 2052.48,
      "duration": 5.199
    },
    {
      "lang": "en",
      "text": "fundamentally you're going to get uh I",
      "offset": 2054.32,
      "duration": 5.519
    },
    {
      "lang": "en",
      "text": "think it's just kind of a a symptom of",
      "offset": 2057.679,
      "duration": 5.361
    },
    {
      "lang": "en",
      "text": "like RL. It's like you like this is what",
      "offset": 2059.839,
      "duration": 5.201
    },
    {
      "lang": "en",
      "text": "users want. This is user preferences.",
      "offset": 2063.04,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "Along the way, you've dropped some names",
      "offset": 2065.04,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "and it seems as though most of them have",
      "offset": 2067.52,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "ended up at Goodfire. I presume there is",
      "offset": 2069.52,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "a a certain number of very talented",
      "offset": 2072,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "people in this field and you've unfairly",
      "offset": 2074.48,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "seem to gather them. Uh can you describe",
      "offset": 2076.079,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "a little bit more about your team, what",
      "offset": 2078.48,
      "duration": 2.96
    },
    {
      "lang": "en",
      "text": "you've pulled together?",
      "offset": 2080.399,
      "duration": 5.121
    },
    {
      "lang": "en",
      "text": "Yeah. Uh so I mean I I I think we have a",
      "offset": 2081.44,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "really fantastic team and that's what",
      "offset": 2085.52,
      "duration": 2.879
    },
    {
      "lang": "en",
      "text": "we've been you know spending a lot of",
      "offset": 2087.2,
      "duration": 3.199
    },
    {
      "lang": "en",
      "text": "our our time on the last year just kind",
      "offset": 2088.399,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "of like uh I think assembling a team of",
      "offset": 2090.399,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "you know world-class interpretability",
      "offset": 2092.879,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "experts that um really have a shot of",
      "offset": 2094.32,
      "duration": 5.039
    },
    {
      "lang": "en",
      "text": "cracking this this problem. Um so it",
      "offset": 2096.879,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "starts with my you know like co-founders",
      "offset": 2099.359,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "you know I I had worked with uh Dan",
      "offset": 2101.2,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "Balsam our CTO for many years at my",
      "offset": 2103.28,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "previous company. Um and uh so he's our",
      "offset": 2105.599,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "CTO um and uh our chief scientist Tom",
      "offset": 2108.72,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "who founded the interpretability team at",
      "offset": 2111.359,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "Google DeepMind way back in the day and",
      "offset": 2112.96,
      "duration": 4.879
    },
    {
      "lang": "en",
      "text": "uh yeah and just have assembled many of",
      "offset": 2115.359,
      "duration": 5.201
    },
    {
      "lang": "en",
      "text": "like the early folks in the field. So uh",
      "offset": 2117.839,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "Tom um Nick Hamarada who is one who's",
      "offset": 2120.56,
      "duration": 5.279
    },
    {
      "lang": "en",
      "text": "like working very closely with Chris Ola",
      "offset": 2123.359,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "who is generally considered like the",
      "offset": 2125.839,
      "duration": 5.041
    },
    {
      "lang": "en",
      "text": "founder uh of of the field of meantur",
      "offset": 2127.52,
      "duration": 5.92
    },
    {
      "lang": "en",
      "text": "and Nick like was on all of the original",
      "offset": 2130.88,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "like circuits papers and helped like you",
      "offset": 2133.44,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "know build everything out at open AI. uh",
      "offset": 2135.76,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "Lee Shy who is the first um who",
      "offset": 2138.64,
      "duration": 4.719
    },
    {
      "lang": "en",
      "text": "pioneered like sparse autoenccoders on",
      "offset": 2141.2,
      "duration": 6.159
    },
    {
      "lang": "en",
      "text": "language models and uh is now working on",
      "offset": 2143.359,
      "duration": 6.72
    },
    {
      "lang": "en",
      "text": "some really interesting work in weights",
      "offset": 2147.359,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "based interpretability. So most",
      "offset": 2150.079,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "interpretability",
      "offset": 2152.079,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "uh techniques that have been deployed",
      "offset": 2153.68,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "into applications are in concept space",
      "offset": 2155.599,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "and activation space and he's he and his",
      "offset": 2157.28,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "group are working on um weight space",
      "offset": 2159.44,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "interpretability techniques. Um and",
      "offset": 2161.76,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "we've also just like kind of pulled in",
      "offset": 2163.76,
      "duration": 3.359
    },
    {
      "lang": "en",
      "text": "scientists, senior scientists from other",
      "offset": 2165.2,
      "duration": 4.639
    },
    {
      "lang": "en",
      "text": "fields who care a lot about uh uh",
      "offset": 2167.119,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "interpretability and just kind of have",
      "offset": 2169.839,
      "duration": 2.801
    },
    {
      "lang": "en",
      "text": "realized that this is one of the most",
      "offset": 2171.359,
      "duration": 2.801
    },
    {
      "lang": "en",
      "text": "important problems that we can can work",
      "offset": 2172.64,
      "duration": 4.719
    },
    {
      "lang": "en",
      "text": "on. So uh Owen Lewis who was a senior",
      "offset": 2174.16,
      "duration": 6.56
    },
    {
      "lang": "en",
      "text": "staff RS at uh Google um working on",
      "offset": 2177.359,
      "duration": 6.881
    },
    {
      "lang": "en",
      "text": "coding agents um came over and uh is now",
      "offset": 2180.72,
      "duration": 4.879
    },
    {
      "lang": "en",
      "text": "like leading a couple directions here",
      "offset": 2184.24,
      "duration": 2.4
    },
    {
      "lang": "en",
      "text": "for us.",
      "offset": 2185.599,
      "duration": 2.48
    },
    {
      "lang": "en",
      "text": "And you're recruiting, right?",
      "offset": 2186.64,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "And we're hiring. Yeah. scientists,",
      "offset": 2188.079,
      "duration": 5.201
    },
    {
      "lang": "en",
      "text": "engineers. Uh I think it's like we are",
      "offset": 2190.48,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "hiring scientists and uh that is like",
      "offset": 2193.28,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "deeply important for the future of the",
      "offset": 2195.28,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "field, but also like it's hard to just",
      "offset": 2196.8,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "like um it's hard to overestimate just",
      "offset": 2198.64,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "how important like good engineering",
      "offset": 2201.68,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "skills are.",
      "offset": 2203.76,
      "duration": 2.319
    },
    {
      "lang": "en",
      "text": "Incredible team.",
      "offset": 2205.04,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "Proud of the team. Yeah, for sure.",
      "offset": 2206.079,
      "duration": 4.881
    },
    {
      "lang": "en",
      "text": "This seems like core functionality for",
      "offset": 2208.24,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "one of for any of these foundation model",
      "offset": 2210.96,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "companies to have. And as you mentioned,",
      "offset": 2212.8,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "you know, Cryola, was it OpenAI?",
      "offset": 2214.56,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "Anthropic OpenAI has has their",
      "offset": 2216.88,
      "duration": 4.959
    },
    {
      "lang": "en",
      "text": "interpretability team as well. Um, how",
      "offset": 2219.04,
      "duration": 4.799
    },
    {
      "lang": "en",
      "text": "do you think about the rationale for",
      "offset": 2221.839,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "having a standalone mechan uh research",
      "offset": 2223.839,
      "duration": 5.681
    },
    {
      "lang": "en",
      "text": "company versus being inside one of the",
      "offset": 2227.359,
      "duration": 4.641
    },
    {
      "lang": "en",
      "text": "labs that should care deeply about this?",
      "offset": 2229.52,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "I think um we can just take a really",
      "offset": 2232,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "different approach if we're independent.",
      "offset": 2234.48,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "I think the benefit of being independent",
      "offset": 2236,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "is we can think independently, push",
      "offset": 2238.56,
      "duration": 3.519
    },
    {
      "lang": "en",
      "text": "things forward independently, and also",
      "offset": 2240.16,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "get like a broader view of the the",
      "offset": 2242.079,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "ecosystem. So usually if you're within a",
      "offset": 2243.68,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "lab, you're kind of doing",
      "offset": 2245.92,
      "duration": 2.96
    },
    {
      "lang": "en",
      "text": "interpretability work on your own models",
      "offset": 2246.72,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "and like kind of pushing forward the the",
      "offset": 2248.88,
      "duration": 4.479
    },
    {
      "lang": "en",
      "text": "field in in that way and you can make",
      "offset": 2251.68,
      "duration": 3.679
    },
    {
      "lang": "en",
      "text": "incredible progress that way. But I I",
      "offset": 2253.359,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "really do think that like a unique third",
      "offset": 2255.359,
      "duration": 6.081
    },
    {
      "lang": "en",
      "text": "party perspective uh is deeply necessary",
      "offset": 2257.76,
      "duration": 8.72
    },
    {
      "lang": "en",
      "text": "in in in the field and I think like yeah",
      "offset": 2261.44,
      "duration": 6.639
    },
    {
      "lang": "en",
      "text": "just given the team that we've assembled",
      "offset": 2266.48,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "like a lot of those folks like agree",
      "offset": 2268.079,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "with that and that's why they've joined",
      "offset": 2270,
      "duration": 5.359
    },
    {
      "lang": "en",
      "text": "and uh also like gives us like um an",
      "offset": 2272,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "ability to work with lots of interesting",
      "offset": 2275.359,
      "duration": 5.041
    },
    {
      "lang": "en",
      "text": "partners across different domains and we",
      "offset": 2277.68,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "can kind of unify those insights across",
      "offset": 2280.4,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "all these different domains. that that",
      "offset": 2283.04,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "teach us more about like the inner",
      "offset": 2284.88,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "workings of neural networks more",
      "offset": 2286.4,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "broadly. So we work across modalities",
      "offset": 2287.92,
      "duration": 6.159
    },
    {
      "lang": "en",
      "text": "like genomics models, exomic models, uh",
      "offset": 2290.16,
      "duration": 7.84
    },
    {
      "lang": "en",
      "text": "um image, video like language and also",
      "offset": 2294.079,
      "duration": 7.121
    },
    {
      "lang": "en",
      "text": "across model architectures and I think",
      "offset": 2298,
      "duration": 6.079
    },
    {
      "lang": "en",
      "text": "um all that just just helps.",
      "offset": 2301.2,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "Anthropic invested in in you all right?",
      "offset": 2304.079,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "Yeah, that's right.",
      "offset": 2306.32,
      "duration": 2.4
    },
    {
      "lang": "en",
      "text": "Say more about that and how you partner",
      "offset": 2307.119,
      "duration": 2.401
    },
    {
      "lang": "en",
      "text": "with them.",
      "offset": 2308.72,
      "duration": 2.72
    },
    {
      "lang": "en",
      "text": "Yeah, so they um I think we were their",
      "offset": 2309.52,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "their first ever investment. uh they um",
      "offset": 2311.44,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "they put in a check in in our last round",
      "offset": 2314.88,
      "duration": 6.16
    },
    {
      "lang": "en",
      "text": "and uh I think uh they just got they",
      "offset": 2317.44,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "just really care about interpretability",
      "offset": 2321.04,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "and really kind of see the future as we",
      "offset": 2322.56,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "do uh where um interpretability is just",
      "offset": 2324.32,
      "duration": 6.16
    },
    {
      "lang": "en",
      "text": "like pretty critical um to to the",
      "offset": 2328.32,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "future. So Dario just published an essay",
      "offset": 2330.48,
      "duration": 3.599
    },
    {
      "lang": "en",
      "text": "called like the urgency of",
      "offset": 2332.32,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "interpretability and um it's like one of",
      "offset": 2334.079,
      "duration": 6.161
    },
    {
      "lang": "en",
      "text": "his like four essays that he has on his",
      "offset": 2337.76,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "site and uh just like talking about like",
      "offset": 2340.24,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "how he views this as almost like a race",
      "offset": 2343.44,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "um and we see that very similarly a race",
      "offset": 2346,
      "duration": 6.24
    },
    {
      "lang": "en",
      "text": "to get interpretability prior to um you",
      "offset": 2347.839,
      "duration": 6.961
    },
    {
      "lang": "en",
      "text": "know super intelligent uh really really",
      "offset": 2352.24,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "intelligent AI models. I just think it's",
      "offset": 2354.8,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "like deeply critical to be able to",
      "offset": 2356.96,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "understand these models before they're",
      "offset": 2358.4,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "before we have like in his words like a",
      "offset": 2360.56,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "country of geniuses in in a data center.",
      "offset": 2362.64,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "Do you think interpretability can help",
      "offset": 2365.2,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "us with open models and you know I think",
      "offset": 2366.8,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "some people have a fear that you know",
      "offset": 2370.56,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "models trained in in other countries",
      "offset": 2372.8,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "that may or may not be enemies of the",
      "offset": 2374.72,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "United States you know have different",
      "offset": 2376.88,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "nationalist properties. Can",
      "offset": 2378.64,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "interpretability help us understand and",
      "offset": 2381.04,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "and even modify those for the you know",
      "offset": 2383.44,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "the American variants of of some of",
      "offset": 2385.52,
      "duration": 2.72
    },
    {
      "lang": "en",
      "text": "these models?",
      "offset": 2387.52,
      "duration": 2.88
    },
    {
      "lang": "en",
      "text": "Yeah. Well, I definitely think so. Um I",
      "offset": 2388.24,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "also think it's like relatively easy to",
      "offset": 2390.4,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "uh like if you take like a DeepSeek",
      "offset": 2393.04,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "model for example. Um it's relatively",
      "offset": 2395.04,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "easy to just like tune it or add in more",
      "offset": 2397.28,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "training data to remove a lot of the",
      "offset": 2399.04,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "like uh propaganda in the model. Um, and",
      "offset": 2400.88,
      "duration": 5.199
    },
    {
      "lang": "en",
      "text": "uh, but yeah, I think like",
      "offset": 2404.56,
      "duration": 3.039
    },
    {
      "lang": "en",
      "text": "interpretability can help like",
      "offset": 2406.079,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "understand like what's actually inside",
      "offset": 2407.599,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "of the model and then also like change",
      "offset": 2409.68,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "it and edit it to um, to like serve",
      "offset": 2411.359,
      "duration": 6.321
    },
    {
      "lang": "en",
      "text": "whatever end purpose that that you want.",
      "offset": 2414.64,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "How long do you think before you're",
      "offset": 2417.68,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "going to be pulled in as a witness in a",
      "offset": 2418.96,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "very important trial to try to",
      "offset": 2421.68,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "understand why a model did something in",
      "offset": 2424.56,
      "duration": 3.039
    },
    {
      "lang": "en",
      "text": "particular? That's",
      "offset": 2426.64,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "a good question. I I think",
      "offset": 2427.599,
      "duration": 5.281
    },
    {
      "lang": "en",
      "text": "uh,",
      "offset": 2430.56,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "few years,",
      "offset": 2432.88,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "who knows? Uh, I think it's really, you",
      "offset": 2435.28,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "know, uh, I mean, we're we're all",
      "offset": 2438.4,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "sitting in like the Bay Area right now,",
      "offset": 2440,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "but at this point, I'm I'm pretty AGI",
      "offset": 2442.4,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "pilled in that like, uh, I think AI AI",
      "offset": 2444.56,
      "duration": 6.24
    },
    {
      "lang": "en",
      "text": "progress will be pretty fast and pretty",
      "offset": 2448.16,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "quick and transformative to society in",
      "offset": 2450.8,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "ways that are really difficult to",
      "offset": 2453.44,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "anticipate from from where we're sitting",
      "offset": 2454.96,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "right now. And so, um, yeah, I do think",
      "offset": 2456.64,
      "duration": 6.16
    },
    {
      "lang": "en",
      "text": "that there will be a couple, you know,",
      "offset": 2460.24,
      "duration": 6.48
    },
    {
      "lang": "en",
      "text": "like, um, big failure cases of AI",
      "offset": 2462.8,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "models. And whether it's me called in",
      "offset": 2466.72,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "or, you know, somebody at a big lab or",
      "offset": 2468.48,
      "duration": 5.599
    },
    {
      "lang": "en",
      "text": "some, you know, uh, some other expert,",
      "offset": 2471.119,
      "duration": 8.161
    },
    {
      "lang": "en",
      "text": "um, I think that we're going to want to,",
      "offset": 2474.079,
      "duration": 7.441
    },
    {
      "lang": "en",
      "text": "uh, be able to explain a model's",
      "offset": 2479.28,
      "duration": 4.559
    },
    {
      "lang": "en",
      "text": "outputs. Um yeah,",
      "offset": 2481.52,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "I agree with you on the rate of uh",
      "offset": 2483.839,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "development by the way and I think it's",
      "offset": 2485.52,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "um I'm sure you've read these articles.",
      "offset": 2488.079,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "The human brain doesn't intuit",
      "offset": 2490.4,
      "duration": 2.16
    },
    {
      "lang": "en",
      "text": "compounding.",
      "offset": 2491.76,
      "duration": 1.52
    },
    {
      "lang": "en",
      "text": "No.",
      "offset": 2492.56,
      "duration": 2.48
    },
    {
      "lang": "en",
      "text": "And so, you know, I've even thought back",
      "offset": 2493.28,
      "duration": 4.799
    },
    {
      "lang": "en",
      "text": "to 20 years ago uh when I first met the",
      "offset": 2495.04,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "self-driving car initiatives and",
      "offset": 2498.079,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "Sebastian's team from Stanford had won",
      "offset": 2499.68,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "the DARPA challenge. You know, you could",
      "offset": 2501.599,
      "duration": 3.361
    },
    {
      "lang": "en",
      "text": "sort of see the glimmers of self-driving",
      "offset": 2503.52,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "cars. But even then, if you'd said, you",
      "offset": 2504.96,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "know, 20 years later, you would have a",
      "offset": 2506.56,
      "duration": 3.759
    },
    {
      "lang": "en",
      "text": "self-driving car in San Francisco take",
      "offset": 2508.24,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "you around. I'm not sure it would have",
      "offset": 2510.319,
      "duration": 3.441
    },
    {
      "lang": "en",
      "text": "been obvious that would be true and",
      "offset": 2511.92,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "maybe take a few took a few years longer",
      "offset": 2513.76,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "for the true visionaries. I think the",
      "offset": 2515.52,
      "duration": 2.799
    },
    {
      "lang": "en",
      "text": "same is going to happen with AI. I don't",
      "offset": 2516.96,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "think we fully fathom what the world's",
      "offset": 2518.319,
      "duration": 4.481
    },
    {
      "lang": "en",
      "text": "going to look like in 2030 or 2035.",
      "offset": 2520.48,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "Yeah. No, I couldn't agree more. And",
      "offset": 2522.8,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "it's just really hard to predict, you",
      "offset": 2524.96,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "know, like even if we feel like it's",
      "offset": 2527.119,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "going to happen really really quickly,",
      "offset": 2529.28,
      "duration": 5.039
    },
    {
      "lang": "en",
      "text": "uh it's hard to predict all of the ways",
      "offset": 2531.44,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "that society will be transformed.",
      "offset": 2534.319,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "Good note to end on. Should we do some",
      "offset": 2536.16,
      "duration": 2.48
    },
    {
      "lang": "en",
      "text": "rapid fire?",
      "offset": 2537.92,
      "duration": 1.6
    },
    {
      "lang": "en",
      "text": "Some predictions.",
      "offset": 2538.64,
      "duration": 2.64
    },
    {
      "lang": "en",
      "text": "Yeah. You need some predictions. These",
      "offset": 2539.52,
      "duration": 3.599
    },
    {
      "lang": "en",
      "text": "all recorded, so we'll hold you to it.",
      "offset": 2541.28,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "Great. Yes. Yes.",
      "offset": 2543.119,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "Eric in 2035 will look back on how wrong",
      "offset": 2545.52,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "he is with all these predictions. Yeah.",
      "offset": 2547.839,
      "duration": 6.321
    },
    {
      "lang": "en",
      "text": "Okay. Maybe first uh inference time",
      "offset": 2550.88,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "compute is vex important vector to scale",
      "offset": 2554.16,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "to scale uh models. Agree or disagree?",
      "offset": 2556.88,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "Uh mostly agree. I think it's one of the",
      "offset": 2559.52,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "important one of the things that we can",
      "offset": 2561.68,
      "duration": 2.72
    },
    {
      "lang": "en",
      "text": "scale up on. Yeah.",
      "offset": 2562.96,
      "duration": 2.8
    },
    {
      "lang": "en",
      "text": "What application category do you think",
      "offset": 2564.4,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "will break out next after code? I think",
      "offset": 2565.76,
      "duration": 6.559
    },
    {
      "lang": "en",
      "text": "there will be a lot of enterprise",
      "offset": 2568.72,
      "duration": 6.32
    },
    {
      "lang": "en",
      "text": "transformations that that happen. So",
      "offset": 2572.319,
      "duration": 6.401
    },
    {
      "lang": "en",
      "text": "just like automating like manual routine",
      "offset": 2575.04,
      "duration": 6.16
    },
    {
      "lang": "en",
      "text": "tasks that people are doing like many",
      "offset": 2578.72,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "many times a day",
      "offset": 2581.2,
      "duration": 4.639
    },
    {
      "lang": "en",
      "text": "employment impact",
      "offset": 2583.2,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "from AI",
      "offset": 2585.839,
      "duration": 2.961
    },
    {
      "lang": "en",
      "text": "vast",
      "offset": 2586.88,
      "duration": 7.28
    },
    {
      "lang": "en",
      "text": "in in uh vast but uh once you cross a",
      "offset": 2588.8,
      "duration": 9.36
    },
    {
      "lang": "en",
      "text": "chasm I think it happens quickly. Um I",
      "offset": 2594.16,
      "duration": 7.04
    },
    {
      "lang": "en",
      "text": "think uh well my my last company was uh",
      "offset": 2598.16,
      "duration": 6.24
    },
    {
      "lang": "en",
      "text": "helping um find early career jobs for",
      "offset": 2601.2,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "people and using AI to to automate that",
      "offset": 2604.4,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "and uh I think that that's where we're",
      "offset": 2606.8,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "going to feel the impact first.",
      "offset": 2608.64,
      "duration": 2.4
    },
    {
      "lang": "en",
      "text": "Um",
      "offset": 2610.24,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "I agree. Recommended piece of content or",
      "offset": 2611.04,
      "duration": 4.799
    },
    {
      "lang": "en",
      "text": "reading for for AI fans maybe spec",
      "offset": 2613.68,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "specifically in your field.",
      "offset": 2615.839,
      "duration": 3.201
    },
    {
      "lang": "en",
      "text": "I think the the original circuits thread",
      "offset": 2617.28,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "that I was referencing a couple times",
      "offset": 2619.04,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "like that's still fantastic. What's u",
      "offset": 2620.72,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "either an AI app or maybe just an",
      "offset": 2624.4,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "experience that you've had with AI that",
      "offset": 2626.48,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "has blown you away recently? Something",
      "offset": 2629.44,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "that just took a breath away.",
      "offset": 2631.92,
      "duration": 6.64
    },
    {
      "lang": "en",
      "text": "I think my like",
      "offset": 2634.4,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "one of those moments that you really",
      "offset": 2638.56,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "just like feel how fast AI is happening.",
      "offset": 2640,
      "duration": 5.359
    },
    {
      "lang": "en",
      "text": "Like when I first uh played with 01 Pro,",
      "offset": 2642.4,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "like that was a a model that I just",
      "offset": 2645.359,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "really felt like was actually reasoning",
      "offset": 2647.52,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "about the world. and um seeing like the",
      "offset": 2649.359,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "kind of cross-domain transfer to I would",
      "offset": 2653.28,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "ask it a strategic question and it felt",
      "offset": 2655.359,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "like it would actually understand like",
      "offset": 2657.44,
      "duration": 3.679
    },
    {
      "lang": "en",
      "text": "all the levers that I was considering",
      "offset": 2659.44,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "with the business and um considering",
      "offset": 2661.119,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "that like at least relatively",
      "offset": 2663.359,
      "duration": 3.361
    },
    {
      "lang": "en",
      "text": "thoughtfully and being a thought partner",
      "offset": 2664.72,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "and that's both exciting because I now",
      "offset": 2666.72,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "have this model that I can talk to about",
      "offset": 2669.52,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "all sorts of critical problems but uh",
      "offset": 2671.119,
      "duration": 5.281
    },
    {
      "lang": "en",
      "text": "and not just of course like trust it",
      "offset": 2674.56,
      "duration": 5.279
    },
    {
      "lang": "en",
      "text": "blindly but um but also like it's like",
      "offset": 2676.4,
      "duration": 5.84
    },
    {
      "lang": "en",
      "text": "wow Wow. How did it how did this happen?",
      "offset": 2679.839,
      "duration": 2.801
    },
    {
      "lang": "en",
      "text": "You know,",
      "offset": 2682.24,
      "duration": 2.32
    },
    {
      "lang": "en",
      "text": "interesting. One of the things I've",
      "offset": 2682.64,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "learned recently is that AI is still",
      "offset": 2684.56,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "struggling to understand humor.",
      "offset": 2686.24,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "And one of my partners, Andrew, actually",
      "offset": 2688.88,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "had this joke that uh humor is humans",
      "offset": 2690.72,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "way of showing off intelligence without",
      "offset": 2692.72,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "actually explicitly bragging. Um, and so",
      "offset": 2694.96,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "maybe there is a lot of embedded",
      "offset": 2698,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "intelligence in humor.",
      "offset": 2699.2,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "Do you think interpretability will help",
      "offset": 2701.52,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "us pinpoint",
      "offset": 2703.359,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "to figure out humor? Yeah. To figure out",
      "offset": 2704.8,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "why AIs don't have a sense of humor. or",
      "offset": 2707.04,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "will help them to develop it",
      "offset": 2709.2,
      "duration": 6.08
    },
    {
      "lang": "en",
      "text": "perhaps. Who knows? Yeah. Uh I hope so.",
      "offset": 2711.76,
      "duration": 6.24
    },
    {
      "lang": "en",
      "text": "Yeah. I can uh I think if I you know",
      "offset": 2715.28,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "wake up to a a model like telling me",
      "offset": 2718,
      "duration": 7.119
    },
    {
      "lang": "en",
      "text": "jokes and Rolof's voice that would be uh",
      "offset": 2721.04,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "that",
      "offset": 2725.119,
      "duration": 3.561
    },
    {
      "lang": "en",
      "text": "would be terrifying.",
      "offset": 2725.52,
      "duration": 3.16
    },
    {
      "lang": "en",
      "text": "Okay, we'll close with one last question",
      "offset": 2729.359,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "on a prediction in your field. Uh do you",
      "offset": 2730.96,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "think we will ever reach the point where",
      "offset": 2733.839,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "we feel like we confidently understand",
      "offset": 2735.52,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "the features, the circuits, the",
      "offset": 2738.16,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "patterns, the weights of a neural net?",
      "offset": 2739.68,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "And if so, what year do you predict",
      "offset": 2741.52,
      "duration": 2.88
    },
    {
      "lang": "en",
      "text": "we'll reach that point?",
      "offset": 2742.96,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "I think we can. I think that it might",
      "offset": 2744.4,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "not look like what you just said, like",
      "offset": 2747.119,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "the features, the circuits, the I think",
      "offset": 2748.88,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "that it requires maybe a",
      "offset": 2750.96,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "reconceptualization of what's actually",
      "offset": 2752.4,
      "duration": 4.719
    },
    {
      "lang": "en",
      "text": "going on inside the model, like",
      "offset": 2754.24,
      "duration": 5.839
    },
    {
      "lang": "en",
      "text": "a deeper, more fundamental understanding",
      "offset": 2757.119,
      "duration": 5.361
    },
    {
      "lang": "en",
      "text": "of the units of computation of a model.",
      "offset": 2760.079,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "It's almost like discovering truths",
      "offset": 2762.48,
      "duration": 3.599
    },
    {
      "lang": "en",
      "text": "about the universe or about like neural",
      "offset": 2764.079,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "nets in this case. Uh, but yes, I think",
      "offset": 2766.079,
      "duration": 4.481
    },
    {
      "lang": "en",
      "text": "we're on track. I think we can do this",
      "offset": 2768.48,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "and I think we can do this",
      "offset": 2770.56,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "in and hold me to this in 2028. We're",
      "offset": 2772.319,
      "duration": 6.321
    },
    {
      "lang": "en",
      "text": "going to figure it all out. Yeah.",
      "offset": 2776.56,
      "duration": 2.96
    },
    {
      "lang": "en",
      "text": "Fantastic.",
      "offset": 2778.64,
      "duration": 2.56
    },
    {
      "lang": "en",
      "text": "Yeah. Just a few years. I think I think",
      "offset": 2779.52,
      "duration": 2.24
    },
    {
      "lang": "en",
      "text": "we're close.",
      "offset": 2781.2,
      "duration": 2.32
    },
    {
      "lang": "en",
      "text": "Just in time for the LA Olympics.",
      "offset": 2781.76,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "Yeah, that's right.",
      "offset": 2783.52,
      "duration": 2.96
    },
    {
      "lang": "en",
      "text": "Just in time for your next round of",
      "offset": 2785.28,
      "duration": 2.64
    },
    {
      "lang": "en",
      "text": "funding.",
      "offset": 2786.48,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "I'm kidding. Eric, thank you so much for",
      "offset": 2787.92,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "doing this today. Ruf and I love the",
      "offset": 2790.24,
      "duration": 2.64
    },
    {
      "lang": "en",
      "text": "conversation.",
      "offset": 2792.079,
      "duration": 1.28
    },
    {
      "lang": "en",
      "text": "Thank you.",
      "offset": 2792.88,
      "duration": 2.4
    },
    {
      "lang": "en",
      "text": "It was a pleasure. Yeah. So much fun.",
      "offset": 2793.359,
      "duration": 4.671
    },
    {
      "lang": "en",
      "text": "Thanks for having me.",
      "offset": 2795.28,
      "duration": 6.029
    },
    {
      "lang": "en",
      "text": "[Music]",
      "offset": 2798.03,
      "duration": 3.279
    },
    {
      "lang": "en",
      "text": "[Music]",
      "offset": 2803.97,
      "duration": 6.06
    },
    {
      "lang": "en",
      "text": "[Music]",
      "offset": 2813.76,
      "duration": 13.209
    }
  ],
  "cleanText": "So Goodfire is an AI interpretability research company really trying to answer the question of, you know, what's actually going on inside the mind of a neural net. Um, so kind of the ultimate goal and the ultimate uh reason why we started everything was like uh we just see neural networks kind of going into more and more mission critical context, and I think it's going to be enormously transformative for society, but in order to do so, and you you want to uh build it safely, powerfully, reliably, and uh I think like it's going to be critical to be able to understand, edit, and debug AI models in order to to do that, and so that's what we're kind of enabling for for the very first time. It's like unlocking the black box of a neural network such that you can intentionally design it rather than just kind of like grow it from from data.\n\n[Music]\n\nWhat if we could crack open the black box of AI and see exactly how it thinks? Today, we're joined by Eric Ho, the founder of Goodfire, who's building tools to peer inside neural nets and understand their minds. Eric reveals how his team has successfully disentangled the mysterious phenomenon of superposition, where single neurons encode multiple concepts and can now steer AI behavior with increasingly surgical precision. We explore whether interpretability could help us discover new biological insights, edit out harmful behaviors from large language models, and even understand our own brains better. Eric boldly predicts that we'll fully decode neural nets by 2028, transforming AI from black boxes into more intentional design. Enjoy the show.\n\nEric, thank you so much for joining us today.\n\nOf course. Yeah, happy to be here. Thanks for having me. First question, can we ever trust generative AI if these foundation models are very much black boxes?\n\nCan we ever trust them if they're black boxes? Uh, so I guess like you know, maybe thinking about like um what would happen if we were to just kind of deploy AI models as black boxes like in perpetuity. Um, so the blackbox way to to do this would be like um and I'm I'm kind of assuming that we're playing this forward a few years and we want AI in charge of like really mission critical applications like um maybe being in charge of our power grid or making big investment decisions, maybe even for a seed investment at Sequoia or like a really large, you know, like um million dollar like investment decision. And I think like the blackbox way to to make sure that the AI is performing appropriately is like you take a look at evals and you run like a bunch of like evaluations to make sure that it's behaving appropriately in test sets and then you look at its track record and see if it's like you know reliable enough to perform across a wide variety of things. And uh I think like the question then is like why not take all of this additional signal that you get from looking inside a neural network and trying to play forward like how it's going to behave in a much wider, broader set of situations. Like why not like look inside and actually like get a bunch more uh reliability, certainty about how it's thinking, how it's approaching the problem. And uh I think like you're just leaving a bunch on the table if you're not like looking for all the signal that you can get. So the way that I think about this is like I don't know when you're manufacturing a new drug. It's like you can do the blackbox way of just like seeing how humans respond to the drug in like a clinical trial. Whereas like you could also just like kind of look inside and like look at biochemically like how the drug is um uh processed or like uh drug interactions uh at the molecular or cellular cellular level. And uh yeah, I just feel like there's so much to be learned when you actually like look inside and deeply understand something.\n\nHow possible do you think it is to look inside and deeply understand a large language model? Do you think it's a you know on the scale from hopeless, we can't ever understand it. It's just a black box. Too many too many neurons to we can actually map out the mind of a neural net. I'm curious where you think the field will be.\n\nWell, I'm I'm very biased, but I think it's very, very possible. Uh so I mean a lot of the people in mechan like come from um backgrounds in like computational neuroscience or like cognitive science, and uh those people when you're like actually looking inside the brain, um you spend so much time like trying to understand like what a single neuron does or just getting any signal whatsoever. Um and in the the field of mechan, you have perfect access to the neurons, the parameters, the weights, the attention patterns of a a neural network. So you're you're coming in with a huge advantage for like uh at least like you get all of the data that you you need. So then the real question is like how can we make progress? How can we um try to understand and seek to understand all of it? Uh and I think we just got to try. I think it's deeply necessary and critical for the future. And we have like a norm established. you can explain some percentage of the network by reconstructing it and extracting you know its concepts and the features that it uses in order to generate its response, and once you have at least a baseline un like rudimentary understanding kind of where we're at right now, you can hill climb on that metric and seek to understand like more and more of the network.\n\nDo you think it's going to be necessary for us to understand neural nets to really harness them long term because I think many other technologies we've invented along the way humans didn't really understand underlying physics or chemistry, but still we were able to make good of medicines or you know totally sort of basic propulsion techniques without understanding you know all the physics.\n\nYeah, I think it's going to be critical for the future just given how transformative I think AI is going to to be. Like I think AI is going to be everywhere running mission critical um parts of our society. And like we can get really, really far just by treating AI as a black box, but I don't think we can truly be able to intentionally design AI as like the new generation of software without like white box techniques. So maybe one example I think about is uh you know in the um early uh 17th century uh you invented like the steam engine and we're able to just like um increase the size of the boiler and increase the amount of pressure going in and it scaled reasonably well, but steam engines also like blew up like um well, we didn't understand thermodynamics at that time. So we didn't actually know like at what point did uh like the ideal size of like the boiler or like the ideal pressure, the the ideal way to construct a steam engine. And so like after we invented thermodynamics, like things started becoming a lot safer, a lot more reliable, and like huge innovations happened afterwards. But already like you know the steam engine kicked off like the industrial revolution. So even just by like uh treating it as a black box, you get a really long way.\n\nYeah. Do you think there's any chance that if we understand neural networks in a computer science context, it might actually help us accelerate our understanding of neuroscience for the Human brain?\n\nI think so. But uh that's like that's a big claim I think. Uh so like we were just having an interesting conversation last night. Uh we had like a dinner together um about like uh do we um do we think in language? Do you think in concepts or something else entirely? Like I'm a person that doesn't really think in language. I think much more like conceptually, maybe in like the latent space of of models. Whereas like our head of product, Sonya Huang, said that she basically is totally faithful to her own chain of thought, like speaks in language, and she basically just thinks like sequentially with like a really, really strong internal monologue. So like maybe maybe some of these insights that we get like will will translate to to humans and our own psychology. And I think that's the hope. It's like yeah, the more that we can understand about AI, like hopefully the more that we can understand about ourselves.\n\nThere's an interesting analogy by the way that in neuroscience often things that have gone wrong help illuminate and create insights into the human brain.\n\nYeah.\n\nYou know people who suffer from specific conditions or people who suffered particular brain injury types have actually perversely enabled us to better understand the brain accidentally. I wonder if something similar might happen with neural networks as Yeah, I hope so.\n\nWhat What's that like uh popular story about the guy who just like got an iron rod through his his brain and it made him like a totally different person?\n\nYeah.\n\nYeah.\n\nAnyway,\n\nyeah, there's also this uh you know to add to that um there's this concept of of universality where like um among totally different neural networks, like similar kind of like circuits or like thought patterns tend to emerge between all these neural networks. So um like even in um like we found in in vision models like very similar uh kind of circuits to our own like visual cortex. Uh and I think like you know there there's this like idea of universality where maybe like intelligence is just this like thing that you gradient descent to and then like uh that's how our brains found like intelligence and that's how artificial minds would would find intelligence um as well, like there's some truth to intelligence. My own neural net is probably pretty sparse.\n\nIt's pretty sparse.\n\nUm, I would love to double click into some of the results you've had from Goodfire and the broader field and and your lab, but before we get into it, can you say a word about Goodfire and and what you all are building?\n\nYeah, so so GoodFire is an AI interpretability research company really trying to answer the question of, you know, what's actually going on inside the mind of a neural net. Um so kind of the ultimate goal and the ultimate uh reason why we started everything was like uh we just see neural networks kind of going into more and more mission critical contexts, and I think it's going to be enormously transformative for society, but in order to do so, and you you want to uh build it safely, powerfully, reliably, and uh I think like it's going to be critical to be able to understand, edit, and debug AI models in order to to do that, and so that's what we're kind of enabling for for the very first time. It's like unlocking the black box of a neural network such that you can intentionally design it rather than just kind of like grow it from from data.\n\nAnd if everything goes right, what do you think will be the impact that you all have on the world?\n\nUh so maybe one one metaphor that we we like and and think about is like yeah, right now like you just kind of like grow AI from a seed and then it just like grows like a a giant tree and it grows all wild and crazy. right now we don't know really know like kind of a lot of the things that it's growing into and all sorts of like interesting and weird stuff can can happen with the really large neural net, but uh if everything goes right with interpretability, we know like we'll know every how every single piece of training data affects like the cognition that the model develops, the um units of computation that it uses, and I almost think of it more as like bonsai where you want to kind of like intentionally design and shape and grow the neural network, like still in an unsupervised like AIdriven approach, like we're we're not going to hand prune every single weight of a neural network, but uh I think we'll gain the ability to like during every single piece of the training post-training process, like just intentionally shape an AI model such that it you know serves humanity and does what we want.\n\nsounds like a parallel to the Human genome project in some sense, yes, given some of the work I've done in genetics. So there this idea that we need to read DNA. We need to understand the building blocks of life. And then ultimately now we're starting to edit DNA and use crisper to come up with interesting cures for diseases or an ability to edit crops to make them more resistant to pesticides and things like that. So it's just it's very interesting parallel.\n\nYeah, definitely. No, I think we we think about that, you know, analogy a lot. And I know you had uh Patrick Shu on the the podcast, you know, at some point uh as well, and we're working with him at Arc Institute to uh to yeah, like crack the code of of the Human genome as well. And uh I think there's there's a lot of really interesting parallels and also direct applications of AI interpretability um as well.\n\nWould you go so far as actually making edits? What I heard from you earlier, the bonsai analogy was a little bit of a shaping um which which is quite different in my mind from editing. you know, shaping to me might be, you know, train and be fit so that your body can survive given a certain DNA and then there's editing which is altering the DNA. Uh, are you going to do both?\n\nYeah, I think in short, yes. Uh I don't know like what the So in Turpp as a field, like there's still a lot to figure out and so it's still pretty um still pretty new, but I think in bonsai you also prune a lot of branches and you prune a lot of like the areas that you don't want to grow such that you can kind of shape the the overall tree to like grow in the the pattern that you want. So I think like you know the the eventual system that we hope to build, like you can ask questions of the model, like why did you why did you come up with this response and get a faithful explanation while also being able to make direct surgical interventions in the mind of the model such that we can remove harmful behavior, enhance good behavior. Um, and uh, still remains to be seen whether like it's just like a direct weights modification or like some other like kind of shaping function that um, is most effective.\n\nIf you think about the some of the ways that people are trying to prune these bonsai trees today, I think it's a lot of prompt engineering, you know, fine-tuning, RL tuning increasingly now. What do you think about that as the approach to kind of steer the behavior of these models uh versus actually go in and introspect and examine each of the individual neurons?\n\nFundamentally like these are blackbox things, like all sorts of weird things can happen when you like fine-tune a model for example or like you know prompt a model and take it out of distribution and it can say all sorts of crazy stuff. So, uh, the the paper that's most interesting about this recently, I don't know if you've you've caught this, is this like emergent misalignment, um, study, no? Okay, this is like uh Owen Evans group um where if you fine-tune a model on just insecure code, so it's just like bad code that you know has all sorts of like cyber security vulnerabilities, it'll then start doing all sorts of insane things like telling like wanting to enslave humanity or like praising Hitler and other dictators. And it's a really surprising result because it's just insecure code. And so yeah, it kind of shows that there's like um maybe like what you're doing with fine-tuning is you're telling the model\n\n\nlike hey do more of this, less of this, and like uh almost like enhancing the circuits that uh you want kind of more of, but you can also have like all sorts of unintended consequences like this um that that show up. And these circuits, these are still like really alien cognition. Like there's some parallels to humanity, but we really don't understand how these neural networks think, and they're not like human thinking. So if you enhance the bad code snippets, it also is like fundamentally linked to maybe all sorts of like other undesirable behaviors and properties.\nThere's sort of a different twist on the nature nurture debate.\nYeah.\nBecause in that situation, it almost feels as though you've imbued that particular model with bad DNA, if you will. Just, you know, uh, it's sort of fundamentally an evil thing or a bad thing, and then it ends up with manifesting all sorts of bad behavior in other domains. It's really interesting.\nYeah, maybe or maybe these models kind of understand right and wrong, and if you enhance the wrong, then all sorts of other behavior is interlinked and expressed, but I don't know. The way I think about it, like these models, the models are just like the functions of their training data, and uh, these models are trained on everything, like all sorts of like misbehavior as well. And you want it trained on like um, like incorrect behavior as well because like otherwise it won't know to refuse harmful requests or to not do a certain set of things.\nDo you have an intuition for why different models have different base models have different personalities? Like for example, the the newest Claude series, like I think one of the models, maybe Opus or so on, it is, is, you know, really cares about animal welfare, for example, and the others don't. Like do you have a sense for why these models develop pretty distinct personalities?\nI think it's just a function of how they're trained, and it's really, really hard to uh anticipate in in advance, like um, yeah, I don't know. I, I, I feel like uh, it might just be me, but like Cloud 4 Opus 2 is like enormously sycophantic. Like I'll kind of nudge it in one direction and it'll just like agree with me wholeheartedly and then nudge it in the other direction, like pose a counter example, and it'll just be like, yes, I was totally wrong before. Like nothing I said earlier was was correct. And I just think it's like really, really hard. It's like kind of goes back to like the witchcraft almost of uh training an AI model today where you're just like throwing in training data into the model and like whispering the incantation of gradient descent and then like trying to like get what you want out of it, and something pops out, and then it like really cares about animals. Oh, great. Like that's that's great.\nI'd love to talk about your research results so far, you know, both at Goodfire and in the broader mechan field as a whole. Maybe could you just give us a a 30,000-foot fly overview of, you know, mechan as a field, how old is it, what are the key results so far, what are the big open questions?\nYeah, so mechan as a field, um, I think like maybe just like in this tradition that we're building on, uh, I think there were all sorts of studies like looking inside neural networks all the way back when we first, you know, designed neural networks, but I think once we um, I think the the way that the field kind of thinks about itself, like Mechanistic Interpretability, was started at like OpenAI with Chris Ola and Nick Camarada and a couple other folks who first put out like this really big circuits thread that posited like three things. One is like there are features in neural networks which are directions in latent space that represent concepts that the model uh uses to generate its response circuits. Uh, these are like features that fire together to um create like higher-order concepts. The example that they lay out is like you have a car window detector and then a car like body detector and then a car wheel detector, and then that's like a car circuit. And uh, universality is the third tenant, like uh, similar circuits evolve in um different neural networks. And so this was like almost like the start of the field of mechanistic uh interpretability in in my mind. Um, and so uh, that really kicked off a lot of uh, you know, interesting research and results and like the feature circuits paradigm and uh, I think like the main players um in the field, there's a lot of academic labs that are doing great work like Anthropic. So Chris Ola is one of the co-founders of Anthropic and building a great interpretability lab there, and uh, Deepmind has an inter interpretability lab as well. And then we were kind of like the newer entrance on on the field and on the stage. Um, and uh, I think one of the other really key things to have happened was um understanding and uh mostly resolving superposition. So uh, superposition is this idea that like uh, each neuron is responsible for encoding like multiple concepts, and uh, there are more like concepts than dimensions in a neural network. So you think about a neural network as like a giant compression algorithm. You're like compressing like the entirety of the internet into like a relatively small number of parameters.\nAnd so that means every single neuron needs to encode or at least every single layer of the model needs to encode more concepts than it has like dimensions. And so there's like this concept of superposition where you have um concepts represented as like near orthogonal directions in in latent space um such that you can represent all of these concepts in in a model's latent space. And so to resolve this, you have to almost untangle and unscramble a neuron such that it's responsible for like one clean interpretable concept. And so um, it's like a group at Apollo Research um led by like Lee Shy, who's actually now at Goodfire, first kind of pioneered like sparse autoencoders for for language models, and Anthropic also like really popularized this with their like big paper like towards monoseity and then right afterwards like scaling monanticity, showing that you can essentially unscramble these neurons into uh higher-order concepts um reliably and at scale with like arbitrarily large neural networks. And I think that was a really big moment for interpretability where you can now in a totally unsupervised way unscramble neurons of a neural network uh to understand them and get clean concepts. Uh, so the concepts aren't like totally clean yet. You can't like edit them super well. There's all sorts of problems with this, but like it's almost like a really big step forward for the field such that like that we can do this in an unsupervised way, and the techniques and interpretability scale, which is really important.\nDoes that mean the superp position isn't real or that you like the Heisenberg's uncertainty principle, you sort of collapse it at a particular moment in time to know that in this instance it represents a particular direction?\nUh, so I think it means it was real, like neurons are responsible for, you know, encoding multiple concepts such that u once you unscramble them, then you can do really interesting things with like a clean neuron. So the way that we do this is like using an interpreter model trained on the activations of a base model, and then um now you have all sorts of neurons in the interpreter model that represent like theoretically clean sparse concepts.\nIn the interpreter model, the original model still has this characteristic of superposition.\nThat's right.\nOkay, got it. Thank you. And in the interpreter model, you unscramble these neurons and you associate these concepts with the concepts in the base model that you're trying to interpret, and then you can do interesting things with it.\nGot it. Thank you.\nYeah, of course.\nHow solved of a problem is this then if you've if you've already been able to kind of disentangle the superp position, then haven't you already mapped out the the mind, so to speak, of the neural net and and what's what's ahead? I think partially, I think it's a partial mapping, and the technique has all sorts of all sorts of flaws as well that we can improve upon, but I think like it gives us the first step towards understanding um these models uh especially going from toy model to like actual network that people care about. Um, so we've done a bunch of work recently on um R1, so it's a 671 billion parameter mixture of experts models. It's a it's a big boy model. Uh, and like the techniques scale really nicely all the way up to that point because, you know, it's just more AI, more training of an interpreter model.\nSo obviously I presume there's an asmtote here to understanding because the models are going to get more and more complex over time and we're going to beef them up.\nYeah. And so I'm guessing it's sort of, you know, like the battle of Sisyphus at some point, you know, this is a never-ending pursuit, which is great. Um, is that correct? Do you agree with that? In some ways, but I also think that like so the techniques that we've developed work on toy models all the way up to like yeah, big network that's like more capable and more intelligent and better, and I think like the techniques also scale effectively with model intelligence. So one part of our pipeline is that for every single latent concept in our interpreter model, we associate that with um and try to we we get another language model to reason about like what that concept actually represents in the base model. So this is a concept called auto interpretability, which Nick Camarada, who's at Goodfire now, invented this technique at OpenAI, um uh pioneered, and this technique because it's a language model reasoning about, you know, what a neuron represents, scales with the quality of the language model, so it actually gets better. So because we use AI in order to understand AI, like the better that you know our our models are, like these analysis agents are at interpreting like what's actually going on, the better we are able to understand them.\nGot it. And our interpreter model techniques also, it's just like if we develop better interpreter models, they theoretically should translate to more and more intelligent and larger and larger networks because these are like unsupervised scalable techniques, and that's like the paradigm in in AI interpretability.\nAll right. When do you think you reach a minimum threshold that makes you feel u it's ready for a real-world application?\nMaybe we're there already.\nI think we're there. Yeah. I think I think um the first real-world applications are already out there, and uh yeah, I think I think we're there on like the the very, very early applications. Yeah.\nCan you share more about this?\nYeah, I was being unnecessarily cryptic. So um yeah, a couple of the partnerships I'm I'm most excited about. Uh, so we worked with Arc Institute, um, like I I mentioned a little bit earlier, to understand uh and interpret EVO 2, which is their like kind of DNA uh foundation model. So it's a sequence-to-sequence model. So it like takes in um a sequence of nucleotides and it predicts the next nucleotide in a in a sequence. And our theory is like this is a narrowly superhuman model. So we really like to work on narrowly superhuman models because it can teach us something about the world that humans don't really know. And so the idea is like this model is representing just an enormous amount about the biological world in order to generate the next and properly model the next nucleotide in a sequence. So what we did um was we sought to understand like what does it actually know such that it can model the world so so effectively. Um, so what we did was we trained uh sparse autoencoders on the activations of this this model, um, extracted all sorts of features that were related to uh concepts that the model like should know, like kind of normal biological concepts that we have like really strong ground truth annotations for. So these are like uh tRNAs, RNAs, star coding sequences, like all sorts of like biological concepts that we have ground truth annotations are we associated with this model. And then the question is like, okay, now we have all of these other features of the model that we've extracted. What do they mean? What what are they? They might just be ways that the model is computing and thinking, or they could represent, you know, like novel biological concepts that the model's using to generate the next, you know, nucleotide in a sequence.\nThat's really interesting.\nThere was for a long time there was this idea that we have a bunch of junk DNA. You may have read about this, and turns out a lot of that DNA actually serves a particular purpose in a different part of evolution or that they govern the expression of other genes. And so, you know, nature generally doesn't want to harbor things that don't have value because it's expensive, you know, just from a biological system point of view. So, that's super interesting. I'm looking forward to the results.\nYeah, totally. Totally. And, uh, I think like hopefully using unsupervised AI techniques, like we can um, better understand like what all these, you know, portions of the DNA are actually doing. Like maybe we can discover the idea of junk DNA like faster or or like or understand that like DNA is not junk DNA like faster and or like yeah, just discover like totally novel things that like genes are are doing and expressing within us.\nYeah.\nWhere's the research as far as going from understanding and mapping towards editing? So for example, being able to reach in and you know, change this weight from here to there. Uh, I'm I'm curious if you all have any results there yet.\nYeah. Uh, so we've done most of our editing work on like language models and image models. Like our our most recent kind of release was a a um a paint with Ember. Ember is our like kind of foundational infrastructure for interpretability. Um, and uh, what we were able to do with this like image model demo was targeted precise control over an image model by by painting. So we could extract latent concepts like a um a dragon or dragon wings or an ocean or a pyramid and then take these concepts and directly intervene on like the portion of a canvas that we want to intervene on. So you can paint on a dragon with wings and then add like a crowd in the corner and add like a pyramid, and it's a it's a really fun demo uh that's just like a kind of a joy to play with. Um, so it's it's out right now. Anybody can play with it. It's just like paint.goodfire.ai.\nBut we're able to I think reasonably intervene uh in like certain situations on on a model's latence and like steer the model to do what we want. But uh, we haven't quite cracked like the idea of direct precision surgical edits that like create a new model that you want to like use and doesn't have like any unintended side effects. So, uh, that's like still, you know, something that we're pushing pushing on and and trying to figure out.\nDo you think that's where the field ultimately goes or or do you think people are focused on different parts of the field?\nI think there are many places where the field is going to go, and this is one of them. Uh, like interpretability is almost like such a general term that I again, I'm I'm biased, but I think it's just like governing and underlying like all\n\n\nAspects of AI.\nIt's like, um, anytime you prefer to take a white box approach to doing something versus a black box approach, like interpretability can probably help in the future.\nSo, how do you select your training data?\nMaybe you want to understand, like, whether the training data is surprising to the model before, like, putting it into the model, because then it can have, like, the most impact on, um, on training.\nYeah, just like in every single part of, like, the AI development stack, I think, like, interpretability will help and change the way that we do things.\nIf AI foundational models go the way that a lot of software has gone, certainly infrastructure software, where much of it is open source or open weight, is there an opportunity for you to play an invaluable role in judging the biases or likely outcomes of using different open weight models?\nI think we could.\nYeah.\nUm, so there's maybe, like, two, two areas of research that we're interested in that intersect with this idea.\nSo, um, auditing, so, like, how do you take a model, understand, like, what's going on, find, like, problematic behavior and good behavior, and hopefully get rid of the bad behavior and enhance the good behavior.\nSo, I think, like, as AI gets, um, deployed in more and more mission-critical contexts, like, that becomes more important.\nUm, so, uh, and then also model diffing.\nSo, it's like, when you have two checkpoints of a model, like, how do they differ from each other and what's changed?\nSo, the recent kind of, like, GPT40, like, was enormously sick of antic for a period of time.\nUh, just like telling, just like, really gassing up the user, like, tell them that they're doing great.\nYou still is.\nPat recently asked it who the most handsome cribble board member was, and it was like, definitely, definitely Pat Greedy.\nStill a bit sick of antic.\nThat's so good.\nThat's so good.\nUh, yeah.\nUm, but yeah, like, model diffing, like, you should be able to detect, like, uh, how a model has changed from checkpoint to checkpoint, like, what surprising things have happened that were, um, that are now contained in the network that weren't there before.\nWhy do you think it was so hard for OpenAI to roll back to a less psychopantic version of the model?\nAnd in an ideal state of the world, is there almost an, you know, a dial and a knob that the OpenAI guys could tune of on a scale of 0 to 100, how sick of antic do you want the model to be?\nLike, do you think we can get there?\nI don't know what questions you're asking of the model, by the way, cuz I never encountered this particular problem.\nAlways does this with me.\nAnd then sometimes it's brutal the other way.\nI ask at the best AI podcast, and it lists 20 things with no training data.\nI ask, what about what about us?\nIt's, oh, I didn't want to, I didn't want to give a biased result.\nThat's so funny.\nWell, that's that's part of what users want, right?\nThey kind of want sick of fancy, like, you know, um, people want to hear what they what they want to hear.\nSo, when you RL a model, I think fundamentally you're going to get, uh, I think it's just kind of a symptom of, like, RL.\nIt's like, you like, this is what users want.\nThis is user preferences.\nAlong the way, you've dropped some names, and it seems as though most of them have ended up at Goodfire.\nI presume there is a certain number of very talented people in this field, and you've unfairly seem to gather them.\nUh, can you describe a little bit more about your team, what you've pulled together?\nYeah.\nUh, so I mean, I, I, I think we have a really fantastic team, and that's what we've been, you know, spending a lot of our, our time on the last year, just kind of, like, uh, I think assembling a team of, you know, world-class interpretability experts that, um, really have a shot of cracking this, this problem.\nUm, so it starts with my, you know, like, co-founders, you know, I, I had worked with, uh, Dan Balsam, our CTO, for many years at my previous company.\nUm, and, uh, so he's our CTO, um, and, uh, our chief scientist, Tom, who founded the interpretability team at Google DeepMind way back in the day, and, uh, yeah, and just have assembled many of, like, the early folks in the field.\nSo, uh, Tom, um, Nick Hamarada, who is one who's, like, working very closely with Chris Ola, who is generally considered, like, the founder, uh, of of the field of Mechanistic Interpretability, and Nick, like, was on all of the original, like, circuits papers and helped, like, you know, build everything out at OpenAI.\nUh, Lee Shy, who is the first, um, who pioneered, like, sparse autoenccoders on language models and, uh, is now working on some really interesting work in weights-based interpretability.\nSo, most interpretability, uh, techniques that have been deployed into applications are in concept space and activation space, and he's, he and his group are working on, um, weight space interpretability techniques.\nUm, and we've also just, like, kind of pulled in scientists, senior scientists from other fields who care a lot about, uh, uh, interpretability and just kind of have realized that this is one of the most important problems that we can can work on.\nSo, uh, Owen Lewis, who was a senior staff RS at, uh, Google, um, working on coding agents, um, came over and, uh, is now, like, leading a couple directions here for us.\nAnd you're recruiting, right?\nAnd we're hiring.\nYeah.\nScientists, engineers.\nUh, I think it's like, we are hiring scientists, and, uh, that is like, deeply important for the future of the field, but also, like, it's hard to just, like, um, it's hard to overestimate just how important, like, good engineering skills are.\nIncredible team.\nProud of the team.\nYeah, for sure.\nThis seems like core functionality for one of for any of these foundation model companies to have.\nAnd as you mentioned, you know, Cryola, was it OpenAI?\nAnthropic OpenAI has has their interpretability team as well.\nUm, how do you think about the rationale for having a standalone mechan, uh, research company versus being inside one of the labs that should care deeply about this?\nI think, um, we can just take a really different approach if we're independent.\nI think the benefit of being independent is we can think independently, push things forward independently, and also get, like, a broader view of the ecosystem.\nSo, usually, if you're within a lab, you're kind of doing interpretability work on your own models and, like, kind of pushing forward the field in in that way, and you can make incredible progress that way.\nBut I, I really do think that, like, a unique third-party perspective, uh, is deeply necessary in in in the field, and I think, like, yeah, just given the team that we've assembled, like, a lot of those folks, like, agree with that, and that's why they've joined, and, uh, also, like, gives us, like, um, an ability to work with lots of interesting partners across different domains, and we can kind of unify those insights across all these different domains that that teach us more about, like, the inner workings of neural networks more broadly.\nSo, we work across modalities, like genomics models, exomic models, uh, um, image, video, like, language, and also across model architectures, and I think, um, all that just just helps.\nAnthropic invested in in you all, right?\nYeah, that's right.\nSay more about that and how you partner with them.\nYeah, so they, um, I think we were their, their first ever investment.\nUh, they, um, they put in a check in in our last round, and, uh, I think, uh, they just got, they just really care about interpretability and really kind of see the future as we do, uh, where, um, interpretability is just, like, pretty critical, um, to to the future.\nSo, Dario just published an essay called, like, the urgency of interpretability, and, um, it's like one of his, like, four essays that he has on his site, and, uh, just like talking about, like, how he views this as almost like a race, um, and we see that very similarly, a race to get interpretability prior to, um, you know, super intelligent, uh, really, really intelligent AI models.\nI just think it's like deeply critical to be able to understand these models before they're, before we have, like, in his words, like, a country of geniuses in in a data center.\nDo you think interpretability can help us with open models, and you know, I think some people have a fear that, you know, models trained in in other countries that may or may not be enemies of the United States, you know, have different nationalist properties.\nCan interpretability help us understand and and even modify those for the, you know, the American variants of of some of these models?\nYeah.\nWell, I definitely think so.\nUm, I also think it's like relatively easy to, uh, like, if you take, like, a DeepSeek model, for example.\nUm, it's relatively easy to just, like, tune it or add in more training data to remove a lot of the, like, uh, propaganda in the model.\nUm, and, uh, but yeah, I think, like, interpretability can help, like, understand, like, what's actually inside of the model and then also, like, change it and edit it to, um, to, like, serve whatever end purpose that that you want.\nHow long do you think before you're going to be pulled in as a witness in a very important trial to try to understand why a model did something in particular?\nThat's a good question.\nI, I think, uh, few years, who knows?\nUh, I think it's really, you know, uh, I mean, we're we're all sitting in, like, the Bay Area right now, but at this point, I'm I'm pretty AGI pilled in that, like, uh, I think AI AI progress will be pretty fast and pretty quick and transformative to Society in ways that are really difficult to anticipate from from where we're sitting right now.\nAnd so, um, yeah, I do think that there will be a couple, you know, like, um, big failure cases of AI models.\nAnd whether it's me called in or, you know, somebody at a big lab or some, you know, uh, some other expert, um, I think that we're going to want to, uh, be able to explain a model's outputs.\nUm, yeah, I agree with you on the rate of, uh, development, by the way, and I think it's, um, I'm sure you've read these articles.\nThe human brain doesn't intuit compounding.\nNo.\nAnd so, you know, I've even thought back to 20 years ago, uh, when I first met the self-driving car initiatives, and Sebastian's team from Stanford had won the DARPA challenge.\nYou know, you could sort of see the glimmers of self-driving cars.\nBut even then, if you'd said, you know, 20 years later, you would have a self-driving car in San Francisco take you around, I'm not sure it would have been obvious that would be true, and maybe take a few took a few years longer for the true visionaries.\nI think the same is going to happen with AI.\nI don't think we fully fathom what the world's going to look like in 2030 or 2035.\nYeah.\nNo, I couldn't agree more.\nAnd it's just really hard to predict, you know, like, even if we feel like it's going to happen really, really quickly, uh, it's hard to predict all of the ways that society will be transformed.\nGood note to end on.\nShould we do some rapid fire?\nSome predictions.\nYeah.\nYou need some predictions.\nThese all recorded, so we'll hold you to it.\nGreat.\nYes.\nYes.\nEric in 2035 will look back on how wrong he is with all these predictions.\nYeah.\nOkay.\nMaybe first, uh, inference time compute is vex important vector to scale to scale, uh, models.\nAgree or disagree?\nUh, mostly agree.\nI think it's one of the important, one of the things that we can scale up on.\nYeah.\nWhat application category do you think will break out next after code?\nI think there will be a lot of enterprise transformations that that happen.\nSo, just like automating, like, manual routine tasks that people are doing, like, many, many times a day.\nEmployment impact from AI, vast.\nIn in, uh, vast, but, uh, once you cross a chasm, I think it happens quickly.\nUm, I think, uh, well, my, my last company was, uh, helping, um, find early career jobs for people and using AI to to automate that, and, uh, I think that that's where we're going to feel the impact first.\nUm, I agree.\nRecommended piece of content or reading for for AI fans, maybe spec specifically in your field.\nI think the the original circuits thread that I was referencing a couple times, like, that's still fantastic.\nWhat's u either an AI app or maybe just an experience that you've had with AI that has blown you away recently?\nSomething that just took a breath away.\nI think my, like, one of those moments that you really just, like, feel how fast AI is happening.\nLike, when I first, uh, played with 01 Pro, like, that was a a model that I just really felt like was actually reasoning about the world.\nAnd, um, seeing, like, the kind of cross-domain transfer to, I would ask it a strategic question, and it felt like it would actually understand, like, all the levers that I was considering with the business and, um, considering that, like, at least relatively thoughtfully and being a thought partner, and that's both exciting because I now have this model that I can talk to about all sorts of critical problems, but, uh, and not just, of course, like, trust it blindly, but, um, but also, like, it's like, wow, wow.\nHow did it, how did this happen?\nYou know, interesting.\nOne of the things I've learned recently is that AI is still struggling to understand humor.\nAnd one of my partners, Andrew, actually had this joke that, uh, humor is humans way of showing off intelligence without actually explicitly bragging.\nUm, and so maybe there is a lot of embedded intelligence in humor.\nDo you think interpretability will help us pinpoint to figure out humor?\nYeah.\nTo figure out why AIs don't have a sense of humor, or will help them to develop it, perhaps.\nWho knows?\nYeah.\nUh, I hope so.\nYeah.\nI can, uh, I think if I, you know, wake up to a a model, like, telling me jokes and Roelof's voice, that would be, uh, that would be terrifying.\nOkay, we'll close with one last question on a prediction in your field.\nUh, do you think we will ever reach the point where we feel like we confidently understand the features, the circuits, the patterns, the weights of a neural net?\nAnd if so, what year do you predict we'll reach that point?\nI think we can.\nI think that it might not look like what you just said, like, the features, the circuits, the, I think that it requires maybe a reconceptualization of what's actually going on inside the model, like, a deeper, more fundamental understanding of the units of computation of a model.\nIt's almost like discovering truths about the universe or about, like, neural nets in this case.\nUh, but yes, I think we're on track.\nI think we can do this, and I think we can do this in, and hold me to this in 2028.\nWe're going to figure it all out.\nYeah.\nFantastic.\nYeah.\nJust a few years.\nI think I think we're close.\nJust in time for the LA Olympics.\nYeah, that's right.\nJust in time for your next round of funding.\nI'm kidding.\nEric, thank you so much for doing this today.\n\n\nRuf and I love the conversation.\nThank you.\nIt was a pleasure.\nYeah, so much fun.\nThanks for having me.\n[Music]\n",
  "dumpedAt": "2025-07-21T18:43:25.223Z"
}