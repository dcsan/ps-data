{
  "episodeId": "ACrOVlbk190",
  "channelSlug": "@suprainsider",
  "title": "#63: How PMs can bring predictability to AI products | Aman Khan (HoP @ Arize AI, ex-Spotify)",
  "publishedAt": "2025-06-23T14:00:11.000Z",
  "rawLines": [
    {
      "lang": "en",
      "text": "Hey everyone, welcome to another episode",
      "offset": 0,
      "duration": 6.16
    },
    {
      "lang": "en",
      "text": "of Super Insider. Imagine launching your",
      "offset": 2.639,
      "duration": 6.481
    },
    {
      "lang": "en",
      "text": "AI feature with confidence, knowing that",
      "offset": 6.16,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "it won't surprise you with unexpected",
      "offset": 9.12,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "results or harm your customer",
      "offset": 11.2,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "relationships.",
      "offset": 13.84,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "Too often, product teams push AI into",
      "offset": 15.36,
      "duration": 7.04
    },
    {
      "lang": "en",
      "text": "products only to realize far too late",
      "offset": 18.24,
      "duration": 6.799
    },
    {
      "lang": "en",
      "text": "that their AI systems aren't delivering",
      "offset": 22.4,
      "duration": 4.799
    },
    {
      "lang": "en",
      "text": "reliable outcomes.",
      "offset": 25.039,
      "duration": 6.08
    },
    {
      "lang": "en",
      "text": "Today, Ben and I talk with Aman Khan,",
      "offset": 27.199,
      "duration": 6.641
    },
    {
      "lang": "en",
      "text": "who spent countless of hours guiding",
      "offset": 31.119,
      "duration": 5.361
    },
    {
      "lang": "en",
      "text": "product teams on how to implement AI",
      "offset": 33.84,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "features effectively through intentional",
      "offset": 36.48,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "evaluation processes.",
      "offset": 39.6,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "We dive deep into practical steps that",
      "offset": 41.92,
      "duration": 7.92
    },
    {
      "lang": "en",
      "text": "every PM can use today, right now. How",
      "offset": 45.04,
      "duration": 7.44
    },
    {
      "lang": "en",
      "text": "to clearly define what good enough means",
      "offset": 49.84,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "for your AI. the difference between by",
      "offset": 52.48,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "coding and structure evaluation",
      "offset": 55.36,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "processes and when each makes sense and",
      "offset": 57.6,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "real examples of avoiding costly",
      "offset": 61.12,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "mistakes through systematic AI",
      "offset": 63.28,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "evaluation.",
      "offset": 65.92,
      "duration": 4.559
    },
    {
      "lang": "en",
      "text": "If your goal is to deliver AI products",
      "offset": 67.6,
      "duration": 5.519
    },
    {
      "lang": "en",
      "text": "that users trust from day one, this",
      "offset": 70.479,
      "duration": 5.201
    },
    {
      "lang": "en",
      "text": "conversation is a must listen. So, let's",
      "offset": 73.119,
      "duration": 5.801
    },
    {
      "lang": "en",
      "text": "jump in.",
      "offset": 75.68,
      "duration": 3.24
    },
    {
      "lang": "en",
      "text": "All right, we're live. Aman, I am so",
      "offset": 84.88,
      "duration": 3.279
    },
    {
      "lang": "en",
      "text": "excited you decided to join us. Thanks",
      "offset": 86.64,
      "duration": 3.519
    },
    {
      "lang": "en",
      "text": "for being here. Excited to be here.",
      "offset": 88.159,
      "duration": 3.521
    },
    {
      "lang": "en",
      "text": "Thank you guys for having me. I've been",
      "offset": 90.159,
      "duration": 2.801
    },
    {
      "lang": "en",
      "text": "looking forward to this conversation all",
      "offset": 91.68,
      "duration": 4.799
    },
    {
      "lang": "en",
      "text": "week. Oh, yeah. We have. We have as",
      "offset": 92.96,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "well. And I know you've been on the",
      "offset": 96.479,
      "duration": 3.521
    },
    {
      "lang": "en",
      "text": "circuit between the Lenny Post, the",
      "offset": 98,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "podcast. We wanted to cover some new",
      "offset": 100,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "ground that you haven't really talked",
      "offset": 101.92,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "about in other places yet. If folks are",
      "offset": 103.28,
      "duration": 3.199
    },
    {
      "lang": "en",
      "text": "interested in learning about some of the",
      "offset": 105.04,
      "duration": 3.119
    },
    {
      "lang": "en",
      "text": "other stuff you've been thinking about,",
      "offset": 106.479,
      "duration": 3.041
    },
    {
      "lang": "en",
      "text": "plenty of resources online that we'll",
      "offset": 108.159,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "link to also in the show notes. But",
      "offset": 109.52,
      "duration": 3.279
    },
    {
      "lang": "en",
      "text": "today, Mark and I were talking about",
      "offset": 111.439,
      "duration": 3.201
    },
    {
      "lang": "en",
      "text": "what would we really want to talk about.",
      "offset": 112.799,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "And what we're seeing is there's a lot",
      "offset": 114.64,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "of product managers, and we talked about",
      "offset": 116.88,
      "duration": 3.279
    },
    {
      "lang": "en",
      "text": "this a little bit before hitting record",
      "offset": 118.799,
      "duration": 3.521
    },
    {
      "lang": "en",
      "text": "that are getting pulled, sometimes",
      "offset": 120.159,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "kicking and screaming, sometimes just",
      "offset": 122.32,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "they're push they're doing the pushing.",
      "offset": 124.159,
      "duration": 3.361
    },
    {
      "lang": "en",
      "text": "But like basically, how do we bring AI",
      "offset": 125.6,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "products? How do we bring AI experiences",
      "offset": 127.52,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "into our products? And often time",
      "offset": 129.28,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "there's some element of the AI does",
      "offset": 131.84,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "something based on inputs and there's",
      "offset": 134.64,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "some outputs and I and obviously like we",
      "offset": 136.16,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "want to make the outputs super good like",
      "offset": 138.08,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "we want the outputs to feel like really",
      "offset": 140.48,
      "duration": 3.759
    },
    {
      "lang": "en",
      "text": "reliably solid even though it's",
      "offset": 142.16,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "leveraging AI that just is",
      "offset": 144.239,
      "duration": 5.281
    },
    {
      "lang": "en",
      "text": "non-deterministic in a lot of ways and I",
      "offset": 146.08,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "think that you're spending so much of",
      "offset": 149.52,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "your time right now trying to educate",
      "offset": 151.52,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "the product world on how to set up their",
      "offset": 153.2,
      "duration": 6.24
    },
    {
      "lang": "en",
      "text": "product development process so that",
      "offset": 156.4,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "their odds of getting the outputs to be",
      "offset": 159.44,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "really high quality and reliably what",
      "offset": 162.16,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "they want them to be is as high as",
      "offset": 164.16,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "possible and that's where the",
      "offset": 165.76,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "evaluations fit in. We want to talk",
      "offset": 168,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "about that process of how product",
      "offset": 170.56,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "managers should be thinking about this",
      "offset": 172.4,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "and just to get you started I'll throw",
      "offset": 174,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "out a scenario and I just want to hear",
      "offset": 176.16,
      "duration": 3.439
    },
    {
      "lang": "en",
      "text": "feel free to start riffing on where",
      "offset": 178.08,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "you'd go with this scenario but imagine",
      "offset": 179.599,
      "duration": 3.201
    },
    {
      "lang": "en",
      "text": "you're a product manager at a company",
      "offset": 181.36,
      "duration": 3.519
    },
    {
      "lang": "en",
      "text": "right now it's got a lot of traction",
      "offset": 182.8,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "there's pressure from the executive team",
      "offset": 184.879,
      "duration": 3.041
    },
    {
      "lang": "en",
      "text": "that people are excited we're going to",
      "offset": 186.879,
      "duration": 3.121
    },
    {
      "lang": "en",
      "text": "build AI into our product they find a",
      "offset": 187.92,
      "duration": 3.679
    },
    {
      "lang": "en",
      "text": "really killer use case for where they're",
      "offset": 190,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "going to put AI into their product",
      "offset": 191.599,
      "duration": 5.201
    },
    {
      "lang": "en",
      "text": "experience and they're just assuming",
      "offset": 193.36,
      "duration": 4.879
    },
    {
      "lang": "en",
      "text": "they're going to follow the traditional",
      "offset": 196.8,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "development process Right. So they're",
      "offset": 198.239,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "going to come up with what is it going",
      "offset": 200.4,
      "duration": 2.24
    },
    {
      "lang": "en",
      "text": "to look like. Maybe they'll do some",
      "offset": 201.599,
      "duration": 2.72
    },
    {
      "lang": "en",
      "text": "prototyping, vibe coding like you talk",
      "offset": 202.64,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "about get to a point where they're all",
      "offset": 204.319,
      "duration": 3.521
    },
    {
      "lang": "en",
      "text": "aligned on like how we want AI to fit",
      "offset": 206,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "into the product and when and where and",
      "offset": 207.84,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "what a good result might look like and",
      "offset": 210.159,
      "duration": 3.521
    },
    {
      "lang": "en",
      "text": "then they ship it and they start testing",
      "offset": 211.84,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "it in dev or in staging or whatever.",
      "offset": 213.68,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "Maybe sometimes on production behind a",
      "offset": 216.159,
      "duration": 3.041
    },
    {
      "lang": "en",
      "text": "feature flag and they're like, man, this",
      "offset": 217.68,
      "duration": 2.72
    },
    {
      "lang": "en",
      "text": "is it's not what it's not what it needs",
      "offset": 219.2,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "to be. It's not good enough. Have they",
      "offset": 220.4,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "missed the boat? Is that too late to",
      "offset": 222.56,
      "duration": 4.959
    },
    {
      "lang": "en",
      "text": "think about eval scenario? It's a really",
      "offset": 224.48,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "good question. I think maybe it's",
      "offset": 227.519,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "helpful to zoom out and think about what",
      "offset": 228.879,
      "duration": 5.681
    },
    {
      "lang": "en",
      "text": "product managers are doing when they're",
      "offset": 231.519,
      "duration": 5.041
    },
    {
      "lang": "en",
      "text": "building products that have AI in them",
      "offset": 234.56,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "in the first place as well. What that",
      "offset": 236.56,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "workflow sort of looks like like how",
      "offset": 238.56,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "you've described and I almost want to",
      "offset": 240.4,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "double click a little bit on that",
      "offset": 243.2,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "scenario which is like how did the group",
      "offset": 244.239,
      "duration": 5.441
    },
    {
      "lang": "en",
      "text": "come together to decide to put AI in the",
      "offset": 247.12,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "product? What's the goal? They're a",
      "offset": 249.68,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "little bit very PM thing to ask here,",
      "offset": 251.2,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "right? Like uh I'll give you an example.",
      "offset": 253.36,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "We have a customer one of the largest",
      "offset": 255.599,
      "duration": 3.521
    },
    {
      "lang": "en",
      "text": "travel sites in the world and for",
      "offset": 257.68,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "context we work with companies that are",
      "offset": 259.12,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "have AI very core to their product.",
      "offset": 262.079,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "Think like product sweet and services we",
      "offset": 264.08,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "all use every single day and it's not",
      "offset": 266,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "just chat bots it's like actually",
      "offset": 267.6,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "sitting in the product helping you know",
      "offset": 269.6,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "their product make decisions. We had a",
      "offset": 271.84,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "customer that helps you book flights,",
      "offset": 274,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "helps you book hotels. And a couple of",
      "offset": 275.84,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "years ago, actually, when LLM really",
      "offset": 278.32,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "started taking off about a probably",
      "offset": 280.24,
      "duration": 3.679
    },
    {
      "lang": "en",
      "text": "about a year ago, they came to us and",
      "offset": 282,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "they were like, &quot;Arise, we are so",
      "offset": 283.919,
      "duration": 5.201
    },
    {
      "lang": "en",
      "text": "excited. We decided to put a chatbot in",
      "offset": 286,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "the product that you type in where",
      "offset": 289.12,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "you're going and it will just help you",
      "offset": 291.12,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "book flights and recommend where you",
      "offset": 293.68,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "want to go based on where you want to",
      "offset": 296.32,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "go, hotels, flights, activities that you",
      "offset": 297.759,
      "duration": 4.481
    },
    {
      "lang": "en",
      "text": "can do.&quot; And it's going really great.",
      "offset": 300.32,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "People are like clicking through there.",
      "offset": 302.24,
      "duration": 2.959
    },
    {
      "lang": "en",
      "text": "The metrics are moving up and people are",
      "offset": 303.68,
      "duration": 2.88
    },
    {
      "lang": "en",
      "text": "using this product even more than they",
      "offset": 305.199,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "were before there was like actually AI",
      "offset": 306.56,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "in it. But the problem is that people",
      "offset": 308.88,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "keep trying to jailbreak it. They're",
      "offset": 310.639,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "like sending input queries. They're",
      "offset": 312.32,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "sending questions that we didn't think",
      "offset": 314.479,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "the LLM would the agent would actually",
      "offset": 316.32,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "try to answer. They're trying to get",
      "offset": 318.16,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "free flights. They're trying to figure",
      "offset": 319.84,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "out how to break this thing. And can you",
      "offset": 321.68,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "can you guys help us solve this problem?",
      "offset": 324.24,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "Figure out what's going on here. And the",
      "offset": 326.32,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "first question we asked actually when",
      "offset": 328.08,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "that happened was why did you decide to",
      "offset": 329.68,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "do this? Like we we thought",
      "offset": 331.919,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "fundamentally we thought that you're a",
      "offset": 333.44,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "product that's helping people book",
      "offset": 335.039,
      "duration": 4.241
    },
    {
      "lang": "en",
      "text": "vacations or book for work. That should",
      "offset": 337.28,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "be a simple search query just like",
      "offset": 339.28,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "Google and you click through and a human",
      "offset": 340.96,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "is the one picking what they want to",
      "offset": 342.56,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "select their hotel to be or select their",
      "offset": 344.72,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "flights. And I think we had a",
      "offset": 346.4,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "fundamental misunderstanding of what the",
      "offset": 348.88,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "product was trying to solve. Like when",
      "offset": 350.56,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "we initially looked at this product, we",
      "offset": 352.32,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "thought, okay, it's building a a trip",
      "offset": 354.479,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "planner that helps you make decisions",
      "offset": 357.12,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "and book a trip for you. But what I",
      "offset": 359.039,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "think we were missing is that the LLM",
      "offset": 361.6,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "and the agent's goal is actually to",
      "offset": 363.44,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "build a trip planner for everyone, a",
      "offset": 365.36,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "personalized trip planner where you can",
      "offset": 367.759,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "have a conversation and figure out where",
      "offset": 369.6,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "you want to go. And I think that kind of",
      "offset": 371.44,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "comes back to what's the end goal here",
      "offset": 374.08,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "and figuring out what the the space for",
      "offset": 376.24,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "AI kind of looks like in the product",
      "offset": 379.6,
      "duration": 3.599
    },
    {
      "lang": "en",
      "text": "kind of helps you understand when you",
      "offset": 381.68,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "need to start thinking about eval. So I",
      "offset": 383.199,
      "duration": 4.481
    },
    {
      "lang": "en",
      "text": "don't actually I think that thinking",
      "offset": 385.84,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "about eval can be helpful when it comes",
      "offset": 387.68,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "to framing what the end goal is making",
      "offset": 390.24,
      "duration": 3.679
    },
    {
      "lang": "en",
      "text": "sure you're hitting those goals but in",
      "offset": 392.08,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "many times we just you just need to have",
      "offset": 393.919,
      "duration": 2.961
    },
    {
      "lang": "en",
      "text": "the right framing of the goal in the",
      "offset": 395.28,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "first place to know what to evaluate. So",
      "offset": 396.88,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "I think to to bend your scenario here, I",
      "offset": 398.88,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "view that as like maybe the goal was",
      "offset": 402,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "just to get AI and the product out",
      "offset": 403.6,
      "duration": 3.439
    },
    {
      "lang": "en",
      "text": "quickly and that's okay. That doesn't",
      "offset": 405.44,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "mean that the goal here was to actually",
      "offset": 407.039,
      "duration": 4.641
    },
    {
      "lang": "en",
      "text": "have a product that was fully reliable",
      "offset": 409.6,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "for all of your users. Those are two",
      "offset": 411.68,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "distinct goals when you're experimenting",
      "offset": 413.52,
      "duration": 2.959
    },
    {
      "lang": "en",
      "text": "with this stuff. Let's actually anchor",
      "offset": 415.12,
      "duration": 2.799
    },
    {
      "lang": "en",
      "text": "to that scenario you shared and just",
      "offset": 416.479,
      "duration": 3.041
    },
    {
      "lang": "en",
      "text": "imagine that company never actually came",
      "offset": 417.919,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "to arise and this was just like a",
      "offset": 419.52,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "hypothetical thought experiment. Okay,",
      "offset": 421.039,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "so we have a travel company. We want to",
      "offset": 422.8,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "build we want to build some kind of",
      "offset": 424.96,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "experience in the product that allows",
      "offset": 426.56,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "people instead of clicking around Google",
      "offset": 428,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "flight style or Expedia style into a",
      "offset": 429.68,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "conversational interface that feels",
      "offset": 432.4,
      "duration": 2.799
    },
    {
      "lang": "en",
      "text": "something like talking to a travel",
      "offset": 433.759,
      "duration": 3.121
    },
    {
      "lang": "en",
      "text": "planner like a human, right? And they're",
      "offset": 435.199,
      "duration": 2.801
    },
    {
      "lang": "en",
      "text": "going to ask you whatever questions they",
      "offset": 436.88,
      "duration": 2.64
    },
    {
      "lang": "en",
      "text": "need to ask and then they're going to",
      "offset": 438,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "give you options and they'll know your",
      "offset": 439.52,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "budget and all the things and then like",
      "offset": 441.68,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "at the end you'll be able to pull the",
      "offset": 443.28,
      "duration": 3.039
    },
    {
      "lang": "en",
      "text": "trigger and or at least they'll give you",
      "offset": 444.8,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "exactly the actions you need to do. So,",
      "offset": 446.319,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "I'd say like my goal as a PM in that",
      "offset": 448.4,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "company might be I want to give people a",
      "offset": 450.16,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "conversational way to plan trips instead",
      "offset": 452.8,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "of having them have to click around.",
      "offset": 455.52,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "Let's just say that's the goal. And then",
      "offset": 456.88,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "maybe my assumption, yeah, like the end",
      "offset": 458.56,
      "duration": 3.359
    },
    {
      "lang": "en",
      "text": "goal might be even like just just book",
      "offset": 460.4,
      "duration": 2.72
    },
    {
      "lang": "en",
      "text": "more flights, right? Because maybe you",
      "offset": 461.919,
      "duration": 3.041
    },
    {
      "lang": "en",
      "text": "make or make or move more hotels. So",
      "offset": 463.12,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "then because maybe you make money based",
      "offset": 464.96,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "on each transaction, maybe you take 10%,",
      "offset": 467.28,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "right? That could be like a business",
      "offset": 468.96,
      "duration": 4.639
    },
    {
      "lang": "en",
      "text": "impact that I could imagine that company",
      "offset": 471.44,
      "duration": 5.199
    },
    {
      "lang": "en",
      "text": "going after basically. Totally. So now",
      "offset": 473.599,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "I'm sitting down with my engineers and",
      "offset": 476.639,
      "duration": 3.041
    },
    {
      "lang": "en",
      "text": "they're like, &quot;Cool.&quot; Like we've got",
      "offset": 478.479,
      "duration": 3.201
    },
    {
      "lang": "en",
      "text": "like open AI models and we've got",
      "offset": 479.68,
      "duration": 4.239
    },
    {
      "lang": "en",
      "text": "enthropic models and we could we've got",
      "offset": 481.68,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "all the structured data and we're going",
      "offset": 483.919,
      "duration": 3.201
    },
    {
      "lang": "en",
      "text": "to build the data pipelines that put the",
      "offset": 485.44,
      "duration": 3.039
    },
    {
      "lang": "en",
      "text": "right information in front of the right",
      "offset": 487.12,
      "duration": 2.56
    },
    {
      "lang": "en",
      "text": "models and pair it with the right",
      "offset": 488.479,
      "duration": 2.4
    },
    {
      "lang": "en",
      "text": "prompts and then we're going to get",
      "offset": 489.68,
      "duration": 3.199
    },
    {
      "lang": "en",
      "text": "these outputs and then and then we'll",
      "offset": 490.879,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "just QA it. That's like the traditional",
      "offset": 492.879,
      "duration": 5.921
    },
    {
      "lang": "en",
      "text": "happy path. That's a Yeah, I think um",
      "offset": 495.919,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "and probably what a lot of people do if",
      "offset": 498.8,
      "duration": 2.88
    },
    {
      "lang": "en",
      "text": "they're not being intentional about the",
      "offset": 500.08,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "evals if I'm guessing. Totally. I think",
      "offset": 501.68,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "it's probably helpful to contextualize",
      "offset": 503.68,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "like where evouts sit in your",
      "offset": 505.44,
      "duration": 5.039
    },
    {
      "lang": "en",
      "text": "traditional software development process",
      "offset": 508.96,
      "duration": 2.88
    },
    {
      "lang": "en",
      "text": "and that's where what you're getting at",
      "offset": 510.479,
      "duration": 2.8
    },
    {
      "lang": "en",
      "text": "right which is what's different about",
      "offset": 511.84,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "this world a little bit and may maybe",
      "offset": 513.279,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "it's helpful if we whiteboard some of",
      "offset": 515.12,
      "duration": 3.599
    },
    {
      "lang": "en",
      "text": "this out and talk through what some of",
      "offset": 516.719,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "the common scenarios we see are where",
      "offset": 518.719,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "like eval start to matter versus where",
      "offset": 520.64,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "they might not really make a huge",
      "offset": 522.88,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "difference in your software development",
      "offset": 524.64,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "process. So, I'll actually I had some of",
      "offset": 526,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "this whiteboarded out as I was like",
      "offset": 528,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "thinking through this for a customer the",
      "offset": 529.44,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "other day and I'll maybe to come back to",
      "offset": 531.6,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "the just ship the thing like I kind of",
      "offset": 534.8,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "call this the vibe coding workflow which",
      "offset": 537.04,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "is a little bit of what you just",
      "offset": 539.6,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "described as well to some degree Ben",
      "offset": 540.72,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "which is your goal is actually just to",
      "offset": 542.72,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "put AI in the product and I that's why",
      "offset": 544.8,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "I've made it just like a single box on",
      "offset": 546.64,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "this workflow imagine that you're",
      "offset": 548.48,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "literally just figuring you've done all",
      "offset": 550.64,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "of your traditional software development",
      "offset": 552.24,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "you're building AI in the product you've",
      "offset": 554.16,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "vibe check the outputs. You make sure",
      "offset": 556.16,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "you know they look good or don't look",
      "offset": 558.56,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "good. You ship the thing. By the way,",
      "offset": 560.08,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "this story here of these three steps",
      "offset": 562.56,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "like I was watching an interview with",
      "offset": 565.04,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "the developers of Claude Code and some",
      "offset": 567.04,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "of the people at Cursor too and some of",
      "offset": 569.2,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "the most widely used AI tools today,",
      "offset": 570.72,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "they follow like vibe coding and vibe",
      "offset": 572.72,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "eval like it's just it feels good or it",
      "offset": 574.48,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "looks good. Just to interrupt for a sec,",
      "offset": 577.12,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "it I I want to make sure I'm",
      "offset": 579.12,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "understanding this so far. Am I",
      "offset": 580.72,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "understanding this correctly that what",
      "offset": 582.72,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "we're calling in the whiteboard that",
      "offset": 584.56,
      "duration": 2.88
    },
    {
      "lang": "en",
      "text": "you're showing here as the vibe coding",
      "offset": 586,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "workflow is this basically traditional",
      "offset": 587.44,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "software development workflow? I would",
      "offset": 589.2,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "call it traditional software development",
      "offset": 591.2,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "with the reason it's like vibe coding is",
      "offset": 594.32,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "like you can just ship so much faster",
      "offset": 596.56,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "now. I don't have any representation for",
      "offset": 598.8,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "like database or AB tests or anything",
      "offset": 600.64,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "like that. like it's all of that",
      "offset": 604,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "traditional software development I'm",
      "offset": 606.16,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "compressing into the box in the far left",
      "offset": 608.16,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "which is just build the agent and",
      "offset": 611.6,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "product. So this is traditional software",
      "offset": 613.2,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "development up until this point. And",
      "offset": 615.04,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "then after you get the outputs, you can",
      "offset": 616.88,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "go ship a website and you can take a",
      "offset": 618.64,
      "duration": 3.439
    },
    {
      "lang": "en",
      "text": "look at it and you know what that",
      "offset": 620.959,
      "duration": 2.961
    },
    {
      "lang": "en",
      "text": "website is going to look like 100% of",
      "offset": 622.079,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "the time, right? Like when you build a",
      "offset": 623.92,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "static HTML asset or something like this",
      "offset": 625.519,
      "duration": 5.601
    },
    {
      "lang": "en",
      "text": "or whatever the product might be where",
      "offset": 629.36,
      "duration": 3.599
    },
    {
      "lang": "en",
      "text": "it's just static code, you know what",
      "offset": 631.12,
      "duration": 2.88
    },
    {
      "lang": "en",
      "text": "it's going to look like. You write the",
      "offset": 632.959,
      "duration": 2.961
    },
    {
      "lang": "en",
      "text": "code, it shows up. The difference in",
      "offset": 634,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "this world is that now based on what the",
      "offset": 635.92,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "input looks like when you change the",
      "offset": 638.64,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "input or you vary the input the outputs",
      "offset": 640.64,
      "duration": 4.879
    },
    {
      "lang": "en",
      "text": "can look really different over time or",
      "offset": 643.04,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "an unexpected ways and that's because",
      "offset": 645.519,
      "duration": 4.641
    },
    {
      "lang": "en",
      "text": "you actually have less control over the",
      "offset": 647.76,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "AI component of the product itself where",
      "offset": 650.16,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "the output can be nine times out of 10",
      "offset": 652.8,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "it'll actually be different as opposed",
      "offset": 655.12,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "to 10 times out of 10 it's the same and",
      "offset": 656.56,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "that's what creates this experience",
      "offset": 659.279,
      "duration": 4.481
    },
    {
      "lang": "en",
      "text": "where the product that you're building",
      "offset": 661.12,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "actually works For some users, maybe",
      "offset": 663.76,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "it's really hard to quantify how many",
      "offset": 665.92,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "users it's going to work for or how",
      "offset": 667.68,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "reliable it's going to be. And",
      "offset": 670.079,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "inevitably, you're going to have users",
      "offset": 672.48,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "complain if this is a real product,",
      "offset": 674.24,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "whether it's internal or external. This",
      "offset": 675.68,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "happens in traditional software",
      "offset": 677.68,
      "duration": 2.32
    },
    {
      "lang": "en",
      "text": "development, too. You're going to have",
      "offset": 678.88,
      "duration": 3.519
    },
    {
      "lang": "en",
      "text": "users complain about the UI, the UX, the",
      "offset": 680,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "snappiness of the product or the the",
      "offset": 682.399,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "website. But the difference here is that",
      "offset": 684.56,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "the way that users are complaining or",
      "offset": 686.959,
      "duration": 2.56
    },
    {
      "lang": "en",
      "text": "what they're complaining about, this",
      "offset": 688.48,
      "duration": 3.359
    },
    {
      "lang": "en",
      "text": "might be the CEO literally like DMing",
      "offset": 689.519,
      "duration": 4.241
    },
    {
      "lang": "en",
      "text": "you as the PM and being like, &quot;Hey, what",
      "offset": 691.839,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "the hell's going on here?&quot; And they show",
      "offset": 693.76,
      "duration": 2.88
    },
    {
      "lang": "en",
      "text": "you a screenshot and it's this makes no",
      "offset": 694.959,
      "duration": 2.961
    },
    {
      "lang": "en",
      "text": "sense in the context of what I'm trying",
      "offset": 696.64,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "to do or this is completely wrong. Fix",
      "offset": 697.92,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "it. Totally. Yeah. And you can try to",
      "offset": 700.16,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "snap it to do something super fixed as",
      "offset": 702.64,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "well, which is interesting. Like even in",
      "offset": 705.6,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "that world, it's like you could have,",
      "offset": 707.12,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "let's imagine that this agent is only",
      "offset": 709.36,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "meant to book flights from San Francisco",
      "offset": 711.279,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "to New York. you type an input query and",
      "offset": 713.2,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "say book me a flight from San Francisco",
      "offset": 715.36,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "to New York this day this time you're",
      "offset": 716.64,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "still going to have this quality kind of",
      "offset": 718.88,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "component that's going to be a variable",
      "offset": 722.16,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "now because of the non-deterministic",
      "offset": 723.92,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "nature of LLM no matter how much you try",
      "offset": 726.48,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "to constrain the system and use function",
      "offset": 728.24,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "calling and these tools to make it more",
      "offset": 730.56,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "deterministic there you're now inserting",
      "offset": 732.639,
      "duration": 4.801
    },
    {
      "lang": "en",
      "text": "some level of non-determinism in your",
      "offset": 735.04,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "code so that's just something to keep in",
      "offset": 737.44,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "mind because if you decide to change the",
      "offset": 739.04,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "model change the prompt change some API",
      "offset": 741.04,
      "duration": 4.239
    },
    {
      "lang": "en",
      "text": "call change the input. There's just so",
      "offset": 743.2,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "many things that can cause the output",
      "offset": 745.279,
      "duration": 4.721
    },
    {
      "lang": "en",
      "text": "now to be not what it used to be in the",
      "offset": 747.519,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "traditional software world. So it so",
      "offset": 750,
      "duration": 5.279
    },
    {
      "lang": "en",
      "text": "we're calling these like the by coding",
      "offset": 753.519,
      "duration": 2.801
    },
    {
      "lang": "en",
      "text": "workflow and I'm sure the other one",
      "offset": 755.279,
      "duration": 2.961
    },
    {
      "lang": "en",
      "text": "maybe it's like the more thoughtful like",
      "offset": 756.32,
      "duration": 4.959
    },
    {
      "lang": "en",
      "text": "eval workflow whatever. I'm having a",
      "offset": 758.24,
      "duration": 6.88
    },
    {
      "lang": "en",
      "text": "hard time like finding situations where",
      "offset": 761.279,
      "duration": 6.081
    },
    {
      "lang": "en",
      "text": "the vibe coding workflow is a good idea",
      "offset": 765.12,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "for a established company that has like",
      "offset": 767.36,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "a reputation and trust right to me.",
      "offset": 769.12,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "Let's say I'm like a PM that works like",
      "offset": 770.8,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "a travel agency that has like millions",
      "offset": 772.48,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "of users, right? The fact that like I",
      "offset": 774.639,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "have some outcome that I cannot control",
      "offset": 776.72,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "that could erase my trust or and I guess",
      "offset": 778.32,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "it depend also I think maybe just a",
      "offset": 780.72,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "caveat here to mention is that it really",
      "offset": 783.68,
      "duration": 3.279
    },
    {
      "lang": "en",
      "text": "depends on like the functionality and",
      "offset": 785.36,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "the use case but I think for example",
      "offset": 786.959,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "like for the booking flights right like",
      "offset": 788.56,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "the consequences of getting it wrong or",
      "offset": 790.56,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "charging the wrong amount in the card",
      "offset": 792.639,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "can like really just delete like insane",
      "offset": 794.16,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "amount of like lifetime value for a",
      "offset": 796.56,
      "duration": 3.279
    },
    {
      "lang": "en",
      "text": "customer right so totally. when is it a",
      "offset": 798.079,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "good idea to do this by by coding",
      "offset": 799.839,
      "duration": 3.761
    },
    {
      "lang": "en",
      "text": "workflow versus when is like maybe",
      "offset": 802,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "absolutely not like you should go to the",
      "offset": 803.6,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "other workflow I think that there's like",
      "offset": 805.839,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "the consumer application lens and then",
      "offset": 807.92,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "I'll actually bring it back to the",
      "offset": 809.76,
      "duration": 3.759
    },
    {
      "lang": "en",
      "text": "claude code note a little bit here too",
      "offset": 811.36,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "which is they claim that they like just",
      "offset": 813.519,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "vibe coded claude code which is which",
      "offset": 814.88,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "actually started as an internal tool at",
      "offset": 817.6,
      "duration": 4.799
    },
    {
      "lang": "en",
      "text": "anthropic to help them build better code",
      "offset": 820,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "I think that's the takeaway here for me",
      "offset": 822.399,
      "duration": 4.641
    },
    {
      "lang": "en",
      "text": "was like this workflow makes sense if",
      "offset": 824.079,
      "duration": 5.681
    },
    {
      "lang": "en",
      "text": "you plan on just trying to get to the",
      "offset": 827.04,
      "duration": 5.359
    },
    {
      "lang": "en",
      "text": "end point of shipping AI in your product",
      "offset": 829.76,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "as fast as possible and you're maybe not",
      "offset": 832.399,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "going to release it to a bunch of users.",
      "offset": 834.8,
      "duration": 3.599
    },
    {
      "lang": "en",
      "text": "If your goal is to release it internally",
      "offset": 836.399,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "and test it and figure out where things",
      "offset": 838.399,
      "duration": 4.961
    },
    {
      "lang": "en",
      "text": "break, uh prototyping is another great",
      "offset": 840.8,
      "duration": 4.479
    },
    {
      "lang": "en",
      "text": "example. I think those are the",
      "offset": 843.36,
      "duration": 4.719
    },
    {
      "lang": "en",
      "text": "situations. Internal tools, prototyping,",
      "offset": 845.279,
      "duration": 5.761
    },
    {
      "lang": "en",
      "text": "low stakes, low stakes. Yeah. Yeah. or",
      "offset": 848.079,
      "duration": 4.801
    },
    {
      "lang": "en",
      "text": "if you are a startup and you're zero to",
      "offset": 851.04,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "one and you're just trying to go as fast",
      "offset": 852.88,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "as possible and you're willing to take",
      "offset": 854.48,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "on some more risk, like this could make",
      "offset": 857.279,
      "duration": 3.761
    },
    {
      "lang": "en",
      "text": "sense. But just know that the expected",
      "offset": 859.04,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "value and like return here can be really",
      "offset": 861.04,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "tilted as soon as you have someone",
      "offset": 863.199,
      "duration": 4.561
    },
    {
      "lang": "en",
      "text": "trying to break your system. there. This",
      "offset": 865.12,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "actually happened pretty publicly not",
      "offset": 867.76,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "too long ago where people were using",
      "offset": 870.16,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "tools like Lovable and Bolt and some",
      "offset": 872.32,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "others like Vzero as well. And there's",
      "offset": 874.56,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "issues like leaking secrets or having",
      "offset": 877.44,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "like leaky best practices, engineering",
      "offset": 880,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "practices that make their way out into",
      "offset": 882.24,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "the open and that's that can be really",
      "offset": 884.24,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "unsafe for a real business or",
      "offset": 886.639,
      "duration": 2.64
    },
    {
      "lang": "en",
      "text": "enterprise. So, if you're just getting",
      "offset": 888.16,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "started on a weekend project, go I love",
      "offset": 889.279,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "vibe coding. Go do it. If you're",
      "offset": 891.76,
      "duration": 3.199
    },
    {
      "lang": "en",
      "text": "actually trying to build something and",
      "offset": 893.68,
      "duration": 2.959
    },
    {
      "lang": "en",
      "text": "release it to real users that are paying",
      "offset": 894.959,
      "duration": 3.361
    },
    {
      "lang": "en",
      "text": "for it, you probably want to at least",
      "offset": 896.639,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "try to write an eval on top of that. And",
      "offset": 898.32,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "the one thing that I'll add there too",
      "offset": 900.8,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "that I just like I think the as you were",
      "offset": 902.24,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "saying, okay, like one use case for the",
      "offset": 904.72,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "bip coding workflow is as you said like",
      "offset": 906.399,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "that weekend hacking project, but I",
      "offset": 908.56,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "think another use case that I've seen",
      "offset": 910.959,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "for the bip coding is hey like my board",
      "offset": 913.44,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "or the exact team like pressures me to",
      "offset": 916.079,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "hey I need you need to find a solution",
      "offset": 918.56,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "how to implement AI. you go build this",
      "offset": 920,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "demo that let's say gets it right like",
      "offset": 922.399,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "70% of the time but then they're like oh",
      "offset": 924.16,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "this is amazing like we just need to get",
      "offset": 926.48,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "it to 95%. But I think the problem is",
      "offset": 928,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "that like you you didn't go you a lot of",
      "offset": 930.16,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "people don't actually really know okay",
      "offset": 933.36,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "like what is that that holistic process",
      "offset": 934.56,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "that you need to do in order to do that",
      "offset": 936.88,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "and I think that's also the risky part",
      "offset": 939.12,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "of it that you just don't know what you",
      "offset": 940.72,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "don't know and that part is actually",
      "offset": 942.24,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "which I'm sure we'll cover in a little",
      "offset": 944,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "bit like a lot longer and there's a lot",
      "offset": 945.36,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "of more ins and outs that you need to",
      "offset": 947.36,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "inform and educate those stakeholders",
      "offset": 949.04,
      "duration": 4.479
    },
    {
      "lang": "en",
      "text": "about. Yeah. And a good question to ask",
      "offset": 951.36,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "if you're if you if this relates to you",
      "offset": 953.519,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "and in your day-to-day as you're",
      "offset": 955.68,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "building AI products is like how good is",
      "offset": 957.199,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "good enough and how do you know what",
      "offset": 959.04,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "that is and is are all of your",
      "offset": 960.88,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "stakeholders on board with you know what",
      "offset": 962.8,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "good looks like which is why it's",
      "offset": 965.44,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "helpful to quantify some of this stuff",
      "offset": 967.199,
      "duration": 3.521
    },
    {
      "lang": "en",
      "text": "as well. That's why it's helpful to have",
      "offset": 968.72,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "a metric or a score that you're looking",
      "offset": 970.72,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "at that goes beyond just like vibes. So",
      "offset": 972.639,
      "duration": 4.241
    },
    {
      "lang": "en",
      "text": "it's it kind of gets to your point of",
      "offset": 975.12,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "does your board know what good even",
      "offset": 976.88,
      "duration": 4.639
    },
    {
      "lang": "en",
      "text": "looks like or your your board should",
      "offset": 978.72,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "trust you or your c your leadership team",
      "offset": 981.519,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "should trust you as the PM whoever the",
      "offset": 984.24,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "pressure is coming from like whoever is",
      "offset": 985.92,
      "duration": 5.599
    },
    {
      "lang": "en",
      "text": "responsible for driving the user",
      "offset": 989.12,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "experience into which AI is embedded",
      "offset": 991.519,
      "duration": 5.041
    },
    {
      "lang": "en",
      "text": "should be responsible for defining what",
      "offset": 994.16,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "quality is. And I think what's",
      "offset": 996.56,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "challenging in this case, cuz I've spent",
      "offset": 998.16,
      "duration": 4.239
    },
    {
      "lang": "en",
      "text": "countless hours in the past putting up",
      "offset": 1000.639,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "like testing scenarios for like",
      "offset": 1002.399,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "deterministic software, traditional",
      "offset": 1004.639,
      "duration": 4.961
    },
    {
      "lang": "en",
      "text": "software, and even that you've got like",
      "offset": 1006.72,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "something that's pretty straightforward",
      "offset": 1009.6,
      "duration": 3.679
    },
    {
      "lang": "en",
      "text": "has 20 potential paths that it could go,",
      "offset": 1010.8,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "right? And I think trying to come up",
      "offset": 1013.279,
      "duration": 3.281
    },
    {
      "lang": "en",
      "text": "with what is good enough for your",
      "offset": 1015.12,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "implementation of AI feels like an",
      "offset": 1016.56,
      "duration": 4.959
    },
    {
      "lang": "en",
      "text": "unanswerable question on its surface for",
      "offset": 1018.959,
      "duration": 5.281
    },
    {
      "lang": "en",
      "text": "a lot of people because the surface area",
      "offset": 1021.519,
      "duration": 4.641
    },
    {
      "lang": "en",
      "text": "of where it could go feels so",
      "offset": 1024.24,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "overwhelming because it's only limited",
      "offset": 1026.16,
      "duration": 3.759
    },
    {
      "lang": "en",
      "text": "by the bounds of natural conversation.",
      "offset": 1028.24,
      "duration": 3.199
    },
    {
      "lang": "en",
      "text": "If natural conversation can go there,",
      "offset": 1029.919,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "the product can go there too. And I",
      "offset": 1031.439,
      "duration": 3.281
    },
    {
      "lang": "en",
      "text": "think it's it's like you can try to",
      "offset": 1033.039,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "restrict certain workflows as well.",
      "offset": 1034.72,
      "duration": 3.199
    },
    {
      "lang": "en",
      "text": "While I was reading this tweet this",
      "offset": 1036.559,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "morning, like even in cloud code, you",
      "offset": 1037.919,
      "duration": 4.961
    },
    {
      "lang": "en",
      "text": "can add rules to what the coding agent",
      "offset": 1040.079,
      "duration": 4.801
    },
    {
      "lang": "en",
      "text": "should be able to do, not not be able to",
      "offset": 1042.88,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "remove certain files from a directory or",
      "offset": 1044.88,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "from your root folder. And the agent can",
      "offset": 1046.959,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "find ways to work around that. It's",
      "offset": 1050.48,
      "duration": 2.96
    },
    {
      "lang": "en",
      "text": "crazy. It's like you put it in a box,",
      "offset": 1051.919,
      "duration": 3.201
    },
    {
      "lang": "en",
      "text": "but it'll find ways out of the box, too.",
      "offset": 1053.44,
      "duration": 3.119
    },
    {
      "lang": "en",
      "text": "So, that's what creates a little bit of",
      "offset": 1055.12,
      "duration": 3.439
    },
    {
      "lang": "en",
      "text": "this like just be really careful what",
      "offset": 1056.559,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "you're measuring in the first place.",
      "offset": 1058.559,
      "duration": 3.761
    },
    {
      "lang": "en",
      "text": "Yeah. Actually, I would love to maybe",
      "offset": 1060.799,
      "duration": 4.801
    },
    {
      "lang": "en",
      "text": "double click on that question like what",
      "offset": 1062.32,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "is good enough and like how should",
      "offset": 1065.6,
      "duration": 3.199
    },
    {
      "lang": "en",
      "text": "people think about good because I think",
      "offset": 1067.2,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "there's like I I know it's a big",
      "offset": 1068.799,
      "duration": 4.561
    },
    {
      "lang": "en",
      "text": "question but I know there's also like I",
      "offset": 1071.12,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "think there's an 8020 here, right? Like",
      "offset": 1073.36,
      "duration": 3.439
    },
    {
      "lang": "en",
      "text": "maybe it's accuracy is one of them,",
      "offset": 1074.96,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "right? I'm sure like latency is one of",
      "offset": 1076.799,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "them as well, right? Of like trade-off",
      "offset": 1079.2,
      "duration": 3.359
    },
    {
      "lang": "en",
      "text": "of like accuracy versus like how quickly",
      "offset": 1080.88,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "you get answers. There's tone like you",
      "offset": 1082.559,
      "duration": 4.561
    },
    {
      "lang": "en",
      "text": "want the right tone or the right",
      "offset": 1085.36,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "branding if you're a brand sensitive",
      "offset": 1087.12,
      "duration": 3.439
    },
    {
      "lang": "en",
      "text": "company and you want it to behave in a",
      "offset": 1089.12,
      "duration": 2.799
    },
    {
      "lang": "en",
      "text": "way that's aligned with your brand.",
      "offset": 1090.559,
      "duration": 2.961
    },
    {
      "lang": "en",
      "text": "Yeah. There's also like maybe the risks",
      "offset": 1091.919,
      "duration": 3.041
    },
    {
      "lang": "en",
      "text": "on the guard rails, right? Of like how",
      "offset": 1093.52,
      "duration": 2.96
    },
    {
      "lang": "en",
      "text": "likely are we not to hit one of these",
      "offset": 1094.96,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "like terrible scenarios that we need to",
      "offset": 1096.48,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "avoid. Verbosity maybe like how many",
      "offset": 1098.16,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "words do you use to say what you're",
      "offset": 1100.96,
      "duration": 2.4
    },
    {
      "lang": "en",
      "text": "trying to say kind of thing that you",
      "offset": 1102.24,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "want to be I'm sure you've thought about",
      "offset": 1103.36,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "this like a million million times more",
      "offset": 1105.36,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "than we have. But no, I mean that it's I",
      "offset": 1107.2,
      "duration": 3.359
    },
    {
      "lang": "en",
      "text": "think that those are all like extremely",
      "offset": 1108.72,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "legitimate types of eval or metrics that",
      "offset": 1110.559,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "you should look at. At the end of the",
      "offset": 1113.52,
      "duration": 2.8
    },
    {
      "lang": "en",
      "text": "day, the eval are like the metrics that",
      "offset": 1114.72,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "you care about for your AI product to",
      "offset": 1116.32,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "some degree. And it's a I got asked this",
      "offset": 1117.84,
      "duration": 5.839
    },
    {
      "lang": "en",
      "text": "question yesterday. How many eval are",
      "offset": 1121.44,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "good enough? Like aside from like",
      "offset": 1123.679,
      "duration": 3.201
    },
    {
      "lang": "en",
      "text": "quality, it's okay, now let's get more",
      "offset": 1125.44,
      "duration": 2.64
    },
    {
      "lang": "en",
      "text": "tactical, right? They're like, okay,",
      "offset": 1126.88,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "fine. We'll talk about quality, but just",
      "offset": 1128.08,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "explain it to us in the form of eval",
      "offset": 1130.16,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "like how many eval should I have?",
      "offset": 1132.08,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "because I think that there's 50",
      "offset": 1134,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "dimensions or 100 dimensions that we",
      "offset": 1135.44,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "care about. And my answer to that is",
      "offset": 1137.36,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "that might just be true. Like depending",
      "offset": 1139.6,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "on the complexity of your product, you",
      "offset": 1141.52,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "might care more about certain eval",
      "offset": 1143.44,
      "duration": 5.599
    },
    {
      "lang": "en",
      "text": "depending on the scenario. I think it's",
      "offset": 1147.28,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "helpful to have another product framing",
      "offset": 1149.039,
      "duration": 4.241
    },
    {
      "lang": "en",
      "text": "to mind as well here, which is if you've",
      "offset": 1151.28,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "taken a Whimo or a self-driving car, it",
      "offset": 1153.28,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "turns out there's a lot of similarities",
      "offset": 1155.76,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "between the LLM agents that people are",
      "offset": 1157.76,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "using today and what self-driving cars",
      "offset": 1160.48,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "look like. I'll give you like a quick 30",
      "offset": 1162.08,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "second example there of I used to work",
      "offset": 1163.76,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "at a company called Cruz on the eval",
      "offset": 1165.919,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "side actually working on frameworks for",
      "offset": 1168.08,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "evaluations and when I joined the",
      "offset": 1169.76,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "company the car could barely drive down",
      "offset": 1171.52,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "a single block without a human having to",
      "offset": 1174.08,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "take over and then eventually the car",
      "offset": 1176.08,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "got really good at driving straight and",
      "offset": 1178.64,
      "duration": 2.96
    },
    {
      "lang": "en",
      "text": "making doing traffic lights correctly",
      "offset": 1180.08,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "and all that and then the car would try",
      "offset": 1181.6,
      "duration": 3.439
    },
    {
      "lang": "en",
      "text": "to make a left-hand turn and the human",
      "offset": 1183.2,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "would have to take over again. And",
      "offset": 1185.039,
      "duration": 4.241
    },
    {
      "lang": "en",
      "text": "eventually what we did was we built a",
      "offset": 1187.2,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "test set, a data set of what we called",
      "offset": 1189.28,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "left-hand turn scenarios. And we kept",
      "offset": 1191.52,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "iterating on the code on that left-hand",
      "offset": 1194,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "turn scenario benchmark. And we had ways",
      "offset": 1196.32,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "to score is this a good left-hand turn",
      "offset": 1198.96,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "or not. And then eventually the car was",
      "offset": 1200.96,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "excellent at making left-hand turns",
      "offset": 1202.88,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "except when there was a pedestrian in",
      "offset": 1204.64,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "the sidewalk trying to cross the street.",
      "offset": 1206.4,
      "duration": 3.519
    },
    {
      "lang": "en",
      "text": "And so what we had to do is build",
      "offset": 1208.559,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "another data set of left-hand turns with",
      "offset": 1209.919,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "a pedestrian in the sidewalk trying to",
      "offset": 1212.16,
      "duration": 2.72
    },
    {
      "lang": "en",
      "text": "cross the street. And then we kept",
      "offset": 1213.76,
      "duration": 3.279
    },
    {
      "lang": "en",
      "text": "iterating on that. And that process is",
      "offset": 1214.88,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "eventually what gets you to a system",
      "offset": 1217.039,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "that is more and more reliable for more",
      "offset": 1220.4,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "and more scenarios. And that's why eval",
      "offset": 1222.799,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "are not like a oneanddone. Let's just",
      "offset": 1225.36,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "pick the dimensions and ship the thing.",
      "offset": 1227.12,
      "duration": 3.039
    },
    {
      "lang": "en",
      "text": "It's really this like iterative process",
      "offset": 1228.64,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "where you get data from the real world",
      "offset": 1230.159,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "and use it to keep iterating on your",
      "offset": 1232.559,
      "duration": 4.641
    },
    {
      "lang": "en",
      "text": "core product. Can you connect what you",
      "offset": 1235.039,
      "duration": 5.361
    },
    {
      "lang": "en",
      "text": "just said to the concept of labeling?",
      "offset": 1237.2,
      "duration": 5.359
    },
    {
      "lang": "en",
      "text": "Yeah, absolutely. Yeah. No, please go",
      "offset": 1240.4,
      "duration": 3.759
    },
    {
      "lang": "en",
      "text": "ahead. Maybe also what were there too",
      "offset": 1242.559,
      "duration": 4.721
    },
    {
      "lang": "en",
      "text": "like how what is an EVA? How what is the",
      "offset": 1244.159,
      "duration": 5.041
    },
    {
      "lang": "en",
      "text": "definition of an eval? Is it just like",
      "offset": 1247.28,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "one variable that you're measuring?",
      "offset": 1249.2,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "Yeah. When you're referring to EVs, I",
      "offset": 1250.88,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "cuz I think the labels are a critical",
      "offset": 1253.28,
      "duration": 3.759
    },
    {
      "lang": "en",
      "text": "part of the concept for evals, right?",
      "offset": 1255.36,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "Because like the eval is almost like a",
      "offset": 1257.039,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "way that you end up comparing like the",
      "offset": 1258.64,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "the human label versus like the machine",
      "offset": 1260.64,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "generated label. Exactly. Yeah. So I",
      "offset": 1263.44,
      "duration": 4.479
    },
    {
      "lang": "en",
      "text": "think we can pick actually it's probably",
      "offset": 1266.08,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "helpful to be just thinking about the",
      "offset": 1267.919,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "whiteboard a little bit more like what",
      "offset": 1269.36,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "ends up happening is we're kind of at",
      "offset": 1271.679,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "phase two of that initial vibecoded",
      "offset": 1273.52,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "workflow right like now we're like hey",
      "offset": 1275.6,
      "duration": 2.959
    },
    {
      "lang": "en",
      "text": "maybe we should write an eval for this",
      "offset": 1277.12,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "product before we actually go ship it",
      "offset": 1278.559,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "and the very next question that comes up",
      "offset": 1280.48,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "usually in these teams is can we trust",
      "offset": 1282.4,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "what this eval label is and let's take",
      "offset": 1284.32,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "an example by the way sorry I'm super",
      "offset": 1286.88,
      "duration": 3.679
    },
    {
      "lang": "en",
      "text": "sorry to interrupt you but just to",
      "offset": 1288.88,
      "duration": 2.799
    },
    {
      "lang": "en",
      "text": "finish the previous story when you said",
      "offset": 1290.559,
      "duration": 2.561
    },
    {
      "lang": "en",
      "text": "that they said we have like 50 things",
      "offset": 1291.679,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "that we care about is that 50 eval Your",
      "offset": 1293.12,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "answer was yes. It might be 50 eval. It",
      "offset": 1295.039,
      "duration": 4.481
    },
    {
      "lang": "en",
      "text": "might be 50 eval. They just might not be",
      "offset": 1297.12,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "running on all of your data all of the",
      "offset": 1299.52,
      "duration": 4.639
    },
    {
      "lang": "en",
      "text": "time. Like you might have pick one eval",
      "offset": 1301.36,
      "duration": 5.199
    },
    {
      "lang": "en",
      "text": "for one scenario and that's one out of a",
      "offset": 1304.159,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "100 or a thousand. But it's really",
      "offset": 1306.559,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "important to run an eval for that one",
      "offset": 1308.24,
      "duration": 2.72
    },
    {
      "lang": "en",
      "text": "scenario. It's a left-hand turn use",
      "offset": 1309.679,
      "duration": 3.201
    },
    {
      "lang": "en",
      "text": "case. You don't need to run your",
      "offset": 1310.96,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "left-hand turn pedestrian eval for all",
      "offset": 1312.88,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "the driving scenarios. It's only when",
      "offset": 1315.6,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "you're making changes to that part of",
      "offset": 1317.36,
      "duration": 3.679
    },
    {
      "lang": "en",
      "text": "the stack necessarily. God. Okay. Thank",
      "offset": 1318.64,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "you. Yeah. Keep going. Yeah. So think of",
      "offset": 1321.039,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "this as like these things are are really",
      "offset": 1322.72,
      "duration": 3.439
    },
    {
      "lang": "en",
      "text": "linked. Actually both you guys Mark and",
      "offset": 1324.559,
      "duration": 3.761
    },
    {
      "lang": "en",
      "text": "Ben have alluded to this. There's a",
      "offset": 1326.159,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "system here when we talk about writing",
      "offset": 1328.32,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "an eval like why do we keep using that",
      "offset": 1330.159,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "term write an eval? It's because it is",
      "offset": 1332.08,
      "duration": 4.479
    },
    {
      "lang": "en",
      "text": "natural language. Right now when people",
      "offset": 1333.919,
      "duration": 5.841
    },
    {
      "lang": "en",
      "text": "think about evaluding",
      "offset": 1336.559,
      "duration": 4.721
    },
    {
      "lang": "en",
      "text": "to there's three that come up. It's like",
      "offset": 1339.76,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "human labels on the product output",
      "offset": 1341.28,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "itself. There's codebased evaluation",
      "offset": 1343.52,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "which is like maybe just a Python string",
      "offset": 1345.76,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "check or something like that. But the",
      "offset": 1348,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "vast majority of evals that scale really",
      "offset": 1349.919,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "well that people are looking at are",
      "offset": 1352.4,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "what's called LLM as a judge eval which",
      "offset": 1353.919,
      "duration": 6.801
    },
    {
      "lang": "en",
      "text": "are basically using another model or",
      "offset": 1357.28,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "language model to grade the output of",
      "offset": 1360.72,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "the first language model. And the reason",
      "offset": 1363.28,
      "duration": 6.24
    },
    {
      "lang": "en",
      "text": "that works is because when you write the",
      "offset": 1366.32,
      "duration": 6.96
    },
    {
      "lang": "en",
      "text": "eval, you're writing a block of text",
      "offset": 1369.52,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "where you're setting the role, giving",
      "offset": 1373.28,
      "duration": 5.279
    },
    {
      "lang": "en",
      "text": "the LLM as a judge context and giving",
      "offset": 1375.2,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "examples for what's good and what's bad",
      "offset": 1378.559,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "in the prompt itself. So for example,",
      "offset": 1380.72,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "you mentioned a couple actually. I'll",
      "offset": 1382.799,
      "duration": 2.24
    },
    {
      "lang": "en",
      "text": "just pick a couple that you guys",
      "offset": 1384.08,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "mentioned. Verbosity, tone. Let's pick",
      "offset": 1385.039,
      "duration": 5.041
    },
    {
      "lang": "en",
      "text": "tone for example, a really common one.",
      "offset": 1387.6,
      "duration": 5.439
    },
    {
      "lang": "en",
      "text": "Is the tone of the agent helpful or not",
      "offset": 1390.08,
      "duration": 6.079
    },
    {
      "lang": "en",
      "text": "helpful? And if I take a look at a text,",
      "offset": 1393.039,
      "duration": 5.201
    },
    {
      "lang": "en",
      "text": "if I take a look at what chat GPT says",
      "offset": 1396.159,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "on the output, like I can determine, I",
      "offset": 1398.24,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "can feel like the answer is either",
      "offset": 1401.039,
      "duration": 3.441
    },
    {
      "lang": "en",
      "text": "helpful or not helpful, right? And it's",
      "offset": 1402.72,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "because in the case of chat GPT, it's",
      "offset": 1404.48,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "been aligned to be a helpful bot. It's",
      "offset": 1407.039,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "literally in the system prompt is like",
      "offset": 1409.44,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "you are a helpful agent. But you can do",
      "offset": 1410.88,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "things and make it more like you're a",
      "offset": 1412.88,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "comedian or you're funny or we want you",
      "offset": 1414.64,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "to respond like a Gen Z type of persona.",
      "offset": 1416.64,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "And you might have an eval against that",
      "offset": 1420.32,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "because what you're trying to do is",
      "offset": 1422.08,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "compare is what would a human look at",
      "offset": 1423.76,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "this output and grade this as good or",
      "offset": 1426.64,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "bad based on this sounds like a Gen Z",
      "offset": 1429.2,
      "duration": 4.719
    },
    {
      "lang": "en",
      "text": "person or not. And then can you",
      "offset": 1431.84,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "basically model that into an LLM as a",
      "offset": 1433.919,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "judge in the first place? So there's",
      "offset": 1436.64,
      "duration": 2.8
    },
    {
      "lang": "en",
      "text": "three components of that. There's the",
      "offset": 1438.08,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "eval prompt, there's the text which is",
      "offset": 1439.44,
      "duration": 4.239
    },
    {
      "lang": "en",
      "text": "setting the context, setting the role of",
      "offset": 1441.76,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "the LLM as a judge, giving some",
      "offset": 1443.679,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "examples. There's the LLM itself that",
      "offset": 1445.36,
      "duration": 4.559
    },
    {
      "lang": "en",
      "text": "you want to select, which is maybe it's",
      "offset": 1447.84,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "a GPT4 or whatever off-the-shelf model",
      "offset": 1449.919,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "you want. You can pick it based on cost,",
      "offset": 1452.159,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "performance, latency. And then there's",
      "offset": 1454.24,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "the data that you're using to align the",
      "offset": 1456.24,
      "duration": 6.08
    },
    {
      "lang": "en",
      "text": "output. So that data is human label",
      "offset": 1458.64,
      "duration": 6.08
    },
    {
      "lang": "en",
      "text": "data, real world data that you're using",
      "offset": 1462.32,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "to align the LLM as a judge output in",
      "offset": 1464.72,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "the first place. So this is what when",
      "offset": 1467.36,
      "duration": 3.439
    },
    {
      "lang": "en",
      "text": "you talk about labels, this is usually",
      "offset": 1469.52,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "what that means that that data box. So",
      "offset": 1470.799,
      "duration": 8.561
    },
    {
      "lang": "en",
      "text": "if the eval prompt includes what are the",
      "offset": 1474.96,
      "duration": 7.04
    },
    {
      "lang": "en",
      "text": "examples of like good versus not good",
      "offset": 1479.36,
      "duration": 4.799
    },
    {
      "lang": "en",
      "text": "then the difference between those",
      "offset": 1482,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "examples and what goes into the data",
      "offset": 1484.159,
      "duration": 4.241
    },
    {
      "lang": "en",
      "text": "prompt is what? Can you clarify that",
      "offset": 1485.919,
      "duration": 5.281
    },
    {
      "lang": "en",
      "text": "part? Yeah there so this I kind of made",
      "offset": 1488.4,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "a little bit of an assumption here of",
      "offset": 1491.2,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "what goes into an eval system. There's",
      "offset": 1492.559,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "three highle things. There's the eval",
      "offset": 1494.24,
      "duration": 3.439
    },
    {
      "lang": "en",
      "text": "prompt, there's the LLM and then there's",
      "offset": 1495.919,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "the data. the data. There's actually a",
      "offset": 1497.679,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "bit of a split here of like in and this",
      "offset": 1499.84,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "will map for some people in the ML data",
      "offset": 1502.08,
      "duration": 6.479
    },
    {
      "lang": "en",
      "text": "sciency world. There's training data and",
      "offset": 1505.6,
      "duration": 5.199
    },
    {
      "lang": "en",
      "text": "then there's production data. And so",
      "offset": 1508.559,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "there's actually two types of data. The",
      "offset": 1510.799,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "data where humans are and humans label",
      "offset": 1512.64,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "both of these actually. They label the",
      "offset": 1515.12,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "training or alignment data that's used",
      "offset": 1516.88,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "to make the LLM as a judge good in the",
      "offset": 1519.2,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "first place. And then as you go into",
      "offset": 1521.76,
      "duration": 5.039
    },
    {
      "lang": "en",
      "text": "production, as you actually have this LM",
      "offset": 1524.48,
      "duration": 5.439
    },
    {
      "lang": "en",
      "text": "as a judge, grading outputs in the real",
      "offset": 1526.799,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "world, you still want to take a look at",
      "offset": 1529.919,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "that data constantly and make sure that",
      "offset": 1531.919,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "there's at least some type of human",
      "offset": 1534.08,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "feedback, making sure that the judge is",
      "offset": 1535.84,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "still aligned based on real world",
      "offset": 1538,
      "duration": 3.279
    },
    {
      "lang": "en",
      "text": "scenarios. So there's kind of two types",
      "offset": 1540.08,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "of data there. There's the initial label",
      "offset": 1541.279,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "data which you're going to use to create",
      "offset": 1543.6,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "the judge and then there's real world",
      "offset": 1545.44,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "data which is this the system actually",
      "offset": 1547.84,
      "duration": 5.439
    },
    {
      "lang": "en",
      "text": "your users actually interacting with the",
      "offset": 1551.2,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "product and an eval scoring the outputs",
      "offset": 1553.279,
      "duration": 5.681
    },
    {
      "lang": "en",
      "text": "of that as well.",
      "offset": 1556,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "If you're enjoying this conversation,",
      "offset": 1558.96,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "please check out the links in the show",
      "offset": 1560.88,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "notes to support the podcast. Mark and I",
      "offset": 1562.48,
      "duration": 4.559
    },
    {
      "lang": "en",
      "text": "do this out of love, but to keep it",
      "offset": 1565.12,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "going, we also need your support.",
      "offset": 1567.039,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "Thanks. And now back to the episode.",
      "offset": 1568.96,
      "duration": 6.4
    },
    {
      "lang": "en",
      "text": "And when we talk about humans evaluating",
      "offset": 1571.919,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "like the training data side of this,",
      "offset": 1575.36,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "when we talk about the humans that are",
      "offset": 1577.279,
      "duration": 4.721
    },
    {
      "lang": "en",
      "text": "involved in labeling or evaluating, are",
      "offset": 1578.88,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "we talking about outsourced? Is this",
      "offset": 1582,
      "duration": 5.039
    },
    {
      "lang": "en",
      "text": "like outsourced humans and company",
      "offset": 1584,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "companies like scale AI that are like",
      "offset": 1587.039,
      "duration": 2.64
    },
    {
      "lang": "en",
      "text": "investing massively in that",
      "offset": 1588.64,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "infrastructure for Yeah. Or could it be",
      "offset": 1589.679,
      "duration": 5.521
    },
    {
      "lang": "en",
      "text": "like the PM too, right? Totally. Yeah.",
      "offset": 1592.08,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "Yeah. So, I can maybe actually I'll kind",
      "offset": 1595.2,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "of throw out this this idea here and I'd",
      "offset": 1597.36,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "love to hear your guys' take. I think",
      "offset": 1599.2,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "that the eval prompt and LLM selection",
      "offset": 1600.96,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "is really important for the PM to be a",
      "offset": 1603.6,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "part of that process and work with their",
      "offset": 1605.52,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "AI engineer on those two things. But I",
      "offset": 1607.12,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "actually think probably one of the most",
      "offset": 1609.919,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "important parts of the system is the",
      "offset": 1611.52,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "data itself. And it's almost like a",
      "offset": 1614,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "little bit of a hot potato of who's",
      "offset": 1615.919,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "whose job is it to label the data. The",
      "offset": 1617.76,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "thing is it's really important to get",
      "offset": 1620.159,
      "duration": 5.841
    },
    {
      "lang": "en",
      "text": "that data right because",
      "offset": 1622.96,
      "duration": 4.959
    },
    {
      "lang": "en",
      "text": "what ends up happening is you might have",
      "offset": 1626,
      "duration": 3.679
    },
    {
      "lang": "en",
      "text": "whether it's a PM or a subject matter",
      "offset": 1627.919,
      "duration": 3.441
    },
    {
      "lang": "en",
      "text": "expert. I actually think this comes back",
      "offset": 1629.679,
      "duration": 3.441
    },
    {
      "lang": "en",
      "text": "to an earlier point you guys said which",
      "offset": 1631.36,
      "duration": 5.199
    },
    {
      "lang": "en",
      "text": "is who's responsible if the LLM as a",
      "offset": 1633.12,
      "duration": 6.559
    },
    {
      "lang": "en",
      "text": "judge or the eval is not good. Is it the",
      "offset": 1636.559,
      "duration": 5.281
    },
    {
      "lang": "en",
      "text": "PM's responsibility or is it the AI",
      "offset": 1639.679,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "engineer responsibility or the the",
      "offset": 1641.84,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "subject matter expert here? But I think",
      "offset": 1643.76,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "that picking the right person to label",
      "offset": 1645.679,
      "duration": 4.721
    },
    {
      "lang": "en",
      "text": "data in the case of like medical data",
      "offset": 1647.679,
      "duration": 5.281
    },
    {
      "lang": "en",
      "text": "for example or legal data, it's it's",
      "offset": 1650.4,
      "duration": 3.519
    },
    {
      "lang": "en",
      "text": "probably not going to be the product",
      "offset": 1652.96,
      "duration": 2.319
    },
    {
      "lang": "en",
      "text": "manager. They might need to outsource",
      "offset": 1653.919,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "that to a specific human or a subject",
      "offset": 1655.279,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "matter expert. But in the case of",
      "offset": 1657.6,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "something like a trip planner, like you",
      "offset": 1659.279,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "could collaborate with this with a",
      "offset": 1661.36,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "travel agent if you're the product",
      "offset": 1663.36,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "manager and make sure that the that this",
      "offset": 1664.72,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "AI travel agent is actually good or bad.",
      "offset": 1667.2,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "So I think you want the PM should at",
      "offset": 1669.6,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "least be in the loop there of who's",
      "offset": 1671.039,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "labeling the data in the first place. So",
      "offset": 1672.88,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "in the context of the trip planning just",
      "offset": 1675.039,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "I'm sorry I'm just like trying to still",
      "offset": 1676.88,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "grasp this. So let's say there's a trip",
      "offset": 1678.559,
      "duration": 4.561
    },
    {
      "lang": "en",
      "text": "planning thread and there's there ends",
      "offset": 1680.88,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "up being something like 50 messages back",
      "offset": 1683.12,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "and forth like 25 from the person 25",
      "offset": 1685.12,
      "duration": 6.08
    },
    {
      "lang": "en",
      "text": "from the LLM. Okay. when the so two two",
      "offset": 1687.279,
      "duration": 5.201
    },
    {
      "lang": "en",
      "text": "questions I'm trying to understand is",
      "offset": 1691.2,
      "duration": 6.079
    },
    {
      "lang": "en",
      "text": "one what does the data set look like",
      "offset": 1692.48,
      "duration": 7.199
    },
    {
      "lang": "en",
      "text": "that needs to be that needs that gets",
      "offset": 1697.279,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "fed into the judge in this scenario if",
      "offset": 1699.679,
      "duration": 4.961
    },
    {
      "lang": "en",
      "text": "I'm asking the wrong question feel free",
      "offset": 1702.799,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "to steer me towards asking the right",
      "offset": 1704.64,
      "duration": 2.8
    },
    {
      "lang": "en",
      "text": "question on that and then the second",
      "offset": 1705.919,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "thing I just wanted to ask is like when",
      "offset": 1707.44,
      "duration": 4.719
    },
    {
      "lang": "en",
      "text": "it comes to the eval the evaluations",
      "offset": 1709.52,
      "duration": 4.639
    },
    {
      "lang": "en",
      "text": "themselves is like every single message",
      "offset": 1712.159,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "being scrutinized or is like the atomic",
      "offset": 1714.159,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "unit of scrutiny something different",
      "offset": 1716.399,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "than like an individual output from the",
      "offset": 1718.08,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "LLM. Is it the input plus output plus",
      "offset": 1720.159,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "context or something that's being like",
      "offset": 1722.88,
      "duration": 3.279
    },
    {
      "lang": "en",
      "text": "based on this context and this input?",
      "offset": 1724.24,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "How does this output stack up? Is that",
      "offset": 1726.159,
      "duration": 3.201
    },
    {
      "lang": "en",
      "text": "basically what's going on? Okay. Could I",
      "offset": 1727.84,
      "duration": 2.8
    },
    {
      "lang": "en",
      "text": "actually double click on your first",
      "offset": 1729.36,
      "duration": 3.039
    },
    {
      "lang": "en",
      "text": "question when you say what would that",
      "offset": 1730.64,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "scenario be? So that would be like you",
      "offset": 1732.399,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "mentioned like 50 or 25 examples like",
      "offset": 1733.84,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "what does that look like in your world?",
      "offset": 1735.919,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "It's one user chatting with this LLM",
      "offset": 1737.52,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "travel agent that's AI, right? So I'm",
      "offset": 1739.84,
      "duration": 2.959
    },
    {
      "lang": "en",
      "text": "like I come in and I'm like my first",
      "offset": 1741.52,
      "duration": 2.56
    },
    {
      "lang": "en",
      "text": "question is like I'm planning a trip to",
      "offset": 1742.799,
      "duration": 3.041
    },
    {
      "lang": "en",
      "text": "Paris and it's like cool like tell me",
      "offset": 1744.08,
      "duration": 3.599
    },
    {
      "lang": "en",
      "text": "more about your trip. So that that would",
      "offset": 1745.84,
      "duration": 3.439
    },
    {
      "lang": "en",
      "text": "be like one message from me and one",
      "offset": 1747.679,
      "duration": 3.201
    },
    {
      "lang": "en",
      "text": "message from the LLM when I I'm going",
      "offset": 1749.279,
      "duration": 3.201
    },
    {
      "lang": "en",
      "text": "with my two kids and we're planning on",
      "offset": 1750.88,
      "duration": 3.039
    },
    {
      "lang": "en",
      "text": "staying for four nights and here's our",
      "offset": 1752.48,
      "duration": 2.72
    },
    {
      "lang": "en",
      "text": "budget per night. So that's like the",
      "offset": 1753.919,
      "duration": 2.64
    },
    {
      "lang": "en",
      "text": "third message in that thread and then it",
      "offset": 1755.2,
      "duration": 2.64
    },
    {
      "lang": "en",
      "text": "comes back to me with a response which",
      "offset": 1756.559,
      "duration": 2.321
    },
    {
      "lang": "en",
      "text": "would be the fourth message in the",
      "offset": 1757.84,
      "duration": 2.719
    },
    {
      "lang": "en",
      "text": "thread. So that's what I mean is like if",
      "offset": 1758.88,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "there's like a whole chat thread between",
      "offset": 1760.559,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "the human and the LLM and it's like a",
      "offset": 1762.72,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "total of 50 total messages. I'm just",
      "offset": 1764.48,
      "duration": 5.679
    },
    {
      "lang": "en",
      "text": "wondering what's the unit of data that",
      "offset": 1766.72,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "is being evaluated from an eval",
      "offset": 1770.159,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "perspective. Is it like the whole chat",
      "offset": 1772.24,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "or is it like a specific response or",
      "offset": 1774.32,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "Yeah. Yeah. Is it like the output of",
      "offset": 1776.399,
      "duration": 3.441
    },
    {
      "lang": "en",
      "text": "like, hey, like we've planned the trip",
      "offset": 1778,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "and we have the tickets or is it more of",
      "offset": 1779.84,
      "duration": 4.959
    },
    {
      "lang": "en",
      "text": "a how did you react to every single",
      "offset": 1782.72,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "question and piece of information? It's",
      "offset": 1784.799,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "almost like what is the Yeah. Where is",
      "offset": 1786.24,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "the granularity that you're doing eval",
      "offset": 1788.159,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "basically? Yeah. I actually think this",
      "offset": 1790.159,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "might look I don't know as we're talking",
      "offset": 1792.399,
      "duration": 3.201
    },
    {
      "lang": "en",
      "text": "about it. This is sort of a visual that",
      "offset": 1794.159,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "came to mind which is this kind of looks",
      "offset": 1795.6,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "like an eval funnel to some degree and I",
      "offset": 1797.279,
      "duration": 4.801
    },
    {
      "lang": "en",
      "text": "think like PM's all funnel. So I'll just",
      "offset": 1800.08,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "use the the funnel analogy here a little",
      "offset": 1802.08,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "bit. There's basically a hierarchy of",
      "offset": 1804.24,
      "duration": 6.96
    },
    {
      "lang": "en",
      "text": "the sort of objects in the system and at",
      "offset": 1808.08,
      "duration": 5.599
    },
    {
      "lang": "en",
      "text": "the top level you have the overall",
      "offset": 1811.2,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "session or maybe the user which is like",
      "offset": 1813.679,
      "duration": 5.841
    },
    {
      "lang": "en",
      "text": "is this user having a good experience or",
      "offset": 1816.24,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "is the individual back and forth you",
      "offset": 1819.52,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "might be having like a customer support",
      "offset": 1821.44,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "bot or a trip planner is this good or",
      "offset": 1823.12,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "bad like you can evaluate that at an",
      "offset": 1824.96,
      "duration": 4.959
    },
    {
      "lang": "en",
      "text": "aggregate level thumbs up thumbs down",
      "offset": 1827.2,
      "duration": 4.479
    },
    {
      "lang": "en",
      "text": "did this customer have their question",
      "offset": 1829.919,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "answered they book a trip you have some",
      "offset": 1831.679,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "real world metric you can tie that back",
      "offset": 1834,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "to. So that's how I would think about",
      "offset": 1835.919,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "that first one. One plug here that I",
      "offset": 1837.84,
      "duration": 2.959
    },
    {
      "lang": "en",
      "text": "just want to make is that's kind of like",
      "offset": 1839.52,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "the importance of like really thinking",
      "offset": 1840.799,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "about what's the goal that we're trying",
      "offset": 1843.2,
      "duration": 2.64
    },
    {
      "lang": "en",
      "text": "to accomplish here because I think it",
      "offset": 1844.399,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "sounds like that makes it a lot easier.",
      "offset": 1845.84,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "Hey, did we accomplish our original",
      "offset": 1847.919,
      "duration": 2.801
    },
    {
      "lang": "en",
      "text": "goal? Which maybe was like, hey, did we",
      "offset": 1849.2,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "get this person booked to for their trip",
      "offset": 1850.72,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "or did we answer the questions or it",
      "offset": 1852.88,
      "duration": 4.799
    },
    {
      "lang": "en",
      "text": "could Yeah, it could be the business",
      "offset": 1856.72,
      "duration": 2.72
    },
    {
      "lang": "en",
      "text": "metric or it could be like the user goal",
      "offset": 1857.679,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "or something like that cuz cuz if I'm",
      "offset": 1859.44,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "overall satisfied with the session even",
      "offset": 1862.159,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "though there was a couple messages in it",
      "offset": 1864.08,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "that felt unsatisfactory,",
      "offset": 1866.159,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "then the overall session gets a thumbs",
      "offset": 1868.48,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "up. But I think where you're going with",
      "offset": 1870.24,
      "duration": 2.88
    },
    {
      "lang": "en",
      "text": "this is that there could be components",
      "offset": 1871.6,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "of that section or subsets of that",
      "offset": 1873.12,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "session that maybe did not pass. Is that",
      "offset": 1875.44,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "kind of exactly that's exactly where",
      "offset": 1877.52,
      "duration": 3.519
    },
    {
      "lang": "en",
      "text": "where things are going here and there's",
      "offset": 1879.279,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "also like a little bit of nuance to",
      "offset": 1881.039,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "thumbs up thumbs down by the way because",
      "offset": 1882.559,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "you can in this example like a very",
      "offset": 1885.36,
      "duration": 4.799
    },
    {
      "lang": "en",
      "text": "common example is a customer support",
      "offset": 1887.679,
      "duration": 4.641
    },
    {
      "lang": "en",
      "text": "agent might give the right answer to",
      "offset": 1890.159,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "something no you're not eligible for a",
      "offset": 1892.32,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "refund but are you going to give that",
      "offset": 1894.08,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "chatbot a thumbs up or a thumbs down in",
      "offset": 1896.32,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "that example right and so even defining",
      "offset": 1898,
      "duration": 6.24
    },
    {
      "lang": "en",
      "text": "who decides whether or not the agent did",
      "offset": 1901.44,
      "duration": 5.359
    },
    {
      "lang": "en",
      "text": "the right thing at the session",
      "offset": 1904.24,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "requires a little bit of like nuance.",
      "offset": 1906.799,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "You can't just rely on your end user.",
      "offset": 1908.32,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "That sounds like an important decision",
      "offset": 1909.919,
      "duration": 2.88
    },
    {
      "lang": "en",
      "text": "actually. Like it's a really important",
      "offset": 1911.36,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "decision cuz if you get that wrong, then",
      "offset": 1912.799,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "your entire northstar for success for",
      "offset": 1914.48,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "the product could be completely exactly",
      "offset": 1916.64,
      "duration": 3.279
    },
    {
      "lang": "en",
      "text": "out of whack. Exactly. If you try to",
      "offset": 1918.32,
      "duration": 3.359
    },
    {
      "lang": "en",
      "text": "optimize for thumbs up and your customer",
      "offset": 1919.919,
      "duration": 2.961
    },
    {
      "lang": "en",
      "text": "support agent, you might be giving away",
      "offset": 1921.679,
      "duration": 2.801
    },
    {
      "lang": "en",
      "text": "a lot more money than you expected to.",
      "offset": 1922.88,
      "duration": 2.799
    },
    {
      "lang": "en",
      "text": "So just kind of keep that in mind. And",
      "offset": 1924.48,
      "duration": 2.72
    },
    {
      "lang": "en",
      "text": "then as you go down, let's say that's",
      "offset": 1925.679,
      "duration": 2.88
    },
    {
      "lang": "en",
      "text": "actually I think that's a good example.",
      "offset": 1927.2,
      "duration": 3.359
    },
    {
      "lang": "en",
      "text": "Let's pick an example where your end",
      "offset": 1928.559,
      "duration": 6.881
    },
    {
      "lang": "en",
      "text": "user gave you a thumbs down because",
      "offset": 1930.559,
      "duration": 6.561
    },
    {
      "lang": "en",
      "text": "they didn't get a refund when they",
      "offset": 1935.44,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "expected one or they wanted one. But if",
      "offset": 1937.12,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "you take a look at the the transcript or",
      "offset": 1939.519,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "the chat back and forth, like the",
      "offset": 1941.36,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "subject matter expert gave the agent a",
      "offset": 1943.039,
      "duration": 3.441
    },
    {
      "lang": "en",
      "text": "thumbs up because it answered the",
      "offset": 1945.12,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "questions correctly and did all the",
      "offset": 1946.48,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "right things. There's levels to that",
      "offset": 1948.48,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "where you might need to go to make sure",
      "offset": 1950.64,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "and verify that's the case. So you can",
      "offset": 1952.08,
      "duration": 4.479
    },
    {
      "lang": "en",
      "text": "do things like verifying is the right",
      "offset": 1954.32,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "data in place. So you mentioned context.",
      "offset": 1956.559,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "So you might do something like a context",
      "offset": 1958.96,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "or data eval which is does is is the",
      "offset": 1960.799,
      "duration": 5.681
    },
    {
      "lang": "en",
      "text": "right areas of our knowledge base being",
      "offset": 1964.72,
      "duration": 3.439
    },
    {
      "lang": "en",
      "text": "retrieved. Are we getting the right data",
      "offset": 1966.48,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "back from this user? You can double",
      "offset": 1968.159,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "check those things. So that's something",
      "offset": 1970.08,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "important which is is there the right",
      "offset": 1971.84,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "context? So basically the refund",
      "offset": 1973.36,
      "duration": 3.679
    },
    {
      "lang": "en",
      "text": "example, if they give a thumbs down",
      "offset": 1975.2,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "because they're not happy with the fact",
      "offset": 1977.039,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "they didn't get the refund and then",
      "offset": 1978.88,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "turns out that the LLM a that the chat",
      "offset": 1981.039,
      "duration": 5.201
    },
    {
      "lang": "en",
      "text": "agent actually maybe there was like a",
      "offset": 1983.76,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "nuance like the terms and conditions or",
      "offset": 1986.24,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "something that said that in the scenario",
      "offset": 1988.159,
      "duration": 3.441
    },
    {
      "lang": "en",
      "text": "in this particular scenario that this",
      "offset": 1990.08,
      "duration": 2.64
    },
    {
      "lang": "en",
      "text": "customer is in there actually should be",
      "offset": 1991.6,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "a refund. Exactly. So in this case like",
      "offset": 1992.72,
      "duration": 5.199
    },
    {
      "lang": "en",
      "text": "we would give a thumbs down",
      "offset": 1995.12,
      "duration": 5.679
    },
    {
      "lang": "en",
      "text": "because it like missed like it got",
      "offset": 1997.919,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "something inaccurate or there was a",
      "offset": 2000.799,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "wrong literally like wrong data or wrong",
      "offset": 2002.24,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "context being brought to the decision,",
      "offset": 2004.96,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "right? Was the right data or context",
      "offset": 2006.48,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "there? Right? Like that's really",
      "offset": 2008.96,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "important to verify. Did we even get the",
      "offset": 2010.32,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "right data or context? What's",
      "offset": 2012.32,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "interesting is if you go a little bit",
      "offset": 2014.48,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "deeper, you can also do what's called a",
      "offset": 2015.76,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "hallucination eval very common",
      "offset": 2018.64,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "evaluation in the case of like",
      "offset": 2020.32,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "retrieval, which is even if you have the",
      "offset": 2021.84,
      "duration": 5.92
    },
    {
      "lang": "en",
      "text": "right data in place, did the LLM use the",
      "offset": 2024.159,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "data correctly? And this was like if you",
      "offset": 2027.76,
      "duration": 5.84
    },
    {
      "lang": "en",
      "text": "put this into your prompt, does the LLM",
      "offset": 2030.159,
      "duration": 6.24
    },
    {
      "lang": "en",
      "text": "use the data? and even if you have the",
      "offset": 2033.6,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "right data in the prompt in the first",
      "offset": 2036.399,
      "duration": 2.64
    },
    {
      "lang": "en",
      "text": "place and that's called like a",
      "offset": 2037.919,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "hallucination email. And so in in the",
      "offset": 2039.039,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "example where there there was like",
      "offset": 2041.279,
      "duration": 2.801
    },
    {
      "lang": "en",
      "text": "something in the terms of service that",
      "offset": 2042.559,
      "duration": 3.041
    },
    {
      "lang": "en",
      "text": "said that this customer should get a",
      "offset": 2044.08,
      "duration": 6.079
    },
    {
      "lang": "en",
      "text": "refund, would the hallucination be about",
      "offset": 2045.6,
      "duration": 6.88
    },
    {
      "lang": "en",
      "text": "the LL like the chat agent telling the",
      "offset": 2050.159,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "customer that they're not eligible for a",
      "offset": 2052.48,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "refund? Yeah. Is that a hallucination or",
      "offset": 2054.24,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "is that more Exactly. Yeah. So like in",
      "offset": 2056.48,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "the case where the in in that exact",
      "offset": 2058.639,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "scenario, it' be like, &quot;Yeah, we fetched",
      "offset": 2060.72,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "the terms of service, we have the right",
      "offset": 2062.48,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "data in place, but for some reason the",
      "offset": 2064.72,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "LLM was peeved because the person was",
      "offset": 2067.28,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "being rude to it and it decided, no,",
      "offset": 2069.52,
      "duration": 3.119
    },
    {
      "lang": "en",
      "text": "you're not eligible for a refund because",
      "offset": 2071.359,
      "duration": 2.961
    },
    {
      "lang": "en",
      "text": "you're being rude to me.&quot; Like that that",
      "offset": 2072.639,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "totally can happen, right? It's like",
      "offset": 2074.32,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "sort of like a human being upset in a",
      "offset": 2075.839,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "scenario as well. Yeah. The thing that I",
      "offset": 2077.44,
      "duration": 3.199
    },
    {
      "lang": "en",
      "text": "want to clarify is Yeah. It's like",
      "offset": 2078.879,
      "duration": 2.72
    },
    {
      "lang": "en",
      "text": "there's a difference between",
      "offset": 2080.639,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "hallucination but also like actually a",
      "offset": 2081.599,
      "duration": 5.361
    },
    {
      "lang": "en",
      "text": "failure in retrieval. You might have the",
      "offset": 2084.879,
      "duration": 4.561
    },
    {
      "lang": "en",
      "text": "right file, but you actually like your",
      "offset": 2086.96,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "retrieval model or whatever is not as",
      "offset": 2089.44,
      "duration": 3.439
    },
    {
      "lang": "en",
      "text": "good and then you missed this nuance.",
      "offset": 2090.96,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "And that's not necessarily a",
      "offset": 2092.879,
      "duration": 2.8
    },
    {
      "lang": "en",
      "text": "hallucination. That's more of your",
      "offset": 2094.24,
      "duration": 3.119
    },
    {
      "lang": "en",
      "text": "retrieval wasn't as good as you thought",
      "offset": 2095.679,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "it was and then you just missed it",
      "offset": 2097.359,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "basically. Totally. Are the systems like",
      "offset": 2099.119,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "this is so interesting if in the",
      "offset": 2101.839,
      "duration": 2.801
    },
    {
      "lang": "en",
      "text": "scenario that we're just playing with",
      "offset": 2103.44,
      "duration": 2.56
    },
    {
      "lang": "en",
      "text": "where there was something in the terms",
      "offset": 2104.64,
      "duration": 2.959
    },
    {
      "lang": "en",
      "text": "of and conditions about this user",
      "offset": 2106,
      "duration": 3.599
    },
    {
      "lang": "en",
      "text": "deserving the refund and the machine",
      "offset": 2107.599,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "says you don't get it. You're not",
      "offset": 2109.599,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "eligible. So that's a hallucination. Do",
      "offset": 2111.28,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "we now have is the system that like",
      "offset": 2114,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "arise is building or the eval systems",
      "offset": 2116,
      "duration": 3.599
    },
    {
      "lang": "en",
      "text": "such that they will like literally tell",
      "offset": 2118,
      "duration": 5.119
    },
    {
      "lang": "en",
      "text": "you the reason that that that it said",
      "offset": 2119.599,
      "duration": 5.041
    },
    {
      "lang": "en",
      "text": "you don't get a refund whether it's",
      "offset": 2123.119,
      "duration": 2.881
    },
    {
      "lang": "en",
      "text": "because of the hallucination or because",
      "offset": 2124.64,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "it didn't have the right data. Yeah.",
      "offset": 2126,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "Exactly. And that's a that's what we",
      "offset": 2128.24,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "call an explanation in the eval world a",
      "offset": 2130.4,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "little bit. And I can kind of show an",
      "offset": 2133.2,
      "duration": 2.879
    },
    {
      "lang": "en",
      "text": "example of that just really quick and",
      "offset": 2134.48,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "we'll talk it out loud as well. Let's",
      "offset": 2136.079,
      "duration": 3.441
    },
    {
      "lang": "en",
      "text": "say this is actually an agent we built",
      "offset": 2137.76,
      "duration": 5.599
    },
    {
      "lang": "en",
      "text": "like a rag agent on our own docs and you",
      "offset": 2139.52,
      "duration": 6.16
    },
    {
      "lang": "en",
      "text": "and what we're looking at is basically",
      "offset": 2143.359,
      "duration": 4.801
    },
    {
      "lang": "en",
      "text": "examples where the chat agent or",
      "offset": 2145.68,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "document agent gave answers and whether",
      "offset": 2148.16,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "or not they were correct based on an",
      "offset": 2150.56,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "evaluation using human labels but then",
      "offset": 2152.4,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "also hallucination which is was the",
      "offset": 2154.96,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "context used correctly and what's",
      "offset": 2157.28,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "interesting is you can see the LLM as a",
      "offset": 2159.44,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "judge might read the context and the",
      "offset": 2161.119,
      "duration": 5.041
    },
    {
      "lang": "en",
      "text": "prompt is actually says take a look at",
      "offset": 2163.839,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "the reference text, take a look at the",
      "offset": 2166.16,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "LLM's output and input and see did the",
      "offset": 2167.92,
      "duration": 5.199
    },
    {
      "lang": "en",
      "text": "context get used correctly or not. And",
      "offset": 2171.04,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "the explanation can say although the",
      "offset": 2173.119,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "answer sounds really good, it said",
      "offset": 2175.52,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "here's reasons why it sounds like it",
      "offset": 2177.599,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "could be correct, it's actually",
      "offset": 2179.599,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "referencing the document incorrectly or",
      "offset": 2181.2,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "maybe misinterpreting parts of the doc.",
      "offset": 2183.599,
      "duration": 3.041
    },
    {
      "lang": "en",
      "text": "So you can actually it's really",
      "offset": 2185.44,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "important to get explanations on your",
      "offset": 2186.64,
      "duration": 4.959
    },
    {
      "lang": "en",
      "text": "eval so that you as a human can decide",
      "offset": 2188.64,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "whether you trust the LLM as a judge in",
      "offset": 2191.599,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "the first place or not.",
      "offset": 2193.68,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "Yeah, I think Sel where my head is going",
      "offset": 2195.359,
      "duration": 3.521
    },
    {
      "lang": "en",
      "text": "right now and by the way let me know if",
      "offset": 2197.2,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "this is getting too in the weeds but",
      "offset": 2198.88,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "when you're looking at evals and to me",
      "offset": 2200.88,
      "duration": 7.68
    },
    {
      "lang": "en",
      "text": "it feels like it's easy to explore like",
      "offset": 2204.24,
      "duration": 6.24
    },
    {
      "lang": "en",
      "text": "the ones that they get wrong almost cuz",
      "offset": 2208.56,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "you're like okay this is obviously is",
      "offset": 2210.48,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "the wrong answer because I know that",
      "offset": 2212.32,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "this is but I think the dangerous ones",
      "offset": 2213.68,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "I'm not sure if the right term is like",
      "offset": 2216.24,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "false positives but like where it",
      "offset": 2217.52,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "actually or actually it's actually not",
      "offset": 2219.28,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "false positive but let's say for example",
      "offset": 2221.28,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "like it actually gives that person the",
      "offset": 2222.72,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "refund, but it gives the refund because",
      "offset": 2224.8,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "it hallucinated, right? Yeah. And even",
      "offset": 2227.2,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "though the top level is correct, I guess",
      "offset": 2229.28,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "my concern would be like we dismiss it",
      "offset": 2231.44,
      "duration": 2.88
    },
    {
      "lang": "en",
      "text": "because oh, you got it right. I don't",
      "offset": 2233.04,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "really and you could just move. Wouldn't",
      "offset": 2234.32,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "that be the session getting a thumbs",
      "offset": 2236.24,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "down from a business metric perspective?",
      "offset": 2238.4,
      "duration": 4.719
    },
    {
      "lang": "en",
      "text": "Well, like in other words, if a refund",
      "offset": 2241.04,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "was issued in that session and it",
      "offset": 2243.119,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "shouldn't have, then doesn't that mean",
      "offset": 2244.72,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "that whoever is evaluating the quality",
      "offset": 2247.04,
      "duration": 3.039
    },
    {
      "lang": "en",
      "text": "of that session would give it a thumbs",
      "offset": 2248.64,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "down at the session level? You would",
      "offset": 2250.079,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "probably need a human in the loop there",
      "offset": 2252.4,
      "duration": 2.719
    },
    {
      "lang": "en",
      "text": "though verifying the output in that",
      "offset": 2253.68,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "case. Yeah. Or wouldn't a human in the",
      "offset": 2255.119,
      "duration": 3.521
    },
    {
      "lang": "en",
      "text": "loop be assumed as in what we're talking",
      "offset": 2256.96,
      "duration": 2.879
    },
    {
      "lang": "en",
      "text": "about or is what we've been talking",
      "offset": 2258.64,
      "duration": 2.719
    },
    {
      "lang": "en",
      "text": "about in this funnel not assuming",
      "offset": 2259.839,
      "duration": 3.201
    },
    {
      "lang": "en",
      "text": "there's a human in the loop. Exactly. So",
      "offset": 2261.359,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "the part of the reason why people",
      "offset": 2263.04,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "gravitate towards these LLM as a judge",
      "offset": 2264.96,
      "duration": 4.879
    },
    {
      "lang": "en",
      "text": "is in back in the back in the old day",
      "offset": 2267.2,
      "duration": 4.639
    },
    {
      "lang": "en",
      "text": "back in the old day of like credit card",
      "offset": 2269.839,
      "duration": 5.041
    },
    {
      "lang": "en",
      "text": "fraud or examples of like classification",
      "offset": 2271.839,
      "duration": 5.601
    },
    {
      "lang": "en",
      "text": "models if things seemed fishy you would",
      "offset": 2274.88,
      "duration": 4.479
    },
    {
      "lang": "en",
      "text": "have humans go in and label the data.",
      "offset": 2277.44,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "But in the case of chat bots or travel",
      "offset": 2279.359,
      "duration": 5.361
    },
    {
      "lang": "en",
      "text": "agents, there's just no way to label",
      "offset": 2282.48,
      "duration": 5.119
    },
    {
      "lang": "en",
      "text": "every single example and back and forth",
      "offset": 2284.72,
      "duration": 6.08
    },
    {
      "lang": "en",
      "text": "and context. And even in the case of the",
      "offset": 2287.599,
      "duration": 5.361
    },
    {
      "lang": "en",
      "text": "business metric, like there's a bit of a",
      "offset": 2290.8,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "lag here between when you actually",
      "offset": 2292.96,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "figure out whether or not the agent",
      "offset": 2294.8,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "should have given a refund or not. And",
      "offset": 2297.359,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "so it's really important to have systems",
      "offset": 2298.88,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "in place that can check scalably. And",
      "offset": 2301.04,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "that's why your human is perhaps in the",
      "offset": 2304.32,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "loop, Ben, but it's not reviewing every",
      "offset": 2307.04,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "session. Yeah. Not every single session.",
      "offset": 2309.92,
      "duration": 3.439
    },
    {
      "lang": "en",
      "text": "Exactly. So, so to Mark's example,",
      "offset": 2311.68,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "another version that comes to mind is",
      "offset": 2313.359,
      "duration": 3.361
    },
    {
      "lang": "en",
      "text": "like when insurance companies like pay",
      "offset": 2314.96,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "out claims or something. It's like",
      "offset": 2316.72,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "almost the same thing is like someone",
      "offset": 2318.4,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "asking for a refund and getting it is",
      "offset": 2320.24,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "similar to someone filing a claim and",
      "offset": 2321.92,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "getting paid out. Yeah. And so my guess",
      "offset": 2323.92,
      "duration": 6.24
    },
    {
      "lang": "en",
      "text": "is you want to spot check a sample of",
      "offset": 2326.4,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "all the claims that you approved. And",
      "offset": 2330.16,
      "duration": 3.439
    },
    {
      "lang": "en",
      "text": "then you probably want to also spot",
      "offset": 2332,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "check a sampling of all of the refunds",
      "offset": 2333.599,
      "duration": 4.721
    },
    {
      "lang": "en",
      "text": "that you've granted and then look at the",
      "offset": 2336.16,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "sessions that led to those refunds",
      "offset": 2338.32,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "getting granted and what label them.",
      "offset": 2340.96,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "That's where maybe a human could label",
      "offset": 2343.44,
      "duration": 4.639
    },
    {
      "lang": "en",
      "text": "20 30 40 50 sessions over the course of",
      "offset": 2345.359,
      "duration": 5.361
    },
    {
      "lang": "en",
      "text": "like exactly I don't know a day maybe.",
      "offset": 2348.079,
      "duration": 4.481
    },
    {
      "lang": "en",
      "text": "And I think that kind of brings me to a",
      "offset": 2350.72,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "little bit of how much data do you need?",
      "offset": 2352.56,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "How many human labels do you need? And",
      "offset": 2355.28,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "it depends so much like I'm hesitant to",
      "offset": 2356.88,
      "duration": 4.959
    },
    {
      "lang": "en",
      "text": "say how many it depends so much on your",
      "offset": 2359.52,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "circumstance right on your product. And",
      "offset": 2361.839,
      "duration": 3.201
    },
    {
      "lang": "en",
      "text": "I actually think that this is a good",
      "offset": 2363.599,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "question for PMs to ask their team which",
      "offset": 2365.04,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "is what should our sampling rate be? How",
      "offset": 2367.2,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "often should humans be tagged to take a",
      "offset": 2369.359,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "look at data for us to be okay with this",
      "offset": 2371.119,
      "duration": 5.281
    },
    {
      "lang": "en",
      "text": "type of system? And the short answer I",
      "offset": 2373.52,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "can give is whatever you settle on, you",
      "offset": 2376.4,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "might need to revisit that answer of",
      "offset": 2378.56,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "your sampling rate. And so having I'm",
      "offset": 2380.8,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "biased obviously I work on a platform",
      "offset": 2382.72,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "for this, but I do think that being able",
      "offset": 2384.24,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "to have a system in place where you can",
      "offset": 2386.4,
      "duration": 4.959
    },
    {
      "lang": "en",
      "text": "see and adjust the sampling rate for",
      "offset": 2388.48,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "humans and LLM as a judge going in and",
      "offset": 2391.359,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "labeling data is really important so",
      "offset": 2393.68,
      "duration": 3.679
    },
    {
      "lang": "en",
      "text": "that you can make a decision and commit",
      "offset": 2395.68,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "but then come back and revisit if you",
      "offset": 2397.359,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "need to as well. When should you revisit",
      "offset": 2399.2,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "how often you're like how you sample",
      "offset": 2401.599,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "data? Like is there any like event you",
      "offset": 2403.52,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "should be looking for that's is it like",
      "offset": 2405.52,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "a model change? Is it Yeah. Yeah. I",
      "offset": 2406.96,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "think that there's a couple of events",
      "offset": 2409.599,
      "duration": 3.361
    },
    {
      "lang": "en",
      "text": "that can help you track this. So let's",
      "offset": 2411.119,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "say you pick a sampling rate for humans",
      "offset": 2412.96,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "to go in and label on top of the LLM as",
      "offset": 2414.96,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "a judge and you're actually comparing",
      "offset": 2418,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "because you have an L. Let's imagine in",
      "offset": 2419.92,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "this chatbot use case you have LLM as a",
      "offset": 2421.52,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "judge on the critical components, right?",
      "offset": 2423.839,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "You might not need tone evaluated every",
      "offset": 2425.68,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "single time, but in cases where the user",
      "offset": 2428.16,
      "duration": 3.679
    },
    {
      "lang": "en",
      "text": "was unhappy, you might want to take a",
      "offset": 2430.16,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "look at tone. So that might be like 1%",
      "offset": 2431.839,
      "duration": 4.881
    },
    {
      "lang": "en",
      "text": "or 5% of cases or something like that.",
      "offset": 2434.16,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "But on top of that, you need another",
      "offset": 2436.72,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "sampling rate of humans going in and",
      "offset": 2438.4,
      "duration": 4.719
    },
    {
      "lang": "en",
      "text": "labeling the data. And what's important",
      "offset": 2440,
      "duration": 6.24
    },
    {
      "lang": "en",
      "text": "is to see what's the rate where if a",
      "offset": 2443.119,
      "duration": 5.921
    },
    {
      "lang": "en",
      "text": "human looks at that example or that step",
      "offset": 2446.24,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "and it disagrees with the LLM as a",
      "offset": 2449.04,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "judge, why is that happening? So if you",
      "offset": 2451.28,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "have a subject matter expert disagreeing",
      "offset": 2453.68,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "with the LLM as a judge, those are",
      "offset": 2455.44,
      "duration": 3.679
    },
    {
      "lang": "en",
      "text": "examples you want to take a closer look",
      "offset": 2457.2,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "at and then you can track the rate of",
      "offset": 2459.119,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "that matching. We call it a match rate.",
      "offset": 2461.52,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "And if your match rate is going above a",
      "offset": 2464.079,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "threshold that you're comfortable with,",
      "offset": 2466.24,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "might just be a couple of percent, five",
      "offset": 2468.16,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "or 10% something like that might be a",
      "offset": 2469.68,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "good time to go back and revisit. Hey,",
      "offset": 2471.28,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "we need to iterate on this judge or we",
      "offset": 2472.8,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "need to iterate on the model or",
      "offset": 2474.64,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "something else. Makes sense. Yeah. was",
      "offset": 2476,
      "duration": 5.119
    },
    {
      "lang": "en",
      "text": "basically like you need as part of a",
      "offset": 2478.64,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "quality like in the beginning you be",
      "offset": 2481.119,
      "duration": 5.041
    },
    {
      "lang": "en",
      "text": "like okay like we're okay with a 5% like",
      "offset": 2483.28,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "disagreement between the human and the",
      "offset": 2486.16,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "judge and if in one of your samplings",
      "offset": 2487.76,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "you start to see consistency actually",
      "offset": 2490.16,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "we're at seven or 10%. That's maybe when",
      "offset": 2491.68,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "you like need to go back to the board",
      "offset": 2493.92,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "and be like okay maybe we need to change",
      "offset": 2495.52,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "the way we write evals or maybe we need",
      "offset": 2497.04,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "to change how this product is operating",
      "offset": 2498.72,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "and then you go through that process",
      "offset": 2501.44,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "again until you're like in that range",
      "offset": 2502.8,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "that you want to be at. Another way to",
      "offset": 2505.52,
      "duration": 2.64
    },
    {
      "lang": "en",
      "text": "think about this is like you have",
      "offset": 2507.04,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "multiple knobs at your disposal as a PM,",
      "offset": 2508.16,
      "duration": 3.439
    },
    {
      "lang": "en",
      "text": "right? You have the model, you have the",
      "offset": 2510.24,
      "duration": 3.599
    },
    {
      "lang": "en",
      "text": "prompt, you have your data labeling, and",
      "offset": 2511.599,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "you can tune these knobs to try to get",
      "offset": 2513.839,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "you to the right business outcome at the",
      "offset": 2516.319,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "end of the day. And that's a I'll bring",
      "offset": 2517.92,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "that to like the third point that comes",
      "offset": 2520.079,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "up for me quite a bit, which is aside",
      "offset": 2521.44,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "from how many labels are good enough,",
      "offset": 2523.76,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "what's our sampling rate? And the second",
      "offset": 2525.359,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "one is what happens when the eval",
      "offset": 2526.8,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "doesn't match the human, how often",
      "offset": 2529.04,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "should we go back and revisit those",
      "offset": 2530.64,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "knobs? But then the third is what",
      "offset": 2532.4,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "happens if the business metric goes down",
      "offset": 2534.64,
      "duration": 4.479
    },
    {
      "lang": "en",
      "text": "but the eval is good. And that's again",
      "offset": 2536.48,
      "duration": 4.639
    },
    {
      "lang": "en",
      "text": "like who's accountable in that case and",
      "offset": 2539.119,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "who's responsible to go in and do a",
      "offset": 2541.119,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "deeper dive. And coming back to like",
      "offset": 2542.72,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "where we started here a little bit. Like",
      "offset": 2545.04,
      "duration": 4.799
    },
    {
      "lang": "en",
      "text": "that's where collaborating between an AI",
      "offset": 2547.119,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "PM and an AI engineer is so important",
      "offset": 2549.839,
      "duration": 4.881
    },
    {
      "lang": "en",
      "text": "because the AI engineer is inherently",
      "offset": 2551.839,
      "duration": 5.441
    },
    {
      "lang": "en",
      "text": "going to be motivated and intrinsically",
      "offset": 2554.72,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "motivated to make the eval good but the",
      "offset": 2557.28,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "PM is the person that's ultimately",
      "offset": 2559.76,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "responsible for the business metric. And",
      "offset": 2561.68,
      "duration": 3.439
    },
    {
      "lang": "en",
      "text": "so you can't really get away from the",
      "offset": 2563.52,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "fact where there's going to be",
      "offset": 2565.119,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "circumstances where the eval looks",
      "offset": 2566.64,
      "duration": 3.679
    },
    {
      "lang": "en",
      "text": "really good but the business metric",
      "offset": 2568.72,
      "duration": 2.8
    },
    {
      "lang": "en",
      "text": "still goes down. And how do you",
      "offset": 2570.319,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "reconcile that is a really important",
      "offset": 2571.52,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "discussion to have in a team just like",
      "offset": 2573.359,
      "duration": 4.641
    },
    {
      "lang": "en",
      "text": "from a very it's very easy to say this",
      "offset": 2575.44,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "as someone who's like not invested in",
      "offset": 2578,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "this like fictional situation but like",
      "offset": 2579.839,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "in my point of view if the eval is great",
      "offset": 2581.76,
      "duration": 3.599
    },
    {
      "lang": "en",
      "text": "and the business metric is not good you",
      "offset": 2583.68,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "got to un ship that puppy like ASAP",
      "offset": 2585.359,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "right or or like sounds like the spec",
      "offset": 2587.2,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "was off right if we build something",
      "offset": 2589.44,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "because we wanted to move something",
      "offset": 2591.92,
      "duration": 2.96
    },
    {
      "lang": "en",
      "text": "that's critical and it's not only not",
      "offset": 2592.96,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "moving it but hurting it right is there",
      "offset": 2594.88,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "what's the point of keeping that around",
      "offset": 2596.96,
      "duration": 2.96
    },
    {
      "lang": "en",
      "text": "and I and is is what you're getting at",
      "offset": 2598.24,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "that there's just so much investment and",
      "offset": 2599.92,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "some cost fallacy there that that is",
      "offset": 2601.92,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "just people struggle to like make that",
      "offset": 2604.079,
      "duration": 3.121
    },
    {
      "lang": "en",
      "text": "decision or am I missing something",
      "offset": 2605.76,
      "duration": 2.72
    },
    {
      "lang": "en",
      "text": "there? It's actually comes back a little",
      "offset": 2607.2,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "bit to the we have 50 eval. We have 100",
      "offset": 2608.48,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "eval. But are you looking even if you",
      "offset": 2610.72,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "have eval?",
      "offset": 2612.8,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "Are you looking at the right things at",
      "offset": 2614.64,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "the right time is one one example of",
      "offset": 2616,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "that, right? If you're hyperfixating on",
      "offset": 2618.24,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "the LLM being helpful, but it's being a",
      "offset": 2620.8,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "pushover. It's the agent is being pushed",
      "offset": 2624,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "over by a customer. That might be",
      "offset": 2625.76,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "something to revisit. Do you have the",
      "offset": 2627.44,
      "duration": 2.8
    },
    {
      "lang": "en",
      "text": "right, you know, this is the unknown",
      "offset": 2628.88,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "unknowns kind of territory a little bit",
      "offset": 2630.24,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "like that that real businesses have all",
      "offset": 2632.16,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "the time. Like you might design your",
      "offset": 2634.4,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "PRD, you might design your product with",
      "offset": 2636.48,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "EV valves in mind even from the",
      "offset": 2637.92,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "beginning and you ship the thing and",
      "offset": 2639.52,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "you're measuring eval but the business",
      "offset": 2640.96,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "metric might still go down and it could",
      "offset": 2643.2,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "just be we're just you just started off",
      "offset": 2645.28,
      "duration": 2.72
    },
    {
      "lang": "en",
      "text": "measuring the wrong thing or you're",
      "offset": 2646.8,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "missing something in in your story is",
      "offset": 2648,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "and I guess one one more question there.",
      "offset": 2650.48,
      "duration": 3.599
    },
    {
      "lang": "en",
      "text": "So I guess maybe like the right question",
      "offset": 2652.8,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "is at what point is it worth iterating",
      "offset": 2654.079,
      "duration": 6.321
    },
    {
      "lang": "en",
      "text": "on kind of maybe using different evals",
      "offset": 2657.68,
      "duration": 6.32
    },
    {
      "lang": "en",
      "text": "or just evolving things differently or",
      "offset": 2660.4,
      "duration": 5.679
    },
    {
      "lang": "en",
      "text": "versus just maybe okay letting go of",
      "offset": 2664,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "that feature be hey we tried didn't move",
      "offset": 2666.079,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "the needle yeah how do you think between",
      "offset": 2667.92,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "those two things right yeah and feel",
      "offset": 2669.839,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "free to hop in as well Ben if you had a",
      "offset": 2672.24,
      "duration": 3.599
    },
    {
      "lang": "en",
      "text": "thought there but I kind of figured this",
      "offset": 2674.16,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "is like what the story actually looks",
      "offset": 2675.839,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "like when you do eval right and I have",
      "offset": 2677.76,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "this as like workflow number three right",
      "offset": 2680,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "so workflow un vibe coding. Where does",
      "offset": 2681.68,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "that fit into your workflow? Workflow 2,",
      "offset": 2683.44,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "eval ship the thing with eval, but",
      "offset": 2685.44,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "there's still problems I think workflow",
      "offset": 2687.52,
      "duration": 4.559
    },
    {
      "lang": "en",
      "text": "3 is like eval sitting in development",
      "offset": 2689.599,
      "duration": 5.681
    },
    {
      "lang": "en",
      "text": "and production and you're using eval to",
      "offset": 2692.079,
      "duration": 4.961
    },
    {
      "lang": "en",
      "text": "make decisions.",
      "offset": 2695.28,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "And in this case, you're building an",
      "offset": 2697.04,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "agent product or an agent or an AI",
      "offset": 2698.96,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "product. The eval iterate in development",
      "offset": 2700.96,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "before you even run your AB tests. So",
      "offset": 2703.359,
      "duration": 4.641
    },
    {
      "lang": "en",
      "text": "you have eval",
      "offset": 2705.359,
      "duration": 5.281
    },
    {
      "lang": "en",
      "text": "like eval are the PRD to some degree.",
      "offset": 2708,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "You're measuring your performance",
      "offset": 2710.64,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "against those eval development and using",
      "offset": 2712.24,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "internal data or subject matter experts",
      "offset": 2714.56,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "to grade the outputs. And when it looks",
      "offset": 2716.8,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "good, when everyone's on the same page,",
      "offset": 2718.88,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "your stakeholders, your engineers, your",
      "offset": 2720.48,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "team are aligned, you ship the thing.",
      "offset": 2722.4,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "And the product should at that point",
      "offset": 2724.72,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "model the real world enough for it to be",
      "offset": 2726.56,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "some some degree of reliability more",
      "offset": 2728.72,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "than an eval that's not aligned or the",
      "offset": 2730.72,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "vibe coding case. But you're still going",
      "offset": 2733.28,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "to have users complain. Like at the end",
      "offset": 2735.2,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "of the day, any product if you actually",
      "offset": 2736.96,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "have reach is going to have users that",
      "offset": 2739.119,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "complain or that the things are going to",
      "offset": 2741.359,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "go wrong. And in those cases, it's",
      "offset": 2743.2,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "really important to just have a system",
      "offset": 2745.76,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "to look at your data and iterate. And",
      "offset": 2747.359,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "that's I think the real moral of the",
      "offset": 2750.24,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "story is like you can have everything",
      "offset": 2751.839,
      "duration": 6.641
    },
    {
      "lang": "en",
      "text": "set up from the get-go correctly, but",
      "offset": 2755.28,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "there's still going to be times when",
      "offset": 2758.48,
      "duration": 2.72
    },
    {
      "lang": "en",
      "text": "things go wrong. And so being able to",
      "offset": 2759.68,
      "duration": 3.679
    },
    {
      "lang": "en",
      "text": "have a system to iterate on the eval in",
      "offset": 2761.2,
      "duration": 4.639
    },
    {
      "lang": "en",
      "text": "the first place is really important. Is",
      "offset": 2763.359,
      "duration": 6.48
    },
    {
      "lang": "en",
      "text": "this is there ever a world where the PM",
      "offset": 2765.839,
      "duration": 6.161
    },
    {
      "lang": "en",
      "text": "the or the engineer or anyone at the",
      "offset": 2769.839,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "company can take their eyes off of the",
      "offset": 2772,
      "duration": 6.319
    },
    {
      "lang": "en",
      "text": "evals for a period? And because every",
      "offset": 2775.359,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "minute you're spending on eval obviously",
      "offset": 2778.319,
      "duration": 3.121
    },
    {
      "lang": "en",
      "text": "a minute you're not spending talking to",
      "offset": 2779.76,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "customers or doing other kinds of",
      "offset": 2781.44,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "product work. So is this just like a",
      "offset": 2784.4,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "full-time job or is this like something",
      "offset": 2786.16,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "that you think PM should spend like x",
      "offset": 2788.88,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "percentage of their time doing? And",
      "offset": 2790.88,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "yeah, like how does this play out?",
      "offset": 2792.48,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "because it sounds like it's never quite",
      "offset": 2794.64,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "done. I think it's like a muscle that we",
      "offset": 2796,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "now as PMs have to learn how to train",
      "offset": 2798.88,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "ourselves a little bit more on because",
      "offset": 2800.88,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "imagine we're literally we are literally",
      "offset": 2803.76,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "all doing a new activity that we weren't",
      "offset": 2805.68,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "doing in the past which is using AI",
      "offset": 2807.599,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "putting AI in our product and the",
      "offset": 2809.599,
      "duration": 4.961
    },
    {
      "lang": "en",
      "text": "stronger that we get at being able to",
      "offset": 2811.839,
      "duration": 5.681
    },
    {
      "lang": "en",
      "text": "measure that the performance of the AI",
      "offset": 2814.56,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "in the product the faster we'll be at",
      "offset": 2817.52,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "iterating the probably the less time you",
      "offset": 2818.96,
      "duration": 5.159
    },
    {
      "lang": "en",
      "text": "have to spend on evalu",
      "offset": 2820.56,
      "duration": 3.559
    },
    {
      "lang": "en",
      "text": "you you know that flags when things go",
      "offset": 2824.8,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "It's sort of like I would kind of view",
      "offset": 2826.4,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "this as like why does Oracle and",
      "offset": 2828.16,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "Salesforce and like these products exist",
      "offset": 2830.56,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "because those processes used to be",
      "offset": 2832.96,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "really cumbersome in the past, right?",
      "offset": 2834.96,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "Like customer relationship management or",
      "offset": 2836.64,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "being able to tag data and track data",
      "offset": 2839.52,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "all in one place or build dashboards and",
      "offset": 2841.92,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "now we almost take it for granted,",
      "offset": 2844.16,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "right? I can go in and just build a",
      "offset": 2845.52,
      "duration": 3.599
    },
    {
      "lang": "en",
      "text": "dashboard super quickly to look at my",
      "offset": 2847.2,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "users metrics or like session or",
      "offset": 2849.119,
      "duration": 3.361
    },
    {
      "lang": "en",
      "text": "analytics data. And so I don't have to",
      "offset": 2850.56,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "think about do I have all the data in",
      "offset": 2852.48,
      "duration": 3.119
    },
    {
      "lang": "en",
      "text": "the right place to do this. I can just",
      "offset": 2854,
      "duration": 3.599
    },
    {
      "lang": "en",
      "text": "load it up. I think eval start to look",
      "offset": 2855.599,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "more and more like that, which is when",
      "offset": 2857.599,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "you're making changes to your product,",
      "offset": 2859.599,
      "duration": 3.121
    },
    {
      "lang": "en",
      "text": "it's important to go back and revisit",
      "offset": 2861.2,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "the eval. When the eval rate is going",
      "offset": 2862.72,
      "duration": 5.84
    },
    {
      "lang": "en",
      "text": "down or declining and it doesn't match",
      "offset": 2866,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "the business metric, it's probably",
      "offset": 2868.56,
      "duration": 3.039
    },
    {
      "lang": "en",
      "text": "important to go and take a look at that",
      "offset": 2870.16,
      "duration": 3.199
    },
    {
      "lang": "en",
      "text": "just like you would any other metric.",
      "offset": 2871.599,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "So, that's how I how I view this world a",
      "offset": 2873.359,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "little bit. Yeah. Like I think the way I",
      "offset": 2875.28,
      "duration": 4.559
    },
    {
      "lang": "en",
      "text": "think about it is like eBalls are going",
      "offset": 2877.68,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "to become almost like customer success",
      "offset": 2879.839,
      "duration": 4.801
    },
    {
      "lang": "en",
      "text": "customer support tickets in a way. Every",
      "offset": 2882.64,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "now and then there's going to be a",
      "offset": 2884.64,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "customer support ticket that bubbles up",
      "offset": 2885.68,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "into your world, right? And depending on",
      "offset": 2887.68,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "what that message says, it's going to",
      "offset": 2890,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "maybe be like, okay, maybe I need to go",
      "offset": 2892,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "deeper here and really see if this is a",
      "offset": 2893.76,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "problem. Then maybe you get into Zenesk,",
      "offset": 2896,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "you start to like search for similar",
      "offset": 2897.839,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "patterns and then that's maybe like when",
      "offset": 2899.28,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "there's something interesting there.",
      "offset": 2901.839,
      "duration": 2.72
    },
    {
      "lang": "en",
      "text": "Yeah. Yeah. Or maybe you have a report",
      "offset": 2903.2,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "that says every time someone mentions a",
      "offset": 2904.559,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "feature that I'm responsible for, I can",
      "offset": 2906.48,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "go in and check like those tickets. So,",
      "offset": 2908.64,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "in a way, I just that's how I see it. or",
      "offset": 2910.72,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "you launch a new feature, like if you",
      "offset": 2912.64,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "launch a new AI AI capability, like to",
      "offset": 2914,
      "duration": 4.559
    },
    {
      "lang": "en",
      "text": "use the self-driving car analogy again,",
      "offset": 2916.48,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "the eval straight roads and left-hand",
      "offset": 2918.559,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "turns, like these might look really",
      "offset": 2921.2,
      "duration": 2.72
    },
    {
      "lang": "en",
      "text": "good, but you might want to go back and",
      "offset": 2922.319,
      "duration": 3.441
    },
    {
      "lang": "en",
      "text": "revisit if you're launching a new city",
      "offset": 2923.92,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "because maybe there's something new in",
      "offset": 2925.76,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "the data or there's some new geography",
      "offset": 2927.2,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "or you're launching a new product",
      "offset": 2929.44,
      "duration": 2.96
    },
    {
      "lang": "en",
      "text": "feature that you want to make sure that",
      "offset": 2930.88,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "the eval doesn't regress. So if somebody",
      "offset": 2932.4,
      "duration": 3.679
    },
    {
      "lang": "en",
      "text": "see what you're saying, if you want the",
      "offset": 2934.24,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "product to perform well in an",
      "offset": 2936.079,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "environment that has not been included",
      "offset": 2937.76,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "in its training data, then you should",
      "offset": 2939.92,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "assume it will not perform well. But as",
      "offset": 2942.4,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "long as it's performing in the same",
      "offset": 2944.48,
      "duration": 6.32
    },
    {
      "lang": "en",
      "text": "landscape as the training data, then it",
      "offset": 2946.8,
      "duration": 7.2
    },
    {
      "lang": "en",
      "text": "should Yeah, that's so interesting. Some",
      "offset": 2950.8,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "cities will literally have things that",
      "offset": 2954,
      "duration": 2.96
    },
    {
      "lang": "en",
      "text": "don't exist in data sets for other",
      "offset": 2955.52,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "cities and Right. Or or like user",
      "offset": 2956.96,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "behavior changes too, right? A really",
      "offset": 2959.359,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "common one is, you know, let's say I",
      "offset": 2961.52,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "work at Spotify or something like this.",
      "offset": 2963.359,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "The music that's popular this year is",
      "offset": 2965.359,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "never the same that's popular next year,",
      "offset": 2967.04,
      "duration": 3.279
    },
    {
      "lang": "en",
      "text": "but your agent should probably be",
      "offset": 2969.04,
      "duration": 3.039
    },
    {
      "lang": "en",
      "text": "adapting to that, right? The taste of",
      "offset": 2970.319,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "the agent should be adaptive to the",
      "offset": 2972.079,
      "duration": 5.121
    },
    {
      "lang": "en",
      "text": "taste or the trends that are in the real",
      "offset": 2975.359,
      "duration": 4.801
    },
    {
      "lang": "en",
      "text": "world. So, because data is dynamic and",
      "offset": 2977.2,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "the the world in which we live in is",
      "offset": 2980.16,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "dynamic and changing, it's good to have",
      "offset": 2981.68,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "a system that's robust to that change,",
      "offset": 2983.52,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "too. Yeah. Okay. So, I know we'll start",
      "offset": 2985.28,
      "duration": 5.039
    },
    {
      "lang": "en",
      "text": "wrapping up here in a couple minutes.",
      "offset": 2988.4,
      "duration": 3.679
    },
    {
      "lang": "en",
      "text": "The last question in my mind because I",
      "offset": 2990.319,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "we could easily spend two more hours on",
      "offset": 2992.079,
      "duration": 4.561
    },
    {
      "lang": "en",
      "text": "this is if someone's listening and",
      "offset": 2993.92,
      "duration": 4.639
    },
    {
      "lang": "en",
      "text": "they're like in an earlier stage",
      "offset": 2996.64,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "company. Okay. Do you have any advice",
      "offset": 2998.559,
      "duration": 4.961
    },
    {
      "lang": "en",
      "text": "that's different for operationalizing",
      "offset": 3001.04,
      "duration": 4.799
    },
    {
      "lang": "en",
      "text": "evals in early stage environments, early",
      "offset": 3003.52,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "stage companies versus like more mature",
      "offset": 3005.839,
      "duration": 5.121
    },
    {
      "lang": "en",
      "text": "like later stage companies? Yeah, I",
      "offset": 3008.16,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "think it's a good question. I mean, I",
      "offset": 3010.96,
      "duration": 5.119
    },
    {
      "lang": "en",
      "text": "think um earlier stage companies have",
      "offset": 3013.28,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "are probably trend closer towards the",
      "offset": 3016.079,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "vibe code like ship something quickly.",
      "offset": 3018.16,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "There's probably dimensions to like",
      "offset": 3020,
      "duration": 2.64
    },
    {
      "lang": "en",
      "text": "early stage companies to think about,",
      "offset": 3021.28,
      "duration": 2.799
    },
    {
      "lang": "en",
      "text": "too. If you're in a highly regulated",
      "offset": 3022.64,
      "duration": 3.439
    },
    {
      "lang": "en",
      "text": "industry, regardless if you're early",
      "offset": 3024.079,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "stage or not, you should probably have",
      "offset": 3026.079,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "metrics on if you're performing well in",
      "offset": 3028.079,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "that industry or that dimension like",
      "offset": 3030.16,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "healthcare or legal, things like that.",
      "offset": 3032,
      "duration": 4.559
    },
    {
      "lang": "en",
      "text": "So, I think the principles are largely",
      "offset": 3034.319,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "the same. It's just that you're again",
      "offset": 3036.559,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "you're like the variables the knobs that",
      "offset": 3039.119,
      "duration": 3.121
    },
    {
      "lang": "en",
      "text": "you have to turn are going to be",
      "offset": 3040.96,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "different. I'll give you one t tangible",
      "offset": 3042.24,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "example there. Larger companies larger",
      "offset": 3044.16,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "enterprises with more scale are going to",
      "offset": 3046.4,
      "duration": 3.439
    },
    {
      "lang": "en",
      "text": "be more costsensitive to picking the",
      "offset": 3048.079,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "right model for an eval. If you are like",
      "offset": 3049.839,
      "duration": 4.561
    },
    {
      "lang": "en",
      "text": "a large scale travel site or a",
      "offset": 3052.079,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "personalized product that's reaching a",
      "offset": 3054.4,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "billion users, you may not always be",
      "offset": 3055.92,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "able to today use the most capable model",
      "offset": 3058.319,
      "duration": 4.721
    },
    {
      "lang": "en",
      "text": "for evaluations or the longest context",
      "offset": 3060.64,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "window, right? you might need to tone",
      "offset": 3063.04,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "that down and just pick something that's",
      "offset": 3064.48,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "really efficient. But if you're at a",
      "offset": 3066.16,
      "duration": 3.199
    },
    {
      "lang": "en",
      "text": "smaller company that's trying to move",
      "offset": 3068,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "fast in legal or healthcare, you can",
      "offset": 3069.359,
      "duration": 4.801
    },
    {
      "lang": "en",
      "text": "probably afford to spend more time or",
      "offset": 3072,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "more capable model on evaluation. So the",
      "offset": 3074.16,
      "duration": 3.439
    },
    {
      "lang": "en",
      "text": "principles are the same and how you",
      "offset": 3076.24,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "think about the system, but the knobs",
      "offset": 3077.599,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "that you have and you want to turn those",
      "offset": 3079.28,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "might be very different. Yeah, I think",
      "offset": 3081.599,
      "duration": 5.121
    },
    {
      "lang": "en",
      "text": "cost is probably an important topic that",
      "offset": 3084.72,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "we didn't get to touch on. And but yeah",
      "offset": 3086.72,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "and I think there's of course the cost",
      "offset": 3089.04,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "of running the model and then like at",
      "offset": 3090.88,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "what scale what are other like maybe",
      "offset": 3093.92,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "like hidden costs right and I think",
      "offset": 3096.24,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "there's and maybe think about it like",
      "offset": 3097.839,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "the opportunity costs right like we",
      "offset": 3100.079,
      "duration": 3.441
    },
    {
      "lang": "en",
      "text": "almost touched on that there's if you",
      "offset": 3101.359,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "need some human label there's as you",
      "offset": 3103.52,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "know are training number of time you're",
      "offset": 3105.44,
      "duration": 2.56
    },
    {
      "lang": "en",
      "text": "going to have to spend reviewing that",
      "offset": 3107.04,
      "duration": 2.24
    },
    {
      "lang": "en",
      "text": "data. What are some other hidden costs",
      "offset": 3108,
      "duration": 2.96
    },
    {
      "lang": "en",
      "text": "that people should think about before",
      "offset": 3109.28,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "you build an AI feature that if you",
      "offset": 3110.96,
      "duration": 4.639
    },
    {
      "lang": "en",
      "text": "don't know enough about this topic,",
      "offset": 3113.68,
      "duration": 2.8
    },
    {
      "lang": "en",
      "text": "you're going to miss and then you're",
      "offset": 3115.599,
      "duration": 2.081
    },
    {
      "lang": "en",
      "text": "going to be, &quot;Oh [ __ ] maybe I should",
      "offset": 3116.48,
      "duration": 2.8
    },
    {
      "lang": "en",
      "text": "have thought about that before and maybe",
      "offset": 3117.68,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "I should have maybe done that cost and",
      "offset": 3119.28,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "benefit analysis beforehand, even going",
      "offset": 3121.52,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "down and going deep into this rabbit",
      "offset": 3123.76,
      "duration": 2.96
    },
    {
      "lang": "en",
      "text": "hole.&quot; Yeah. I'll actually bring it back",
      "offset": 3125.28,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "to the example you guys uh we started",
      "offset": 3126.72,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "this one with, right, which is you get",
      "offset": 3128.72,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "to the finish line with your prototype",
      "offset": 3130.24,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "and everyone loves it and they're your",
      "offset": 3132.24,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "town hall and you present this thing and",
      "offset": 3134.079,
      "duration": 2.801
    },
    {
      "lang": "en",
      "text": "it's working great as a prototype, but",
      "offset": 3135.68,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "then you try to ship it and it sucks,",
      "offset": 3136.88,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "right? So, you've invested all this time",
      "offset": 3138.8,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "up front in something that doesn't",
      "offset": 3140.72,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "scale. And the flip also goes with like",
      "offset": 3143.44,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "how much time you spend in evaluations",
      "offset": 3145.92,
      "duration": 3.679
    },
    {
      "lang": "en",
      "text": "and getting your data set up for",
      "offset": 3148,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "evaluations in the first place. So time",
      "offset": 3149.599,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "is a little bit of a cost on both",
      "offset": 3151.839,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "dimensions because you can get really",
      "offset": 3153.28,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "close to thinking that you're done and",
      "offset": 3156.079,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "then you got to go back to square one or",
      "offset": 3157.52,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "you can spend too much time trying to",
      "offset": 3159.599,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "set up eval in the first place. I think",
      "offset": 3161.04,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "picking a system that scales with you at",
      "offset": 3163.2,
      "duration": 4.639
    },
    {
      "lang": "en",
      "text": "the earliest stage is really an",
      "offset": 3165.76,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "important cost to think about because a",
      "offset": 3167.839,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "lot of people think eval is like what I",
      "offset": 3170.24,
      "duration": 3.359
    },
    {
      "lang": "en",
      "text": "need to get my product out in that last",
      "offset": 3172.079,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "mile and you're going to land up back at",
      "offset": 3173.599,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "square one. So thinking about eval as",
      "offset": 3175.599,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "part of your development process and as",
      "offset": 3177.44,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "part of your requirement so that you",
      "offset": 3179.92,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "actually have a benchmark you can ship",
      "offset": 3181.52,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "to words will save you a lot of pain",
      "offset": 3182.96,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "when you get to production because you",
      "offset": 3184.72,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "can use those same eval. So that's how I",
      "offset": 3186.16,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "think time is probably one of the most",
      "offset": 3188.96,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "probably the most expensive part of this",
      "offset": 3190.64,
      "duration": 2.479
    },
    {
      "lang": "en",
      "text": "whole thing at the end of the day when",
      "offset": 3192,
      "duration": 2.559
    },
    {
      "lang": "en",
      "text": "we're all trying to move fast. Yeah. And",
      "offset": 3193.119,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "social capital too, right? You promised",
      "offset": 3194.559,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "your board that you're going to do this",
      "offset": 3197.2,
      "duration": 2.48
    },
    {
      "lang": "en",
      "text": "and then all of a sudden you realize",
      "offset": 3198.48,
      "duration": 3.119
    },
    {
      "lang": "en",
      "text": "actually no I cannot do this. Right. Can",
      "offset": 3199.68,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "I give you a really tangible example of",
      "offset": 3201.599,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "that? Actually, I was listening to Craig",
      "offset": 3203.04,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "Federiki actually talking to the Wall",
      "offset": 3205.359,
      "duration": 3.361
    },
    {
      "lang": "en",
      "text": "Street Journal and it's this five-minute",
      "offset": 3207.2,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "clip this morning because everyone's",
      "offset": 3208.72,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "talking about WWDC and the reporter is",
      "offset": 3210.4,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "like, &quot;Craig, where's all the AI",
      "offset": 3212.96,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "features? Where's the new Siri that you",
      "offset": 3214.64,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "demoed last year that you said we were",
      "offset": 3217.04,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "going to have?&quot; And Craig's answer was,",
      "offset": 3218.559,
      "duration": 5.201
    },
    {
      "lang": "en",
      "text": "&quot;We got to a point where we thought it",
      "offset": 3221.76,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "was working really well internally, but",
      "offset": 3223.76,
      "duration": 2.799
    },
    {
      "lang": "en",
      "text": "when we actually tried it on more",
      "offset": 3225.2,
      "duration": 2.96
    },
    {
      "lang": "en",
      "text": "scenarios, it just wasn't reliable",
      "offset": 3226.559,
      "duration": 4.881
    },
    {
      "lang": "en",
      "text": "enough.&quot; So the takeaway from that is",
      "offset": 3228.16,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "Apple probably didn't have the right",
      "offset": 3231.44,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "eval in place and that's probably why",
      "offset": 3232.64,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "you don't have a new Siri right now. So",
      "offset": 3235.44,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "I'll give you a counterfactual there. I",
      "offset": 3237.52,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "think Apple needs their own Aman in",
      "offset": 3239.44,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "house or Arise you know at least some",
      "offset": 3241.839,
      "duration": 4.561
    },
    {
      "lang": "en",
      "text": "type of system in there to think about",
      "offset": 3244.88,
      "duration": 2.959
    },
    {
      "lang": "en",
      "text": "reliability early and and you know it",
      "offset": 3246.4,
      "duration": 2.959
    },
    {
      "lang": "en",
      "text": "could be that they were designing with",
      "offset": 3247.839,
      "duration": 2.961
    },
    {
      "lang": "en",
      "text": "reliability and the system is just",
      "offset": 3249.359,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "really complex and that is totally where",
      "offset": 3250.8,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "the world we're in right now as well.",
      "offset": 3253.119,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "But it does help you with a little bit",
      "offset": 3255.04,
      "duration": 3.519
    },
    {
      "lang": "en",
      "text": "of the heartburn of trying to like make",
      "offset": 3256.96,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "an announcement early before you're",
      "offset": 3258.559,
      "duration": 3.121
    },
    {
      "lang": "en",
      "text": "actually",
      "offset": 3260.16,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "uncle team doesn't want to spend money",
      "offset": 3261.68,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "on expensive models. Maybe that's that's",
      "offset": 3263.92,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "also part of the problem. The scale that",
      "offset": 3265.599,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "they're working with and also like",
      "offset": 3268,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "you're trying to evaluate basically you",
      "offset": 3269.119,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "build the operating system. You're",
      "offset": 3271.04,
      "duration": 2.319
    },
    {
      "lang": "en",
      "text": "trying to build something into the",
      "offset": 3272.319,
      "duration": 2.641
    },
    {
      "lang": "en",
      "text": "operating system that theoretically has",
      "offset": 3273.359,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "permissions to everything that you can",
      "offset": 3274.96,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "do on that device and in that machine.",
      "offset": 3277.04,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "And of course things are going to go I",
      "offset": 3278.72,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "don't know. We could spend again",
      "offset": 3280.48,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "probably three or four more hours",
      "offset": 3282.48,
      "duration": 2.72
    },
    {
      "lang": "en",
      "text": "talking about this. So, we'll have to",
      "offset": 3283.68,
      "duration": 2.96
    },
    {
      "lang": "en",
      "text": "have you back on. But just in closing,",
      "offset": 3285.2,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "Aman, like where can people learn more",
      "offset": 3286.64,
      "duration": 3.199
    },
    {
      "lang": "en",
      "text": "about what you're up to and then how",
      "offset": 3288.4,
      "duration": 2.56
    },
    {
      "lang": "en",
      "text": "could they potentially be helpful to",
      "offset": 3289.839,
      "duration": 3.041
    },
    {
      "lang": "en",
      "text": "you? Yeah, absolutely. And yeah, thanks",
      "offset": 3290.96,
      "duration": 3.119
    },
    {
      "lang": "en",
      "text": "again for having me, guys. This was a",
      "offset": 3292.88,
      "duration": 2.719
    },
    {
      "lang": "en",
      "text": "ton of fun. Amaya and I'm trying to be",
      "offset": 3294.079,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "as helpful as possible and try and give",
      "offset": 3295.599,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "away as much for free as possible to PMs",
      "offset": 3298,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "that this resonated with you, reach out.",
      "offset": 3299.68,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "Would love to learn more about what",
      "offset": 3301.68,
      "duration": 2.8
    },
    {
      "lang": "en",
      "text": "you're building. You can find me on",
      "offset": 3302.96,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "LinkedIn X. My website is also ammon.ai,",
      "offset": 3304.48,
      "duration": 5.839
    },
    {
      "lang": "en",
      "text": "so you can also just navigate to my",
      "offset": 3308.72,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "homepage and see what I'm up to. But",
      "offset": 3310.319,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "yeah, yeah, exactly. I I got I grabbed",
      "offset": 3312,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "the domain just in time. Would love to",
      "offset": 3314.64,
      "duration": 2.88
    },
    {
      "lang": "en",
      "text": "hear from you and see if I can be",
      "offset": 3316.24,
      "duration": 3.359
    },
    {
      "lang": "en",
      "text": "helpful. And my goal is to try to help",
      "offset": 3317.52,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "more PMs go from prototype to production",
      "offset": 3319.599,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "with AI with educational content and",
      "offset": 3321.76,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "tools to help them along that way. Yeah,",
      "offset": 3324.079,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "feel free to reach out.",
      "offset": 3326,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "Cool. Thanks for coming. Yeah. Yeah.",
      "offset": 3328.4,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "Thank you for letting us ask all the all",
      "offset": 3330.72,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "these stupid questions. Those are",
      "offset": 3332.64,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "questions. Great questions, actually.",
      "offset": 3335.119,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "Yeah. That's a wrap. All right. Thanks,",
      "offset": 3337.2,
      "duration": 3.9
    },
    {
      "lang": "en",
      "text": "guys.",
      "offset": 3340.079,
      "duration": 4.681
    },
    {
      "lang": "en",
      "text": "[Music]",
      "offset": 3341.1,
      "duration": 3.66
    }
  ],
  "cleanText": "Hey everyone, welcome to another episode of Supra Insider. Imagine launching your AI feature with confidence, knowing that it won't surprise you with unexpected results or harm your customer relationships.\n\nToo often, product teams push AI into products only to realize far too late that their AI systems aren't delivering reliable outcomes.\n\nToday, Ben and I talk with Aman Khan, who spent countless hours guiding product teams on how to implement AI features effectively through intentional evaluation processes.\n\nWe dive deep into practical steps that every PM can use today, right now. How to clearly define what good enough means for your AI, the difference between by coding and structure evaluation processes, and when each makes sense, and real examples of avoiding costly mistakes through systematic AI evaluation.\n\nIf your goal is to deliver AI products that users trust from day one, this conversation is a must listen. So, let's jump in.\n\nAll right, we're live. Aman, I am so excited you decided to join us. Thanks for being here. Excited to be here. Thank you guys for having me. I've been looking forward to this conversation all week. Oh, yeah. We have. We have as well. And I know you've been on the circuit between the Lenny Post, the podcast. We wanted to cover some new ground that you haven't really talked about in other places yet. If folks are interested in learning about some of the other stuff you've been thinking about, plenty of resources online that we'll link to also in the show notes. But today, Mark and I were talking about what would we really want to talk about. And what we're seeing is there's a lot of product managers, and we talked about this a little bit before hitting record that are getting pulled, sometimes kicking and screaming, sometimes just they're push they're doing the pushing. But like basically, how do we bring AI products? How do we bring AI experiences into our products? And often time there's some element of the AI does something based on inputs and there's some outputs and I and obviously like we want to make the outputs super good like we want the outputs to feel like really reliably solid even though it's leveraging AI that just is non-deterministic in a lot of ways and I think that you're spending so much of your time right now trying to educate the product world on how to set up their product development process so that their odds of getting the outputs to be really high quality and reliably what they want them to be is as high as possible and that's where the evaluations fit in. We want to talk about that process of how product managers should be thinking about this and just to get you started I'll throw out a scenario and I just want to hear feel free to start riffing on where you'd go with this scenario but imagine you're a product manager at a company right now it's got a lot of traction there's pressure from the executive team that people are excited we're going to build AI into our product they find a really killer use case for where they're going to put AI into their product experience and they're just assuming they're going to follow the traditional development process Right. So they're going to come up with what is it going to look like. Maybe they'll do some prototyping, vibe coding like you talk about get to a point where they're all aligned on like how we want AI to fit into the product and when and where and what a good result might look like and then they ship it and they start testing it in dev or in staging or whatever. Maybe sometimes on production behind a feature flag and they're like, man, this is it's not what it's not what it needs to be. It's not good enough. Have they missed the boat? Is that too late to think about eval scenario? It's a really good question. I think maybe it's helpful to zoom out and think about what product managers are doing when they're building products that have AI in them in the first place as well. What that workflow sort of looks like like how you've described and I almost want to double click a little bit on that scenario which is like how did the group come together to decide to put AI in the product? What's the goal? They're a little bit very PM thing to ask here, right? Like uh I'll give you an example. We have a customer one of the largest travel sites in the world and for context we work with companies that are have AI very core to their product. Think like product sweet and services we all use every single day and it's not just chat bots it's like actually sitting in the product helping you know their product make decisions. We had a customer that helps you book flights, helps you book hotels. And a couple of years ago, actually, when LLM really started taking off about a probably about a year ago, they came to us and they were like, \"Arize, we are so excited. We decided to put a chatbot in the product that you type in where you're going and it will just help you book flights and recommend where you want to go based on where you want to go, hotels, flights, activities that you can do.\" And it's going really great. People are like clicking through there. The metrics are moving up and people are using this product even more than they were before there was like actually AI in it. But the problem is that people keep trying to jailbreak it. They're like sending input queries. They're sending questions that we didn't think the LLM would the agent would actually try to answer. They're trying to get free flights. They're trying to figure out how to break this thing. And can you can you guys help us solve this problem? Figure out what's going on here. And the first question we asked actually when that happened was why did you decide to do this? Like we we thought fundamentally we thought that you're a product that's helping people book vacations or book for work. That should be a simple search query just like Google and you click through and a human is the one picking what they want to select their hotel to be or select their flights. And I think we had a fundamental misunderstanding of what the product was trying to solve. Like when we initially looked at this product, we thought, okay, it's building a a trip planner that helps you make decisions and book a trip for you. But what I think we were missing is that the LLM and the agent's goal is actually to build a trip planner for everyone, a personalized trip planner where you can have a conversation and figure out where you want to go. And I think that kind of comes back to what's the end goal here and figuring out what the the space for AI kind of looks like in the product kind of helps you understand when you need to start thinking about eval. So I don't actually I think that thinking about eval can be helpful when it comes to framing what the end goal is making sure you're hitting those goals but in many times we just you just need to have the right framing of the goal in the first place to know what to evaluate. So I think to to bend your scenario here, I view that as like maybe the goal was just to get AI and the product out quickly and that's okay. That doesn't mean that the goal here was to actually have a product that was fully reliable for all of your users. Those are two distinct goals when you're experimenting with this stuff. Let's actually anchor to that scenario you shared and just imagine that company never actually came to Arize and this was just like a hypothetical thought experiment. Okay, so we have a travel company. We want to build we want to build some kind of experience in the product that allows people instead of clicking around Google flight style or Expedia style into a conversational interface that feels something like talking to a travel planner like a human, right? And they're going to ask you whatever questions they need to ask and then they're going to give you options and they'll know your budget and all the things and then like at the end you'll be able to pull the trigger and or at least they'll give you exactly the actions you need to do. So, I'd say like my goal as a PM in that company might be I want to give people a conversational way to plan trips instead of having them have to click around. Let's just say that's the goal. And then maybe my assumption, yeah, like the end goal might be even like just just book more flights, right? Because maybe you make or make or move more hotels. So then because maybe you make money based on each transaction, maybe you take 10%, right? That could be like a business impact that I could imagine that company going after basically. Totally. So now I'm sitting down with my engineers and they're like, \"Cool.\" Like we've got like open AI models and we've got anthropic models and we could we've got all the structured data and we're going to build the data pipelines that put the right information in front of the right models and pair it with the right prompts and then we're going to get these outputs and then and then we'll just QA it. That's like the traditional happy path. That's a Yeah, I think um and probably what a lot of people do if they're not being intentional about the evals if I'm guessing. Totally. I think it's probably helpful to contextualize like where evouts sit in your traditional software development process and that's where what you're getting at right which is what's different about this world a little bit and may maybe it's helpful if we whiteboard some of this out and talk through what some of the common scenarios we see are where like eval start to matter versus where they might not really make a huge difference in your software development process. So, I'll actually I had some of this whiteboarded out as I was like thinking through this for a customer the other day and I'll maybe to come back to the just ship the thing like I kind of call this the vibe coding workflow which is a little bit of what you just described as well to some degree Ben which is your goal is actually just to put AI in the product and I that's why I've made it just like a single box on this workflow imagine that you're literally just figuring you've done all of your traditional software development you're building AI in the product you've vibe check the outputs. You make sure you know they look good or don't look good. You ship the thing. By the way, this story here of these three steps like I was watching an interview with the developers of Claude Code and some of the people at Cursor too and some of the most widely used AI tools today, they follow like vibe coding and vibe eval like it's just it feels good or it looks good. Just to interrupt for a sec, it I I want to make sure I'm understanding this so far. Am I understanding this correctly that what we're calling in the whiteboard that you're showing here as the vibe coding workflow is this basically traditional software development workflow? I would call it traditional software development with the reason it's like vibe coding is like you can just ship so much faster now. I don't have any representation for like database or AB tests or anything like that. like it's all of that traditional software development I'm compressing into the box in the far left which is just build the agent and product. So this is traditional software development up until this point. And then after you get the outputs, you can go ship a website and you can take a look at it and you know what that website is going to look like 100% of the time, right? Like when you build a static HTML asset or something like this or whatever the product might be where it's just static code, you know what it's going to look like. You write the code, it shows up. The difference in this world is that now based on what the input looks like when you change the input or you vary the input the outputs can look really different over time or an unexpected ways and that's because you actually have less control over the AI component of the product itself where the output can be nine times out of 10 it'll actually be different as opposed to 10 times out of 10 it's the same and that's what creates this experience where the product that you're building actually works For some users, maybe it's really hard to quantify how many users it's going to work for or how reliable it's going to be. And inevitably, you're going to have users complain if this is a real product, whether it's internal or external. This happens in traditional software development, too. You're going to have users complain about the UI, the UX, the snappiness of the product or the the website. But the difference here is that the way that users are complaining or what they're complaining about, this might be the CEO literally like DMing you as the PM and being like, \"Hey, what the hell's going on here?\" And they show you a screenshot and it's this makes no sense in the context of what I'm trying to do or this is completely wrong. Fix it. Totally. Yeah. And you can try to snap it to do something super fixed as well, which is interesting. Like even in that world, it's like you could have, let's imagine that this agent is only meant to book flights from San Francisco to New York. you type an input query and say book me a flight from San Francisco to New York this day this time you're still going to have this quality kind of component that's going to be a variable now because of the non-deterministic nature of LLM no matter how much you try to constrain the system and use function calling and these tools to make it more deterministic there you're now inserting some level of non-determinism in your code so that's just something to keep in mind because if you decide to change the model change the prompt change some API call change the input. There's just so many things that can cause the output now to be not what it used to be in the traditional software world. So it so we're calling these like the by coding workflow and I'm sure the other one maybe it's like the more thoughtful like eval workflow whatever. I'm having a hard time like finding situations where the vibe coding workflow is a good idea for a established company that has like a reputation and trust right to me. Let's say I'm like a PM that works like a travel agency that has like millions of users, right? The fact that like I have some outcome that I cannot control that could erase my trust or and I guess it depend also I think maybe just a caveat here to mention is that it really depends on like the functionality and the use case but I think for example like for the booking flights right like the consequences of getting it wrong or charging the wrong amount in the card can like really just delete like insane amount of like lifetime value for a customer right so totally. when is it a good idea to do this by by coding workflow versus when is like maybe absolutely not like you should go to the other workflow I think that there's like the consumer application lens and then I'll actually bring it back to the claude code note a little bit here too which is they claim that they like just vibe coded claude code which is which actually started as an internal tool at anthropic to help them build better code I think that's the takeaway here for me was like this workflow makes sense if you plan on just trying to get to\n\n\nThe end point of shipping AI in your product as fast as possible, and you're maybe not going to release it to a bunch of users. If your goal is to release it internally and test it and figure out where things break, uh, prototyping is another great example. I think those are the situations: internal tools, prototyping, low stakes, low stakes. Yeah. Yeah, or if you are a startup and you're zero to one, and you're just trying to go as fast as possible, and you're willing to take on some more risk, like this could make sense. But just know that the expected value and like return here can be really tilted as soon as you have someone trying to break your system there. This actually happened pretty publicly not too long ago where people were using tools like Lovable and Bolt and some others like Vzero as well. And there's issues like leaking secrets or having like leaky best practices, engineering practices that make their way out into the open, and that's that can be really unsafe for a real business or enterprise. So, if you're just getting started on a weekend project, go, I love vibe coding. Go do it. If you're actually trying to build something and release it to real users that are paying for it, you probably want to at least try to write an eval on top of that. And the one thing that I'll add there too that I just like, I think the, as you were saying, okay, like one use case for the vibe coding workflow is, as you said, like that weekend hacking project, but I think another use case that I've seen for the vibe coding is, hey, like my board or the exact team, like pressures me to, hey, I need you to find a solution how to implement AI. You go build this demo that, let's say, gets it right like 70% of the time, but then they're like, oh, this is amazing, like we just need to get it to 95%. But I think the problem is that, like, you, you didn't go, a lot of people don't actually really know, okay, like what is that, that holistic process that you need to do in order to do that, and I think that's also the risky part of it, that you just don't know what you don't know, and that part is actually, which I'm sure we'll cover in a little bit, like a lot longer, and there's a lot of more ins and outs that you need to inform and educate those stakeholders about. Yeah. And a good question to ask if you're, if you, if this relates to you and in your day-to-day as you're building AI products is, like, how good is good enough, and how do you know what that is, and is, are all of your stakeholders on board with, you know, what good looks like, which is why it's helpful to quantify some of this stuff as well. That's why it's helpful to have a metric or a score that you're looking at that goes beyond just like vibes. So it's, it kind of gets to your point of, does your board know what good even looks like, or your, your board should trust you, or your, your leadership team should trust you as the PM, whoever the pressure is coming from, like, whoever is responsible for driving the user experience into which AI is embedded, should be responsible for defining what quality is. And I think what's challenging in this case, cuz I've spent countless hours in the past putting up like testing scenarios for like deterministic software, traditional software, and even that you've got like something that's pretty straightforward, has 20 potential paths that it could go, right? And I think trying to come up with what is good enough for your implementation of AI feels like an unanswerable question on its surface for a lot of people because the surface area of where it could go feels so overwhelming because it's only limited by the bounds of natural conversation. If natural conversation can go there, the product can go there too. And I think it's, it's like you can try to restrict certain workflows as well. While I was reading this tweet this morning, like even in cloud code, you can add rules to what the coding agent should be able to do, not, not be able to remove certain files from a directory or from your root folder. And the agent can find ways to work around that. It's crazy. It's like you put it in a box, but it'll find ways out of the box, too. So, that's what creates a little bit of this, like, just be really careful what you're measuring in the first place. Yeah. Actually, I would love to maybe double click on that question, like what is good enough, and like how should people think about good, because I think there's like, I, I know it's a big question, but I know there's also like, I think there's an 80/20 here, right? Like maybe it's accuracy is one of them, right? I'm sure like latency is one of them as well, right? Of like trade-off of like accuracy versus like how quickly you get answers. There's tone, like you want the right tone or the right branding if you're a brand sensitive company, and you want it to behave in a way that's aligned with your brand. Yeah. There's also like maybe the risks on the guard rails, right? Of like how likely are we not to hit one of these like terrible scenarios that we need to avoid. Verbosity, maybe like how many words do you use to say what you're trying to say, kind of thing that you want to be. I'm sure you've thought about this like a million, million times more than we have. But no, I mean that it's, I think that those are all like extremely legitimate types of eval or metrics that you should look at. At the end of the day, the eval are like the metrics that you care about for your AI product to some degree. And it's a, I got asked this question yesterday. How many eval are good enough? Like, aside from like quality, it's okay, now let's get more tactical, right? They're like, okay, fine. We'll talk about quality, but just explain it to us in the form of eval, like how many eval should I have? Because I think that there's 50 dimensions or 100 dimensions that we care about. And my answer to that is that might just be true. Like, depending on the complexity of your product, you might care more about certain eval depending on the scenario. I think it's helpful to have another product framing to mind as well here, which is if you've taken a Whimo or a self-driving car, it turns out there's a lot of similarities between the LLM agents that people are using today and what self-driving cars look like. I'll give you like a quick 30 second example there of, I used to work at a company called Cruz on the eval side, actually working on frameworks for evaluations, and when I joined the company, the car could barely drive down a single block without a human having to take over, and then eventually the car got really good at driving straight and making doing traffic lights correctly and all that, and then the car would try to make a left-hand turn and the human would have to take over again. And eventually what we did was we built a test set, a data set of what we called left-hand turn scenarios. And we kept iterating on the code on that left-hand turn scenario benchmark. And we had ways to score, is this a good left-hand turn or not. And then eventually the car was excellent at making left-hand turns, except when there was a pedestrian in the sidewalk trying to cross the street. And so what we had to do is build another data set of left-hand turns with a pedestrian in the sidewalk trying to cross the street. And then we kept iterating on that. And that process is eventually what gets you to a system that is more and more reliable for more and more scenarios. And that's why eval are not like a one-and-done. Let's just pick the dimensions and ship the thing. It's really this like iterative process where you get data from the real world and use it to keep iterating on your core product. Can you connect what you just said to the concept of labeling? Yeah, absolutely. Yeah. No, please go ahead. Maybe also what were there too, like how, what is an EVA? How, what is the definition of an eval? Is it just like one variable that you're measuring? Yeah. When you're referring to EVs, I, cuz I think the labels are a critical part of the concept for evals, right? Because like the eval is almost like a way that you end up comparing like the, the human label versus like the machine generated label. Exactly. Yeah. So I think we can pick, actually it's probably helpful to be just thinking about the whiteboard a little bit more, like what ends up happening is we're kind of at phase two of that initial vibecoded workflow, right? Like now we're like, hey, maybe we should write an eval for this product before we actually go ship it, and the very next question that comes up usually in these teams is, can we trust what this eval label is? And let's take an example, by the way, sorry, I'm super sorry to interrupt you, but just to finish the previous story when you said that they said we have like 50 things that we care about, is that 50 eval? Your answer was yes. It might be 50 eval. It just might not be running on all of your data all of the time. Like you might have pick one eval for one scenario, and that's one out of a 100 or a thousand. But it's really important to run an eval for that one scenario. It's a left-hand turn use case. You don't need to run your left-hand turn pedestrian eval for all the driving scenarios. It's only when you're making changes to that part of the stack necessarily. God. Okay. Thank you. Yeah. Keep going. Yeah. So think of this as like these things are, are really linked. Actually, both you guys, Mark and Ben, have alluded to this. There's a system here when we talk about writing an eval, like why do we keep using that term, write an eval? It's because it is natural language. Right now when people think about evaluding, there's three that come up. It's like human labels on the product output itself. There's code-based evaluation, which is like maybe just a Python string check or something like that. But the vast majority of evals that scale really well that people are looking at are what's called LLM as a judge eval, which are basically using another model or language model to grade the output of the first language model. And the reason that works is because when you write the eval, you're writing a block of text where you're setting the role, giving the LLM as a judge context and giving examples for what's good and what's bad in the prompt itself. So for example, you mentioned a couple actually. I'll just pick a couple that you guys mentioned: verbosity, tone. Let's pick tone for example, a really common one. Is the tone of the agent helpful or not helpful? And if I take a look at a text, if I take a look at what chat GPT says on the output, like I can determine, I can feel like the answer is either helpful or not helpful, right? And it's because in the case of chat GPT, it's been aligned to be a helpful bot. It's literally in the system prompt is like, you are a helpful agent. But you can do things and make it more like you're a comedian or you're funny, or we want you to respond like a Gen Z type of persona. And you might have an eval against that because what you're trying to do is compare, is what would a human look at this output and grade this as good or bad based on this sounds like a Gen Z person or not. And then can you basically model that into an LLM as a judge in the first place? So there's three components of that. There's the eval prompt, there's the text which is setting the context, setting the role of the LLM as a judge, giving some examples. There's the LLM itself that you want to select, which is maybe it's a GPT4 or whatever off-the-shelf model you want. You can pick it based on cost, performance, latency. And then there's the data that you're using to align the output. So that data is human label data, real world data that you're using to align the LLM as a judge output in the first place. So this is what when you talk about labels, this is usually what that means, that that data box. So if the eval prompt includes what are the examples of like good versus not good, then the difference between those examples and what goes into the data prompt is what? Can you clarify that part? Yeah, there, so this, I kind of made a little bit of an assumption here of what goes into an eval system. There's three high-level things. There's the eval prompt, there's the LLM, and then there's the data. The data. There's actually a bit of a split here of like, in, and this will map for some people in the ML data sciency world. There's training data and then there's production data. And so there's actually two types of data. The data where humans are, and humans label both of these actually. They label the training or alignment data that's used to make the LLM as a judge good in the first place. And then as you go into production, as you actually have this LM as a judge, grading outputs in the real world, you still want to take a look at that data constantly and make sure that there's at least some type of human feedback, making sure that the judge is still aligned based on real world scenarios. So there's kind of two types of data there. There's the initial label data which you're going to use to create the judge, and then there's real world data which is this, the system actually, your users actually interacting with the product and an eval scoring the outputs of that as well.\nIf you're enjoying this conversation, please check out the links in the show notes to support the podcast. Mark and I do this out of love, but to keep it going, we also need your support. Thanks. And now back to the episode.\nAnd when we talk about humans evaluating like the training data side of this, when we talk about the humans that are involved in labeling or evaluating, are we talking about outsourced? Is this like outsourced humans and company companies like Scale AI that are like investing massively in that infrastructure for Yeah. Or could it be like the PM too, right? Totally. Yeah. Yeah. So, I can maybe actually I'll kind of throw out this, this idea here, and I'd love to hear your guys' take. I think that the eval prompt and LLM selection is really important for the PM to be a part of that process and work with their AI engineer on those two things. But I actually think probably one of the most important parts of the system is the data itself. And it's almost like a little bit of a hot potato of who's, whose job is it to label the data. The thing is, it's really important to get that data right because what ends up happening is you might have, whether it's a PM or a subject matter expert. I actually think this comes back to an earlier point you guys said, which is who's responsible if the LLM as a judge or the eval is not good? Is it the PM's responsibility or is it the AI engineer responsibility or the, the subject matter expert here? But I think\n\n\nThat picking the right person to label data in the case of medical data, for example, or legal data, it's probably not going to be the product manager.\nThey might need to outsource that to a specific human or a subject matter expert.\nBut in the case of something like a trip planner, like you could collaborate with this with a travel agent if you're the product manager and make sure that this AI travel agent is actually good or bad.\nSo I think you want the PM should at least be in the loop there of who's labeling the data in the first place.\nSo in the context of the trip planning, just I'm sorry, I'm just like trying to still grasp this.\nSo let's say there's a trip planning thread and there's there ends up being something like 50 messages back and forth, like 25 from the person, 25 from the LLM.\nOkay, when the so two questions I'm trying to understand is one, what does the data set look like that needs to be that needs that gets fed into the judge in this scenario?\nIf I'm asking the wrong question, feel free to steer me towards asking the right question on that.\nAnd then the second thing I just wanted to ask is like when it comes to the eval, the evaluations themselves, is like every single message being scrutinized, or is like the atomic unit of scrutiny something different than like an individual output from the LLM?\nIs it the input plus output plus context or something that's being like based on this context and this input?\nHow does this output stack up?\nIs that basically what's going on?\nOkay.\nCould I actually double click on your first question when you say what would that scenario be?\nSo that would be like you mentioned like 50 or 25 examples, like what does that look like in your world?\nIt's one user chatting with this LLM travel agent that's AI, right?\nSo I'm like I come in and I'm like my first question is like I'm planning a trip to Paris and it's like cool, like tell me more about your trip.\nSo that that would be like one message from me and one message from the LLM when I I'm going with my two kids and we're planning on staying for four nights and here's our budget per night.\nSo that's like the third message in that thread and then it comes back to me with a response which would be the fourth message in the thread.\nSo that's what I mean is like if there's like a whole chat thread between the human and the LLM and it's like a total of 50 total messages.\nI'm just wondering what's the unit of data that is being evaluated from an eval perspective.\nIs it like the whole chat or is it like a specific response?\nYeah.\nYeah.\nIs it like the output of like, hey, like we've planned the trip and we have the tickets or is it more of a how did you react to every single question and piece of information?\nIt's almost like what is the Yeah.\nWhere is the granularity that you're doing eval basically?\nYeah.\nI actually think this might look, I don't know, as we're talking about it, this is sort of a visual that came to mind, which is this kind of looks like an eval funnel to some degree, and I think like PM's all funnel.\nSo I'll just use the the funnel analogy here a little bit.\nThere's basically a hierarchy of the sort of objects in the system, and at the top level you have the overall session or maybe the user, which is like, is this user having a good experience, or is the individual back and forth you might be having like a customer support bot or a trip planner, is this good or bad, like you can evaluate that at an aggregate level, thumbs up, thumbs down, did this customer have their question answered, they book a trip, you have some real world metric you can tie that back to.\nSo that's how I would think about that first one.\nOne plug here that I just want to make is that's kind of like the importance of like really thinking about what's the goal that we're trying to accomplish here because I think it sounds like that makes it a lot easier.\nHey, did we accomplish our original goal?\nWhich maybe was like, hey, did we get this person booked to for their trip or did we answer the questions or it could Yeah, it could be the business metric or it could be like the user goal or something like that, cuz cuz if I'm overall satisfied with the session even though there was a couple messages in it that felt unsatisfactory, then the overall session gets a thumbs up.\nBut I think where you're going with this is that there could be components of that section or subsets of that session that maybe did not pass.\nIs that kind of exactly that's exactly where where things are going here and there's also like a little bit of nuance to thumbs up, thumbs down by the way, because you can in this example, like a very common example is a customer support agent might give the right answer to something, no, you're not eligible for a refund, but are you going to give that chatbot a thumbs up or a thumbs down in that example, right?\nAnd so even defining who decides whether or not the agent did the right thing at the session requires a little bit of like nuance.\nYou can't just rely on your end user.\nThat sounds like an important decision actually.\nLike it's a really important decision cuz if you get that wrong, then your entire northstar for success for the product could be completely exactly out of whack.\nExactly.\nIf you try to optimize for thumbs up and your customer support agent, you might be giving away a lot more money than you expected to.\nSo just kind of keep that in mind.\nAnd then as you go down, let's say that's actually I think that's a good example.\nLet's pick an example where your end user gave you a thumbs down because they didn't get a refund when they expected one or they wanted one.\nBut if you take a look at the the transcript or the chat back and forth, like the subject matter expert gave the agent a thumbs up because it answered the questions correctly and did all the right things.\nThere's levels to that where you might need to go to make sure and verify that's the case.\nSo you can do things like verifying is the right data in place.\nSo you mentioned context.\nSo you might do something like a context or data eval, which is does is is the right areas of our knowledge base being retrieved?\nAre we getting the right data back from this user?\nYou can double check those things.\nSo that's something important, which is is there the right context?\nSo basically the refund example, if they give a thumbs down because they're not happy with the fact they didn't get the refund and then turns out that the LLM a that the chat agent actually maybe there was like a nuance like the terms and conditions or something that said that in the scenario in this particular scenario that this customer is in there actually should be a refund.\nExactly.\nSo in this case, like we would give a thumbs down because it like missed like it got something inaccurate or there was a wrong literally like wrong data or wrong context being brought to the decision, right?\nWas the right data or context there?\nRight?\nLike that's really important to verify.\nDid we even get the right data or context?\nWhat's interesting is if you go a little bit deeper, you can also do what's called a hallucination eval, very common evaluation in the case of like retrieval, which is even if you have the right data in place, did the LLM use the data correctly?\nAnd this was like if you put this into your prompt, does the LLM use the data?\nAnd even if you have the right data in the prompt in the first place and that's called like a hallucination email.\nAnd so in in the example where there there was like something in the terms of service that said that this customer should get a refund, would the hallucination be about the LL like the chat agent telling the customer that they're not eligible for a refund?\nYeah.\nIs that a hallucination or is that more Exactly.\nYeah.\nSo like in the case where the in in that exact scenario, it'd be like, \"Yeah, we fetched the terms of service, we have the right data in place, but for some reason the LLM was peeved because the person was being rude to it and it decided, no, you're not eligible for a refund because you're being rude to me.\"\nLike that that totally can happen, right?\nIt's like sort of like a human being upset in a scenario as well.\nYeah.\nThe thing that I want to clarify is Yeah.\nIt's like there's a difference between hallucination but also like actually a failure in retrieval.\nYou might have the right file, but you actually like your retrieval model or whatever is not as good and then you missed this nuance.\nAnd that's not necessarily a hallucination.\nThat's more of your retrieval wasn't as good as you thought it was and then you just missed it basically.\nTotally.\nAre the systems like this is so interesting if in the scenario that we're just playing with where there was something in the terms of and conditions about this user deserving the refund and the machine says you don't get it.\nYou're not eligible.\nSo that's a hallucination.\nDo we now have is the system that like Arize AI is building or the eval systems such that they will like literally tell you the reason that that that it said you don't get a refund, whether it's because of the hallucination or because it didn't have the right data?\nYeah.\nExactly.\nAnd that's a that's what we call an explanation in the eval world a little bit.\nAnd I can kind of show an example of that just really quick and we'll talk it out loud as well.\nLet's say this is actually an agent we built like a rag agent on our own docs and you and what we're looking at is basically examples where the chat agent or document agent gave answers and whether or not they were correct based on an evaluation using human labels, but then also hallucination, which is was the context used correctly, and what's interesting is you can see the LLM as a judge might read the context and the prompt is actually says take a look at the reference text, take a look at the LLM's output and input and see did the context get used correctly or not.\nAnd the explanation can say although the answer sounds really good, it said here's reasons why it sounds like it could be correct, it's actually referencing the document incorrectly or maybe misinterpreting parts of the doc.\nSo you can actually it's really important to get explanations on your eval so that you as a human can decide whether you trust the LLM as a judge in the first place or not.\nYeah, I think Sel where my head is going right now and by the way, let me know if this is getting too in the weeds, but when you're looking at evals and to me it feels like it's easy to explore like the ones that they get wrong almost cuz you're like okay, this is obviously is the wrong answer because I know that this is, but I think the dangerous ones, I'm not sure if the right term is like false positives, but like where it actually or actually it's actually not false positive, but let's say for example, like it actually gives that person the refund, but it gives the refund because it hallucinated, right?\nYeah.\nAnd even though the top level is correct, I guess my concern would be like we dismiss it because oh, you got it right.\nI don't really and you could just move.\nWouldn't that be the session getting a thumbs down from a business metric perspective?\nWell, like in other words, if a refund was issued in that session and it shouldn't have, then doesn't that mean that whoever is evaluating the quality of that session would give it a thumbs down at the session level?\nYou would probably need a human in the loop there though verifying the output in that case.\nYeah.\nOr wouldn't a human in the loop be assumed as in what we're talking about or is what we've been talking about in this funnel not assuming there's a human in the loop?\nExactly.\nSo the part of the reason why people gravitate towards these LLM as a judge is in back in the back in the old day, back in the old day of like credit card fraud or examples of like classification models, if things seemed fishy, you would have humans go in and label the data.\nBut in the case of chat bots or travel agents, there's just no way to label every single example and back and forth and context.\nAnd even in the case of the business metric, like there's a bit of a lag here between when you actually figure out whether or not the agent should have given a refund or not.\nAnd so it's really important to have systems in place that can check scalably.\nAnd that's why your human is perhaps in the loop, Ben, but it's not reviewing every session.\nYeah.\nNot every single session.\nExactly.\nSo, so to Mark's example, another version that comes to mind is like when insurance companies like pay out claims or something.\nIt's like almost the same thing is like someone asking for a refund and getting it is similar to someone filing a claim and getting paid out.\nYeah.\nAnd so my guess is you want to spot check a sample of all the claims that you approved.\nAnd then you probably want to also spot check a sampling of all of the refunds that you've granted and then look at the sessions that led to those refunds getting granted and what label them.\nThat's where maybe a human could label 20, 30, 40, 50 sessions over the course of like exactly, I don't know, a day maybe.\nAnd I think that kind of brings me to a little bit of how much data do you need?\nHow many human labels do you need?\nAnd it depends so much, like I'm hesitant to say how many, it depends so much on your circumstance, right, on your product.\nAnd I actually think that this is a good question for PMs to ask their team, which is what should our sampling rate be?\nHow often should humans be tagged to take a look at data for us to be okay with this type of system?\nAnd the short answer I can give is whatever you settle on, you might need to revisit that answer of your sampling rate.\nAnd so having, I'm biased, obviously, I work on a platform for this, but I do think that being able to have a system in place where you can see and adjust the sampling rate for humans and LLM as a judge going in and labeling data is really important so that you can make a decision and commit, but then come back and revisit if you need to as well.\nWhen should you revisit how often you're like how you sample data?\nLike is there any like event you should be looking for that's is it like a model change?\nIs it Yeah.\nYeah.\nI think that there's a couple of events that can help you track this.\nSo let's say you pick a sampling rate for humans to go in and label on top of the LLM as a judge and you're actually comparing because you have an L.\nLet's imagine in this chatbot use case, you have LLM as a judge on the critical components, right?\nYou might not need tone evaluated every single time, but in cases where the user was unhappy, you might want to take a look at tone.\nSo that might be like 1% or 5% of cases or something like that.\nBut on top of that, you need another sampling rate of humans going in and labeling the data.\nAnd what's important is to see what's the rate where if a human looks at that example\n\n\nOr that step.\nAnd it disagrees with the LLM as a judge, why is that happening?\nSo if you have a subject matter expert disagreeing with the LLM as a judge, those are examples you want to take a closer look at, and then you can track the rate of that matching.\nWe call it a match rate.\nAnd if your match rate is going above a threshold that you're comfortable with, might just be a couple of percent, five or 10%, something like that might be a good time to go back and revisit.\nHey, we need to iterate on this judge, or we need to iterate on the model, or something else.\nMakes sense.\nYeah.\nWas basically like you need as part of a quality, like in the beginning, you be like, okay, like we're okay with a 5% like disagreement between the human and the judge, and if in one of your samplings you start to see consistency, actually we're at seven or 10%.\nThat's maybe when you like need to go back to the board and be like, okay, maybe we need to change the way we write evals, or maybe we need to change how this product is operating, and then you go through that process again until you're like in that range that you want to be at.\nAnother way to think about this is like you have multiple knobs at your disposal as a PM, right?\nYou have the model, you have the prompt, you have your data labeling, and you can tune these knobs to try to get you to the right business outcome at the end of the day.\nAnd that's a, I'll bring that to like the third point that comes up for me quite a bit, which is aside from how many labels are good enough, what's our sampling rate?\nAnd the second one is what happens when the eval doesn't match the human, how often should we go back and revisit those knobs?\nBut then the third is what happens if the business metric goes down, but the eval is good.\nAnd that's again, like who's accountable in that case and who's responsible to go in and do a deeper dive.\nAnd coming back to like where we started here a little bit.\nLike that's where collaborating between an AI PM and an AI engineer is so important because the AI engineer is inherently going to be motivated and intrinsically motivated to make the eval good, but the PM is the person that's ultimately responsible for the business metric.\nAnd so you can't really get away from the fact where there's going to be circumstances where the eval looks really good, but the business metric still goes down.\nAnd how do you reconcile that is a really important discussion to have in a team, just like from a very, it's very easy to say this as someone who's like not invested in this like fictional situation, but like in my point of view, if the eval is great and the business metric is not good, you got to un ship that puppy like ASAP, right?\nOr or like sounds like the spec was off, right?\nIf we build something because we wanted to move something that's critical, and it's not only not moving it, but hurting it, right?\nIs there, what's the point of keeping that around?\nAnd I, and is, is what you're getting at that there's just so much investment and sunk cost fallacy there that that is just people struggle to like make that decision, or am I missing something there?\nIt's actually comes back a little bit to the we have 50 eval.\nWe have 100 eval.\nBut are you looking, even if you have eval?\nAre you looking at the right things at the right time is one, one example of that, right?\nIf you're hyperfixating on the LLM being helpful, but it's being a pushover.\nIt's the agent is being pushed over by a customer.\nThat might be something to revisit.\nDo you have the right, you know, this is the unknown unknowns kind of territory a little bit, like that that real businesses have all the time.\nLike you might design your PRD, you might design your product with EV valves in mind even from the beginning, and you ship the thing and you're measuring eval, but the business metric might still go down, and it could just be we're just you just started off measuring the wrong thing, or you're missing something in in your story.\nAnd I guess one, one more question there.\nSo I guess maybe like the right question is at what point is it worth iterating on kind of maybe using different evals or just evolving things differently or versus just maybe okay, letting go of that feature, be hey, we tried, didn't move the needle.\nYeah, how do you think between those two things, right?\nYeah, and feel free to hop in as well, Ben, if you had a thought there, but I kind of figured this is like what the story actually looks like when you do eval, right?\nAnd I have this as like workflow number three, right?\nSo workflow un vibe coding.\nWhere does that fit into your workflow?\nWorkflow 2, eval ship the thing with eval, but there's still problems.\nI think workflow 3 is like eval sitting in development and production, and you're using eval to make decisions.\nAnd in this case, you're building an agent product or an agent or an AI product.\nThe eval iterate in development before you even run your AB tests.\nSo you have eval, like eval are the PRD to some degree.\nYou're measuring your performance against those eval development and using internal data or subject matter experts to grade the outputs.\nAnd when it looks good, when everyone's on the same page, your stakeholders, your engineers, your team are aligned, you ship the thing.\nAnd the product should at that point model the real world enough for it to be some, some degree of reliability more than an eval that's not aligned or the vibe coding case.\nBut you're still going to have users complain.\nLike at the end of the day, any product if you actually have reach is going to have users that complain or that the things are going to go wrong.\nAnd in those cases, it's really important to just have a system to look at your data and iterate.\nAnd that's I think the real moral of the story is like you can have everything set up from the get-go correctly, but there's still going to be times when things go wrong.\nAnd so being able to have a system to iterate on the eval in the first place is really important.\nIs this, is there ever a world where the PM, the or the engineer or anyone at the company can take their eyes off of the evals for a period?\nAnd because every minute you're spending on eval, obviously a minute you're not spending talking to customers or doing other kinds of product work.\nSo is this just like a full-time job, or is this like something that you think PM should spend like x percentage of their time doing?\nAnd yeah, like how does this play out?\nBecause it sounds like it's never quite done.\nI think it's like a muscle that we now as PMs have to learn how to train ourselves a little bit more on because imagine we're literally, we are literally all doing a new activity that we weren't doing in the past, which is using AI, putting AI in our product, and the stronger that we get at being able to measure that the performance of the AI in the product, the faster we'll be at iterating, the probably the less time you have to spend on evalu, you, you know that flags when things go.\nIt's sort of like I would kind of view this as like why does Oracle and Salesforce and like these products exist because those processes used to be really cumbersome in the past, right?\nLike customer relationship management or being able to tag data and track data all in one place or build dashboards, and now we almost take it for granted, right?\nI can go in and just build a dashboard super quickly to look at my users metrics or like session or analytics data.\nAnd so I don't have to think about do I have all the data in the right place to do this.\nI can just load it up.\nI think eval start to look more and more like that, which is when you're making changes to your product, it's important to go back and revisit the eval.\nWhen the eval rate is going down or declining and it doesn't match the business metric, it's probably important to go and take a look at that, just like you would any other metric.\nSo, that's how I, how I view this world a little bit.\nYeah.\nLike I think the way I think about it is like eBalls are going to become almost like customer success, customer support tickets in a way.\nEvery now and then there's going to be a customer support ticket that bubbles up into your world, right?\nAnd depending on what that message says, it's going to maybe be like, okay, maybe I need to go deeper here and really see if this is a problem.\nThen maybe you get into Zenesk, you start to like search for similar patterns, and then that's maybe like when there's something interesting there.\nYeah.\nYeah.\nOr maybe you have a report that says every time someone mentions a feature that I'm responsible for, I can go in and check like those tickets.\nSo, in a way, I just that's how I see it.\nOr you launch a new feature, like if you launch a new AI AI capability, like to use the self-driving car analogy again, the eval straight roads and left-hand turns, like these might look really good, but you might want to go back and revisit if you're launching a new city because maybe there's something new in the data or there's some new geography, or you're launching a new product feature that you want to make sure that the eval doesn't regress.\nSo if somebody see what you're saying, if you want the product to perform well in an environment that has not been included in its training data, then you should assume it will not perform well.\nBut as long as it's performing in the same landscape as the training data, then it should.\nYeah, that's so interesting.\nSome cities will literally have things that don't exist in data sets for other cities and Right.\nOr or like user behavior changes too, right?\nA really common one is, you know, let's say I work at Spotify or something like this.\nThe music that's popular this year is never the same that's popular next year, but your agent should probably be adapting to that, right?\nThe taste of the agent should be adaptive to the taste or the trends that are in the real world.\nSo, because data is dynamic and the the world in which we live in is dynamic and changing, it's good to have a system that's robust to that change, too.\nYeah.\nOkay.\nSo, I know we'll start wrapping up here in a couple minutes.\nThe last question in my mind because I, we could easily spend two more hours on this is if someone's listening and they're like in an earlier stage company.\nOkay.\nDo you have any advice that's different for operationalizing evals in early stage environments, early stage companies versus like more mature, like later stage companies?\nYeah, I think it's a good question.\nI mean, I think um earlier stage companies have are probably trend closer towards the vibe code, like ship something quickly.\nThere's probably dimensions to like early stage companies to think about, too.\nIf you're in a highly regulated industry, regardless if you're early stage or not, you should probably have metrics on if you're performing well in that industry or that dimension, like healthcare or legal, things like that.\nSo, I think the principles are largely the same.\nIt's just that you're again, you're like the variables, the knobs that you have to turn are going to be different.\nI'll give you one t tangible example there.\nLarger companies, larger enterprises with more scale are going to be more cost sensitive to picking the right model for an eval.\nIf you are like a large scale travel site or a personalized product that's reaching a billion users, you may not always be able to today use the most capable model for evaluations or the longest context window, right?\nYou might need to tone that down and just pick something that's really efficient.\nBut if you're at a smaller company that's trying to move fast in legal or healthcare, you can probably afford to spend more time or more capable model on evaluation.\nSo the principles are the same and how you think about the system, but the knobs that you have and you want to turn those might be very different.\nYeah, I think cost is probably an important topic that we didn't get to touch on.\nAnd but yeah, and I think there's of course the cost of running the model, and then like at what scale, what are other like maybe like hidden costs, right?\nAnd I think there's and maybe think about it like the opportunity costs, right?\nLike we almost touched on that there's if you need some human label, there's as you know, are training number of time you're going to have to spend reviewing that data.\nWhat are some other hidden costs that people should think about before you build an AI feature that if you don't know enough about this topic, you're going to miss, and then you're going to be, \"Oh [ __ ] maybe I should have thought about that before, and maybe I should have maybe done that cost and benefit analysis beforehand, even going down and going deep into this rabbit hole.\"\nYeah.\nI'll actually bring it back to the example you guys uh we started this one with, right, which is you get to the finish line with your prototype and everyone loves it and they're your town hall and you present this thing and it's working great as a prototype, but then you try to ship it and it sucks, right?\nSo, you've invested all this time up front in something that doesn't scale.\nAnd the flip also goes with like how much time you spend in evaluations and getting your data set up for evaluations in the first place.\nSo time is a little bit of a cost on both dimensions because you can get really close to thinking that you're done and then you got to go back to square one, or you can spend too much time trying to set up eval in the first place.\nI think picking a system that scales with you at the earliest stage is really an important cost to think about because a lot of people think eval is like what I need to get my product out in that last mile, and you're going to land up back at square one.\nSo thinking about eval as part of your development process and as part of your requirement so that you actually have a benchmark you can ship to words will save you a lot of pain when you get to production because you can use those same eval.\nSo that's how I think time is probably one of the most probably the most expensive part of this whole thing at the end of the day when we're all trying to move fast.\nYeah.\nAnd social capital too, right?\nYou promised your board that you're going to do this, and then all of a sudden you realize actually no, I cannot do this.\nRight.\nCan I give you a really tangible example of that?\nActually, I was listening to Craig Federiki actually talking to the Wall Street Journal, and it's this five-minute clip this morning because everyone's talking about WWDC, and the reporter is like, \"Craig, where's all the AI features?\nWhere's the new Siri that you demoed last year that you said we were going to have?\"\nAnd Craig's answer was, \"We got to a point where we thought it was working really well internally, but when we actually tried it on more scenarios, it just wasn't reliable enough.\"\nSo the takeaway from that is Apple probably didn't have the right eval in place and that's probably why you don't have\n\n\nA new Siri right now. So, I'll give you a counterfactual there. I think Apple needs their own Aman in house or Arize AI, you know, at least some type of system in there to think about reliability early and, and you know, it could be that they were designing with reliability and the system is just really complex, and that is totally where the world we're in right now as well. But it does help you with a little bit of the heartburn of trying to like make an announcement early before you're actually.\n\nUncle team doesn't want to spend money on expensive models. Maybe that's also part of the problem. The scale that they're working with and also like you're trying to evaluate, basically, you build the operating system. You're trying to build something into the operating system that theoretically has permissions to everything that you can do on that device and in that machine. And of course, things are going to go, I don't know. We could spend again probably three or four more hours talking about this. So, we'll have to have you back on. But just in closing, Aman, like where can people learn more about what you're up to and then how could they potentially be helpful to you?\n\nYeah, absolutely. And yeah, thanks again for having me, guys. This was a ton of fun. And I'm trying to be as helpful as possible and try and give away as much for free as possible to PMs. If this resonated with you, reach out. Would love to learn more about what you're building. You can find me on LinkedIn X. My website is also amankhan.ai, so you can also just navigate to my homepage and see what I'm up to. But yeah, yeah, exactly. I got I grabbed the domain just in time. Would love to hear from you and see if I can be helpful. And my goal is to try to help more PMs go from prototype to production with AI with educational content and tools to help them along that way. Yeah, feel free to reach out.\n\nCool. Thanks for coming. Yeah. Yeah. Thank you for letting us ask all the all these stupid questions. Those are questions. Great questions, actually. Yeah. That's a wrap. All right. Thanks, guys.\n\n[Music]\n",
  "dumpedAt": "2025-07-21T18:43:25.265Z"
}