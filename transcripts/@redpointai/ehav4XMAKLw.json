{
  "episodeId": "ehav4XMAKLw",
  "channelSlug": "@redpointai",
  "title": "Databricks Co-Founder: Eval Limitations, Why China is Winning Open Source and Future of AI Infra",
  "publishedAt": "2025-06-17T13:00:12.000Z",
  "rawLines": [
    {
      "lang": "en",
      "text": "Don Stoga has an incredible background.",
      "offset": 0,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "He's the co-founder of Data Bricks,",
      "offset": 1.76,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "Anycale, and now Ella Marina, a company",
      "offset": 3.36,
      "duration": 4.479
    },
    {
      "lang": "en",
      "text": "that's raised $100 million to help other",
      "offset": 5.6,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "companies with eval. He's also professor",
      "offset": 7.839,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "over at Berkeley. And today I was joined",
      "offset": 10,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "by guest host Rob Taves, general partner",
      "offset": 11.92,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "at Radical Ventures. And Yan, Rob and I",
      "offset": 14.08,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "talked about a bunch of things. We hit",
      "offset": 16.48,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "on Ella Marina, Jan's new company, and",
      "offset": 18.24,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "where he thinks the opportunities are.",
      "offset": 20.48,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "We talked about the future of AI",
      "offset": 22.24,
      "duration": 2.799
    },
    {
      "lang": "en",
      "text": "infrastructure and where the gaps are in",
      "offset": 23.6,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "the space today. We also talked about",
      "offset": 25.039,
      "duration": 3.361
    },
    {
      "lang": "en",
      "text": "what the US can learn from China to",
      "offset": 26.72,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "better improve open source model efforts",
      "offset": 28.4,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "within the country. This was a super fun",
      "offset": 29.92,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "opportunity to talk with one of the most",
      "offset": 31.92,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "brilliant minds in computer science uh",
      "offset": 33.2,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "about everything AI. I think people will",
      "offset": 35.12,
      "duration": 3.439
    },
    {
      "lang": "en",
      "text": "really enjoy it. Without further ado,",
      "offset": 36.96,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "here's Yan.",
      "offset": 38.559,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "Well, thanks so much for uh for coming",
      "offset": 40.8,
      "duration": 2.96
    },
    {
      "lang": "en",
      "text": "on the podcast. Really appreciate it.",
      "offset": 42.079,
      "duration": 3.441
    },
    {
      "lang": "en",
      "text": "Thanks for having me. Yeah, been looking",
      "offset": 43.76,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "forward to this one. Uh and I was we",
      "offset": 45.52,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "were joking beforehand. We we timed this",
      "offset": 47.2,
      "duration": 3.199
    },
    {
      "lang": "en",
      "text": "uh recording pretty nicely. I think",
      "offset": 48.8,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "we'll we'll start with obviously the big",
      "offset": 50.399,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "news announced yesterday. um the launch",
      "offset": 51.84,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "of your new startup Ella Marina, you",
      "offset": 54.239,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "know, $100 million fund raise. Tell us a",
      "offset": 56,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "bit about the company, you know, the",
      "offset": 58.079,
      "duration": 2.48
    },
    {
      "lang": "en",
      "text": "product, the vision, what what are you",
      "offset": 59.28,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "all building? Yeah, indeed. Um so, uh",
      "offset": 60.559,
      "duration": 6.721
    },
    {
      "lang": "en",
      "text": "the LM Marina is based on the project we",
      "offset": 63.68,
      "duration": 6.32
    },
    {
      "lang": "en",
      "text": "had at Berkeley started almost two years",
      "offset": 67.28,
      "duration": 6.08
    },
    {
      "lang": "en",
      "text": "ago. Well, two years ago and actually",
      "offset": 70,
      "duration": 6.24
    },
    {
      "lang": "en",
      "text": "that was driven by a need to evaluate a",
      "offset": 73.36,
      "duration": 6.72
    },
    {
      "lang": "en",
      "text": "model which we released I think March",
      "offset": 76.24,
      "duration": 7.12
    },
    {
      "lang": "en",
      "text": "2024 called Vikunia. So it was a model",
      "offset": 80.08,
      "duration": 5.84
    },
    {
      "lang": "en",
      "text": "which was basically a fine-tuned llama",
      "offset": 83.36,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "the first version of llama using the",
      "offset": 85.92,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "share GPT data if you remember the data",
      "offset": 88,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "which was um people sharing their",
      "offset": 90.4,
      "duration": 7.12
    },
    {
      "lang": "en",
      "text": "conversation with GPT share GPD and uh",
      "offset": 93.52,
      "duration": 6.559
    },
    {
      "lang": "en",
      "text": "someone making them publicly available.",
      "offset": 97.52,
      "duration": 6.08
    },
    {
      "lang": "en",
      "text": "So we did that and uh you know Vikunia",
      "offset": 100.079,
      "duration": 6.481
    },
    {
      "lang": "en",
      "text": "was uh a few students actually the",
      "offset": 103.6,
      "duration": 4.879
    },
    {
      "lang": "en",
      "text": "students did that even without me",
      "offset": 106.56,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "knowing I I realized later that they",
      "offset": 108.479,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "just you know we can fine-tune it um uh",
      "offset": 110.479,
      "duration": 6.241
    },
    {
      "lang": "en",
      "text": "this model and then the question is",
      "offset": 113.759,
      "duration": 5.121
    },
    {
      "lang": "en",
      "text": "about evaluating it right it's like of",
      "offset": 116.72,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "course you know you have uh a few",
      "offset": 118.88,
      "duration": 5.599
    },
    {
      "lang": "en",
      "text": "benchmarks back then and so forth like",
      "offset": 122.24,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "today a lot of benchmarks uh but also it",
      "offset": 124.479,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "was a little bit harder because it was",
      "offset": 127.2,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "this kind of conversational right chat",
      "offset": 128.56,
      "duration": 6.56
    },
    {
      "lang": "en",
      "text": "right so that was kind of how do you",
      "offset": 132.56,
      "duration": 6.16
    },
    {
      "lang": "en",
      "text": "evaluate it how you show that you are",
      "offset": 135.12,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "meaningfully better than what is out",
      "offset": 138.72,
      "duration": 6.8
    },
    {
      "lang": "en",
      "text": "there at that time and uh our initial",
      "offset": 141.12,
      "duration": 7.68
    },
    {
      "lang": "en",
      "text": "um effort was what you do like you know",
      "offset": 145.52,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "at university you buy some pizza get",
      "offset": 148.8,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "some students and you know ask some",
      "offset": 151.2,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "questions and evaluate them right on",
      "offset": 154.08,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "different models um the problems that",
      "offset": 155.76,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "was didn't didn't scale",
      "offset": 158.16,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "I thought they could scale pretty well",
      "offset": 160,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "on a g. Yeah. Yeah. Yeah. But you know",
      "offset": 161.36,
      "duration": 6.72
    },
    {
      "lang": "en",
      "text": "um and uh then actually we we did a",
      "offset": 164.8,
      "duration": 7.92
    },
    {
      "lang": "en",
      "text": "detour. Um it was two weeks before GPD4",
      "offset": 168.08,
      "duration": 7.28
    },
    {
      "lang": "en",
      "text": "was released. So we had we thought okay",
      "offset": 172.72,
      "duration": 7.68
    },
    {
      "lang": "en",
      "text": "why don't we use GPD4 to evaluate. Um",
      "offset": 175.36,
      "duration": 7.68
    },
    {
      "lang": "en",
      "text": "and that was what became eventually",
      "offset": 180.4,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "known as LLM as a judge. Um so we did",
      "offset": 183.04,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "that and to our surprise it performed",
      "offset": 186,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "pretty well right. So I look at that and",
      "offset": 188.4,
      "duration": 5.759
    },
    {
      "lang": "en",
      "text": "you know did it we got good numbers for",
      "offset": 191.44,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "our model and um but then still people",
      "offset": 194.159,
      "duration": 5.841
    },
    {
      "lang": "en",
      "text": "asking because again the using LLM to",
      "offset": 197.2,
      "duration": 5.039
    },
    {
      "lang": "en",
      "text": "evaluate was very early right we were",
      "offset": 200,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "the first or maybe among the first to do",
      "offset": 202.239,
      "duration": 5.121
    },
    {
      "lang": "en",
      "text": "that um and uh I'm saying among the",
      "offset": 204.08,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "first because I think that some of the",
      "offset": 207.36,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "companies they did it internally before",
      "offset": 209.2,
      "duration": 5.039
    },
    {
      "lang": "en",
      "text": "maybe you know Microsoft and so forth um",
      "offset": 211.04,
      "duration": 5.119
    },
    {
      "lang": "en",
      "text": "and but people are still asking okay you",
      "offset": 214.239,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "know yes I see that for these examples",
      "offset": 216.159,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "it looks it's doing Well, but still how",
      "offset": 218.799,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "does it compare with people? Um so",
      "offset": 221.599,
      "duration": 5.121
    },
    {
      "lang": "en",
      "text": "that's why we started you know um",
      "offset": 224.319,
      "duration": 5.92
    },
    {
      "lang": "en",
      "text": "chatbot arena and trying to scale up the",
      "offset": 226.72,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "kind of evaluation of humans. That was",
      "offset": 230.239,
      "duration": 5.201
    },
    {
      "lang": "en",
      "text": "one reason. Um the other reason it was",
      "offset": 232.48,
      "duration": 5.759
    },
    {
      "lang": "en",
      "text": "this thinks about uh is like today it's",
      "offset": 235.44,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "very hard to evaluate this light",
      "offset": 238.239,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "language model and already there there",
      "offset": 239.92,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "was evidence of contamination",
      "offset": 242.64,
      "duration": 6.319
    },
    {
      "lang": "en",
      "text": "right uh basically you know uh GPT4 I",
      "offset": 245.12,
      "duration": 7.6
    },
    {
      "lang": "en",
      "text": "remember um doing very well for some",
      "offset": 248.959,
      "duration": 6.801
    },
    {
      "lang": "en",
      "text": "different kind of problems um which are",
      "offset": 252.72,
      "duration": 6.079
    },
    {
      "lang": "en",
      "text": "before uh the cutoff for training but",
      "offset": 255.76,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "not doing very well after that right so",
      "offset": 258.799,
      "duration": 4.561
    },
    {
      "lang": "en",
      "text": "it was this kind of static benchmarks",
      "offset": 261.44,
      "duration": 4.479
    },
    {
      "lang": "en",
      "text": "Right. So then we also thought about",
      "offset": 263.36,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "okay that if this is static of a",
      "offset": 265.919,
      "duration": 3.521
    },
    {
      "lang": "en",
      "text": "benchmark how do this is almost",
      "offset": 267.6,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "equivalent if you think about people is",
      "offset": 269.44,
      "duration": 5.199
    },
    {
      "lang": "en",
      "text": "that you take over and over the same",
      "offset": 272.24,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "exam right it's like what it is right so",
      "offset": 274.639,
      "duration": 6.321
    },
    {
      "lang": "en",
      "text": "you know how you make it and with humans",
      "offset": 277.84,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "you know we do make exams differently",
      "offset": 280.96,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "and different exam and so forth. Um so",
      "offset": 282.88,
      "duration": 4.879
    },
    {
      "lang": "en",
      "text": "that's why the second these are the kind",
      "offset": 286,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "of the two two reasons right we wanted",
      "offset": 287.759,
      "duration": 5.841
    },
    {
      "lang": "en",
      "text": "to have a benchmark which is not static",
      "offset": 290,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "it's more dynamic and also which capture",
      "offset": 293.6,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "the preference of the users of the",
      "offset": 296,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "humans right that's the two reasons and",
      "offset": 298.16,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "then we try to figure out how to do that",
      "offset": 301.36,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "there are multiple ways to do it you can",
      "offset": 303.44,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "uh do a little bit of a tournament which",
      "offset": 305.84,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "is what the students are doing before",
      "offset": 308.24,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "because you give okay this is a question",
      "offset": 310.08,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "this is a prompt and you have this light",
      "offset": 312.56,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "language models of you know whatever",
      "offset": 314.32,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "three or four of them you compare and",
      "offset": 316.16,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "see the answer to each of them and you",
      "offset": 318.24,
      "duration": 3.679
    },
    {
      "lang": "en",
      "text": "rank them. Unfortunately that kind of",
      "offset": 319.84,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "more like it's a tournament like almost",
      "offset": 321.919,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "it doesn't scale uh as well and is not",
      "offset": 323.68,
      "duration": 5.84
    },
    {
      "lang": "en",
      "text": "only that but assumes that while you are",
      "offset": 327.199,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "doing this tournament the number of",
      "offset": 329.52,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "models is fixed. So that's one and again",
      "offset": 331.52,
      "duration": 4.959
    },
    {
      "lang": "en",
      "text": "we look always inspiration of how humans",
      "offset": 334,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "do evaluation and then um it was you",
      "offset": 336.479,
      "duration": 6.881
    },
    {
      "lang": "en",
      "text": "know this thing okay like in where are",
      "offset": 339.52,
      "duration": 7.28
    },
    {
      "lang": "en",
      "text": "you know similar situation in which not",
      "offset": 343.36,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "everyone is playing with everyone and",
      "offset": 346.8,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "the number of players is kind of dynamic",
      "offset": 348.8,
      "duration": 6.16
    },
    {
      "lang": "en",
      "text": "and one is obviously chess and but then",
      "offset": 351.84,
      "duration": 7.68
    },
    {
      "lang": "en",
      "text": "many other sports like u tennis ATP and",
      "offset": 354.96,
      "duration": 7.519
    },
    {
      "lang": "en",
      "text": "also team sports they do that so Yeah.",
      "offset": 359.52,
      "duration": 6.799
    },
    {
      "lang": "en",
      "text": "So that yellow rating and um kind of",
      "offset": 362.479,
      "duration": 6.081
    },
    {
      "lang": "en",
      "text": "yellow rating we used and then the model",
      "offset": 366.319,
      "duration": 5.201
    },
    {
      "lang": "en",
      "text": "was very simple. You come you ask uh",
      "offset": 368.56,
      "duration": 6.079
    },
    {
      "lang": "en",
      "text": "your prompt and we provide answers from",
      "offset": 371.52,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "two randomized anonymized light language",
      "offset": 374.639,
      "duration": 5.761
    },
    {
      "lang": "en",
      "text": "models and then you can pick one which",
      "offset": 377.12,
      "duration": 6.4
    },
    {
      "lang": "en",
      "text": "you believe is better and you may vote.",
      "offset": 380.4,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "Yeah. You are not it's not mandatory to",
      "offset": 383.52,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "vote but you may vote and we get all",
      "offset": 385.68,
      "duration": 4.799
    },
    {
      "lang": "en",
      "text": "this data and we compute these ratings.",
      "offset": 387.84,
      "duration": 4.479
    },
    {
      "lang": "en",
      "text": "Right. And obviously it became wildly",
      "offset": 390.479,
      "duration": 4.241
    },
    {
      "lang": "en",
      "text": "popular. When did you decide it was a",
      "offset": 392.319,
      "duration": 5.281
    },
    {
      "lang": "en",
      "text": "company? Yeah. Well, just to their",
      "offset": 394.72,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "credit, you know, wellin and then",
      "offset": 397.6,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "Anastasio who work on this um they",
      "offset": 399.12,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "believe more that it's a company before",
      "offset": 401.68,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "I did.",
      "offset": 403.84,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "I said, you know, this is just this is",
      "offset": 405.68,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "just evaluation. It's just a",
      "offset": 407.6,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "leaderboard. What what what companies",
      "offset": 408.88,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "here, right?",
      "offset": 411.68,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "You know, but you know, to their credit,",
      "offset": 413.52,
      "duration": 5.679
    },
    {
      "lang": "en",
      "text": "they really believe in it. And then um I",
      "offset": 415.84,
      "duration": 6.56
    },
    {
      "lang": "en",
      "text": "think that um you you get to a point and",
      "offset": 419.199,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "of course there are so many things you",
      "offset": 422.4,
      "duration": 4.799
    },
    {
      "lang": "en",
      "text": "need to do and becomes more popular. Um",
      "offset": 423.919,
      "duration": 6.4
    },
    {
      "lang": "en",
      "text": "some light language mo uh providers",
      "offset": 427.199,
      "duration": 4.961
    },
    {
      "lang": "en",
      "text": "light language model providers like",
      "offset": 430.319,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "frontier labs uh started to eval also",
      "offset": 432.16,
      "duration": 6.4
    },
    {
      "lang": "en",
      "text": "asking us to evaluate uh before the",
      "offset": 435.759,
      "duration": 5.921
    },
    {
      "lang": "en",
      "text": "release. Um so it kind of becomes bigger",
      "offset": 438.56,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "and bigger and people start to ask okay",
      "offset": 441.68,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "what about categories? uh people started",
      "offset": 443.52,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "to ask about well what about um you know",
      "offset": 445.84,
      "duration": 5.199
    },
    {
      "lang": "en",
      "text": "the humans is very subjective right hey",
      "offset": 448.8,
      "duration": 4.799
    },
    {
      "lang": "en",
      "text": "this model gets higher rating because uh",
      "offset": 451.039,
      "duration": 4.641
    },
    {
      "lang": "en",
      "text": "it it's it's doing it's it's showing",
      "offset": 453.599,
      "duration": 4.961
    },
    {
      "lang": "en",
      "text": "more emojis right so we introduce kind",
      "offset": 455.68,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "of style control to try to factor out",
      "offset": 458.56,
      "duration": 7.359
    },
    {
      "lang": "en",
      "text": "some of these things um and or you know",
      "offset": 461.28,
      "duration": 7.52
    },
    {
      "lang": "en",
      "text": "uh and um so that kind of grew and then",
      "offset": 465.919,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "another dimension it started to grow it",
      "offset": 468.8,
      "duration": 5.119
    },
    {
      "lang": "en",
      "text": "started to text and then multimodel",
      "offset": 470.639,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "right it it was most text to image,",
      "offset": 473.919,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "image to text, uh text to web to you",
      "offset": 475.759,
      "duration": 6.321
    },
    {
      "lang": "en",
      "text": "know to generate code um and many more.",
      "offset": 478.879,
      "duration": 5.921
    },
    {
      "lang": "en",
      "text": "So it kind of grew uh into a valuation",
      "offset": 482.08,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "platform and then the data we got um it",
      "offset": 484.8,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "started to realize that it's quite",
      "offset": 488.08,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "valuable uh in terms of what you can do",
      "offset": 490.8,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "with it and I'm not sure you've seen but",
      "offset": 493.36,
      "duration": 7.04
    },
    {
      "lang": "en",
      "text": "one of the feature we launched um uh one",
      "offset": 496.8,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "month or two months ago something like",
      "offset": 500.4,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "that is called prompto leaderboard and",
      "offset": 502.16,
      "duration": 5.039
    },
    {
      "lang": "en",
      "text": "prompt to leaderboard what it is is that",
      "offset": 505.36,
      "duration": 5.119
    },
    {
      "lang": "en",
      "text": "you come and you give your prompt I may",
      "offset": 507.199,
      "duration": 5.84
    },
    {
      "lang": "en",
      "text": "not never have seen prompt but I can",
      "offset": 510.479,
      "duration": 6.161
    },
    {
      "lang": "en",
      "text": "give you back um it's a leaderboard for",
      "offset": 513.039,
      "duration": 6.321
    },
    {
      "lang": "en",
      "text": "your prompt right what are the best",
      "offset": 516.64,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "models to answer your prompt what is",
      "offset": 519.36,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "their estimated rating and the way you",
      "offset": 521.68,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "do it is although I didn't you know",
      "offset": 523.68,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "intuitively it's not it's not u very",
      "offset": 525.839,
      "duration": 5.201
    },
    {
      "lang": "en",
      "text": "accurate but I think intuitively I think",
      "offset": 528.48,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "it's um you know it's reasonable I think",
      "offset": 531.04,
      "duration": 6.64
    },
    {
      "lang": "en",
      "text": "to so you although I I I never seen your",
      "offset": 534.16,
      "duration": 7.679
    },
    {
      "lang": "en",
      "text": "prompt uh I've seen a lot of prompts",
      "offset": 537.68,
      "duration": 7.04
    },
    {
      "lang": "en",
      "text": "which looks like your prompt and then I",
      "offset": 541.839,
      "duration": 4.641
    },
    {
      "lang": "en",
      "text": "can use the votes on these similar",
      "offset": 544.72,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "prompts as a proxy to estimate the",
      "offset": 546.48,
      "duration": 7.919
    },
    {
      "lang": "en",
      "text": "rating of the models on your prompt",
      "offset": 550.24,
      "duration": 6.64
    },
    {
      "lang": "en",
      "text": "right you know that's kind of exciting",
      "offset": 554.399,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "and there are many other question you",
      "offset": 556.88,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "know when you you you start realizing",
      "offset": 558.48,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "there is a potential here so first of",
      "offset": 560.48,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "all we need a company because there was",
      "offset": 562.08,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "no way to scale what we are doing right",
      "offset": 564.16,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "it's it's costly yeah right because uh",
      "offset": 566.72,
      "duration": 5.119
    },
    {
      "lang": "en",
      "text": "what we provide the user there is free",
      "offset": 569.68,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "access to these powerful models, right?",
      "offset": 571.839,
      "duration": 6.801
    },
    {
      "lang": "en",
      "text": "And um even you know like we spend um",
      "offset": 574.88,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "for the past year maybe you know",
      "offset": 578.64,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "probably close to 2 millions to run uh",
      "offset": 580.32,
      "duration": 6.32
    },
    {
      "lang": "en",
      "text": "uh this of course a lot of money comes",
      "offset": 584.64,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "in terms of credits in terms of uh some",
      "offset": 586.64,
      "duration": 6.4
    },
    {
      "lang": "en",
      "text": "gifts uh grants thing like that right u",
      "offset": 589.76,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "but if you think about right now you",
      "offset": 593.04,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "know want to scale 10x or something like",
      "offset": 594.88,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "that it's clearly it's a lot of uh you",
      "offset": 596.8,
      "duration": 5.599
    },
    {
      "lang": "en",
      "text": "know it's not going to be cheap. Um the",
      "offset": 599.92,
      "duration": 6.32
    },
    {
      "lang": "en",
      "text": "other thing it is was that um like I",
      "offset": 602.399,
      "duration": 6.641
    },
    {
      "lang": "en",
      "text": "mentioned to you is a lot of a lot of",
      "offset": 606.24,
      "duration": 5.92
    },
    {
      "lang": "en",
      "text": "request to uh do more of kind of",
      "offset": 609.04,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "evaluations. Right now you have agents",
      "offset": 612.16,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "and you have all of these. We have a",
      "offset": 614.48,
      "duration": 3.599
    },
    {
      "lang": "en",
      "text": "search now you evaluate the search",
      "offset": 616.079,
      "duration": 4.481
    },
    {
      "lang": "en",
      "text": "engines. not the search the you know",
      "offset": 618.079,
      "duration": 7.2
    },
    {
      "lang": "en",
      "text": "yeah the like perplexity and the",
      "offset": 620.56,
      "duration": 6.64
    },
    {
      "lang": "en",
      "text": "open AI search and things like that and",
      "offset": 625.279,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "then you need to build really a scalable",
      "offset": 627.2,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "back end and you need to build something",
      "offset": 629.279,
      "duration": 4.641
    },
    {
      "lang": "en",
      "text": "a new you know uh a much more responsive",
      "offset": 631.519,
      "duration": 4.641
    },
    {
      "lang": "en",
      "text": "UIUX you know all of these things right",
      "offset": 633.92,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "you know there is no way you can you can",
      "offset": 636.16,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "do that um with a few people and uh and",
      "offset": 637.68,
      "duration": 6.56
    },
    {
      "lang": "en",
      "text": "then you have a model and providers and",
      "offset": 641.36,
      "duration": 6.479
    },
    {
      "lang": "en",
      "text": "other people um both open source and uh",
      "offset": 644.24,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "proprietary",
      "offset": 647.839,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "asking for evaluations, right? And there",
      "offset": 648.8,
      "duration": 5.039
    },
    {
      "lang": "en",
      "text": "is no way, you know, we have a student",
      "offset": 652.079,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "while basically, you know, he's like",
      "offset": 653.839,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "doing that's he's a back end, right?",
      "offset": 656.399,
      "duration": 5.361
    },
    {
      "lang": "en",
      "text": "Okay. Request, you know, like you put so",
      "offset": 659.519,
      "duration": 4.961
    },
    {
      "lang": "en",
      "text": "all of these things and then um you you",
      "offset": 661.76,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "see that again once you have this kind",
      "offset": 664.48,
      "duration": 5.039
    },
    {
      "lang": "en",
      "text": "of data there are a lot of questions you",
      "offset": 666.64,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "can answer, right? Like I mentioned",
      "offset": 669.519,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "prompt leaderboard maybe you can answer",
      "offset": 672.16,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "questions about which many people have.",
      "offset": 673.839,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "I build my application on a particular",
      "offset": 676.24,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "model and now I want to swap the model.",
      "offset": 678.16,
      "duration": 4.799
    },
    {
      "lang": "en",
      "text": "Yeah, you know, maybe it's a new one,",
      "offset": 680.64,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "it's available uh maybe something",
      "offset": 682.959,
      "duration": 5.601
    },
    {
      "lang": "en",
      "text": "cheaper. So, but what will be the impact",
      "offset": 686.32,
      "duration": 5.199
    },
    {
      "lang": "en",
      "text": "of swapping the model on my application?",
      "offset": 688.56,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "uh many many of these questions and then",
      "offset": 691.519,
      "duration": 7.121
    },
    {
      "lang": "en",
      "text": "but what convinced me about um that its",
      "offset": 694.32,
      "duration": 7.759
    },
    {
      "lang": "en",
      "text": "potential here um and us in general",
      "offset": 698.64,
      "duration": 5.759
    },
    {
      "lang": "en",
      "text": "maybe not only me is that if you look at",
      "offset": 702.079,
      "duration": 5.841
    },
    {
      "lang": "en",
      "text": "AI um I think that one of the main",
      "offset": 704.399,
      "duration": 7.041
    },
    {
      "lang": "en",
      "text": "challenges today with of AI it's um",
      "offset": 707.92,
      "duration": 6.56
    },
    {
      "lang": "en",
      "text": "reliab reliability right it's like",
      "offset": 711.44,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "that's key question and it's very hard",
      "offset": 714.48,
      "duration": 5.599
    },
    {
      "lang": "en",
      "text": "to see how uh AI will really achieve its",
      "offset": 716.64,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "potential",
      "offset": 720.079,
      "duration": 3.121
    },
    {
      "lang": "en",
      "text": "without figuring out how to build more",
      "offset": 721.04,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "reliable application. Right? Now, if you",
      "offset": 723.2,
      "duration": 4.639
    },
    {
      "lang": "en",
      "text": "look about software, a lot of things we",
      "offset": 725.68,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "do, it's about reliability, right? It's",
      "offset": 727.839,
      "duration": 4.881
    },
    {
      "lang": "en",
      "text": "actually most of the energy we put in",
      "offset": 730.48,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "software development is about",
      "offset": 732.72,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "reliability because it doesn't take a",
      "offset": 733.92,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "lot of time to write the code to provide",
      "offset": 736,
      "duration": 6.32
    },
    {
      "lang": "en",
      "text": "a feature or a service. But you spend a",
      "offset": 738.72,
      "duration": 7.04
    },
    {
      "lang": "en",
      "text": "lot of more time in order to uh test it,",
      "offset": 742.32,
      "duration": 8.639
    },
    {
      "lang": "en",
      "text": "debug it, um and and so forth. and um",
      "offset": 745.76,
      "duration": 6.72
    },
    {
      "lang": "en",
      "text": "and there's a lot of innovation there.",
      "offset": 750.959,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "You'll have a CI/CD all of these things.",
      "offset": 752.48,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "So and and that in some sense easier",
      "offset": 755.36,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "problem because the software is pretty",
      "offset": 758.24,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "white box right this is the instruction",
      "offset": 760.88,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "you change the instruction you can see",
      "offset": 762.639,
      "duration": 3.521
    },
    {
      "lang": "en",
      "text": "what is the state of the program after",
      "offset": 764.32,
      "duration": 3.519
    },
    {
      "lang": "en",
      "text": "each instruction if you don't use a",
      "offset": 766.16,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "debugger you can do print fs and things",
      "offset": 767.839,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "like that but models are more blackbox",
      "offset": 769.6,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "right so if you look at the analogy and",
      "offset": 772.639,
      "duration": 6.081
    },
    {
      "lang": "en",
      "text": "we still want reliable application um",
      "offset": 775.12,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "and because even if you look now the",
      "offset": 778.72,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "most successful AI applications are the",
      "offset": 780.88,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "one which you have a human in the loop",
      "offset": 783.68,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "Yeah, for the same reason to validate",
      "offset": 785.12,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "the answer like code code code",
      "offset": 786.72,
      "duration": 5.679
    },
    {
      "lang": "en",
      "text": "assistance uh customer support um and",
      "offset": 788.24,
      "duration": 6.56
    },
    {
      "lang": "en",
      "text": "many others. Um so then if you think",
      "offset": 792.399,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "kind of the analogy you know you have to",
      "offset": 794.8,
      "duration": 6.64
    },
    {
      "lang": "en",
      "text": "have ways to to test and validate and",
      "offset": 796.8,
      "duration": 7.839
    },
    {
      "lang": "en",
      "text": "build more reliable um AI applications",
      "offset": 801.44,
      "duration": 8.48
    },
    {
      "lang": "en",
      "text": "again a big problem and um it's seems",
      "offset": 804.639,
      "duration": 7.521
    },
    {
      "lang": "en",
      "text": "like obviously there are many things you",
      "offset": 809.92,
      "duration": 5.039
    },
    {
      "lang": "en",
      "text": "need to do but also something like LMAR",
      "offset": 812.16,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "now will help super interesting Y it",
      "offset": 814.959,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "makes a lot of sense and I think as",
      "offset": 816.88,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "you've touched on evaluations and like",
      "offset": 818.959,
      "duration": 5.361
    },
    {
      "lang": "en",
      "text": "validation of reliability for AI systems",
      "offset": 821.92,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "is one of the biggest unsolved",
      "offset": 824.32,
      "duration": 2.959
    },
    {
      "lang": "en",
      "text": "challenges. So I think it's a it's a",
      "offset": 825.68,
      "duration": 2.8
    },
    {
      "lang": "en",
      "text": "massive opportunity you guys are",
      "offset": 827.279,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "tackling is your vision and is the",
      "offset": 828.48,
      "duration": 6.08
    },
    {
      "lang": "en",
      "text": "thesis of of the company LM Arena that",
      "offset": 831.44,
      "duration": 5.199
    },
    {
      "lang": "en",
      "text": "human-based evaluations will always be",
      "offset": 834.56,
      "duration": 3.519
    },
    {
      "lang": "en",
      "text": "the best way to go and that that needs",
      "offset": 836.639,
      "duration": 4.721
    },
    {
      "lang": "en",
      "text": "to be yeah that's a great question um",
      "offset": 838.079,
      "duration": 4.961
    },
    {
      "lang": "en",
      "text": "happy to answer that that's why we have",
      "offset": 841.36,
      "duration": 5.599
    },
    {
      "lang": "en",
      "text": "our guest as a great question yeah so um",
      "offset": 843.04,
      "duration": 6.64
    },
    {
      "lang": "en",
      "text": "I think that um uh it is very",
      "offset": 846.959,
      "duration": 4.641
    },
    {
      "lang": "en",
      "text": "interesting here like I we were you know",
      "offset": 849.68,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "have a lot of discussion on this and",
      "offset": 851.6,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "probably you've seen and so forth Um I",
      "offset": 853.68,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "think it's it's it's it's one one",
      "offset": 856.24,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "evaluation. There are many other",
      "offset": 858.88,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "evaluations and you should look at many",
      "offset": 860.32,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "evaluations, many benchmarks. However,",
      "offset": 862.16,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "if you think today like we discussed",
      "offset": 864.88,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "early on that most of the application",
      "offset": 866.72,
      "duration": 5.119
    },
    {
      "lang": "en",
      "text": "today, they have a human in the loop. So",
      "offset": 869.199,
      "duration": 4.801
    },
    {
      "lang": "en",
      "text": "this makes the human evaluation",
      "offset": 871.839,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "particularly important, right? And there",
      "offset": 874,
      "duration": 4.959
    },
    {
      "lang": "en",
      "text": "are people saying well you know like we",
      "offset": 876.639,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "mentioned to you about this style",
      "offset": 878.959,
      "duration": 5.361
    },
    {
      "lang": "en",
      "text": "control but you know it's it's it's",
      "offset": 881.199,
      "duration": 5.121
    },
    {
      "lang": "en",
      "text": "people like that model not because it's",
      "offset": 884.32,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "better but because it's funnier or",
      "offset": 886.32,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "because you know answer or emojis or",
      "offset": 888.639,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "something like that. Um and the answer",
      "offset": 890.88,
      "duration": 6.16
    },
    {
      "lang": "en",
      "text": "to that question well first of all even",
      "offset": 893.279,
      "duration": 6.321
    },
    {
      "lang": "en",
      "text": "that is relevant. If you build",
      "offset": 897.04,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "application which interacts with humans",
      "offset": 899.6,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "you want to know that. Yeah. Right. And",
      "offset": 901.92,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "by the way guys, you know, like we as a",
      "offset": 904.16,
      "duration": 4.799
    },
    {
      "lang": "en",
      "text": "human, right? It's like, you know, we",
      "offset": 906.8,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "like people who give better",
      "offset": 908.959,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "presentations, more articulated speak",
      "offset": 910.72,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "of biases, right? So you want to",
      "offset": 914.639,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "understand that. Um, so that's kind of",
      "offset": 916.24,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "very legitimate, right? And of course,",
      "offset": 918.639,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "now the other thing is that you have",
      "offset": 921.04,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "enough data. If you know a bias, you can",
      "offset": 922.56,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "factor it out, right? And this what we",
      "offset": 924.72,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "do a little bit with style control, you",
      "offset": 926.88,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "know, for instance, formatting, right?",
      "offset": 928.48,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "If you have nicer formatted outer, you",
      "offset": 930.32,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "like it better, right? Like so you you",
      "offset": 932.88,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "try to factor that out that you can pick",
      "offset": 935.36,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "style. Maybe you style control by",
      "offset": 937.68,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "default in in the in the future, right?",
      "offset": 939.6,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "In which you factor out some of these",
      "offset": 942,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "things or so um so and and and then you",
      "offset": 943.68,
      "duration": 6.399
    },
    {
      "lang": "en",
      "text": "know that's having a platform in which",
      "offset": 948,
      "duration": 4.639
    },
    {
      "lang": "en",
      "text": "you can try to remove certain biases. Of",
      "offset": 950.079,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "course you can remove only the biases",
      "offset": 952.639,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "you know they exist, right? That's a",
      "offset": 954.079,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "problem. Um but definitely uh by the way",
      "offset": 955.839,
      "duration": 5.281
    },
    {
      "lang": "en",
      "text": "you know this is funny about the biases.",
      "offset": 958.959,
      "duration": 5.521
    },
    {
      "lang": "en",
      "text": "Um but you know when we look um I",
      "offset": 961.12,
      "duration": 4.959
    },
    {
      "lang": "en",
      "text": "mentioned to you that when we do this",
      "offset": 964.48,
      "duration": 6.719
    },
    {
      "lang": "en",
      "text": "when we when we um um build um uh when",
      "offset": 966.079,
      "duration": 8.961
    },
    {
      "lang": "en",
      "text": "we when we when we use this GPT4 for as",
      "offset": 971.199,
      "duration": 7.44
    },
    {
      "lang": "en",
      "text": "a as a judge early on and then we build",
      "offset": 975.04,
      "duration": 6.479
    },
    {
      "lang": "en",
      "text": "uh you know chatbot arena one of the",
      "offset": 978.639,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "reason to answer the question about how",
      "offset": 981.519,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "well and how does it compare with GP4",
      "offset": 983.759,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "because people are asking we did a we",
      "offset": 985.759,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "wrote a paper and we did uh we made a",
      "offset": 987.6,
      "duration": 5.359
    },
    {
      "lang": "en",
      "text": "study and The funniest thing is that um",
      "offset": 990.079,
      "duration": 6.801
    },
    {
      "lang": "en",
      "text": "is that these LLMs have also biases as a",
      "offset": 992.959,
      "duration": 5.761
    },
    {
      "lang": "en",
      "text": "judge like for instance if they have",
      "offset": 996.88,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "position bias they in general prefer the",
      "offset": 998.72,
      "duration": 4.479
    },
    {
      "lang": "en",
      "text": "first answer they have verbosity bias",
      "offset": 1001.04,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "the more they prefer the more verbose",
      "offset": 1003.199,
      "duration": 5.841
    },
    {
      "lang": "en",
      "text": "answer right um uh at this time maybe",
      "offset": 1005.199,
      "duration": 5.281
    },
    {
      "lang": "en",
      "text": "now they are better they are not very",
      "offset": 1009.04,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "good at math like people right they are",
      "offset": 1010.48,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "not very good at math so it's very a lot",
      "offset": 1012.24,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "of biases of um",
      "offset": 1014.48,
      "duration": 6.32
    },
    {
      "lang": "en",
      "text": "of or or liking their own answers",
      "offset": 1018,
      "duration": 5.199
    },
    {
      "lang": "en",
      "text": "right? So, you know, from their own",
      "offset": 1020.8,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "family, right? The family of models,",
      "offset": 1023.199,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "right? It's like llama model view that",
      "offset": 1025.52,
      "duration": 5.039
    },
    {
      "lang": "en",
      "text": "the judge is going to to to like from",
      "offset": 1027.199,
      "duration": 6.48
    },
    {
      "lang": "en",
      "text": "other version of llama models. Um, so uh",
      "offset": 1030.559,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "but that's kind of very interesting",
      "offset": 1033.679,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "because even of these models maybe maybe",
      "offset": 1035.199,
      "duration": 5.281
    },
    {
      "lang": "en",
      "text": "not surprisingly again they are trained",
      "offset": 1037.679,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "on uh on artifacts on on on what are",
      "offset": 1040.48,
      "duration": 6.079
    },
    {
      "lang": "en",
      "text": "produced by the humans. So, but yeah,",
      "offset": 1043.679,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "it's interesting. And I feel like uh",
      "offset": 1046.559,
      "duration": 3.281
    },
    {
      "lang": "en",
      "text": "obviously evaluations I feel like any",
      "offset": 1048,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "startup you talk to this is like you",
      "offset": 1049.84,
      "duration": 2.88
    },
    {
      "lang": "en",
      "text": "know one of the top things they're",
      "offset": 1051.28,
      "duration": 2.96
    },
    {
      "lang": "en",
      "text": "thinking about and I think a question's",
      "offset": 1052.72,
      "duration": 2.72
    },
    {
      "lang": "en",
      "text": "always been as people have been building",
      "offset": 1054.24,
      "duration": 3.439
    },
    {
      "lang": "en",
      "text": "tooling in this space you know how",
      "offset": 1055.44,
      "duration": 3.599
    },
    {
      "lang": "en",
      "text": "generalizable can you make an",
      "offset": 1057.679,
      "duration": 3.041
    },
    {
      "lang": "en",
      "text": "evaluations tool for a company because I",
      "offset": 1059.039,
      "duration": 3.281
    },
    {
      "lang": "en",
      "text": "think every you know you know in some",
      "offset": 1060.72,
      "duration": 3.199
    },
    {
      "lang": "en",
      "text": "senses the most valuable thing companies",
      "offset": 1062.32,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "have is their own eval right that are",
      "offset": 1063.919,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "specific to their own use cases and so",
      "offset": 1065.84,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "how do you think about like providing a",
      "offset": 1067.52,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "general set of tooling to companies in",
      "offset": 1069.2,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "very different end domains. Yeah, that's",
      "offset": 1071.2,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "a good question. I I I I don't think I",
      "offset": 1073.36,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "know the answer to that question. I",
      "offset": 1075.52,
      "duration": 2.96
    },
    {
      "lang": "en",
      "text": "don't either. We are we are we are",
      "offset": 1076.96,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "happy. But but you know things like that",
      "offset": 1078.48,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "like I'm I mentioned to you the prompty",
      "offset": 1080.48,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "leaderboard um are going to help right",
      "offset": 1082.24,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "because in that particular case we don't",
      "offset": 1084.559,
      "duration": 4.561
    },
    {
      "lang": "en",
      "text": "know again your we haven't seen your uh",
      "offset": 1086.32,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "your prompt or your question before but",
      "offset": 1089.12,
      "duration": 7.52
    },
    {
      "lang": "en",
      "text": "we can still tell you um you know um you",
      "offset": 1091.84,
      "duration": 7.04
    },
    {
      "lang": "en",
      "text": "know within some stat statistical",
      "offset": 1096.64,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "meaningful margins that uh which are the",
      "offset": 1098.88,
      "duration": 6.24
    },
    {
      "lang": "en",
      "text": "best models for for that question. So",
      "offset": 1102,
      "duration": 4.559
    },
    {
      "lang": "en",
      "text": "that's can generalize easily. You give",
      "offset": 1105.12,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "me the set of data and I can give you",
      "offset": 1106.559,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "you know the you know the best models",
      "offset": 1108.72,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "for your set of data. I can give you",
      "offset": 1110.88,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "also probably you can do uh personalized",
      "offset": 1112.559,
      "duration": 4.641
    },
    {
      "lang": "en",
      "text": "right you can do what are the best",
      "offset": 1115.36,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "models for you right so I think you can",
      "offset": 1117.2,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "do that that's why the key for that is",
      "offset": 1120.16,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "to scale right to get more data the more",
      "offset": 1122.96,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "data you're going to have the more kind",
      "offset": 1125.28,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "of this kind of micro um um categories",
      "offset": 1126.64,
      "duration": 6.32
    },
    {
      "lang": "en",
      "text": "you can have yeah makes uh makes total",
      "offset": 1130.32,
      "duration": 4.479
    },
    {
      "lang": "en",
      "text": "sense what do you think happens to the",
      "offset": 1132.96,
      "duration": 3.599
    },
    {
      "lang": "en",
      "text": "you know model landscape over the next",
      "offset": 1134.799,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "few years maybe starting with the like",
      "offset": 1136.559,
      "duration": 3.441
    },
    {
      "lang": "en",
      "text": "most state-of-the-art closed source",
      "offset": 1138.559,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "models yeah Um",
      "offset": 1140,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "uh",
      "offset": 1142.799,
      "duration": 5.601
    },
    {
      "lang": "en",
      "text": "I think really if you think about um",
      "offset": 1144.48,
      "duration": 6.24
    },
    {
      "lang": "en",
      "text": "right now the trends obviously and that",
      "offset": 1148.4,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "was",
      "offset": 1150.72,
      "duration": 6.079
    },
    {
      "lang": "en",
      "text": "um uh the open source model caught up",
      "offset": 1152.32,
      "duration": 6.56
    },
    {
      "lang": "en",
      "text": "the progressor quite impressive over the",
      "offset": 1156.799,
      "duration": 7.12
    },
    {
      "lang": "en",
      "text": "past year. Um, of course it was",
      "offset": 1158.88,
      "duration": 8.96
    },
    {
      "lang": "en",
      "text": "um not of course but um maybe surprising",
      "offset": 1163.919,
      "duration": 6.721
    },
    {
      "lang": "en",
      "text": "and also a surprising uh thing is that",
      "offset": 1167.84,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "these models are not necessarily from US",
      "offset": 1170.64,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "or from China.",
      "offset": 1172.64,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "Um but definitely at this point if",
      "offset": 1174.32,
      "duration": 4.719
    },
    {
      "lang": "en",
      "text": "you're talking about the open source",
      "offset": 1177.2,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "models the best car coming from China",
      "offset": 1179.039,
      "duration": 5.601
    },
    {
      "lang": "en",
      "text": "and if you look at the trends uh you",
      "offset": 1182,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "know the open source should be able to",
      "offset": 1184.64,
      "duration": 5.039
    },
    {
      "lang": "en",
      "text": "catch up with proprietary models within",
      "offset": 1187.12,
      "duration": 7.28
    },
    {
      "lang": "en",
      "text": "one year or so um and um yeah now the",
      "offset": 1189.679,
      "duration": 6.321
    },
    {
      "lang": "en",
      "text": "question where this opensource model are",
      "offset": 1194.4,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "going to come from um and what I can say",
      "offset": 1196,
      "duration": 7.52
    },
    {
      "lang": "en",
      "text": "is that um in China it's a lot of right",
      "offset": 1199.36,
      "duration": 7.6
    },
    {
      "lang": "en",
      "text": "now a lot of momentum and for I think",
      "offset": 1203.52,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "for",
      "offset": 1206.96,
      "duration": 7.36
    },
    {
      "lang": "en",
      "text": "structural structural and reasons and um",
      "offset": 1208.72,
      "duration": 8.959
    },
    {
      "lang": "en",
      "text": "you know how the ecosystem it's uh right",
      "offset": 1214.32,
      "duration": 7.12
    },
    {
      "lang": "en",
      "text": "now grew in China versus US so I think",
      "offset": 1217.679,
      "duration": 5.761
    },
    {
      "lang": "en",
      "text": "that we and US are a little bit of",
      "offset": 1221.44,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "disadvantage now say more about that why",
      "offset": 1223.44,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "is that structural so first if you think",
      "offset": 1226.4,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "about what do you need to develop these",
      "offset": 1228.72,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "models right you need three things you",
      "offset": 1230.559,
      "duration": 4.801
    },
    {
      "lang": "en",
      "text": "experts, you need data, you need",
      "offset": 1233.2,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "infrastructure, right?",
      "offset": 1235.36,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "Um and I think that if you look at",
      "offset": 1238.08,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "China, they have a lot of experts.",
      "offset": 1240.72,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "Probably in sheer numbers, they have",
      "offset": 1242.88,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "more than us. Um data, they have data,",
      "offset": 1244.08,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "they have, you know, they don't have as",
      "offset": 1247.6,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "much infrastructure, but they are making",
      "offset": 1249.52,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "progress, right? Um if you look at the",
      "offset": 1250.96,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "latest announcement from Huawei and so",
      "offset": 1254.24,
      "duration": 5.84
    },
    {
      "lang": "en",
      "text": "forth and you know uh export controls",
      "offset": 1256.32,
      "duration": 5.92
    },
    {
      "lang": "en",
      "text": "you know everyone guess about how",
      "offset": 1260.08,
      "duration": 4.719
    },
    {
      "lang": "en",
      "text": "effective they are going to be uh or",
      "offset": 1262.24,
      "duration": 7.76
    },
    {
      "lang": "en",
      "text": "they are um that's you know that's to to",
      "offset": 1264.799,
      "duration": 8.321
    },
    {
      "lang": "en",
      "text": "you know to to debate. Um",
      "offset": 1270,
      "duration": 7.84
    },
    {
      "lang": "en",
      "text": "but the one thing there is that um the",
      "offset": 1273.12,
      "duration": 8.32
    },
    {
      "lang": "en",
      "text": "the open source it's much more prevalent",
      "offset": 1277.84,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "right it's almost by default now if you",
      "offset": 1281.44,
      "duration": 7.92
    },
    {
      "lang": "en",
      "text": "go to US um is that um you have huge",
      "offset": 1283.84,
      "duration": 9.12
    },
    {
      "lang": "en",
      "text": "resources that's so force and um you",
      "offset": 1289.36,
      "duration": 7.679
    },
    {
      "lang": "en",
      "text": "have lots of smart people uh uh the",
      "offset": 1292.96,
      "duration": 7.12
    },
    {
      "lang": "en",
      "text": "problem is that the development what how",
      "offset": 1297.039,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "happens in US siloed,",
      "offset": 1300.08,
      "duration": 6.64
    },
    {
      "lang": "en",
      "text": "right? It's um you know this frontier",
      "offset": 1303.039,
      "duration": 5.281
    },
    {
      "lang": "en",
      "text": "lab,",
      "offset": 1306.72,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "right? Everyone is doing the same thing",
      "offset": 1308.32,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "basically. Uh that's number one. The",
      "offset": 1310.72,
      "duration": 6.72
    },
    {
      "lang": "en",
      "text": "number two is that academia when talk",
      "offset": 1313.6,
      "duration": 5.92
    },
    {
      "lang": "en",
      "text": "when you talk about",
      "offset": 1317.44,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "pre-training and building the models uh",
      "offset": 1319.52,
      "duration": 8.32
    },
    {
      "lang": "en",
      "text": "doesn't play a major role because um",
      "offset": 1322.64,
      "duration": 8.08
    },
    {
      "lang": "en",
      "text": "um lack of resources you know there are",
      "offset": 1327.84,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "companies like AI2 there is a group from",
      "offset": 1330.72,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "Stanford Percy Leang trying to develop",
      "offset": 1333.36,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "and we at Berkeley try to develop this",
      "offset": 1336.08,
      "duration": 6.959
    },
    {
      "lang": "en",
      "text": "um you know pre-training post-training",
      "offset": 1338.96,
      "duration": 6.48
    },
    {
      "lang": "en",
      "text": "um full open source pipelines and so",
      "offset": 1343.039,
      "duration": 6.481
    },
    {
      "lang": "en",
      "text": "forth. Um but it's a challenge and",
      "offset": 1345.44,
      "duration": 7.28
    },
    {
      "lang": "en",
      "text": "unless that changes we are going to be a",
      "offset": 1349.52,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "structural disadvantage because the",
      "offset": 1352.72,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "diffusion of innovation is very limited",
      "offset": 1354.4,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "right um it's like you have people so",
      "offset": 1357.28,
      "duration": 6.08
    },
    {
      "lang": "en",
      "text": "the way you can if you want to maximize",
      "offset": 1360.08,
      "duration": 5.599
    },
    {
      "lang": "en",
      "text": "the rate of progress",
      "offset": 1363.36,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "you have to have all the smart people",
      "offset": 1365.679,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "collaborate",
      "offset": 1368.08,
      "duration": 4.719
    },
    {
      "lang": "en",
      "text": "right uh but if you have kind of these",
      "offset": 1369.6,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "silos and a big part of the researcher",
      "offset": 1372.799,
      "duration": 4.721
    },
    {
      "lang": "en",
      "text": "I'm talking about academia uh not being",
      "offset": 1374.96,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "able to contribute in a meaningful way",
      "offset": 1377.52,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "to developing these models",
      "offset": 1379.2,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "then uh",
      "offset": 1381.76,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "it's a significant disadvantage. The",
      "offset": 1384,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "main diffusion of innovation here in in",
      "offset": 1386.159,
      "duration": 6.321
    },
    {
      "lang": "en",
      "text": "the US in in um is that through people",
      "offset": 1388.4,
      "duration": 6.24
    },
    {
      "lang": "en",
      "text": "who leave one company go to another or",
      "offset": 1392.48,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "start new companies. uh if you but if",
      "offset": 1394.64,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "you look for instance in China um there",
      "offset": 1397.2,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "is a much stronger collaboration between",
      "offset": 1400,
      "duration": 7.12
    },
    {
      "lang": "en",
      "text": "academia and and um and industry you",
      "offset": 1402.32,
      "duration": 9.599
    },
    {
      "lang": "en",
      "text": "know like bid dance or um Alibaba and",
      "offset": 1407.12,
      "duration": 7.2
    },
    {
      "lang": "en",
      "text": "and obviously DeepS",
      "offset": 1411.919,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "and um that really helps them. What what",
      "offset": 1414.32,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "is the reason like academia is like so",
      "offset": 1417.679,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "much more effectively involved in China?",
      "offset": 1419.6,
      "duration": 2.559
    },
    {
      "lang": "en",
      "text": "How does that come about? Because it's",
      "offset": 1421.039,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "much closer collaboration with industry.",
      "offset": 1422.159,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "it here is very hard to collaborate with",
      "offset": 1424.159,
      "duration": 4.481
    },
    {
      "lang": "en",
      "text": "the frontier lab because everything is",
      "offset": 1426.799,
      "duration": 4.641
    },
    {
      "lang": "en",
      "text": "secret. If if you really want to",
      "offset": 1428.64,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "maximize the rate of progress again you",
      "offset": 1431.44,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "have to have all your researchers or",
      "offset": 1433.36,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "your experts collaborating. The only way",
      "offset": 1435.28,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "they can collaborate by share artifacts.",
      "offset": 1438.32,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "Yeah. Which is means",
      "offset": 1440.64,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "at the software side open source models",
      "offset": 1443.28,
      "duration": 5.279
    },
    {
      "lang": "en",
      "text": "and they need also to have a shared",
      "offset": 1446.64,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "infrastructure. Yeah. Right. I mean",
      "offset": 1448.559,
      "duration": 3.201
    },
    {
      "lang": "en",
      "text": "obviously a motivation behind a lot of",
      "offset": 1450.48,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "the closed labs is you know this belief",
      "offset": 1451.76,
      "duration": 3.519
    },
    {
      "lang": "en",
      "text": "that you know they you know being the",
      "offset": 1453.6,
      "duration": 2.72
    },
    {
      "lang": "en",
      "text": "first to find these state-of-the-art",
      "offset": 1455.279,
      "duration": 2.4
    },
    {
      "lang": "en",
      "text": "models there's all these dangers of what",
      "offset": 1456.32,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "they can be done in bio or cyber and",
      "offset": 1457.679,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "they need to get to them first like what",
      "offset": 1460.08,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "what do you make of that uh look I mean",
      "offset": 1461.36,
      "duration": 6.64
    },
    {
      "lang": "en",
      "text": "um I am on I am optimist in general I am",
      "offset": 1464,
      "duration": 7.52
    },
    {
      "lang": "en",
      "text": "not I think it's very you know you",
      "offset": 1468,
      "duration": 6.96
    },
    {
      "lang": "en",
      "text": "always need to remember that as a humans",
      "offset": 1471.52,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "we are driven by emotions and one of the",
      "offset": 1474.96,
      "duration": 7.12
    },
    {
      "lang": "en",
      "text": "most by far powerful emotion is fear. So",
      "offset": 1477.12,
      "duration": 6.96
    },
    {
      "lang": "en",
      "text": "it's it's you always going to respond to",
      "offset": 1482.08,
      "duration": 4.959
    },
    {
      "lang": "en",
      "text": "that much more much stronger, right? But",
      "offset": 1484.08,
      "duration": 6.719
    },
    {
      "lang": "en",
      "text": "then providing you some optimistic view",
      "offset": 1487.039,
      "duration": 6.721
    },
    {
      "lang": "en",
      "text": "which is not palpable. But the other one",
      "offset": 1490.799,
      "duration": 5.921
    },
    {
      "lang": "en",
      "text": "you know is you are you know like kill",
      "offset": 1493.76,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "you right it may kill you. So you are",
      "offset": 1496.72,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "going to react very strongly. So I think",
      "offset": 1498.72,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "to start with whenever you are seeing",
      "offset": 1501.039,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "this kind of discussion you need to",
      "offset": 1503.12,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "discount the negative one because you as",
      "offset": 1505.44,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "a human you are going to be much more",
      "offset": 1508.4,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "prone to respond to that. Yeah. Right.",
      "offset": 1510.24,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "Just to keep a little bit objectivity",
      "offset": 1512.4,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "objectivity. Um the other thing I would",
      "offset": 1514.88,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "say is that I still do you know you're",
      "offset": 1517.76,
      "duration": 5.039
    },
    {
      "lang": "en",
      "text": "talking about and this was sben 47 last",
      "offset": 1519.44,
      "duration": 6.16
    },
    {
      "lang": "en",
      "text": "year and so forth. Um you are talking",
      "offset": 1522.799,
      "duration": 5.201
    },
    {
      "lang": "en",
      "text": "about think about the marginal risks",
      "offset": 1525.6,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "right? uh and marginal risk. It's about",
      "offset": 1528,
      "duration": 6.559
    },
    {
      "lang": "en",
      "text": "uh risk which are not present before but",
      "offset": 1531.36,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "they are enabled by this technology and",
      "offset": 1534.559,
      "duration": 5.281
    },
    {
      "lang": "en",
      "text": "right now I still still need to see real",
      "offset": 1536.88,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "marginal risk enabled by AI uh you know",
      "offset": 1539.84,
      "duration": 6.48
    },
    {
      "lang": "en",
      "text": "is it makes the risk exist the previous",
      "offset": 1542.64,
      "duration": 6.32
    },
    {
      "lang": "en",
      "text": "more prevalent they're making much worse",
      "offset": 1546.32,
      "duration": 6.16
    },
    {
      "lang": "en",
      "text": "maybe but if talk about you know uh deep",
      "offset": 1548.96,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "fake and so forth I mean you could do",
      "offset": 1552.48,
      "duration": 5.679
    },
    {
      "lang": "en",
      "text": "that before with Adobe and so forth and",
      "offset": 1554.96,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "impersonating people it's all the way",
      "offset": 1558.159,
      "duration": 6.161
    },
    {
      "lang": "en",
      "text": "from antiquity right so so that's one",
      "offset": 1560.96,
      "duration": 5.199
    },
    {
      "lang": "en",
      "text": "you know obviously it's like they speak",
      "offset": 1564.32,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "oh you you can tell you how to build a",
      "offset": 1566.159,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "bomb so first of all what it tells you",
      "offset": 1568.24,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "can make it maybe easier in the best",
      "offset": 1571.279,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "case scenario but if I am going to kind",
      "offset": 1572.88,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "of any library and so forth I should be",
      "offset": 1575.2,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "able to find that information if I am",
      "offset": 1577.039,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "determined so it makes this much easier",
      "offset": 1578.64,
      "duration": 5.039
    },
    {
      "lang": "en",
      "text": "maybe say 10 times easier maybe 100 time",
      "offset": 1581.12,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "easier but if you look at end to end",
      "offset": 1583.679,
      "duration": 5.201
    },
    {
      "lang": "en",
      "text": "what you need to do to apply to make",
      "offset": 1586.72,
      "duration": 4.959
    },
    {
      "lang": "en",
      "text": "that a reality. Acquiring the knowledge",
      "offset": 1588.88,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "it's like very little, right? Then you",
      "offset": 1591.679,
      "duration": 4.721
    },
    {
      "lang": "en",
      "text": "need to get the materials. You need to",
      "offset": 1594.08,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "assemble without anyone detected. You",
      "offset": 1596.4,
      "duration": 3.519
    },
    {
      "lang": "en",
      "text": "need to deliver that or something like",
      "offset": 1598.159,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "that. So if you look at the asan, that's",
      "offset": 1599.919,
      "duration": 4.961
    },
    {
      "lang": "en",
      "text": "kind of dominating. So yeah, I I'm the",
      "offset": 1602.48,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "10% of acquiring which was before I'm",
      "offset": 1604.88,
      "duration": 5.84
    },
    {
      "lang": "en",
      "text": "going to do it to 1% or 0.1%.",
      "offset": 1607.52,
      "duration": 5.84
    },
    {
      "lang": "en",
      "text": "Yeah, sure. But the rest is not going to",
      "offset": 1610.72,
      "duration": 4.559
    },
    {
      "lang": "en",
      "text": "get better, right? is like he's still",
      "offset": 1613.36,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "gay. So, so that's kind of um uh when",
      "offset": 1615.279,
      "duration": 4.481
    },
    {
      "lang": "en",
      "text": "when when you think at this kind of",
      "offset": 1618.4,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "level of details uh not details, it's um",
      "offset": 1619.76,
      "duration": 7.039
    },
    {
      "lang": "en",
      "text": "doesn't convince me that this exist",
      "offset": 1624,
      "duration": 4.559
    },
    {
      "lang": "en",
      "text": "existential risk and so forth. Of",
      "offset": 1626.799,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "course, everything you know there are",
      "offset": 1628.559,
      "duration": 5.521
    },
    {
      "lang": "en",
      "text": "things you cannot imagine. Granted, you",
      "offset": 1630.799,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "mentioned uh physical infrastructure as",
      "offset": 1634.08,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "one area where China is still lagging",
      "offset": 1636.159,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "and export controls are are a piece of",
      "offset": 1638.48,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "that and so forth. uh in the US",
      "offset": 1640.799,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "obviously in the west more broadly a",
      "offset": 1642.72,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "massive physical infrastructure buildout",
      "offset": 1644.88,
      "duration": 3.679
    },
    {
      "lang": "en",
      "text": "is underway and all of the big",
      "offset": 1647.12,
      "duration": 3.679
    },
    {
      "lang": "en",
      "text": "hyperscalers are pouring tens of",
      "offset": 1648.559,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "billions of dollars into building out",
      "offset": 1650.799,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "massive data centers 1 gawatt 5 gawatt",
      "offset": 1652.159,
      "duration": 6.321
    },
    {
      "lang": "en",
      "text": "data centers etc. Um, do you think that",
      "offset": 1654.88,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "like that's the right approach and that",
      "offset": 1658.48,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "that's a good good trend to be happening",
      "offset": 1660.4,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "in the US? Do you think there's some",
      "offset": 1662.32,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "risk of overbuilding infrastructure? I'm",
      "offset": 1663.6,
      "duration": 2.8
    },
    {
      "lang": "en",
      "text": "curious how you think about that over",
      "offset": 1665.44,
      "duration": 2.8
    },
    {
      "lang": "en",
      "text": "like I think overbuilding it's very",
      "offset": 1666.4,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "likely that will happen like with the",
      "offset": 1668.24,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "internet. Yep. That what happened with",
      "offset": 1669.6,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "the internet. We overbuild the internet",
      "offset": 1671.36,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "and a lot of companies who are",
      "offset": 1672.96,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "overbuilding it, you know, went under",
      "offset": 1674.96,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "and there were a lot of other companies",
      "offset": 1677.2,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "which really took advantage of that",
      "offset": 1680.08,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "infrastructure like you know Google and",
      "offset": 1681.6,
      "duration": 7.199
    },
    {
      "lang": "en",
      "text": "Amazon and so forth, right? So",
      "offset": 1684.96,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "probably very likely this is something",
      "offset": 1688.799,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "like this could happen now, right? It's",
      "offset": 1690.48,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "like clearly look it's is much easier to",
      "offset": 1692.159,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "get GPUs today than it was one year and",
      "offset": 1694.32,
      "duration": 4.719
    },
    {
      "lang": "en",
      "text": "a half ago. Okay, for one that's that's",
      "offset": 1696.32,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "a fact, right? I am not you know it's",
      "offset": 1699.039,
      "duration": 5.601
    },
    {
      "lang": "en",
      "text": "not about housings. Um but I do think",
      "offset": 1701.84,
      "duration": 6.079
    },
    {
      "lang": "en",
      "text": "that China is not going to you know it's",
      "offset": 1704.64,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "going to be two years three years I",
      "offset": 1707.919,
      "duration": 2.801
    },
    {
      "lang": "en",
      "text": "don't know it's like but they are going",
      "offset": 1709.44,
      "duration": 4.479
    },
    {
      "lang": "en",
      "text": "to build and the advantage is that you",
      "offset": 1710.72,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "know they have an economy which is in",
      "offset": 1713.919,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "the same ballpark I don't you know",
      "offset": 1716.32,
      "duration": 3.359
    },
    {
      "lang": "en",
      "text": "whatever numbers you look at with the US",
      "offset": 1717.6,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "economy right and the other thing what",
      "offset": 1719.679,
      "duration": 5.201
    },
    {
      "lang": "en",
      "text": "they do they they have the ability to",
      "offset": 1721.679,
      "duration": 6.801
    },
    {
      "lang": "en",
      "text": "fund strategic initiatives you know many",
      "offset": 1724.88,
      "duration": 6.56
    },
    {
      "lang": "en",
      "text": "many years decades if needed right so",
      "offset": 1728.48,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "that's kind of gives them maybe a",
      "offset": 1731.44,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "structural advantage there. Um so we'll",
      "offset": 1733.12,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "see we'll see but and also they have a",
      "offset": 1736.48,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "lot of experts and like we see deepseek",
      "offset": 1738.64,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "right they are going to you know do",
      "offset": 1740.72,
      "duration": 3.679
    },
    {
      "lang": "en",
      "text": "optimization at the lower level and some",
      "offset": 1742.64,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "people say oh yeah but you know they do",
      "offset": 1744.399,
      "duration": 5.121
    },
    {
      "lang": "en",
      "text": "that optimization if you force them to",
      "offset": 1747.039,
      "duration": 4.561
    },
    {
      "lang": "en",
      "text": "spend their intellectual cycles to do",
      "offset": 1749.52,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "that optimization sure but you have",
      "offset": 1751.6,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "enough resources it's going to work out",
      "offset": 1753.2,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "work out for you but you know look look",
      "offset": 1755.84,
      "duration": 6.4
    },
    {
      "lang": "en",
      "text": "at and and look you know this is also um",
      "offset": 1757.6,
      "duration": 6.959
    },
    {
      "lang": "en",
      "text": "always amazes me that people say Oh, you",
      "offset": 1762.24,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "know it's like this kind of belief which",
      "offset": 1764.559,
      "duration": 4.881
    },
    {
      "lang": "en",
      "text": "is confidence that we are always going",
      "offset": 1766.96,
      "duration": 7.28
    },
    {
      "lang": "en",
      "text": "to be ahead. But there are many many um",
      "offset": 1769.44,
      "duration": 6.4
    },
    {
      "lang": "en",
      "text": "high-tech",
      "offset": 1774.24,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "industries which we are no longer ready",
      "offset": 1775.84,
      "duration": 7.439
    },
    {
      "lang": "en",
      "text": "like uh solar cells, car batteries,",
      "offset": 1778.24,
      "duration": 6.799
    },
    {
      "lang": "en",
      "text": "drones,",
      "offset": 1783.279,
      "duration": 3.441
    },
    {
      "lang": "en",
      "text": "uh",
      "offset": 1785.039,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "electric cars,",
      "offset": 1786.72,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "um robot, you know, at least uh",
      "offset": 1788.64,
      "duration": 5.759
    },
    {
      "lang": "en",
      "text": "industrial robotics. Maybe transitioning",
      "offset": 1791.76,
      "duration": 6.08
    },
    {
      "lang": "en",
      "text": "topics slightly. Um you have co-founded",
      "offset": 1794.399,
      "duration": 5.601
    },
    {
      "lang": "en",
      "text": "and helped build many defining",
      "offset": 1797.84,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "infrastructure companies over the years",
      "offset": 1800,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "software infrastructure companies data",
      "offset": 1802.159,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "bricks any scale now LM Marina um aside",
      "offset": 1804.24,
      "duration": 5.679
    },
    {
      "lang": "en",
      "text": "from the evaluations topic which",
      "offset": 1808.159,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "obviously you guys are focusing on with",
      "offset": 1809.919,
      "duration": 4.561
    },
    {
      "lang": "en",
      "text": "the new company um what do you think the",
      "offset": 1811.279,
      "duration": 5.441
    },
    {
      "lang": "en",
      "text": "biggest opportunities and the most",
      "offset": 1814.48,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "important unsolved issues are at the",
      "offset": 1816.72,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "infrastructure layer for AI right now?",
      "offset": 1819.36,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "Again you look uh you look at the trends",
      "offset": 1821.52,
      "duration": 6.639
    },
    {
      "lang": "en",
      "text": "and and clearly right now what we see",
      "offset": 1824.32,
      "duration": 7.68
    },
    {
      "lang": "en",
      "text": "and every lab is doing um we are seeing",
      "offset": 1828.159,
      "duration": 6.721
    },
    {
      "lang": "en",
      "text": "a lot of um",
      "offset": 1832,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "the infrastructure evolving towards",
      "offset": 1834.88,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "being very you know vertical integrated",
      "offset": 1837.36,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "you know co-design across all the layers",
      "offset": 1839.6,
      "duration": 6.079
    },
    {
      "lang": "en",
      "text": "all the way from the application to",
      "offset": 1842.48,
      "duration": 5.439
    },
    {
      "lang": "en",
      "text": "the hardware and I think that we are",
      "offset": 1845.679,
      "duration": 5.041
    },
    {
      "lang": "en",
      "text": "going to see more and more on that uh",
      "offset": 1847.919,
      "duration": 4.721
    },
    {
      "lang": "en",
      "text": "that's And I'm going to say again based",
      "offset": 1850.72,
      "duration": 4.959
    },
    {
      "lang": "en",
      "text": "on the trends or I think there are",
      "offset": 1852.64,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "some opportunities sorry clearly what",
      "offset": 1855.679,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "what what what what what we are seeing",
      "offset": 1858.32,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "here right it's like one thing it's",
      "offset": 1859.919,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "about you have this kind of distributed",
      "offset": 1861.76,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "heterogeneous infrastructures right and",
      "offset": 1863.6,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "if anything you know you have at the",
      "offset": 1865.919,
      "duration": 5.601
    },
    {
      "lang": "en",
      "text": "accelerator level you have uh GPUs",
      "offset": 1868.24,
      "duration": 7.039
    },
    {
      "lang": "en",
      "text": "Nvidia and MD and you have many other",
      "offset": 1871.52,
      "duration": 7.2
    },
    {
      "lang": "en",
      "text": "accelerators like uh TPU tranium and",
      "offset": 1875.279,
      "duration": 6.321
    },
    {
      "lang": "en",
      "text": "others um then you have as the",
      "offset": 1878.72,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "networking right you have Ethernet you",
      "offset": 1881.6,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "have infiniband and then a little bit",
      "offset": 1884.24,
      "duration": 6.159
    },
    {
      "lang": "en",
      "text": "higher level RDMA um so you have a lot",
      "offset": 1887.12,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "of this and then collective",
      "offset": 1890.399,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "communication like nickel recl and so",
      "offset": 1892.72,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "forth uh so huge huge hairogenity so you",
      "offset": 1894.799,
      "duration": 8.161
    },
    {
      "lang": "en",
      "text": "need to master that um and the one thing",
      "offset": 1898.48,
      "duration": 6.4
    },
    {
      "lang": "en",
      "text": "I would say is that and there is quite a",
      "offset": 1902.96,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "bit of work I'm I I'm hopeful um it's",
      "offset": 1904.88,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "about automatically optimizing and",
      "offset": 1907.6,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "generating",
      "offset": 1909.76,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "optimized lowle code kernels right for",
      "offset": 1911.2,
      "duration": 5.359
    },
    {
      "lang": "en",
      "text": "this accelerators I think that's",
      "offset": 1914.24,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "hopefully it will it will happen so that",
      "offset": 1916.559,
      "duration": 6.321
    },
    {
      "lang": "en",
      "text": "will help help us um support much easier",
      "offset": 1919.2,
      "duration": 8.319
    },
    {
      "lang": "en",
      "text": "newies and optimize for most a large",
      "offset": 1922.88,
      "duration": 8.399
    },
    {
      "lang": "en",
      "text": "variety of hardware and networking I",
      "offset": 1927.519,
      "duration": 6.4
    },
    {
      "lang": "en",
      "text": "think that it's going to see a lot of",
      "offset": 1931.279,
      "duration": 4.481
    },
    {
      "lang": "en",
      "text": "more optimization at the intersection",
      "offset": 1933.919,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "between networking and compute",
      "offset": 1935.76,
      "duration": 6.24
    },
    {
      "lang": "en",
      "text": "right fine grain in uh overlapping the",
      "offset": 1938.399,
      "duration": 5.201
    },
    {
      "lang": "en",
      "text": "communication with computation and so",
      "offset": 1942,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "forth obviously load balancing is going",
      "offset": 1943.6,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "to be very important. Um so so that's",
      "offset": 1945.6,
      "duration": 6.959
    },
    {
      "lang": "en",
      "text": "one and when you look about",
      "offset": 1949.36,
      "duration": 6.64
    },
    {
      "lang": "en",
      "text": "in order to optimize this kind of models",
      "offset": 1952.559,
      "duration": 5.84
    },
    {
      "lang": "en",
      "text": "and workloads",
      "offset": 1956,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "it's it's so complicated right it's like",
      "offset": 1958.399,
      "duration": 5.841
    },
    {
      "lang": "en",
      "text": "uh if you have if you look at this kind",
      "offset": 1961.44,
      "duration": 6.32
    },
    {
      "lang": "en",
      "text": "of parallelism like for model model",
      "offset": 1964.24,
      "duration": 6.159
    },
    {
      "lang": "en",
      "text": "serving and and training you have the",
      "offset": 1967.76,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "last time I was looking it was like",
      "offset": 1970.399,
      "duration": 5.201
    },
    {
      "lang": "en",
      "text": "seven you know model data paralle model",
      "offset": 1972.08,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "parallels or tensor paral",
      "offset": 1975.6,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "pipeline parallelism um context",
      "offset": 1977.76,
      "duration": 5.759
    },
    {
      "lang": "en",
      "text": "parallelism and um and the token",
      "offset": 1980.48,
      "duration": 7.28
    },
    {
      "lang": "en",
      "text": "parallelism and expert parallelism um",
      "offset": 1983.519,
      "duration": 6.16
    },
    {
      "lang": "en",
      "text": "sequence parallelism I forgot so I think",
      "offset": 1987.76,
      "duration": 5.279
    },
    {
      "lang": "en",
      "text": "these are seven um so it it's you know",
      "offset": 1989.679,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "it's like you need to do this in",
      "offset": 1993.039,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "automated way right um because there are",
      "offset": 1994.399,
      "duration": 7.201
    },
    {
      "lang": "en",
      "text": "too many and then are very fine grain",
      "offset": 1998.159,
      "duration": 4.961
    },
    {
      "lang": "en",
      "text": "again between communication and",
      "offset": 2001.6,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "computation because you are you you want",
      "offset": 2003.12,
      "duration": 3.039
    },
    {
      "lang": "en",
      "text": "to overlap the computation with",
      "offset": 2004.72,
      "duration": 2.319
    },
    {
      "lang": "en",
      "text": "communication",
      "offset": 2006.159,
      "duration": 4.561
    },
    {
      "lang": "en",
      "text": "to increase utilization of",
      "offset": 2007.039,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "GPUs. Obviously, we'll see what happens",
      "offset": 2010.72,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "at the agentic level.",
      "offset": 2013.039,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "Yeah. What do you think the uh like",
      "offset": 2015.84,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "infrastructure needs will end up being",
      "offset": 2018.399,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "for uh for agents? I feel like there's",
      "offset": 2019.84,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "been some early attempts at broad",
      "offset": 2021.519,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "frameworks at other you know air sorts",
      "offset": 2023.36,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "areas. It feels like the model companies",
      "offset": 2025.36,
      "duration": 2.96
    },
    {
      "lang": "en",
      "text": "themselves are building lots of things.",
      "offset": 2026.48,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "It's hard because when you have a field",
      "offset": 2028.32,
      "duration": 6.32
    },
    {
      "lang": "en",
      "text": "which is so um",
      "offset": 2030.96,
      "duration": 9.04
    },
    {
      "lang": "en",
      "text": "move so fast it's very hard to come with",
      "offset": 2034.64,
      "duration": 8.879
    },
    {
      "lang": "en",
      "text": "good frameworks and which are going to",
      "offset": 2040,
      "duration": 5.679
    },
    {
      "lang": "en",
      "text": "be stable over time right because it's",
      "offset": 2043.519,
      "duration": 6.801
    },
    {
      "lang": "en",
      "text": "just um the needs you know change every",
      "offset": 2045.679,
      "duration": 7.761
    },
    {
      "lang": "en",
      "text": "mass every week every day right so that",
      "offset": 2050.32,
      "duration": 4.559
    },
    {
      "lang": "en",
      "text": "kind of makes it difficult so I think",
      "offset": 2053.44,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "this will be typically when you start to",
      "offset": 2054.879,
      "duration": 6.161
    },
    {
      "lang": "en",
      "text": "build good frameworks or good um",
      "offset": 2057.52,
      "duration": 7.599
    },
    {
      "lang": "en",
      "text": "software abstractions is when the the",
      "offset": 2061.04,
      "duration": 7.119
    },
    {
      "lang": "en",
      "text": "speed of evolution of the at the",
      "offset": 2065.119,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "application level it's a little is is",
      "offset": 2068.159,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "kind of slowing down. Is that ever going",
      "offset": 2070.639,
      "duration": 5.601
    },
    {
      "lang": "en",
      "text": "to happen given model progress? Yeah.",
      "offset": 2072.399,
      "duration": 6.96
    },
    {
      "lang": "en",
      "text": "Well, you know, it's like look um the",
      "offset": 2076.24,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "different layers it does happen. I mean",
      "offset": 2079.359,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "it's like now everyone is using",
      "offset": 2081.52,
      "duration": 4.639
    },
    {
      "lang": "en",
      "text": "transformers, everyone is using like",
      "offset": 2083.76,
      "duration": 5.919
    },
    {
      "lang": "en",
      "text": "kind of PyTorch right almost there are",
      "offset": 2086.159,
      "duration": 6.48
    },
    {
      "lang": "en",
      "text": "things like um",
      "offset": 2089.679,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "we are using right now uh you know when",
      "offset": 2092.639,
      "duration": 4.641
    },
    {
      "lang": "en",
      "text": "you talk about inference we are using",
      "offset": 2095.679,
      "duration": 4.721
    },
    {
      "lang": "en",
      "text": "open AAI API more or less. So yeah I",
      "offset": 2097.28,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "think there are you you are seeing that",
      "offset": 2100.4,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "you're kind of the standardization is a",
      "offset": 2102.64,
      "duration": 6.16
    },
    {
      "lang": "en",
      "text": "low level. Um if you look about um for",
      "offset": 2104.32,
      "duration": 7.279
    },
    {
      "lang": "en",
      "text": "instance a lot of um",
      "offset": 2108.8,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "new post training frameworks every day",
      "offset": 2111.599,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "you get another one but most of them are",
      "offset": 2113.28,
      "duration": 7.52
    },
    {
      "lang": "en",
      "text": "built uh on ray blm and maybe you know",
      "offset": 2115.28,
      "duration": 8.96
    },
    {
      "lang": "en",
      "text": "agilang also yeah so I think you you see",
      "offset": 2120.8,
      "duration": 5.279
    },
    {
      "lang": "en",
      "text": "at different points some kind of",
      "offset": 2124.24,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "standardization",
      "offset": 2126.079,
      "duration": 4.721
    },
    {
      "lang": "en",
      "text": "uh but it's still it's",
      "offset": 2128.079,
      "duration": 4.801
    },
    {
      "lang": "en",
      "text": "pretty late dispersed since the you know",
      "offset": 2130.8,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "generative AI explosion I feel like it",
      "offset": 2132.88,
      "duration": 2.479
    },
    {
      "lang": "en",
      "text": "was this you",
      "offset": 2134.32,
      "duration": 2.64
    },
    {
      "lang": "en",
      "text": "huge moment for data bricks and in many",
      "offset": 2135.359,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "ways um you guys have kind of met it",
      "offset": 2136.96,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "head on. Um reflecting back maybe on the",
      "offset": 2138.96,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "last two and a half years like what do",
      "offset": 2141.359,
      "duration": 2.961
    },
    {
      "lang": "en",
      "text": "you think the company got like most",
      "offset": 2143.119,
      "duration": 2.72
    },
    {
      "lang": "en",
      "text": "right in the kind of immediate post",
      "offset": 2144.32,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "chatb moment and then maybe if you could",
      "offset": 2145.839,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "do it over again something you might",
      "offset": 2148.16,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "have done differently. So I think that",
      "offset": 2149.359,
      "duration": 5.681
    },
    {
      "lang": "en",
      "text": "one thing was um you got right it's",
      "offset": 2151.52,
      "duration": 7.599
    },
    {
      "lang": "en",
      "text": "about the data is as important as ever",
      "offset": 2155.04,
      "duration": 8
    },
    {
      "lang": "en",
      "text": "right so getting access to all your data",
      "offset": 2159.119,
      "duration": 5.681
    },
    {
      "lang": "en",
      "text": "in a",
      "offset": 2163.04,
      "duration": 5.92
    },
    {
      "lang": "en",
      "text": "seamless and performant way while having",
      "offset": 2164.8,
      "duration": 8.72
    },
    {
      "lang": "en",
      "text": "all the uh governance on top is very",
      "offset": 2168.96,
      "duration": 6.72
    },
    {
      "lang": "en",
      "text": "important right and this is what we've",
      "offset": 2173.52,
      "duration": 4.559
    },
    {
      "lang": "en",
      "text": "done with lakehouse now with the unity",
      "offset": 2175.68,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "catalog I think that's the key Because",
      "offset": 2178.079,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "if you are a company, an enterprise, a",
      "offset": 2180,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "large enterprise, you are going to have",
      "offset": 2181.839,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "the data in a myriad of storage right",
      "offset": 2184,
      "duration": 7.44
    },
    {
      "lang": "en",
      "text": "legacy or newer you know like used to be",
      "offset": 2187.119,
      "duration": 7.921
    },
    {
      "lang": "en",
      "text": "um data links and things like that. So",
      "offset": 2191.44,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "having access uniformly accessing the",
      "offset": 2195.04,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "data uh and not only that to have the",
      "offset": 2197.44,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "metadata associated with the data you",
      "offset": 2200.4,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "are going to access is super super",
      "offset": 2202.56,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "important. Okay. So I think that was",
      "offset": 2204.88,
      "duration": 6.56
    },
    {
      "lang": "en",
      "text": "that was uh right and you see even today",
      "offset": 2208.32,
      "duration": 6.16
    },
    {
      "lang": "en",
      "text": "it's that's why you know the our",
      "offset": 2211.44,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "our main conference is called data plus",
      "offset": 2214.48,
      "duration": 6.879
    },
    {
      "lang": "en",
      "text": "AI right data intelligence is a new um",
      "offset": 2216.56,
      "duration": 9.2
    },
    {
      "lang": "en",
      "text": "is a new category um so and you you'll",
      "offset": 2221.359,
      "duration": 7.281
    },
    {
      "lang": "en",
      "text": "see still it's it's it's a huge push in",
      "offset": 2225.76,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "that direction um I think the other one",
      "offset": 2228.64,
      "duration": 6.959
    },
    {
      "lang": "en",
      "text": "it's about um also after acquiring",
      "offset": 2231.76,
      "duration": 7.359
    },
    {
      "lang": "en",
      "text": "mosaic and of ours um we are very early",
      "offset": 2235.599,
      "duration": 8.721
    },
    {
      "lang": "en",
      "text": "on very aggressively pursuing um um AI",
      "offset": 2239.119,
      "duration": 7.281
    },
    {
      "lang": "en",
      "text": "for enterprises right and it's it's",
      "offset": 2244.32,
      "duration": 3.279
    },
    {
      "lang": "en",
      "text": "perfect right because you have",
      "offset": 2246.4,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "enterprise they have the data uh in",
      "offset": 2247.599,
      "duration": 6.321
    },
    {
      "lang": "en",
      "text": "general their data it's one of their big",
      "offset": 2249.92,
      "duration": 8.08
    },
    {
      "lang": "en",
      "text": "um uh crown jewel right it's like it's",
      "offset": 2253.92,
      "duration": 8
    },
    {
      "lang": "en",
      "text": "unique and then you help them to um",
      "offset": 2258,
      "duration": 6.96
    },
    {
      "lang": "en",
      "text": "extract a lot of value from the data and",
      "offset": 2261.92,
      "duration": 6.08
    },
    {
      "lang": "en",
      "text": "build new products powered by I AI on",
      "offset": 2264.96,
      "duration": 6.32
    },
    {
      "lang": "en",
      "text": "the data right so that's one one thing",
      "offset": 2268,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "now the one thing I want to mention here",
      "offset": 2271.28,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "is that",
      "offset": 2273.28,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "um and people may not realize that but",
      "offset": 2275.359,
      "duration": 8.641
    },
    {
      "lang": "en",
      "text": "um this AI was in the in in uh in it's",
      "offset": 2278.8,
      "duration": 7.92
    },
    {
      "lang": "en",
      "text": "it's in the DNA of datab bricks when we",
      "offset": 2284,
      "duration": 6.4
    },
    {
      "lang": "en",
      "text": "started datab bricks um with with spark",
      "offset": 2286.72,
      "duration": 7.92
    },
    {
      "lang": "en",
      "text": "um um um one of the main libraries on",
      "offset": 2290.4,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "top of spark of machine learning",
      "offset": 2294.64,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "library. It was ML and then Spark ML and",
      "offset": 2295.92,
      "duration": 6.72
    },
    {
      "lang": "en",
      "text": "um it was of course it wasn't deep",
      "offset": 2300.16,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "learning at that stage. It was classic",
      "offset": 2302.64,
      "duration": 3.439
    },
    {
      "lang": "en",
      "text": "machine learning random forest and",
      "offset": 2304.4,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "linear regression and things like that.",
      "offset": 2306.079,
      "duration": 4.801
    },
    {
      "lang": "en",
      "text": "But that's one and even early customers",
      "offset": 2307.92,
      "duration": 6.48
    },
    {
      "lang": "en",
      "text": "actually were were buying data bricks um",
      "offset": 2310.88,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "you know product and spark because they",
      "offset": 2314.4,
      "duration": 5.199
    },
    {
      "lang": "en",
      "text": "wanted to do AI right early on. So it's",
      "offset": 2316.56,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "coming in some sense full circle but I",
      "offset": 2319.599,
      "duration": 6.641
    },
    {
      "lang": "en",
      "text": "think you know that's um um I think",
      "offset": 2322.16,
      "duration": 7.439
    },
    {
      "lang": "en",
      "text": "uh you know um it's hard to know what",
      "offset": 2326.24,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "you we would have done differently of",
      "offset": 2329.599,
      "duration": 5.121
    },
    {
      "lang": "en",
      "text": "course we we tried to build the you know",
      "offset": 2331.44,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "we built and it was a pretty high",
      "offset": 2334.72,
      "duration": 6.32
    },
    {
      "lang": "en",
      "text": "performance model uh dicks right so if",
      "offset": 2337.2,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "you go back whether you are going to do",
      "offset": 2341.04,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "that again it's a question given the",
      "offset": 2342.48,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "power you given how many powerful",
      "offset": 2344.96,
      "duration": 4.879
    },
    {
      "lang": "en",
      "text": "open-source models have been released Of",
      "offset": 2347.2,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "course I cannot talk about everything",
      "offset": 2349.839,
      "duration": 6.721
    },
    {
      "lang": "en",
      "text": "here but I think we did um for the last",
      "offset": 2352.24,
      "duration": 8.64
    },
    {
      "lang": "en",
      "text": "two years and so forth I think that um I",
      "offset": 2356.56,
      "duration": 6.48
    },
    {
      "lang": "en",
      "text": "don't think I will go back I I would go",
      "offset": 2360.88,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "back and say we should have done",
      "offset": 2363.04,
      "duration": 3.039
    },
    {
      "lang": "en",
      "text": "differently and of course we need to",
      "offset": 2364.88,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "talk with Ali and so forth much better",
      "offset": 2366.079,
      "duration": 4.961
    },
    {
      "lang": "en",
      "text": "than I know and he will be better to",
      "offset": 2368.48,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "answer his questions. You're so close to",
      "offset": 2371.04,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "all this you know cutting edge stuff in",
      "offset": 2373.2,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "the AI world. What's one thing you've",
      "offset": 2374.72,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "changed your mind on in the last year?",
      "offset": 2376.56,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "Maybe the way I would answer the",
      "offset": 2378.24,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "question what things are I thought will",
      "offset": 2379.92,
      "duration": 5.84
    },
    {
      "lang": "en",
      "text": "happen and didn't happen and by",
      "offset": 2382.32,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "definition you'll change a little bit",
      "offset": 2385.76,
      "duration": 5.599
    },
    {
      "lang": "en",
      "text": "your mind on that. Um I thought that um",
      "offset": 2387.04,
      "duration": 8.24
    },
    {
      "lang": "en",
      "text": "we are going to see more alternative to",
      "offset": 2391.359,
      "duration": 7.201
    },
    {
      "lang": "en",
      "text": "Nvidia more right and we haven't seen",
      "offset": 2395.28,
      "duration": 6.88
    },
    {
      "lang": "en",
      "text": "that yet. Uh that's number that's one.",
      "offset": 2398.56,
      "duration": 7.279
    },
    {
      "lang": "en",
      "text": "Um the other thing I was pleasantly",
      "offset": 2402.16,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "surprised by the progress of the open",
      "offset": 2405.839,
      "duration": 6.721
    },
    {
      "lang": "en",
      "text": "source now this came from where I",
      "offset": 2407.68,
      "duration": 6.64
    },
    {
      "lang": "en",
      "text": "maybe one more than one year ago I",
      "offset": 2412.56,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "haven't expected you know came more from",
      "offset": 2414.32,
      "duration": 5.519
    },
    {
      "lang": "en",
      "text": "China rather than uh US I thought that",
      "offset": 2416.24,
      "duration": 6.4
    },
    {
      "lang": "en",
      "text": "we'll make",
      "offset": 2419.839,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "more progress on reliability",
      "offset": 2422.64,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "hallucination and so forth but that",
      "offset": 2425.839,
      "duration": 4.561
    },
    {
      "lang": "en",
      "text": "still remain a problem uh especially",
      "offset": 2427.76,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "with the reasoning models I think that",
      "offset": 2430.4,
      "duration": 5.439
    },
    {
      "lang": "en",
      "text": "uh certainly reasoning models are",
      "offset": 2433.04,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "probably more effective than not",
      "offset": 2435.839,
      "duration": 3.121
    },
    {
      "lang": "en",
      "text": "reasoning post training was more",
      "offset": 2437.359,
      "duration": 4.561
    },
    {
      "lang": "en",
      "text": "effective uh than I thought and one",
      "offset": 2438.96,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "particular thing which okay one I I know",
      "offset": 2441.92,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "now one one thing I changed my mind I",
      "offset": 2444.72,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "was not very",
      "offset": 2447.28,
      "duration": 6.64
    },
    {
      "lang": "en",
      "text": "bigger early on on uh quantization",
      "offset": 2450.16,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "because I saw that everyone you know",
      "offset": 2453.92,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "like uh people quantization makes a",
      "offset": 2455.76,
      "duration": 6.079
    },
    {
      "lang": "en",
      "text": "tradeoff right it's like a little bit",
      "offset": 2458.64,
      "duration": 7.04
    },
    {
      "lang": "en",
      "text": "hit the performance uh to provide you uh",
      "offset": 2461.839,
      "duration": 7.201
    },
    {
      "lang": "en",
      "text": "better efficiency or um and I thought",
      "offset": 2465.68,
      "duration": 5.439
    },
    {
      "lang": "en",
      "text": "that people will not be willing to do to",
      "offset": 2469.04,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "make that trade-off but that's",
      "offset": 2471.119,
      "duration": 4.881
    },
    {
      "lang": "en",
      "text": "um",
      "offset": 2474.4,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "there and quantization without question",
      "offset": 2476,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "is very he's been very successful and a",
      "offset": 2477.92,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "game changer. Yeah, there's a lot in",
      "offset": 2479.76,
      "duration": 2.88
    },
    {
      "lang": "en",
      "text": "there that you said that's interesting.",
      "offset": 2481.68,
      "duration": 2.159
    },
    {
      "lang": "en",
      "text": "I mean I guess to go back to your first",
      "offset": 2482.64,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "one like do you still think over time",
      "offset": 2483.839,
      "duration": 3.441
    },
    {
      "lang": "en",
      "text": "you know in the next few years there",
      "offset": 2486.16,
      "duration": 2.88
    },
    {
      "lang": "en",
      "text": "does emerge real challenggers to Nvidia",
      "offset": 2487.28,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "or like has what's happened over the",
      "offset": 2489.04,
      "duration": 2.72
    },
    {
      "lang": "en",
      "text": "last year changed your mind on the",
      "offset": 2490.48,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "viability of that? I think there could",
      "offset": 2491.76,
      "duration": 6.319
    },
    {
      "lang": "en",
      "text": "be for you know it's",
      "offset": 2493.52,
      "duration": 6.72
    },
    {
      "lang": "en",
      "text": "certainly you know probably China will",
      "offset": 2498.079,
      "duration": 4.721
    },
    {
      "lang": "en",
      "text": "put a lot of effort and Huawei to",
      "offset": 2500.24,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "because they don't have any other choice",
      "offset": 2502.8,
      "duration": 6.24
    },
    {
      "lang": "en",
      "text": "if um things do not change otherwise in",
      "offset": 2504.56,
      "duration": 6.72
    },
    {
      "lang": "en",
      "text": "the export control get worse or",
      "offset": 2509.04,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "something like that",
      "offset": 2511.28,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "that could happen. I think that yeah and",
      "offset": 2513.2,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "I think that clearly we see a lot of",
      "offset": 2515.28,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "investments. Google always invested on",
      "offset": 2517.04,
      "duration": 6.96
    },
    {
      "lang": "en",
      "text": "TPOS then uh AWS makes a lot of effort",
      "offset": 2519.359,
      "duration": 7.521
    },
    {
      "lang": "en",
      "text": "on Tranium and then AMD",
      "offset": 2524,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "um very good hardware. I think the",
      "offset": 2526.88,
      "duration": 5.84
    },
    {
      "lang": "en",
      "text": "biggest challenge as you know is like is",
      "offset": 2529.76,
      "duration": 7.12
    },
    {
      "lang": "en",
      "text": "software the software stuck right",
      "offset": 2532.72,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "one of the biggest challenges. We'll",
      "offset": 2536.88,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "see. I'm hope hopeful because you know",
      "offset": 2538.72,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "it's like it's u obviously from this at",
      "offset": 2540.96,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "the softer layer it's like well you",
      "offset": 2543.44,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "never know like on one hand if you have",
      "offset": 2545.2,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "a lot of more choices you need to put a",
      "offset": 2547.359,
      "duration": 3.121
    },
    {
      "lang": "en",
      "text": "lot more effort in the software to use",
      "offset": 2549.04,
      "duration": 2.96
    },
    {
      "lang": "en",
      "text": "these different choices. Continuing with",
      "offset": 2550.48,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "the with the crystal ball gazing a",
      "offset": 2552,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "little bit here. I'm curious to hear",
      "offset": 2553.68,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "what what's your view on our current",
      "offset": 2555.04,
      "duration": 6.079
    },
    {
      "lang": "en",
      "text": "trajectory toward super intelligence AGI",
      "offset": 2558,
      "duration": 5.839
    },
    {
      "lang": "en",
      "text": "timeline there if it's even a coherent",
      "offset": 2561.119,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "concept. How do you think about that",
      "offset": 2563.839,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "debate? You know I used to joke that",
      "offset": 2565.2,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "with AGI everyone will be right because",
      "offset": 2568.319,
      "duration": 4.481
    },
    {
      "lang": "en",
      "text": "they have no good definition right so I",
      "offset": 2570.24,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "said I am right because what I call I",
      "offset": 2572.8,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "said is AGI right I don't know is like",
      "offset": 2575.04,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "it's and this is that and what is AGI",
      "offset": 2577.76,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "like what people say is that you have",
      "offset": 2580.8,
      "duration": 6.16
    },
    {
      "lang": "en",
      "text": "one artifact that is going to um do",
      "offset": 2582.96,
      "duration": 6.24
    },
    {
      "lang": "en",
      "text": "majority of task better than humans",
      "offset": 2586.96,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "right um but how that artifact will be",
      "offset": 2589.2,
      "duration": 4.879
    },
    {
      "lang": "en",
      "text": "built I can you can build even probably",
      "offset": 2592,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "today something like that or maybe very",
      "offset": 2594.079,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "few years but I don't think that",
      "offset": 2596,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "intuitively what people mean by uh art",
      "offset": 2597.92,
      "duration": 5.84
    },
    {
      "lang": "en",
      "text": "you know AGI uh but but if you look",
      "offset": 2600.88,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "historically right there are you know",
      "offset": 2603.76,
      "duration": 5.359
    },
    {
      "lang": "en",
      "text": "it's like there are an increasing number",
      "offset": 2606,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "of tasks at which computers are better",
      "offset": 2609.119,
      "duration": 3.521
    },
    {
      "lang": "en",
      "text": "than humans",
      "offset": 2610.96,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "right think about calculators right that",
      "offset": 2612.64,
      "duration": 5.439
    },
    {
      "lang": "en",
      "text": "was 70s or 60 right they are better than",
      "offset": 2615.2,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "humans for a long time right then",
      "offset": 2618.079,
      "duration": 5.921
    },
    {
      "lang": "en",
      "text": "playing games right it's like",
      "offset": 2620.48,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "um",
      "offset": 2624,
      "duration": 5.599
    },
    {
      "lang": "en",
      "text": "uh chess, right? It was DBL 97 or",
      "offset": 2625.68,
      "duration": 8.88
    },
    {
      "lang": "en",
      "text": "something and then it was obviously go",
      "offset": 2629.599,
      "duration": 8.561
    },
    {
      "lang": "en",
      "text": "2017 and now you have kind of more",
      "offset": 2634.56,
      "duration": 6.799
    },
    {
      "lang": "en",
      "text": "imageet. It was for a lot convolution",
      "offset": 2638.16,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "networks for recognizing",
      "offset": 2641.359,
      "duration": 5.201
    },
    {
      "lang": "en",
      "text": "uh image recognition which is arguably",
      "offset": 2643.92,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "better than humans. So you always have",
      "offset": 2646.56,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "these kind of things which are going to",
      "offset": 2648.8,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "add up right maybe you're going to",
      "offset": 2650.24,
      "duration": 7.359
    },
    {
      "lang": "en",
      "text": "proofs and so forth. Uh so",
      "offset": 2653.28,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "you know you're going to have more and",
      "offset": 2657.599,
      "duration": 2.961
    },
    {
      "lang": "en",
      "text": "more task at which computers are better",
      "offset": 2658.8,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "than humans and you can package them in",
      "offset": 2660.56,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "one artifact and depending on the task",
      "offset": 2662.64,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "you can invoke different things under",
      "offset": 2664.88,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "the hood but from the user perspective",
      "offset": 2667.2,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "is the same. um although people you know",
      "offset": 2669.92,
      "duration": 6.399
    },
    {
      "lang": "en",
      "text": "that some of them will not call that AGI",
      "offset": 2673.2,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "but one thing I say so I'm I'm not going",
      "offset": 2676.319,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "to I I don't know right but one thing I",
      "offset": 2678.4,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "were going to say is that what you see",
      "offset": 2681.119,
      "duration": 3.441
    },
    {
      "lang": "en",
      "text": "there and this goes back to the",
      "offset": 2682.64,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "discussion about reliability a little",
      "offset": 2684.56,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "bit what you see progress you see",
      "offset": 2686.16,
      "duration": 7.04
    },
    {
      "lang": "en",
      "text": "progress where you have uh good",
      "offset": 2689.2,
      "duration": 6.24
    },
    {
      "lang": "en",
      "text": "validation good test for the answers you",
      "offset": 2693.2,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "have ground truth",
      "offset": 2695.44,
      "duration": 6.639
    },
    {
      "lang": "en",
      "text": "that's what you see okay um like like",
      "offset": 2697.599,
      "duration": 6.801
    },
    {
      "lang": "en",
      "text": "you're talking calculator right it's",
      "offset": 2702.079,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "like you know like it's only one right",
      "offset": 2704.4,
      "duration": 5.84
    },
    {
      "lang": "en",
      "text": "answer uh if you look at games it's very",
      "offset": 2706.24,
      "duration": 6.48
    },
    {
      "lang": "en",
      "text": "easy to test whether",
      "offset": 2710.24,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "uh you are successful or not you win or",
      "offset": 2712.72,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "lose it's also the rules are pretty",
      "offset": 2714.4,
      "duration": 5.84
    },
    {
      "lang": "en",
      "text": "clear yeah right uh if you think even",
      "offset": 2717.04,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "reasoning models where are they more",
      "offset": 2720.24,
      "duration": 6.079
    },
    {
      "lang": "en",
      "text": "successful right problem solving coding",
      "offset": 2722.48,
      "duration": 6.32
    },
    {
      "lang": "en",
      "text": "coding is this is natural shouldn't be a",
      "offset": 2726.319,
      "duration": 5.121
    },
    {
      "lang": "en",
      "text": "surprise Because if I if I look forget",
      "offset": 2728.8,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "about you know computers if you look",
      "offset": 2731.44,
      "duration": 5.679
    },
    {
      "lang": "en",
      "text": "where the progress was done in the",
      "offset": 2734.16,
      "duration": 6.8
    },
    {
      "lang": "en",
      "text": "history of humanity just over the past",
      "offset": 2737.119,
      "duration": 6.321
    },
    {
      "lang": "en",
      "text": "you know say 200 years where did it",
      "offset": 2740.96,
      "duration": 5.84
    },
    {
      "lang": "en",
      "text": "happen in sciences engineering when you",
      "offset": 2743.44,
      "duration": 5.919
    },
    {
      "lang": "en",
      "text": "have measurable outcomes",
      "offset": 2746.8,
      "duration": 5.519
    },
    {
      "lang": "en",
      "text": "right chemistry mechanical engineering",
      "offset": 2749.359,
      "duration": 6.401
    },
    {
      "lang": "en",
      "text": "electrical engineering um physics and so",
      "offset": 2752.319,
      "duration": 6.161
    },
    {
      "lang": "en",
      "text": "forth right you sort of the pro right",
      "offset": 2755.76,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "there's a word in front for these",
      "offset": 2758.48,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "sciences is today very different than",
      "offset": 2760.16,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "200 years ago. Yeah. Where things are",
      "offset": 2762,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "not as measurable",
      "offset": 2764.64,
      "duration": 6.64
    },
    {
      "lang": "en",
      "text": "like uh novels, books, writing, creative",
      "offset": 2766.72,
      "duration": 7.119
    },
    {
      "lang": "en",
      "text": "writing, right? Arguably you don't see",
      "offset": 2771.28,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "the same progress. Actually, some people",
      "offset": 2773.839,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "will argue the other way around. Right?",
      "offset": 2775.599,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "So that's kind of what I want to say. So",
      "offset": 2778.319,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "this is so this what I'm trying to say",
      "offset": 2780,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "is that I think that we are going to see",
      "offset": 2781.599,
      "duration": 5.201
    },
    {
      "lang": "en",
      "text": "continuously for the measurable the you",
      "offset": 2783.52,
      "duration": 5.839
    },
    {
      "lang": "en",
      "text": "know the task or use cases measurable",
      "offset": 2786.8,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "outcome you are going to see very rapid",
      "offset": 2789.359,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "progress but for the other one it will",
      "offset": 2791.2,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "be",
      "offset": 2793.2,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "more subjective whatever yeah do you",
      "offset": 2794.8,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "think we'll see a proliferation of what",
      "offset": 2796.72,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "measurable tasks are I mean obviously a",
      "offset": 2798.48,
      "duration": 2.879
    },
    {
      "lang": "en",
      "text": "lot of people in the lab seem to think",
      "offset": 2800.24,
      "duration": 3.599
    },
    {
      "lang": "en",
      "text": "you can build reward models for almost",
      "offset": 2801.359,
      "duration": 5.121
    },
    {
      "lang": "en",
      "text": "any domain yes but there are things",
      "offset": 2803.839,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "which are going to be more called kind",
      "offset": 2806.48,
      "duration": 5.599
    },
    {
      "lang": "en",
      "text": "of objective what is true or false right",
      "offset": 2809.839,
      "duration": 4.561
    },
    {
      "lang": "en",
      "text": "you can have formal specification and so",
      "offset": 2812.079,
      "duration": 5.841
    },
    {
      "lang": "en",
      "text": "forth um and and things which are going",
      "offset": 2814.4,
      "duration": 7.12
    },
    {
      "lang": "en",
      "text": "to be more subjective right and because",
      "offset": 2817.92,
      "duration": 5.919
    },
    {
      "lang": "en",
      "text": "what is a good book right how you are",
      "offset": 2821.52,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "going to do develop a your model for",
      "offset": 2823.839,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "that that's why I think that you may",
      "offset": 2826.48,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "have you know your personal model maybe",
      "offset": 2829.119,
      "duration": 4.801
    },
    {
      "lang": "en",
      "text": "you can someone write a book for your",
      "offset": 2831.44,
      "duration": 6.32
    },
    {
      "lang": "en",
      "text": "model right your own model um so yeah",
      "offset": 2833.92,
      "duration": 6.08
    },
    {
      "lang": "en",
      "text": "you are going to do but reward models",
      "offset": 2837.76,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "are not as efficient as I said, right?",
      "offset": 2840,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "Like for instance, if you have even for",
      "offset": 2842.079,
      "duration": 4.961
    },
    {
      "lang": "en",
      "text": "um",
      "offset": 2844.8,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "say you you you build you know so you do",
      "offset": 2847.04,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "you you solve mass problems and you can",
      "offset": 2849.44,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "use to have a models to kind of learn",
      "offset": 2852.24,
      "duration": 9.04
    },
    {
      "lang": "en",
      "text": "what is good or bad uh uh result and now",
      "offset": 2855.04,
      "duration": 8.96
    },
    {
      "lang": "en",
      "text": "you compare that if you have the ground",
      "offset": 2861.28,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "truth. I know this results the correct",
      "offset": 2864,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "results right",
      "offset": 2866.72,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "um if you have the ground truth it's",
      "offset": 2868.8,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "much more efficient maybe one or",
      "offset": 2871.44,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "magnitude more efficient in terms of the",
      "offset": 2874.24,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "compute to get to a particular accuracy",
      "offset": 2876.56,
      "duration": 7.6
    },
    {
      "lang": "en",
      "text": "for whatever benchmarks am or whatever",
      "offset": 2879.76,
      "duration": 6.16
    },
    {
      "lang": "en",
      "text": "problem solving this is almost a",
      "offset": 2884.16,
      "duration": 3.679
    },
    {
      "lang": "en",
      "text": "philosophical question but within the",
      "offset": 2885.92,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "hard sciences which are verifiable do",
      "offset": 2887.839,
      "duration": 4.801
    },
    {
      "lang": "en",
      "text": "you think that the the current paradigm",
      "offset": 2890.64,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "of AI that we're in It's possible for AI",
      "offset": 2892.64,
      "duration": 6.24
    },
    {
      "lang": "en",
      "text": "to generate novel ideas and",
      "offset": 2895.76,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "breakthroughs. Definitely. But there the",
      "offset": 2898.88,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "bottleneck will be testing them.",
      "offset": 2900.96,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "Right. Right. Because now you are",
      "offset": 2903.76,
      "duration": 2.72
    },
    {
      "lang": "en",
      "text": "talking about a little bit more",
      "offset": 2905.68,
      "duration": 2.72
    },
    {
      "lang": "en",
      "text": "reinforcement learning and so forth.",
      "offset": 2906.48,
      "duration": 4.639
    },
    {
      "lang": "en",
      "text": "Right. Because I I I I generate that's",
      "offset": 2908.4,
      "duration": 4.959
    },
    {
      "lang": "en",
      "text": "generative AI. I generate a solution.",
      "offset": 2911.119,
      "duration": 5.681
    },
    {
      "lang": "en",
      "text": "Yep. Right. Now you need to test it. Y",
      "offset": 2913.359,
      "duration": 6.321
    },
    {
      "lang": "en",
      "text": "right. Uh so that's kind of the will be",
      "offset": 2916.8,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "the bottleneck. It seems like AI",
      "offset": 2919.68,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "research will be like the first place.",
      "offset": 2921.52,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "Yeah. Yeah. I research. Yeah. It's like",
      "offset": 2922.8,
      "duration": 6.16
    },
    {
      "lang": "en",
      "text": "well yeah but then it's uh what what is",
      "offset": 2924.88,
      "duration": 6.08
    },
    {
      "lang": "en",
      "text": "a what is a what what does it mean to be",
      "offset": 2928.96,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "to generate a good uh you know a good",
      "offset": 2930.96,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "artifact research artifact right?",
      "offset": 2932.88,
      "duration": 2.959
    },
    {
      "lang": "en",
      "text": "Because right now we have so many",
      "offset": 2934.4,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "papers, right? It's like Yeah. And so in",
      "offset": 2935.839,
      "duration": 4.801
    },
    {
      "lang": "en",
      "text": "in that sense is can you think of AI",
      "offset": 2938.559,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "creativity as basically just being",
      "offset": 2940.64,
      "duration": 4.479
    },
    {
      "lang": "en",
      "text": "generating a ton of ideas some most of",
      "offset": 2942.24,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "which are awful some of which are good",
      "offset": 2945.119,
      "duration": 3.761
    },
    {
      "lang": "en",
      "text": "and then just being able to accurately",
      "offset": 2946.64,
      "duration": 3.439
    },
    {
      "lang": "en",
      "text": "part of it right sounds like my typical",
      "offset": 2948.88,
      "duration": 2.88
    },
    {
      "lang": "en",
      "text": "brainstorm",
      "offset": 2950.079,
      "duration": 4.641
    },
    {
      "lang": "en",
      "text": "that's so those things right is like uh",
      "offset": 2951.76,
      "duration": 6.079
    },
    {
      "lang": "en",
      "text": "yeah it's like brainstorming right uh",
      "offset": 2954.72,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "you know on one hand you need to even to",
      "offset": 2957.839,
      "duration": 4.641
    },
    {
      "lang": "en",
      "text": "solve a problem right is like this",
      "offset": 2960.72,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "method and in many many um like all the",
      "offset": 2962.48,
      "duration": 5.92
    },
    {
      "lang": "en",
      "text": "way alpha you alpha geometry and so",
      "offset": 2966.48,
      "duration": 5.119
    },
    {
      "lang": "en",
      "text": "forth. This the same kind of um uh",
      "offset": 2968.4,
      "duration": 6.32
    },
    {
      "lang": "en",
      "text": "pattern. You generate lots of solution",
      "offset": 2971.599,
      "duration": 5.441
    },
    {
      "lang": "en",
      "text": "and then you select the good solution.",
      "offset": 2974.72,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "So this has two parts right. First part",
      "offset": 2977.04,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "is generating solution. Now this means",
      "offset": 2978.96,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "that you you a condition to find a good",
      "offset": 2980.8,
      "duration": 6.319
    },
    {
      "lang": "en",
      "text": "solution good solution is that at least",
      "offset": 2984.72,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "one solution that is generated should be",
      "offset": 2987.119,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "good. Yeah. Right. And then is",
      "offset": 2989.52,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "selection. Selection is also very hard.",
      "offset": 2991.599,
      "duration": 4.881
    },
    {
      "lang": "en",
      "text": "You need to the your needle in the high",
      "offset": 2994,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "stack from all these myriad of solutions",
      "offset": 2996.48,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "you generated you need to identify that",
      "offset": 2998.8,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "good solution and that's very tricky",
      "offset": 3000.96,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "because even our probability of",
      "offset": 3003.28,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "identifying the solution you say is 99%.",
      "offset": 3005.44,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "But if you have to pick from 1 million",
      "offset": 3008.8,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "solution or good solution you are",
      "offset": 3010.96,
      "duration": 3.359
    },
    {
      "lang": "en",
      "text": "guaranteed you're going to pick the",
      "offset": 3013.28,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "wrong one all with very high probability",
      "offset": 3014.319,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "guarantee. Yeah. Right. So that's kind",
      "offset": 3016.72,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "of these are the two the the two things",
      "offset": 3018.72,
      "duration": 7.04
    },
    {
      "lang": "en",
      "text": "and um but yeah I think that uh right",
      "offset": 3021.68,
      "duration": 6.32
    },
    {
      "lang": "en",
      "text": "now even today when you have a human in",
      "offset": 3025.76,
      "duration": 4.559
    },
    {
      "lang": "en",
      "text": "the loop there the best application are",
      "offset": 3028,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "the one in which the solution generating",
      "offset": 3030.319,
      "duration": 5.681
    },
    {
      "lang": "en",
      "text": "the solution is hard but verifying it is",
      "offset": 3032.24,
      "duration": 5.599
    },
    {
      "lang": "en",
      "text": "relatively easy. Um well it's been",
      "offset": 3036,
      "duration": 2.8
    },
    {
      "lang": "en",
      "text": "fascinating. We always like to end our",
      "offset": 3037.839,
      "duration": 2.161
    },
    {
      "lang": "en",
      "text": "interviews with a quick fire round where",
      "offset": 3038.8,
      "duration": 2.48
    },
    {
      "lang": "en",
      "text": "we get your thoughts on on a standard",
      "offset": 3040,
      "duration": 3.359
    },
    {
      "lang": "en",
      "text": "set of questions. So maybe to start",
      "offset": 3041.28,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "what's one thing that's overhyped and",
      "offset": 3043.359,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "underhyped in the AI world today? I",
      "offset": 3044.88,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "think under hype is reliability. still",
      "offset": 3046.96,
      "duration": 4.879
    },
    {
      "lang": "en",
      "text": "people discuss but it's not enough",
      "offset": 3049.2,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "because if you believe that that's one",
      "offset": 3051.839,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "of the main challenges which will hold",
      "offset": 3054.16,
      "duration": 7.12
    },
    {
      "lang": "en",
      "text": "back the proliferation of AI and solving",
      "offset": 3057.839,
      "duration": 5.361
    },
    {
      "lang": "en",
      "text": "real problems",
      "offset": 3061.28,
      "duration": 6.16
    },
    {
      "lang": "en",
      "text": "um or I think that's that's on overhyped",
      "offset": 3063.2,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "maybe",
      "offset": 3067.44,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "a little bit",
      "offset": 3068.96,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "all this kind of scale maybe scaling",
      "offset": 3071.04,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "laws everyone now is looking for scaling",
      "offset": 3074.16,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "laws uh especially In a post training",
      "offset": 3076.64,
      "duration": 6.24
    },
    {
      "lang": "en",
      "text": "recently we've seen that um if you have",
      "offset": 3079.52,
      "duration": 6.799
    },
    {
      "lang": "en",
      "text": "of course a powerful base model just",
      "offset": 3082.88,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "with a very small set of high quality",
      "offset": 3086.319,
      "duration": 5.601
    },
    {
      "lang": "en",
      "text": "data you can unleash new capabilities in",
      "offset": 3088.4,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "that base model. Another rapid fire",
      "offset": 3091.92,
      "duration": 4.639
    },
    {
      "lang": "en",
      "text": "question for you. Um what's one AI",
      "offset": 3094,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "startup outside of your area of focus",
      "offset": 3096.559,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "that you're really excited about or",
      "offset": 3098.8,
      "duration": 4.799
    },
    {
      "lang": "en",
      "text": "bullish on? This is probably one of the",
      "offset": 3100.559,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "most successful application but I still",
      "offset": 3103.599,
      "duration": 4.641
    },
    {
      "lang": "en",
      "text": "be very curious about um you know",
      "offset": 3105.119,
      "duration": 5.521
    },
    {
      "lang": "en",
      "text": "startups like Corser or Insurf or",
      "offset": 3108.24,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "something like that code assistants how",
      "offset": 3110.64,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "far they can push this because it's",
      "offset": 3112.559,
      "duration": 5.601
    },
    {
      "lang": "en",
      "text": "clearly that you know they act they are",
      "offset": 3115.04,
      "duration": 6.4
    },
    {
      "lang": "en",
      "text": "great for some of the use cases you know",
      "offset": 3118.16,
      "duration": 9.04
    },
    {
      "lang": "en",
      "text": "of but when you have to have uh bigger",
      "offset": 3121.44,
      "duration": 7.84
    },
    {
      "lang": "en",
      "text": "um",
      "offset": 3127.2,
      "duration": 4.879
    },
    {
      "lang": "en",
      "text": "to have to work with the context of the",
      "offset": 3129.28,
      "duration": 5.279
    },
    {
      "lang": "en",
      "text": "entire codebase and things like that is",
      "offset": 3132.079,
      "duration": 5.441
    },
    {
      "lang": "en",
      "text": "much more difficult. Uh and I think that",
      "offset": 3134.559,
      "duration": 6.321
    },
    {
      "lang": "en",
      "text": "the the other point there is about um",
      "offset": 3137.52,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "for instance once you generate more and",
      "offset": 3140.88,
      "duration": 6.959
    },
    {
      "lang": "en",
      "text": "more code then it's going to uh how easy",
      "offset": 3142.72,
      "duration": 7.119
    },
    {
      "lang": "en",
      "text": "is to maintain it. Yeah. Right. The",
      "offset": 3147.839,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "maintainability but the reason I'm",
      "offset": 3149.839,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "saying you know obviously cursor it's",
      "offset": 3151.68,
      "duration": 5.679
    },
    {
      "lang": "en",
      "text": "and uh they made a lot of progress uh",
      "offset": 3154.319,
      "duration": 5.441
    },
    {
      "lang": "en",
      "text": "and here maybe they it was more than I",
      "offset": 3157.359,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "expected. That's what I would say. Um",
      "offset": 3159.76,
      "duration": 4.559
    },
    {
      "lang": "en",
      "text": "and also it's interesting because there",
      "offset": 3162.319,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "are a lot of still open interesting",
      "offset": 3164.319,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "questions there in that space and if",
      "offset": 3165.839,
      "duration": 4.561
    },
    {
      "lang": "en",
      "text": "successful obviously they are going to",
      "offset": 3168.16,
      "duration": 4.959
    },
    {
      "lang": "en",
      "text": "have um there will be a massive impact",
      "offset": 3170.4,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "but in that space uh no it's the area",
      "offset": 3173.119,
      "duration": 5.361
    },
    {
      "lang": "en",
      "text": "the space is going to get it's quite",
      "offset": 3176.16,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "crowded now with the big players also",
      "offset": 3178.48,
      "duration": 5.599
    },
    {
      "lang": "en",
      "text": "entering but I think that space it's",
      "offset": 3180.64,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "we are going to learn a lot because in",
      "offset": 3184.079,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "some sense this is like canary in in in",
      "offset": 3185.68,
      "duration": 6.159
    },
    {
      "lang": "en",
      "text": "the mind because um is you know code",
      "offset": 3188.4,
      "duration": 8
    },
    {
      "lang": "en",
      "text": "assistance is like it's it's almost",
      "offset": 3191.839,
      "duration": 6.48
    },
    {
      "lang": "en",
      "text": "uh a perfect application because you",
      "offset": 3196.4,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "have uh developers which are early",
      "offset": 3198.319,
      "duration": 6.401
    },
    {
      "lang": "en",
      "text": "adopters of technology right so they are",
      "offset": 3201.28,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "going to adopt the other thing is that",
      "offset": 3204.72,
      "duration": 6.32
    },
    {
      "lang": "en",
      "text": "this code assistants coding assistants",
      "offset": 3207.04,
      "duration": 6.88
    },
    {
      "lang": "en",
      "text": "they already they fit in the existing",
      "offset": 3211.04,
      "duration": 5.92
    },
    {
      "lang": "en",
      "text": "workflow right so I think that this kind",
      "offset": 3213.92,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "of having early adopters and fitting",
      "offset": 3216.96,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "naturally in the workflow are big",
      "offset": 3218.96,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "advantages which you are not going to",
      "offset": 3221.2,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "see for other examples like doctors or",
      "offset": 3222.72,
      "duration": 6.399
    },
    {
      "lang": "en",
      "text": "lawyers and things like that. So I think",
      "offset": 3226.8,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "that it's very interesting to see how",
      "offset": 3229.119,
      "duration": 5.521
    },
    {
      "lang": "en",
      "text": "far this will go. Well, I'm sure there's",
      "offset": 3232.4,
      "duration": 3.439
    },
    {
      "lang": "en",
      "text": "all sorts of threads folks will want to",
      "offset": 3234.64,
      "duration": 2.8
    },
    {
      "lang": "en",
      "text": "pull on. You obviously are involved with",
      "offset": 3235.839,
      "duration": 2.961
    },
    {
      "lang": "en",
      "text": "so many interesting parts of the AI",
      "offset": 3237.44,
      "duration": 2.96
    },
    {
      "lang": "en",
      "text": "world. I want to leave the last word to",
      "offset": 3238.8,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "you. Any place you'd point our listeners",
      "offset": 3240.4,
      "duration": 2.56
    },
    {
      "lang": "en",
      "text": "where they can go to learn more about",
      "offset": 3241.92,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "you, the work you're doing?",
      "offset": 3242.96,
      "duration": 5.92
    },
    {
      "lang": "en",
      "text": "Um so you know we are we are doing still",
      "offset": 3246.079,
      "duration": 4.641
    },
    {
      "lang": "en",
      "text": "a lot of a lot of work is happening at",
      "offset": 3248.88,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "Berkeley high computing lab and",
      "offset": 3250.72,
      "duration": 3.599
    },
    {
      "lang": "en",
      "text": "obviously the companies have all of them",
      "offset": 3252.24,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "they have uh these websites uh good",
      "offset": 3254.319,
      "duration": 6.081
    },
    {
      "lang": "en",
      "text": "websites I assume presumably um but I",
      "offset": 3257.68,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "think that the the cutting research you",
      "offset": 3260.4,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "are doing it's people should go to sky",
      "offset": 3262.96,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "computing lab we have blogs and",
      "offset": 3265.44,
      "duration": 2.96
    },
    {
      "lang": "en",
      "text": "everything amazing well thanks so much",
      "offset": 3266.88,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "this was a ton of fun thank Go.",
      "offset": 3268.4,
      "duration": 20.63
    },
    {
      "lang": "en",
      "text": "[Music]",
      "offset": 3272,
      "duration": 17.03
    }
  ],
  "cleanText": "Don Stoica has an incredible background. He's the co-founder of Databricks, Anyscale, and now LMArena, a company that's raised $100 million to help other companies with Eval. He's also professor over at Berkeley. And today I was joined by guest host Rob Taves, general partner at Redpoint. And Yan, Rob and I talked about a bunch of things. We hit on LMArena, Yan's new company, and where he thinks the opportunities are. We talked about the future of AI infrastructure and where the gaps are in the space today. We also talked about what the U.S. can learn from China to better improve Open Source model efforts within the country. This was a super fun opportunity to talk with one of the most brilliant minds in computer science about everything AI. I think people will really enjoy it. Without further ado, here's Ion.\n\nWell, thanks so much for coming on the podcast. Really appreciate it.\nThanks for having me. Yeah, been looking forward to this one. And I was, we were joking beforehand. We timed this recording pretty nicely. I think we'll start with obviously the big news announced yesterday. The launch of your new startup LMArena, you know, $100 million fund raise. Tell us a bit about the company, you know, the product, the vision, what are you all building?\nYeah, indeed. So, the LMArena is based on the project we had at Berkeley started almost two years ago. Well, two years ago and actually that was driven by a need to evaluate a model which we released I think March 2024 called Vicuna Model. So it was a model which was basically a fine-tuned llama, the first version of llama using the share GPT data if you remember the data which was people sharing their conversation with GPT share GPD and someone making them publicly available. So we did that and you know Vicuna was a few students actually the students did that even without me knowing. I realized later that they just, you know, we can fine-tune it, um, this model and then the question is about evaluating it, right? It's like, of course, you know, you have a few benchmarks back then and so forth, like today a lot of benchmarks, but also it was a little bit harder because it was this kind of conversational, right? Chat, right? So that was kind of how do you evaluate it, how you show that you are meaningfully better than what is out there at that time. And our initial effort was what you do like, you know, at university, you buy some pizza, get some students and you know, ask some questions and evaluate them, right? On different models. The problems that was didn't scale.\nI thought they could scale pretty well on a G. Yeah. Yeah. But you know, and then actually we did a detour. It was two weeks before GPD4 was released. So we had, we thought, okay, why don't we use GPD4 to evaluate? And that was what became eventually known as LLM as a judge. So we did that and to our surprise, it performed pretty well, right? So I look at that and you know, did it, we got good numbers for our model and but then still people asking because again, the using LLM to evaluate was very early, right? We were the first or maybe among the first to do that. And I'm saying among the first because I think that some of the companies they did it internally before, maybe you know, Microsoft and so forth. But people are still asking, okay, you know, yes, I see that for these examples, it looks it's doing well, but still how does it compare with people? So that's why we started, you know, chatbot arena and trying to scale up the kind of evaluation of humans. That was one reason. The other reason it was this thinks about is like today it's very hard to evaluate this light language model and already there, there was evidence of contamination, right? Basically, you know, GPT4, I remember, doing very well for some different kind of problems, which are before the cutoff for training, but not doing very well after that, right? So it was this kind of static benchmarks.\nRight. So then we also thought about, okay, that if this is static of a benchmark, how do this is almost equivalent if you think about people is that you take over and over the same exam, right? It's like what it is, right? So, you know, how you make it and with humans, you know, we do make exams differently and different exam and so forth. So that's why the second, these are the kind of the two, two reasons, right? We wanted to have a benchmark which is not static, it's more dynamic and also which capture the preference of the users of the humans, right? That's the two reasons and then we try to figure out how to do that. There are multiple ways to do it. You can do a little bit of a tournament, which is what the students are doing before because you give, okay, this is a question, this is a prompt and you have this light language models of, you know, whatever, three or four of them, you compare and see the answer to each of them and you rank them. Unfortunately, that kind of more like it's a tournament, like almost it doesn't scale as well and is not only that, but assumes that while you are doing this tournament, the number of models is fixed. So that's one and again, we look always inspiration of how humans do evaluation and then it was, you know, this thing, okay, like in where are you know, similar situation in which not everyone is playing with everyone and the number of players is kind of dynamic and one is obviously chess and but then many other sports like tennis, ATP and also team sports, they do that. So Yeah.\nSo that yellow rating and kind of yellow rating we used and then the model was very simple. You come, you ask your prompt and we provide answers from two randomized anonymized light language models and then you can pick one which you believe is better and you may vote. Yeah. You are not, it's not mandatory to vote, but you may vote and we get all this data and we compute these ratings. Right. And obviously it became wildly popular.\nWhen did you decide it was a company?\nYeah. Well, just to their credit, you know, wellin and then Anastasio who work on this, um, they believe more that it's a company before I did. I said, you know, this is just, this is just evaluation. It's just a leaderboard. What, what, what companies here, right? You know, but you know, to their credit, they really believe in it. And then, um, I think that, um, you, you get to a point and of course there are so many things you need to do and becomes more popular. Um, some light language mo, uh, providers, light language model providers like frontier labs, uh, started to eval also asking us to evaluate, uh, before the release. Um, so it kind of becomes bigger and bigger and people start to ask, okay, what about categories? Uh, people started to ask about, well, what about, um, you know, the humans is very subjective, right? Hey, this model gets higher rating because, uh, it's, it's, it's showing more emojis, right? So we introduce kind of style control to try to factor out some of these things, um, and or, you know, uh, and, um, so that kind of grew and then another dimension it started to grow, it started to text and then multimodel, right? It, it was most text to image, image to text, uh, text to web to, you know, to generate code, um, and many more. So it kind of grew into a valuation platform and then the data we got, um, it started to realize that it's quite valuable, uh, in terms of what you can do with it. And I'm not sure you've seen, but one of the feature we launched, um, uh, one month or two months ago, something like that, is called prompto leaderboard. And prompt to leaderboard, what it is is that you come and you give your prompt. I may not never have seen prompt, but I can give you back, um, it's a leaderboard for your prompt, right? What are the best models to answer your prompt, what is their estimated rating? And the way you do it is, although I didn't, you know, intuitively, it's not, it's not very accurate, but I think intuitively, I think it's, um, you know, it's reasonable, I think to, so you, although I, I, I never seen your prompt, uh, I've seen a lot of prompts which looks like your prompt and then I can use the votes on these similar prompts as a proxy to estimate the rating of the models on your prompt, right? You know, that's kind of exciting and there are many other question, you know, when you, you, you start realizing there is a potential here. So first of all, we need a company because there was no way to scale what we are doing, right? It's, it's costly, yeah, right? Because, uh, what we provide the user, there is free access to these powerful models, right? And, um, even, you know, like we spend, um, for the past year, maybe, you know, probably close to 2 millions to run, uh, uh, this, of course, a lot of money comes in terms of credits, in terms of, uh, some gifts, uh, grants, thing like that, right? But if you think about right now, you know, want to scale 10x or something like that, it's clearly, it's a lot of, uh, you know, it's not going to be cheap. Um, the other thing it is was that, um, like I mentioned to you, is a lot of, a lot of requests to, uh, do more of kind of evaluations. Right now, you have agents and you have all of these. We have a search now, you evaluate the search engines, not the search, the, you know, yeah, the like perplexity and the open AI search and things like that and then you need to build really a scalable back end and you need to build something a new, you know, uh, a much more responsive UIUX, you know, all of these things, right? You know, there is no way you can, you can do that, um, with a few people and, uh, and then you have a model and providers and other people, um, both Open Source and, uh, proprietary asking for evaluations, right? And there is no way, you know, we have a student while basically, you know, he's like doing that's he's a back end, right? Okay. Request, you know, like you put so all of these things and then, um, you, you see that again, once you have this kind of data, there are a lot of questions you can answer, right? Like I mentioned prompt leaderboard, maybe you can answer questions about which many people have. I build my application on a particular model and now I want to swap the model. Yeah, you know, maybe it's a new one, it's available, uh, maybe something cheaper. So, but what will be the impact of swapping the model on my application? Uh, many, many of these questions and then, but what convinced me about, um, that its potential here, um, and us in general, maybe not only me, is that if you look at AI, um, I think that one of the main challenges today with of AI, it's, um, reliab reliability, right? It's like that's key question and it's very hard to see how, uh, AI will really achieve its potential without figuring out how to build more reliable application. Right? Now, if you look about software, a lot of things we do, it's about reliability, right? It's actually most of the energy we put in software development is about reliability because it doesn't take a lot of time to write the code to provide a feature or a service. But you spend a lot of more time in order to uh, test it, debug it, um, and and so forth. And um, and there's a lot of innovation there. You'll have a CI/CD, all of these things. So and and that in some sense easier problem because the software is pretty white box, right? This is the instruction, you change the instruction, you can see what is the state of the program after each instruction, if you don't use a debugger, you can do print fs and things like that, but models are more blackbox, right? So if you look at the analogy and we still want reliable application, um, and because even if you look now, the most successful AI applications are the one which you have a human in the loop. Yeah, for the same reason to validate the answer, like code, code, code assistance, uh, customer support, um, and many others. Um, so then if you think kind of the analogy, you know, you have to have ways to to test and validate and build more reliable, um, AI applications, again, a big problem and, um, it's seems like obviously there are many things you need to do, but also something like LMAR now will help.\nSuper interesting.\nIt makes a lot of sense and I think as you've touched on, evaluations and like validation of reliability for AI systems is one of the biggest unsolved challenges. So I think it's a, it's a massive opportunity you guys are tackling. Is your vision and is the thesis of of the company LMArena that human-based evaluations will always be the best way to go and that that needs to be?\nYeah, that's a great question. Um, happy to answer that. That's why we have our guest as a great question. Yeah, so, um, I think that, um, uh, it is very interesting here, like I, we were, you know, have a lot of discussion on this and probably you've seen and so forth. Um, I think it's, it's, it's, it's one, one evaluation. There are many other evaluations and you should look at many evaluations, many benchmarks. However, if you think today, like we discussed early on that most of the application today, they have a human in the loop. So this makes the human evaluation particularly important, right? And there are people saying, well, you know, like we mentioned to you about this style control, but you know, it's, it's, it's people like that model not because it's better, but because it's funnier or because, you know, answer or emojis or something like that. Um, and the answer to that question, well, first of all, even that is relevant. If you build application which interacts with humans, you want to know that. Yeah. Right. And by the way, guys, you know, like we as a human, right? It's like, you know, we like people who give better presentations, more articulated speak of biases, right? So you want to understand that. Um, so that's kind of very legitimate, right? And of course, now the other thing is that you have enough data. If you know a bias, you can factor it out, right? And this what we do a little bit with style control, you know, for instance, formatting, right? If you have nicer formatted outer, you like it better, right? Like so you, you try to factor that out that you can pick style. Maybe you style control by default in in the in the future, right? In which you factor out some of these things or so. Um, so and and and then you know, that's having a platform in which you can try to remove certain biases. Of course, you can remove only the biases you know they exist, right? That's a problem. Um, but definitely, uh, by the way, you know, this is funny about the biases. Um, but you know, when we look, um, I mentioned to you that when we do this, when we, when we, um, um, build, um, uh, when we, when we, when we use this GPT4 for as a as a judge early on and then we build, uh, you know, chatbot arena, one of the reason to answer the question about how well and how does it compare with GP4 because people are asking, we did a, we wrote a paper and we did, uh, we made a study and The funniest thing is that, um, is that these LLMs have also biases as a judge, like for instance, if they have position bias, they in general\n\n\nI prefer the first answer. They have verbosity bias.\nThe more they prefer, the more verbose answer, right? Um, uh, at this time, maybe now they are better. They are not very good at math, like people, right? They are not very good at math, so it's very a lot of biases of, um, of or or liking their own answers, right? So, you know, from their own family, right? The family of models, right? It's like Llama model view that the judge is going to to to like from other versions of Llama models. Um, so, uh, but that's kind of very interesting because even of these models, maybe, maybe not surprisingly, again, they are trained on, uh, on artifacts, on on what are produced by the humans. So, but yeah, it's interesting. And I feel like, uh, obviously, evaluations, I feel like any startup you talk to, this is like, you know, one of the top things they're thinking about. And I think a question's always been as people have been building tooling in this space, you know, how generalizable can you make an evaluations tool for a company? Because I think every, you know, you know, in some senses, the most valuable thing companies have is their own eval, right? That are specific to their own use cases. And so, how do you think about like providing a general set of tooling to companies in very different end domains? Yeah, that's a good question. I, I, I, I don't think I know the answer to that question. I don't either. We are, we are, we are happy. But, but, you know, things like that, like I mentioned to you, the Promptly leaderboard, um, are going to help, right? Because in that particular case, we don't know, again, your, we haven't seen your, uh, your prompt or your question before, but we can still tell you, um, you know, um, you know, within some statistical meaningful margins that, uh, which are the best models for, for that question. So that's can generalize easily. You give me the set of data and I can give you, you know, the, you know, the best models for your set of data. I can give you also, probably you can do, uh, personalized, right? You can do what are the best models for you, right? So I think you can do that. That's why the key for that is to scale, right? To get more data. The more data you're going to have, the more kind of this kind of micro, um, um, categories you can have. Yeah, makes, uh, makes total sense. What do you think happens to the, you know, model landscape over the next few years, maybe starting with the like most state-of-the-art closed source models? Yeah. Um, uh, I think really, if you think about, um, right now, the trends, obviously, and that was, um, uh, the Open Source model caught up, the progressor quite impressive over the past year. Um, of course, it was, um, not of course, but, um, maybe surprising, and also a surprising, uh, thing is that these models are not necessarily from U.S. or from China.\nUm, but definitely at this point, if you're talking about the Open Source models, the best car coming from China. And if you look at the trends, uh, you know, the Open Source should be able to catch up with proprietary models within one year or so. Um, and, um, yeah, now the question where this Open Source model are going to come from. Um, and what I can say is that, um, in China, it's a lot of, right now, a lot of momentum, and for, I think, for structural, structural and reasons. And, um, you know, how the ecosystem it's, uh, right now grew in China versus U.S. So I think that we and U.S. are a little bit of disadvantage now. Say more about that. Why is that structural? So first, if you think about what do you need to develop these models, right? You need three things: you need experts, you need data, you need infrastructure, right?\nUm, and I think that if you look at China, they have a lot of experts. Probably in sheer numbers, they have more than us. Um, data, they have data, they have, you know, they don't have as much infrastructure, but they are making progress, right? Um, if you look at the latest announcement from Huawei and so forth, and you know, uh, export controls, you know, everyone guesses about how effective they are going to be, uh, or they are, um, that's, you know, that's to, to, you know, to debate. Um, but the one thing there is that, um, the, the Open Source, it's much more prevalent, right? It's almost by default now. If you go to U.S., um, is that, um, you have huge resources that's so forced, and, um, you have lots of smart people, uh, uh, the problem is that the development, what how happens in U.S. siloed, right? It's, um, you know, this frontier lab, right? Everyone is doing the same thing, basically. Uh, that's number one. The number two is that academia, when talk, when you talk about pre-training and building the models, uh, doesn't play a major role because, um, um, lack of resources, you know, there are companies like AI2, there is a group from Stanford, Percy Liang trying to develop, and we at Berkeley try to develop this, um, you know, pre-training, post-training, um, full Open Source pipelines and so forth. Um, but it's a challenge, and unless that changes, we are going to be a structural disadvantage because the diffusion of innovation is very limited, right? Um, it's like you have people, so the way you can, if you want to maximize the rate of progress, you have to have all the smart people collaborate, right? Uh, but if you have kind of these silos and a big part of the researcher, I'm talking about academia, uh, not being able to contribute in a meaningful way to developing these models, then, uh, it's a significant disadvantage. The main diffusion of innovation here in, in, um, is that through people who leave one company, go to another or start new companies. Uh, if you, but if you look, for instance, in China, um, there is a much stronger collaboration between academia and, and, um, and industry, you know, like Bid Dance or, um, Alibaba and, and obviously DeepSeek.\nAnd, um, that really helps them. What, what is the reason, like, academia is like so much more effectively involved in China? How does that come about? Because it's much closer collaboration with industry. It here is very hard to collaborate with the frontier lab because everything is secret. If, if you really want to maximize the rate of progress, again, you have to have all your researchers or your experts collaborating. The only way they can collaborate by share artifacts. Yeah. Which is means at the software side, Open Source models, and they need also to have a shared infrastructure. Yeah. Right. I mean, obviously, a motivation behind a lot of the closed labs is, you know, this belief that, you know, they, you know, being the first to find these state-of-the-art models, there's all these dangers of what they can be done in bio or cyber, and they need to get to them first. Like, what, what do you make of that? Uh, look, I mean, um, I am on, I am optimist in general. I am not, I think it's very, you know, you always need to remember that as a humans, we are driven by emotions, and one of the most, by far, powerful emotion is fear. So it's, it's, you're always going to respond to that much more, much stronger, right? But then providing you some optimistic view, which is not palpable. But the other one, you know, is you are, you know, like, kill you, right? It may kill you. So you are going to react very strongly. So I think to start with, whenever you are seeing this kind of discussion, you need to discount the negative one because you as a human, you are going to be much more prone to respond to that. Yeah. Right. Just to keep a little bit objectivity, objectivity. Um, the other thing I would say is that I still do, you know, you're talking about, and this was Sben 47 last year and so forth. Um, you are talking about, think about the marginal risks, right? Uh, and marginal risk. It's about, uh, risk which are not present before, but they are enabled by this technology. And right now, I still, still need to see real marginal risk enabled by AI. Uh, you know, is it makes the risk exist the previous more prevalent? They're making much worse, maybe. But if talk about, you know, uh, deep fake and so forth, I mean, you could do that before with Adobe and so forth and impersonating people, it's all the way from antiquity, right? So, so that's one, you know, obviously, it's like they speak, oh, you, you can tell you how to build a bomb. So first of all, what it tells you can make it maybe easier in the best case scenario, but if I am going to kind of any library and so forth, I should be able to find that information if I am determined. So it makes this much easier, maybe say 10 times easier, maybe 100 time easier, but if you look at end to end, what you need to do to apply to make that a reality. Acquiring the knowledge, it's like very little, right? Then you need to get the materials. You need to assemble without anyone detected. You need to deliver that or something like that. So if you look at the asan, that's kind of dominating. So yeah, I'm the 10% of acquiring which was before, I'm going to do it to 1% or 0.1%.\nYeah, sure. But the rest is not going to get better, right? It's like he's still gay. So, so that's kind of, um, uh, when, when, when you think at this kind of level of details, uh, not details, it's, um, doesn't convince me that this exist, existential risk and so forth. Of course, everything, you know, there are things you cannot imagine. Granted, you mentioned, uh, physical infrastructure as one area where China is still lagging, and export controls are are a piece of that and so forth. Uh, in the U.S., obviously, in the West more broadly, a massive physical infrastructure buildout is underway, and all of the big hyperscalers are pouring tens of billions of dollars into building out massive data centers, 1 gigawatt, 5 gigawatt data centers, etc. Um, do you think that like that's the right approach and that that's a good, good trend to be happening in the U.S.? Do you think there's some risk of overbuilding infrastructure? I'm curious how you think about that over, like, I think overbuilding, it's very likely that will happen, like with the internet. Yep. That what happened with the internet. We overbuilt the internet, and a lot of companies who are overbuilding it, you know, went under, and there were a lot of other companies which really took advantage of that infrastructure, like, you know, Google and Amazon and so forth, right? So probably very likely this is something like this could happen now, right? It's like, clearly, look, it's is much easier to get GPUs today than it was one year and a half ago. Okay, for one, that's that's a fact, right? I am not, you know, it's not about housings. Um, but I do think that China is not going to, you know, it's going to be two years, three years, I don't know, it's like, but they are going to build, and the advantage is that, you know, they have an economy which is in the same ballpark, I don't, you know, whatever numbers you look at with the U.S. economy, right? And the other thing what they do, they, they have the ability to fund strategic initiatives, you know, many, many years, decades, if needed, right? So that's kind of gives them maybe a structural advantage there. Um, so we'll see, we'll see, but and also they have a lot of experts, and like we see DeepSeek, right? They are going to, you know, do optimization at the lower level, and some people say, oh yeah, but you know, they do that optimization if you force them to spend their intellectual cycles to do that optimization, sure, but you have enough resources, it's going to work out, work out for you. But you know, look, look at, and and look, you know, this is also, um, always amazes me that people say, Oh, you know, it's like this kind of belief, which is confidence that we are always going to be ahead. But there are many, many, um, high-tech industries which we are no longer ready, like, uh, solar cells, car batteries, drones, uh, electric cars, um, robot, you know, at least, uh, industrial robotics. Maybe transitioning topics slightly. Um, you have co-founded and helped build many defining infrastructure companies over the years, software infrastructure companies, Databricks, Anyscale, now LMArena. Um, aside from the evaluations topic, which obviously you guys are focusing on with the new company, um, what do you think the biggest opportunities and the most important unsolved issues are at the infrastructure layer for AI right now? Again, you look, uh, you look at the trends, and and clearly right now what we see, and every lab is doing, um, we are seeing a lot of, um, the infrastructure evolving towards being very, you know, vertically integrated, you know, co-design across all the layers, all the way from the application to the hardware. And I think that we are going to see more and more on that. Uh, that's And I'm going to say again, based on the trends, or I think there are some opportunities, sorry, clearly what, what, what, what, what we are seeing here, right? It's like one thing, it's about you have this kind of distributed heterogeneous infrastructures, right? And if anything, you know, you have at the accelerator level, you have, uh, GPUs, Nvidia and AMD, and you have many other accelerators, like, uh, TPU, Tranium, and others. Um, then you have as the networking, right? You have Ethernet, you have Infiniband, and then a little bit higher level, RDMA. Um, so you have a lot of this, and then collective communication, like Nickel, Recl, and so forth, uh, so huge, huge heterogeneity. So you need to master that. Um, and the one thing I would say is that, and there is quite a bit of work, I'm, I'm hopeful, um, it's about automatically optimizing and generating optimized low-level code kernels, right? For this accelerators. I think that's hopefully it will, it will happen, so that will help, help us, um, support much easier newies and optimize for most a large variety of hardware and networking. I think that it's going to see a lot of more optimization at the intersection between networking and compute, right? Fine grain in, uh, overlapping the communication with computation and so forth. Obviously, load balancing is going to be very important. Um, so, so that's one. And when you look about, in order to optimize this kind of models and workloads, it's, it's so complicated, right? It's like, uh, if you have, if you look at this kind of parallelism, like for model, model serving and and training, you have the last time I was looking, it was like seven, you know, model data parallel, model parallels, or tensor paral, pipeline parallelism, um, context parallelism, and, um, and the token parallelism and expert parallelism, um, sequence parallelism, I forgot. So I think these are seven. Um, so it, it's, you know, it's like you need to do this in automated way, right? Um, because there are too many, and then are very fine grain again between communication and computation, because you are, you, you want to overlap the computation with communication to increase utilization of GPUs. Obviously, we'll see what happens at the agentic level.\nYeah. What do you think the, uh, like infrastructure needs will end up being for, uh, for agents? I feel like there's been some early attempts at broad frameworks at other, you know, air sorts areas. It feels like the model companies themselves are building lots of things. It's hard because when you have a field which is so, um, move so fast, it's very hard to come with good frameworks and which are going to be stable over time, right? Because it's just, um, the needs, you know, change every mass, every week, every day, right? So that kind of makes it difficult. So I think this will be typically when you start to build good frameworks or good, um, software abstractions is\n\n\nWhen the speed of evolution at the application level, it's kind of slowing down. Is that ever going to happen given model progress? Yeah. Well, you know, it's like, look, um, the different layers, it does happen. I mean, it's like now everyone is using transformers, everyone is using like kind of PyTorch, right? Almost. There are things like, um, we are using right now, uh, you know, when you talk about inference, we are using Open AI API more or less. So yeah, I think there are, you are seeing that, you're kind of the standardization is a low level. Um, if you look about, um, for instance, a lot of new post-training frameworks, every day you get another one, but most of them are built on Ray, BLM, and maybe, you know, Agilang also. Yeah, so I think you see at different points some kind of standardization, uh, but it's still, it's pretty late dispersed since the, you know, generative AI explosion. I feel like it was this huge moment for Databricks, and in many ways, um, you guys have kind of met it head on. Um, reflecting back maybe on the last two and a half years, like, what do you think the company got like most right in the kind of immediate post-chatbot moment, and then maybe if you could do it over again, something you might have done differently? So I think that one thing was, um, you got right, it's about the data is as important as ever, right? So getting access to all your data in a seamless and performant way while having all the governance on top is very important, right? And this is what we've done with Lakehouse now with the Unity Catalog. I think that's the key. Because if you are a company, an enterprise, a large enterprise, you are going to have the data in a myriad of storage, right? Legacy or newer, you know, like used to be, um, data links and things like that. So having access, uniformly accessing the data, uh, and not only that, to have the metadata associated with the data you are going to access is super, super important. Okay. So I think that was, that was, uh, right, and you see even today, it's, that's why, you know, the our main conference is called Data + AI, right? Data intelligence is a new, um, is a new category. Um, so and you'll see still, it's, it's, it's a huge push in that direction. Um, I think the other one, it's about, um, also after acquiring Mosaic and of ours, um, we are very early on, very aggressively pursuing, um, um, AI for enterprises, right? And it's, it's perfect, right? Because you have enterprise, they have the data, uh, in general, their data, it's one of their big, um, uh, crown jewel, right? It's like, it's unique, and then you help them to, um, extract a lot of value from the data and build new products powered by AI on the data, right? So that's one, one thing. Now, the one thing I want to mention here is that, um, and people may not realize that, but, um, this AI was in the, in, in, uh, in it's, it's in the DNA of Databricks. When we started Databricks, um, with Spark, um, um, one of the main libraries on top of Spark of machine learning library. It was ML and then Spark ML, and, um, it was, of course, it wasn't deep learning at that stage. It was classic machine learning, random forest and linear regression and things like that. But that's one, and even early customers actually were buying Databricks, um, you know, product and Spark because they wanted to do AI, right? Early on. So it's coming in some sense full circle, but I think, you know, that's, um, um, I think, uh, you know, um, it's hard to know what you, we would have done differently. Of course, we, we tried to build the, you know, we built, and it was a pretty high-performance model, uh, dicks, right? So if you go back, whether you are going to do that again, it's a question, given the power, you given how many powerful open-source models have been released. Of course, I cannot talk about everything here, but I think we did, um, for the last two years and so forth. I think that, um, I don't think I will go back, I, I would go back and say we should have done differently, and of course, we need to talk with Ali and so forth much better than I know, and he will be better to answer his questions. You're so close to all this, you know, cutting-edge stuff in the AI world. What's one thing you've changed your mind on in the last year? Maybe the way I would answer the question, what things are I thought will happen and didn't happen, and by definition, you'll change a little bit your mind on that. Um, I thought that, um, we are going to see more alternative to Nvidia, more, right? And we haven't seen that yet. Uh, that's number, that's one. Um, the other thing I was pleasantly surprised by the progress of the Open Source. Now, this came from where I, maybe one more than one year ago, I haven't expected, you know, came more from China rather than, uh, U.S. I thought that we'll make more progress on reliability, hallucination, and so forth, but that still remain a problem, uh, especially with the reasoning models. I think that, uh, certainly reasoning models are probably more effective than not reasoning. Post-training was more effective, uh, than I thought, and one particular thing, which, okay, one, I, I know now, one, one thing I changed my mind, I was not very bigger early on on, uh, quantization, because I saw that everyone, you know, like, uh, people, quantization makes a tradeoff, right? It's like a little bit hit the performance, uh, to provide you, uh, better efficiency or, um, and I thought that people will not be willing to do to make that trade-off, but that's, um, there, and quantization, without question, is very, he's been very successful and a game changer. Yeah, there's a lot in there that you said that's interesting. I mean, I guess to go back to your first one, like, do you still think over time, you know, in the next few years, there does emerge real challengers to Nvidia, or like, has what's happened over the last year changed your mind on the viability of that? I think there could be, for, you know, it's certainly, you know, probably China will put a lot of effort and Huawei to, because they don't have any other choice if, um, things do not change, otherwise, in the export control get worse or something like that, that could happen. I think that, yeah, and I think that clearly we see a lot of investments. Google always invested on TPOS, then, uh, AWS makes a lot of effort on Tranium, and then AMD, um, very good hardware. I think the biggest challenge, as you know, is like, is software, the software stuck, right? One of the biggest challenges. We'll see. I'm hopeful, because, you know, it's like, it's, uh, obviously, from this at the softer layer, it's like, well, you never know, like, on one hand, if you have a lot of more choices, you need to put a lot more effort in the software to use these different choices. Continuing with the, with the crystal ball gazing a little bit here, I'm curious to hear what, what's your view on our current trajectory toward super intelligence, AGI timeline there, if it's even a coherent concept. How do you think about that debate? You know, I used to joke that with AGI, everyone will be right, because they have no good definition, right? So I said, I am right, because what I call, I said, is AGI, right? I don't know, is like, it's, and this is that, and what is AGI? Like, what people say is that you have one artifact that is going to, um, do majority of tasks better than humans, right? Um, but how that artifact will be built, I can, you can build even probably today something like that, or maybe very few years, but I don't think that intuitively what people mean by, uh, art, you know, AGI, uh, but, but if you look historically, right, there are, you know, it's like there are an increasing number of tasks at which computers are better than humans, right? Think about calculators, right? That was 70s or 60, right? They are better than humans for a long time, right? Then playing games, right? It's like, um, uh, chess, right? It was DBL 97 or something, and then it was obviously go 2017, and now you have kind of more imageet. It was for a lot convolution networks for recognizing, uh, image recognition, which is arguably better than humans. So you always have these kind of things which are going to add up, right? Maybe you're going to proofs and so forth. Uh, so, you know, you're going to have more and more tasks at which computers are better than humans, and you can package them in one artifact, and depending on the task, you can invoke different things under the hood, but from the user perspective, is the same. Um, although people, you know, that some of them will not call that AGI, but one thing I say, so I'm, I'm not going to, I, I don't know, right? But one thing I were going to say is that what you see there, and this goes back to the discussion about reliability a little bit, what you see progress, you see progress where you have, uh, good validation, good test for the answers, you have ground truth, that's what you see, okay? Um, like, like you're talking calculator, right? It's like, you know, like, it's only one right answer. Uh, if you look at games, it's very easy to test whether, uh, you are successful or not, you win or lose, it's also the rules are pretty clear. Yeah, right? Uh, if you think even reasoning models, where are they more successful, right? Problem solving, coding, coding is this is natural, shouldn't be a surprise. Because if I, if I look, forget about, you know, computers, if you look where the progress was done in the history of humanity, just over the past, you know, say 200 years, where did it happen? In sciences, engineering, when you have measurable outcomes, right? Chemistry, mechanical engineering, electrical engineering, um, physics and so forth, right? You sort of the pro, right? There's a word in front for these sciences is today very different than 200 years ago. Yeah. Where things are not as measurable, like, uh, novels, books, writing, creative writing, right? Arguably, you don't see the same progress. Actually, some people will argue the other way around. Right? So that's kind of what I want to say. So this is, so this what I'm trying to say is that I think that we are going to see continuously for the measurable, the, you know, the task or use cases, measurable outcome, you are going to see very rapid progress, but for the other one, it will be more subjective, whatever. Yeah, do you think we'll see a proliferation of what measurable tasks are? I mean, obviously, a lot of people in the lab seem to think you can build reward models for almost any domain. Yes, but there are things which are going to be more called kind of objective, what is true or false, right? You can have formal specification and so forth, um, and, and things which are going to be more subjective, right? And because what is a good book, right? How you are going to do develop a your model for that? That's why I think that you may have, you know, your personal model, maybe you can someone write a book for your model, right? Your own model. Um, so yeah, you are going to do, but reward models are not as efficient as I said, right? Like, for instance, if you have even for, um, say you, you, you build, you know, so you do, you solve mass problems, and you can use to have a models to kind of learn what is good or bad, uh, uh, result, and now you compare that if you have the ground truth. I know this results, the correct results, right? Um, if you have the ground truth, it's much more efficient, maybe one or magnitude more efficient in terms of the compute to get to a particular accuracy for whatever benchmarks, am, or whatever problem solving. This is almost a philosophical question, but within the hard sciences, which are verifiable, do you think that the, the current paradigm of AI that we're in, it's possible for AI to generate novel ideas and breakthroughs? Definitely. But there, the bottleneck will be testing them. Right. Right. Because now you are talking about a little bit more reinforcement learning and so forth. Right. Because I, I, I generate, that's generative AI. I generate a solution. Yep. Right. Now you need to test it. Y, right. Uh, so that's kind of the will be the bottleneck. It seems like AI research will be like the first place. Yeah. Yeah. I research. Yeah. It's like, well, yeah, but then it's, uh, what, what is a, what, what does it mean to be to generate a good, uh, you know, a good artifact, research artifact, right? Because right now we have so many papers, right? It's like, Yeah. And so in, in that sense, is can you think of AI creativity as basically just being generating a ton of ideas, some most of which are awful, some of which are good, and then just being able to accurately part of it, right? Sounds like my typical brainstorm. That's so those things, right? It's like, uh, yeah, it's like brainstorming, right? Uh, you know, on one hand, you need to even to solve a problem, right? It's like this method, and in many, many, um, like all the way alpha, you, alpha geometry and so forth. This the same kind of, um, uh, pattern. You generate lots of solution, and then you select the good solution. So this has two parts, right? First part is generating solution. Now, this means that you, you a condition to find a good solution, good solution is that at least one solution that is generated should be good. Yeah. Right. And then is selection. Selection is also very hard. You need to the your needle in the high stack from all these myriad of solutions you generated, you need to identify that good solution, and that's very tricky, because even our probability of identifying the solution you say is 99%. But if you have to pick from 1 million solution or good solution, you are guaranteed you're going to pick the wrong one, all with very high probability, guarantee. Yeah. Right. So that's kind of these are the two, the, the two things, and, um, but yeah, I think that, uh, right now, even today, when you have a human in the loop, there the best application are the one in which the solution generating the solution is hard, but verifying it is relatively easy. Um, well, it's been fascinating. We always like to end our interviews with a quick fire round where we get your thoughts on on a standard set of questions. So maybe to start, what's one thing that's overhyped and underhyped in the AI world today? I think under hype is reliability. Still people discuss, but it's not enough, because if you believe that that's one of the main challenges which will hold back the proliferation of AI and solving real problems, um, or I think that's, that's on overhyped, maybe a little bit, all this kind of scale, maybe scaling laws, everyone now is looking for scaling laws, uh, especially in a post-training, recently, we've seen that, um, if you have, of course, a powerful base model, just with a very small set of high-quality data, you can unleash new capabilities in that base model. Another rapid fire question for you. Um, what's one AI startup outside of your area of focus that you're really excited about or bullish on? This is probably one of the most successful application, but I still be very curious about, um, you know, startups like Corser or Insurf or something like that, code assistants, how far they can push this, because it's clearly that, you know, they act, they are great for some of the use cases, you know, of, but when you have to have, uh, bigger, um, to have to work with the context of the entire codebase and things like that is much more difficult. Uh, and I think that the, the other point there is about, um, for instance, once you generate more and more code,\n\n\nThen it's going to, uh, how easy is it to maintain it?\nYeah, right, the maintainability.\nBut the reason I'm saying, you know, obviously, cursor, it's, and, uh, they made a lot of progress, uh, and here maybe they, it was more than I expected.\nThat's what I would say.\nUm, and also, it's interesting because there are a lot of still open, interesting questions there in that space, and if successful, obviously, they are going to have, um, there will be a massive impact.\nBut in that space, uh, no, it's the area, the space is going to get, it's quite crowded now with the big players also entering.\nBut I think that space, it's, we are going to learn a lot because in some sense, this is like canary in in in the mind because, um, is, you know, code assistance is like, it's, it's almost, uh, a perfect application because you have, uh, developers which are early adopters of technology, right?\nSo they are going to adopt.\nThe other thing is that this code assistants, coding assistants, they already, they fit in the existing workflow, right?\nSo I think that this kind of having early adopters and fitting naturally in the workflow are big advantages which you are not going to see for other examples like doctors or lawyers and things like that.\nSo I think that it's very interesting to see how far this will go.\nWell, I'm sure there's all sorts of threads folks will want to pull on.\nYou obviously are involved with so many interesting parts of the AI world.\nI want to leave the last word to you.\nAny place you'd point our listeners where they can go to learn more about you, the work you're doing?\nUm, so, you know, we are, we are doing still a lot of, a lot of work is happening at Berkeley high computing lab, and obviously the companies have all of them, they have, uh, these websites, uh, good websites, I assume, presumably.\nUm, but I think that the, the cutting research you are doing, it's people should go to sky computing lab.\nWe have blogs and everything.\nAmazing.\nWell, thanks so much.\nThis was a ton of fun.\nThank Go.\n[Music]\n",
  "dumpedAt": "2025-07-21T18:43:26.446Z"
}