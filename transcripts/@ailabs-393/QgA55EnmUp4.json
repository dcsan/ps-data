{
  "episodeId": "QgA55EnmUp4",
  "channelSlug": "@ailabs-393",
  "title": "My 4-Part SYSTEM to Build AI Apps with Context Engineering",
  "publishedAt": "2025-07-09T12:52:43.000Z",
  "rawLines": [
    {
      "lang": "en",
      "text": "You probably know about vibe coding, but",
      "offset": 0.24,
      "duration": 3.679
    },
    {
      "lang": "en",
      "text": "turns out that when it was coined by",
      "offset": 2.24,
      "duration": 3.599
    },
    {
      "lang": "en",
      "text": "Andre Karpathy, it wasn't like he",
      "offset": 3.919,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "invented it. He just coined something",
      "offset": 5.839,
      "duration": 3.521
    },
    {
      "lang": "en",
      "text": "that people had been doing for months.",
      "offset": 7.52,
      "duration": 3.999
    },
    {
      "lang": "en",
      "text": "And now he has done it again. Karpathy,",
      "offset": 9.36,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "who was a founding member at OpenAI, has",
      "offset": 11.519,
      "duration": 5.201
    },
    {
      "lang": "en",
      "text": "unknowingly coined another term, context",
      "offset": 14,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "engineering. And again, just like vibe",
      "offset": 16.72,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "coding, it's nothing new. Many people",
      "offset": 18.8,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "have been doing this practice. But one",
      "offset": 20.72,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "thing that he is right about is that",
      "offset": 22.64,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "this is absolutely necessary and this is",
      "offset": 24.32,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "the way that we should be coding with",
      "offset": 26.72,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "AI. Now, this is not just an explainer",
      "offset": 28.48,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "video. We will not only be going",
      "offset": 31.039,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "hands-on with what context engineering",
      "offset": 32.559,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "is and how you would prepare the",
      "offset": 34.88,
      "duration": 3.679
    },
    {
      "lang": "en",
      "text": "context, but I will also show you how to",
      "offset": 36.48,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "properly use that context. And this is",
      "offset": 38.559,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "what most of you are completely missing.",
      "offset": 40.64,
      "duration": 3.759
    },
    {
      "lang": "en",
      "text": "Now, the first thing to understand is",
      "offset": 42.719,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "that all models have context windows. It",
      "offset": 44.399,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "is the amount of text that they can",
      "offset": 46.879,
      "duration": 3.281
    },
    {
      "lang": "en",
      "text": "currently remember. With the prompts",
      "offset": 48.559,
      "duration": 3.441
    },
    {
      "lang": "en",
      "text": "that we were giving LLMs, we were",
      "offset": 50.16,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "phrasing things in a specific way to get",
      "offset": 52,
      "duration": 4.719
    },
    {
      "lang": "en",
      "text": "a single good answer from the LLM. But",
      "offset": 54.32,
      "duration": 4.239
    },
    {
      "lang": "en",
      "text": "here with context engineering, we're",
      "offset": 56.719,
      "duration": 4.801
    },
    {
      "lang": "en",
      "text": "giving all relevant facts, rules, tools,",
      "offset": 58.559,
      "duration": 4.961
    },
    {
      "lang": "en",
      "text": "and information and filling in the",
      "offset": 61.52,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "model's context window so that there is",
      "offset": 63.52,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "just no chance of hallucination and the",
      "offset": 65.68,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "model knows what it is doing. This way,",
      "offset": 67.92,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "we're actually working on what the model",
      "offset": 70.24,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "needs to remember in order to accomplish",
      "offset": 72.24,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "what we want. Now, if we look at the",
      "offset": 74.32,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "tweet in the first part, he tells us",
      "offset": 76.32,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "about how we're now shifting from prompt",
      "offset": 78.32,
      "duration": 4.479
    },
    {
      "lang": "en",
      "text": "engineering to context engineering and",
      "offset": 80.479,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "essentially what context engineering",
      "offset": 82.799,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "consists of. There's also this diagram I",
      "offset": 84.56,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "found from another person that pretty",
      "offset": 86.799,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "nicely explains how context engineering",
      "offset": 88.479,
      "duration": 4.481
    },
    {
      "lang": "en",
      "text": "isn't just a new form of prompt",
      "offset": 90.96,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "engineering. It's a broader term that",
      "offset": 92.96,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "includes everything from rag to memory",
      "offset": 94.799,
      "duration": 4.241
    },
    {
      "lang": "en",
      "text": "and also includes prompt engineering",
      "offset": 97.04,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "within it. So this whole art has now",
      "offset": 99.04,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "been termed as context engineering. In",
      "offset": 100.88,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "the second part of the tweet, Andre",
      "offset": 102.96,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "actually tells us that it's not only the",
      "offset": 104.64,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "context we need to look at, it's also",
      "offset": 106.56,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "the app we're using because the LLM app",
      "offset": 108.56,
      "duration": 4.879
    },
    {
      "lang": "en",
      "text": "isn't just a chat GPT wrapper anymore.",
      "offset": 111.04,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "It doesn't just contain an LLM. It uses",
      "offset": 113.439,
      "duration": 4.561
    },
    {
      "lang": "en",
      "text": "that LLM and gives you tools and",
      "offset": 115.84,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "workflows that are actually useful. He",
      "offset": 118,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "specifies that the LLM app needs to have",
      "offset": 120.24,
      "duration": 4.559
    },
    {
      "lang": "en",
      "text": "the components necessary for context",
      "offset": 122.64,
      "duration": 4.479
    },
    {
      "lang": "en",
      "text": "engineering and that apps like cursor,",
      "offset": 124.799,
      "duration": 4.481
    },
    {
      "lang": "en",
      "text": "clawed code, and other coding agents",
      "offset": 127.119,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "aren't just chat GPT wrappers anymore.",
      "offset": 129.28,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "They are actually important components",
      "offset": 131.599,
      "duration": 4.241
    },
    {
      "lang": "en",
      "text": "in context engineering. Now, on the",
      "offset": 133.36,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "topic of the LLM apps we need to use, we",
      "offset": 135.84,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "have cursor and claude code. Both have",
      "offset": 138.16,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "their own strengths, but right now",
      "offset": 140.239,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "Claude Code is much more powerful as an",
      "offset": 141.84,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "agent. Cursor has been catching up",
      "offset": 143.84,
      "duration": 3.759
    },
    {
      "lang": "en",
      "text": "though, recently adding features like",
      "offset": 145.76,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "the to-do lists that Claude Code already",
      "offset": 147.599,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "had. Bottom line, the context",
      "offset": 150.08,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "engineering workflow I'm about to show",
      "offset": 152,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "you works in either app. So, you can use",
      "offset": 153.92,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "whichever one you've purchased. Now,",
      "offset": 156.48,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "I've explained what context engineering",
      "offset": 158.4,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "is, and you're all probably excited",
      "offset": 160.4,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "thinking we should just go ahead and",
      "offset": 162.4,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "give everything to the model to get the",
      "offset": 164.08,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "exact results we want. But here's the",
      "offset": 166,
      "duration": 3.599
    },
    {
      "lang": "en",
      "text": "thing with these coding models. Remember",
      "offset": 167.84,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "the context window I told you about?",
      "offset": 169.599,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "Well, once that fills up, the chances of",
      "offset": 171.44,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "hallucination increase rather than",
      "offset": 173.68,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "things getting more accurate. So,",
      "offset": 175.76,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "efficient management of the context",
      "offset": 177.44,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "window is crucial. You can't just dump",
      "offset": 179.12,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "everything into one file. You need to",
      "offset": 181.12,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "break it down into pieces and only give",
      "offset": 182.959,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "it to the model when it's needed. So,",
      "offset": 185.04,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "right now, I'm going to explain my",
      "offset": 186.879,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "workflow with context engineering. I've",
      "offset": 188.64,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "been doing this long before the term was",
      "offset": 190.959,
      "duration": 3.761
    },
    {
      "lang": "en",
      "text": "even coined. It's just a new trend now.",
      "offset": 192.72,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "But there is something new I learned",
      "offset": 194.72,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "while watching a video by Cole Medan",
      "offset": 196.56,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "which was actually pretty great. It",
      "offset": 198.56,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "introduced the idea of including",
      "offset": 200.08,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "external documentation in the context",
      "offset": 202.08,
      "duration": 4.239
    },
    {
      "lang": "en",
      "text": "window as well. So I got inspired by",
      "offset": 204.4,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "that and updated my workflow. Coming",
      "offset": 206.319,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "back to my workflow. First we start with",
      "offset": 208.239,
      "duration": 4.481
    },
    {
      "lang": "en",
      "text": "a PRD which is the project requirement",
      "offset": 210.4,
      "duration": 4.479
    },
    {
      "lang": "en",
      "text": "document. In that we list the features",
      "offset": 212.72,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "we want. Based on that the model can",
      "offset": 214.879,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "decide what's best for us. If you're a",
      "offset": 217.2,
      "duration": 3.679
    },
    {
      "lang": "en",
      "text": "developer you can add specific",
      "offset": 219.2,
      "duration": 3.759
    },
    {
      "lang": "en",
      "text": "requirements to the PRD as well. For",
      "offset": 220.879,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "example, I've mentioned that I want",
      "offset": 222.959,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "Nex.js for the front end and fast API",
      "offset": 224.72,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "for the back end. But even if you don't",
      "offset": 227.36,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "know what you want, the workflow I'm",
      "offset": 229.2,
      "duration": 3.679
    },
    {
      "lang": "en",
      "text": "about to show you can automatically",
      "offset": 231.04,
      "duration": 3.759
    },
    {
      "lang": "en",
      "text": "configure all of that and get you a",
      "offset": 232.879,
      "duration": 3.761
    },
    {
      "lang": "en",
      "text": "ready-made app. Now, let's come to the",
      "offset": 234.799,
      "duration": 3.761
    },
    {
      "lang": "en",
      "text": "part of the engineering workflow that",
      "offset": 236.64,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "actually has the context for the models,",
      "offset": 238.56,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "the documentation folder. These four",
      "offset": 240.64,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "files are the most important. the",
      "offset": 242.72,
      "duration": 3.519
    },
    {
      "lang": "en",
      "text": "implementation plan, the project",
      "offset": 244.56,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "structure which is currently empty",
      "offset": 246.239,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "because it's still being generated, the",
      "offset": 248,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "UI and UX documentation, and finally bug",
      "offset": 249.92,
      "duration": 4.879
    },
    {
      "lang": "en",
      "text": "tracking. These files are the different",
      "offset": 252.72,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "components that the AI model needs to",
      "offset": 254.799,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "complete the project. Now, this was",
      "offset": 257.28,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "context that the model will use, but the",
      "offset": 258.959,
      "duration": 4.001
    },
    {
      "lang": "en",
      "text": "model should also know how to use it.",
      "offset": 261.04,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "For that, I've set up two rules, the",
      "offset": 262.96,
      "duration": 4.239
    },
    {
      "lang": "en",
      "text": "generate rule and the work rule. First,",
      "offset": 264.96,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "the generate rule converts the PRD into",
      "offset": 267.199,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "all the other files. It basically",
      "offset": 269.52,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "generates full context for the",
      "offset": 271.28,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "development process. Once all that",
      "offset": 272.96,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "context has been generated, the models",
      "offset": 274.72,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "context limit gets full for that session",
      "offset": 276.88,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "and I won't be able to generate quality",
      "offset": 279.04,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "code further on. You can see this in",
      "offset": 280.96,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "cursor because it uses models with",
      "offset": 282.8,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "limited context windows. They fill up",
      "offset": 284.8,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "quickly. If I were using clawed code,",
      "offset": 286.88,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "this wouldn't happen as soon. But once I",
      "offset": 289.04,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "have all four files generated and ready,",
      "offset": 291.12,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "that becomes our complete context. Now",
      "offset": 293.52,
      "duration": 3.679
    },
    {
      "lang": "en",
      "text": "if the model starts working on the",
      "offset": 295.6,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "project, it doesn't need to keep all of",
      "offset": 297.199,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "that loaded in its context. Otherwise,",
      "offset": 299.12,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "it'll just hallucinate more and more.",
      "offset": 301.36,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "That's why we move to an implementation",
      "offset": 303.28,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "plan so we can work through everything",
      "offset": 305.199,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "step by step. Now you might ask, how",
      "offset": 307.28,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "does cursor even know how to use these",
      "offset": 309.52,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "files? That's where the workflow rule",
      "offset": 311.52,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "comes in. It's always attached to cursor",
      "offset": 313.52,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "and tells it exactly how to use each",
      "offset": 315.68,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "file. When implementing the project, it",
      "offset": 317.68,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "looks at the implementation file. When",
      "offset": 319.6,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "working on UI and UX, it refers to the",
      "offset": 321.52,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "UI and UX documentation. If it's about",
      "offset": 323.919,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "to create something new or run a",
      "offset": 326.32,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "command, it checks the project structure",
      "offset": 328.08,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "to make sure it's consistent. And when",
      "offset": 330,
      "duration": 3.759
    },
    {
      "lang": "en",
      "text": "there's an error or a bug, it first",
      "offset": 331.84,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "looks into the bug tracking file to make",
      "offset": 333.759,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "sure it wasn't already documented. This",
      "offset": 335.84,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "workflow rule regulates that entire",
      "offset": 337.919,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "process. I've purposely kept it small.",
      "offset": 340.08,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "You can see it's way smaller than the",
      "offset": 342.32,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "generate file, which is really long. The",
      "offset": 344,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "implementation plan is even longer. This",
      "offset": 346,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "is so that the workflow file which is to",
      "offset": 348.08,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "be always in the context takes as little",
      "offset": 350.24,
      "duration": 3.679
    },
    {
      "lang": "en",
      "text": "place there as possible. In the",
      "offset": 352.32,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "implementation plan, we also have task",
      "offset": 353.919,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "lists. These are broader task lists and",
      "offset": 356.08,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "then they have their own subtasks. And",
      "offset": 358.479,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "you might say that cursor and claude",
      "offset": 360.4,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "already have their task lists. Yes, they",
      "offset": 362.16,
      "duration": 4.479
    },
    {
      "lang": "en",
      "text": "do. But here when a subtask comes up, it",
      "offset": 364.24,
      "duration": 4.239
    },
    {
      "lang": "en",
      "text": "decides whether to create a new task",
      "offset": 366.639,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "list in the LLM app to break that",
      "offset": 368.479,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "specific subtask if it is too long or if",
      "offset": 370.72,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "it's simple, then just follow the steps",
      "offset": 373.199,
      "duration": 3.761
    },
    {
      "lang": "en",
      "text": "outlined in the current one. For",
      "offset": 375.12,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "example, when we reach the core feature",
      "offset": 376.96,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "stage, and by the way, this",
      "offset": 378.88,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "implementation is for the entire app,",
      "offset": 380.24,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "not just the MVP. It proceeds step by",
      "offset": 382.4,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "step. You can narrow it down to just the",
      "offset": 384.88,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "MVP if you want. Right now, the full",
      "offset": 386.8,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "app's development is estimated at 3 to 4",
      "offset": 389.199,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "weeks. If it were just the MVP, it would",
      "offset": 391.68,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "be a matter of hours. When it comes to",
      "offset": 393.919,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "something like designing and",
      "offset": 395.759,
      "duration": 3.521
    },
    {
      "lang": "en",
      "text": "implementing the database and schema,",
      "offset": 397.199,
      "duration": 3.761
    },
    {
      "lang": "en",
      "text": "that task would have been broken down",
      "offset": 399.28,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "into further tasks by cursor. This is",
      "offset": 400.96,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "where Andre's advice on the LLM app",
      "offset": 403.28,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "being good enough comes in. And cursor",
      "offset": 405.36,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "is good enough that it can decide on its",
      "offset": 407.12,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "own. And if you think that when you open",
      "offset": 408.88,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "a new chat, meaning the context window",
      "offset": 410.8,
      "duration": 4.239
    },
    {
      "lang": "en",
      "text": "resets, cursor will forget what the",
      "offset": 413.039,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "project was about, you don't have to",
      "offset": 415.039,
      "duration": 3.361
    },
    {
      "lang": "en",
      "text": "worry about cursor forgetting because",
      "offset": 416.639,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "everything's already written down in the",
      "offset": 418.4,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "implementation file. That's the core",
      "offset": 420.319,
      "duration": 4.241
    },
    {
      "lang": "en",
      "text": "idea in context engineering. Of course,",
      "offset": 422.16,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "both of these files will be in the",
      "offset": 424.56,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "description and you can generate these",
      "offset": 426.16,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "documentation files for yourself. But",
      "offset": 428,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "again, I encourage you to create your",
      "offset": 430.08,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "own workflows. The important thing isn't",
      "offset": 431.919,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "that you got these implementation files",
      "offset": 434,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "from me. The important thing is that you",
      "offset": 436,
      "duration": 3.759
    },
    {
      "lang": "en",
      "text": "understand what context engineering",
      "offset": 437.919,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "actually is. And with that",
      "offset": 439.759,
      "duration": 3.121
    },
    {
      "lang": "en",
      "text": "understanding, you can build your own",
      "offset": 441.039,
      "duration": 3.761
    },
    {
      "lang": "en",
      "text": "implementation, your own generation",
      "offset": 442.88,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "workflows, and the exact set of files",
      "offset": 444.8,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "that cursor or claude code needs to",
      "offset": 446.8,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "follow. Oh, and if you're enjoying the",
      "offset": 448.8,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "content we're making, I'd really",
      "offset": 450.96,
      "duration": 3.519
    },
    {
      "lang": "en",
      "text": "appreciate it if you hit that subscribe",
      "offset": 452.639,
      "duration": 3.761
    },
    {
      "lang": "en",
      "text": "button. We're also testing out channel",
      "offset": 454.479,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "memberships. launched the first tier as",
      "offset": 456.4,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "a test and 90 people have joined so far.",
      "offset": 458.319,
      "duration": 4.481
    },
    {
      "lang": "en",
      "text": "The support's been incredible. So, we're",
      "offset": 460.8,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "thinking about launching additional",
      "offset": 462.8,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "tiers. Right now, members get priority",
      "offset": 464.16,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "replies to your comments. Perfect if you",
      "offset": 466.8,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "need feedback or have questions. Now,",
      "offset": 468.88,
      "duration": 3.759
    },
    {
      "lang": "en",
      "text": "there's another important point you need",
      "offset": 470.96,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "to understand about context engineering.",
      "offset": 472.639,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "You can see that I wanted to make the",
      "offset": 474.96,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "implementation plan for an MVP, but it's",
      "offset": 476.56,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "been taken to an advanced level because",
      "offset": 479.039,
      "duration": 3.761
    },
    {
      "lang": "en",
      "text": "of my generate prompt. Even though I",
      "offset": 480.96,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "mentioned that I wanted an MVP since it",
      "offset": 482.8,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "was written in the generate file that",
      "offset": 485.039,
      "duration": 3.121
    },
    {
      "lang": "en",
      "text": "the whole application should be",
      "offset": 486.8,
      "duration": 3.519
    },
    {
      "lang": "en",
      "text": "developed with example stages being of a",
      "offset": 488.16,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "whole app rather than an MVP. It didn't",
      "offset": 490.319,
      "duration": 4.641
    },
    {
      "lang": "en",
      "text": "really take the MVP scope into account.",
      "offset": 492.56,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "This brings me to the crucial point. You",
      "offset": 494.96,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "need to be very careful and read",
      "offset": 496.879,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "everything you give to these AI models",
      "offset": 498.56,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "because they will follow instructions",
      "offset": 500.639,
      "duration": 3.761
    },
    {
      "lang": "en",
      "text": "blindly. If there are any conflicts or",
      "offset": 502.24,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "contradictions, there's no telling which",
      "offset": 504.4,
      "duration": 3.519
    },
    {
      "lang": "en",
      "text": "one they'll follow. In my case, I",
      "offset": 506.16,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "specifically told it in the generate",
      "offset": 507.919,
      "duration": 3.441
    },
    {
      "lang": "en",
      "text": "file that it should first build the",
      "offset": 509.68,
      "duration": 3.599
    },
    {
      "lang": "en",
      "text": "foundations and do the setup, then",
      "offset": 511.36,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "include advanced features. So, it is",
      "offset": 513.279,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "following that because that's what it",
      "offset": 515.44,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "was told to do. Whether it's a file, a",
      "offset": 517.039,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "config, or anything else you generate",
      "offset": 519.2,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "from claude or chat GPT models. Please",
      "offset": 521.12,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "don't just blindly accept it. You need",
      "offset": 523.36,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "to read through everything carefully and",
      "offset": 525.2,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "adjust it to your own workflow. I highly",
      "offset": 527.36,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "recommend taking an hour to go through",
      "offset": 529.76,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "everything that needs to be done so that",
      "offset": 531.92,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "you don't face problems moving on. Now,",
      "offset": 533.92,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "another important thing that I recommend",
      "offset": 536.08,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "doing is this. I suggest you decide the",
      "offset": 537.92,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "tech stack yourself because even though",
      "offset": 540.48,
      "duration": 4.479
    },
    {
      "lang": "en",
      "text": "the whole workflow may look automated,",
      "offset": 542.56,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "eventually it's your decision because",
      "offset": 544.959,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "what if it integrates something that",
      "offset": 546.8,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "works with the PRD but doesn't work with",
      "offset": 548.56,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "you. For example, you have access to",
      "offset": 550.64,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "OpenAI models but it integrates clawed",
      "offset": 552.56,
      "duration": 4.959
    },
    {
      "lang": "en",
      "text": "models. Both work in the project but not",
      "offset": 555.12,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "for you. So instead of integrating the",
      "offset": 557.519,
      "duration": 4.481
    },
    {
      "lang": "en",
      "text": "tech stack discovery process into your",
      "offset": 559.519,
      "duration": 4.961
    },
    {
      "lang": "en",
      "text": "entire context ecosystem, I recommend",
      "offset": 562,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "researching it yourself. Now let me show",
      "offset": 564.48,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "you the workflow in action. As you can",
      "offset": 566.24,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "see on the left side, there's a process",
      "offset": 568.24,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "going on. I've asked it to start",
      "offset": 570.16,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "building the app and begin with stage",
      "offset": 571.76,
      "duration": 3.759
    },
    {
      "lang": "en",
      "text": "one. You might notice I started a",
      "offset": 573.68,
      "duration": 3.599
    },
    {
      "lang": "en",
      "text": "completely new chat. It doesn't know",
      "offset": 575.519,
      "duration": 3.521
    },
    {
      "lang": "en",
      "text": "anything about the project, but it gets",
      "offset": 577.279,
      "duration": 3.521
    },
    {
      "lang": "en",
      "text": "the context from the implementation",
      "offset": 579.04,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "plan. Everything's written at the top,",
      "offset": 580.8,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "what we're building, the tech stack, and",
      "offset": 582.64,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "so on. Let me show you what it did. It",
      "offset": 584.72,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "went ahead and created the to-dos.",
      "offset": 586.48,
      "duration": 3.359
    },
    {
      "lang": "en",
      "text": "Pretty simple stuff. It just picked up",
      "offset": 588.16,
      "duration": 2.96
    },
    {
      "lang": "en",
      "text": "what I had written and started",
      "offset": 589.839,
      "duration": 2.721
    },
    {
      "lang": "en",
      "text": "implementing them. It didn't need to",
      "offset": 591.12,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "divide the subtasks itself. This new",
      "offset": 592.56,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "feature in cursor is something I really",
      "offset": 594.64,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "like. It just copied exactly what I had",
      "offset": 596.399,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "specified and started executing it. As",
      "offset": 598.48,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "you can see, it's implementing them one",
      "offset": 600.48,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "by one. It's installing everything",
      "offset": 602.16,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "mentioned and going step by step. This",
      "offset": 603.92,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "was already available in claude code,",
      "offset": 606,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "but now that it's in cursor, it makes",
      "offset": 607.839,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "things a lot easier. The model knows",
      "offset": 609.76,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "exactly what it's doing. The context is",
      "offset": 611.839,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "right there and it's following the",
      "offset": 613.92,
      "duration": 3.359
    },
    {
      "lang": "en",
      "text": "instructions step by step. And you can",
      "offset": 615.44,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "see that as I told it to make all the",
      "offset": 617.279,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "folders, they're starting to take shape.",
      "offset": 619.2,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "If I collapse the view, we can already",
      "offset": 621.2,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "see our back end, our front end, our",
      "offset": 623.2,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "scripts, and our shared folders all",
      "offset": 625.44,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "starting to form. The whole project is",
      "offset": 627.519,
      "duration": 4.241
    },
    {
      "lang": "en",
      "text": "now being built from the ground up. You",
      "offset": 629.519,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "can see that now everything is being",
      "offset": 631.76,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "generated. All my basic foundations are",
      "offset": 633.36,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "being set up. If I go into the back end,",
      "offset": 635.6,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "you can see that the Python app is being",
      "offset": 637.76,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "configured because the model already",
      "offset": 639.76,
      "duration": 3.759
    },
    {
      "lang": "en",
      "text": "knows how to set it up. It understands",
      "offset": 641.6,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "what text stack is going to be used. So,",
      "offset": 643.519,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "it didn't need to think about that. Even",
      "offset": 645.68,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "if you do ask it explicitly, it's not a",
      "offset": 647.44,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "problem. But that was just my",
      "offset": 649.839,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "recommendation. Now that it knows what",
      "offset": 651.12,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "it needs to connect, it's using all the",
      "offset": 652.959,
      "duration": 4.721
    },
    {
      "lang": "en",
      "text": "APIs and laying down whatever foundation",
      "offset": 655.04,
      "duration": 4.799
    },
    {
      "lang": "en",
      "text": "is required. Everything it sets up now",
      "offset": 657.68,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "will be included in that initial",
      "offset": 659.839,
      "duration": 3.361
    },
    {
      "lang": "en",
      "text": "structure. One thing with software",
      "offset": 661.6,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "development is that you can't just go",
      "offset": 663.2,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "ahead and implement any feature at any",
      "offset": 664.88,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "time. You need the basic structure in",
      "offset": 667.12,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "place first. If that foundation isn't",
      "offset": 669.12,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "there, either you'll end up restarting",
      "offset": 671.04,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "everything from scratch or the amount of",
      "offset": 673.12,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "modification needed later will be too",
      "offset": 675.12,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "much. Reconfiguring and adding features",
      "offset": 677.12,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "without proper scalability in mind.",
      "offset": 679.36,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "Well, that kind of project just isn't",
      "offset": 681.519,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "good. Anyway, as you can see, this new",
      "offset": 683.36,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "to-do feature, even though it's moving",
      "offset": 685.44,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "slowly, the advantage is that everything",
      "offset": 687.44,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "stays on track. it doesn't forget what",
      "offset": 689.68,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "needs to be done and everything is being",
      "offset": 691.76,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "completed thoroughly. The model won't",
      "offset": 693.76,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "move on until it verifies the current",
      "offset": 695.68,
      "duration": 3.599
    },
    {
      "lang": "en",
      "text": "step. So now you can see it's",
      "offset": 697.76,
      "duration": 3.759
    },
    {
      "lang": "en",
      "text": "progressing. This will take some time",
      "offset": 699.279,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "and stage one is just about setting",
      "offset": 701.519,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "everything up. But here's what I want",
      "offset": 703.68,
      "duration": 2.96
    },
    {
      "lang": "en",
      "text": "you to take away. While these",
      "offset": 705.2,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "implementation plans will be available",
      "offset": 706.64,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "in the description below, you should",
      "offset": 708.64,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "create your own. If you want to use",
      "offset": 710.48,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "claude code, you can use these files",
      "offset": 712.24,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "with claude code as well. Just drag them",
      "offset": 714.24,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "in and when you enter the slash command,",
      "offset": 716.32,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "it'll generate everything for you. For",
      "offset": 718.48,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "example, I created this custom command",
      "offset": 720.32,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "called generate implementation. And all",
      "offset": 722.48,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "I need to do is copy the generate",
      "offset": 724.64,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "workflow file over here. That's it.",
      "offset": 726.32,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "It'll generate everything for me.",
      "offset": 728.24,
      "duration": 3.599
    },
    {
      "lang": "en",
      "text": "Another thing I really like about claude",
      "offset": 730,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "code is that it includes a cloud.md file",
      "offset": 731.839,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "which holds all the codebased",
      "offset": 734.72,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "documentation. But for managing the",
      "offset": 736.079,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "context window, using this documentation",
      "offset": 738,
      "duration": 4.639
    },
    {
      "lang": "en",
      "text": "approach with multiple files is way",
      "offset": 740.399,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "better than dumping everything into one",
      "offset": 742.639,
      "duration": 4.481
    },
    {
      "lang": "en",
      "text": "single file. Also, if I ask it to do",
      "offset": 744.639,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "something that requires multiple agents,",
      "offset": 747.12,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "Claude code will spin up those agents.",
      "offset": 749.279,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "This is where claude code has a slight",
      "offset": 751.519,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "advantage because all the agents can",
      "offset": 753.44,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "work at once. But that only helps in",
      "offset": 755.6,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "tasks where you don't need to go step by",
      "offset": 757.6,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "step. For example, this entire",
      "offset": 759.92,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "implementation plan needs to be done",
      "offset": 761.76,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "step by step. Each part has to connect",
      "offset": 763.92,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "sequentially. You can't just install",
      "offset": 766.32,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "everything in one go. Sure, for things",
      "offset": 768.079,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "like installing dependencies or setting",
      "offset": 770,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "up packages, that parallelism can help.",
      "offset": 772.079,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "But for most of these workflows, it has",
      "offset": 774.48,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "to be done one step at a time. Now,",
      "offset": 776.48,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "there are some things like generating UI",
      "offset": 778.399,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "variations where multiple agents really",
      "offset": 780.48,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "shine. They can each create different",
      "offset": 782.399,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "variations for you. And for that, we",
      "offset": 784.32,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "actually have a separate video dedicated",
      "offset": 786.399,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "to claude code that also falls under",
      "offset": 788.32,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "context management because in that",
      "offset": 790.48,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "video, I've used these rule files as",
      "offset": 792.32,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "well. So, definitely go check that out.",
      "offset": 794.24,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "That brings us to the end of this video.",
      "offset": 796.399,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "If you'd like to support the channel and",
      "offset": 798.32,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "help us keep making videos like this,",
      "offset": 800.079,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "you can do so by using the super thanks",
      "offset": 802.16,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "button below. As always, thank you for",
      "offset": 804.16,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "watching and I'll see you in the next",
      "offset": 806.48,
      "duration": 3.68
    }
  ],
  "cleanText": "You probably know about vibe coding, but turns out that when it was coined by Andrej Karpathy, it wasn't like he invented it. He just coined something that people had been doing for months. And now he has done it again. Karpathy, who was a founding member at OpenAI, has unknowingly coined another term, context engineering. And again, just like vibe coding, it's nothing new. Many people have been doing this practice. But one thing that he is right about is that this is absolutely necessary and this is the way that we should be coding with AI. Now, this is not just an explainer video. We will not only be going hands-on with what context engineering is and how you would prepare the context, but I will also show you how to properly use that context. And this is what most of you are completely missing.\n\nNow, the first thing to understand is that all models have context windows. It is the amount of text that they can currently remember. With the prompts that we were giving LLMs, we were phrasing things in a specific way to get a single good answer from the LLM. But here with context engineering, we're giving all relevant facts, rules, tools, and information and filling in the model's context window so that there is just no chance of hallucination and the model knows what it is doing. This way, we're actually working on what the model needs to remember in order to accomplish what we want.\n\nNow, if we look at the tweet in the first part, he tells us about how we're now shifting from prompt engineering to context engineering and essentially what context engineering consists of. There's also this diagram I found from another person that pretty nicely explains how context engineering isn't just a new form of prompt engineering. It's a broader term that includes everything from RAG to memory and also includes prompt engineering within it. So this whole art has now been termed as context engineering.\n\nIn the second part of the tweet, Andre actually tells us that it's not only the context we need to look at, it's also the app we're using because the LLM app isn't just a chat GPT wrapper anymore. It doesn't just contain an LLM. It uses that LLM and gives you tools and workflows that are actually useful. He specifies that the LLM app needs to have the components necessary for context engineering and that apps like Cursor AI, Claude Code, and other coding agents aren't just chat GPT wrappers anymore. They are actually important components in context engineering.\n\nNow, on the topic of the LLM apps we need to use, we have Cursor AI and Claude Code. Both have their own strengths, but right now Claude Code is much more powerful as an agent. Cursor AI has been catching up though, recently adding features like the to-do lists that Claude Code already had. Bottom line, the context engineering workflow I'm about to show you works in either app. So, you can use whichever one you've purchased.\n\nNow, I've explained what context engineering is, and you're all probably excited thinking we should just go ahead and give everything to the model to get the exact results we want. But here's the thing with these coding models. Remember the context window I told you about? Well, once that fills up, the chances of hallucination increase rather than things getting more accurate. So, efficient management of the context window is crucial. You can't just dump everything into one file. You need to break it down into pieces and only give it to the model when it's needed.\n\nSo, right now, I'm going to explain my workflow with context engineering. I've been doing this long before the term was even coined. It's just a new trend now. But there is something new I learned while watching a video by Cole Medan which was actually pretty great. It introduced the idea of including external documentation in the context window as well. So I got inspired by that and updated my workflow.\n\nComing back to my workflow. First we start with a PRD which is the project requirement document. In that we list the features we want. Based on that the model can decide what's best for us. If you're a developer you can add specific requirements to the PRD as well. For example, I've mentioned that I want Next.js for the front end and FastAPI for the back end. But even if you don't know what you want, the workflow I'm about to show you can automatically configure all of that and get you a ready-made app.\n\nNow, let's come to the part of the engineering workflow that actually has the context for the models, the documentation folder. These four files are the most important: the implementation plan, the project structure which is currently empty because it's still being generated, the UI and UX documentation, and finally bug tracking. These files are the different components that the AI model needs to complete the project.\n\nNow, this was context that the model will use, but the model should also know how to use it. For that, I've set up two rules, the generate rule and the work rule. First, the generate rule converts the PRD into all the other files. It basically generates full context for the development process. Once all that context has been generated, the models context limit gets full for that session and I won't be able to generate quality code further on. You can see this in Cursor AI because it uses models with limited context windows. They fill up quickly. If I were using Claude Code, this wouldn't happen as soon. But once I have all four files generated and ready, that becomes our complete context.\n\nNow if the model starts working on the project, it doesn't need to keep all of that loaded in its context. Otherwise, it'll just hallucinate more and more. That's why we move to an implementation plan so we can work through everything step by step. Now you might ask, how does Cursor AI even know how to use these files? That's where the workflow rule comes in. It's always attached to Cursor AI and tells it exactly how to use each file. When implementing the project, it looks at the implementation file. When working on UI and UX, it refers to the UI and UX documentation. If it's about to create something new or run a command, it checks the project structure to make sure it's consistent. And when there's an error or a bug, it first looks into the bug tracking file to make sure it wasn't already documented. This workflow rule regulates that entire process.\n\nI've purposely kept it small. You can see it's way smaller than the generate file, which is really long. The implementation plan is even longer. This is so that the workflow file which is to be always in the context takes as little place there as possible. In the implementation plan, we also have task lists. These are broader task lists and then they have their own subtasks. And you might say that Cursor AI and Claude Code already have their task lists. Yes, they do. But here when a subtask comes up, it decides whether to create a new task list in the LLM app to break that specific subtask if it is too long or if it's simple, then just follow the steps outlined in the current one.\n\nFor example, when we reach the core feature stage, and by the way, this implementation is for the entire app, not just the MVP. It proceeds step by step. You can narrow it down to just the MVP if you want. Right now, the full app's development is estimated at 3 to 4 weeks. If it were just the MVP, it would be a matter of hours. When it comes to something like designing and implementing the database and schema, that task would have been broken down into further tasks by Cursor AI. This is where Andre's advice on the LLM app being good enough comes in. And Cursor AI is good enough that it can decide on its own.\n\nAnd if you think that when you open a new chat, meaning the context window resets, Cursor AI will forget what the project was about, you don't have to worry about Cursor AI forgetting because everything's already written down in the implementation file. That's the core idea in context engineering. Of course, both of these files will be in the description and you can generate these documentation files for yourself. But again, I encourage you to create your own workflows. The important thing isn't that you got these implementation files from me. The important thing is that you understand what context engineering actually is. And with that understanding, you can build your own implementation, your own generation workflows, and the exact set of files that Cursor AI or Claude Code needs to follow.\n\nOh, and if you're enjoying the content we're making, I'd really appreciate it if you hit that subscribe button. We're also testing out channel memberships. launched the first tier as a test and 90 people have joined so far. The support's been incredible. So, we're thinking about launching additional tiers. Right now, members get priority replies to your comments. Perfect if you need feedback or have questions.\n\nNow, there's another important point you need to understand about context engineering. You can see that I wanted to make the implementation plan for an MVP, but it's been taken to an advanced level because of my generate prompt. Even though I mentioned that I wanted an MVP since it was written in the generate file that the whole application should be developed with example stages being of a whole app rather than an MVP. It didn't really take the MVP scope into account. This brings me to the crucial point. You need to be very careful and read everything you give to these AI models because they will follow instructions blindly. If there are any conflicts or contradictions, there's no telling which one they'll follow. In my case, I specifically told it in the generate file that it should first build the foundations and do the setup, then include advanced features. So, it is following that because that's what it was told to do. Whether it's a file, a config, or anything else you generate from Claude or chat GPT models. Please don't just blindly accept it. You need to read through everything carefully and adjust it to your own workflow. I highly recommend taking an hour to go through everything that needs to be done so that you don't face problems moving on.\n\nNow, another important thing that I recommend doing is this. I suggest you decide the tech stack yourself because even though the whole workflow may look automated, eventually it's your decision because what if it integrates something that works with the PRD but doesn't work with you. For example, you have access to OpenAI models but it integrates clawed models. Both work in the project but not for you. So instead of integrating the tech stack discovery process into your entire context ecosystem, I recommend researching it yourself.\n\nNow let me show you the workflow in action. As you can see on the left side, there's a process going on. I've asked it to start building the app and begin with stage one. You might notice I started a completely new chat. It doesn't know anything about the project, but it gets the context from the implementation plan. Everything's written at the top, what we're building, the tech stack, and so on. Let me show you what it did. It went ahead and created the to-dos. Pretty simple stuff. It just picked up what I had written and started implementing them. It didn't need to divide the subtasks itself. This new feature in Cursor AI is something I really like. It just copied exactly what I had specified and started executing it. As you can see, it's implementing them one by one. It's installing everything mentioned and going step by step. This was already available in Claude Code, but now that it's in Cursor AI, it makes things a lot easier. The model knows exactly what it's doing. The context is right there and it's following the instructions step by step. And you can see that as I told it to make all the folders, they're starting to take shape. If I collapse the view, we can already see our back end, our front end, our scripts, and our shared folders all starting to form. The whole project is now being built from the ground up. You can see that now everything is being generated. All my basic foundations are being set up. If I go into the back end, you can see that the Python app is being configured because the model already knows how to set it up. It understands what text stack is going to be used. So, it didn't need to think about that. Even if you do ask it explicitly, it's not a problem. But that was just my recommendation. Now that it knows what it needs to connect, it's using all the APIs and laying down whatever foundation is required. Everything it sets up now will be included in that initial structure.\n\nOne thing with software development is that you can't just go ahead and implement any feature at any time. You need the basic structure in place first. If that foundation isn't there, either you'll end up restarting everything from scratch or the amount of modification needed later will be too much. Reconfiguring and adding features without proper scalability in mind. Well, that kind of project just isn't good. Anyway, as you can see, this new to-do feature, even though it's moving slowly, the advantage is that everything stays on track. it doesn't forget what needs to be done and everything is being completed thoroughly. The model won't move on until it verifies the current step. So now you can see it's progressing. This will take some time and stage one is just about setting everything up. But here's what I want you to take away. While these implementation plans will be available in the description below, you should create your own. If you want to use Claude Code, you can use these files with Claude Code as well. Just drag them in and when you enter the slash command, it'll generate everything for you. For example, I created this custom command called generate implementation. And all I need to do is copy the generate workflow file over here. That's it. It'll generate everything for me.\n\nAnother thing I really like about Claude Code is that it includes a cloud.md file which holds all the codebased documentation. But for managing the context window, using this documentation approach with multiple files is way better than dumping everything into one single file. Also, if I ask it to do something that requires multiple agents, Claude Code will spin up those agents. This is where Claude Code has a slight advantage because all the agents can work at once. But that only helps in tasks where you don't need to go step by step. For example, this entire implementation plan needs to be done step by step. Each part has to connect sequentially. You can't just install everything in one go. Sure, for things like installing dependencies or setting up packages, that parallelism can help. But for most of these workflows, it has to be done one step at a time. Now, there are some things like generating UI variations where multiple agents really shine. They can each create different variations for you. And for that, we actually have a separate video dedicated to Claude Code that also falls under context management because in that video, I've used these rule files as well. So, definitely go check that out.\n\nThat brings us to the end of this video. If you'd like to support the channel and help us\n\n\nKeep making videos like this.\nYou can do so by using the super thanks button below.\nAs always, thank you for watching, and I'll see you in the next.\n",
  "dumpedAt": "2025-07-21T18:43:25.710Z"
}