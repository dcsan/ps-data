{
  "episodeId": "jkrNMKz9pWU",
  "channelSlug": "@howardjeremyp",
  "title": "A Hackers' Guide to Language Models",
  "publishedAt": "2023-09-24T07:09:20.000Z",
  "rawLines": [
    {
      "lang": "en",
      "text": "hi I am Jeremy Howard from fast.ai and",
      "offset": 0.539,
      "duration": 6.661
    },
    {
      "lang": "en",
      "text": "this is a hacker's guide to language",
      "offset": 4.62,
      "duration": 5.1
    },
    {
      "lang": "en",
      "text": "models",
      "offset": 7.2,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "when I say a hacker's guide what we're",
      "offset": 9.72,
      "duration": 5.039
    },
    {
      "lang": "en",
      "text": "going to be looking at is a code first",
      "offset": 12,
      "duration": 4.98
    },
    {
      "lang": "en",
      "text": "approach to understanding how to use",
      "offset": 14.759,
      "duration": 5.221
    },
    {
      "lang": "en",
      "text": "language models in practice",
      "offset": 16.98,
      "duration": 4.86
    },
    {
      "lang": "en",
      "text": "so before we get started we should",
      "offset": 19.98,
      "duration": 3.42
    },
    {
      "lang": "en",
      "text": "probably talk about what is a language",
      "offset": 21.84,
      "duration": 3.62
    },
    {
      "lang": "en",
      "text": "model",
      "offset": 23.4,
      "duration": 5.119
    },
    {
      "lang": "en",
      "text": "I would say that",
      "offset": 25.46,
      "duration": 6.399
    },
    {
      "lang": "en",
      "text": "this is going to make more sense if you",
      "offset": 28.519,
      "duration": 6.301
    },
    {
      "lang": "en",
      "text": "know the kind of basics of deep learning",
      "offset": 31.859,
      "duration": 5.761
    },
    {
      "lang": "en",
      "text": "if you don't I think you'll still get",
      "offset": 34.82,
      "duration": 4.239
    },
    {
      "lang": "en",
      "text": "plenty out of it and there'll be plenty",
      "offset": 37.62,
      "duration": 4.439
    },
    {
      "lang": "en",
      "text": "of things you can do but if you do have",
      "offset": 39.059,
      "duration": 5.301
    },
    {
      "lang": "en",
      "text": "a chance I would recommend checking out",
      "offset": 42.059,
      "duration": 4.701
    },
    {
      "lang": "en",
      "text": "course.fast.ai which is a free course",
      "offset": 44.36,
      "duration": 5.62
    },
    {
      "lang": "en",
      "text": "and specifically",
      "offset": 46.76,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "um",
      "offset": 49.98,
      "duration": 3.72
    },
    {
      "lang": "en",
      "text": "if you could at least kind of watch if",
      "offset": 50.76,
      "duration": 6.299
    },
    {
      "lang": "en",
      "text": "not work through the first five lessons",
      "offset": 53.7,
      "duration": 5.999
    },
    {
      "lang": "en",
      "text": "that would get you to a point where you",
      "offset": 57.059,
      "duration": 5.16
    },
    {
      "lang": "en",
      "text": "understand all the basic fundamentals of",
      "offset": 59.699,
      "duration": 5.901
    },
    {
      "lang": "en",
      "text": "deep learning that will make this this",
      "offset": 62.219,
      "duration": 6.561
    },
    {
      "lang": "en",
      "text": "lesson tutorial make even more sense",
      "offset": 65.6,
      "duration": 5.559
    },
    {
      "lang": "en",
      "text": "maybe I shouldn't call this a tutorial",
      "offset": 68.78,
      "duration": 5.019
    },
    {
      "lang": "en",
      "text": "it's more of a quick run through so I've",
      "offset": 71.159,
      "duration": 4.441
    },
    {
      "lang": "en",
      "text": "got to try to run through all the basic",
      "offset": 73.799,
      "duration": 5.161
    },
    {
      "lang": "en",
      "text": "ideas of language models how to use them",
      "offset": 75.6,
      "duration": 6.42
    },
    {
      "lang": "en",
      "text": "both open source ones and open AI based",
      "offset": 78.96,
      "duration": 4.799
    },
    {
      "lang": "en",
      "text": "ones and it's all going to be based",
      "offset": 82.02,
      "duration": 5.7
    },
    {
      "lang": "en",
      "text": "using Code as much as possible",
      "offset": 83.759,
      "duration": 6.9
    },
    {
      "lang": "en",
      "text": "um so let's start by talking about what",
      "offset": 87.72,
      "duration": 5.939
    },
    {
      "lang": "en",
      "text": "a language model is and so as you might",
      "offset": 90.659,
      "duration": 4.741
    },
    {
      "lang": "en",
      "text": "have heard before a language model is",
      "offset": 93.659,
      "duration": 3.301
    },
    {
      "lang": "en",
      "text": "something that knows how to predict the",
      "offset": 95.4,
      "duration": 3.78
    },
    {
      "lang": "en",
      "text": "next word of a sentence or knows how to",
      "offset": 96.96,
      "duration": 4.339
    },
    {
      "lang": "en",
      "text": "fill in the missing words of a sentence",
      "offset": 99.18,
      "duration": 4.68
    },
    {
      "lang": "en",
      "text": "and we can look at an example of one",
      "offset": 101.299,
      "duration": 5.261
    },
    {
      "lang": "en",
      "text": "open AI has a language model text",
      "offset": 103.86,
      "duration": 6.48
    },
    {
      "lang": "en",
      "text": "DaVinci 003 and we can play with it by",
      "offset": 106.56,
      "duration": 5.699
    },
    {
      "lang": "en",
      "text": "passing in",
      "offset": 110.34,
      "duration": 4.919
    },
    {
      "lang": "en",
      "text": "some words and ask it to predict what",
      "offset": 112.259,
      "duration": 6.241
    },
    {
      "lang": "en",
      "text": "the next words might be so if we pass in",
      "offset": 115.259,
      "duration": 5.22
    },
    {
      "lang": "en",
      "text": "when I arrived back at the panda",
      "offset": 118.5,
      "duration": 3.54
    },
    {
      "lang": "en",
      "text": "breeding facility after the",
      "offset": 120.479,
      "duration": 3.541
    },
    {
      "lang": "en",
      "text": "extraordinary reign of live frogs I",
      "offset": 122.04,
      "duration": 4.619
    },
    {
      "lang": "en",
      "text": "couldn't believe what I saw I just came",
      "offset": 124.02,
      "duration": 3.959
    },
    {
      "lang": "en",
      "text": "up with that yesterday and I thought",
      "offset": 126.659,
      "duration": 3.181
    },
    {
      "lang": "en",
      "text": "what might happen next so kind of fun",
      "offset": 127.979,
      "duration": 4.98
    },
    {
      "lang": "en",
      "text": "for Creative brainstorming uh there's a",
      "offset": 129.84,
      "duration": 5.82
    },
    {
      "lang": "en",
      "text": "nice site called nat.dev",
      "offset": 132.959,
      "duration": 5.341
    },
    {
      "lang": "en",
      "text": "Nat dot let Dev lets us play with a",
      "offset": 135.66,
      "duration": 4.38
    },
    {
      "lang": "en",
      "text": "variety of language models and here I've",
      "offset": 138.3,
      "duration": 5.1
    },
    {
      "lang": "en",
      "text": "selected text DaVinci 003 and I'll hit",
      "offset": 140.04,
      "duration": 7.199
    },
    {
      "lang": "en",
      "text": "submit and it starts printing stuff out",
      "offset": 143.4,
      "duration": 6.18
    },
    {
      "lang": "en",
      "text": "the pandas were happily playing and",
      "offset": 147.239,
      "duration": 3.901
    },
    {
      "lang": "en",
      "text": "eating the frogs that had fallen from",
      "offset": 149.58,
      "duration": 3.54
    },
    {
      "lang": "en",
      "text": "the sky there's an amazing sight to see",
      "offset": 151.14,
      "duration": 3.599
    },
    {
      "lang": "en",
      "text": "these animals taking advantage of such a",
      "offset": 153.12,
      "duration": 3.54
    },
    {
      "lang": "en",
      "text": "unique opportunity",
      "offset": 154.739,
      "duration": 4.261
    },
    {
      "lang": "en",
      "text": "first after quick measures to ensure the",
      "offset": 156.66,
      "duration": 4.439
    },
    {
      "lang": "en",
      "text": "safety of the pandas and the frogs so",
      "offset": 159,
      "duration": 3.18
    },
    {
      "lang": "en",
      "text": "there you go that's what happened after",
      "offset": 161.099,
      "duration": 3
    },
    {
      "lang": "en",
      "text": "the extraordinary reign of live frogs at",
      "offset": 162.18,
      "duration": 4.44
    },
    {
      "lang": "en",
      "text": "the panda breeding facility uh you'll",
      "offset": 164.099,
      "duration": 4.92
    },
    {
      "lang": "en",
      "text": "see here that I've enabled show",
      "offset": 166.62,
      "duration": 3.899
    },
    {
      "lang": "en",
      "text": "probabilities which is a thing in",
      "offset": 169.019,
      "duration": 4.141
    },
    {
      "lang": "en",
      "text": "that.dev where it shows",
      "offset": 170.519,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "um well let's take a look it's pretty",
      "offset": 173.16,
      "duration": 3.78
    },
    {
      "lang": "en",
      "text": "likely the next word here is going to be",
      "offset": 175.319,
      "duration": 3.901
    },
    {
      "lang": "en",
      "text": "the and after this since we're talking",
      "offset": 176.94,
      "duration": 3.72
    },
    {
      "lang": "en",
      "text": "about a panda breeding facility it's",
      "offset": 179.22,
      "duration": 3.299
    },
    {
      "lang": "en",
      "text": "going to be Panda's were and what were",
      "offset": 180.66,
      "duration": 3.54
    },
    {
      "lang": "en",
      "text": "they doing well they could have been",
      "offset": 182.519,
      "duration": 3.061
    },
    {
      "lang": "en",
      "text": "doing a few things they could have been",
      "offset": 184.2,
      "duration": 2.94
    },
    {
      "lang": "en",
      "text": "doing something happily",
      "offset": 185.58,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "or the pandas were having the pandas",
      "offset": 187.14,
      "duration": 5.16
    },
    {
      "lang": "en",
      "text": "were out the pandas were playing so it",
      "offset": 189.66,
      "duration": 5.159
    },
    {
      "lang": "en",
      "text": "picked the most likely uh it thought it",
      "offset": 192.3,
      "duration": 4.26
    },
    {
      "lang": "en",
      "text": "was 20 likely it's going to be happily",
      "offset": 194.819,
      "duration": 4.441
    },
    {
      "lang": "en",
      "text": "and what were they happily doing",
      "offset": 196.56,
      "duration": 4.44
    },
    {
      "lang": "en",
      "text": "could have been playing",
      "offset": 199.26,
      "duration": 3.059
    },
    {
      "lang": "en",
      "text": "hopping",
      "offset": 201,
      "duration": 2.819
    },
    {
      "lang": "en",
      "text": "eating",
      "offset": 202.319,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "and so forth",
      "offset": 203.819,
      "duration": 5.161
    },
    {
      "lang": "en",
      "text": "so they're eating the frogs that and",
      "offset": 206.159,
      "duration": 5.521
    },
    {
      "lang": "en",
      "text": "then had almost certainly so you can see",
      "offset": 208.98,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "what it's doing at each point is it's",
      "offset": 211.68,
      "duration": 4.26
    },
    {
      "lang": "en",
      "text": "predicting the probability of a variety",
      "offset": 213.78,
      "duration": 4.679
    },
    {
      "lang": "en",
      "text": "of possible next words and depending on",
      "offset": 215.94,
      "duration": 4.98
    },
    {
      "lang": "en",
      "text": "how you set it up it will either pick",
      "offset": 218.459,
      "duration": 4.941
    },
    {
      "lang": "en",
      "text": "the most likely one every time",
      "offset": 220.92,
      "duration": 5.58
    },
    {
      "lang": "en",
      "text": "or you can change muck around with",
      "offset": 223.4,
      "duration": 6.18
    },
    {
      "lang": "en",
      "text": "things like P values and temperatures",
      "offset": 226.5,
      "duration": 8.819
    },
    {
      "lang": "en",
      "text": "to change what comes up so at each time",
      "offset": 229.58,
      "duration": 9.12
    },
    {
      "lang": "en",
      "text": "then it'll give us a different result",
      "offset": 235.319,
      "duration": 7.161
    },
    {
      "lang": "en",
      "text": "and this is kind of fun",
      "offset": 238.7,
      "duration": 3.78
    },
    {
      "lang": "en",
      "text": "frogs perched on the heads of some of",
      "offset": 243.12,
      "duration": 4.619
    },
    {
      "lang": "en",
      "text": "the pandas it was an amazing sight",
      "offset": 245.34,
      "duration": 4.02
    },
    {
      "lang": "en",
      "text": "etc etc",
      "offset": 247.739,
      "duration": 2.941
    },
    {
      "lang": "en",
      "text": "okay",
      "offset": 249.36,
      "duration": 6.18
    },
    {
      "lang": "en",
      "text": "so that's what a language model does",
      "offset": 250.68,
      "duration": 6.979
    },
    {
      "lang": "en",
      "text": "um",
      "offset": 255.54,
      "duration": 2.119
    },
    {
      "lang": "en",
      "text": "now you might notice",
      "offset": 258.299,
      "duration": 5.821
    },
    {
      "lang": "en",
      "text": "here it hasn't predicted pandas it's",
      "offset": 261,
      "duration": 6.06
    },
    {
      "lang": "en",
      "text": "predicted panned",
      "offset": 264.12,
      "duration": 4.799
    },
    {
      "lang": "en",
      "text": "and then separately",
      "offset": 267.06,
      "duration": 3.06
    },
    {
      "lang": "en",
      "text": "us",
      "offset": 268.919,
      "duration": 3.541
    },
    {
      "lang": "en",
      "text": "okay after Panda it's going to be us so",
      "offset": 270.12,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "it's not always a whole word",
      "offset": 272.46,
      "duration": 4.14
    },
    {
      "lang": "en",
      "text": "here it's an",
      "offset": 274.44,
      "duration": 3.9
    },
    {
      "lang": "en",
      "text": "and then harmed",
      "offset": 276.6,
      "duration": 5.94
    },
    {
      "lang": "en",
      "text": "oh actually it's unha mood so you can",
      "offset": 278.34,
      "duration": 5.639
    },
    {
      "lang": "en",
      "text": "see that it's not always predicting",
      "offset": 282.54,
      "duration": 3
    },
    {
      "lang": "en",
      "text": "words specifically what it's doing is",
      "offset": 283.979,
      "duration": 4.981
    },
    {
      "lang": "en",
      "text": "predicting tokens uh tokens are either",
      "offset": 285.54,
      "duration": 8.159
    },
    {
      "lang": "en",
      "text": "whole words or sub word units pieces of",
      "offset": 288.96,
      "duration": 6.54
    },
    {
      "lang": "en",
      "text": "a word or it could even be punctuation",
      "offset": 293.699,
      "duration": 5.301
    },
    {
      "lang": "en",
      "text": "or numbers or so forth",
      "offset": 295.5,
      "duration": 3.5
    },
    {
      "lang": "en",
      "text": "um so let's have a look at how that",
      "offset": 300.78,
      "duration": 4.26
    },
    {
      "lang": "en",
      "text": "works so for example we can use the",
      "offset": 302.1,
      "duration": 3.9
    },
    {
      "lang": "en",
      "text": "actual",
      "offset": 305.04,
      "duration": 2.879
    },
    {
      "lang": "en",
      "text": "um it's called tokenization to create",
      "offset": 306,
      "duration": 4.62
    },
    {
      "lang": "en",
      "text": "tokens from us from a uh from a string",
      "offset": 307.919,
      "duration": 6.241
    },
    {
      "lang": "en",
      "text": "we can use the same tokenizer that GPT",
      "offset": 310.62,
      "duration": 6.12
    },
    {
      "lang": "en",
      "text": "uses by using tick token and we can",
      "offset": 314.16,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "specifically say we want to use the same",
      "offset": 316.74,
      "duration": 4.38
    },
    {
      "lang": "en",
      "text": "tokenizer that that model text",
      "offset": 319.04,
      "duration": 4.54
    },
    {
      "lang": "en",
      "text": "eventually double O three uses and so",
      "offset": 321.12,
      "duration": 5.579
    },
    {
      "lang": "en",
      "text": "for example when I earlier tried this it",
      "offset": 323.58,
      "duration": 5.7
    },
    {
      "lang": "en",
      "text": "talked about the Frog splashing and so I",
      "offset": 326.699,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "thought I'll include data we'll encode",
      "offset": 329.28,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "they are splashing and the result is a",
      "offset": 331.02,
      "duration": 4.38
    },
    {
      "lang": "en",
      "text": "bunch of numbers",
      "offset": 333.6,
      "duration": 3.72
    },
    {
      "lang": "en",
      "text": "and what those numbers are they'd",
      "offset": 335.4,
      "duration": 4.44
    },
    {
      "lang": "en",
      "text": "basically just lookups into a vocabulary",
      "offset": 337.32,
      "duration": 4.92
    },
    {
      "lang": "en",
      "text": "that openai in this case created and if",
      "offset": 339.84,
      "duration": 4.44
    },
    {
      "lang": "en",
      "text": "you train your own models you'll be",
      "offset": 342.24,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "automatically creating or your code will",
      "offset": 344.28,
      "duration": 2.34
    },
    {
      "lang": "en",
      "text": "create",
      "offset": 345.84,
      "duration": 4.62
    },
    {
      "lang": "en",
      "text": "and if I then decode those it says oh",
      "offset": 346.62,
      "duration": 5.82
    },
    {
      "lang": "en",
      "text": "these numbers are they",
      "offset": 350.46,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "space r space spool",
      "offset": 352.44,
      "duration": 5.22
    },
    {
      "lang": "en",
      "text": "hashing",
      "offset": 356.46,
      "duration": 3.06
    },
    {
      "lang": "en",
      "text": "and so put that all together they are",
      "offset": 357.66,
      "duration": 4.5
    },
    {
      "lang": "en",
      "text": "splashing so you can see that",
      "offset": 359.52,
      "duration": 6.36
    },
    {
      "lang": "en",
      "text": "the start of a word is give me the space",
      "offset": 362.16,
      "duration": 9.2
    },
    {
      "lang": "en",
      "text": "before it is also being encoded here",
      "offset": 365.88,
      "duration": 5.48
    },
    {
      "lang": "en",
      "text": "so these um language models are quite",
      "offset": 371.72,
      "duration": 9.4
    },
    {
      "lang": "en",
      "text": "neat that they can work at all but",
      "offset": 376.88,
      "duration": 6.759
    },
    {
      "lang": "en",
      "text": "they're not of themselves really",
      "offset": 381.12,
      "duration": 6.18
    },
    {
      "lang": "en",
      "text": "designed to do anything",
      "offset": 383.639,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "um uh let me explain",
      "offset": 387.3,
      "duration": 5.58
    },
    {
      "lang": "en",
      "text": "um the basic idea",
      "offset": 389.639,
      "duration": 9.261
    },
    {
      "lang": "en",
      "text": "of what chat GPT gpt4 Bard Etc are doing",
      "offset": 392.88,
      "duration": 8.599
    },
    {
      "lang": "en",
      "text": "comes from a paper",
      "offset": 398.9,
      "duration": 5.38
    },
    {
      "lang": "en",
      "text": "which describes an algorithm that I",
      "offset": 401.479,
      "duration": 6.461
    },
    {
      "lang": "en",
      "text": "created back in 2017 called ULM fit and",
      "offset": 404.28,
      "duration": 5.759
    },
    {
      "lang": "en",
      "text": "Sebastian Rooter and I wrote a paper up",
      "offset": 407.94,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "describing the ULM fit approach which",
      "offset": 410.039,
      "duration": 4.141
    },
    {
      "lang": "en",
      "text": "was the one that basically laid out",
      "offset": 412.02,
      "duration": 4.019
    },
    {
      "lang": "en",
      "text": "what everybody's doing how this system",
      "offset": 414.18,
      "duration": 5.519
    },
    {
      "lang": "en",
      "text": "works and the system has three steps",
      "offset": 416.039,
      "duration": 5.401
    },
    {
      "lang": "en",
      "text": "step one is",
      "offset": 419.699,
      "duration": 3.78
    },
    {
      "lang": "en",
      "text": "language model training but you'll see",
      "offset": 421.44,
      "duration": 3.9
    },
    {
      "lang": "en",
      "text": "this is actually from the paper we",
      "offset": 423.479,
      "duration": 4.201
    },
    {
      "lang": "en",
      "text": "actually described it as pre-training",
      "offset": 425.34,
      "duration": 4.139
    },
    {
      "lang": "en",
      "text": "now what language model pre-training",
      "offset": 427.68,
      "duration": 4.38
    },
    {
      "lang": "en",
      "text": "does is this is the thing which predicts",
      "offset": 429.479,
      "duration": 5.22
    },
    {
      "lang": "en",
      "text": "the next word of a sentence and so in",
      "offset": 432.06,
      "duration": 4.979
    },
    {
      "lang": "en",
      "text": "the original ULM fit paper so the",
      "offset": 434.699,
      "duration": 4.681
    },
    {
      "lang": "en",
      "text": "algorithm I developed in 2017 then",
      "offset": 437.039,
      "duration": 4.44
    },
    {
      "lang": "en",
      "text": "Sebastian Rooter and I wrote it up in",
      "offset": 439.38,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "2018 early 2018",
      "offset": 441.479,
      "duration": 5.761
    },
    {
      "lang": "en",
      "text": "what I originally did was I trained this",
      "offset": 444.02,
      "duration": 5.32
    },
    {
      "lang": "en",
      "text": "language model on Wikipedia now what",
      "offset": 447.24,
      "duration": 6.6
    },
    {
      "lang": "en",
      "text": "that meant is I took a neural network",
      "offset": 449.34,
      "duration": 6.359
    },
    {
      "lang": "en",
      "text": "um and a neural network is just a",
      "offset": 453.84,
      "duration": 3
    },
    {
      "lang": "en",
      "text": "function if you don't know what it is",
      "offset": 455.699,
      "duration": 2.581
    },
    {
      "lang": "en",
      "text": "it's just a mathematical function that's",
      "offset": 456.84,
      "duration": 3.479
    },
    {
      "lang": "en",
      "text": "extremely flexible and it's got lots and",
      "offset": 458.28,
      "duration": 3.539
    },
    {
      "lang": "en",
      "text": "lots of parameters and initially it",
      "offset": 460.319,
      "duration": 4.681
    },
    {
      "lang": "en",
      "text": "can't do anything but using stochastic",
      "offset": 461.819,
      "duration": 5.88
    },
    {
      "lang": "en",
      "text": "gradient descent or SGD you can teach it",
      "offset": 465,
      "duration": 4.74
    },
    {
      "lang": "en",
      "text": "to do almost anything if you give it",
      "offset": 467.699,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "examples and so I gave it lots of",
      "offset": 469.74,
      "duration": 4.679
    },
    {
      "lang": "en",
      "text": "examples of sentences from Wikipedia so",
      "offset": 471.78,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "for example from the Wikipedia article",
      "offset": 474.419,
      "duration": 4.861
    },
    {
      "lang": "en",
      "text": "for the birds the birds is a 1963",
      "offset": 476.34,
      "duration": 5.88
    },
    {
      "lang": "en",
      "text": "American Natural horror natural horror",
      "offset": 479.28,
      "duration": 4.74
    },
    {
      "lang": "en",
      "text": "Thriller film produced and directed by",
      "offset": 482.22,
      "duration": 3.96
    },
    {
      "lang": "en",
      "text": "Alfred and then it would stop",
      "offset": 484.02,
      "duration": 3.959
    },
    {
      "lang": "en",
      "text": "and so then the model would have to",
      "offset": 486.18,
      "duration": 3.9
    },
    {
      "lang": "en",
      "text": "guess what the next word is",
      "offset": 487.979,
      "duration": 4.801
    },
    {
      "lang": "en",
      "text": "and if it guest Hitchcock it would be",
      "offset": 490.08,
      "duration": 5.22
    },
    {
      "lang": "en",
      "text": "rewarded and if it gets guessed",
      "offset": 492.78,
      "duration": 4.859
    },
    {
      "lang": "en",
      "text": "something else it would be penalized and",
      "offset": 495.3,
      "duration": 3.899
    },
    {
      "lang": "en",
      "text": "effectively basically it's trying to",
      "offset": 497.639,
      "duration": 3.721
    },
    {
      "lang": "en",
      "text": "maximize those rewards it's trying to",
      "offset": 499.199,
      "duration": 4.68
    },
    {
      "lang": "en",
      "text": "find a set of weights for this function",
      "offset": 501.36,
      "duration": 4.38
    },
    {
      "lang": "en",
      "text": "that makes it more likely that it would",
      "offset": 503.879,
      "duration": 4.021
    },
    {
      "lang": "en",
      "text": "predict Hitchcock and then later on in",
      "offset": 505.74,
      "duration": 4.92
    },
    {
      "lang": "en",
      "text": "this article it reads from Wikipedia at",
      "offset": 507.9,
      "duration": 5.34
    },
    {
      "lang": "en",
      "text": "a previously dated Mitch but ended it",
      "offset": 510.66,
      "duration": 4.499
    },
    {
      "lang": "en",
      "text": "due to Mitch's cold overbearing mother",
      "offset": 513.24,
      "duration": 5.58
    },
    {
      "lang": "en",
      "text": "Lydia who dislikes any woman in mitches",
      "offset": 515.159,
      "duration": 6.06
    },
    {
      "lang": "en",
      "text": "now you can see that filling this in",
      "offset": 518.82,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "actually requires being pretty",
      "offset": 521.219,
      "duration": 3.781
    },
    {
      "lang": "en",
      "text": "thoughtful because there's a bunch of",
      "offset": 523.62,
      "duration": 4.02
    },
    {
      "lang": "en",
      "text": "things that like kind of logically could",
      "offset": 525,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "go there like a woman could be in",
      "offset": 527.64,
      "duration": 3.42
    },
    {
      "lang": "en",
      "text": "Mitch's",
      "offset": 529.56,
      "duration": 6.86
    },
    {
      "lang": "en",
      "text": "closet could be in which is house",
      "offset": 531.06,
      "duration": 7.86
    },
    {
      "lang": "en",
      "text": "and so you know you could probably guess",
      "offset": 536.42,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "in the Wikipedia article describing the",
      "offset": 538.92,
      "duration": 3.539
    },
    {
      "lang": "en",
      "text": "plot of the birds it's actually any",
      "offset": 541.14,
      "duration": 4.139
    },
    {
      "lang": "en",
      "text": "woman in Mitch's life",
      "offset": 542.459,
      "duration": 4.38
    },
    {
      "lang": "en",
      "text": "now",
      "offset": 545.279,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "to do a good job",
      "offset": 546.839,
      "duration": 5.041
    },
    {
      "lang": "en",
      "text": "of solving this problem as well as",
      "offset": 549.12,
      "duration": 5.159
    },
    {
      "lang": "en",
      "text": "possible of guessing the next word of",
      "offset": 551.88,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "sentences",
      "offset": 554.279,
      "duration": 3.361
    },
    {
      "lang": "en",
      "text": "the neural network",
      "offset": 555.32,
      "duration": 6.16
    },
    {
      "lang": "en",
      "text": "is gonna have to learn a lot of stuff",
      "offset": 557.64,
      "duration": 7.74
    },
    {
      "lang": "en",
      "text": "about the world it's going to learn",
      "offset": 561.48,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "that there are things called objects",
      "offset": 565.38,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "that there's a thing called time that",
      "offset": 567.48,
      "duration": 5.16
    },
    {
      "lang": "en",
      "text": "objects react to each other over time",
      "offset": 569.22,
      "duration": 5.88
    },
    {
      "lang": "en",
      "text": "that there are things called movies that",
      "offset": 572.64,
      "duration": 4.92
    },
    {
      "lang": "en",
      "text": "movies have directors that there are",
      "offset": 575.1,
      "duration": 4.02
    },
    {
      "lang": "en",
      "text": "people that people have names and so",
      "offset": 577.56,
      "duration": 3.66
    },
    {
      "lang": "en",
      "text": "forth and that a movie director is",
      "offset": 579.12,
      "duration": 4.02
    },
    {
      "lang": "en",
      "text": "Alfred Hitchcock and he directed horror",
      "offset": 581.22,
      "duration": 3.9
    },
    {
      "lang": "en",
      "text": "films and",
      "offset": 583.14,
      "duration": 2.819
    },
    {
      "lang": "en",
      "text": "um",
      "offset": 585.12,
      "duration": 4.02
    },
    {
      "lang": "en",
      "text": "so on and so forth it's going to have to",
      "offset": 585.959,
      "duration": 5.221
    },
    {
      "lang": "en",
      "text": "learn extraordinary amount if it's going",
      "offset": 589.14,
      "duration": 3.54
    },
    {
      "lang": "en",
      "text": "to do a really good job of predicting",
      "offset": 591.18,
      "duration": 3.48
    },
    {
      "lang": "en",
      "text": "the next word of sentences",
      "offset": 592.68,
      "duration": 5.099
    },
    {
      "lang": "en",
      "text": "now these neural networks specifically",
      "offset": 594.66,
      "duration": 5.1
    },
    {
      "lang": "en",
      "text": "are deep neural networks so this is deep",
      "offset": 597.779,
      "duration": 4.141
    },
    {
      "lang": "en",
      "text": "learning and in these deep neural",
      "offset": 599.76,
      "duration": 4.62
    },
    {
      "lang": "en",
      "text": "networks which have",
      "offset": 601.92,
      "duration": 4.14
    },
    {
      "lang": "en",
      "text": "um when when I created this I think it",
      "offset": 604.38,
      "duration": 4.019
    },
    {
      "lang": "en",
      "text": "had like 100 million parameters nowadays",
      "offset": 606.06,
      "duration": 4.86
    },
    {
      "lang": "en",
      "text": "they have billions of parameters",
      "offset": 608.399,
      "duration": 4.521
    },
    {
      "lang": "en",
      "text": "um",
      "offset": 610.92,
      "duration": 2
    },
    {
      "lang": "en",
      "text": "it's got the ability to create a rich",
      "offset": 613.08,
      "duration": 6.18
    },
    {
      "lang": "en",
      "text": "hierarchy of abstractions and",
      "offset": 616.94,
      "duration": 6.06
    },
    {
      "lang": "en",
      "text": "representations which it can build on",
      "offset": 619.26,
      "duration": 8.519
    },
    {
      "lang": "en",
      "text": "and so this is really the the key idea",
      "offset": 623,
      "duration": 6.459
    },
    {
      "lang": "en",
      "text": "behind",
      "offset": 627.779,
      "duration": 3.961
    },
    {
      "lang": "en",
      "text": "neural networks and language models is",
      "offset": 629.459,
      "duration": 4.261
    },
    {
      "lang": "en",
      "text": "that if it's going to do a good job of",
      "offset": 631.74,
      "duration": 3.659
    },
    {
      "lang": "en",
      "text": "being able to predict the next word of",
      "offset": 633.72,
      "duration": 4.98
    },
    {
      "lang": "en",
      "text": "any sentence in any situation it's going",
      "offset": 635.399,
      "duration": 4.741
    },
    {
      "lang": "en",
      "text": "to have to know an awful lot about the",
      "offset": 638.7,
      "duration": 3.18
    },
    {
      "lang": "en",
      "text": "world it's going to have to know about",
      "offset": 640.14,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "how to solve math questions or figure",
      "offset": 641.88,
      "duration": 7.519
    },
    {
      "lang": "en",
      "text": "out the next move in a chess game or",
      "offset": 644.94,
      "duration": 7.92
    },
    {
      "lang": "en",
      "text": "recognize poetry and so on and so forth",
      "offset": 649.399,
      "duration": 4.481
    },
    {
      "lang": "en",
      "text": "now",
      "offset": 652.86,
      "duration": 2.82
    },
    {
      "lang": "en",
      "text": "nobody said it's going to do a good job",
      "offset": 653.88,
      "duration": 2.84
    },
    {
      "lang": "en",
      "text": "of that",
      "offset": 655.68,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "so it's a lot of work to find to create",
      "offset": 656.72,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "and train a model that is good at that",
      "offset": 660,
      "duration": 3.899
    },
    {
      "lang": "en",
      "text": "but if you can create one that's good at",
      "offset": 662.16,
      "duration": 4.94
    },
    {
      "lang": "en",
      "text": "that it's going to have a lot of",
      "offset": 663.899,
      "duration": 5.94
    },
    {
      "lang": "en",
      "text": "capabilities internally that it would",
      "offset": 667.1,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "have to be a drawing on to be able to do",
      "offset": 669.839,
      "duration": 4.801
    },
    {
      "lang": "en",
      "text": "this effectively so the key idea here",
      "offset": 671.82,
      "duration": 6.36
    },
    {
      "lang": "en",
      "text": "for me is that this is a form of",
      "offset": 674.64,
      "duration": 5.879
    },
    {
      "lang": "en",
      "text": "compression and this idea of the",
      "offset": 678.18,
      "duration": 4.2
    },
    {
      "lang": "en",
      "text": "relationship between compression and",
      "offset": 680.519,
      "duration": 5
    },
    {
      "lang": "en",
      "text": "intelligence goes back many many decades",
      "offset": 682.38,
      "duration": 6.24
    },
    {
      "lang": "en",
      "text": "and the basic idea is that yeah if you",
      "offset": 685.519,
      "duration": 4.621
    },
    {
      "lang": "en",
      "text": "can",
      "offset": 688.62,
      "duration": 5.219
    },
    {
      "lang": "en",
      "text": "guess what words are coming up next then",
      "offset": 690.14,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "effectively you're compressing all that",
      "offset": 693.839,
      "duration": 6.861
    },
    {
      "lang": "en",
      "text": "information down into a neural network",
      "offset": 695.82,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "um now I said this is not useful of",
      "offset": 701.1,
      "duration": 4.979
    },
    {
      "lang": "en",
      "text": "itself well why do we do it well we do",
      "offset": 702.779,
      "duration": 5.641
    },
    {
      "lang": "en",
      "text": "it because we want to pull out those",
      "offset": 706.079,
      "duration": 4.5
    },
    {
      "lang": "en",
      "text": "capabilities and the way we pull out",
      "offset": 708.42,
      "duration": 4.02
    },
    {
      "lang": "en",
      "text": "those capabilities is we take two more",
      "offset": 710.579,
      "duration": 4.861
    },
    {
      "lang": "en",
      "text": "steps the second step is we do something",
      "offset": 712.44,
      "duration": 5.399
    },
    {
      "lang": "en",
      "text": "called language model fine tuning",
      "offset": 715.44,
      "duration": 5.88
    },
    {
      "lang": "en",
      "text": "a language model fine tuning we are no",
      "offset": 717.839,
      "duration": 5.581
    },
    {
      "lang": "en",
      "text": "longer just giving it all of Wikipedia",
      "offset": 721.32,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "or nowadays we don't just give it all of",
      "offset": 723.42,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "Wikipedia",
      "offset": 725.16,
      "duration": 2.88
    },
    {
      "lang": "en",
      "text": "but in fact",
      "offset": 726.54,
      "duration": 4.26
    },
    {
      "lang": "en",
      "text": "a large chunk of the internet is fed to",
      "offset": 728.04,
      "duration": 4.739
    },
    {
      "lang": "en",
      "text": "pre-training these models in the fine",
      "offset": 730.8,
      "duration": 3.599
    },
    {
      "lang": "en",
      "text": "tuning stage",
      "offset": 732.779,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "we feed it a set of documents a lot",
      "offset": 734.399,
      "duration": 5.821
    },
    {
      "lang": "en",
      "text": "closer to the final task that we want",
      "offset": 737.339,
      "duration": 4.5
    },
    {
      "lang": "en",
      "text": "the model to do",
      "offset": 740.22,
      "duration": 3.72
    },
    {
      "lang": "en",
      "text": "but it's still the same basic idea it's",
      "offset": 741.839,
      "duration": 4.861
    },
    {
      "lang": "en",
      "text": "still trying to predict the next word of",
      "offset": 743.94,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "a sentence",
      "offset": 746.7,
      "duration": 5.759
    },
    {
      "lang": "en",
      "text": "after that we then do a final classifier",
      "offset": 749.22,
      "duration": 4.739
    },
    {
      "lang": "en",
      "text": "fine tuning and then the classifier",
      "offset": 752.459,
      "duration": 4.741
    },
    {
      "lang": "en",
      "text": "fine-tuning this is this is the kind of",
      "offset": 753.959,
      "duration": 5.041
    },
    {
      "lang": "en",
      "text": "end task we're trying to get it to do",
      "offset": 757.2,
      "duration": 6.36
    },
    {
      "lang": "en",
      "text": "now nowadays these two steps are very",
      "offset": 759,
      "duration": 6.72
    },
    {
      "lang": "en",
      "text": "specific approaches are taken for the",
      "offset": 763.56,
      "duration": 4.44
    },
    {
      "lang": "en",
      "text": "step two the step B the language model",
      "offset": 765.72,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "fine tuning",
      "offset": 768,
      "duration": 3.24
    },
    {
      "lang": "en",
      "text": "people nowadays do a particular kind",
      "offset": 769.32,
      "duration": 4.74
    },
    {
      "lang": "en",
      "text": "called instruction tuning the idea is",
      "offset": 771.24,
      "duration": 5.039
    },
    {
      "lang": "en",
      "text": "that the task we want most of the time",
      "offset": 774.06,
      "duration": 4.2
    },
    {
      "lang": "en",
      "text": "to achieve is",
      "offset": 776.279,
      "duration": 5.281
    },
    {
      "lang": "en",
      "text": "solve problems answer questions and so",
      "offset": 778.26,
      "duration": 5.879
    },
    {
      "lang": "en",
      "text": "in the instruction tuning phase we use",
      "offset": 781.56,
      "duration": 5.88
    },
    {
      "lang": "en",
      "text": "data sets like this one this is a great",
      "offset": 784.139,
      "duration": 5.64
    },
    {
      "lang": "en",
      "text": "data set called openalker created by a",
      "offset": 787.44,
      "duration": 7.139
    },
    {
      "lang": "en",
      "text": "fantastic open source group and and it's",
      "offset": 789.779,
      "duration": 6.481
    },
    {
      "lang": "en",
      "text": "built on top of something called the",
      "offset": 794.579,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "flan collection",
      "offset": 796.26,
      "duration": 5.639
    },
    {
      "lang": "en",
      "text": "and you can see that basically",
      "offset": 797.779,
      "duration": 6.041
    },
    {
      "lang": "en",
      "text": "there's all kinds of different questions",
      "offset": 801.899,
      "duration": 5.88
    },
    {
      "lang": "en",
      "text": "in here so this four gigabytes of",
      "offset": 803.82,
      "duration": 7.019
    },
    {
      "lang": "en",
      "text": "of questions and context and so forth",
      "offset": 807.779,
      "duration": 6.721
    },
    {
      "lang": "en",
      "text": "and each one generally has a question or",
      "offset": 810.839,
      "duration": 6.3
    },
    {
      "lang": "en",
      "text": "an instruction or a request and then a",
      "offset": 814.5,
      "duration": 5.18
    },
    {
      "lang": "en",
      "text": "response",
      "offset": 817.139,
      "duration": 2.541
    },
    {
      "lang": "en",
      "text": "here are some examples of instructions I",
      "offset": 820.139,
      "duration": 6.061
    },
    {
      "lang": "en",
      "text": "think this is from the flan data set if",
      "offset": 824.459,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "I remember correctly so for instance it",
      "offset": 826.2,
      "duration": 4.199
    },
    {
      "lang": "en",
      "text": "could be does the sentence in the Iron",
      "offset": 828.54,
      "duration": 4.62
    },
    {
      "lang": "en",
      "text": "Age answer the question the period of",
      "offset": 830.399,
      "duration": 5.341
    },
    {
      "lang": "en",
      "text": "time from 1200 to 1000 BCE is known as",
      "offset": 833.16,
      "duration": 6.419
    },
    {
      "lang": "en",
      "text": "what choice is one yes or no and then",
      "offset": 835.74,
      "duration": 6.48
    },
    {
      "lang": "en",
      "text": "the language model is meant to write one",
      "offset": 839.579,
      "duration": 7.5
    },
    {
      "lang": "en",
      "text": "or two as appropriate for yes or no",
      "offset": 842.22,
      "duration": 6.84
    },
    {
      "lang": "en",
      "text": "or it could be uh things about I think",
      "offset": 847.079,
      "duration": 4.621
    },
    {
      "lang": "en",
      "text": "this is from a music video who is the",
      "offset": 849.06,
      "duration": 5.399
    },
    {
      "lang": "en",
      "text": "girl in more than you know answer and",
      "offset": 851.7,
      "duration": 4.259
    },
    {
      "lang": "en",
      "text": "then it would have to write the correct",
      "offset": 854.459,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "name of the remember model or dancer or",
      "offset": 855.959,
      "duration": 5.341
    },
    {
      "lang": "en",
      "text": "whatever from um from that music video",
      "offset": 858.779,
      "duration": 5.881
    },
    {
      "lang": "en",
      "text": "and so forth so it's still doing",
      "offset": 861.3,
      "duration": 6.24
    },
    {
      "lang": "en",
      "text": "language modeling so fine-tuning and",
      "offset": 864.66,
      "duration": 4.34
    },
    {
      "lang": "en",
      "text": "pre-training are kind of the same thing",
      "offset": 867.54,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "but this is more targeted now not just",
      "offset": 869,
      "duration": 6.1
    },
    {
      "lang": "en",
      "text": "to be able to fill in the missing parts",
      "offset": 872.82,
      "duration": 5.88
    },
    {
      "lang": "en",
      "text": "of any document from the internet",
      "offset": 875.1,
      "duration": 7.739
    },
    {
      "lang": "en",
      "text": "um but to fill in the words necessary to",
      "offset": 878.7,
      "duration": 7.139
    },
    {
      "lang": "en",
      "text": "to answer questions to do useful things",
      "offset": 882.839,
      "duration": 6.601
    },
    {
      "lang": "en",
      "text": "okay so that's instruction tuning",
      "offset": 885.839,
      "duration": 5.821
    },
    {
      "lang": "en",
      "text": "and then step three which is the",
      "offset": 889.44,
      "duration": 4.68
    },
    {
      "lang": "en",
      "text": "classifier fine tuning nowadays there's",
      "offset": 891.66,
      "duration": 4.979
    },
    {
      "lang": "en",
      "text": "generally various approaches such as",
      "offset": 894.12,
      "duration": 4.14
    },
    {
      "lang": "en",
      "text": "reinforcement learning from Human",
      "offset": 896.639,
      "duration": 7.021
    },
    {
      "lang": "en",
      "text": "feedback and others which are basically",
      "offset": 898.26,
      "duration": 5.4
    },
    {
      "lang": "en",
      "text": "giving humans or sometimes more advanced",
      "offset": 903.779,
      "duration": 5.541
    },
    {
      "lang": "en",
      "text": "models",
      "offset": 908.04,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "multiple answers to a question such as",
      "offset": 909.32,
      "duration": 5.259
    },
    {
      "lang": "en",
      "text": "here are some from a reinforcement",
      "offset": 912.36,
      "duration": 3.719
    },
    {
      "lang": "en",
      "text": "lighting from Human feedback paper I",
      "offset": 914.579,
      "duration": 2.581
    },
    {
      "lang": "en",
      "text": "can't remember which one I got it from",
      "offset": 916.079,
      "duration": 3.481
    },
    {
      "lang": "en",
      "text": "list five ideas for how to regain",
      "offset": 917.16,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "enthusiasm for my career and so the",
      "offset": 919.56,
      "duration": 5.82
    },
    {
      "lang": "en",
      "text": "model will spit out two possible answers",
      "offset": 922.44,
      "duration": 5.1
    },
    {
      "lang": "en",
      "text": "or it'll have a less good model and a",
      "offset": 925.38,
      "duration": 4.92
    },
    {
      "lang": "en",
      "text": "more good model and then a human or a",
      "offset": 927.54,
      "duration": 5.659
    },
    {
      "lang": "en",
      "text": "better model will pick which is best",
      "offset": 930.3,
      "duration": 5.58
    },
    {
      "lang": "en",
      "text": "and so that's used for the the final",
      "offset": 933.199,
      "duration": 4.721
    },
    {
      "lang": "en",
      "text": "fine tuning Stitch",
      "offset": 935.88,
      "duration": 4.199
    },
    {
      "lang": "en",
      "text": "so all of that is to say",
      "offset": 937.92,
      "duration": 2.82
    },
    {
      "lang": "en",
      "text": "um",
      "offset": 940.079,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "although you can download pure language",
      "offset": 940.74,
      "duration": 7.02
    },
    {
      "lang": "en",
      "text": "models from the internet",
      "offset": 944.639,
      "duration": 6.601
    },
    {
      "lang": "en",
      "text": "um they're not generally that useful of",
      "offset": 947.76,
      "duration": 5.939
    },
    {
      "lang": "en",
      "text": "their on their own until you've",
      "offset": 951.24,
      "duration": 3.779
    },
    {
      "lang": "en",
      "text": "fine-tuned them now you don't",
      "offset": 953.699,
      "duration": 3.241
    },
    {
      "lang": "en",
      "text": "necessarily need step C nowadays",
      "offset": 955.019,
      "duration": 3.18
    },
    {
      "lang": "en",
      "text": "actually people are discovering that",
      "offset": 956.94,
      "duration": 3.42
    },
    {
      "lang": "en",
      "text": "maybe just step B might be enough it's",
      "offset": 958.199,
      "duration": 4.561
    },
    {
      "lang": "en",
      "text": "still a bit controversial",
      "offset": 960.36,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "Okay so",
      "offset": 962.76,
      "duration": 4.62
    },
    {
      "lang": "en",
      "text": "when we talk about a language bottle",
      "offset": 964.68,
      "duration": 4.44
    },
    {
      "lang": "en",
      "text": "um where we could be talking about",
      "offset": 967.38,
      "duration": 3.24
    },
    {
      "lang": "en",
      "text": "something that's just been pre-trained",
      "offset": 969.12,
      "duration": 4.2
    },
    {
      "lang": "en",
      "text": "something that's been fine-tuned or",
      "offset": 970.62,
      "duration": 3.719
    },
    {
      "lang": "en",
      "text": "something that's gone through something",
      "offset": 973.32,
      "duration": 3.66
    },
    {
      "lang": "en",
      "text": "like rlhf all of those things are",
      "offset": 974.339,
      "duration": 5.161
    },
    {
      "lang": "en",
      "text": "generally described nowadays as language",
      "offset": 976.98,
      "duration": 5.06
    },
    {
      "lang": "en",
      "text": "models",
      "offset": 979.5,
      "duration": 2.54
    },
    {
      "lang": "en",
      "text": "so my view my view is that if you are",
      "offset": 982.98,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "going to be",
      "offset": 985.62,
      "duration": 4.7
    },
    {
      "lang": "en",
      "text": "good at language modeling in any way",
      "offset": 987.06,
      "duration": 6.6
    },
    {
      "lang": "en",
      "text": "then you need to start by being a really",
      "offset": 990.32,
      "duration": 5.62
    },
    {
      "lang": "en",
      "text": "effective user of language models and to",
      "offset": 993.66,
      "duration": 3.599
    },
    {
      "lang": "en",
      "text": "be a really effective user of language",
      "offset": 995.94,
      "duration": 3
    },
    {
      "lang": "en",
      "text": "models you've got to use the best one",
      "offset": 997.259,
      "duration": 4.561
    },
    {
      "lang": "en",
      "text": "that there is and currently so what are",
      "offset": 998.94,
      "duration": 6.959
    },
    {
      "lang": "en",
      "text": "we up to September 2023 the best one is",
      "offset": 1001.82,
      "duration": 8.879
    },
    {
      "lang": "en",
      "text": "by far gpt4 this might change sometime",
      "offset": 1005.899,
      "duration": 6.3
    },
    {
      "lang": "en",
      "text": "in the not too distant future but this",
      "offset": 1010.699,
      "duration": 3.961
    },
    {
      "lang": "en",
      "text": "is right now gpt4 is the recommendation",
      "offset": 1012.199,
      "duration": 5.82
    },
    {
      "lang": "en",
      "text": "strong strong recommendation now you can",
      "offset": 1014.66,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "use GPT for",
      "offset": 1018.019,
      "duration": 4.801
    },
    {
      "lang": "en",
      "text": "by paying 20 bucks a month to open Ai",
      "offset": 1020.18,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "and then you can use it a whole lot it's",
      "offset": 1022.82,
      "duration": 3.72
    },
    {
      "lang": "en",
      "text": "very hard to",
      "offset": 1025.22,
      "duration": 5.239
    },
    {
      "lang": "en",
      "text": "to run out of credits I find",
      "offset": 1026.54,
      "duration": 7.259
    },
    {
      "lang": "en",
      "text": "now what can GPT do",
      "offset": 1030.459,
      "duration": 5.801
    },
    {
      "lang": "en",
      "text": "it's interesting and instructive in my",
      "offset": 1033.799,
      "duration": 5.64
    },
    {
      "lang": "en",
      "text": "opinion to start with the very common",
      "offset": 1036.26,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "views you see on the internet or even in",
      "offset": 1039.439,
      "duration": 4.561
    },
    {
      "lang": "en",
      "text": "Academia about what it can't do so for",
      "offset": 1041.54,
      "duration": 3.899
    },
    {
      "lang": "en",
      "text": "example there was this paper you might",
      "offset": 1044,
      "duration": 5.179
    },
    {
      "lang": "en",
      "text": "have seen GPT for can't reason",
      "offset": 1045.439,
      "duration": 8.061
    },
    {
      "lang": "en",
      "text": "which describes a number of uh empirical",
      "offset": 1049.179,
      "duration": 7.781
    },
    {
      "lang": "en",
      "text": "analysis done of 25 diverse reasoning",
      "offset": 1053.5,
      "duration": 7.059
    },
    {
      "lang": "en",
      "text": "problems and found it that it",
      "offset": 1056.96,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "was not able to solve them and it's",
      "offset": 1060.559,
      "duration": 6.24
    },
    {
      "lang": "en",
      "text": "utterly incapable of reasoning so",
      "offset": 1062.48,
      "duration": 6.18
    },
    {
      "lang": "en",
      "text": "I always find you've got to be a bit",
      "offset": 1066.799,
      "duration": 3.661
    },
    {
      "lang": "en",
      "text": "careful about reading stuff like this",
      "offset": 1068.66,
      "duration": 3.24
    },
    {
      "lang": "en",
      "text": "because I just talked the first three",
      "offset": 1070.46,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "that I came across in that paper and I",
      "offset": 1071.9,
      "duration": 7.74
    },
    {
      "lang": "en",
      "text": "gave them to gpt4",
      "offset": 1075.58,
      "duration": 6.28
    },
    {
      "lang": "en",
      "text": "um and by the way something very useful",
      "offset": 1079.64,
      "duration": 7.32
    },
    {
      "lang": "en",
      "text": "in gpt4 is you can click on the the",
      "offset": 1081.86,
      "duration": 8.22
    },
    {
      "lang": "en",
      "text": "share button and you'll get something",
      "offset": 1086.96,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "that looks like this and this is really",
      "offset": 1090.08,
      "duration": 4.44
    },
    {
      "lang": "en",
      "text": "handy so here's an example of something",
      "offset": 1092,
      "duration": 5.64
    },
    {
      "lang": "en",
      "text": "from the paper that said gpt4 can't do",
      "offset": 1094.52,
      "duration": 6.24
    },
    {
      "lang": "en",
      "text": "this Mabel's heart rate at 9 00 am was",
      "offset": 1097.64,
      "duration": 5.159
    },
    {
      "lang": "en",
      "text": "75 beats per minute her blood pressure",
      "offset": 1100.76,
      "duration": 5.58
    },
    {
      "lang": "en",
      "text": "at 7 pm was 120 over 80. she died 11 p.m",
      "offset": 1102.799,
      "duration": 5.581
    },
    {
      "lang": "en",
      "text": "while she arrive at noon so of course",
      "offset": 1106.34,
      "duration": 4.26
    },
    {
      "lang": "en",
      "text": "you're human we know obviously she must",
      "offset": 1108.38,
      "duration": 3.56
    },
    {
      "lang": "en",
      "text": "be",
      "offset": 1110.6,
      "duration": 4.98
    },
    {
      "lang": "en",
      "text": "and GPT forces Hmm this appears to be a",
      "offset": 1111.94,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "riddle not a real inquiry into medical",
      "offset": 1115.58,
      "duration": 4.86
    },
    {
      "lang": "en",
      "text": "conditions uh here's a summary of the",
      "offset": 1117.62,
      "duration": 5.7
    },
    {
      "lang": "en",
      "text": "information and yeah",
      "offset": 1120.44,
      "duration": 6.479
    },
    {
      "lang": "en",
      "text": "it sounds like Mabel was alive at noon",
      "offset": 1123.32,
      "duration": 6.06
    },
    {
      "lang": "en",
      "text": "so that's correct uh this was the second",
      "offset": 1126.919,
      "duration": 4.561
    },
    {
      "lang": "en",
      "text": "one I tried from the paper that says",
      "offset": 1129.38,
      "duration": 4.919
    },
    {
      "lang": "en",
      "text": "gpt4 can't do this and I found actually",
      "offset": 1131.48,
      "duration": 5.939
    },
    {
      "lang": "en",
      "text": "gpt4 can do this",
      "offset": 1134.299,
      "duration": 5.521
    },
    {
      "lang": "en",
      "text": "um and it said that gpt4 can't do this",
      "offset": 1137.419,
      "duration": 6.181
    },
    {
      "lang": "en",
      "text": "and I found gpt4 can do this now",
      "offset": 1139.82,
      "duration": 6.84
    },
    {
      "lang": "en",
      "text": "um I mentioned this to say gpt4 is",
      "offset": 1143.6,
      "duration": 5.34
    },
    {
      "lang": "en",
      "text": "probably a lot better than you would",
      "offset": 1146.66,
      "duration": 5.22
    },
    {
      "lang": "en",
      "text": "expect if you've read all this um stuff",
      "offset": 1148.94,
      "duration": 4.859
    },
    {
      "lang": "en",
      "text": "on the internet about all the dumb",
      "offset": 1151.88,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "things that it does",
      "offset": 1153.799,
      "duration": 3.24
    },
    {
      "lang": "en",
      "text": "um",
      "offset": 1156.44,
      "duration": 2.28
    },
    {
      "lang": "en",
      "text": "almost every time I see on the internet",
      "offset": 1157.039,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "saying something something that GPT 4",
      "offset": 1158.72,
      "duration": 5.1
    },
    {
      "lang": "en",
      "text": "can't do I check it and it turns out it",
      "offset": 1161.12,
      "duration": 4.74
    },
    {
      "lang": "en",
      "text": "does this one was just last week",
      "offset": 1163.82,
      "duration": 5.219
    },
    {
      "lang": "en",
      "text": "Sally a girl has three brothers each",
      "offset": 1165.86,
      "duration": 5.58
    },
    {
      "lang": "en",
      "text": "brother has two sisters how many sisters",
      "offset": 1169.039,
      "duration": 4.38
    },
    {
      "lang": "en",
      "text": "does Sally have",
      "offset": 1171.44,
      "duration": 5.18
    },
    {
      "lang": "en",
      "text": "so have a think about it",
      "offset": 1173.419,
      "duration": 3.201
    },
    {
      "lang": "en",
      "text": "and so gpt4 says okay",
      "offset": 1176.84,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "Sally's counted as one system each of",
      "offset": 1180.14,
      "duration": 3.3
    },
    {
      "lang": "en",
      "text": "her brothers",
      "offset": 1182.12,
      "duration": 3.66
    },
    {
      "lang": "en",
      "text": "if each brother has two sisters",
      "offset": 1183.44,
      "duration": 4.02
    },
    {
      "lang": "en",
      "text": "that means there's another sister in the",
      "offset": 1185.78,
      "duration": 4.019
    },
    {
      "lang": "en",
      "text": "picture apart from salary so Sally has",
      "offset": 1187.46,
      "duration": 5.7
    },
    {
      "lang": "en",
      "text": "one sister okay correct",
      "offset": 1189.799,
      "duration": 5.481
    },
    {
      "lang": "en",
      "text": "um",
      "offset": 1193.16,
      "duration": 2.12
    },
    {
      "lang": "en",
      "text": "and then this one I got sort of like",
      "offset": 1196.88,
      "duration": 3.86
    },
    {
      "lang": "en",
      "text": "three or four days ago",
      "offset": 1198.799,
      "duration": 4.861
    },
    {
      "lang": "en",
      "text": "this is a common view that language",
      "offset": 1200.74,
      "duration": 5.08
    },
    {
      "lang": "en",
      "text": "models can't",
      "offset": 1203.66,
      "duration": 4.379
    },
    {
      "lang": "en",
      "text": "track things like this see is the riddle",
      "offset": 1205.82,
      "duration": 3.96
    },
    {
      "lang": "en",
      "text": "I'm in my house on top of my chair in",
      "offset": 1208.039,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "the living room is a coffee cup inside",
      "offset": 1209.78,
      "duration": 4.019
    },
    {
      "lang": "en",
      "text": "the coffee cup is a thimble inside the",
      "offset": 1211.64,
      "duration": 3.779
    },
    {
      "lang": "en",
      "text": "thimble is a diamond",
      "offset": 1213.799,
      "duration": 3.661
    },
    {
      "lang": "en",
      "text": "I moved the chair to the bedroom I put",
      "offset": 1215.419,
      "duration": 3.541
    },
    {
      "lang": "en",
      "text": "the coffee cup on the bed I turned the",
      "offset": 1217.46,
      "duration": 3.42
    },
    {
      "lang": "en",
      "text": "cup upside down then I return it upside",
      "offset": 1218.96,
      "duration": 3.78
    },
    {
      "lang": "en",
      "text": "up Place The Coffee Cup on the counter",
      "offset": 1220.88,
      "duration": 3.9
    },
    {
      "lang": "en",
      "text": "in the kitchen where's my diamond",
      "offset": 1222.74,
      "duration": 6.179
    },
    {
      "lang": "en",
      "text": "and so gpt4 says yeah okay you turned it",
      "offset": 1224.78,
      "duration": 6.54
    },
    {
      "lang": "en",
      "text": "upside down so probably the diamond fell",
      "offset": 1228.919,
      "duration": 3.421
    },
    {
      "lang": "en",
      "text": "out",
      "offset": 1231.32,
      "duration": 2.94
    },
    {
      "lang": "en",
      "text": "so therefore the diamond is in the",
      "offset": 1232.34,
      "duration": 4.92
    },
    {
      "lang": "en",
      "text": "bedroom where it fell out okay correct",
      "offset": 1234.26,
      "duration": 3.779
    },
    {
      "lang": "en",
      "text": "um",
      "offset": 1237.26,
      "duration": 5.94
    },
    {
      "lang": "en",
      "text": "why is it that people are claiming that",
      "offset": 1238.039,
      "duration": 7.621
    },
    {
      "lang": "en",
      "text": "gpt4 can't do these things we can well",
      "offset": 1243.2,
      "duration": 4.26
    },
    {
      "lang": "en",
      "text": "the reason is because I think on the",
      "offset": 1245.66,
      "duration": 4.86
    },
    {
      "lang": "en",
      "text": "whole they are not aware of how gpt4 was",
      "offset": 1247.46,
      "duration": 5.48
    },
    {
      "lang": "en",
      "text": "trained",
      "offset": 1250.52,
      "duration": 2.42
    },
    {
      "lang": "en",
      "text": "gpt4",
      "offset": 1253,
      "duration": 4.84
    },
    {
      "lang": "en",
      "text": "was not trained at any point to give",
      "offset": 1254.72,
      "duration": 5.06
    },
    {
      "lang": "en",
      "text": "correct answers",
      "offset": 1257.84,
      "duration": 6.6
    },
    {
      "lang": "en",
      "text": "gpt4 was trained initially to give most",
      "offset": 1259.78,
      "duration": 7.12
    },
    {
      "lang": "en",
      "text": "likely next words and there's an awful",
      "offset": 1264.44,
      "duration": 4.44
    },
    {
      "lang": "en",
      "text": "lot of stuff on the internet where the",
      "offset": 1266.9,
      "duration": 3.96
    },
    {
      "lang": "en",
      "text": "most rare documents are not describing",
      "offset": 1268.88,
      "duration": 3.9
    },
    {
      "lang": "en",
      "text": "things that are true there could be",
      "offset": 1270.86,
      "duration": 4.5
    },
    {
      "lang": "en",
      "text": "fiction there could be jokes there could",
      "offset": 1272.78,
      "duration": 4.44
    },
    {
      "lang": "en",
      "text": "be just stupid people don't saying dumb",
      "offset": 1275.36,
      "duration": 2.72
    },
    {
      "lang": "en",
      "text": "stuff",
      "offset": 1277.22,
      "duration": 4.02
    },
    {
      "lang": "en",
      "text": "so this first stage does not necessarily",
      "offset": 1278.08,
      "duration": 5.62
    },
    {
      "lang": "en",
      "text": "give you correct answers the second",
      "offset": 1281.24,
      "duration": 5.4
    },
    {
      "lang": "en",
      "text": "stage with the instruction tuning uh",
      "offset": 1283.7,
      "duration": 5.459
    },
    {
      "lang": "en",
      "text": "also like it's it's",
      "offset": 1286.64,
      "duration": 5.279
    },
    {
      "lang": "en",
      "text": "it's trying to give correct answers but",
      "offset": 1289.159,
      "duration": 4.561
    },
    {
      "lang": "en",
      "text": "part of the problem is that then in the",
      "offset": 1291.919,
      "duration": 3.5
    },
    {
      "lang": "en",
      "text": "stage where you start asking people",
      "offset": 1293.72,
      "duration": 4.699
    },
    {
      "lang": "en",
      "text": "which answer do they like better",
      "offset": 1295.419,
      "duration": 7.301
    },
    {
      "lang": "en",
      "text": "people tended to say in these uh in",
      "offset": 1298.419,
      "duration": 6.701
    },
    {
      "lang": "en",
      "text": "these things that they prefer more",
      "offset": 1302.72,
      "duration": 6.12
    },
    {
      "lang": "en",
      "text": "confident answers and they often were",
      "offset": 1305.12,
      "duration": 5.22
    },
    {
      "lang": "en",
      "text": "not people who were trained well enough",
      "offset": 1308.84,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "to recognize wrong answers",
      "offset": 1310.34,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "so there's lots of reasons that the that",
      "offset": 1312.52,
      "duration": 5.92
    },
    {
      "lang": "en",
      "text": "the you know SGD weight updates from",
      "offset": 1316.1,
      "duration": 5.699
    },
    {
      "lang": "en",
      "text": "this process for stuff like gpt4 don't",
      "offset": 1318.44,
      "duration": 6.54
    },
    {
      "lang": "en",
      "text": "particularly or don't entirely reward",
      "offset": 1321.799,
      "duration": 4.921
    },
    {
      "lang": "en",
      "text": "correct answers",
      "offset": 1324.98,
      "duration": 5.4
    },
    {
      "lang": "en",
      "text": "but you can help it want to give you",
      "offset": 1326.72,
      "duration": 6.06
    },
    {
      "lang": "en",
      "text": "correct answers if you think about",
      "offset": 1330.38,
      "duration": 5.1
    },
    {
      "lang": "en",
      "text": "the LM pre-training what are the kinds",
      "offset": 1332.78,
      "duration": 5.519
    },
    {
      "lang": "en",
      "text": "of things in a document that would",
      "offset": 1335.48,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "suggest oh this is going to be high",
      "offset": 1338.299,
      "duration": 5.281
    },
    {
      "lang": "en",
      "text": "quality information and so you can",
      "offset": 1341,
      "duration": 5.299
    },
    {
      "lang": "en",
      "text": "actually Prime",
      "offset": 1343.58,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "gpt4 to give you high quality",
      "offset": 1346.299,
      "duration": 4.36
    },
    {
      "lang": "en",
      "text": "information by giving it custom",
      "offset": 1349.1,
      "duration": 3.72
    },
    {
      "lang": "en",
      "text": "instructions",
      "offset": 1350.659,
      "duration": 5.88
    },
    {
      "lang": "en",
      "text": "and what this does is this is basically",
      "offset": 1352.82,
      "duration": 6.3
    },
    {
      "lang": "en",
      "text": "text that is prepended to all of your",
      "offset": 1356.539,
      "duration": 3.721
    },
    {
      "lang": "en",
      "text": "queries",
      "offset": 1359.12,
      "duration": 4.26
    },
    {
      "lang": "en",
      "text": "and so you say like oh you're brilliant",
      "offset": 1360.26,
      "duration": 6.18
    },
    {
      "lang": "en",
      "text": "at reasoning so like okay that's",
      "offset": 1363.38,
      "duration": 5.039
    },
    {
      "lang": "en",
      "text": "obviously or to prime it to give good",
      "offset": 1366.44,
      "duration": 3.359
    },
    {
      "lang": "en",
      "text": "answers",
      "offset": 1368.419,
      "duration": 2.221
    },
    {
      "lang": "en",
      "text": "um",
      "offset": 1369.799,
      "duration": 3.061
    },
    {
      "lang": "en",
      "text": "and then try to work against the fact",
      "offset": 1370.64,
      "duration": 3.3
    },
    {
      "lang": "en",
      "text": "that",
      "offset": 1372.86,
      "duration": 5.939
    },
    {
      "lang": "en",
      "text": "um the the rlhf uh folks uh preferred",
      "offset": 1373.94,
      "duration": 8.34
    },
    {
      "lang": "en",
      "text": "confidence just tell it no tell me if",
      "offset": 1378.799,
      "duration": 6.321
    },
    {
      "lang": "en",
      "text": "there might not be a correct answer",
      "offset": 1382.28,
      "duration": 6.66
    },
    {
      "lang": "en",
      "text": "also the way that the text is generated",
      "offset": 1385.12,
      "duration": 7.299
    },
    {
      "lang": "en",
      "text": "is it literally generates the next word",
      "offset": 1388.94,
      "duration": 6.3
    },
    {
      "lang": "en",
      "text": "and then it puts all that whole lot back",
      "offset": 1392.419,
      "duration": 4.38
    },
    {
      "lang": "en",
      "text": "into the bottle and generates the next",
      "offset": 1395.24,
      "duration": 3.179
    },
    {
      "lang": "en",
      "text": "next word puts that all back in the",
      "offset": 1396.799,
      "duration": 3.661
    },
    {
      "lang": "en",
      "text": "model generates the next next word and",
      "offset": 1398.419,
      "duration": 3.481
    },
    {
      "lang": "en",
      "text": "so forth",
      "offset": 1400.46,
      "duration": 3.18
    },
    {
      "lang": "en",
      "text": "that means the more words it generates",
      "offset": 1401.9,
      "duration": 4.38
    },
    {
      "lang": "en",
      "text": "the more computation it can do and so I",
      "offset": 1403.64,
      "duration": 4.44
    },
    {
      "lang": "en",
      "text": "literally I tell it that",
      "offset": 1406.28,
      "duration": 4.5
    },
    {
      "lang": "en",
      "text": "right and so I say first spend a few",
      "offset": 1408.08,
      "duration": 5.16
    },
    {
      "lang": "en",
      "text": "sentences explaining background context",
      "offset": 1410.78,
      "duration": 3.96
    },
    {
      "lang": "en",
      "text": "Etc",
      "offset": 1413.24,
      "duration": 6.319
    },
    {
      "lang": "en",
      "text": "so this uh custom instruction",
      "offset": 1414.74,
      "duration": 4.819
    },
    {
      "lang": "en",
      "text": "um allows it to solve more challenging",
      "offset": 1420.32,
      "duration": 5.719
    },
    {
      "lang": "en",
      "text": "problems",
      "offset": 1423.559,
      "duration": 2.48
    },
    {
      "lang": "en",
      "text": "and you can see the difference",
      "offset": 1428,
      "duration": 3.14
    },
    {
      "lang": "en",
      "text": "here's what it looks like for example if",
      "offset": 1431.9,
      "duration": 4.259
    },
    {
      "lang": "en",
      "text": "I say how do I get a count of rows",
      "offset": 1434.419,
      "duration": 3.961
    },
    {
      "lang": "en",
      "text": "grouped by value in pandas",
      "offset": 1436.159,
      "duration": 4.861
    },
    {
      "lang": "en",
      "text": "and it just gives me a whole lot of",
      "offset": 1438.38,
      "duration": 4.14
    },
    {
      "lang": "en",
      "text": "information which is actually it",
      "offset": 1441.02,
      "duration": 4.019
    },
    {
      "lang": "en",
      "text": "thinking so I just skip over it and then",
      "offset": 1442.52,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "it gives me the answer",
      "offset": 1445.039,
      "duration": 4.921
    },
    {
      "lang": "en",
      "text": "and actually in my uh",
      "offset": 1446.36,
      "duration": 5.22
    },
    {
      "lang": "en",
      "text": "um",
      "offset": 1449.96,
      "duration": 3.66
    },
    {
      "lang": "en",
      "text": "custom instructions I actually say if",
      "offset": 1451.58,
      "duration": 4.44
    },
    {
      "lang": "en",
      "text": "the request begins with VV",
      "offset": 1453.62,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "actually make it as concise as possible",
      "offset": 1456.02,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "and so it kind of goes into brief mode",
      "offset": 1458.9,
      "duration": 5.1
    },
    {
      "lang": "en",
      "text": "and here's brief mode how do I get the",
      "offset": 1461.78,
      "duration": 3.72
    },
    {
      "lang": "en",
      "text": "group this is the same thing but with VV",
      "offset": 1464,
      "duration": 2.52
    },
    {
      "lang": "en",
      "text": "at the start",
      "offset": 1465.5,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "and it just spits it out now in this",
      "offset": 1466.52,
      "duration": 4.38
    },
    {
      "lang": "en",
      "text": "case it's a really simple question so I",
      "offset": 1469.1,
      "duration": 3.72
    },
    {
      "lang": "en",
      "text": "didn't need time to think",
      "offset": 1470.9,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "so hopefully that gives you a sense of",
      "offset": 1472.82,
      "duration": 6.479
    },
    {
      "lang": "en",
      "text": "how to get language models to give",
      "offset": 1475.94,
      "duration": 4.739
    },
    {
      "lang": "en",
      "text": "good answers",
      "offset": 1479.299,
      "duration": 5.161
    },
    {
      "lang": "en",
      "text": "you have to help them and if you if it's",
      "offset": 1480.679,
      "duration": 6.12
    },
    {
      "lang": "en",
      "text": "not working it might be user error",
      "offset": 1484.46,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "basically but having said that there's",
      "offset": 1486.799,
      "duration": 4.74
    },
    {
      "lang": "en",
      "text": "plenty of stuff that language models",
      "offset": 1489.5,
      "duration": 4.22
    },
    {
      "lang": "en",
      "text": "like gpt4 can't do",
      "offset": 1491.539,
      "duration": 5.941
    },
    {
      "lang": "en",
      "text": "one thing to think carefully about is",
      "offset": 1493.72,
      "duration": 6.579
    },
    {
      "lang": "en",
      "text": "does it know about itself can you ask it",
      "offset": 1497.48,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "what is your context length how were you",
      "offset": 1500.299,
      "duration": 5.88
    },
    {
      "lang": "en",
      "text": "trained what Transformer architecture",
      "offset": 1503.48,
      "duration": 5.3
    },
    {
      "lang": "en",
      "text": "are you based on",
      "offset": 1506.179,
      "duration": 2.601
    },
    {
      "lang": "en",
      "text": "any one of these stages",
      "offset": 1509.6,
      "duration": 4.439
    },
    {
      "lang": "en",
      "text": "did it have the opportunity to learn any",
      "offset": 1511.88,
      "duration": 3.539
    },
    {
      "lang": "en",
      "text": "of those things",
      "offset": 1514.039,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "well obviously not at the pre-training",
      "offset": 1515.419,
      "duration": 3.721
    },
    {
      "lang": "en",
      "text": "stage nothing on the internet",
      "offset": 1517.159,
      "duration": 4.681
    },
    {
      "lang": "en",
      "text": "existed during GPT 4's training saying",
      "offset": 1519.14,
      "duration": 4.68
    },
    {
      "lang": "en",
      "text": "how gpt4 was trained",
      "offset": 1521.84,
      "duration": 4.92
    },
    {
      "lang": "en",
      "text": "right uh probably Ditto in the",
      "offset": 1523.82,
      "duration": 4.739
    },
    {
      "lang": "en",
      "text": "instruction tuning probably Ditto in the",
      "offset": 1526.76,
      "duration": 4.799
    },
    {
      "lang": "en",
      "text": "rlhf so in general you can't ask for",
      "offset": 1528.559,
      "duration": 6.72
    },
    {
      "lang": "en",
      "text": "example a language model about itself",
      "offset": 1531.559,
      "duration": 6.661
    },
    {
      "lang": "en",
      "text": "now again because of the rlhf it'll want",
      "offset": 1535.279,
      "duration": 5.041
    },
    {
      "lang": "en",
      "text": "to make you happy by giving your",
      "offset": 1538.22,
      "duration": 5.16
    },
    {
      "lang": "en",
      "text": "opinionated answers so it'll just spit",
      "offset": 1540.32,
      "duration": 5.82
    },
    {
      "lang": "en",
      "text": "out the most likely thing it thinks with",
      "offset": 1543.38,
      "duration": 4.74
    },
    {
      "lang": "en",
      "text": "great confidence",
      "offset": 1546.14,
      "duration": 3.419
    },
    {
      "lang": "en",
      "text": "this is just a general kind of",
      "offset": 1548.12,
      "duration": 3.539
    },
    {
      "lang": "en",
      "text": "hallucination right so hallucinations is",
      "offset": 1549.559,
      "duration": 4.5
    },
    {
      "lang": "en",
      "text": "just this idea that the language model",
      "offset": 1551.659,
      "duration": 4.981
    },
    {
      "lang": "en",
      "text": "wants to complete the sentence and it",
      "offset": 1554.059,
      "duration": 4.681
    },
    {
      "lang": "en",
      "text": "wants to do it in an opinionated way",
      "offset": 1556.64,
      "duration": 5.039
    },
    {
      "lang": "en",
      "text": "that's likely to make people happy",
      "offset": 1558.74,
      "duration": 3.66
    },
    {
      "lang": "en",
      "text": "um",
      "offset": 1561.679,
      "duration": 3.48
    },
    {
      "lang": "en",
      "text": "it doesn't know anything about URLs it",
      "offset": 1562.4,
      "duration": 5.7
    },
    {
      "lang": "en",
      "text": "really hasn't seen many at all I think a",
      "offset": 1565.159,
      "duration": 4.5
    },
    {
      "lang": "en",
      "text": "lot of them if not all of them pretty",
      "offset": 1568.1,
      "duration": 4.679
    },
    {
      "lang": "en",
      "text": "much were stripped out so if you ask it",
      "offset": 1569.659,
      "duration": 4.861
    },
    {
      "lang": "en",
      "text": "anything about like what's at this",
      "offset": 1572.779,
      "duration": 4.26
    },
    {
      "lang": "en",
      "text": "webpage again it'll generally just make",
      "offset": 1574.52,
      "duration": 4.38
    },
    {
      "lang": "en",
      "text": "it up",
      "offset": 1577.039,
      "duration": 3.961
    },
    {
      "lang": "en",
      "text": "um and it doesn't know at least gpt4",
      "offset": 1578.9,
      "duration": 3.72
    },
    {
      "lang": "en",
      "text": "doesn't know anything after September",
      "offset": 1581,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "2021",
      "offset": 1582.62,
      "duration": 3.96
    },
    {
      "lang": "en",
      "text": "um because the",
      "offset": 1584.12,
      "duration": 5.64
    },
    {
      "lang": "en",
      "text": "um information it was pre-trained on was",
      "offset": 1586.58,
      "duration": 4.14
    },
    {
      "lang": "en",
      "text": "from",
      "offset": 1589.76,
      "duration": 2.94
    },
    {
      "lang": "en",
      "text": "that time period September 2021 and",
      "offset": 1590.72,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "before called the knowledge cut off",
      "offset": 1592.7,
      "duration": 4.92
    },
    {
      "lang": "en",
      "text": "so here's some things it can't do",
      "offset": 1595.52,
      "duration": 2.94
    },
    {
      "lang": "en",
      "text": "um",
      "offset": 1597.62,
      "duration": 3.24
    },
    {
      "lang": "en",
      "text": "Steve Newman sent me this good example",
      "offset": 1598.46,
      "duration": 5.4
    },
    {
      "lang": "en",
      "text": "of something that it can't do",
      "offset": 1600.86,
      "duration": 4.439
    },
    {
      "lang": "en",
      "text": "um",
      "offset": 1603.86,
      "duration": 4.559
    },
    {
      "lang": "en",
      "text": "here is a logic puzzle I need to carry a",
      "offset": 1605.299,
      "duration": 5.581
    },
    {
      "lang": "en",
      "text": "cabbage a goat and a wolf across a river",
      "offset": 1608.419,
      "duration": 5.581
    },
    {
      "lang": "en",
      "text": "I can only carry one item at a time I",
      "offset": 1610.88,
      "duration": 5.399
    },
    {
      "lang": "en",
      "text": "can't leave the goat with a cabbage I",
      "offset": 1614,
      "duration": 4.02
    },
    {
      "lang": "en",
      "text": "can't leave the cabbage with the wolf",
      "offset": 1616.279,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "how do I get everything across to the",
      "offset": 1618.02,
      "duration": 3
    },
    {
      "lang": "en",
      "text": "other side",
      "offset": 1619.88,
      "duration": 4.5
    },
    {
      "lang": "en",
      "text": "now the problem is this looks a lot like",
      "offset": 1621.02,
      "duration": 5.399
    },
    {
      "lang": "en",
      "text": "something called the classic River",
      "offset": 1624.38,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "Crossing puzzle",
      "offset": 1626.419,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "so classic in fact that it has a whole",
      "offset": 1628.94,
      "duration": 5.46
    },
    {
      "lang": "en",
      "text": "Wikipedia page",
      "offset": 1632.419,
      "duration": 3.481
    },
    {
      "lang": "en",
      "text": "about it",
      "offset": 1634.4,
      "duration": 5.1
    },
    {
      "lang": "en",
      "text": "and in the classic puzzle",
      "offset": 1635.9,
      "duration": 6.18
    },
    {
      "lang": "en",
      "text": "the wolf would eat the goat",
      "offset": 1639.5,
      "duration": 5.4
    },
    {
      "lang": "en",
      "text": "or the goat would eat the cabbage",
      "offset": 1642.08,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "now",
      "offset": 1644.9,
      "duration": 4.2
    },
    {
      "lang": "en",
      "text": "in",
      "offset": 1646.64,
      "duration": 6.919
    },
    {
      "lang": "en",
      "text": "in Steve's version he changed it",
      "offset": 1649.1,
      "duration": 4.459
    },
    {
      "lang": "en",
      "text": "the goat would eat the cabbage and the",
      "offset": 1654.559,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "Wolf would eat the cabbage but the wolf",
      "offset": 1657.08,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "won't eat the goat",
      "offset": 1658.88,
      "duration": 2.84
    },
    {
      "lang": "en",
      "text": "so what happens well very interestingly",
      "offset": 1661.82,
      "duration": 6.66
    },
    {
      "lang": "en",
      "text": "gpt4 here is entirely overwhelmed by the",
      "offset": 1665.08,
      "duration": 5.079
    },
    {
      "lang": "en",
      "text": "language model training it's seen this",
      "offset": 1668.48,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "puzzle so many times it knows what word",
      "offset": 1670.159,
      "duration": 3.301
    },
    {
      "lang": "en",
      "text": "comes next",
      "offset": 1672.32,
      "duration": 2.82
    },
    {
      "lang": "en",
      "text": "so it says oh yeah I take the goat",
      "offset": 1673.46,
      "duration": 3.9
    },
    {
      "lang": "en",
      "text": "across the road across the river and",
      "offset": 1675.14,
      "duration": 4.26
    },
    {
      "lang": "en",
      "text": "leave it on the other side leaving the",
      "offset": 1677.36,
      "duration": 3.72
    },
    {
      "lang": "en",
      "text": "wolf with a cabbage but we're just told",
      "offset": 1679.4,
      "duration": 4.92
    },
    {
      "lang": "en",
      "text": "you can't leave the wolf with a cabbage",
      "offset": 1681.08,
      "duration": 5.94
    },
    {
      "lang": "en",
      "text": "so it gets it wrong",
      "offset": 1684.32,
      "duration": 4.92
    },
    {
      "lang": "en",
      "text": "now the thing is though you can",
      "offset": 1687.02,
      "duration": 5.279
    },
    {
      "lang": "en",
      "text": "encourage gpt4 or any of these language",
      "offset": 1689.24,
      "duration": 5.22
    },
    {
      "lang": "en",
      "text": "models to try again so during the",
      "offset": 1692.299,
      "duration": 4.021
    },
    {
      "lang": "en",
      "text": "instruction tuning an R lhf they're",
      "offset": 1694.46,
      "duration": 4.26
    },
    {
      "lang": "en",
      "text": "actually fine-tuned with multi-stage",
      "offset": 1696.32,
      "duration": 4.62
    },
    {
      "lang": "en",
      "text": "conversations so you can give it a",
      "offset": 1698.72,
      "duration": 4.439
    },
    {
      "lang": "en",
      "text": "multi-stage conversation repeat back to",
      "offset": 1700.94,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "me the constraints I listed what",
      "offset": 1703.159,
      "duration": 4.02
    },
    {
      "lang": "en",
      "text": "happened after Step One is a constraint",
      "offset": 1705.02,
      "duration": 3.24
    },
    {
      "lang": "en",
      "text": "violated",
      "offset": 1707.179,
      "duration": 5.541
    },
    {
      "lang": "en",
      "text": "oh yeah yeah yeah I made a mistake okay",
      "offset": 1708.26,
      "duration": 7.32
    },
    {
      "lang": "en",
      "text": "my new attempt instead of taking the",
      "offset": 1712.72,
      "duration": 4.3
    },
    {
      "lang": "en",
      "text": "goat across the river and leaving it on",
      "offset": 1715.58,
      "duration": 2.82
    },
    {
      "lang": "en",
      "text": "the other side is I'll take the code",
      "offset": 1717.02,
      "duration": 2.639
    },
    {
      "lang": "en",
      "text": "across the river and leave from the",
      "offset": 1718.4,
      "duration": 2.82
    },
    {
      "lang": "en",
      "text": "other side",
      "offset": 1719.659,
      "duration": 4.981
    },
    {
      "lang": "en",
      "text": "it's done the same thing",
      "offset": 1721.22,
      "duration": 6.6
    },
    {
      "lang": "en",
      "text": "um oh yeah I did do the same thing okay",
      "offset": 1724.64,
      "duration": 5.7
    },
    {
      "lang": "en",
      "text": "I'll take the wolf across well now the",
      "offset": 1727.82,
      "duration": 3.9
    },
    {
      "lang": "en",
      "text": "goats with the Cabbage that still",
      "offset": 1730.34,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "doesn't work oh yeah that didn't work",
      "offset": 1731.72,
      "duration": 4.339
    },
    {
      "lang": "en",
      "text": "out",
      "offset": 1733.94,
      "duration": 5.219
    },
    {
      "lang": "en",
      "text": "uh sorry about that instead of taking",
      "offset": 1736.059,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "the goat across the other side I'll take",
      "offset": 1739.159,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "the goat across the other side okay",
      "offset": 1740.539,
      "duration": 3.781
    },
    {
      "lang": "en",
      "text": "what's going on here right this is",
      "offset": 1742.279,
      "duration": 3.481
    },
    {
      "lang": "en",
      "text": "terrible",
      "offset": 1744.32,
      "duration": 4.739
    },
    {
      "lang": "en",
      "text": "well one of the problems here is that",
      "offset": 1745.76,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "not only is",
      "offset": 1749.059,
      "duration": 5.641
    },
    {
      "lang": "en",
      "text": "on the Internet it's so common to see",
      "offset": 1751.52,
      "duration": 6.24
    },
    {
      "lang": "en",
      "text": "this particular goat puzzle that it's so",
      "offset": 1754.7,
      "duration": 4.62
    },
    {
      "lang": "en",
      "text": "confident it knows what the next word is",
      "offset": 1757.76,
      "duration": 4.519
    },
    {
      "lang": "en",
      "text": "also on the internet when you see stuff",
      "offset": 1759.32,
      "duration": 6.54
    },
    {
      "lang": "en",
      "text": "which is stupid on a web page it's",
      "offset": 1762.279,
      "duration": 5.441
    },
    {
      "lang": "en",
      "text": "really likely to be followed up with",
      "offset": 1765.86,
      "duration": 4.679
    },
    {
      "lang": "en",
      "text": "more stuff that is stupid",
      "offset": 1767.72,
      "duration": 5.4
    },
    {
      "lang": "en",
      "text": "once gpt4",
      "offset": 1770.539,
      "duration": 5.281
    },
    {
      "lang": "en",
      "text": "starts being wrong",
      "offset": 1773.12,
      "duration": 5.939
    },
    {
      "lang": "en",
      "text": "it tends to be more and more wrong it's",
      "offset": 1775.82,
      "duration": 5.579
    },
    {
      "lang": "en",
      "text": "very hard to turn it around to start it",
      "offset": 1779.059,
      "duration": 4.761
    },
    {
      "lang": "en",
      "text": "making it be right",
      "offset": 1781.399,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "so you actually have to go back and",
      "offset": 1783.82,
      "duration": 7.26
    },
    {
      "lang": "en",
      "text": "there's actually a an edit button",
      "offset": 1786.919,
      "duration": 8.341
    },
    {
      "lang": "en",
      "text": "on these chats",
      "offset": 1791.08,
      "duration": 5.92
    },
    {
      "lang": "en",
      "text": "um",
      "offset": 1795.26,
      "duration": 3.72
    },
    {
      "lang": "en",
      "text": "and so what you generally want to do is",
      "offset": 1797,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "if it's made a mistake is don't say oh",
      "offset": 1798.98,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "here's more information to help you fix",
      "offset": 1801.32,
      "duration": 3.959
    },
    {
      "lang": "en",
      "text": "it but instead go back and click the",
      "offset": 1803.059,
      "duration": 4.561
    },
    {
      "lang": "en",
      "text": "edit",
      "offset": 1805.279,
      "duration": 5.481
    },
    {
      "lang": "en",
      "text": "and change it here",
      "offset": 1807.62,
      "duration": 3.14
    },
    {
      "lang": "en",
      "text": "and so this time it's not going to get",
      "offset": 1816.02,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "confused",
      "offset": 1818.6,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "so in this case actually fixing Steve's",
      "offset": 1820.82,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "example",
      "offset": 1823.88,
      "duration": 3.299
    },
    {
      "lang": "en",
      "text": "takes quite a lot of effort but I think",
      "offset": 1825.14,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "I've managed to get it to work",
      "offset": 1827.179,
      "duration": 3.24
    },
    {
      "lang": "en",
      "text": "eventually and I actually said oh",
      "offset": 1828.5,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "sometimes people read things too quickly",
      "offset": 1830.419,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "they don't notice things it can trick",
      "offset": 1832.1,
      "duration": 5.16
    },
    {
      "lang": "en",
      "text": "them up then they apply some pattern get",
      "offset": 1834.26,
      "duration": 5.1
    },
    {
      "lang": "en",
      "text": "the wrong answer you do the same thing",
      "offset": 1837.26,
      "duration": 4.68
    },
    {
      "lang": "en",
      "text": "by the way so I'm going to trick you",
      "offset": 1839.36,
      "duration": 6.24
    },
    {
      "lang": "en",
      "text": "so before you about to get tricked make",
      "offset": 1841.94,
      "duration": 5.099
    },
    {
      "lang": "en",
      "text": "sure you don't get tricked here's the",
      "offset": 1845.6,
      "duration": 2.819
    },
    {
      "lang": "en",
      "text": "tricky puzzle",
      "offset": 1847.039,
      "duration": 3.24
    },
    {
      "lang": "en",
      "text": "and then also with my custom",
      "offset": 1848.419,
      "duration": 4.38
    },
    {
      "lang": "en",
      "text": "instructions it takes time",
      "offset": 1850.279,
      "duration": 4.26
    },
    {
      "lang": "en",
      "text": "discussing it",
      "offset": 1852.799,
      "duration": 3.721
    },
    {
      "lang": "en",
      "text": "and this time it gets it correct it",
      "offset": 1854.539,
      "duration": 4.801
    },
    {
      "lang": "en",
      "text": "takes the Cabbage across first so it",
      "offset": 1856.52,
      "duration": 5.519
    },
    {
      "lang": "en",
      "text": "took a lot of effort to get to a point",
      "offset": 1859.34,
      "duration": 3.78
    },
    {
      "lang": "en",
      "text": "where it could actually solve this",
      "offset": 1862.039,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "because yeah when it's you know for",
      "offset": 1863.12,
      "duration": 4.02
    },
    {
      "lang": "en",
      "text": "things where",
      "offset": 1865.399,
      "duration": 5.701
    },
    {
      "lang": "en",
      "text": "it's been primed to answer a certain way",
      "offset": 1867.14,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "again and again and again it's very hard",
      "offset": 1871.1,
      "duration": 4.92
    },
    {
      "lang": "en",
      "text": "for it to not do that",
      "offset": 1873.14,
      "duration": 8.3
    },
    {
      "lang": "en",
      "text": "okay now uh something else super helpful",
      "offset": 1876.02,
      "duration": 7.86
    },
    {
      "lang": "en",
      "text": "that you can use is what they call",
      "offset": 1881.44,
      "duration": 4.839
    },
    {
      "lang": "en",
      "text": "Advanced Data analysis",
      "offset": 1883.88,
      "duration": 5.399
    },
    {
      "lang": "en",
      "text": "in Advanced Data analysis you can ask it",
      "offset": 1886.279,
      "duration": 5.221
    },
    {
      "lang": "en",
      "text": "to basically write code for you",
      "offset": 1889.279,
      "duration": 3.541
    },
    {
      "lang": "en",
      "text": "and we're going to look at how to",
      "offset": 1891.5,
      "duration": 2.64
    },
    {
      "lang": "en",
      "text": "implement this from scratch ourself",
      "offset": 1892.82,
      "duration": 3.42
    },
    {
      "lang": "en",
      "text": "quite soon but first of all let's learn",
      "offset": 1894.14,
      "duration": 5.639
    },
    {
      "lang": "en",
      "text": "how to use it so I was trying to build",
      "offset": 1896.24,
      "duration": 6.24
    },
    {
      "lang": "en",
      "text": "something that split uh into markdown",
      "offset": 1899.779,
      "duration": 4.861
    },
    {
      "lang": "en",
      "text": "headings a document on third level",
      "offset": 1902.48,
      "duration": 4.679
    },
    {
      "lang": "en",
      "text": "markdown headings so that's uh three",
      "offset": 1904.64,
      "duration": 4.5
    },
    {
      "lang": "en",
      "text": "hashes at the start of a line",
      "offset": 1907.159,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "and I was doing it on the whole of",
      "offset": 1909.14,
      "duration": 4.86
    },
    {
      "lang": "en",
      "text": "Wikipedia so using regular Expressions",
      "offset": 1911.48,
      "duration": 4.26
    },
    {
      "lang": "en",
      "text": "was really slow so I said oh I want to",
      "offset": 1914,
      "duration": 3.419
    },
    {
      "lang": "en",
      "text": "speed this up",
      "offset": 1915.74,
      "duration": 4.679
    },
    {
      "lang": "en",
      "text": "and it said okay here's some code",
      "offset": 1917.419,
      "duration": 4.561
    },
    {
      "lang": "en",
      "text": "which is great because then I can say",
      "offset": 1920.419,
      "duration": 5.161
    },
    {
      "lang": "en",
      "text": "Okay test it and include edge cases",
      "offset": 1921.98,
      "duration": 6.299
    },
    {
      "lang": "en",
      "text": "and so it then",
      "offset": 1925.58,
      "duration": 5.9
    },
    {
      "lang": "en",
      "text": "puts in the code creates extra cases",
      "offset": 1928.279,
      "duration": 6.38
    },
    {
      "lang": "en",
      "text": "tests it",
      "offset": 1931.48,
      "duration": 3.179
    },
    {
      "lang": "en",
      "text": "says yep it's working",
      "offset": 1935.14,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "it's not I notice it's actually removing",
      "offset": 1939.76,
      "duration": 4.12
    },
    {
      "lang": "en",
      "text": "the carriage return at the end of each",
      "offset": 1942.26,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "sentence so I said I'll fix that",
      "offset": 1943.88,
      "duration": 4.919
    },
    {
      "lang": "en",
      "text": "and update your tests",
      "offset": 1946.58,
      "duration": 4.339
    },
    {
      "lang": "en",
      "text": "so it said okay",
      "offset": 1948.799,
      "duration": 4.62
    },
    {
      "lang": "en",
      "text": "so now it's changed the test update the",
      "offset": 1950.919,
      "duration": 6.76
    },
    {
      "lang": "en",
      "text": "test cases surround them and oh it's not",
      "offset": 1953.419,
      "duration": 5.281
    },
    {
      "lang": "en",
      "text": "working",
      "offset": 1957.679,
      "duration": 3.24
    },
    {
      "lang": "en",
      "text": "so it says oh yeah",
      "offset": 1958.7,
      "duration": 5.16
    },
    {
      "lang": "en",
      "text": "fix the issue in the test cases",
      "offset": 1960.919,
      "duration": 4.62
    },
    {
      "lang": "en",
      "text": "nope they didn't work",
      "offset": 1963.86,
      "duration": 4.679
    },
    {
      "lang": "en",
      "text": "and you can see it's quite clever the",
      "offset": 1965.539,
      "duration": 5.581
    },
    {
      "lang": "en",
      "text": "way it's trying to fix it by looking at",
      "offset": 1968.539,
      "duration": 6.541
    },
    {
      "lang": "en",
      "text": "the results and but as you can see it's",
      "offset": 1971.12,
      "duration": 4.98
    },
    {
      "lang": "en",
      "text": "not",
      "offset": 1975.08,
      "duration": 3.42
    },
    {
      "lang": "en",
      "text": "every one of these is another attempt",
      "offset": 1976.1,
      "duration": 3.9
    },
    {
      "lang": "en",
      "text": "another attempt another attempt until",
      "offset": 1978.5,
      "duration": 3.899
    },
    {
      "lang": "en",
      "text": "eventually I gave up waiting and it's so",
      "offset": 1980,
      "duration": 4.76
    },
    {
      "lang": "en",
      "text": "funny each time it's like debating again",
      "offset": 1982.399,
      "duration": 5.341
    },
    {
      "lang": "en",
      "text": "okay this time I gotta handle it",
      "offset": 1984.76,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "properly and I gave up at the point",
      "offset": 1987.74,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "where it's like oh one more attempt",
      "offset": 1989.96,
      "duration": 4.14
    },
    {
      "lang": "en",
      "text": "so I didn't solve it",
      "offset": 1991.82,
      "duration": 4.92
    },
    {
      "lang": "en",
      "text": "um interestingly enough and",
      "offset": 1994.1,
      "duration": 6.179
    },
    {
      "lang": "en",
      "text": "you know I I again it's it it's there's",
      "offset": 1996.74,
      "duration": 6.96
    },
    {
      "lang": "en",
      "text": "some limits to the amount of kind of",
      "offset": 2000.279,
      "duration": 5.341
    },
    {
      "lang": "en",
      "text": "logic that it can do this is really a",
      "offset": 2003.7,
      "duration": 4.5
    },
    {
      "lang": "en",
      "text": "very simple question I asked it to do",
      "offset": 2005.62,
      "duration": 4.86
    },
    {
      "lang": "en",
      "text": "for me and so hopefully you can see you",
      "offset": 2008.2,
      "duration": 4.199
    },
    {
      "lang": "en",
      "text": "can't expect",
      "offset": 2010.48,
      "duration": 4.74
    },
    {
      "lang": "en",
      "text": "even GPT for code interpreter or",
      "offset": 2012.399,
      "duration": 7.16
    },
    {
      "lang": "en",
      "text": "Advanced Data analysis is now called to",
      "offset": 2015.22,
      "duration": 4.339
    },
    {
      "lang": "en",
      "text": "make it so you don't have to write code",
      "offset": 2019.659,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "anymore you know it's not a substitute",
      "offset": 2021.159,
      "duration": 4.201
    },
    {
      "lang": "en",
      "text": "for having programmers",
      "offset": 2023.019,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "um",
      "offset": 2025.36,
      "duration": 4.5
    },
    {
      "lang": "en",
      "text": "um so",
      "offset": 2026.86,
      "duration": 3
    },
    {
      "lang": "en",
      "text": "but again you know it it can often do a",
      "offset": 2030.159,
      "duration": 4.26
    },
    {
      "lang": "en",
      "text": "lot as I'll show you in a moment so for",
      "offset": 2032.559,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "example actually",
      "offset": 2034.419,
      "duration": 5.041
    },
    {
      "lang": "en",
      "text": "um OCR uh like this is something I",
      "offset": 2036.399,
      "duration": 4.38
    },
    {
      "lang": "en",
      "text": "thought was really cool",
      "offset": 2039.46,
      "duration": 3.24
    },
    {
      "lang": "en",
      "text": "um you can just paste and um sorry",
      "offset": 2040.779,
      "duration": 5.581
    },
    {
      "lang": "en",
      "text": "pastry upload so jpt4 you can upload",
      "offset": 2042.7,
      "duration": 5.459
    },
    {
      "lang": "en",
      "text": "um an image",
      "offset": 2046.36,
      "duration": 3.66
    },
    {
      "lang": "en",
      "text": "um",
      "offset": 2048.159,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "Advanced Data analysis yeah you can",
      "offset": 2050.02,
      "duration": 4.74
    },
    {
      "lang": "en",
      "text": "upload an image here",
      "offset": 2051.76,
      "duration": 3.96
    },
    {
      "lang": "en",
      "text": "um",
      "offset": 2054.76,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "and then um I wanted to basically grab",
      "offset": 2055.72,
      "duration": 5.22
    },
    {
      "lang": "en",
      "text": "some text out of an image somebody had",
      "offset": 2059.32,
      "duration": 3.539
    },
    {
      "lang": "en",
      "text": "got a screenshot of their screen and I",
      "offset": 2060.94,
      "duration": 3.659
    },
    {
      "lang": "en",
      "text": "wanted to edit which is something saying",
      "offset": 2062.859,
      "duration": 3.961
    },
    {
      "lang": "en",
      "text": "oh uh this language model can't do this",
      "offset": 2064.599,
      "duration": 4.26
    },
    {
      "lang": "en",
      "text": "and I wanted to try it as well so rather",
      "offset": 2066.82,
      "duration": 4.019
    },
    {
      "lang": "en",
      "text": "than retyping it I just uploaded that",
      "offset": 2068.859,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "image my screenshot and said can you",
      "offset": 2070.839,
      "duration": 3.721
    },
    {
      "lang": "en",
      "text": "extract the text from this image",
      "offset": 2072.46,
      "duration": 4.139
    },
    {
      "lang": "en",
      "text": "and it said oh yeah I could do that I",
      "offset": 2074.56,
      "duration": 3.779
    },
    {
      "lang": "en",
      "text": "could use OCR",
      "offset": 2076.599,
      "duration": 4.381
    },
    {
      "lang": "en",
      "text": "um and like so it literally wrote at OCR",
      "offset": 2078.339,
      "duration": 4.26
    },
    {
      "lang": "en",
      "text": "script",
      "offset": 2080.98,
      "duration": 3.119
    },
    {
      "lang": "en",
      "text": "and",
      "offset": 2082.599,
      "duration": 6.06
    },
    {
      "lang": "en",
      "text": "there it is just took a few seconds so",
      "offset": 2084.099,
      "duration": 6.721
    },
    {
      "lang": "en",
      "text": "the difference here is it didn't really",
      "offset": 2088.659,
      "duration": 5.341
    },
    {
      "lang": "en",
      "text": "require it to think of much logic it",
      "offset": 2090.82,
      "duration": 5.7
    },
    {
      "lang": "en",
      "text": "could just use a very very familiar",
      "offset": 2094,
      "duration": 4.02
    },
    {
      "lang": "en",
      "text": "pattern that it would have seen many",
      "offset": 2096.52,
      "duration": 2.819
    },
    {
      "lang": "en",
      "text": "times",
      "offset": 2098.02,
      "duration": 3.18
    },
    {
      "lang": "en",
      "text": "so this is generally where I find",
      "offset": 2099.339,
      "duration": 4.681
    },
    {
      "lang": "en",
      "text": "language models Excel is where it",
      "offset": 2101.2,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "doesn't have to think too far outside",
      "offset": 2104.02,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "the box I mean it's great on kind of",
      "offset": 2105.52,
      "duration": 5.22
    },
    {
      "lang": "en",
      "text": "creativity tasks but for like reasoning",
      "offset": 2108.099,
      "duration": 4.381
    },
    {
      "lang": "en",
      "text": "and logic tasks that are outside the box",
      "offset": 2110.74,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "I find it not great but yeah it's great",
      "offset": 2112.48,
      "duration": 5.82
    },
    {
      "lang": "en",
      "text": "at doing code for a whole wide variety",
      "offset": 2115.54,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "of different libraries and languages",
      "offset": 2118.3,
      "duration": 5.18
    },
    {
      "lang": "en",
      "text": "having said that by the way",
      "offset": 2120.66,
      "duration": 5.22
    },
    {
      "lang": "en",
      "text": "Google also has",
      "offset": 2123.48,
      "duration": 5.56
    },
    {
      "lang": "en",
      "text": "a language model called bad it's way",
      "offset": 2125.88,
      "duration": 6.04
    },
    {
      "lang": "en",
      "text": "less good than gpd4 most of the time but",
      "offset": 2129.04,
      "duration": 3.78
    },
    {
      "lang": "en",
      "text": "there is a nice thing that you can",
      "offset": 2131.92,
      "duration": 2.84
    },
    {
      "lang": "en",
      "text": "literally paste",
      "offset": 2132.82,
      "duration": 4.799
    },
    {
      "lang": "en",
      "text": "an image straight into the prompt and I",
      "offset": 2134.76,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "just typed OCR this and it didn't even",
      "offset": 2137.619,
      "duration": 3.781
    },
    {
      "lang": "en",
      "text": "have to go through code interpreter or",
      "offset": 2139.96,
      "duration": 3.06
    },
    {
      "lang": "en",
      "text": "whatever it just said oh sure I've done",
      "offset": 2141.4,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "it and",
      "offset": 2143.02,
      "duration": 3.78
    },
    {
      "lang": "en",
      "text": "there's the result of the OCR",
      "offset": 2144.52,
      "duration": 4.44
    },
    {
      "lang": "en",
      "text": "and then it even commented I thought it",
      "offset": 2146.8,
      "duration": 3.66
    },
    {
      "lang": "en",
      "text": "just does yard which I thought was cute",
      "offset": 2148.96,
      "duration": 5.159
    },
    {
      "lang": "en",
      "text": "and oh even more interestingly it even",
      "offset": 2150.46,
      "duration": 6.72
    },
    {
      "lang": "en",
      "text": "figured out where the OCR text came from",
      "offset": 2154.119,
      "duration": 5.581
    },
    {
      "lang": "en",
      "text": "and gave me a link to it",
      "offset": 2157.18,
      "duration": 5.399
    },
    {
      "lang": "en",
      "text": "um that I thought that was pretty cool",
      "offset": 2159.7,
      "duration": 5.7
    },
    {
      "lang": "en",
      "text": "okay so",
      "offset": 2162.579,
      "duration": 5.461
    },
    {
      "lang": "en",
      "text": "there's an example of it doing well I'll",
      "offset": 2165.4,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "show you one for this talk I found",
      "offset": 2168.04,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "really helpful I wanted to show you guys",
      "offset": 2169.96,
      "duration": 8.28
    },
    {
      "lang": "en",
      "text": "how much it cost to use the open AI API",
      "offset": 2172.359,
      "duration": 7.081
    },
    {
      "lang": "en",
      "text": "um but unfortunately when I went to the",
      "offset": 2178.24,
      "duration": 2.76
    },
    {
      "lang": "en",
      "text": "open AI webpage",
      "offset": 2179.44,
      "duration": 4.74
    },
    {
      "lang": "en",
      "text": "it was like all over the place the",
      "offset": 2181,
      "duration": 5.339
    },
    {
      "lang": "en",
      "text": "pricing information was on all Separate",
      "offset": 2184.18,
      "duration": 4.02
    },
    {
      "lang": "en",
      "text": "Tables and it was kind of a bit of a",
      "offset": 2186.339,
      "duration": 2.841
    },
    {
      "lang": "en",
      "text": "mess",
      "offset": 2188.2,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "so I wanted to create a table with all",
      "offset": 2189.18,
      "duration": 7.84
    },
    {
      "lang": "en",
      "text": "of the information combined like this",
      "offset": 2192.52,
      "duration": 8.3
    },
    {
      "lang": "en",
      "text": "um and here's how I did it",
      "offset": 2197.02,
      "duration": 3.8
    },
    {
      "lang": "en",
      "text": "I went to the open AI page",
      "offset": 2202.119,
      "duration": 6.181
    },
    {
      "lang": "en",
      "text": "I hit Apple a to select all",
      "offset": 2205.42,
      "duration": 6.179
    },
    {
      "lang": "en",
      "text": "and then I said in chat jpt create a",
      "offset": 2208.3,
      "duration": 5.279
    },
    {
      "lang": "en",
      "text": "table with the pricing information Rose",
      "offset": 2211.599,
      "duration": 4.921
    },
    {
      "lang": "en",
      "text": "no summarization no information not in",
      "offset": 2213.579,
      "duration": 4.741
    },
    {
      "lang": "en",
      "text": "this page every row should appear as a",
      "offset": 2216.52,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "separate Row in your output and I hit",
      "offset": 2218.32,
      "duration": 2.58
    },
    {
      "lang": "en",
      "text": "paste",
      "offset": 2219.88,
      "duration": 2.64
    },
    {
      "lang": "en",
      "text": "now that was not very helpful to it",
      "offset": 2220.9,
      "duration": 3.179
    },
    {
      "lang": "en",
      "text": "because hitting paste it's got the nav",
      "offset": 2222.52,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "bar it's got",
      "offset": 2224.079,
      "duration": 4.201
    },
    {
      "lang": "en",
      "text": "uh",
      "offset": 2225.88,
      "duration": 4.92
    },
    {
      "lang": "en",
      "text": "lots of extra information at the bottom",
      "offset": 2228.28,
      "duration": 6.18
    },
    {
      "lang": "en",
      "text": "it's got all of its uh footer",
      "offset": 2230.8,
      "duration": 5.819
    },
    {
      "lang": "en",
      "text": "Etc",
      "offset": 2234.46,
      "duration": 4.619
    },
    {
      "lang": "en",
      "text": "um but it's really good at this stuff it",
      "offset": 2236.619,
      "duration": 4.861
    },
    {
      "lang": "en",
      "text": "did it first time so there was the",
      "offset": 2239.079,
      "duration": 4.561
    },
    {
      "lang": "en",
      "text": "markdown table so I copied and pasted",
      "offset": 2241.48,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "that into Jupiter and I got my markdown",
      "offset": 2243.64,
      "duration": 6.18
    },
    {
      "lang": "en",
      "text": "table and so now you can see at a glance",
      "offset": 2247,
      "duration": 7.859
    },
    {
      "lang": "en",
      "text": "the cost of gpt4 3.5 Etc but then what I",
      "offset": 2249.82,
      "duration": 6.779
    },
    {
      "lang": "en",
      "text": "really wanted to do was show you that is",
      "offset": 2254.859,
      "duration": 3.421
    },
    {
      "lang": "en",
      "text": "a picture",
      "offset": 2256.599,
      "duration": 4.74
    },
    {
      "lang": "en",
      "text": "so I just said oh chart the input Row",
      "offset": 2258.28,
      "duration": 4.62
    },
    {
      "lang": "en",
      "text": "from this table and just paste to the",
      "offset": 2261.339,
      "duration": 3.121
    },
    {
      "lang": "en",
      "text": "table back",
      "offset": 2262.9,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "um",
      "offset": 2264.46,
      "duration": 3.48
    },
    {
      "lang": "en",
      "text": "and it did",
      "offset": 2266.26,
      "duration": 4.02
    },
    {
      "lang": "en",
      "text": "so that's pretty amazing now so let's",
      "offset": 2267.94,
      "duration": 6.3
    },
    {
      "lang": "en",
      "text": "talk about this um pricing so so far",
      "offset": 2270.28,
      "duration": 6.12
    },
    {
      "lang": "en",
      "text": "we've used chat GPT which costs 20 bucks",
      "offset": 2274.24,
      "duration": 4.92
    },
    {
      "lang": "en",
      "text": "a month and there's no like per token",
      "offset": 2276.4,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "cost or anything but if you want to use",
      "offset": 2279.16,
      "duration": 3.959
    },
    {
      "lang": "en",
      "text": "the API from python or whatever you have",
      "offset": 2280.96,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "to pay per token which is approximately",
      "offset": 2283.119,
      "duration": 5.881
    },
    {
      "lang": "en",
      "text": "per word maybe it's about uh",
      "offset": 2286,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "one and a third tokens per word on",
      "offset": 2289,
      "duration": 3.66
    },
    {
      "lang": "en",
      "text": "average",
      "offset": 2291.28,
      "duration": 3.48
    },
    {
      "lang": "en",
      "text": "unfortunately in the chart it did not",
      "offset": 2292.66,
      "duration": 4.919
    },
    {
      "lang": "en",
      "text": "include these headers gpt4 GPT 3.5 so",
      "offset": 2294.76,
      "duration": 4.859
    },
    {
      "lang": "en",
      "text": "these first two ones are gpt4",
      "offset": 2297.579,
      "duration": 4.861
    },
    {
      "lang": "en",
      "text": "and these two are GPT 3.5 so you can see",
      "offset": 2299.619,
      "duration": 7.521
    },
    {
      "lang": "en",
      "text": "the GPT 3.5 is way way cheaper",
      "offset": 2302.44,
      "duration": 4.7
    },
    {
      "lang": "en",
      "text": "um and you can see it here it's 0.03",
      "offset": 2307.54,
      "duration": 5.94
    },
    {
      "lang": "en",
      "text": "versus 0.0015",
      "offset": 2310.06,
      "duration": 3.42
    },
    {
      "lang": "en",
      "text": "so",
      "offset": 2314.28,
      "duration": 4.54
    },
    {
      "lang": "en",
      "text": "it's so cheap you can really play around",
      "offset": 2316.119,
      "duration": 5.101
    },
    {
      "lang": "en",
      "text": "with it and not worry and I want to give",
      "offset": 2318.82,
      "duration": 4.2
    },
    {
      "lang": "en",
      "text": "you a sense of what that looks like",
      "offset": 2321.22,
      "duration": 4.44
    },
    {
      "lang": "en",
      "text": "Okay so",
      "offset": 2323.02,
      "duration": 6.36
    },
    {
      "lang": "en",
      "text": "why would you use the open AI API rather",
      "offset": 2325.66,
      "duration": 5.22
    },
    {
      "lang": "en",
      "text": "than chat GPT",
      "offset": 2329.38,
      "duration": 3.54
    },
    {
      "lang": "en",
      "text": "because you can do it programmatically",
      "offset": 2330.88,
      "duration": 5.219
    },
    {
      "lang": "en",
      "text": "so you can",
      "offset": 2332.92,
      "duration": 6.24
    },
    {
      "lang": "en",
      "text": "you know you can analyze data sets you",
      "offset": 2336.099,
      "duration": 5.721
    },
    {
      "lang": "en",
      "text": "can do repetitive stuff",
      "offset": 2339.16,
      "duration": 4.679
    },
    {
      "lang": "en",
      "text": "it's kind of like a different way of",
      "offset": 2341.82,
      "duration": 4.18
    },
    {
      "lang": "en",
      "text": "programming you know it's it's things",
      "offset": 2343.839,
      "duration": 5.161
    },
    {
      "lang": "en",
      "text": "that you can think of describing",
      "offset": 2346,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "but let's just look at the most simple",
      "offset": 2349,
      "duration": 3.54
    },
    {
      "lang": "en",
      "text": "example of what that looks like so if",
      "offset": 2350.8,
      "duration": 3.539
    },
    {
      "lang": "en",
      "text": "your pip install open AI",
      "offset": 2352.54,
      "duration": 5.1
    },
    {
      "lang": "en",
      "text": "then you can import check and chat",
      "offset": 2354.339,
      "duration": 5.461
    },
    {
      "lang": "en",
      "text": "completion and then you can say Okay",
      "offset": 2357.64,
      "duration": 5.58
    },
    {
      "lang": "en",
      "text": "chat completion.create using GPT 3.5",
      "offset": 2359.8,
      "duration": 4.92
    },
    {
      "lang": "en",
      "text": "Turbo",
      "offset": 2363.22,
      "duration": 3.899
    },
    {
      "lang": "en",
      "text": "and then you can pass in a system",
      "offset": 2364.72,
      "duration": 4.379
    },
    {
      "lang": "en",
      "text": "message this is basically the same as",
      "offset": 2367.119,
      "duration": 4.381
    },
    {
      "lang": "en",
      "text": "custom instructions so okay you're an",
      "offset": 2369.099,
      "duration": 4.26
    },
    {
      "lang": "en",
      "text": "Aussie llm that uses Aussie slang and",
      "offset": 2371.5,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "analogies wherever possible",
      "offset": 2373.359,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "okay and so you can see I'm passing in",
      "offset": 2375.339,
      "duration": 4.201
    },
    {
      "lang": "en",
      "text": "an array here of messages so the first",
      "offset": 2377.44,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "is the system message and then the user",
      "offset": 2379.54,
      "duration": 3.24
    },
    {
      "lang": "en",
      "text": "message",
      "offset": 2382,
      "duration": 3.18
    },
    {
      "lang": "en",
      "text": "which is what is money",
      "offset": 2382.78,
      "duration": 6.9
    },
    {
      "lang": "en",
      "text": "okay so GPT 3.5 returns a big embedded",
      "offset": 2385.18,
      "duration": 7.38
    },
    {
      "lang": "en",
      "text": "dictionary",
      "offset": 2389.68,
      "duration": 6.899
    },
    {
      "lang": "en",
      "text": "um and the message content is well my",
      "offset": 2392.56,
      "duration": 5.88
    },
    {
      "lang": "en",
      "text": "money is like the oil that keeps the",
      "offset": 2396.579,
      "duration": 3.421
    },
    {
      "lang": "en",
      "text": "Machinery of our economy running",
      "offset": 2398.44,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "smoothly",
      "offset": 2400,
      "duration": 4.859
    },
    {
      "lang": "en",
      "text": "there you go just like a koala loves its",
      "offset": 2402.52,
      "duration": 3.96
    },
    {
      "lang": "en",
      "text": "eucalyptus leaves we humans can't",
      "offset": 2404.859,
      "duration": 3.781
    },
    {
      "lang": "en",
      "text": "survive without this stuff",
      "offset": 2406.48,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "so there's the Aussie llm's view of what",
      "offset": 2408.64,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "is money",
      "offset": 2410.8,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "so",
      "offset": 2412.96,
      "duration": 4.5
    },
    {
      "lang": "en",
      "text": "the really uh the main ones I pretty",
      "offset": 2414.64,
      "duration": 7.76
    },
    {
      "lang": "en",
      "text": "much always use are gpt4 and GPT 3.5",
      "offset": 2417.46,
      "duration": 8.58
    },
    {
      "lang": "en",
      "text": "gpd4 is just so so much better at",
      "offset": 2422.4,
      "duration": 5.62
    },
    {
      "lang": "en",
      "text": "anything remotely",
      "offset": 2426.04,
      "duration": 4.26
    },
    {
      "lang": "en",
      "text": "challenging but obviously it's much more",
      "offset": 2428.02,
      "duration": 4.74
    },
    {
      "lang": "en",
      "text": "expensive so rule of thumb you know",
      "offset": 2430.3,
      "duration": 5.279
    },
    {
      "lang": "en",
      "text": "maybe try 3.5 turbo first",
      "offset": 2432.76,
      "duration": 4.92
    },
    {
      "lang": "en",
      "text": "see how it goes if you're happy with the",
      "offset": 2435.579,
      "duration": 3.721
    },
    {
      "lang": "en",
      "text": "results then great if you're not",
      "offset": 2437.68,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "planning out for the more expensive one",
      "offset": 2439.3,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "okay so I just created a little function",
      "offset": 2442.72,
      "duration": 5.22
    },
    {
      "lang": "en",
      "text": "here called response that will print out",
      "offset": 2445.06,
      "duration": 3.42
    },
    {
      "lang": "en",
      "text": "um",
      "offset": 2447.94,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "this nested thing",
      "offset": 2448.48,
      "duration": 3.72
    },
    {
      "lang": "en",
      "text": "um",
      "offset": 2451.54,
      "duration": 3.059
    },
    {
      "lang": "en",
      "text": "and so now oh and so then the other",
      "offset": 2452.2,
      "duration": 4.74
    },
    {
      "lang": "en",
      "text": "thing to point out here is that the",
      "offset": 2454.599,
      "duration": 5.881
    },
    {
      "lang": "en",
      "text": "result of this also has a usage field",
      "offset": 2456.94,
      "duration": 7.26
    },
    {
      "lang": "en",
      "text": "which contains how many tokens was it",
      "offset": 2460.48,
      "duration": 5.94
    },
    {
      "lang": "en",
      "text": "so it's about 150 tokens",
      "offset": 2464.2,
      "duration": 6.54
    },
    {
      "lang": "en",
      "text": "so at point zero zero two",
      "offset": 2466.42,
      "duration": 8.04
    },
    {
      "lang": "en",
      "text": "dollars per thousand tokens",
      "offset": 2470.74,
      "duration": 6.119
    },
    {
      "lang": "en",
      "text": "for 150 tokens",
      "offset": 2474.46,
      "duration": 6.26
    },
    {
      "lang": "en",
      "text": "means we just paid",
      "offset": 2476.859,
      "duration": 7.381
    },
    {
      "lang": "en",
      "text": ".03 cents point zero zero zero three",
      "offset": 2480.72,
      "duration": 6.16
    },
    {
      "lang": "en",
      "text": "dollars uh to get that done so as you",
      "offset": 2484.24,
      "duration": 5.46
    },
    {
      "lang": "en",
      "text": "can see the cost is insignificant if we",
      "offset": 2486.88,
      "duration": 7.32
    },
    {
      "lang": "en",
      "text": "were using gpt4 it would be 0.03 per",
      "offset": 2489.7,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "thousand",
      "offset": 2494.2,
      "duration": 2.46
    },
    {
      "lang": "en",
      "text": "so it would be",
      "offset": 2495.22,
      "duration": 3.48
    },
    {
      "lang": "en",
      "text": "half a cent",
      "offset": 2496.66,
      "duration": 2.939
    },
    {
      "lang": "en",
      "text": "um",
      "offset": 2498.7,
      "duration": 3.78
    },
    {
      "lang": "en",
      "text": "so unless you're doing",
      "offset": 2499.599,
      "duration": 5.581
    },
    {
      "lang": "en",
      "text": "many thousands of gpt4 you're not going",
      "offset": 2502.48,
      "duration": 5.82
    },
    {
      "lang": "en",
      "text": "to be even up into the dollars and GPT",
      "offset": 2505.18,
      "duration": 5.64
    },
    {
      "lang": "en",
      "text": "3.5 even more than that",
      "offset": 2508.3,
      "duration": 4.92
    },
    {
      "lang": "en",
      "text": "but you know keep an eye on it open AI",
      "offset": 2510.82,
      "duration": 4.62
    },
    {
      "lang": "en",
      "text": "has a usage page and you can track your",
      "offset": 2513.22,
      "duration": 3.3
    },
    {
      "lang": "en",
      "text": "usage",
      "offset": 2515.44,
      "duration": 2.46
    },
    {
      "lang": "en",
      "text": "now",
      "offset": 2516.52,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "happens when we are this is really",
      "offset": 2517.9,
      "duration": 4.38
    },
    {
      "lang": "en",
      "text": "important to understand",
      "offset": 2520.599,
      "duration": 5.041
    },
    {
      "lang": "en",
      "text": "when we have a follow-up",
      "offset": 2522.28,
      "duration": 5.339
    },
    {
      "lang": "en",
      "text": "in the same conversation",
      "offset": 2525.64,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "how does that work",
      "offset": 2527.619,
      "duration": 2.901
    },
    {
      "lang": "en",
      "text": "so we just asked what goat means so for",
      "offset": 2531.46,
      "duration": 6.18
    },
    {
      "lang": "en",
      "text": "example Michael Jordan is often referred",
      "offset": 2535,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "to as",
      "offset": 2537.64,
      "duration": 4.62
    },
    {
      "lang": "en",
      "text": "the goat for his exceptional skills and",
      "offset": 2539.079,
      "duration": 5.941
    },
    {
      "lang": "en",
      "text": "accomplishments",
      "offset": 2542.26,
      "duration": 4.859
    },
    {
      "lang": "en",
      "text": "and Elvis and The Beatles referred to as",
      "offset": 2545.02,
      "duration": 3.54
    },
    {
      "lang": "en",
      "text": "goat due to their profound influence and",
      "offset": 2547.119,
      "duration": 2.641
    },
    {
      "lang": "en",
      "text": "achievement",
      "offset": 2548.56,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "so I could say",
      "offset": 2549.76,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "what",
      "offset": 2554.98,
      "duration": 3.599
    },
    {
      "lang": "en",
      "text": "profound influence and achievements are",
      "offset": 2556.72,
      "duration": 5.899
    },
    {
      "lang": "en",
      "text": "you referring to",
      "offset": 2558.579,
      "duration": 4.04
    },
    {
      "lang": "en",
      "text": "okay well I meant Elvis Presley and the",
      "offset": 2564.88,
      "duration": 4.38
    },
    {
      "lang": "en",
      "text": "Beatles did all these things now how",
      "offset": 2567.22,
      "duration": 3.54
    },
    {
      "lang": "en",
      "text": "does that work how does this follow-up",
      "offset": 2569.26,
      "duration": 4.62
    },
    {
      "lang": "en",
      "text": "work well what happens is the entire",
      "offset": 2570.76,
      "duration": 6.599
    },
    {
      "lang": "en",
      "text": "conversation is passed back",
      "offset": 2573.88,
      "duration": 6.36
    },
    {
      "lang": "en",
      "text": "and so we can actually do that here so",
      "offset": 2577.359,
      "duration": 5.161
    },
    {
      "lang": "en",
      "text": "here is the same",
      "offset": 2580.24,
      "duration": 6.119
    },
    {
      "lang": "en",
      "text": "system prompt here is the same question",
      "offset": 2582.52,
      "duration": 6.24
    },
    {
      "lang": "en",
      "text": "right and then the answer comes back",
      "offset": 2586.359,
      "duration": 4.201
    },
    {
      "lang": "en",
      "text": "with role assistant and I'm going to do",
      "offset": 2588.76,
      "duration": 3.359
    },
    {
      "lang": "en",
      "text": "something pretty cheeky",
      "offset": 2590.56,
      "duration": 3.299
    },
    {
      "lang": "en",
      "text": "I'm going to pretend",
      "offset": 2592.119,
      "duration": 3.541
    },
    {
      "lang": "en",
      "text": "that it didn't say",
      "offset": 2593.859,
      "duration": 4.801
    },
    {
      "lang": "en",
      "text": "money is like oil I'm going to say oh",
      "offset": 2595.66,
      "duration": 5.1
    },
    {
      "lang": "en",
      "text": "you actually said money is like",
      "offset": 2598.66,
      "duration": 3.24
    },
    {
      "lang": "en",
      "text": "kangaroos",
      "offset": 2600.76,
      "duration": 4.14
    },
    {
      "lang": "en",
      "text": "I thought what it's going to do okay so",
      "offset": 2601.9,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "you can like literally invent a",
      "offset": 2604.9,
      "duration": 4.199
    },
    {
      "lang": "en",
      "text": "conversation in which the language model",
      "offset": 2607.42,
      "duration": 4.02
    },
    {
      "lang": "en",
      "text": "said something different because this is",
      "offset": 2609.099,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "actually how it's done in a multi-stage",
      "offset": 2611.44,
      "duration": 4.62
    },
    {
      "lang": "en",
      "text": "conversation there's no state",
      "offset": 2613.18,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "right there's nothing stored on the",
      "offset": 2616.06,
      "duration": 4.14
    },
    {
      "lang": "en",
      "text": "server you're passing back the entire",
      "offset": 2617.98,
      "duration": 5.339
    },
    {
      "lang": "en",
      "text": "conversation again and telling it what",
      "offset": 2620.2,
      "duration": 4.44
    },
    {
      "lang": "en",
      "text": "it told you",
      "offset": 2623.319,
      "duration": 3.721
    },
    {
      "lang": "en",
      "text": "right so I'm going to tell it it's it",
      "offset": 2624.64,
      "duration": 4.38
    },
    {
      "lang": "en",
      "text": "told me that money is like kangaroos and",
      "offset": 2627.04,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "then I'll ask the user oh really in what",
      "offset": 2629.02,
      "duration": 4.26
    },
    {
      "lang": "en",
      "text": "way and this is kind of cool because you",
      "offset": 2631.359,
      "duration": 5.641
    },
    {
      "lang": "en",
      "text": "can like see how it convinces you of of",
      "offset": 2633.28,
      "duration": 6.299
    },
    {
      "lang": "en",
      "text": "something I just invented oh let me",
      "offset": 2637,
      "duration": 4.14
    },
    {
      "lang": "en",
      "text": "break it down for you cover it just like",
      "offset": 2639.579,
      "duration": 3.181
    },
    {
      "lang": "en",
      "text": "kangaroos hop around and carry their",
      "offset": 2641.14,
      "duration": 3.66
    },
    {
      "lang": "en",
      "text": "Joeys in their pouch money is a means of",
      "offset": 2642.76,
      "duration": 4.26
    },
    {
      "lang": "en",
      "text": "carrying value around so there you go",
      "offset": 2644.8,
      "duration": 5.58
    },
    {
      "lang": "en",
      "text": "it's uh make your own analogy",
      "offset": 2647.02,
      "duration": 6.42
    },
    {
      "lang": "en",
      "text": "cool so I'll create a little function",
      "offset": 2650.38,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "here that just puts these things",
      "offset": 2653.44,
      "duration": 4.98
    },
    {
      "lang": "en",
      "text": "together for us just a message if there",
      "offset": 2655.66,
      "duration": 4.62
    },
    {
      "lang": "en",
      "text": "is one the user message and returns",
      "offset": 2658.42,
      "duration": 3.96
    },
    {
      "lang": "en",
      "text": "they're completion",
      "offset": 2660.28,
      "duration": 3.9
    },
    {
      "lang": "en",
      "text": "and so now we can ask it what's the",
      "offset": 2662.38,
      "duration": 3.239
    },
    {
      "lang": "en",
      "text": "meaning of life",
      "offset": 2664.18,
      "duration": 4.679
    },
    {
      "lang": "en",
      "text": "passing in the Aussie system prompt",
      "offset": 2665.619,
      "duration": 5.101
    },
    {
      "lang": "en",
      "text": "the meaning of life is like trying to",
      "offset": 2668.859,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "catch a wave on a sunny day at Bondi",
      "offset": 2670.72,
      "duration": 4.74
    },
    {
      "lang": "en",
      "text": "Beach okay there you go so",
      "offset": 2672.46,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "um what do you need to be aware of",
      "offset": 2675.46,
      "duration": 3.659
    },
    {
      "lang": "en",
      "text": "um well as I said one thing is keep an",
      "offset": 2677.5,
      "duration": 3.96
    },
    {
      "lang": "en",
      "text": "eye on your usage if you're doing it you",
      "offset": 2679.119,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "know hundreds or thousands of times in a",
      "offset": 2681.46,
      "duration": 4.859
    },
    {
      "lang": "en",
      "text": "loop keep an eye on not spending too",
      "offset": 2683.44,
      "duration": 5.639
    },
    {
      "lang": "en",
      "text": "much money but also if you're doing it",
      "offset": 2686.319,
      "duration": 4.621
    },
    {
      "lang": "en",
      "text": "too fast particularly the first day or",
      "offset": 2689.079,
      "duration": 4.5
    },
    {
      "lang": "en",
      "text": "two you've got an account you're likely",
      "offset": 2690.94,
      "duration": 7.62
    },
    {
      "lang": "en",
      "text": "to hit the limits for the API and so the",
      "offset": 2693.579,
      "duration": 8.941
    },
    {
      "lang": "en",
      "text": "limits initially are pretty low",
      "offset": 2698.56,
      "duration": 8.039
    },
    {
      "lang": "en",
      "text": "as you can see three requests per minute",
      "offset": 2702.52,
      "duration": 6.14
    },
    {
      "lang": "en",
      "text": "um",
      "offset": 2706.599,
      "duration": 2.061
    },
    {
      "lang": "en",
      "text": "so that's for free users page users",
      "offset": 2709.72,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "First 48 hours and after that it starts",
      "offset": 2711.94,
      "duration": 4.379
    },
    {
      "lang": "en",
      "text": "going up and you can always ask for more",
      "offset": 2715,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "I just mentioned this because you're",
      "offset": 2716.319,
      "duration": 4.861
    },
    {
      "lang": "en",
      "text": "going to want to have a function that",
      "offset": 2719.56,
      "duration": 4.74
    },
    {
      "lang": "en",
      "text": "keeps an eye on that and so what I did",
      "offset": 2721.18,
      "duration": 5.399
    },
    {
      "lang": "en",
      "text": "is I actually just went to Bing which",
      "offset": 2724.3,
      "duration": 5.64
    },
    {
      "lang": "en",
      "text": "has a somewhat crappy version of gpt4",
      "offset": 2726.579,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "nowadays but it can still do basic stuff",
      "offset": 2729.94,
      "duration": 4.82
    },
    {
      "lang": "en",
      "text": "for free and I said please show me",
      "offset": 2731.859,
      "duration": 7.441
    },
    {
      "lang": "en",
      "text": "python code to call the open AI API",
      "offset": 2734.76,
      "duration": 6.7
    },
    {
      "lang": "en",
      "text": "and handle rate limits",
      "offset": 2739.3,
      "duration": 4.74
    },
    {
      "lang": "en",
      "text": "and it wrote this code",
      "offset": 2741.46,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "it's got to try",
      "offset": 2744.04,
      "duration": 3.72
    },
    {
      "lang": "en",
      "text": "checks for rate limit errors",
      "offset": 2745.78,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "grabs the retry after",
      "offset": 2747.76,
      "duration": 7.14
    },
    {
      "lang": "en",
      "text": "sleeps for that long and calls itself",
      "offset": 2751.3,
      "duration": 5.94
    },
    {
      "lang": "en",
      "text": "and so now we can use that to ask for",
      "offset": 2754.9,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "example what's the world's funniest joke",
      "offset": 2757.24,
      "duration": 5.9
    },
    {
      "lang": "en",
      "text": "and",
      "offset": 2760.42,
      "duration": 5.22
    },
    {
      "lang": "en",
      "text": "there we go is the world's funniest",
      "offset": 2763.14,
      "duration": 4.78
    },
    {
      "lang": "en",
      "text": "trick",
      "offset": 2765.64,
      "duration": 5.16
    },
    {
      "lang": "en",
      "text": "so there's like the basic stuff you need",
      "offset": 2767.92,
      "duration": 7.5
    },
    {
      "lang": "en",
      "text": "to get started using the open AI",
      "offset": 2770.8,
      "duration": 6.9
    },
    {
      "lang": "en",
      "text": "llms",
      "offset": 2775.42,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "um and uh",
      "offset": 2777.7,
      "duration": 4.68
    },
    {
      "lang": "en",
      "text": "and yeah I'd definitely suggest spending",
      "offset": 2780.46,
      "duration": 3.3
    },
    {
      "lang": "en",
      "text": "plenty of time",
      "offset": 2782.38,
      "duration": 3.78
    },
    {
      "lang": "en",
      "text": "with that so that you feel like you're",
      "offset": 2783.76,
      "duration": 4.62
    },
    {
      "lang": "en",
      "text": "really a llm",
      "offset": 2786.16,
      "duration": 3.659
    },
    {
      "lang": "en",
      "text": "using",
      "offset": 2788.38,
      "duration": 4.1
    },
    {
      "lang": "en",
      "text": "expert",
      "offset": 2789.819,
      "duration": 2.661
    },
    {
      "lang": "en",
      "text": "so what else can we do",
      "offset": 2793.599,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "well let's create our own code",
      "offset": 2795.4,
      "duration": 5.179
    },
    {
      "lang": "en",
      "text": "interpreter that runs inside Jupiter",
      "offset": 2797.44,
      "duration": 6.419
    },
    {
      "lang": "en",
      "text": "and so to do this we're going to take",
      "offset": 2800.579,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "advantage of a really Nifty thing",
      "offset": 2803.859,
      "duration": 5.641
    },
    {
      "lang": "en",
      "text": "called function calling which is",
      "offset": 2806.099,
      "duration": 6.22
    },
    {
      "lang": "en",
      "text": "provided by the open AI API and in",
      "offset": 2809.5,
      "duration": 5.099
    },
    {
      "lang": "en",
      "text": "function calling when we call our ask",
      "offset": 2812.319,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "GPT function",
      "offset": 2814.599,
      "duration": 4.5
    },
    {
      "lang": "en",
      "text": "which is this little one here",
      "offset": 2816.64,
      "duration": 4.679
    },
    {
      "lang": "en",
      "text": "we had room to pass in some keyword",
      "offset": 2819.099,
      "duration": 4.381
    },
    {
      "lang": "en",
      "text": "arguments that will be just passed along",
      "offset": 2821.319,
      "duration": 4.26
    },
    {
      "lang": "en",
      "text": "to chat completion.create",
      "offset": 2823.48,
      "duration": 4.5
    },
    {
      "lang": "en",
      "text": "and one of those keyword arguments you",
      "offset": 2825.579,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "can pass is",
      "offset": 2827.98,
      "duration": 4.44
    },
    {
      "lang": "en",
      "text": "functions",
      "offset": 2830.859,
      "duration": 5.701
    },
    {
      "lang": "en",
      "text": "what on Earth is that functions tells",
      "offset": 2832.42,
      "duration": 5.88
    },
    {
      "lang": "en",
      "text": "open AI",
      "offset": 2836.56,
      "duration": 3
    },
    {
      "lang": "en",
      "text": "about",
      "offset": 2838.3,
      "duration": 4.14
    },
    {
      "lang": "en",
      "text": "tools that you have about functions that",
      "offset": 2839.56,
      "duration": 5.1
    },
    {
      "lang": "en",
      "text": "you have so for example I created a",
      "offset": 2842.44,
      "duration": 6.179
    },
    {
      "lang": "en",
      "text": "really simple function called sums",
      "offset": 2844.66,
      "duration": 6.179
    },
    {
      "lang": "en",
      "text": "and it adds",
      "offset": 2848.619,
      "duration": 4.801
    },
    {
      "lang": "en",
      "text": "two things",
      "offset": 2850.839,
      "duration": 5.841
    },
    {
      "lang": "en",
      "text": "in fact it adds two it's",
      "offset": 2853.42,
      "duration": 3.26
    },
    {
      "lang": "en",
      "text": "um and I'm going to pass that function",
      "offset": 2857.38,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "to",
      "offset": 2860.14,
      "duration": 3
    },
    {
      "lang": "en",
      "text": "chatcompletion.create",
      "offset": 2864.24,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "now you can't pass a python function",
      "offset": 2865.96,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "directly you actually have to pass",
      "offset": 2868.96,
      "duration": 5.399
    },
    {
      "lang": "en",
      "text": "What's called the Json schema so you",
      "offset": 2870.76,
      "duration": 5.78
    },
    {
      "lang": "en",
      "text": "have to pass the schema for the function",
      "offset": 2874.359,
      "duration": 5.341
    },
    {
      "lang": "en",
      "text": "so I created this Nifty little function",
      "offset": 2876.54,
      "duration": 4.86
    },
    {
      "lang": "en",
      "text": "that you're welcome to borrow",
      "offset": 2879.7,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "which uses pedantic",
      "offset": 2881.4,
      "duration": 7.48
    },
    {
      "lang": "en",
      "text": "and also Python's inspect module to",
      "offset": 2885.3,
      "duration": 7.84
    },
    {
      "lang": "en",
      "text": "automatically take a python function and",
      "offset": 2888.88,
      "duration": 5.34
    },
    {
      "lang": "en",
      "text": "return",
      "offset": 2893.14,
      "duration": 3.3
    },
    {
      "lang": "en",
      "text": "the schema for it and so this is",
      "offset": 2894.22,
      "duration": 3.359
    },
    {
      "lang": "en",
      "text": "actually what's going to get passed to",
      "offset": 2896.44,
      "duration": 2.52
    },
    {
      "lang": "en",
      "text": "open AI so it's going to know that",
      "offset": 2897.579,
      "duration": 2.701
    },
    {
      "lang": "en",
      "text": "there's a function called sums it's",
      "offset": 2898.96,
      "duration": 3
    },
    {
      "lang": "en",
      "text": "going to know what it does",
      "offset": 2900.28,
      "duration": 3.96
    },
    {
      "lang": "en",
      "text": "and it's going to know what parameters",
      "offset": 2901.96,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "it takes",
      "offset": 2904.24,
      "duration": 3.9
    },
    {
      "lang": "en",
      "text": "what the defaults are and what's",
      "offset": 2905.56,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "required",
      "offset": 2908.14,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "so this is like when I first heard about",
      "offset": 2909.64,
      "duration": 4.5
    },
    {
      "lang": "en",
      "text": "this I found this a bit mind-bending",
      "offset": 2912.22,
      "duration": 3.66
    },
    {
      "lang": "en",
      "text": "because this is so different to how we",
      "offset": 2914.14,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "normally program computers where the key",
      "offset": 2915.88,
      "duration": 4.68
    },
    {
      "lang": "en",
      "text": "thing for programming the computer",
      "offset": 2918.7,
      "duration": 4.2
    },
    {
      "lang": "en",
      "text": "here actually is the doc string this is",
      "offset": 2920.56,
      "duration": 5.4
    },
    {
      "lang": "en",
      "text": "the thing that gpt4 will look at and say",
      "offset": 2922.9,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "oh what does this function do so it's",
      "offset": 2925.96,
      "duration": 4.2
    },
    {
      "lang": "en",
      "text": "critical that this describes exactly",
      "offset": 2928.42,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "what the function does",
      "offset": 2930.16,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "and so if I then say",
      "offset": 2932.02,
      "duration": 5.22
    },
    {
      "lang": "en",
      "text": "um",
      "offset": 2935.92,
      "duration": 4.14
    },
    {
      "lang": "en",
      "text": "what is six plus three",
      "offset": 2937.24,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "right and I just I really wanted to make",
      "offset": 2940.06,
      "duration": 4.14
    },
    {
      "lang": "en",
      "text": "sure it actually did it here so I gave",
      "offset": 2942.04,
      "duration": 3.96
    },
    {
      "lang": "en",
      "text": "it lots of prompts to say because",
      "offset": 2944.2,
      "duration": 3.899
    },
    {
      "lang": "en",
      "text": "obviously it knows how to do it itself",
      "offset": 2946,
      "duration": 5.099
    },
    {
      "lang": "en",
      "text": "without calling sums so it'll only use",
      "offset": 2948.099,
      "duration": 5.941
    },
    {
      "lang": "en",
      "text": "your functions if it feels it needs to",
      "offset": 2951.099,
      "duration": 5.281
    },
    {
      "lang": "en",
      "text": "which is a weird concept I mean I guess",
      "offset": 2954.04,
      "duration": 5.279
    },
    {
      "lang": "en",
      "text": "feels is not a great word to use but you",
      "offset": 2956.38,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "kind of have to anthropomorphize these",
      "offset": 2959.319,
      "duration": 2.641
    },
    {
      "lang": "en",
      "text": "things a little bit because they don't",
      "offset": 2960.94,
      "duration": 4.44
    },
    {
      "lang": "en",
      "text": "behave like normal computer programs",
      "offset": 2961.96,
      "duration": 7.68
    },
    {
      "lang": "en",
      "text": "um so if I if I ask GPT what is six plus",
      "offset": 2965.38,
      "duration": 5.939
    },
    {
      "lang": "en",
      "text": "three and tell it that there's a",
      "offset": 2969.64,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "function called sums then it does not",
      "offset": 2971.319,
      "duration": 5.581
    },
    {
      "lang": "en",
      "text": "actually return the number nine",
      "offset": 2973.96,
      "duration": 5.1
    },
    {
      "lang": "en",
      "text": "instead it returns something saying",
      "offset": 2976.9,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "please call a function",
      "offset": 2979.06,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "call this function and pass it these",
      "offset": 2980.98,
      "duration": 6.06
    },
    {
      "lang": "en",
      "text": "arguments so if I print it out there's",
      "offset": 2985.06,
      "duration": 4.5
    },
    {
      "lang": "en",
      "text": "the arguments",
      "offset": 2987.04,
      "duration": 4.62
    },
    {
      "lang": "en",
      "text": "so I created a little function called",
      "offset": 2989.56,
      "duration": 5.22
    },
    {
      "lang": "en",
      "text": "core function and it goes into the",
      "offset": 2991.66,
      "duration": 6.659
    },
    {
      "lang": "en",
      "text": "result of open AI grabs the function",
      "offset": 2994.78,
      "duration": 5.059
    },
    {
      "lang": "en",
      "text": "call",
      "offset": 2998.319,
      "duration": 3.721
    },
    {
      "lang": "en",
      "text": "checks that the name is something that",
      "offset": 2999.839,
      "duration": 3.461
    },
    {
      "lang": "en",
      "text": "it's allowed to do",
      "offset": 3002.04,
      "duration": 4.26
    },
    {
      "lang": "en",
      "text": "grabs it from the global system table",
      "offset": 3003.3,
      "duration": 4.86
    },
    {
      "lang": "en",
      "text": "and calls it",
      "offset": 3006.3,
      "duration": 4.26
    },
    {
      "lang": "en",
      "text": "passing in the parameters",
      "offset": 3008.16,
      "duration": 4.679
    },
    {
      "lang": "en",
      "text": "and so if I now say okay call the",
      "offset": 3010.56,
      "duration": 5.299
    },
    {
      "lang": "en",
      "text": "function that",
      "offset": 3012.839,
      "duration": 3.02
    },
    {
      "lang": "en",
      "text": "we got back",
      "offset": 3016.2,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "we finally get",
      "offset": 3017.76,
      "duration": 4.74
    },
    {
      "lang": "en",
      "text": "nine",
      "offset": 3020.04,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "so",
      "offset": 3022.5,
      "duration": 3.359
    },
    {
      "lang": "en",
      "text": "this is a very simple example it's not",
      "offset": 3023.88,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "really doing anything that useful but",
      "offset": 3025.859,
      "duration": 3.96
    },
    {
      "lang": "en",
      "text": "what we could do now is we can create a",
      "offset": 3027.48,
      "duration": 4.619
    },
    {
      "lang": "en",
      "text": "much more powerful function",
      "offset": 3029.819,
      "duration": 3.961
    },
    {
      "lang": "en",
      "text": "called",
      "offset": 3032.099,
      "duration": 3.24
    },
    {
      "lang": "en",
      "text": "python",
      "offset": 3033.78,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "and the python function",
      "offset": 3035.339,
      "duration": 4.74
    },
    {
      "lang": "en",
      "text": "executes",
      "offset": 3038.099,
      "duration": 3.661
    },
    {
      "lang": "en",
      "text": "code",
      "offset": 3040.079,
      "duration": 3.661
    },
    {
      "lang": "en",
      "text": "using python",
      "offset": 3041.76,
      "duration": 4.74
    },
    {
      "lang": "en",
      "text": "and Returns the result",
      "offset": 3043.74,
      "duration": 6.119
    },
    {
      "lang": "en",
      "text": "now of course I didn't want my computer",
      "offset": 3046.5,
      "duration": 6.9
    },
    {
      "lang": "en",
      "text": "to run arbitrary python code that gpt4",
      "offset": 3049.859,
      "duration": 5.821
    },
    {
      "lang": "en",
      "text": "told it to without checking so I just",
      "offset": 3053.4,
      "duration": 4.26
    },
    {
      "lang": "en",
      "text": "got it to check first so say oh you're",
      "offset": 3055.68,
      "duration": 4.639
    },
    {
      "lang": "en",
      "text": "sure you want to do this",
      "offset": 3057.66,
      "duration": 2.659
    },
    {
      "lang": "en",
      "text": "um",
      "offset": 3060.599,
      "duration": 3
    },
    {
      "lang": "en",
      "text": "so now",
      "offset": 3061.44,
      "duration": 4.2
    },
    {
      "lang": "en",
      "text": "I can say",
      "offset": 3063.599,
      "duration": 5.701
    },
    {
      "lang": "en",
      "text": "ask GPT what is 12 factorial",
      "offset": 3065.64,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "system prompt you can use Python for any",
      "offset": 3069.3,
      "duration": 4.14
    },
    {
      "lang": "en",
      "text": "required computations and say okay",
      "offset": 3071.64,
      "duration": 3.08
    },
    {
      "lang": "en",
      "text": "here's a function you've got available",
      "offset": 3073.44,
      "duration": 4.619
    },
    {
      "lang": "en",
      "text": "it's the python function",
      "offset": 3074.72,
      "duration": 6.76
    },
    {
      "lang": "en",
      "text": "so if I now call this",
      "offset": 3078.059,
      "duration": 6.661
    },
    {
      "lang": "en",
      "text": "it will pass me back again",
      "offset": 3081.48,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "a completion object and here it's going",
      "offset": 3084.72,
      "duration": 4.02
    },
    {
      "lang": "en",
      "text": "to say okay I want you to call python",
      "offset": 3086.52,
      "duration": 3.9
    },
    {
      "lang": "en",
      "text": "passing in",
      "offset": 3088.74,
      "duration": 4.52
    },
    {
      "lang": "en",
      "text": "this argument",
      "offset": 3090.42,
      "duration": 2.84
    },
    {
      "lang": "en",
      "text": "and when I do it's going to go import",
      "offset": 3093.3,
      "duration": 4.559
    },
    {
      "lang": "en",
      "text": "math result equals blur and then return",
      "offset": 3095.579,
      "duration": 7.5
    },
    {
      "lang": "en",
      "text": "result do I want to do that yes I do",
      "offset": 3097.859,
      "duration": 7.74
    },
    {
      "lang": "en",
      "text": "and there it is",
      "offset": 3103.079,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "now there's one more step which we can",
      "offset": 3105.599,
      "duration": 3.96
    },
    {
      "lang": "en",
      "text": "optionally do I mean we've got the",
      "offset": 3108.359,
      "duration": 3.541
    },
    {
      "lang": "en",
      "text": "answer we wanted but often we want the",
      "offset": 3109.559,
      "duration": 4.921
    },
    {
      "lang": "en",
      "text": "answer in more of a chat format and so",
      "offset": 3111.9,
      "duration": 5.459
    },
    {
      "lang": "en",
      "text": "the way to do that is to again repeat",
      "offset": 3114.48,
      "duration": 6.9
    },
    {
      "lang": "en",
      "text": "everything that you've passed into so",
      "offset": 3117.359,
      "duration": 5.161
    },
    {
      "lang": "en",
      "text": "far",
      "offset": 3121.38,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "but then instead of adding in",
      "offset": 3122.52,
      "duration": 4.799
    },
    {
      "lang": "en",
      "text": "an assistant role response we have to",
      "offset": 3124.98,
      "duration": 5.639
    },
    {
      "lang": "en",
      "text": "provide a function role response and",
      "offset": 3127.319,
      "duration": 5.461
    },
    {
      "lang": "en",
      "text": "simply",
      "offset": 3130.619,
      "duration": 4.621
    },
    {
      "lang": "en",
      "text": "put in here the result we got back from",
      "offset": 3132.78,
      "duration": 3.539
    },
    {
      "lang": "en",
      "text": "the function",
      "offset": 3135.24,
      "duration": 4.46
    },
    {
      "lang": "en",
      "text": "and if we do that",
      "offset": 3136.319,
      "duration": 3.381
    },
    {
      "lang": "en",
      "text": "we now get",
      "offset": 3141.059,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "the prose response 12 factorial is equal",
      "offset": 3142.92,
      "duration": 3.3
    },
    {
      "lang": "en",
      "text": "to",
      "offset": 3145.38,
      "duration": 4.62
    },
    {
      "lang": "en",
      "text": "470 and a million 1 600.",
      "offset": 3146.22,
      "duration": 5.099
    },
    {
      "lang": "en",
      "text": "now",
      "offset": 3150,
      "duration": 3.72
    },
    {
      "lang": "en",
      "text": "functions",
      "offset": 3151.319,
      "duration": 6.361
    },
    {
      "lang": "en",
      "text": "like python you can still ask it about",
      "offset": 3153.72,
      "duration": 6.72
    },
    {
      "lang": "en",
      "text": "non-python things",
      "offset": 3157.68,
      "duration": 5.58
    },
    {
      "lang": "en",
      "text": "and it just ignores it if you don't need",
      "offset": 3160.44,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "it right so you can have a whole bunch",
      "offset": 3163.26,
      "duration": 4.44
    },
    {
      "lang": "en",
      "text": "of functions available that you've built",
      "offset": 3165,
      "duration": 6.359
    },
    {
      "lang": "en",
      "text": "to do whatever you need for the stuff",
      "offset": 3167.7,
      "duration": 5.22
    },
    {
      "lang": "en",
      "text": "which",
      "offset": 3171.359,
      "duration": 2.821
    },
    {
      "lang": "en",
      "text": "um",
      "offset": 3172.92,
      "duration": 3.56
    },
    {
      "lang": "en",
      "text": "the language model isn't familiar with",
      "offset": 3174.18,
      "duration": 4.82
    },
    {
      "lang": "en",
      "text": "and it'll still",
      "offset": 3176.48,
      "duration": 5.92
    },
    {
      "lang": "en",
      "text": "solve whatever it can on its own and use",
      "offset": 3179,
      "duration": 6.7
    },
    {
      "lang": "en",
      "text": "your tools use your functions where",
      "offset": 3182.4,
      "duration": 5.719
    },
    {
      "lang": "en",
      "text": "possible",
      "offset": 3185.7,
      "duration": 2.419
    },
    {
      "lang": "en",
      "text": "okay so we have built our own",
      "offset": 3188.52,
      "duration": 6.839
    },
    {
      "lang": "en",
      "text": "code interpreter from scratch I think",
      "offset": 3193.38,
      "duration": 4.699
    },
    {
      "lang": "en",
      "text": "that's pretty amazing",
      "offset": 3195.359,
      "duration": 2.72
    },
    {
      "lang": "en",
      "text": "so that is",
      "offset": 3202.2,
      "duration": 5.58
    },
    {
      "lang": "en",
      "text": "um what you can do with or some of the",
      "offset": 3204.24,
      "duration": 7.98
    },
    {
      "lang": "en",
      "text": "stuff you can do with open AI",
      "offset": 3207.78,
      "duration": 7.2
    },
    {
      "lang": "en",
      "text": "um what about stuff that you can do on",
      "offset": 3212.22,
      "duration": 4.5
    },
    {
      "lang": "en",
      "text": "your own computer",
      "offset": 3214.98,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "well to use a language model on your own",
      "offset": 3216.72,
      "duration": 5.7
    },
    {
      "lang": "en",
      "text": "computer you're going to need to use",
      "offset": 3219.54,
      "duration": 5.519
    },
    {
      "lang": "en",
      "text": "a GPU",
      "offset": 3222.42,
      "duration": 4.679
    },
    {
      "lang": "en",
      "text": "um so I guess the first thing to think",
      "offset": 3225.059,
      "duration": 3.721
    },
    {
      "lang": "en",
      "text": "about is like",
      "offset": 3227.099,
      "duration": 4.921
    },
    {
      "lang": "en",
      "text": "do you want this does it make sense to",
      "offset": 3228.78,
      "duration": 7.02
    },
    {
      "lang": "en",
      "text": "do stuff on your own computer what are",
      "offset": 3232.02,
      "duration": 5.64
    },
    {
      "lang": "en",
      "text": "the benefits",
      "offset": 3235.8,
      "duration": 2.7
    },
    {
      "lang": "en",
      "text": "um",
      "offset": 3237.66,
      "duration": 3.659
    },
    {
      "lang": "en",
      "text": "there are not any open source models",
      "offset": 3238.5,
      "duration": 7.579
    },
    {
      "lang": "en",
      "text": "that are as good yet as gpt4",
      "offset": 3241.319,
      "duration": 4.76
    },
    {
      "lang": "en",
      "text": "and I would have to say also like",
      "offset": 3246.54,
      "duration": 3.72
    },
    {
      "lang": "en",
      "text": "actually open ai's pricing's really",
      "offset": 3248.099,
      "duration": 5.281
    },
    {
      "lang": "en",
      "text": "pretty good so it's it's not immediately",
      "offset": 3250.26,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "obvious that you definitely want to kind",
      "offset": 3253.38,
      "duration": 4.679
    },
    {
      "lang": "en",
      "text": "of go in-house but there's lots of",
      "offset": 3256.26,
      "duration": 4.44
    },
    {
      "lang": "en",
      "text": "reasons you might want to and we'll look",
      "offset": 3258.059,
      "duration": 6.201
    },
    {
      "lang": "en",
      "text": "at some examples of them today",
      "offset": 3260.7,
      "duration": 5.399
    },
    {
      "lang": "en",
      "text": "one example you might want to go",
      "offset": 3264.26,
      "duration": 5.5
    },
    {
      "lang": "en",
      "text": "in-house is that you want to be able to",
      "offset": 3266.099,
      "duration": 7.081
    },
    {
      "lang": "en",
      "text": "ask questions about your proprietary",
      "offset": 3269.76,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "documents or about information after",
      "offset": 3273.18,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "September 2021 the the knowledge cut off",
      "offset": 3275.76,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "or you might want to create your own",
      "offset": 3278.54,
      "duration": 4.12
    },
    {
      "lang": "en",
      "text": "model that's particularly good at",
      "offset": 3280.8,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "solving the kinds of problems that you",
      "offset": 3282.66,
      "duration": 4.199
    },
    {
      "lang": "en",
      "text": "need to solve using fine tuning and",
      "offset": 3284.16,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "these are all things that you absolutely",
      "offset": 3286.859,
      "duration": 4.041
    },
    {
      "lang": "en",
      "text": "can get better than GPT for performance",
      "offset": 3288.24,
      "duration": 5.78
    },
    {
      "lang": "en",
      "text": "at work or at home without too much",
      "offset": 3290.9,
      "duration": 6.58
    },
    {
      "lang": "en",
      "text": "without too much money or travel so",
      "offset": 3294.02,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "these are the situations in which you",
      "offset": 3297.48,
      "duration": 3.9
    },
    {
      "lang": "en",
      "text": "might want to go down this path and so",
      "offset": 3298.98,
      "duration": 4.94
    },
    {
      "lang": "en",
      "text": "you don't necessarily have to buy a GPU",
      "offset": 3301.38,
      "duration": 5.699
    },
    {
      "lang": "en",
      "text": "on kaggle they will give you a notebook",
      "offset": 3303.92,
      "duration": 4.419
    },
    {
      "lang": "en",
      "text": "with two",
      "offset": 3307.079,
      "duration": 3.721
    },
    {
      "lang": "en",
      "text": "quite old gpus attached",
      "offset": 3308.339,
      "duration": 5.601
    },
    {
      "lang": "en",
      "text": "and very little Ram but it's something",
      "offset": 3310.8,
      "duration": 6.9
    },
    {
      "lang": "en",
      "text": "or you can use collab and on collab you",
      "offset": 3313.94,
      "duration": 7.119
    },
    {
      "lang": "en",
      "text": "can get much better gpus than kaggle has",
      "offset": 3317.7,
      "duration": 7.139
    },
    {
      "lang": "en",
      "text": "and more RAM particularly if you pay a",
      "offset": 3321.059,
      "duration": 6.78
    },
    {
      "lang": "en",
      "text": "monthly subscription fee",
      "offset": 3324.839,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "um",
      "offset": 3327.839,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "so those are some options for free or",
      "offset": 3328.44,
      "duration": 4.7
    },
    {
      "lang": "en",
      "text": "low cost",
      "offset": 3331.68,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "you can also of course",
      "offset": 3333.14,
      "duration": 3.9
    },
    {
      "lang": "en",
      "text": "you know go to one of the many kind of",
      "offset": 3337.38,
      "duration": 7.979
    },
    {
      "lang": "en",
      "text": "GPU server providers and they change all",
      "offset": 3341.359,
      "duration": 6.521
    },
    {
      "lang": "en",
      "text": "the time is to kind of what's what's",
      "offset": 3345.359,
      "duration": 5.641
    },
    {
      "lang": "en",
      "text": "good or what's not run pod is one",
      "offset": 3347.88,
      "duration": 4.34
    },
    {
      "lang": "en",
      "text": "example",
      "offset": 3351,
      "duration": 5.099
    },
    {
      "lang": "en",
      "text": "and you can see you know if you want the",
      "offset": 3352.22,
      "duration": 6.7
    },
    {
      "lang": "en",
      "text": "biggest and best machine you're talking",
      "offset": 3356.099,
      "duration": 5.841
    },
    {
      "lang": "en",
      "text": "34 an hour so it gets pretty expensive",
      "offset": 3358.92,
      "duration": 5.34
    },
    {
      "lang": "en",
      "text": "but you can certainly get things a lot",
      "offset": 3361.94,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "cheaper",
      "offset": 3364.26,
      "duration": 3.359
    },
    {
      "lang": "en",
      "text": "80 cents an hour",
      "offset": 3365.22,
      "duration": 6.619
    },
    {
      "lang": "en",
      "text": "um Lambda Labs is often pretty good",
      "offset": 3367.619,
      "duration": 4.22
    },
    {
      "lang": "en",
      "text": "um you know it's really hard at the",
      "offset": 3374.579,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "moment to actually find",
      "offset": 3375.96,
      "duration": 4.82
    },
    {
      "lang": "en",
      "text": "um",
      "offset": 3378.66,
      "duration": 2.12
    },
    {
      "lang": "en",
      "text": "let's see pricing to actually find",
      "offset": 3382.02,
      "duration": 3.72
    },
    {
      "lang": "en",
      "text": "people that have them available so",
      "offset": 3383.88,
      "duration": 3.78
    },
    {
      "lang": "en",
      "text": "they've got lots listed here but they",
      "offset": 3385.74,
      "duration": 6.54
    },
    {
      "lang": "en",
      "text": "often have nine or very few available",
      "offset": 3387.66,
      "duration": 6.419
    },
    {
      "lang": "en",
      "text": "um there's also something pretty",
      "offset": 3392.28,
      "duration": 4.38
    },
    {
      "lang": "en",
      "text": "interesting called Fast AI",
      "offset": 3394.079,
      "duration": 6.661
    },
    {
      "lang": "en",
      "text": "which basically lets you use",
      "offset": 3396.66,
      "duration": 4.74
    },
    {
      "lang": "en",
      "text": "um",
      "offset": 3400.74,
      "duration": 2.7
    },
    {
      "lang": "en",
      "text": "other people's",
      "offset": 3401.4,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "computers when they're not using them",
      "offset": 3403.44,
      "duration": 5.82
    },
    {
      "lang": "en",
      "text": "and as you can see",
      "offset": 3406.04,
      "duration": 7.44
    },
    {
      "lang": "en",
      "text": "you know they tend to be much cheaper",
      "offset": 3409.26,
      "duration": 4.22
    },
    {
      "lang": "en",
      "text": "than other folks",
      "offset": 3413.52,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "and they they tend to have better",
      "offset": 3415.2,
      "duration": 3.78
    },
    {
      "lang": "en",
      "text": "availability as well but of course for",
      "offset": 3416.88,
      "duration": 3.3
    },
    {
      "lang": "en",
      "text": "sensitive stuff you don't want to be",
      "offset": 3418.98,
      "duration": 3.359
    },
    {
      "lang": "en",
      "text": "running it on some randos computer so",
      "offset": 3420.18,
      "duration": 3.72
    },
    {
      "lang": "en",
      "text": "anyway so there's a few options for",
      "offset": 3422.339,
      "duration": 3.361
    },
    {
      "lang": "en",
      "text": "renting stuff",
      "offset": 3423.9,
      "duration": 3.48
    },
    {
      "lang": "en",
      "text": "um you know I think it's if you can it's",
      "offset": 3425.7,
      "duration": 3.359
    },
    {
      "lang": "en",
      "text": "worth buying something and definitely",
      "offset": 3427.38,
      "duration": 4.02
    },
    {
      "lang": "en",
      "text": "the one to buy at the moment is the GTX",
      "offset": 3429.059,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "3090 used",
      "offset": 3431.4,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "you can generally get them from eBay for",
      "offset": 3433.46,
      "duration": 5.74
    },
    {
      "lang": "en",
      "text": "like 700 bucks or so",
      "offset": 3436.2,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "um a 40 90 isn't really better for",
      "offset": 3439.2,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "language models even though it's a newer",
      "offset": 3442.2,
      "duration": 5.159
    },
    {
      "lang": "en",
      "text": "GPU the reason for that is that language",
      "offset": 3444.72,
      "duration": 5.94
    },
    {
      "lang": "en",
      "text": "models are all about memory speed how",
      "offset": 3447.359,
      "duration": 4.801
    },
    {
      "lang": "en",
      "text": "quickly can you get in and stuff in and",
      "offset": 3450.66,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "out of memory rather than how fast is",
      "offset": 3452.16,
      "duration": 3.24
    },
    {
      "lang": "en",
      "text": "the processor and that hasn't really",
      "offset": 3453.78,
      "duration": 3.319
    },
    {
      "lang": "en",
      "text": "improved a whole lot",
      "offset": 3455.4,
      "duration": 5.459
    },
    {
      "lang": "en",
      "text": "so the two thousand bucks hmm the other",
      "offset": 3457.099,
      "duration": 5.381
    },
    {
      "lang": "en",
      "text": "thing as well as memory speed is memory",
      "offset": 3460.859,
      "duration": 2.7
    },
    {
      "lang": "en",
      "text": "size",
      "offset": 3462.48,
      "duration": 4.2
    },
    {
      "lang": "en",
      "text": "24 gigs it doesn't quite cut it for a",
      "offset": 3463.559,
      "duration": 4.441
    },
    {
      "lang": "en",
      "text": "lot of things so you'd probably want to",
      "offset": 3466.68,
      "duration": 3.899
    },
    {
      "lang": "en",
      "text": "get two of these gpus so you're talking",
      "offset": 3468,
      "duration": 5.579
    },
    {
      "lang": "en",
      "text": "like fifteen hundred dollars or so",
      "offset": 3470.579,
      "duration": 7.381
    },
    {
      "lang": "en",
      "text": "um or you can get a 48 gig ram GPU it's",
      "offset": 3473.579,
      "duration": 7.561
    },
    {
      "lang": "en",
      "text": "called an a6000 but this is going to",
      "offset": 3477.96,
      "duration": 5.359
    },
    {
      "lang": "en",
      "text": "cost you more like five grand",
      "offset": 3481.14,
      "duration": 5.699
    },
    {
      "lang": "en",
      "text": "so again getting two of these is going",
      "offset": 3483.319,
      "duration": 6.161
    },
    {
      "lang": "en",
      "text": "to be a better deal and this is not",
      "offset": 3486.839,
      "duration": 5.881
    },
    {
      "lang": "en",
      "text": "going to be faster than these either",
      "offset": 3489.48,
      "duration": 4.379
    },
    {
      "lang": "en",
      "text": "um",
      "offset": 3492.72,
      "duration": 2.879
    },
    {
      "lang": "en",
      "text": "or funnily enough you could just get a",
      "offset": 3493.859,
      "duration": 3.96
    },
    {
      "lang": "en",
      "text": "Mac with a lot of ram particularly if",
      "offset": 3495.599,
      "duration": 4.46
    },
    {
      "lang": "en",
      "text": "you get an M2 Ultra",
      "offset": 3497.819,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "Max have",
      "offset": 3500.059,
      "duration": 3.401
    },
    {
      "lang": "en",
      "text": "um",
      "offset": 3502.859,
      "duration": 2.521
    },
    {
      "lang": "en",
      "text": "particularly the M2 Ultra has pretty",
      "offset": 3503.46,
      "duration": 3.78
    },
    {
      "lang": "en",
      "text": "fast memory it's still going to be way",
      "offset": 3505.38,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "slower than using an Nvidia card but",
      "offset": 3507.24,
      "duration": 4.2
    },
    {
      "lang": "en",
      "text": "it's going to be like you're going to be",
      "offset": 3510.18,
      "duration": 4.139
    },
    {
      "lang": "en",
      "text": "able to get you know like I think 192",
      "offset": 3511.44,
      "duration": 4.919
    },
    {
      "lang": "en",
      "text": "gig or something",
      "offset": 3514.319,
      "duration": 2.941
    },
    {
      "lang": "en",
      "text": "um",
      "offset": 3516.359,
      "duration": 3.5
    },
    {
      "lang": "en",
      "text": "so",
      "offset": 3517.26,
      "duration": 2.599
    },
    {
      "lang": "en",
      "text": "it's not a terrible option particularly",
      "offset": 3520.02,
      "duration": 3.48
    },
    {
      "lang": "en",
      "text": "if you're not training models you're",
      "offset": 3522.119,
      "duration": 4.021
    },
    {
      "lang": "en",
      "text": "just wanting to use other existing",
      "offset": 3523.5,
      "duration": 5.42
    },
    {
      "lang": "en",
      "text": "trained models",
      "offset": 3526.14,
      "duration": 2.78
    },
    {
      "lang": "en",
      "text": "um",
      "offset": 3530.46,
      "duration": 3.48
    },
    {
      "lang": "en",
      "text": "so anyway most people who do this stuff",
      "offset": 3531.78,
      "duration": 4.5
    },
    {
      "lang": "en",
      "text": "seriously almost everybody",
      "offset": 3533.94,
      "duration": 5.46
    },
    {
      "lang": "en",
      "text": "has in video cards",
      "offset": 3536.28,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "um",
      "offset": 3539.4,
      "duration": 2.58
    },
    {
      "lang": "en",
      "text": "so then what we're going to be using is",
      "offset": 3540.119,
      "duration": 3.72
    },
    {
      "lang": "en",
      "text": "a library called Transformers from",
      "offset": 3541.98,
      "duration": 4.379
    },
    {
      "lang": "en",
      "text": "hugging face and the reason for that is",
      "offset": 3543.839,
      "duration": 5
    },
    {
      "lang": "en",
      "text": "that basically people upload",
      "offset": 3546.359,
      "duration": 4.621
    },
    {
      "lang": "en",
      "text": "lots of pre-trained models or",
      "offset": 3548.839,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "firetrained models up to the hugging",
      "offset": 3550.98,
      "duration": 4.5
    },
    {
      "lang": "en",
      "text": "face Hub and in fact there's even a",
      "offset": 3553.559,
      "duration": 5.341
    },
    {
      "lang": "en",
      "text": "leaderboard where you can see which are",
      "offset": 3555.48,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "the best models",
      "offset": 3558.9,
      "duration": 7.62
    },
    {
      "lang": "en",
      "text": "now this is a really uh",
      "offset": 3560.76,
      "duration": 8.339
    },
    {
      "lang": "en",
      "text": "fraud area so at the moment this one is",
      "offset": 3566.52,
      "duration": 4.38
    },
    {
      "lang": "en",
      "text": "meant to be the best model it has the",
      "offset": 3569.099,
      "duration": 3.301
    },
    {
      "lang": "en",
      "text": "highest average score",
      "offset": 3570.9,
      "duration": 3.78
    },
    {
      "lang": "en",
      "text": "and maybe it is good I haven't actually",
      "offset": 3572.4,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "used this particular model",
      "offset": 3574.68,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "um or maybe it's not I actually have no",
      "offset": 3576.96,
      "duration": 4.5
    },
    {
      "lang": "en",
      "text": "idea because the problem is",
      "offset": 3579.72,
      "duration": 6.3
    },
    {
      "lang": "en",
      "text": "these metrics are not particularly well",
      "offset": 3581.46,
      "duration": 7.8
    },
    {
      "lang": "en",
      "text": "aligned with real life usage",
      "offset": 3586.02,
      "duration": 3.96
    },
    {
      "lang": "en",
      "text": "um",
      "offset": 3589.26,
      "duration": 2.4
    },
    {
      "lang": "en",
      "text": "for all kinds of reasons and also",
      "offset": 3589.98,
      "duration": 3.18
    },
    {
      "lang": "en",
      "text": "sometimes you get something called",
      "offset": 3591.66,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "leakage which means that sometimes some",
      "offset": 3593.16,
      "duration": 4.62
    },
    {
      "lang": "en",
      "text": "of the questions from these things",
      "offset": 3595.5,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "actually leaks through to some of the",
      "offset": 3597.78,
      "duration": 3.14
    },
    {
      "lang": "en",
      "text": "training sets",
      "offset": 3599.339,
      "duration": 5.341
    },
    {
      "lang": "en",
      "text": "so you can get as a rule of thumb what",
      "offset": 3600.92,
      "duration": 5.199
    },
    {
      "lang": "en",
      "text": "to use from here but you should always",
      "offset": 3604.68,
      "duration": 3.179
    },
    {
      "lang": "en",
      "text": "try things",
      "offset": 3606.119,
      "duration": 2.641
    },
    {
      "lang": "en",
      "text": "um",
      "offset": 3607.859,
      "duration": 3.181
    },
    {
      "lang": "en",
      "text": "and you can also say you know these ones",
      "offset": 3608.76,
      "duration": 4.92
    },
    {
      "lang": "en",
      "text": "are all the 70b here that tells you how",
      "offset": 3611.04,
      "duration": 4.38
    },
    {
      "lang": "en",
      "text": "big it is so this is a 70 billion",
      "offset": 3613.68,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "parameter model",
      "offset": 3615.42,
      "duration": 2.659
    },
    {
      "lang": "en",
      "text": "um",
      "offset": 3618.299,
      "duration": 4.26
    },
    {
      "lang": "en",
      "text": "so generally speaking for the kinds of",
      "offset": 3618.9,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "gpus you we're talking about you'll be",
      "offset": 3622.559,
      "duration": 4.861
    },
    {
      "lang": "en",
      "text": "wanting no bigger than 13B and quite",
      "offset": 3624.9,
      "duration": 4.38
    },
    {
      "lang": "en",
      "text": "often 7B",
      "offset": 3627.42,
      "duration": 2.939
    },
    {
      "lang": "en",
      "text": "um",
      "offset": 3629.28,
      "duration": 2.819
    },
    {
      "lang": "en",
      "text": "so",
      "offset": 3630.359,
      "duration": 4.141
    },
    {
      "lang": "en",
      "text": "let's see if we've confined here the 13B",
      "offset": 3632.099,
      "duration": 5.421
    },
    {
      "lang": "en",
      "text": "model for example",
      "offset": 3634.5,
      "duration": 3.02
    },
    {
      "lang": "en",
      "text": "um all right so you can find models to",
      "offset": 3637.559,
      "duration": 4.26
    },
    {
      "lang": "en",
      "text": "try out from things like this",
      "offset": 3639.96,
      "duration": 3.96
    },
    {
      "lang": "en",
      "text": "leaderboard",
      "offset": 3641.819,
      "duration": 4.02
    },
    {
      "lang": "en",
      "text": "um and there's also a really great",
      "offset": 3643.92,
      "duration": 3.78
    },
    {
      "lang": "en",
      "text": "leaderboard called fast eval which I",
      "offset": 3645.839,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "like a lot because it focuses on some",
      "offset": 3647.7,
      "duration": 7.379
    },
    {
      "lang": "en",
      "text": "more sophisticated evaluation methods",
      "offset": 3651.359,
      "duration": 5.94
    },
    {
      "lang": "en",
      "text": "such as this Chain of Thought evaluation",
      "offset": 3655.079,
      "duration": 5.701
    },
    {
      "lang": "en",
      "text": "method so I kind of trust these a little",
      "offset": 3657.299,
      "duration": 7.5
    },
    {
      "lang": "en",
      "text": "bit more and these are also GSM 8K is a",
      "offset": 3660.78,
      "duration": 5.88
    },
    {
      "lang": "en",
      "text": "difficult math benchmark",
      "offset": 3664.799,
      "duration": 4.26
    },
    {
      "lang": "en",
      "text": "uh big bench hard",
      "offset": 3666.66,
      "duration": 6.06
    },
    {
      "lang": "en",
      "text": "um so forth so yeah so you know stable",
      "offset": 3669.059,
      "duration": 7.621
    },
    {
      "lang": "en",
      "text": "Beluga 2 Wizard math 13B dolphin Lima",
      "offset": 3672.72,
      "duration": 6.54
    },
    {
      "lang": "en",
      "text": "13B et cetera these would all be good",
      "offset": 3676.68,
      "duration": 5.24
    },
    {
      "lang": "en",
      "text": "options",
      "offset": 3679.26,
      "duration": 2.66
    },
    {
      "lang": "en",
      "text": "um yeah so you need to pick a model and",
      "offset": 3683.04,
      "duration": 4.98
    },
    {
      "lang": "en",
      "text": "at the moment nearly all the good models",
      "offset": 3685.559,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "are based on metas",
      "offset": 3688.02,
      "duration": 5.279
    },
    {
      "lang": "en",
      "text": "llama too so when I say based on what",
      "offset": 3690.599,
      "duration": 5.821
    },
    {
      "lang": "en",
      "text": "does that mean well what that means is",
      "offset": 3693.299,
      "duration": 8.341
    },
    {
      "lang": "en",
      "text": "this model here llama 2 7B so it's a",
      "offset": 3696.42,
      "duration": 6.84
    },
    {
      "lang": "en",
      "text": "llama model that's that's just the name",
      "offset": 3701.64,
      "duration": 3.479
    },
    {
      "lang": "en",
      "text": "meta called it this is their version two",
      "offset": 3703.26,
      "duration": 4.26
    },
    {
      "lang": "en",
      "text": "of llama this is their seven billion",
      "offset": 3705.119,
      "duration": 4.381
    },
    {
      "lang": "en",
      "text": "size one it's the smallest one that they",
      "offset": 3707.52,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "make and specifically these weights have",
      "offset": 3709.5,
      "duration": 4.44
    },
    {
      "lang": "en",
      "text": "been created for hugging face so you can",
      "offset": 3711.839,
      "duration": 2.941
    },
    {
      "lang": "en",
      "text": "load it with the hugging face",
      "offset": 3713.94,
      "duration": 2.04
    },
    {
      "lang": "en",
      "text": "Transformers",
      "offset": 3714.78,
      "duration": 4.799
    },
    {
      "lang": "en",
      "text": "and this model has only got As far as",
      "offset": 3715.98,
      "duration": 5.46
    },
    {
      "lang": "en",
      "text": "here it's done the language model of",
      "offset": 3719.579,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "pre-trading it's done none of the",
      "offset": 3721.44,
      "duration": 6.54
    },
    {
      "lang": "en",
      "text": "instruction tuning and none of the rlhf",
      "offset": 3723.42,
      "duration": 5.46
    },
    {
      "lang": "en",
      "text": "um",
      "offset": 3727.98,
      "duration": 3.3
    },
    {
      "lang": "en",
      "text": "so we would need to fine tune it to",
      "offset": 3728.88,
      "duration": 5.419
    },
    {
      "lang": "en",
      "text": "really get it to do much useful",
      "offset": 3731.28,
      "duration": 7.019
    },
    {
      "lang": "en",
      "text": "so we can just say Okay create a",
      "offset": 3734.299,
      "duration": 5.981
    },
    {
      "lang": "en",
      "text": "automatically create the appropriate",
      "offset": 3738.299,
      "duration": 2.76
    },
    {
      "lang": "en",
      "text": "model",
      "offset": 3740.28,
      "duration": 3.779
    },
    {
      "lang": "en",
      "text": "for language models so cause or LM is",
      "offset": 3741.059,
      "duration": 5.221
    },
    {
      "lang": "en",
      "text": "basically refers to that ULM fit stage",
      "offset": 3744.059,
      "duration": 3.381
    },
    {
      "lang": "en",
      "text": "one process",
      "offset": 3746.28,
      "duration": 4.44
    },
    {
      "lang": "en",
      "text": "or stage two in fact so we've got the",
      "offset": 3747.44,
      "duration": 5.56
    },
    {
      "lang": "en",
      "text": "pre-trained model from this name metal",
      "offset": 3750.72,
      "duration": 5.579
    },
    {
      "lang": "en",
      "text": "alarm element two blah blah okay",
      "offset": 3753,
      "duration": 5.099
    },
    {
      "lang": "en",
      "text": "now",
      "offset": 3756.299,
      "duration": 3
    },
    {
      "lang": "en",
      "text": "um",
      "offset": 3758.099,
      "duration": 4.52
    },
    {
      "lang": "en",
      "text": "generally speaking we use",
      "offset": 3759.299,
      "duration": 7.82
    },
    {
      "lang": "en",
      "text": "16-bit floating Point numbers nowadays",
      "offset": 3762.619,
      "duration": 7.24
    },
    {
      "lang": "en",
      "text": "but if you think about it",
      "offset": 3767.119,
      "duration": 7.361
    },
    {
      "lang": "en",
      "text": "16 bit is two bytes so 7B times two it's",
      "offset": 3769.859,
      "duration": 7.641
    },
    {
      "lang": "en",
      "text": "going to be 14 gigabytes",
      "offset": 3774.48,
      "duration": 6.9
    },
    {
      "lang": "en",
      "text": "just to load in the weights so you've",
      "offset": 3777.5,
      "duration": 6.46
    },
    {
      "lang": "en",
      "text": "got to have a decent model to be able to",
      "offset": 3781.38,
      "duration": 3.679
    },
    {
      "lang": "en",
      "text": "do that",
      "offset": 3783.96,
      "duration": 3.899
    },
    {
      "lang": "en",
      "text": "perhaps surprisingly you can actually",
      "offset": 3785.059,
      "duration": 5.74
    },
    {
      "lang": "en",
      "text": "just cast it to 8-bit and it still works",
      "offset": 3787.859,
      "duration": 4.2
    },
    {
      "lang": "en",
      "text": "pretty well thanks to something called",
      "offset": 3790.799,
      "duration": 3.181
    },
    {
      "lang": "en",
      "text": "discretization",
      "offset": 3792.059,
      "duration": 5.881
    },
    {
      "lang": "en",
      "text": "so let's try that so remember this is",
      "offset": 3793.98,
      "duration": 5.22
    },
    {
      "lang": "en",
      "text": "just a language model looking only",
      "offset": 3797.94,
      "duration": 3.06
    },
    {
      "lang": "en",
      "text": "complete sentences we can't ask it a",
      "offset": 3799.2,
      "duration": 3.78
    },
    {
      "lang": "en",
      "text": "question and expect a great answer so",
      "offset": 3801,
      "duration": 3.059
    },
    {
      "lang": "en",
      "text": "let's just give it the start of a",
      "offset": 3802.98,
      "duration": 3.42
    },
    {
      "lang": "en",
      "text": "sentence Jeremy how it is a",
      "offset": 3804.059,
      "duration": 4.621
    },
    {
      "lang": "en",
      "text": "and so we need the right tokenizer so",
      "offset": 3806.4,
      "duration": 3.54
    },
    {
      "lang": "en",
      "text": "this will automatically create the right",
      "offset": 3808.68,
      "duration": 3.3
    },
    {
      "lang": "en",
      "text": "kind of tokenizer for this model",
      "offset": 3809.94,
      "duration": 6.359
    },
    {
      "lang": "en",
      "text": "we can grab the tokens as Pi torch",
      "offset": 3811.98,
      "duration": 7.099
    },
    {
      "lang": "en",
      "text": "here they are",
      "offset": 3816.299,
      "duration": 2.78
    },
    {
      "lang": "en",
      "text": "and",
      "offset": 3820.68,
      "duration": 3.96
    },
    {
      "lang": "en",
      "text": "just to confirm if we decode them back",
      "offset": 3822.839,
      "duration": 3.541
    },
    {
      "lang": "en",
      "text": "again we get back the original plus a",
      "offset": 3824.64,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "special token to say this is the start",
      "offset": 3826.38,
      "duration": 3.54
    },
    {
      "lang": "en",
      "text": "of a document",
      "offset": 3828.24,
      "duration": 5.16
    },
    {
      "lang": "en",
      "text": "and so we can now call generate so",
      "offset": 3829.92,
      "duration": 4.86
    },
    {
      "lang": "en",
      "text": "generate",
      "offset": 3833.4,
      "duration": 3.24
    },
    {
      "lang": "en",
      "text": "will",
      "offset": 3834.78,
      "duration": 4.98
    },
    {
      "lang": "en",
      "text": "um Auto regressively so call the model",
      "offset": 3836.64,
      "duration": 5.459
    },
    {
      "lang": "en",
      "text": "again and again passing its previous",
      "offset": 3839.76,
      "duration": 5.24
    },
    {
      "lang": "en",
      "text": "result back as the next",
      "offset": 3842.099,
      "duration": 5.48
    },
    {
      "lang": "en",
      "text": "as the next input",
      "offset": 3845,
      "duration": 5.74
    },
    {
      "lang": "en",
      "text": "and I'm just going to do that 15 times",
      "offset": 3847.579,
      "duration": 5.201
    },
    {
      "lang": "en",
      "text": "so this is you can you can write this",
      "offset": 3850.74,
      "duration": 3.48
    },
    {
      "lang": "en",
      "text": "for Loop yourself this isn't doing",
      "offset": 3852.78,
      "duration": 3.24
    },
    {
      "lang": "en",
      "text": "anything fancy in fact I would recommend",
      "offset": 3854.22,
      "duration": 4.5
    },
    {
      "lang": "en",
      "text": "writing this yourself to make sure that",
      "offset": 3856.02,
      "duration": 6.02
    },
    {
      "lang": "en",
      "text": "you know how that it all works okay",
      "offset": 3858.72,
      "duration": 3.32
    },
    {
      "lang": "en",
      "text": "um",
      "offset": 3862.859,
      "duration": 3.48
    },
    {
      "lang": "en",
      "text": "we have to put those tokens on the GPU",
      "offset": 3863.94,
      "duration": 4.02
    },
    {
      "lang": "en",
      "text": "and at the end I recommend putting them",
      "offset": 3866.339,
      "duration": 3.661
    },
    {
      "lang": "en",
      "text": "back onto the CPU the result and here",
      "offset": 3867.96,
      "duration": 3.42
    },
    {
      "lang": "en",
      "text": "are the tokens",
      "offset": 3870,
      "duration": 3.18
    },
    {
      "lang": "en",
      "text": "not very interesting so we have to",
      "offset": 3871.38,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "decode them using the tokenizer and so",
      "offset": 3873.18,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "the first 25 sorry first 15 tokens are",
      "offset": 3875.94,
      "duration": 4.98
    },
    {
      "lang": "en",
      "text": "Jeremy Howard is a 28 year old",
      "offset": 3878.46,
      "duration": 4.139
    },
    {
      "lang": "en",
      "text": "Australian AI researcher and",
      "offset": 3880.92,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "entrepreneur okay well 28 years old is",
      "offset": 3882.599,
      "duration": 4.26
    },
    {
      "lang": "en",
      "text": "not exactly correct but we'll call it",
      "offset": 3885,
      "duration": 4.02
    },
    {
      "lang": "en",
      "text": "close enough I like that thank you very",
      "offset": 3886.859,
      "duration": 3
    },
    {
      "lang": "en",
      "text": "much",
      "offset": 3889.02,
      "duration": 4.5
    },
    {
      "lang": "en",
      "text": "llama 7B So Okay so we've got a language",
      "offset": 3889.859,
      "duration": 6.5
    },
    {
      "lang": "en",
      "text": "model completing sentences",
      "offset": 3893.52,
      "duration": 5.64
    },
    {
      "lang": "en",
      "text": "it took",
      "offset": 3896.359,
      "duration": 5.22
    },
    {
      "lang": "en",
      "text": "one in the third seconds",
      "offset": 3899.16,
      "duration": 4.86
    },
    {
      "lang": "en",
      "text": "and that's a bit slower than it could be",
      "offset": 3901.579,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "because we used 8-bit",
      "offset": 3904.02,
      "duration": 4.38
    },
    {
      "lang": "en",
      "text": "if we use 16 bit there's a special thing",
      "offset": 3906.059,
      "duration": 5.341
    },
    {
      "lang": "en",
      "text": "called B float 16 which is a really",
      "offset": 3908.4,
      "duration": 5.58
    },
    {
      "lang": "en",
      "text": "great 16-bit floating Point format",
      "offset": 3911.4,
      "duration": 5.34
    },
    {
      "lang": "en",
      "text": "that's used usable on any somewhat",
      "offset": 3913.98,
      "duration": 5.819
    },
    {
      "lang": "en",
      "text": "recent GPS Nvidia GPU now if we use it",
      "offset": 3916.74,
      "duration": 5.579
    },
    {
      "lang": "en",
      "text": "it's going to take twice as much RAM as",
      "offset": 3919.799,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "we discussed",
      "offset": 3922.319,
      "duration": 3.54
    },
    {
      "lang": "en",
      "text": "but look at the time",
      "offset": 3923.64,
      "duration": 6.14
    },
    {
      "lang": "en",
      "text": "it's come down to 390 milliseconds",
      "offset": 3925.859,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "um",
      "offset": 3929.819,
      "duration": 3.24
    },
    {
      "lang": "en",
      "text": "now there is a better option still than",
      "offset": 3930.599,
      "duration": 3.96
    },
    {
      "lang": "en",
      "text": "even that",
      "offset": 3933.059,
      "duration": 3.06
    },
    {
      "lang": "en",
      "text": "there's a different kind of",
      "offset": 3934.559,
      "duration": 4.441
    },
    {
      "lang": "en",
      "text": "discretization called gptq",
      "offset": 3936.119,
      "duration": 7.5
    },
    {
      "lang": "en",
      "text": "where a model is carefully optimized to",
      "offset": 3939,
      "duration": 8.28
    },
    {
      "lang": "en",
      "text": "work with uh four or eight or other you",
      "offset": 3943.619,
      "duration": 7.801
    },
    {
      "lang": "en",
      "text": "know lower Precision data automatically",
      "offset": 3947.28,
      "duration": 6.42
    },
    {
      "lang": "en",
      "text": "and",
      "offset": 3951.42,
      "duration": 3.24
    },
    {
      "lang": "en",
      "text": "um",
      "offset": 3953.7,
      "duration": 2.7
    },
    {
      "lang": "en",
      "text": "this particular person known as the",
      "offset": 3954.66,
      "duration": 5.159
    },
    {
      "lang": "en",
      "text": "bloke is fantastic at taking popular",
      "offset": 3956.4,
      "duration": 6.3
    },
    {
      "lang": "en",
      "text": "models running that optimization process",
      "offset": 3959.819,
      "duration": 4.98
    },
    {
      "lang": "en",
      "text": "and then uploading the results back to",
      "offset": 3962.7,
      "duration": 4.26
    },
    {
      "lang": "en",
      "text": "hacking face",
      "offset": 3964.799,
      "duration": 6.56
    },
    {
      "lang": "en",
      "text": "so we can use this gptq version",
      "offset": 3966.96,
      "duration": 7.26
    },
    {
      "lang": "en",
      "text": "and internally this is actually going to",
      "offset": 3971.359,
      "duration": 4.421
    },
    {
      "lang": "en",
      "text": "use I'm not sure exactly how many bits",
      "offset": 3974.22,
      "duration": 2.639
    },
    {
      "lang": "en",
      "text": "this particular one is I think it's",
      "offset": 3975.78,
      "duration": 3.059
    },
    {
      "lang": "en",
      "text": "probably going to be four bits",
      "offset": 3976.859,
      "duration": 4.801
    },
    {
      "lang": "en",
      "text": "but it's going to be much more optimized",
      "offset": 3978.839,
      "duration": 5.401
    },
    {
      "lang": "en",
      "text": "um and so look at this 270 milliseconds",
      "offset": 3981.66,
      "duration": 4.919
    },
    {
      "lang": "en",
      "text": "it's actually faster",
      "offset": 3984.24,
      "duration": 3.9
    },
    {
      "lang": "en",
      "text": "than",
      "offset": 3986.579,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "16 bit even though internally it's",
      "offset": 3988.14,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "actually casting it up to 16 bit each",
      "offset": 3990.9,
      "duration": 3.48
    },
    {
      "lang": "en",
      "text": "layer to do it",
      "offset": 3992.94,
      "duration": 2.94
    },
    {
      "lang": "en",
      "text": "and that's because there's a lot less",
      "offset": 3994.38,
      "duration": 3.78
    },
    {
      "lang": "en",
      "text": "memory moving around",
      "offset": 3995.88,
      "duration": 4.26
    },
    {
      "lang": "en",
      "text": "and to confirm",
      "offset": 3998.16,
      "duration": 3.78
    },
    {
      "lang": "en",
      "text": "in fact what we could even do now is we",
      "offset": 4000.14,
      "duration": 5
    },
    {
      "lang": "en",
      "text": "go up to 13B easy and in fact it's still",
      "offset": 4001.94,
      "duration": 6.359
    },
    {
      "lang": "en",
      "text": "faster than the 7B now that we're using",
      "offset": 4005.14,
      "duration": 4.959
    },
    {
      "lang": "en",
      "text": "the gptq version so this is a really",
      "offset": 4008.299,
      "duration": 4.141
    },
    {
      "lang": "en",
      "text": "helpful tip",
      "offset": 4010.099,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "so let's put all those things together",
      "offset": 4012.44,
      "duration": 3.78
    },
    {
      "lang": "en",
      "text": "the tokenizer the generate the batch",
      "offset": 4014.18,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "decode we'll call this gen for Generate",
      "offset": 4016.22,
      "duration": 5.099
    },
    {
      "lang": "en",
      "text": "and so we can now use the 13B GPT key",
      "offset": 4018.26,
      "duration": 4.92
    },
    {
      "lang": "en",
      "text": "model",
      "offset": 4021.319,
      "duration": 4.681
    },
    {
      "lang": "en",
      "text": "and let's try this Jeremy Howard is a so",
      "offset": 4023.18,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "it's got to 50 tokens so fast 16-year",
      "offset": 4026,
      "duration": 4.859
    },
    {
      "lang": "en",
      "text": "veteran of Silicon Valley co-founder of",
      "offset": 4028.94,
      "duration": 3.899
    },
    {
      "lang": "en",
      "text": "cargo a Marketplace or predictive model",
      "offset": 4030.859,
      "duration": 4.561
    },
    {
      "lang": "en",
      "text": "here's company kaggle.com has become the",
      "offset": 4032.839,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "data science competitions what I don't",
      "offset": 4035.42,
      "duration": 3.06
    },
    {
      "lang": "en",
      "text": "know I was going to say but anyway it's",
      "offset": 4037.16,
      "duration": 3.3
    },
    {
      "lang": "en",
      "text": "on the right track I was actually there",
      "offset": 4038.48,
      "duration": 6.319
    },
    {
      "lang": "en",
      "text": "for 10 years not 16 but that's all right",
      "offset": 4040.46,
      "duration": 4.339
    },
    {
      "lang": "en",
      "text": "um",
      "offset": 4044.9,
      "duration": 3.419
    },
    {
      "lang": "en",
      "text": "okay so this is looking good",
      "offset": 4045.5,
      "duration": 4.26
    },
    {
      "lang": "en",
      "text": "um",
      "offset": 4048.319,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "but probably a lot of the time we're",
      "offset": 4049.76,
      "duration": 4.62
    },
    {
      "lang": "en",
      "text": "going to be interested in you know",
      "offset": 4051.92,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "asking questions or using instructions",
      "offset": 4054.38,
      "duration": 4.38
    },
    {
      "lang": "en",
      "text": "so stability AI has this nice series",
      "offset": 4056.24,
      "duration": 4.859
    },
    {
      "lang": "en",
      "text": "called stable Beluga including a small",
      "offset": 4058.76,
      "duration": 5.339
    },
    {
      "lang": "en",
      "text": "7B one and other bigger ones",
      "offset": 4061.099,
      "duration": 5.46
    },
    {
      "lang": "en",
      "text": "and these are all based on llama2 but",
      "offset": 4064.099,
      "duration": 5.041
    },
    {
      "lang": "en",
      "text": "these have been instruction tuned they",
      "offset": 4066.559,
      "duration": 4.201
    },
    {
      "lang": "en",
      "text": "might even have been RL hdf but I can't",
      "offset": 4069.14,
      "duration": 3
    },
    {
      "lang": "en",
      "text": "remember now",
      "offset": 4070.76,
      "duration": 2.039
    },
    {
      "lang": "en",
      "text": "um",
      "offset": 4072.14,
      "duration": 4.74
    },
    {
      "lang": "en",
      "text": "so we can create a stable Beluga model",
      "offset": 4072.799,
      "duration": 7.201
    },
    {
      "lang": "en",
      "text": "and now something really important",
      "offset": 4076.88,
      "duration": 5.64
    },
    {
      "lang": "en",
      "text": "that I keep forgetting everybody keeps",
      "offset": 4080,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "forgetting is",
      "offset": 4082.52,
      "duration": 7.039
    },
    {
      "lang": "en",
      "text": "during the instruction tuning process",
      "offset": 4084.319,
      "duration": 5.24
    },
    {
      "lang": "en",
      "text": "during the instruction tuning process",
      "offset": 4092.059,
      "duration": 6.601
    },
    {
      "lang": "en",
      "text": "the instructions that are",
      "offset": 4095.059,
      "duration": 7.981
    },
    {
      "lang": "en",
      "text": "passed in actually uh",
      "offset": 4098.66,
      "duration": 5
    },
    {
      "lang": "en",
      "text": "um",
      "offset": 4103.04,
      "duration": 3.54
    },
    {
      "lang": "en",
      "text": "they don't just appear like this they",
      "offset": 4103.66,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "actually always are in a particular",
      "offset": 4106.58,
      "duration": 3.96
    },
    {
      "lang": "en",
      "text": "format and the format Believe It or Not",
      "offset": 4108.14,
      "duration": 5.88
    },
    {
      "lang": "en",
      "text": "changes quite a bit from from fine tune",
      "offset": 4110.54,
      "duration": 6.299
    },
    {
      "lang": "en",
      "text": "to fine tune and so you have to go to",
      "offset": 4114.02,
      "duration": 5.1
    },
    {
      "lang": "en",
      "text": "the web page",
      "offset": 4116.839,
      "duration": 5.101
    },
    {
      "lang": "en",
      "text": "for the model",
      "offset": 4119.12,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "and scroll down to found out",
      "offset": 4121.94,
      "duration": 5.279
    },
    {
      "lang": "en",
      "text": "what the prompt format is",
      "offset": 4124.88,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "so here's the prompt format so I",
      "offset": 4127.219,
      "duration": 3.421
    },
    {
      "lang": "en",
      "text": "generally just copy it",
      "offset": 4128.96,
      "duration": 5.779
    },
    {
      "lang": "en",
      "text": "and then I paste it into python",
      "offset": 4130.64,
      "duration": 4.099
    },
    {
      "lang": "en",
      "text": "which I did here",
      "offset": 4134.9,
      "duration": 2.839
    },
    {
      "lang": "en",
      "text": "and",
      "offset": 4138.199,
      "duration": 5.221
    },
    {
      "lang": "en",
      "text": "created a function called make prompt",
      "offset": 4140,
      "duration": 7.259
    },
    {
      "lang": "en",
      "text": "that used the exact same format that it",
      "offset": 4143.42,
      "duration": 6.66
    },
    {
      "lang": "en",
      "text": "said to use and so now if I want to say",
      "offset": 4147.259,
      "duration": 5.701
    },
    {
      "lang": "en",
      "text": "who is Jeremy Howard I can call Jen",
      "offset": 4150.08,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "again that was that function I created",
      "offset": 4152.96,
      "duration": 3
    },
    {
      "lang": "en",
      "text": "up here",
      "offset": 4154.64,
      "duration": 4.44
    },
    {
      "lang": "en",
      "text": "and make the correct prompt from that",
      "offset": 4155.96,
      "duration": 4.44
    },
    {
      "lang": "en",
      "text": "question",
      "offset": 4159.08,
      "duration": 3.659
    },
    {
      "lang": "en",
      "text": "and then it returns back okay so you can",
      "offset": 4160.4,
      "duration": 3.54
    },
    {
      "lang": "en",
      "text": "see here",
      "offset": 4162.739,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "or this prefix this is a system",
      "offset": 4163.94,
      "duration": 3.359
    },
    {
      "lang": "en",
      "text": "instruction",
      "offset": 4165.859,
      "duration": 3.48
    },
    {
      "lang": "en",
      "text": "this is my question and then the",
      "offset": 4167.299,
      "duration": 4.201
    },
    {
      "lang": "en",
      "text": "assistant says Jeremy Howard's an",
      "offset": 4169.339,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "Australian entrepreneur computer",
      "offset": 4171.5,
      "duration": 3.42
    },
    {
      "lang": "en",
      "text": "scientist co-founder of machine learning",
      "offset": 4172.699,
      "duration": 4.62
    },
    {
      "lang": "en",
      "text": "and deep Learning Company faster AI okay",
      "offset": 4174.92,
      "duration": 4.439
    },
    {
      "lang": "en",
      "text": "so this one's actually all correct so",
      "offset": 4177.319,
      "duration": 4.801
    },
    {
      "lang": "en",
      "text": "it's getting better by using an actual",
      "offset": 4179.359,
      "duration": 5.701
    },
    {
      "lang": "en",
      "text": "instruction tune model",
      "offset": 4182.12,
      "duration": 3.9
    },
    {
      "lang": "en",
      "text": "um",
      "offset": 4185.06,
      "duration": 3.06
    },
    {
      "lang": "en",
      "text": "and so we could then start to scale up",
      "offset": 4186.02,
      "duration": 6.48
    },
    {
      "lang": "en",
      "text": "so we could use the 13B and in fact uh",
      "offset": 4188.12,
      "duration": 6.599
    },
    {
      "lang": "en",
      "text": "we looked briefly at this open Orca data",
      "offset": 4192.5,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "set earlier so llama2 has been",
      "offset": 4194.719,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "fine-tuned on Oakman Orca and then also",
      "offset": 4197.54,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "fine-tuned on another really great data",
      "offset": 4200.719,
      "duration": 5.161
    },
    {
      "lang": "en",
      "text": "set called platypus and so the whole",
      "offset": 4202.58,
      "duration": 6.42
    },
    {
      "lang": "en",
      "text": "thing together is the open Orca platypus",
      "offset": 4205.88,
      "duration": 4.68
    },
    {
      "lang": "en",
      "text": "and then this is going to be the bigger",
      "offset": 4209,
      "duration": 2.58
    },
    {
      "lang": "en",
      "text": "13B",
      "offset": 4210.56,
      "duration": 4.86
    },
    {
      "lang": "en",
      "text": "gptq means it's going to be quantized",
      "offset": 4211.58,
      "duration": 7.32
    },
    {
      "lang": "en",
      "text": "so that's got a different format okay a",
      "offset": 4215.42,
      "duration": 5.64
    },
    {
      "lang": "en",
      "text": "different prompt format so again we can",
      "offset": 4218.9,
      "duration": 4.44
    },
    {
      "lang": "en",
      "text": "scroll down and see what the prompt",
      "offset": 4221.06,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "format is there it is",
      "offset": 4223.34,
      "duration": 6.72
    },
    {
      "lang": "en",
      "text": "okay and so",
      "offset": 4226.1,
      "duration": 6.059
    },
    {
      "lang": "en",
      "text": "we can create a function called make",
      "offset": 4230.06,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "open Orca prompt that has that prompt",
      "offset": 4232.159,
      "duration": 4.881
    },
    {
      "lang": "en",
      "text": "format",
      "offset": 4234.62,
      "duration": 2.42
    },
    {
      "lang": "en",
      "text": "and so now we can say okay who is Jeremy",
      "offset": 4237.26,
      "duration": 4.5
    },
    {
      "lang": "en",
      "text": "Howard and now I've become British which",
      "offset": 4239.659,
      "duration": 3.301
    },
    {
      "lang": "en",
      "text": "is kind of true I was born in England",
      "offset": 4241.76,
      "duration": 3
    },
    {
      "lang": "en",
      "text": "but I moved to Australia",
      "offset": 4242.96,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "uh professional poker player no",
      "offset": 4244.76,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "definitely not that uh co-founding",
      "offset": 4247.04,
      "duration": 3.9
    },
    {
      "lang": "en",
      "text": "several companies",
      "offset": 4249.32,
      "duration": 5.1
    },
    {
      "lang": "en",
      "text": "including first.ai also kaggle okay so",
      "offset": 4250.94,
      "duration": 5.7
    },
    {
      "lang": "en",
      "text": "not bad yeah it was acquired by Google",
      "offset": 4254.42,
      "duration": 4.2
    },
    {
      "lang": "en",
      "text": "was it 2017 probably something around",
      "offset": 4256.64,
      "duration": 6.059
    },
    {
      "lang": "en",
      "text": "there okay so you can see we've got our",
      "offset": 4258.62,
      "duration": 5.7
    },
    {
      "lang": "en",
      "text": "own models",
      "offset": 4262.699,
      "duration": 5.96
    },
    {
      "lang": "en",
      "text": "giving us some pretty good information",
      "offset": 4264.32,
      "duration": 4.339
    },
    {
      "lang": "en",
      "text": "how do we make it even better you know",
      "offset": 4269.659,
      "duration": 2.881
    },
    {
      "lang": "en",
      "text": "because it's it's it's still",
      "offset": 4271.34,
      "duration": 3.3
    },
    {
      "lang": "en",
      "text": "hallucinating",
      "offset": 4272.54,
      "duration": 3.9
    },
    {
      "lang": "en",
      "text": "you know",
      "offset": 4274.64,
      "duration": 3.78
    },
    {
      "lang": "en",
      "text": "um",
      "offset": 4276.44,
      "duration": 3.54
    },
    {
      "lang": "en",
      "text": "and",
      "offset": 4278.42,
      "duration": 4.14
    },
    {
      "lang": "en",
      "text": "you know llama two I think has been",
      "offset": 4279.98,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "trained with more up-to-date information",
      "offset": 4282.56,
      "duration": 4.02
    },
    {
      "lang": "en",
      "text": "than gpt4 it doesn't have the September",
      "offset": 4284.06,
      "duration": 5.22
    },
    {
      "lang": "en",
      "text": "2021 cut off",
      "offset": 4286.58,
      "duration": 5.639
    },
    {
      "lang": "en",
      "text": "um but it you know it's still",
      "offset": 4289.28,
      "duration": 4.68
    },
    {
      "lang": "en",
      "text": "got a knowledge cut off you know we",
      "offset": 4292.219,
      "duration": 3.241
    },
    {
      "lang": "en",
      "text": "would like to use the most up-to-date",
      "offset": 4293.96,
      "duration": 3.06
    },
    {
      "lang": "en",
      "text": "information we want to use the right",
      "offset": 4295.46,
      "duration": 3.719
    },
    {
      "lang": "en",
      "text": "information to answer these questions as",
      "offset": 4297.02,
      "duration": 4.139
    },
    {
      "lang": "en",
      "text": "well as possible",
      "offset": 4299.179,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "so to do this we can use something",
      "offset": 4301.159,
      "duration": 5.161
    },
    {
      "lang": "en",
      "text": "called retrieval augmented generation",
      "offset": 4303.02,
      "duration": 6.54
    },
    {
      "lang": "en",
      "text": "so what happens with retrieval augmented",
      "offset": 4306.32,
      "duration": 6.12
    },
    {
      "lang": "en",
      "text": "generation is",
      "offset": 4309.56,
      "duration": 4.86
    },
    {
      "lang": "en",
      "text": "when we take the question we've been",
      "offset": 4312.44,
      "duration": 5.46
    },
    {
      "lang": "en",
      "text": "asked like who is Jeremy held and then",
      "offset": 4314.42,
      "duration": 6.38
    },
    {
      "lang": "en",
      "text": "we say okay",
      "offset": 4317.9,
      "duration": 2.9
    },
    {
      "lang": "en",
      "text": "let's try and search for",
      "offset": 4321.02,
      "duration": 4.92
    },
    {
      "lang": "en",
      "text": "documents that may help us answer that",
      "offset": 4323.78,
      "duration": 3.62
    },
    {
      "lang": "en",
      "text": "question",
      "offset": 4325.94,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "so obviously we would expect for example",
      "offset": 4327.4,
      "duration": 5.38
    },
    {
      "lang": "en",
      "text": "Wikipedia to be useful and then what we",
      "offset": 4330.02,
      "duration": 7.46
    },
    {
      "lang": "en",
      "text": "do is we say okay with that information",
      "offset": 4332.78,
      "duration": 9.18
    },
    {
      "lang": "en",
      "text": "let's now see if we can tell",
      "offset": 4337.48,
      "duration": 7.42
    },
    {
      "lang": "en",
      "text": "the language model about what we found",
      "offset": 4341.96,
      "duration": 6.5
    },
    {
      "lang": "en",
      "text": "and then have it answer the question",
      "offset": 4344.9,
      "duration": 6.42
    },
    {
      "lang": "en",
      "text": "so let me show you so let's actually",
      "offset": 4348.46,
      "duration": 5.88
    },
    {
      "lang": "en",
      "text": "grab a Wikipedia",
      "offset": 4351.32,
      "duration": 4.919
    },
    {
      "lang": "en",
      "text": "python package",
      "offset": 4354.34,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "we will scrape Wikipedia grabbing the",
      "offset": 4356.239,
      "duration": 5.94
    },
    {
      "lang": "en",
      "text": "Jeremy Howard web page",
      "offset": 4359.78,
      "duration": 4.5
    },
    {
      "lang": "en",
      "text": "and so here's the start of the Jeremy",
      "offset": 4362.179,
      "duration": 5.241
    },
    {
      "lang": "en",
      "text": "Howard Wikipedia page",
      "offset": 4364.28,
      "duration": 3.14
    },
    {
      "lang": "en",
      "text": "it has 613 words now generally speaking",
      "offset": 4368.199,
      "duration": 5.861
    },
    {
      "lang": "en",
      "text": "these open source models will have a",
      "offset": 4372.199,
      "duration": 3.661
    },
    {
      "lang": "en",
      "text": "context length of about two thousand or",
      "offset": 4374.06,
      "duration": 3.78
    },
    {
      "lang": "en",
      "text": "four thousand so the context length is",
      "offset": 4375.86,
      "duration": 4.92
    },
    {
      "lang": "en",
      "text": "how many tokens Can it handle so that's",
      "offset": 4377.84,
      "duration": 4.62
    },
    {
      "lang": "en",
      "text": "fine it'll be able to handle this web",
      "offset": 4380.78,
      "duration": 2.58
    },
    {
      "lang": "en",
      "text": "page",
      "offset": 4382.46,
      "duration": 2.34
    },
    {
      "lang": "en",
      "text": "and what we're going to do is we're",
      "offset": 4383.36,
      "duration": 3.66
    },
    {
      "lang": "en",
      "text": "going to ask it the question so we're",
      "offset": 4384.8,
      "duration": 3.66
    },
    {
      "lang": "en",
      "text": "going to have here question and with a",
      "offset": 4387.02,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "question but before it we're going to",
      "offset": 4388.46,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "say answer the question with the help of",
      "offset": 4390.38,
      "duration": 2.94
    },
    {
      "lang": "en",
      "text": "the context we're going to provide this",
      "offset": 4391.82,
      "duration": 2.82
    },
    {
      "lang": "en",
      "text": "to the language model",
      "offset": 4393.32,
      "duration": 2.7
    },
    {
      "lang": "en",
      "text": "and we're going to say context and",
      "offset": 4394.64,
      "duration": 3.3
    },
    {
      "lang": "en",
      "text": "they're going to have the whole web page",
      "offset": 4396.02,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "so suddenly now our question is going to",
      "offset": 4397.94,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "be a lot bigger our prompt",
      "offset": 4400.1,
      "duration": 5.88
    },
    {
      "lang": "en",
      "text": "right so our prompt",
      "offset": 4402.98,
      "duration": 6.54
    },
    {
      "lang": "en",
      "text": "now contains the entire web page the",
      "offset": 4405.98,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "whole Wikipedia page",
      "offset": 4409.52,
      "duration": 4.26
    },
    {
      "lang": "en",
      "text": "followed by a question",
      "offset": 4411.5,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "and so now",
      "offset": 4413.78,
      "duration": 3.78
    },
    {
      "lang": "en",
      "text": "it says",
      "offset": 4416.06,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "Jeremy how does an Australian data",
      "offset": 4417.56,
      "duration": 3.9
    },
    {
      "lang": "en",
      "text": "scientist Edge entrepreneur an educator",
      "offset": 4419.42,
      "duration": 3.42
    },
    {
      "lang": "en",
      "text": "known for his work in deep learning",
      "offset": 4421.46,
      "duration": 3.719
    },
    {
      "lang": "en",
      "text": "co-founder of fast AI teaches courses",
      "offset": 4422.84,
      "duration": 4.98
    },
    {
      "lang": "en",
      "text": "develops software conducts research used",
      "offset": 4425.179,
      "duration": 7.201
    },
    {
      "lang": "en",
      "text": "to be yeah okay it's perfect right so",
      "offset": 4427.82,
      "duration": 6.6
    },
    {
      "lang": "en",
      "text": "it's actually done a really good job",
      "offset": 4432.38,
      "duration": 4.859
    },
    {
      "lang": "en",
      "text": "like if somebody asked me to send them a",
      "offset": 4434.42,
      "duration": 5.299
    },
    {
      "lang": "en",
      "text": "you know 100 word bio",
      "offset": 4437.239,
      "duration": 4.98
    },
    {
      "lang": "en",
      "text": "uh that would actually probably be",
      "offset": 4439.719,
      "duration": 4.121
    },
    {
      "lang": "en",
      "text": "better than I would have written myself",
      "offset": 4442.219,
      "duration": 3.301
    },
    {
      "lang": "en",
      "text": "and you'll see even though I asked for",
      "offset": 4443.84,
      "duration": 5.879
    },
    {
      "lang": "en",
      "text": "300 tokens it actually got sent back the",
      "offset": 4445.52,
      "duration": 7.139
    },
    {
      "lang": "en",
      "text": "end of stream token and so it knows to",
      "offset": 4449.719,
      "duration": 5.401
    },
    {
      "lang": "en",
      "text": "stop at this point",
      "offset": 4452.659,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "um",
      "offset": 4455.12,
      "duration": 4.26
    },
    {
      "lang": "en",
      "text": "well that's all very well but how do we",
      "offset": 4456.98,
      "duration": 4.14
    },
    {
      "lang": "en",
      "text": "know to pass in the Jeremy Howard",
      "offset": 4459.38,
      "duration": 3.359
    },
    {
      "lang": "en",
      "text": "Wikipedia page",
      "offset": 4461.12,
      "duration": 3.96
    },
    {
      "lang": "en",
      "text": "well the way we know which Wikipedia",
      "offset": 4462.739,
      "duration": 3.96
    },
    {
      "lang": "en",
      "text": "page to pass in",
      "offset": 4465.08,
      "duration": 5.46
    },
    {
      "lang": "en",
      "text": "is that we can use another model to tell",
      "offset": 4466.699,
      "duration": 7.381
    },
    {
      "lang": "en",
      "text": "us which web page or which document is",
      "offset": 4470.54,
      "duration": 6.98
    },
    {
      "lang": "en",
      "text": "the most useful for answering a question",
      "offset": 4474.08,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "and the way we do that is we we can use",
      "offset": 4481.04,
      "duration": 4.5
    },
    {
      "lang": "en",
      "text": "something called sentence Transformer",
      "offset": 4484.1,
      "duration": 4.02
    },
    {
      "lang": "en",
      "text": "and we can use a special kind of model",
      "offset": 4485.54,
      "duration": 5.94
    },
    {
      "lang": "en",
      "text": "that specifically designed to take a",
      "offset": 4488.12,
      "duration": 6.78
    },
    {
      "lang": "en",
      "text": "document and turn it into a bunch of",
      "offset": 4491.48,
      "duration": 5.94
    },
    {
      "lang": "en",
      "text": "activations where",
      "offset": 4494.9,
      "duration": 4.98
    },
    {
      "lang": "en",
      "text": "two documents that are similar will have",
      "offset": 4497.42,
      "duration": 4.02
    },
    {
      "lang": "en",
      "text": "similar activations",
      "offset": 4499.88,
      "duration": 3.24
    },
    {
      "lang": "en",
      "text": "so let me just let me show you what I",
      "offset": 4501.44,
      "duration": 3.719
    },
    {
      "lang": "en",
      "text": "mean what I'm going to do is I'm going",
      "offset": 4503.12,
      "duration": 4.559
    },
    {
      "lang": "en",
      "text": "to grab just the first paragraph of my",
      "offset": 4505.159,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "Wikipedia page and I'm going to grab the",
      "offset": 4507.679,
      "duration": 5.461
    },
    {
      "lang": "en",
      "text": "first paragraph of Tony Blair's",
      "offset": 4510.679,
      "duration": 4.02
    },
    {
      "lang": "en",
      "text": "Wikipedia page",
      "offset": 4513.14,
      "duration": 3.48
    },
    {
      "lang": "en",
      "text": "okay so we're pretty different people",
      "offset": 4514.699,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "right this is just like a really simple",
      "offset": 4516.62,
      "duration": 5.34
    },
    {
      "lang": "en",
      "text": "small example and I'm going to then call",
      "offset": 4518.54,
      "duration": 4.74
    },
    {
      "lang": "en",
      "text": "this model",
      "offset": 4521.96,
      "duration": 3.719
    },
    {
      "lang": "en",
      "text": "so I'm going to say encode and I'm going",
      "offset": 4523.28,
      "duration": 4.5
    },
    {
      "lang": "en",
      "text": "to encode my Wikipedia first paragraph",
      "offset": 4525.679,
      "duration": 4.621
    },
    {
      "lang": "en",
      "text": "Tony Blair's first paragraph and the",
      "offset": 4527.78,
      "duration": 4.14
    },
    {
      "lang": "en",
      "text": "question",
      "offset": 4530.3,
      "duration": 6.32
    },
    {
      "lang": "en",
      "text": "which was who is Jeremy Howard",
      "offset": 4531.92,
      "duration": 4.7
    },
    {
      "lang": "en",
      "text": "and it's going to pass back",
      "offset": 4536.84,
      "duration": 6.12
    },
    {
      "lang": "en",
      "text": "a 384 long vector",
      "offset": 4539,
      "duration": 5.699
    },
    {
      "lang": "en",
      "text": "of embeddings",
      "offset": 4542.96,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "for the question",
      "offset": 4544.699,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "for me and for Tony Blair",
      "offset": 4546.08,
      "duration": 5.46
    },
    {
      "lang": "en",
      "text": "and what I can now do is I can calculate",
      "offset": 4549.02,
      "duration": 4.86
    },
    {
      "lang": "en",
      "text": "the similarity",
      "offset": 4551.54,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "between the question and the Jeremy",
      "offset": 4553.88,
      "duration": 4.5
    },
    {
      "lang": "en",
      "text": "Howard Wikipedia page",
      "offset": 4556.58,
      "duration": 3.42
    },
    {
      "lang": "en",
      "text": "and I can also do it for the question",
      "offset": 4558.38,
      "duration": 4.859
    },
    {
      "lang": "en",
      "text": "versus the Tony Blair Wikipedia page and",
      "offset": 4560,
      "duration": 6.84
    },
    {
      "lang": "en",
      "text": "as you can see it's higher for me and so",
      "offset": 4563.239,
      "duration": 6.361
    },
    {
      "lang": "en",
      "text": "that tells you that if you're trying to",
      "offset": 4566.84,
      "duration": 4.62
    },
    {
      "lang": "en",
      "text": "figure out what document to use to help",
      "offset": 4569.6,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "you answer this question better off",
      "offset": 4571.46,
      "duration": 4.259
    },
    {
      "lang": "en",
      "text": "using the Jeremy Howard Wikipedia page",
      "offset": 4573.679,
      "duration": 5.161
    },
    {
      "lang": "en",
      "text": "than the Tony Blair Wikipedia pitch",
      "offset": 4575.719,
      "duration": 4.561
    },
    {
      "lang": "en",
      "text": "foreign",
      "offset": 4578.84,
      "duration": 4.98
    },
    {
      "lang": "en",
      "text": "so if you had a few hundred documents",
      "offset": 4580.28,
      "duration": 6.66
    },
    {
      "lang": "en",
      "text": "you were thinking of using to give back",
      "offset": 4583.82,
      "duration": 4.68
    },
    {
      "lang": "en",
      "text": "to the model as context to help it",
      "offset": 4586.94,
      "duration": 3.66
    },
    {
      "lang": "en",
      "text": "answer a question you could literally",
      "offset": 4588.5,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "just pass them all through to encode go",
      "offset": 4590.6,
      "duration": 4.98
    },
    {
      "lang": "en",
      "text": "through each one one at a time and see",
      "offset": 4593.78,
      "duration": 3.54
    },
    {
      "lang": "en",
      "text": "which is closest",
      "offset": 4595.58,
      "duration": 4.2
    },
    {
      "lang": "en",
      "text": "when you've got thousands or millions of",
      "offset": 4597.32,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "documents",
      "offset": 4599.78,
      "duration": 3.419
    },
    {
      "lang": "en",
      "text": "you can use something called a vector",
      "offset": 4601.159,
      "duration": 4.801
    },
    {
      "lang": "en",
      "text": "database where basically as a one-off",
      "offset": 4603.199,
      "duration": 7.321
    },
    {
      "lang": "en",
      "text": "thing you go through and you encode all",
      "offset": 4605.96,
      "duration": 5.94
    },
    {
      "lang": "en",
      "text": "of your documents",
      "offset": 4610.52,
      "duration": 3.24
    },
    {
      "lang": "en",
      "text": "and so in fact",
      "offset": 4611.9,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "um there's there's lots of pre-built",
      "offset": 4613.76,
      "duration": 4.02
    },
    {
      "lang": "en",
      "text": "systems for this",
      "offset": 4616.46,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "um here's an example of one called H2O",
      "offset": 4617.78,
      "duration": 4.1
    },
    {
      "lang": "en",
      "text": "GPT",
      "offset": 4620.06,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "and this is just something that I've got",
      "offset": 4621.88,
      "duration": 5.46
    },
    {
      "lang": "en",
      "text": "um",
      "offset": 4625.34,
      "duration": 2
    },
    {
      "lang": "en",
      "text": "that I've got running here on my",
      "offset": 4630.32,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "computer it's just an open source thing",
      "offset": 4632.42,
      "duration": 3.9
    },
    {
      "lang": "en",
      "text": "written in Python and sitting here",
      "offset": 4634.159,
      "duration": 5.101
    },
    {
      "lang": "en",
      "text": "running on Port 7860 and so I just gone",
      "offset": 4636.32,
      "duration": 5.54
    },
    {
      "lang": "en",
      "text": "to localhost 7860",
      "offset": 4639.26,
      "duration": 6.84
    },
    {
      "lang": "en",
      "text": "and what I did was I just uploaded I",
      "offset": 4641.86,
      "duration": 5.5
    },
    {
      "lang": "en",
      "text": "just clicked upload and I've wrapped",
      "offset": 4646.1,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "last uploaded a bunch of papers in fact",
      "offset": 4647.36,
      "duration": 5.16
    },
    {
      "lang": "en",
      "text": "I might be able to see it better",
      "offset": 4650.42,
      "duration": 5.22
    },
    {
      "lang": "en",
      "text": "yeah here we go a bunch of papers",
      "offset": 4652.52,
      "duration": 6.78
    },
    {
      "lang": "en",
      "text": "and so you know we could look at",
      "offset": 4655.64,
      "duration": 5.88
    },
    {
      "lang": "en",
      "text": "uh",
      "offset": 4659.3,
      "duration": 4.74
    },
    {
      "lang": "en",
      "text": "let me search yeah I can so for example",
      "offset": 4661.52,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "we can look at the ULM fit paper that uh",
      "offset": 4664.04,
      "duration": 4.92
    },
    {
      "lang": "en",
      "text": "so bruter and I did and you can see it's",
      "offset": 4666.56,
      "duration": 5.46
    },
    {
      "lang": "en",
      "text": "taken the PDF and turned it into",
      "offset": 4668.96,
      "duration": 6.6
    },
    {
      "lang": "en",
      "text": "slightly crappily a text format and then",
      "offset": 4672.02,
      "duration": 8.28
    },
    {
      "lang": "en",
      "text": "it's created an embedding for each",
      "offset": 4675.56,
      "duration": 7.08
    },
    {
      "lang": "en",
      "text": "you know each section",
      "offset": 4680.3,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "so I could then",
      "offset": 4682.64,
      "duration": 4.26
    },
    {
      "lang": "en",
      "text": "um ask it",
      "offset": 4684.86,
      "duration": 7.2
    },
    {
      "lang": "en",
      "text": "you know what is ULM fit",
      "offset": 4686.9,
      "duration": 8.06
    },
    {
      "lang": "en",
      "text": "and I'll hit enter",
      "offset": 4692.06,
      "duration": 2.9
    },
    {
      "lang": "en",
      "text": "and you can see here it's now actually",
      "offset": 4695,
      "duration": 2.88
    },
    {
      "lang": "en",
      "text": "saying based on the information provided",
      "offset": 4696.32,
      "duration": 3.419
    },
    {
      "lang": "en",
      "text": "in the context so it's showing us it's",
      "offset": 4697.88,
      "duration": 3.9
    },
    {
      "lang": "en",
      "text": "been given some context what context did",
      "offset": 4699.739,
      "duration": 3.781
    },
    {
      "lang": "en",
      "text": "it get so here are the things that it",
      "offset": 4701.78,
      "duration": 4.04
    },
    {
      "lang": "en",
      "text": "found",
      "offset": 4703.52,
      "duration": 2.3
    },
    {
      "lang": "en",
      "text": "right so it's being sent this context",
      "offset": 4706.4,
      "duration": 4.46
    },
    {
      "lang": "en",
      "text": "so this is kind of citations",
      "offset": 4711.5,
      "duration": 3.32
    },
    {
      "lang": "en",
      "text": "performance by leveraging the knowledge",
      "offset": 4717.1,
      "duration": 5.5
    },
    {
      "lang": "en",
      "text": "and adapting it to the specific task at",
      "offset": 4720.38,
      "duration": 3.72
    },
    {
      "lang": "en",
      "text": "hand",
      "offset": 4722.6,
      "duration": 2.88
    },
    {
      "lang": "en",
      "text": "um",
      "offset": 4724.1,
      "duration": 3.24
    },
    {
      "lang": "en",
      "text": "how",
      "offset": 4725.48,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "what techniques be more specific",
      "offset": 4727.34,
      "duration": 7.08
    },
    {
      "lang": "en",
      "text": "does ULM fit",
      "offset": 4730.52,
      "duration": 7.52
    },
    {
      "lang": "en",
      "text": "uh let's see how it goes",
      "offset": 4734.42,
      "duration": 3.62
    },
    {
      "lang": "en",
      "text": "okay there we go so here's the three",
      "offset": 4740.48,
      "duration": 4.259
    },
    {
      "lang": "en",
      "text": "steps pre-trained fine-tune fine tune",
      "offset": 4742.34,
      "duration": 3.96
    },
    {
      "lang": "en",
      "text": "cool",
      "offset": 4744.739,
      "duration": 4.381
    },
    {
      "lang": "en",
      "text": "um so you can see it's not bad right",
      "offset": 4746.3,
      "duration": 4.379
    },
    {
      "lang": "en",
      "text": "um it's not",
      "offset": 4749.12,
      "duration": 4.44
    },
    {
      "lang": "en",
      "text": "amazing like you know the context in",
      "offset": 4750.679,
      "duration": 6.06
    },
    {
      "lang": "en",
      "text": "this particular case is pretty small",
      "offset": 4753.56,
      "duration": 5.7
    },
    {
      "lang": "en",
      "text": "um and it's and in particular",
      "offset": 4756.739,
      "duration": 4.861
    },
    {
      "lang": "en",
      "text": "if you think about how that embedding",
      "offset": 4759.26,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "thing worked you can't really use like",
      "offset": 4761.6,
      "duration": 4.38
    },
    {
      "lang": "en",
      "text": "the normal kind of follow-up so for",
      "offset": 4763.82,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "example",
      "offset": 4765.98,
      "duration": 2.64
    },
    {
      "lang": "en",
      "text": "um",
      "offset": 4767.659,
      "duration": 3.481
    },
    {
      "lang": "en",
      "text": "if I so it says fine tuning a classifier",
      "offset": 4768.62,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "so I could say",
      "offset": 4771.14,
      "duration": 5.94
    },
    {
      "lang": "en",
      "text": "what classifier is used now the problem",
      "offset": 4773.42,
      "duration": 6.299
    },
    {
      "lang": "en",
      "text": "is that there's no context here being",
      "offset": 4777.08,
      "duration": 4.44
    },
    {
      "lang": "en",
      "text": "sent to the embedding model so it's",
      "offset": 4779.719,
      "duration": 3
    },
    {
      "lang": "en",
      "text": "actually going to have no idea I'm",
      "offset": 4781.52,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "talking about new lmfit so generally",
      "offset": 4782.719,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "speaking it's going to do a terrible job",
      "offset": 4785.12,
      "duration": 4.68
    },
    {
      "lang": "en",
      "text": "yeah I see it says it's used as a",
      "offset": 4788.239,
      "duration": 3.181
    },
    {
      "lang": "en",
      "text": "Roberta model but it's not but if I look",
      "offset": 4789.8,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "at the sources it's no longer actually",
      "offset": 4791.42,
      "duration": 4.92
    },
    {
      "lang": "en",
      "text": "referring to Howard and Rooter",
      "offset": 4793.88,
      "duration": 4.799
    },
    {
      "lang": "en",
      "text": "so anyway you can see the basic idea",
      "offset": 4796.34,
      "duration": 4.74
    },
    {
      "lang": "en",
      "text": "this is called retrieval augmented",
      "offset": 4798.679,
      "duration": 5.101
    },
    {
      "lang": "en",
      "text": "generation Reg",
      "offset": 4801.08,
      "duration": 3.48
    },
    {
      "lang": "en",
      "text": "um",
      "offset": 4803.78,
      "duration": 4.02
    },
    {
      "lang": "en",
      "text": "and it's a it's a Nifty approach but you",
      "offset": 4804.56,
      "duration": 6.78
    },
    {
      "lang": "en",
      "text": "have to do it with with some care",
      "offset": 4807.8,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "um and so there are lots of these uh",
      "offset": 4811.34,
      "duration": 6.18
    },
    {
      "lang": "en",
      "text": "private GPT things out there",
      "offset": 4813.8,
      "duration": 6.419
    },
    {
      "lang": "en",
      "text": "um actually the H2O GPT web page does a",
      "offset": 4817.52,
      "duration": 4.199
    },
    {
      "lang": "en",
      "text": "fantastic job",
      "offset": 4820.219,
      "duration": 4.98
    },
    {
      "lang": "en",
      "text": "of listing lots of them",
      "offset": 4821.719,
      "duration": 6.561
    },
    {
      "lang": "en",
      "text": "and comparing",
      "offset": 4825.199,
      "duration": 8.401
    },
    {
      "lang": "en",
      "text": "so as you can see if you want to run a",
      "offset": 4828.28,
      "duration": 7.06
    },
    {
      "lang": "en",
      "text": "private GPT",
      "offset": 4833.6,
      "duration": 4.46
    },
    {
      "lang": "en",
      "text": "there's no shortage of options",
      "offset": 4835.34,
      "duration": 4.74
    },
    {
      "lang": "en",
      "text": "and you can have your retrieval",
      "offset": 4838.06,
      "duration": 4.84
    },
    {
      "lang": "en",
      "text": "augmented generation I haven't tried",
      "offset": 4840.08,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "I've only tried this one H2O GPT I don't",
      "offset": 4842.9,
      "duration": 4.98
    },
    {
      "lang": "en",
      "text": "love it it's all right",
      "offset": 4845.6,
      "duration": 3.66
    },
    {
      "lang": "en",
      "text": "um",
      "offset": 4847.88,
      "duration": 2.7
    },
    {
      "lang": "en",
      "text": "good",
      "offset": 4849.26,
      "duration": 2.939
    },
    {
      "lang": "en",
      "text": "so finally I want to talk about what's",
      "offset": 4850.58,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "perhaps the most interesting",
      "offset": 4852.199,
      "duration": 4.861
    },
    {
      "lang": "en",
      "text": "option we have which is to do our own",
      "offset": 4854.26,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "fine tuning and fine tuning is cool",
      "offset": 4857.06,
      "duration": 4.38
    },
    {
      "lang": "en",
      "text": "because rather than just retrieving",
      "offset": 4859.46,
      "duration": 3.54
    },
    {
      "lang": "en",
      "text": "documents which might have useful",
      "offset": 4861.44,
      "duration": 4.34
    },
    {
      "lang": "en",
      "text": "context we can actually change our model",
      "offset": 4863,
      "duration": 6.36
    },
    {
      "lang": "en",
      "text": "to behave based on the documents that we",
      "offset": 4865.78,
      "duration": 5.32
    },
    {
      "lang": "en",
      "text": "have available and I'm going to show you",
      "offset": 4869.36,
      "duration": 3.06
    },
    {
      "lang": "en",
      "text": "a really interesting example of fine",
      "offset": 4871.1,
      "duration": 4.559
    },
    {
      "lang": "en",
      "text": "tuning here what we're going to do is",
      "offset": 4872.42,
      "duration": 6.18
    },
    {
      "lang": "en",
      "text": "we're going to fine tune using this um",
      "offset": 4875.659,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "no SQL data set",
      "offset": 4878.6,
      "duration": 9.059
    },
    {
      "lang": "en",
      "text": "and it's got examples of like a a schema",
      "offset": 4881.659,
      "duration": 8.701
    },
    {
      "lang": "en",
      "text": "for a table in a database",
      "offset": 4887.659,
      "duration": 4.5
    },
    {
      "lang": "en",
      "text": "a question",
      "offset": 4890.36,
      "duration": 5.4
    },
    {
      "lang": "en",
      "text": "and then the answer is",
      "offset": 4892.159,
      "duration": 7.861
    },
    {
      "lang": "en",
      "text": "the correct SQL",
      "offset": 4895.76,
      "duration": 6.54
    },
    {
      "lang": "en",
      "text": "to solve that question",
      "offset": 4900.02,
      "duration": 4.62
    },
    {
      "lang": "en",
      "text": "using that database schema",
      "offset": 4902.3,
      "duration": 5.16
    },
    {
      "lang": "en",
      "text": "and so I'm hoping we could use this to",
      "offset": 4904.64,
      "duration": 5.039
    },
    {
      "lang": "en",
      "text": "create a",
      "offset": 4907.46,
      "duration": 4.259
    },
    {
      "lang": "en",
      "text": "um you know I kind of it could be a hand",
      "offset": 4909.679,
      "duration": 4.5
    },
    {
      "lang": "en",
      "text": "to use a handy tool for for business",
      "offset": 4911.719,
      "duration": 4.02
    },
    {
      "lang": "en",
      "text": "users where they type some English",
      "offset": 4914.179,
      "duration": 6.241
    },
    {
      "lang": "en",
      "text": "question and SQL generated for them",
      "offset": 4915.739,
      "duration": 6.841
    },
    {
      "lang": "en",
      "text": "automatically don't know if it actually",
      "offset": 4920.42,
      "duration": 4.739
    },
    {
      "lang": "en",
      "text": "work in practice or not but this is just",
      "offset": 4922.58,
      "duration": 5.7
    },
    {
      "lang": "en",
      "text": "a little fun idea I thought we'd try out",
      "offset": 4925.159,
      "duration": 5.821
    },
    {
      "lang": "en",
      "text": "um I know there's lots of uh",
      "offset": 4928.28,
      "duration": 4.26
    },
    {
      "lang": "en",
      "text": "startups and stuff out there trying to",
      "offset": 4930.98,
      "duration": 4.679
    },
    {
      "lang": "en",
      "text": "do this more seriously but this is this",
      "offset": 4932.54,
      "duration": 4.619
    },
    {
      "lang": "en",
      "text": "is quite cool because it actually got it",
      "offset": 4935.659,
      "duration": 4.261
    },
    {
      "lang": "en",
      "text": "working today in just a couple of hours",
      "offset": 4937.159,
      "duration": 7.401
    },
    {
      "lang": "en",
      "text": "so what we do is we use the hugging face",
      "offset": 4939.92,
      "duration": 8.64
    },
    {
      "lang": "en",
      "text": "data sets library and what that does",
      "offset": 4944.56,
      "duration": 6.4
    },
    {
      "lang": "en",
      "text": "just like the hugging face Hub has lots",
      "offset": 4948.56,
      "duration": 5.159
    },
    {
      "lang": "en",
      "text": "of models stored on it hacking face data",
      "offset": 4950.96,
      "duration": 5.58
    },
    {
      "lang": "en",
      "text": "sets has lots of data sets stored on it",
      "offset": 4953.719,
      "duration": 4.98
    },
    {
      "lang": "en",
      "text": "and so instead of using Transformers",
      "offset": 4956.54,
      "duration": 4.02
    },
    {
      "lang": "en",
      "text": "which is what we use to grab models we",
      "offset": 4958.699,
      "duration": 4.861
    },
    {
      "lang": "en",
      "text": "use data sets and we just pass in the",
      "offset": 4960.56,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "name of the person and the name of their",
      "offset": 4963.56,
      "duration": 5.099
    },
    {
      "lang": "en",
      "text": "repo and it grabs the data set and so we",
      "offset": 4965.84,
      "duration": 4.379
    },
    {
      "lang": "en",
      "text": "can take a look at it",
      "offset": 4968.659,
      "duration": 3.961
    },
    {
      "lang": "en",
      "text": "and it just has a training set",
      "offset": 4970.219,
      "duration": 4.801
    },
    {
      "lang": "en",
      "text": "with features",
      "offset": 4972.62,
      "duration": 6.26
    },
    {
      "lang": "en",
      "text": "and so then I can",
      "offset": 4975.02,
      "duration": 3.86
    },
    {
      "lang": "en",
      "text": "have a look at the training set so",
      "offset": 4980.3,
      "duration": 4.14
    },
    {
      "lang": "en",
      "text": "here's an example",
      "offset": 4983,
      "duration": 2.82
    },
    {
      "lang": "en",
      "text": "which looks a bit like what we've just",
      "offset": 4984.44,
      "duration": 2.46
    },
    {
      "lang": "en",
      "text": "seen",
      "offset": 4985.82,
      "duration": 4.98
    },
    {
      "lang": "en",
      "text": "so what we do now is we want to",
      "offset": 4986.9,
      "duration": 6.66
    },
    {
      "lang": "en",
      "text": "fine-tune a model now we can do that in",
      "offset": 4990.8,
      "duration": 6.3
    },
    {
      "lang": "en",
      "text": "in a notebook from scratch takes I don't",
      "offset": 4993.56,
      "duration": 5.4
    },
    {
      "lang": "en",
      "text": "know 100 or so lines of code it's not",
      "offset": 4997.1,
      "duration": 3.9
    },
    {
      "lang": "en",
      "text": "too much but given the time constraints",
      "offset": 4998.96,
      "duration": 5.4
    },
    {
      "lang": "en",
      "text": "here and also like I thought why not why",
      "offset": 5001,
      "duration": 4.679
    },
    {
      "lang": "en",
      "text": "don't we just use something that's ready",
      "offset": 5004.36,
      "duration": 3.42
    },
    {
      "lang": "en",
      "text": "to go so for example there's something",
      "offset": 5005.679,
      "duration": 4.921
    },
    {
      "lang": "en",
      "text": "called Axolotl which is quite nice in my",
      "offset": 5007.78,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "opinion",
      "offset": 5010.6,
      "duration": 2.3
    },
    {
      "lang": "en",
      "text": "here it is here lovely another very nice",
      "offset": 5013.719,
      "duration": 5.341
    },
    {
      "lang": "en",
      "text": "open source piece of software and uh",
      "offset": 5016.12,
      "duration": 5.46
    },
    {
      "lang": "en",
      "text": "again you can just pip install it",
      "offset": 5019.06,
      "duration": 6.179
    },
    {
      "lang": "en",
      "text": "and it's got things like gptq and 16 bit",
      "offset": 5021.58,
      "duration": 5.72
    },
    {
      "lang": "en",
      "text": "and so forth ready to go",
      "offset": 5025.239,
      "duration": 7.401
    },
    {
      "lang": "en",
      "text": "and so what I did was a",
      "offset": 5027.3,
      "duration": 5.34
    },
    {
      "lang": "en",
      "text": "um it basically has a whole bunch of",
      "offset": 5032.679,
      "duration": 4.381
    },
    {
      "lang": "en",
      "text": "examples of things that it already knows",
      "offset": 5034.78,
      "duration": 3.66
    },
    {
      "lang": "en",
      "text": "how to do",
      "offset": 5037.06,
      "duration": 3.3
    },
    {
      "lang": "en",
      "text": "it's got llama 2 examples so I copied",
      "offset": 5038.44,
      "duration": 6.12
    },
    {
      "lang": "en",
      "text": "the Llama 2 example and I created a SQL",
      "offset": 5040.36,
      "duration": 6.359
    },
    {
      "lang": "en",
      "text": "example so basically just told it this",
      "offset": 5044.56,
      "duration": 4.679
    },
    {
      "lang": "en",
      "text": "is the path to the data set that I want",
      "offset": 5046.719,
      "duration": 5.701
    },
    {
      "lang": "en",
      "text": "this is the type",
      "offset": 5049.239,
      "duration": 5.161
    },
    {
      "lang": "en",
      "text": "um and everything else pretty much I",
      "offset": 5052.42,
      "duration": 3.72
    },
    {
      "lang": "en",
      "text": "left the same",
      "offset": 5054.4,
      "duration": 5.22
    },
    {
      "lang": "en",
      "text": "and then I just ran this command which",
      "offset": 5056.14,
      "duration": 5.22
    },
    {
      "lang": "en",
      "text": "is from there read me accelerate launch",
      "offset": 5059.62,
      "duration": 5.22
    },
    {
      "lang": "en",
      "text": "Axolotl passed in my yaml and that took",
      "offset": 5061.36,
      "duration": 4.7
    },
    {
      "lang": "en",
      "text": "about an hour",
      "offset": 5064.84,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "on my GPU",
      "offset": 5066.06,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "and at the end of the hour",
      "offset": 5068.44,
      "duration": 7.739
    },
    {
      "lang": "en",
      "text": "it had created a q Laura out directory Q",
      "offset": 5071.02,
      "duration": 6.659
    },
    {
      "lang": "en",
      "text": "stands for quantize that's because I was",
      "offset": 5076.179,
      "duration": 4.261
    },
    {
      "lang": "en",
      "text": "creating a smaller quantized model Laura",
      "offset": 5077.679,
      "duration": 4.141
    },
    {
      "lang": "en",
      "text": "I'm not going to talk about today but",
      "offset": 5080.44,
      "duration": 2.88
    },
    {
      "lang": "en",
      "text": "Laura is a very cool thing that",
      "offset": 5081.82,
      "duration": 3.359
    },
    {
      "lang": "en",
      "text": "basically another thing that makes your",
      "offset": 5083.32,
      "duration": 5.3
    },
    {
      "lang": "en",
      "text": "models smaller and also handles",
      "offset": 5085.179,
      "duration": 6.841
    },
    {
      "lang": "en",
      "text": "I can use bigger models on smaller gpus",
      "offset": 5088.62,
      "duration": 5.74
    },
    {
      "lang": "en",
      "text": "for training",
      "offset": 5092.02,
      "duration": 4.139
    },
    {
      "lang": "en",
      "text": "um so",
      "offset": 5094.36,
      "duration": 4.26
    },
    {
      "lang": "en",
      "text": "uh I trained it",
      "offset": 5096.159,
      "duration": 6.961
    },
    {
      "lang": "en",
      "text": "and then I thought okay let's uh create",
      "offset": 5098.62,
      "duration": 6.9
    },
    {
      "lang": "en",
      "text": "our own one so we're going to have this",
      "offset": 5103.12,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "context",
      "offset": 5105.52,
      "duration": 4.92
    },
    {
      "lang": "en",
      "text": "and",
      "offset": 5107.44,
      "duration": 3
    },
    {
      "lang": "en",
      "text": "um",
      "offset": 5110.679,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "this question",
      "offset": 5111.64,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "get the count of competition hosts by",
      "offset": 5115.06,
      "duration": 3.72
    },
    {
      "lang": "en",
      "text": "theme",
      "offset": 5117.219,
      "duration": 3
    },
    {
      "lang": "en",
      "text": "and I'm not going to pass it an answer",
      "offset": 5118.78,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "so I'll just ignore that so again I've",
      "offset": 5120.219,
      "duration": 7.681
    },
    {
      "lang": "en",
      "text": "found out what prompt they were using",
      "offset": 5123.58,
      "duration": 7.98
    },
    {
      "lang": "en",
      "text": "um and created a SQL prompt function and",
      "offset": 5127.9,
      "duration": 5.4
    },
    {
      "lang": "en",
      "text": "so here's what I've got to do use the",
      "offset": 5131.56,
      "duration": 3.179
    },
    {
      "lang": "en",
      "text": "following contextual information to",
      "offset": 5133.3,
      "duration": 3.06
    },
    {
      "lang": "en",
      "text": "answer the question",
      "offset": 5134.739,
      "duration": 3.721
    },
    {
      "lang": "en",
      "text": "context create tables there's the",
      "offset": 5136.36,
      "duration": 4.5
    },
    {
      "lang": "en",
      "text": "context question list or competition",
      "offset": 5138.46,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "host sorted in ascending order",
      "offset": 5140.86,
      "duration": 6.5
    },
    {
      "lang": "en",
      "text": "and then I",
      "offset": 5143.98,
      "duration": 3.38
    },
    {
      "lang": "en",
      "text": "tokenized that chord generate",
      "offset": 5147.719,
      "duration": 6.581
    },
    {
      "lang": "en",
      "text": "and",
      "offset": 5152.52,
      "duration": 4.36
    },
    {
      "lang": "en",
      "text": "the answer was select count hosts kind",
      "offset": 5154.3,
      "duration": 5.64
    },
    {
      "lang": "en",
      "text": "of theme from Farm competition Group by",
      "offset": 5156.88,
      "duration": 5.7
    },
    {
      "lang": "en",
      "text": "theme that is correct",
      "offset": 5159.94,
      "duration": 6.18
    },
    {
      "lang": "en",
      "text": "so I think that's pretty remarkable we",
      "offset": 5162.58,
      "duration": 7.2
    },
    {
      "lang": "en",
      "text": "have just built it also took me like an",
      "offset": 5166.12,
      "duration": 5.82
    },
    {
      "lang": "en",
      "text": "hour to figure out how to do it and then",
      "offset": 5169.78,
      "duration": 5.58
    },
    {
      "lang": "en",
      "text": "an hour to actually do the training",
      "offset": 5171.94,
      "duration": 4.799
    },
    {
      "lang": "en",
      "text": "um and at the end of that we've actually",
      "offset": 5175.36,
      "duration": 5.16
    },
    {
      "lang": "en",
      "text": "got something which which is converting",
      "offset": 5176.739,
      "duration": 4.92
    },
    {
      "lang": "en",
      "text": "um",
      "offset": 5180.52,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "Pros into SQL based on a schema so I",
      "offset": 5181.659,
      "duration": 5.461
    },
    {
      "lang": "en",
      "text": "think that's that's a really exciting",
      "offset": 5185.8,
      "duration": 3
    },
    {
      "lang": "en",
      "text": "idea",
      "offset": 5187.12,
      "duration": 3.539
    },
    {
      "lang": "en",
      "text": "um the only other thing I do want to",
      "offset": 5188.8,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "briefly mention is",
      "offset": 5190.659,
      "duration": 6.241
    },
    {
      "lang": "en",
      "text": "um is doing stuff on Macs if you've got",
      "offset": 5192.88,
      "duration": 7.56
    },
    {
      "lang": "en",
      "text": "a Mac uh you there's a couple of really",
      "offset": 5196.9,
      "duration": 7.279
    },
    {
      "lang": "en",
      "text": "good options the options are mlc and",
      "offset": 5200.44,
      "duration": 7.86
    },
    {
      "lang": "en",
      "text": "lima.cpp currently mlc in particular I",
      "offset": 5204.179,
      "duration": 6.101
    },
    {
      "lang": "en",
      "text": "think it's kind of underappreciated it's",
      "offset": 5208.3,
      "duration": 3.96
    },
    {
      "lang": "en",
      "text": "a",
      "offset": 5210.28,
      "duration": 5.419
    },
    {
      "lang": "en",
      "text": "you know really nice",
      "offset": 5212.26,
      "duration": 3.439
    },
    {
      "lang": "en",
      "text": "project",
      "offset": 5216.34,
      "duration": 2.6
    },
    {
      "lang": "en",
      "text": "um",
      "offset": 5219.219,
      "duration": 4.621
    },
    {
      "lang": "en",
      "text": "uh where you can run language models on",
      "offset": 5220.26,
      "duration": 6.82
    },
    {
      "lang": "en",
      "text": "literally iPhone Android web browsers",
      "offset": 5223.84,
      "duration": 4.44
    },
    {
      "lang": "en",
      "text": "everything",
      "offset": 5227.08,
      "duration": 2.88
    },
    {
      "lang": "en",
      "text": "it's really cool",
      "offset": 5228.28,
      "duration": 4.5
    },
    {
      "lang": "en",
      "text": "and",
      "offset": 5229.96,
      "duration": 7.16
    },
    {
      "lang": "en",
      "text": "and so I'm now actually on my Mac here",
      "offset": 5232.78,
      "duration": 4.34
    },
    {
      "lang": "en",
      "text": "and I've got a",
      "offset": 5237.46,
      "duration": 3.259
    },
    {
      "lang": "en",
      "text": "tiny little Python program called chat",
      "offset": 5240.94,
      "duration": 7.38
    },
    {
      "lang": "en",
      "text": "and it's going to import chat module and",
      "offset": 5244.239,
      "duration": 6.601
    },
    {
      "lang": "en",
      "text": "it's going to import a",
      "offset": 5248.32,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "discretized",
      "offset": 5250.84,
      "duration": 4.799
    },
    {
      "lang": "en",
      "text": "7B",
      "offset": 5252.639,
      "duration": 3
    },
    {
      "lang": "en",
      "text": "and that's going to ask the question",
      "offset": 5255.699,
      "duration": 4.44
    },
    {
      "lang": "en",
      "text": "what is the meaning of life",
      "offset": 5257.44,
      "duration": 4.68
    },
    {
      "lang": "en",
      "text": "so let's try it",
      "offset": 5260.139,
      "duration": 5.641
    },
    {
      "lang": "en",
      "text": "python chat.pi again I just installed",
      "offset": 5262.12,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "this",
      "offset": 5265.78,
      "duration": 3.48
    },
    {
      "lang": "en",
      "text": "earlier today I haven't done that much",
      "offset": 5267.4,
      "duration": 4.14
    },
    {
      "lang": "en",
      "text": "stuff on Max before but I was pretty",
      "offset": 5269.26,
      "duration": 4.979
    },
    {
      "lang": "en",
      "text": "impressed to see",
      "offset": 5271.54,
      "duration": 5.659
    },
    {
      "lang": "en",
      "text": "that it is",
      "offset": 5274.239,
      "duration": 2.96
    },
    {
      "lang": "en",
      "text": "doing a good job here what is the",
      "offset": 5277.3,
      "duration": 3.66
    },
    {
      "lang": "en",
      "text": "meaning of life is complex and",
      "offset": 5279.52,
      "duration": 4.04
    },
    {
      "lang": "en",
      "text": "philosophical",
      "offset": 5280.96,
      "duration": 2.6
    },
    {
      "lang": "en",
      "text": "some people might find meaning in their",
      "offset": 5283.96,
      "duration": 3.9
    },
    {
      "lang": "en",
      "text": "relationships with others",
      "offset": 5285.58,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "their impact in the world et cetera et",
      "offset": 5287.86,
      "duration": 4.94
    },
    {
      "lang": "en",
      "text": "cetera okay and it's doing",
      "offset": 5289.659,
      "duration": 5.881
    },
    {
      "lang": "en",
      "text": "9.6 tokens per second",
      "offset": 5292.8,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "so there you go so there is running",
      "offset": 5295.54,
      "duration": 4.92
    },
    {
      "lang": "en",
      "text": "um a model on a Mac and then another",
      "offset": 5298,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "option that you've probably heard about",
      "offset": 5300.46,
      "duration": 4.52
    },
    {
      "lang": "en",
      "text": "is llama.cpp",
      "offset": 5302.08,
      "duration": 5.88
    },
    {
      "lang": "en",
      "text": "llama.cpp runs on lots of different",
      "offset": 5304.98,
      "duration": 5.8
    },
    {
      "lang": "en",
      "text": "things as well including Max and also on",
      "offset": 5307.96,
      "duration": 4.34
    },
    {
      "lang": "en",
      "text": "Cuda",
      "offset": 5310.78,
      "duration": 5.18
    },
    {
      "lang": "en",
      "text": "it uses a different format called gguf",
      "offset": 5312.3,
      "duration": 5.919
    },
    {
      "lang": "en",
      "text": "and you can again you can use it from",
      "offset": 5315.96,
      "duration": 4.179
    },
    {
      "lang": "en",
      "text": "python even if it was a CPP thing it's",
      "offset": 5318.219,
      "duration": 4.201
    },
    {
      "lang": "en",
      "text": "got a python wrapper so you can just",
      "offset": 5320.139,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "download",
      "offset": 5322.42,
      "duration": 5.88
    },
    {
      "lang": "en",
      "text": "again from hugging face at gguf",
      "offset": 5323.98,
      "duration": 5.94
    },
    {
      "lang": "en",
      "text": "file",
      "offset": 5328.3,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "so you can just go through and there's",
      "offset": 5329.92,
      "duration": 3.299
    },
    {
      "lang": "en",
      "text": "lots of different ones they're all",
      "offset": 5332.139,
      "duration": 2.641
    },
    {
      "lang": "en",
      "text": "documented as to what's what you can",
      "offset": 5333.219,
      "duration": 3.721
    },
    {
      "lang": "en",
      "text": "pick how big a file you want you can",
      "offset": 5334.78,
      "duration": 4.5
    },
    {
      "lang": "en",
      "text": "download it and then you just say Okay",
      "offset": 5336.94,
      "duration": 5.4
    },
    {
      "lang": "en",
      "text": "llama model path equals pass in that",
      "offset": 5339.28,
      "duration": 4.5
    },
    {
      "lang": "en",
      "text": "gguf file",
      "offset": 5342.34,
      "duration": 3.42
    },
    {
      "lang": "en",
      "text": "it spits out lots and lots and lots of",
      "offset": 5343.78,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "gunk",
      "offset": 5345.76,
      "duration": 5.1
    },
    {
      "lang": "en",
      "text": "and then you can say okay so if I called",
      "offset": 5347.62,
      "duration": 5.7
    },
    {
      "lang": "en",
      "text": "that llm you can then say llm question",
      "offset": 5350.86,
      "duration": 5.58
    },
    {
      "lang": "en",
      "text": "name the planets of the solar system 32",
      "offset": 5353.32,
      "duration": 4.62
    },
    {
      "lang": "en",
      "text": "tokens",
      "offset": 5356.44,
      "duration": 4.199
    },
    {
      "lang": "en",
      "text": "and",
      "offset": 5357.94,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "there we are right in Pluto no longer",
      "offset": 5360.639,
      "duration": 3.901
    },
    {
      "lang": "en",
      "text": "considered a planet two mercury three",
      "offset": 5362.98,
      "duration": 4.44
    },
    {
      "lang": "en",
      "text": "Venus poor Earth Mars six oh never run",
      "offset": 5364.54,
      "duration": 6.3
    },
    {
      "lang": "en",
      "text": "out of tokens so again you know it's um",
      "offset": 5367.42,
      "duration": 5.279
    },
    {
      "lang": "en",
      "text": "just to show you here there are all",
      "offset": 5370.84,
      "duration": 4.14
    },
    {
      "lang": "en",
      "text": "these different options",
      "offset": 5372.699,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "um",
      "offset": 5374.98,
      "duration": 3.54
    },
    {
      "lang": "en",
      "text": "uh you know I would say you know if",
      "offset": 5376.3,
      "duration": 4.02
    },
    {
      "lang": "en",
      "text": "you've got a",
      "offset": 5378.52,
      "duration": 5.1
    },
    {
      "lang": "en",
      "text": "Nvidia graphics card and your reasonably",
      "offset": 5380.32,
      "duration": 5.399
    },
    {
      "lang": "en",
      "text": "capable python programmer you'd probably",
      "offset": 5383.62,
      "duration": 5.64
    },
    {
      "lang": "en",
      "text": "be one of you use Pi torch and the",
      "offset": 5385.719,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "hugging face ecosystem",
      "offset": 5389.26,
      "duration": 4.74
    },
    {
      "lang": "en",
      "text": "um but you know I think you know these",
      "offset": 5391.719,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "things might change over time as well",
      "offset": 5394,
      "duration": 2.52
    },
    {
      "lang": "en",
      "text": "and certainly a lot of stuff is coming",
      "offset": 5395.32,
      "duration": 3
    },
    {
      "lang": "en",
      "text": "into llama pretty quickly now when it's",
      "offset": 5396.52,
      "duration": 3.119
    },
    {
      "lang": "en",
      "text": "developing very fast",
      "offset": 5398.32,
      "duration": 2.96
    },
    {
      "lang": "en",
      "text": "as you can see",
      "offset": 5399.639,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "there's a lot of stuff that you can do",
      "offset": 5401.28,
      "duration": 5.8
    },
    {
      "lang": "en",
      "text": "right now with language models",
      "offset": 5403.48,
      "duration": 5.159
    },
    {
      "lang": "en",
      "text": "um particularly if you if you're pretty",
      "offset": 5407.08,
      "duration": 4.639
    },
    {
      "lang": "en",
      "text": "comfortable as a python programmer",
      "offset": 5408.639,
      "duration": 5.1
    },
    {
      "lang": "en",
      "text": "I think it's a really exciting time to",
      "offset": 5411.719,
      "duration": 3.581
    },
    {
      "lang": "en",
      "text": "get involved in some ways it's a",
      "offset": 5413.739,
      "duration": 5.46
    },
    {
      "lang": "en",
      "text": "frustrating time to get involved because",
      "offset": 5415.3,
      "duration": 5.399
    },
    {
      "lang": "en",
      "text": "um",
      "offset": 5419.199,
      "duration": 3.721
    },
    {
      "lang": "en",
      "text": "you know it's very early",
      "offset": 5420.699,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "and a lot of stuff has weird little edge",
      "offset": 5422.92,
      "duration": 6.12
    },
    {
      "lang": "en",
      "text": "cases and It's tricky to install and",
      "offset": 5426.219,
      "duration": 4.381
    },
    {
      "lang": "en",
      "text": "stuff like that",
      "offset": 5429.04,
      "duration": 3
    },
    {
      "lang": "en",
      "text": "um",
      "offset": 5430.6,
      "duration": 3.48
    },
    {
      "lang": "en",
      "text": "there's a lot of great Discord channels",
      "offset": 5432.04,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "however first AI have our own Discord",
      "offset": 5434.08,
      "duration": 3.78
    },
    {
      "lang": "en",
      "text": "channel so feel free to just Google for",
      "offset": 5436.12,
      "duration": 5.099
    },
    {
      "lang": "en",
      "text": "fast AI Discord and drop in we've got a",
      "offset": 5437.86,
      "duration": 5.279
    },
    {
      "lang": "en",
      "text": "channel called generative you feel free",
      "offset": 5441.219,
      "duration": 3.96
    },
    {
      "lang": "en",
      "text": "to ask any questions or",
      "offset": 5443.139,
      "duration": 4.921
    },
    {
      "lang": "en",
      "text": "tell us about what you're finding",
      "offset": 5445.179,
      "duration": 4.381
    },
    {
      "lang": "en",
      "text": "um yeah it's definitely something where",
      "offset": 5448.06,
      "duration": 3.119
    },
    {
      "lang": "en",
      "text": "you want to be getting help from other",
      "offset": 5449.56,
      "duration": 3.179
    },
    {
      "lang": "en",
      "text": "people on this journey because it is",
      "offset": 5451.179,
      "duration": 4.441
    },
    {
      "lang": "en",
      "text": "very early days and",
      "offset": 5452.739,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "you know people are still figuring",
      "offset": 5455.62,
      "duration": 3.599
    },
    {
      "lang": "en",
      "text": "things out as we go but I think it's an",
      "offset": 5457.06,
      "duration": 4.44
    },
    {
      "lang": "en",
      "text": "exciting time to be doing this stuff and",
      "offset": 5459.219,
      "duration": 4.98
    },
    {
      "lang": "en",
      "text": "I'm yeah I'm really enjoying it and I",
      "offset": 5461.5,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "hope that this has given some of you a",
      "offset": 5464.199,
      "duration": 4.261
    },
    {
      "lang": "en",
      "text": "useful starting point on your own",
      "offset": 5466.78,
      "duration": 3.419
    },
    {
      "lang": "en",
      "text": "Journey so I hope you found this useful",
      "offset": 5468.46,
      "duration": 5.66
    },
    {
      "lang": "en",
      "text": "thanks for listening bye",
      "offset": 5470.199,
      "duration": 3.921
    }
  ],
  "cleanText": null,
  "dumpedAt": "2025-07-21T18:43:25.281Z"
}