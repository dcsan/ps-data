{
  "episodeId": "kA-P9ood-cE",
  "channelSlug": "@openai",
  "title": "GPT 4.1 in the API",
  "publishedAt": "2025-04-14T17:30:14.000Z",
  "rawLines": [
    {
      "lang": "en",
      "text": "Hey, I'm Kevin and I lead product at",
      "offset": 6.799,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "OpenAI. Hi, I'm Michelle and I'm a",
      "offset": 8.559,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "post-training research lead here at",
      "offset": 10.96,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "OpenAI. Hi, I'm Ishan and I also work on",
      "offset": 12.559,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "post training. All right, today we're",
      "offset": 15.2,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "excited to announce GPT 4.1, which is a",
      "offset": 17.279,
      "duration": 5.201
    },
    {
      "lang": "en",
      "text": "family of models in the API that were",
      "offset": 20.4,
      "duration": 4.959
    },
    {
      "lang": "en",
      "text": "trained just for developers. And it's",
      "offset": 22.48,
      "duration": 7.039
    },
    {
      "lang": "en",
      "text": "three models. So, it's GPT 4.1, GPT 4.1",
      "offset": 25.359,
      "duration": 7.36
    },
    {
      "lang": "en",
      "text": "Mini, and for the first time, GPT 4.1",
      "offset": 29.519,
      "duration": 5.441
    },
    {
      "lang": "en",
      "text": "Nano, which is our smallest, fastest,",
      "offset": 32.719,
      "duration": 5.041
    },
    {
      "lang": "en",
      "text": "and cheapest model ever. Now, these",
      "offset": 34.96,
      "duration": 5.84
    },
    {
      "lang": "en",
      "text": "models are better than GPT40 on just",
      "offset": 37.76,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "about every dimension. They're even they",
      "offset": 40.8,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "even meet or beat GPT 4.5 in a bunch of",
      "offset": 43.12,
      "duration": 6.24
    },
    {
      "lang": "en",
      "text": "key ways. And for the first time, they",
      "offset": 46.32,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "have long context. So, all three models,",
      "offset": 49.36,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "even the nano model, can handle up to a",
      "offset": 51.76,
      "duration": 4.479
    },
    {
      "lang": "en",
      "text": "million tokens of context. We've also",
      "offset": 53.6,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "got some fun pricing uh stuff to talk",
      "offset": 56.239,
      "duration": 3.361
    },
    {
      "lang": "en",
      "text": "about, but we'll save that for later.",
      "offset": 58,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "And actually, the decision to name these",
      "offset": 59.6,
      "duration": 4.879
    },
    {
      "lang": "en",
      "text": "4.1 was intentional. I mean, it's not",
      "offset": 61.68,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "just that we're bad at naming. It's not",
      "offset": 64.479,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "just that. It's also that uh but these",
      "offset": 65.84,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "models are better across the board.",
      "offset": 68.4,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "They're great at coding. They're great",
      "offset": 70.56,
      "duration": 2.8
    },
    {
      "lang": "en",
      "text": "at complex instruction following.",
      "offset": 71.84,
      "duration": 3.599
    },
    {
      "lang": "en",
      "text": "They're fantastic for building agents.",
      "offset": 73.36,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "So, let's dive in. Let's talk evals.",
      "offset": 75.439,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "Let's do demos. You want to take us",
      "offset": 77.36,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "away? Yeah, let's get started with a",
      "offset": 79.04,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "little look at kind of the intelligence",
      "offset": 81.2,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "by latency curves here. And the quaazar",
      "offset": 83.2,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "or sorry the 4.1 series actually",
      "offset": 86.24,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "improves a lot from 40. So you can see",
      "offset": 89.2,
      "duration": 4.559
    },
    {
      "lang": "en",
      "text": "40 and mini in here are in green and",
      "offset": 91.36,
      "duration": 4.799
    },
    {
      "lang": "en",
      "text": "then 4.1 we have these three new models",
      "offset": 93.759,
      "duration": 4.641
    },
    {
      "lang": "en",
      "text": "that kind of move that frontier upward",
      "offset": 96.159,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "because they're much more intelligent.",
      "offset": 98.4,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "You also can see that we have nano as a",
      "offset": 100.159,
      "duration": 4.561
    },
    {
      "lang": "en",
      "text": "new entrant in this area and it's much",
      "offset": 102.24,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "faster but also you know really holds",
      "offset": 104.72,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "its weight on intelligence. So that's",
      "offset": 107.28,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "kind of the rough shape of the models",
      "offset": 109.28,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "and you know when deciding when to use",
      "offset": 110.88,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "them we recommend starting with 4.1 uh",
      "offset": 112.96,
      "duration": 4.479
    },
    {
      "lang": "en",
      "text": "and it's our kind of powerhouse for",
      "offset": 115.68,
      "duration": 3.119
    },
    {
      "lang": "en",
      "text": "these three dimensions coding",
      "offset": 117.439,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "instruction following and long context.",
      "offset": 118.799,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "Um but if you need something a little",
      "offset": 120.719,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "faster you know for maybe a slightly",
      "offset": 122.159,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "simpler use case I'd recommend 4.1 mini.",
      "offset": 123.759,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "And then finally, nano is just an",
      "offset": 126.399,
      "duration": 3.761
    },
    {
      "lang": "en",
      "text": "absolute workhorse for, you know, tons",
      "offset": 128.319,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "of applications like autocomplete or",
      "offset": 130.16,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "classification or extracting, you know,",
      "offset": 132.72,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "stuff from long documents. So that's",
      "offset": 135.2,
      "duration": 3.759
    },
    {
      "lang": "en",
      "text": "kind of when you should use each model.",
      "offset": 137.04,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "Um, but let's get into coding first. So",
      "offset": 138.959,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "you know, developers care a lot about",
      "offset": 141.36,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "coding and we've been improving our",
      "offset": 142.879,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "model's ability to write functional",
      "offset": 144.8,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "code. Um, and so what does that mean?",
      "offset": 146.879,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "We've been working on making it follow",
      "offset": 148.8,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "diff formats better, explore repos,",
      "offset": 150.319,
      "duration": 4.481
    },
    {
      "lang": "en",
      "text": "write unit tests, and write code that",
      "offset": 152.959,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "compiles. And actually uh SWEBench is a",
      "offset": 154.8,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "really great eval for evaluating this",
      "offset": 158.239,
      "duration": 3.441
    },
    {
      "lang": "en",
      "text": "sort of performance. Kind of the model",
      "offset": 160,
      "duration": 4.239
    },
    {
      "lang": "en",
      "text": "is dropped into a Python repo. It's",
      "offset": 161.68,
      "duration": 5.199
    },
    {
      "lang": "en",
      "text": "given a task. It's got to explore, write",
      "offset": 164.239,
      "duration": 4.881
    },
    {
      "lang": "en",
      "text": "some code, write some tests. And we see",
      "offset": 166.879,
      "duration": 4.961
    },
    {
      "lang": "en",
      "text": "that GBT4.1 is a significant improvement",
      "offset": 169.12,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "over our past models. It reaches 55%",
      "offset": 171.84,
      "duration": 5.679
    },
    {
      "lang": "en",
      "text": "accuracy, up from 33% from our previous",
      "offset": 174.56,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "GPT40 model. And we think this is pretty",
      "offset": 177.519,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "impressive for a non-reasoning model. It",
      "offset": 180,
      "duration": 5.519
    },
    {
      "lang": "en",
      "text": "even beats 01 and 03 mini. But uh",
      "offset": 182.239,
      "duration": 5.92
    },
    {
      "lang": "en",
      "text": "Swebench is all Python and we've also",
      "offset": 185.519,
      "duration": 4.881
    },
    {
      "lang": "en",
      "text": "improved this model's ability to code in",
      "offset": 188.159,
      "duration": 5.041
    },
    {
      "lang": "en",
      "text": "other languages and Ader polyglot is a",
      "offset": 190.4,
      "duration": 4.479
    },
    {
      "lang": "en",
      "text": "great benchmark for that specifically.",
      "offset": 193.2,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "It's got a bunch of languages, but also",
      "offset": 194.879,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "what's cool is that it's got a whole",
      "offset": 197.12,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "diff format. Um so sometimes developers",
      "offset": 199.04,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "want the model to rewrite the entire",
      "offset": 201.92,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "file, but sometimes you want it to",
      "offset": 203.84,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "produce diffs and that's useful when you",
      "offset": 205.44,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "want a faster application. You know, you",
      "offset": 207.68,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "save latency on the tokens that are not",
      "offset": 209.44,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "changed. Also save money, right, on",
      "offset": 211.599,
      "duration": 4.801
    },
    {
      "lang": "en",
      "text": "Exactly. Um, and so here you can see",
      "offset": 213.519,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "that we've really closed the gap on",
      "offset": 216.4,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "whole and diff performance and we've",
      "offset": 218.239,
      "duration": 4.481
    },
    {
      "lang": "en",
      "text": "also doubled GBD4.1's diff performance",
      "offset": 220,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "from 40. Um, you can also see that mini",
      "offset": 222.72,
      "duration": 4.799
    },
    {
      "lang": "en",
      "text": "is a really significant improvement over",
      "offset": 225.68,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "GPT40 mini. So we think both of these",
      "offset": 227.519,
      "duration": 4.961
    },
    {
      "lang": "en",
      "text": "models will be a great uh great model",
      "offset": 229.84,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "for any kind of coding tasks. Um, so",
      "offset": 232.48,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "those are coding benchmarks, but there's",
      "offset": 235.12,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "also kind of the intangibles of when",
      "offset": 236.879,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "you're using a model. You know, when",
      "offset": 239.12,
      "duration": 3.039
    },
    {
      "lang": "en",
      "text": "you're creating a front end, is it",
      "offset": 240.56,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "functional? Is it beautiful? Does it",
      "offset": 242.159,
      "duration": 4.481
    },
    {
      "lang": "en",
      "text": "nail the mark? And so for that, we have",
      "offset": 244,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "uh a little example of a flashc card app",
      "offset": 246.64,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "I've been making. You're learning Hindi.",
      "offset": 249.12,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "Yeah, working on it. Uh and so I've got",
      "offset": 251.36,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "uh you know a prompt here. It's pretty",
      "offset": 254.08,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "complicated. I'm asking for this app",
      "offset": 256.16,
      "duration": 4.479
    },
    {
      "lang": "en",
      "text": "pretty specifically. I want a nice 3D",
      "offset": 258.16,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "animation when you click on the flash",
      "offset": 260.639,
      "duration": 4.241
    },
    {
      "lang": "en",
      "text": "card. Um and so when I give this prompt",
      "offset": 262.4,
      "duration": 5.92
    },
    {
      "lang": "en",
      "text": "to GBT40, this is what I get. Um it",
      "offset": 264.88,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "follows some of the instructions and and",
      "offset": 268.32,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "some of the app is functional. Um, but",
      "offset": 270.88,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "you know, we've really trained GBT4.1 to",
      "offset": 273.44,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "do better. And that model, you can see",
      "offset": 275.6,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "it looks way better. It's discovered",
      "offset": 278.32,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "colors. Uh, it can also do the 3D",
      "offset": 280.56,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "animation. Um, so we think you're really",
      "offset": 283.28,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "going to like this improvement to",
      "offset": 285.52,
      "duration": 2.88
    },
    {
      "lang": "en",
      "text": "front-end coding. And this was just",
      "offset": 286.88,
      "duration": 2.879
    },
    {
      "lang": "en",
      "text": "based on that prompt that you gave it.",
      "offset": 288.4,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "Just one prompt and you get back an",
      "offset": 289.759,
      "duration": 3.361
    },
    {
      "lang": "en",
      "text": "entire working application. It's pretty",
      "offset": 291.44,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "cool. Um, but we've also been working on",
      "offset": 293.12,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "instruction following. So, can you tell",
      "offset": 295.36,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "us a bit about that? Yeah. So just like",
      "offset": 296.88,
      "duration": 3.599
    },
    {
      "lang": "en",
      "text": "coding, we have made the model way",
      "offset": 298.88,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "better at instruction following. It now",
      "offset": 300.479,
      "duration": 3.361
    },
    {
      "lang": "en",
      "text": "strictly follows all the instructions",
      "offset": 302.32,
      "duration": 3.599
    },
    {
      "lang": "en",
      "text": "that you provided. So using all the",
      "offset": 303.84,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "feedback that we received, we created",
      "offset": 305.919,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "this internal instruction following eval",
      "offset": 307.44,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "where it mimics all how an API developer",
      "offset": 310.08,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "uses our model. So each sample in the",
      "offset": 313.12,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "eval contains a complex set of",
      "offset": 315.36,
      "duration": 3.279
    },
    {
      "lang": "en",
      "text": "instructions where each instruction",
      "offset": 317.12,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "belongs to one of several categories",
      "offset": 318.639,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "like formatting, uh ranking, ordered",
      "offset": 320.4,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "instructions, overconfidence and so on.",
      "offset": 322.8,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "And collectively that sample is given a",
      "offset": 324.8,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "difficulty rating from like easy, medium",
      "offset": 326.639,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "and hard. And we see that this model",
      "offset": 328.24,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "does really well across all those axis",
      "offset": 330.479,
      "duration": 4.961
    },
    {
      "lang": "en",
      "text": "and on difficulty levels as well. So",
      "offset": 333.28,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "here you can see the hard subset eval",
      "offset": 335.44,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "results. And this model is so much",
      "offset": 337.44,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "better than the previous 40 model. So",
      "offset": 338.96,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "what's an example of like a really hard",
      "offset": 341.6,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "set of of instructions to follow? Yeah.",
      "offset": 343.6,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "So let's say you're building a trip uh",
      "offset": 346.08,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "planning application and you give it",
      "offset": 347.919,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "instructions like make sure you receive",
      "offset": 349.6,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "all the info from the user before",
      "offset": 351.52,
      "duration": 3.519
    },
    {
      "lang": "en",
      "text": "answering them. And when you answer with",
      "offset": 353.12,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "the trip itinary, make sure it's in a",
      "offset": 355.039,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "table format. It contains five rows,",
      "offset": 356.72,
      "duration": 3.759
    },
    {
      "lang": "en",
      "text": "three columns. The columns are formatted",
      "offset": 358.88,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "in a certain way. Yeah. I I don't know",
      "offset": 360.479,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "about you all. I remember all the times",
      "offset": 362.4,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "that you have to you learn these tricks",
      "offset": 363.919,
      "duration": 3.441
    },
    {
      "lang": "en",
      "text": "in prompting where you're like, &quot;No, no,",
      "offset": 365.6,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "no. You really need to make this a",
      "offset": 367.36,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "table, not a list. Trust me, my boss is",
      "offset": 368.8,
      "duration": 3.519
    },
    {
      "lang": "en",
      "text": "going to be super mad at me if you don't",
      "offset": 370.72,
      "duration": 3.599
    },
    {
      "lang": "en",
      "text": "get this right.&quot; So hopefully no more of",
      "offset": 372.319,
      "duration": 3.761
    },
    {
      "lang": "en",
      "text": "that. Yeah. And people actually were",
      "offset": 374.319,
      "duration": 2.961
    },
    {
      "lang": "en",
      "text": "doing that just so that they could get",
      "offset": 376.08,
      "duration": 2.8
    },
    {
      "lang": "en",
      "text": "the model to follow an instruction. None",
      "offset": 377.28,
      "duration": 3.039
    },
    {
      "lang": "en",
      "text": "of that is needed now. The model follows",
      "offset": 378.88,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "all your instructions to the tea and",
      "offset": 380.319,
      "duration": 3.521
    },
    {
      "lang": "en",
      "text": "it's Yeah, it does really well. We also",
      "offset": 382,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "have a new prompting guide now that",
      "offset": 383.84,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "we'll publish on how to get the best out",
      "offset": 385.6,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "of our models. Awesome. Um, and not just",
      "offset": 387.52,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "internal evals, even on external",
      "offset": 389.84,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "benchmarks like scales multi-challenge",
      "offset": 391.52,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "eval that tests models instruction",
      "offset": 393.44,
      "duration": 3.199
    },
    {
      "lang": "en",
      "text": "following capabilities on multiple",
      "offset": 395.28,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "turns. Uh, our model does really well.",
      "offset": 396.639,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "So, for example, you might have an",
      "offset": 398.88,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "instruction three turns ago and it tests",
      "offset": 400.56,
      "duration": 2.72
    },
    {
      "lang": "en",
      "text": "whether the model remembers that",
      "offset": 402.16,
      "duration": 2.8
    },
    {
      "lang": "en",
      "text": "instructions and continues to follow it.",
      "offset": 403.28,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "So, it also tests models coherence and",
      "offset": 404.96,
      "duration": 4.799
    },
    {
      "lang": "en",
      "text": "memory. Um, these improvements also",
      "offset": 407.44,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "scale well on long context data too. So",
      "offset": 409.759,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "you could give it large corpus of data",
      "offset": 412,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "and the be behavior that you're trying",
      "offset": 413.759,
      "duration": 2.88
    },
    {
      "lang": "en",
      "text": "to extract from the model, it'll",
      "offset": 415.36,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "continue to follow that. Nice. Yeah.",
      "offset": 416.639,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "Speaking of large corpuses, GBT4.1, Mini",
      "offset": 418.8,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "and Nano are our first models to have 1",
      "offset": 421.919,
      "duration": 4.961
    },
    {
      "lang": "en",
      "text": "million of tokens in as the context.",
      "offset": 424.16,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "This is up from 128K for our past",
      "offset": 426.88,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "models. So it's a 8x improvement, which",
      "offset": 429.36,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "is pretty big. But it's not enough to",
      "offset": 431.44,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "just have the context. You want the",
      "offset": 433.44,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "model to be able to use it effectively.",
      "offset": 435.12,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "Um and so for that we're showing this uh",
      "offset": 437.28,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "eval we created um which is a needle in",
      "offset": 439.44,
      "duration": 4.879
    },
    {
      "lang": "en",
      "text": "a haststack. We insert some kind of uh",
      "offset": 442,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "text into a large corpus and we ask the",
      "offset": 444.319,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "model to find it. Um and we see that the",
      "offset": 446.4,
      "duration": 5.519
    },
    {
      "lang": "en",
      "text": "model can find it across any depth. Uh",
      "offset": 449.039,
      "duration": 4.641
    },
    {
      "lang": "en",
      "text": "so maybe at the beginning, the middle or",
      "offset": 451.919,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "the end of the the document and also",
      "offset": 453.68,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "across the entire full length of the",
      "offset": 455.84,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "context up to 1 million. This is a very",
      "offset": 458.08,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "boring looking graph but it's boring in",
      "offset": 460.16,
      "duration": 3.599
    },
    {
      "lang": "en",
      "text": "a great way because it says every square",
      "offset": 461.919,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "is actually working. Yeah, it's actually",
      "offset": 463.759,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "boring through so much work, which is so",
      "offset": 465.919,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "cool. Normally, you would expect to see",
      "offset": 468.319,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "some of these be red, like you know, the",
      "offset": 470.24,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "long context doesn't hold up to a",
      "offset": 471.759,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "certain area, but the fact that all of",
      "offset": 473.28,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "these is blue means that the model can",
      "offset": 474.879,
      "duration": 3.201
    },
    {
      "lang": "en",
      "text": "find what you're looking for. And this",
      "offset": 476.56,
      "duration": 3.039
    },
    {
      "lang": "en",
      "text": "is for all three models, all three",
      "offset": 478.08,
      "duration": 4.959
    },
    {
      "lang": "en",
      "text": "models, even nano. Um, so this is not,",
      "offset": 479.599,
      "duration": 5.361
    },
    {
      "lang": "en",
      "text": "you know, the end all beall of long",
      "offset": 483.039,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "context. Uh, it's nice to find a",
      "offset": 484.96,
      "duration": 4.639
    },
    {
      "lang": "en",
      "text": "detractor in a in a long document, but",
      "offset": 487.039,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "that's not exactly what all our",
      "offset": 489.599,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "developers are doing. Um, so we've also",
      "offset": 490.879,
      "duration": 5.281
    },
    {
      "lang": "en",
      "text": "created an eval called OpenAI MRCR. Uh,",
      "offset": 492.879,
      "duration": 5.841
    },
    {
      "lang": "en",
      "text": "and this is a kind of more challenging",
      "offset": 496.16,
      "duration": 4.479
    },
    {
      "lang": "en",
      "text": "uh way of determining how well the model",
      "offset": 498.72,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "does on long context. Um, so you can see",
      "offset": 500.639,
      "duration": 6.481
    },
    {
      "lang": "en",
      "text": "that GBT 4.1 in blue exceeds GBT40 in",
      "offset": 503.12,
      "duration": 7.359
    },
    {
      "lang": "en",
      "text": "green significantly up to 128K tokens.",
      "offset": 507.12,
      "duration": 5.279
    },
    {
      "lang": "en",
      "text": "Um, and it holds up quite well all the",
      "offset": 510.479,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "way up to 1 million tokens. And this",
      "offset": 512.399,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "this eval is actually really complex.",
      "offset": 514.64,
      "duration": 3.199
    },
    {
      "lang": "en",
      "text": "Can you explain a little bit more about",
      "offset": 516.32,
      "duration": 2.8
    },
    {
      "lang": "en",
      "text": "how it works? Yeah, it's pretty",
      "offset": 517.839,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "complicated. So we basically create",
      "offset": 519.12,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "these synthetic conversations where",
      "offset": 521.519,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "there's a user and an assistant talking",
      "offset": 523.519,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "back and forth and the user is asking",
      "offset": 525.279,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "for things like give me a poem about",
      "offset": 527.36,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "depear and then give me a poem about",
      "offset": 529.279,
      "duration": 4.641
    },
    {
      "lang": "en",
      "text": "frogs and then maybe give me a short",
      "offset": 531.6,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "story about tiers and then we ask the",
      "offset": 533.92,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "model uh find me the second short story",
      "offset": 536.32,
      "duration": 5.519
    },
    {
      "lang": "en",
      "text": "about peers and so you can find it's",
      "offset": 539.36,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "pretty complicated. You have to not get",
      "offset": 541.839,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "confused by the poems and the frogs and",
      "offset": 543.36,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "find you know the second and not the",
      "offset": 545.76,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "first one. Um, so we're really excited",
      "offset": 547.279,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "about this improvement in performance,",
      "offset": 550.08,
      "duration": 3.439
    },
    {
      "lang": "en",
      "text": "but you can see that there's still some",
      "offset": 551.6,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "work to do here. Um, and so as part of",
      "offset": 553.519,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "that, we're publishing this eval on",
      "offset": 555.6,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "hugging face today, uh, OpenAI MRC, and",
      "offset": 557.68,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "we really want to spur on more work in",
      "offset": 560.64,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "the kind of more difficult long context",
      "offset": 562.88,
      "duration": 6.16
    },
    {
      "lang": "en",
      "text": "uh, processing area. Yeah. Um, and then",
      "offset": 565.76,
      "duration": 6.16
    },
    {
      "lang": "en",
      "text": "more on multimodal long context. So",
      "offset": 569.04,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "sometimes you're not just using text,",
      "offset": 571.92,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "but you also want to upload a video. And",
      "offset": 573.36,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "uh we found that on the video MME",
      "offset": 576.32,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "benchmark, GPT4.1 reaches",
      "offset": 578.24,
      "duration": 4.599
    },
    {
      "lang": "en",
      "text": "state-of-the-art performance achieving",
      "offset": 580.56,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "72%. Um so this benchmark is pretty",
      "offset": 582.839,
      "duration": 5.161
    },
    {
      "lang": "en",
      "text": "cool. You upload like a 30 to 60 minute",
      "offset": 585.36,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "video without subtitles and the models",
      "offset": 588,
      "duration": 4.36
    },
    {
      "lang": "en",
      "text": "asked multiple choice questions. So",
      "offset": 590.48,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "GBT4.1 is much better at understanding",
      "offset": 592.36,
      "duration": 4.36
    },
    {
      "lang": "en",
      "text": "this sorts of thing. All right. And then",
      "offset": 594.72,
      "duration": 4.799
    },
    {
      "lang": "en",
      "text": "one last hit on eval",
      "offset": 596.72,
      "duration": 6.32
    },
    {
      "lang": "en",
      "text": "uh on multimodal uh processing in",
      "offset": 599.519,
      "duration": 5.201
    },
    {
      "lang": "en",
      "text": "general. These models are a really",
      "offset": 603.04,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "significant improvement, but the real",
      "offset": 604.72,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "story is GBT4.1 mini. Um, this model,",
      "offset": 607.04,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "you can see it really punches above its",
      "offset": 610.48,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "weight uh on multimodal uh reasoning and",
      "offset": 612.24,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "intelligence. And we think this is",
      "offset": 615.12,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "probably the top model to be used uh if",
      "offset": 617.04,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "you're doing any sort of multimodal or",
      "offset": 619.44,
      "duration": 4.639
    },
    {
      "lang": "en",
      "text": "image processing. Okay, amazing",
      "offset": 621.12,
      "duration": 4.719
    },
    {
      "lang": "en",
      "text": "benchmarks. But let's see some demos.",
      "offset": 624.079,
      "duration": 3.521
    },
    {
      "lang": "en",
      "text": "Let's do it.",
      "offset": 625.839,
      "duration": 4.481
    },
    {
      "lang": "en",
      "text": "So here we have the OpenAI playground",
      "offset": 627.6,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "which is a really nice UI to iterate on",
      "offset": 630.32,
      "duration": 4.959
    },
    {
      "lang": "en",
      "text": "OpenAI's APIs. Um I've pre-selected the",
      "offset": 632.24,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "latest 4.1 model and in the system",
      "offset": 635.279,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "message I've given it a light identity.",
      "offset": 637.68,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "The identity is it needs to produce a",
      "offset": 639.6,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "single Python file code application uh",
      "offset": 641.76,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "with very limited setup required. I also",
      "offset": 644.24,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "told it that it has access to the latest",
      "offset": 646.64,
      "duration": 3.759
    },
    {
      "lang": "en",
      "text": "4.1 model which can handle up to 1",
      "offset": 648.16,
      "duration": 5.359
    },
    {
      "lang": "en",
      "text": "million tokens of input and 32K output.",
      "offset": 650.399,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "So on the right we mimic a user query.",
      "offset": 653.519,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "So the user is asking to make a website",
      "offset": 655.519,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "that can take a large text file and",
      "offset": 657.279,
      "duration": 5.041
    },
    {
      "lang": "en",
      "text": "answer questions about it. We give it",
      "offset": 659.68,
      "duration": 5.279
    },
    {
      "lang": "en",
      "text": "very limited style guidance and we tell",
      "offset": 662.32,
      "duration": 5.199
    },
    {
      "lang": "en",
      "text": "it to use OpenAI's responses APIs to",
      "offset": 664.959,
      "duration": 5.801
    },
    {
      "lang": "en",
      "text": "answer questions about the doc.",
      "offset": 667.519,
      "duration": 6.721
    },
    {
      "lang": "en",
      "text": "So let's see it in action. So you're",
      "offset": 670.76,
      "duration": 5
    },
    {
      "lang": "en",
      "text": "having as part of the demo, you're",
      "offset": 674.24,
      "duration": 3.039
    },
    {
      "lang": "en",
      "text": "having it create a website and then",
      "offset": 675.76,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "you'll use that website for the rest of",
      "offset": 677.279,
      "duration": 3.761
    },
    {
      "lang": "en",
      "text": "the demo. Exactly. Okay. Yeah. So now",
      "offset": 678.8,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "it's producing like multiple hundreds of",
      "offset": 681.04,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "lines of code. I've rerun this query",
      "offset": 683.12,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "before and I have copied that the code",
      "offset": 685.68,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "that it spits out into this app.py file.",
      "offset": 688.16,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "So you can see it's a multiple hundred",
      "offset": 690.72,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "line file. You see that the HTML has",
      "offset": 692.24,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "been inlined in this file. Um if you",
      "offset": 694.8,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "keep scrolling you would see there's the",
      "offset": 697.92,
      "duration": 5.039
    },
    {
      "lang": "en",
      "text": "upload code, the code to ask questions.",
      "offset": 700.24,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "It's going to hit the responses API. So",
      "offset": 702.959,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "the model did this just in one shot.",
      "offset": 704.8,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "Yeah, it's doing that right now as",
      "offset": 706.64,
      "duration": 2.879
    },
    {
      "lang": "en",
      "text": "you're seeing it. Yeah. Just produce the",
      "offset": 708,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "code. It tells you how to spin it up.",
      "offset": 709.519,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "Cool. Yeah. Should we take it for a",
      "offset": 711.44,
      "duration": 6.28
    },
    {
      "lang": "en",
      "text": "spin? Let's do it. Yeah. Cool.",
      "offset": 713.2,
      "duration": 4.52
    },
    {
      "lang": "en",
      "text": "Okay. So, let's try.",
      "offset": 719.72,
      "duration": 5.48
    },
    {
      "lang": "en",
      "text": "Nice. What do you think? That looks",
      "offset": 723.36,
      "duration": 3.279
    },
    {
      "lang": "en",
      "text": "pretty cool. It's It's a little BDB",
      "offset": 725.2,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "sassy, but I think it worked. I do like",
      "offset": 726.639,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "that it uh advertises itself there at",
      "offset": 729.36,
      "duration": 4.719
    },
    {
      "lang": "en",
      "text": "the bottom. Powered by GPT 4.1. Yeah,",
      "offset": 731.839,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "it's kind of neat. Just based on the",
      "offset": 734.079,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "limited guidance that we gave it, it",
      "offset": 736.16,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "produced this website. So to test the",
      "offset": 737.519,
      "duration": 5.361
    },
    {
      "lang": "en",
      "text": "log file that I'm about to upload, um",
      "offset": 740.56,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "that file is NASA's server request",
      "offset": 742.88,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "response log file from 1995 August. Let",
      "offset": 745.04,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "me show you that file. You just have",
      "offset": 748.56,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "this file lying around. Yeah, that's",
      "offset": 750.16,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "don't you don't? I actually I prefer the",
      "offset": 752.399,
      "duration": 4.641
    },
    {
      "lang": "en",
      "text": "94. Oh, uh the 94 is a great version.",
      "offset": 754.8,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "That's a good one. Yeah. So in this log",
      "offset": 757.04,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "file, you can see the client name in the",
      "offset": 759.76,
      "duration": 3.759
    },
    {
      "lang": "en",
      "text": "left that made the request to NASA",
      "offset": 761.92,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "servers. You see the time stamp, the",
      "offset": 763.519,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "resource that was accessed, and the HTTP",
      "offset": 765.2,
      "duration": 5.199
    },
    {
      "lang": "en",
      "text": "response code. This is a long file that",
      "offset": 767.68,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "contains a lot of log lines, and you can",
      "offset": 770.399,
      "duration": 3.761
    },
    {
      "lang": "en",
      "text": "see on the left that this is about",
      "offset": 773.04,
      "duration": 4.239
    },
    {
      "lang": "en",
      "text": "450,000 tokens of uh content here. Nice.",
      "offset": 774.16,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "So, you just couldn't use this with our",
      "offset": 777.279,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "past model. Yeah, this wasn't possible.",
      "offset": 778.8,
      "duration": 5.4
    },
    {
      "lang": "en",
      "text": "So, let's try uploading this",
      "offset": 781.519,
      "duration": 5.281
    },
    {
      "lang": "en",
      "text": "file. Now, what I've done is I've snuck",
      "offset": 784.2,
      "duration": 5.24
    },
    {
      "lang": "en",
      "text": "in a line that is not actually an HTTP",
      "offset": 786.8,
      "duration": 4.479
    },
    {
      "lang": "en",
      "text": "request response. Let's see if it can",
      "offset": 789.44,
      "duration": 6.959
    },
    {
      "lang": "en",
      "text": "find it. Very sneaky",
      "offset": 791.279,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "view. Okay. So, it's a little needle in",
      "offset": 803.88,
      "duration": 4.759
    },
    {
      "lang": "en",
      "text": "the haststack except in this case you",
      "offset": 806.079,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "don't even tell it what the needle looks",
      "offset": 808.639,
      "duration": 3.041
    },
    {
      "lang": "en",
      "text": "like. It's just figure out what's",
      "offset": 809.839,
      "duration": 3.361
    },
    {
      "lang": "en",
      "text": "different and tell me exactly. So, it's",
      "offset": 811.68,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "going to sift through the whole file, do",
      "offset": 813.2,
      "duration": 3.759
    },
    {
      "lang": "en",
      "text": "some pattern matching to see how all the",
      "offset": 815.36,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "log lines look like and then try to see",
      "offset": 816.959,
      "duration": 3.281
    },
    {
      "lang": "en",
      "text": "if there's one that does not look like",
      "offset": 818.8,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "the others. Nice. And I really like this",
      "offset": 820.24,
      "duration": 5.279
    },
    {
      "lang": "en",
      "text": "thinking spinner. So this is just the",
      "offset": 823.12,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "front end that we created uh in the demo",
      "offset": 825.519,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "right before this one. Exactly. It's",
      "offset": 828.32,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "like a nice actively going spinner. And",
      "offset": 829.839,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "all the front end improvements also are",
      "offset": 831.92,
      "duration": 2.96
    },
    {
      "lang": "en",
      "text": "showing up here even in this like very",
      "offset": 833.44,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "limited single page Python application",
      "offset": 834.88,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "that we asked it to write. It doesn't",
      "offset": 836.88,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "have access to like other additional",
      "offset": 838.88,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "files that it could spit out for styling",
      "offset": 840.48,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "or anything like that. So totally. Yeah.",
      "offset": 841.92,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "I think this front end is is definitely",
      "offset": 843.92,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "significantly better than what I can",
      "offset": 845.92,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "make. So it meets my bar for sure. Yeah.",
      "offset": 847.36,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "Yeah. And this spinning thing is kind of",
      "offset": 849.92,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "neat.",
      "offset": 851.519,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "Definitely taken a sec, but we're I",
      "offset": 853.6,
      "duration": 5.72
    },
    {
      "lang": "en",
      "text": "think we're almost there.",
      "offset": 855.839,
      "duration": 3.481
    },
    {
      "lang": "en",
      "text": "Any minute now.",
      "offset": 862.24,
      "duration": 3.64
    },
    {
      "lang": "en",
      "text": "Come on. 4.1. Live demos are awesome.",
      "offset": 870,
      "duration": 4.92
    },
    {
      "lang": "en",
      "text": "Okay, we made it.",
      "offset": 878.32,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "Uh, okay. There is a line that it has",
      "offset": 881.12,
      "duration": 4.719
    },
    {
      "lang": "en",
      "text": "spit out that does not look like an HTTP",
      "offset": 883.36,
      "duration": 5.279
    },
    {
      "lang": "en",
      "text": "request line to me. It does not. Okay.",
      "offset": 885.839,
      "duration": 4.961
    },
    {
      "lang": "en",
      "text": "Uh, let's see if this line is indeed in",
      "offset": 888.639,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "the log file that we uploaded. I'm going",
      "offset": 890.8,
      "duration": 5.32
    },
    {
      "lang": "en",
      "text": "to copy this keyword.",
      "offset": 892.639,
      "duration": 3.481
    },
    {
      "lang": "en",
      "text": "Nice. Here it is. Great. So, it was able",
      "offset": 897.76,
      "duration": 4.639
    },
    {
      "lang": "en",
      "text": "to find this line that has been snuck in",
      "offset": 900.399,
      "duration": 4.721
    },
    {
      "lang": "en",
      "text": "into this D4 450,000 token log file that",
      "offset": 902.399,
      "duration": 4.721
    },
    {
      "lang": "en",
      "text": "is like very hard to find. So, did",
      "offset": 905.12,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "pretty well. Nice job, GBG4.1.",
      "offset": 907.12,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "Let's look at another demo. Awesome.",
      "offset": 911.12,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "Okay. So, here we are going to riff on",
      "offset": 912.72,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "the previous demo that we saw, but this",
      "offset": 915.199,
      "duration": 2.88
    },
    {
      "lang": "en",
      "text": "one is going to be more focused on how",
      "offset": 916.72,
      "duration": 3.679
    },
    {
      "lang": "en",
      "text": "an API developer prompts our model. So,",
      "offset": 918.079,
      "duration": 5.281
    },
    {
      "lang": "en",
      "text": "I've again selected the 4.1 model here.",
      "offset": 920.399,
      "duration": 5.201
    },
    {
      "lang": "en",
      "text": "And here the the application's",
      "offset": 923.36,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "personality is of a log analyst",
      "offset": 925.6,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "assistant. We tell it how the input data",
      "offset": 927.44,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "will be structured. So we tell it it",
      "offset": 930.16,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "will be within these log data uh tags",
      "offset": 931.6,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "and how the user's query would be",
      "offset": 934.56,
      "duration": 2.959
    },
    {
      "lang": "en",
      "text": "structured. So that would be in the",
      "offset": 936.32,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "query tag. And then we have a set of",
      "offset": 937.519,
      "duration": 3.041
    },
    {
      "lang": "en",
      "text": "rules. So these are kind of the",
      "offset": 939.6,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "instructions that a API developer would",
      "offset": 940.56,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "provide to the model. So they are saying",
      "offset": 943.04,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "that only answer questions about the",
      "offset": 944.959,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "content within log data. Uh the question",
      "offset": 946.56,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "should always be formatted within the",
      "offset": 949.04,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "query tags. If any of those things are",
      "offset": 950.56,
      "duration": 4.04
    },
    {
      "lang": "en",
      "text": "not true, please respond with an error",
      "offset": 952.88,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "message. The response should be in an",
      "offset": 954.6,
      "duration": 3.96
    },
    {
      "lang": "en",
      "text": "XML format. And I've given it some very",
      "offset": 956.8,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "light guidance on how the XML format",
      "offset": 958.56,
      "duration": 2.719
    },
    {
      "lang": "en",
      "text": "should look like. So it should have some",
      "offset": 960.16,
      "duration": 3.359
    },
    {
      "lang": "en",
      "text": "tags like result, final answer,",
      "offset": 961.279,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "references, and so on. Nice. Yeah, this",
      "offset": 963.519,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "looks a lot like the system messages we",
      "offset": 965.44,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "find developers use often. You know,",
      "offset": 967.199,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "they're pretty meaty. Yeah. Um, and I've",
      "offset": 968.88,
      "duration": 5.199
    },
    {
      "lang": "en",
      "text": "preloaded the log file here. So this is",
      "offset": 971.759,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "the trimmed version of the same log file",
      "offset": 974.079,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "we saw earlier. Cool. So I first made a",
      "offset": 975.6,
      "duration": 6.56
    },
    {
      "lang": "en",
      "text": "request u saying how many requests were",
      "offset": 978.959,
      "duration": 6.161
    },
    {
      "lang": "en",
      "text": "made by fnal.gov of and it rejected it",
      "offset": 982.16,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "because it was not formatted within the",
      "offset": 985.12,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "query tags. Now I'm going to make the",
      "offset": 986.8,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "same request within query tags and see",
      "offset": 989.279,
      "duration": 3.401
    },
    {
      "lang": "en",
      "text": "how it",
      "offset": 990.88,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "does. Okay, now it was able to find the",
      "offset": 992.68,
      "duration": 4.12
    },
    {
      "lang": "en",
      "text": "two references that are within the log",
      "offset": 995.199,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "file. So this is the kind of interaction",
      "offset": 996.8,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "we see quite a bit with 40 where users",
      "offset": 998.639,
      "duration": 5.041
    },
    {
      "lang": "en",
      "text": "want a certain behavior and especially",
      "offset": 1001.68,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "certain behavior not to happen and the",
      "offset": 1003.68,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "model sometimes misses on it. So I have",
      "offset": 1005.36,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "an example. I made the same query to 40",
      "offset": 1007.12,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "and it answered the question instead of",
      "offset": 1009.44,
      "duration": 2.959
    },
    {
      "lang": "en",
      "text": "saying that it needs to be wrapped in",
      "offset": 1010.959,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "query tax. Yeah, that's a key detail we",
      "offset": 1012.399,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "hear a lot from developers. You really",
      "offset": 1014.959,
      "duration": 3.361
    },
    {
      "lang": "en",
      "text": "want it to follow negative instructions",
      "offset": 1016.639,
      "duration": 3.521
    },
    {
      "lang": "en",
      "text": "and and do exactly as specified.",
      "offset": 1018.32,
      "duration": 5.999
    },
    {
      "lang": "en",
      "text": "Exactly. Yeah. Super cool. Awesome. So,",
      "offset": 1020.16,
      "duration": 6.639
    },
    {
      "lang": "en",
      "text": "great results on benchmarks. That was an",
      "offset": 1024.319,
      "duration": 4.961
    },
    {
      "lang": "en",
      "text": "awesome set of live demos. I I know a",
      "offset": 1026.799,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "big amount of work has gone into just",
      "offset": 1029.28,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "making sure that this model is is really",
      "offset": 1031.039,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "good at the kind of day-to-day tasks",
      "offset": 1032.72,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "that developers face. and you and your",
      "offset": 1034.319,
      "duration": 3.281
    },
    {
      "lang": "en",
      "text": "team have put a ton of time into that.",
      "offset": 1036.4,
      "duration": 2.72
    },
    {
      "lang": "en",
      "text": "So maybe talk a bit about it. Yeah,",
      "offset": 1037.6,
      "duration": 3.359
    },
    {
      "lang": "en",
      "text": "totally. Um, yeah, it's not an accident",
      "offset": 1039.12,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "that developers in the real world love",
      "offset": 1040.959,
      "duration": 5.201
    },
    {
      "lang": "en",
      "text": "using these models. Um, to that end, we",
      "offset": 1043.039,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "kind of went with a data sharing program",
      "offset": 1046.16,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "last year where developers can opt in to",
      "offset": 1048.319,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "share their traffic with us. Uh, and in",
      "offset": 1050.64,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "exchange for free free credits and so",
      "offset": 1052.64,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "when that traffic comes in, we'll, you",
      "offset": 1054.799,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "know, scrub it for PII, remove any",
      "offset": 1056.48,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "identifying details, and then use that",
      "offset": 1058.4,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "to improve our models. And actually one",
      "offset": 1060.08,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "of the key things we do with that is",
      "offset": 1062.48,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "creating evals. Um and so the evals help",
      "offset": 1064.08,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "us tell like when we're creating a new",
      "offset": 1066.799,
      "duration": 3.441
    },
    {
      "lang": "en",
      "text": "model, are we on the right track? Are",
      "offset": 1068.64,
      "duration": 3.279
    },
    {
      "lang": "en",
      "text": "developers going to like this? And so",
      "offset": 1070.24,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "the eval Sean mentioned at the top",
      "offset": 1071.919,
      "duration": 3.281
    },
    {
      "lang": "en",
      "text": "instruction following was directly",
      "offset": 1073.76,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "inspired by this. Um and so first I want",
      "offset": 1075.2,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "to say thank you to all of the",
      "offset": 1078,
      "duration": 2.96
    },
    {
      "lang": "en",
      "text": "developers who've opted in. Thanks to",
      "offset": 1079.12,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "you opting in, we've been able to make a",
      "offset": 1080.96,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "much better model. And then what I'll",
      "offset": 1082.64,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "say for developers who haven't yet, uh,",
      "offset": 1084.48,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "if you want the models to get better for",
      "offset": 1086.64,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "you with no work on your part, I'd",
      "offset": 1089.12,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "recommend opting in. Yeah, it really",
      "offset": 1091.12,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "does help us build great models for you.",
      "offset": 1093.12,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "Now, we said we also would come back and",
      "offset": 1095.44,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "talk pricing. Uh, our mission is to",
      "offset": 1097.2,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "ensure that AGI benefits all of",
      "offset": 1100.08,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "humanity. And one of the things that",
      "offset": 1101.76,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "we've learned over and over is that the",
      "offset": 1103.36,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "more cost-effectively we can offer our",
      "offset": 1105.36,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "models, the more use cases you're able",
      "offset": 1107.28,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "to build, the more that you're able to",
      "offset": 1109.52,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "use AI to help people all over the",
      "offset": 1111.44,
      "duration": 5.359
    },
    {
      "lang": "en",
      "text": "world. And so in particular, GPT 4.1",
      "offset": 1113.84,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "with all of the improvements that",
      "offset": 1116.799,
      "duration": 3.201
    },
    {
      "lang": "en",
      "text": "Michelle and Isan have been talking",
      "offset": 1118.24,
      "duration": 6.679
    },
    {
      "lang": "en",
      "text": "about is going to be 26% cheaper than",
      "offset": 1120,
      "duration": 9.039
    },
    {
      "lang": "en",
      "text": "GPT40. And GPT4.1 Nano is our smallest,",
      "offset": 1124.919,
      "duration": 7.321
    },
    {
      "lang": "en",
      "text": "fastest, cheapest model ever at just 12",
      "offset": 1129.039,
      "duration": 7.121
    },
    {
      "lang": "en",
      "text": "cents blended per million tokens. And uh",
      "offset": 1132.24,
      "duration": 6.08
    },
    {
      "lang": "en",
      "text": "going beyond what any of our competitors",
      "offset": 1136.16,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "offer, there is no pricing bump for long",
      "offset": 1138.32,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "context. So when you use our long",
      "offset": 1140.559,
      "duration": 3.761
    },
    {
      "lang": "en",
      "text": "context models, you're just paying for",
      "offset": 1142.48,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "your tokens uh the same way that you pay",
      "offset": 1144.32,
      "duration": 6.88
    },
    {
      "lang": "en",
      "text": "for a non-long context uh request. Now",
      "offset": 1146.559,
      "duration": 7.521
    },
    {
      "lang": "en",
      "text": "uh one bit of uh you know, fun police",
      "offset": 1151.2,
      "duration": 5.839
    },
    {
      "lang": "en",
      "text": "update here. Uh, we know GPUs are at a",
      "offset": 1154.08,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "premium. We want to make sure that we",
      "offset": 1157.039,
      "duration": 5.281
    },
    {
      "lang": "en",
      "text": "can get GPT 4.1 out as broadly as",
      "offset": 1159.12,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "possible to all of you and we've just",
      "offset": 1162.32,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "been talking about how 4.1 beats even",
      "offset": 1164.88,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "4.5 on a lot of key benchmarks. So,",
      "offset": 1167.6,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "we're announcing that we're going to be",
      "offset": 1170.88,
      "duration": 5.24
    },
    {
      "lang": "en",
      "text": "deprecating GPT 4.5 in the API. Not",
      "offset": 1172.24,
      "duration": 6.16
    },
    {
      "lang": "en",
      "text": "today. It'll happen over the course of",
      "offset": 1176.12,
      "duration": 4.919
    },
    {
      "lang": "en",
      "text": "the next 3 months or so, but we really",
      "offset": 1178.4,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "do need those GPUs back. Yeah, we're",
      "offset": 1181.039,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "really excited to get some back for",
      "offset": 1183.12,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "research. So, thank you. Yeah. And uh I",
      "offset": 1184.64,
      "duration": 3.96
    },
    {
      "lang": "en",
      "text": "know we all love",
      "offset": 1187.039,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "GPT4.5. Uh a lot of the improvements",
      "offset": 1188.6,
      "duration": 5.24
    },
    {
      "lang": "en",
      "text": "that we've made uh are going to continue",
      "offset": 1191.2,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "on in this model and in other models.",
      "offset": 1193.84,
      "duration": 4.36
    },
    {
      "lang": "en",
      "text": "So, it has been a very successful",
      "offset": 1196.08,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "experiment. Now, we have one more",
      "offset": 1198.2,
      "duration": 4.2
    },
    {
      "lang": "en",
      "text": "surprise for you. Uh I'm really excited",
      "offset": 1200.4,
      "duration": 4.639
    },
    {
      "lang": "en",
      "text": "to invite Verun, who is the founder and",
      "offset": 1202.4,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "CEO of Windsurf, which is one of the",
      "offset": 1205.039,
      "duration": 5.041
    },
    {
      "lang": "en",
      "text": "premier agentic coding uh idees out in",
      "offset": 1207.2,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "the market. Verun and his team have been",
      "offset": 1210.08,
      "duration": 5.839
    },
    {
      "lang": "en",
      "text": "early testers of GPT4.1 and uh excited",
      "offset": 1212.32,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "to hear from you directly. How's it",
      "offset": 1215.919,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "been? Yeah, we got access to GPT 4.1. We",
      "offset": 1217.28,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "were super excited to sort of test it",
      "offset": 1220.799,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "out and we were very surprised with the",
      "offset": 1222.64,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "performance. Uh we have internal",
      "offset": 1224.88,
      "duration": 3.279
    },
    {
      "lang": "en",
      "text": "benchmarks that are very similar to what",
      "offset": 1226.559,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "a SWEBench looks like that validates",
      "offset": 1228.159,
      "duration": 4.481
    },
    {
      "lang": "en",
      "text": "endto-end software performance and we",
      "offset": 1230.48,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "found that it was a 60% improvement over",
      "offset": 1232.64,
      "duration": 5.279
    },
    {
      "lang": "en",
      "text": "GPT40 which is a massive bump. Uh but",
      "offset": 1234.88,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "internal benchmarks only tell a part of",
      "offset": 1237.919,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "the story, right? Uh for our users, what",
      "offset": 1239.84,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "matters more than just getting to a",
      "offset": 1242.24,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "solution, it's actually the smoothness,",
      "offset": 1244.32,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "the interactivity when you're viating an",
      "offset": 1246.559,
      "duration": 4.721
    },
    {
      "lang": "en",
      "text": "app or or modifying an app. Um and what",
      "offset": 1248.48,
      "duration": 5.679
    },
    {
      "lang": "en",
      "text": "we actually found was GPT 4.1 has",
      "offset": 1251.28,
      "duration": 5.759
    },
    {
      "lang": "en",
      "text": "substantially fewer cases of degenerate",
      "offset": 1254.159,
      "duration": 5.041
    },
    {
      "lang": "en",
      "text": "behavior. And maybe a couple examples",
      "offset": 1257.039,
      "duration": 5.681
    },
    {
      "lang": "en",
      "text": "here. We found the GPT4.1 reduces uh",
      "offset": 1259.2,
      "duration": 4.959
    },
    {
      "lang": "en",
      "text": "kind of the number of times that it",
      "offset": 1262.72,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "needs to read unnecessary files uh by",
      "offset": 1264.159,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "40% compared to the other leading",
      "offset": 1266.72,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "models. And also it modifies unnecessary",
      "offset": 1268.32,
      "duration": 5.92
    },
    {
      "lang": "en",
      "text": "files 70% less than the other leading",
      "offset": 1272,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "models. Um to top it all off, the model",
      "offset": 1274.24,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "is also surprisingly less verbose.",
      "offset": 1276.64,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "Right? These models sometimes tend to",
      "offset": 1278.64,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "blabber a lot and GBT 4.1 is 50% less",
      "offset": 1280.08,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "verbose than the other leading models as",
      "offset": 1283.44,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "well. Um, for all these reasons, we've",
      "offset": 1285.36,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "been super excited about the",
      "offset": 1287.76,
      "duration": 2.96
    },
    {
      "lang": "en",
      "text": "performance. Uh, we decided to actually",
      "offset": 1288.88,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "go out and provide GPT 4.1 for free for",
      "offset": 1290.72,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "all of our free and paid users for the",
      "offset": 1293.76,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "week and also heavily discount the",
      "offset": 1295.84,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "product uh, immediately afterwards. So,",
      "offset": 1297.84,
      "duration": 6.719
    },
    {
      "lang": "en",
      "text": "just to recap, in Windsurf, GPT4.1 will",
      "offset": 1300.4,
      "duration": 6.48
    },
    {
      "lang": "en",
      "text": "be free, totally free for the next 7",
      "offset": 1304.559,
      "duration": 4.561
    },
    {
      "lang": "en",
      "text": "days and then going forward will be",
      "offset": 1306.88,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "heavily discounted for a while. That's",
      "offset": 1309.12,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "exactly right. Awesome. Amazing. I will",
      "offset": 1311.039,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "say uh this weekend my 8-year-old",
      "offset": 1313.28,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "decided he wanted to start selling Legos",
      "offset": 1315.2,
      "duration": 6.08
    },
    {
      "lang": "en",
      "text": "and so uh we opened up Wind Surf uh",
      "offset": 1317.76,
      "duration": 6.96
    },
    {
      "lang": "en",
      "text": "opened GPT4.1 and we vibecoded a Lego",
      "offset": 1321.28,
      "duration": 6.56
    },
    {
      "lang": "en",
      "text": "website for his uh his upcoming business",
      "offset": 1324.72,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "and it worked great. So uh you'll have",
      "offset": 1327.84,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "to send that over. Yeah, we'll we'll",
      "offset": 1330,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "post it with the live stream. I'm sure",
      "offset": 1331.84,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "everybody everybody is excited about it.",
      "offset": 1333.2,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "Um but thanks so much for joining us.",
      "offset": 1335.679,
      "duration": 3.441
    },
    {
      "lang": "en",
      "text": "We're super excited to see what what",
      "offset": 1337.44,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "people build in Windsurf and beyond. So",
      "offset": 1339.12,
      "duration": 5.679
    },
    {
      "lang": "en",
      "text": "that's today. We have a family of three",
      "offset": 1341.76,
      "duration": 6.88
    },
    {
      "lang": "en",
      "text": "models, GPT 4.1, GPT 4.1 Mini, and GPT",
      "offset": 1344.799,
      "duration": 8.161
    },
    {
      "lang": "en",
      "text": "4.1 Nano that are our smartest, fastest,",
      "offset": 1348.64,
      "duration": 6.88
    },
    {
      "lang": "en",
      "text": "cheapest uh models that we have ever",
      "offset": 1352.96,
      "duration": 5.92
    },
    {
      "lang": "en",
      "text": "built just in the API for developers. By",
      "offset": 1355.52,
      "duration": 6.72
    },
    {
      "lang": "en",
      "text": "the way, you can also fine-tune GPT 4.1",
      "offset": 1358.88,
      "duration": 6.56
    },
    {
      "lang": "en",
      "text": "and 4.1 Mini starting today, and Nano",
      "offset": 1362.24,
      "duration": 5.439
    },
    {
      "lang": "en",
      "text": "will be uh available to fine-tune in the",
      "offset": 1365.44,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "near future. I want to say a huge thank",
      "offset": 1367.679,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "you to Michelle, to Isan, and to their",
      "offset": 1370,
      "duration": 4.559
    },
    {
      "lang": "en",
      "text": "whole teams. These models are fantastic.",
      "offset": 1372.159,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "We're super excited to see what you all",
      "offset": 1374.559,
      "duration": 4.881
    },
    {
      "lang": "en",
      "text": "build. So, uh, that's it for today. Uh,",
      "offset": 1376.159,
      "duration": 5.841
    },
    {
      "lang": "en",
      "text": "these models are available now. Uh,",
      "offset": 1379.44,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "they're they're in the API. Please start",
      "offset": 1382,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "using them. We can't wait to see what",
      "offset": 1384.48,
      "duration": 2.24
    },
    {
      "lang": "en",
      "text": "you build, and we look forward to",
      "offset": 1385.76,
      "duration": 2.32
    },
    {
      "lang": "en",
      "text": "hearing your feedback. Thank you so",
      "offset": 1386.72,
      "duration": 4.36
    },
    {
      "lang": "en",
      "text": "much.",
      "offset": 1388.08,
      "duration": 3
    }
  ],
  "cleanText": null,
  "dumpedAt": "2025-07-21T18:43:25.059Z"
}