{
  "episodeId": "OfTR8g5iQZc",
  "channelSlug": "@startups",
  "title": "Orchestrating Smarter AI Systems with Yoav Shoham | AI Basics with Google Cloud",
  "publishedAt": "2025-07-10T14:51:57.000Z",
  "rawLines": [
    {
      "lang": "en",
      "text": "All",
      "offset": 0,
      "duration": 2
    },
    {
      "lang": "en",
      "text": "right, everybody. Welcome back to this",
      "offset": 4.24,
      "duration": 3.599
    },
    {
      "lang": "en",
      "text": "week in startups. It's time again for",
      "offset": 5.68,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "our AI basics series. What is this? Ah",
      "offset": 7.839,
      "duration": 5.441
    },
    {
      "lang": "en",
      "text": "man, founders ask us all the time the",
      "offset": 10.48,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "same questions over and over again. So",
      "offset": 13.28,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "we have done basics for legal. We've",
      "offset": 15.44,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "done it for marketing and growth",
      "offset": 18,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "tactics, obviously accounting, and here",
      "offset": 19.84,
      "duration": 5.279
    },
    {
      "lang": "en",
      "text": "we are in the age of AI. People need to",
      "offset": 22.32,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "understand the best practices. And hey,",
      "offset": 25.119,
      "duration": 5.361
    },
    {
      "lang": "en",
      "text": "it's moving pretty quickly. If you want",
      "offset": 27.68,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "to get caught up on your AI basics, go",
      "offset": 30.48,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "ahead and download this fantastic report",
      "offset": 33.68,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "by our partner Google Cloud. It's called",
      "offset": 35.6,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "the future of AI perspectives for",
      "offset": 37.76,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "startups featuring insights from 23 top",
      "offset": 39.68,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "AI experts. And today, one of them is",
      "offset": 42.64,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "with us. Yo Shawam is here. He's a",
      "offset": 45.12,
      "duration": 5.279
    },
    {
      "lang": "en",
      "text": "Stanford professor, ameritus as you",
      "offset": 47.84,
      "duration": 6.239
    },
    {
      "lang": "en",
      "text": "know, and he is the co-founder of AI21",
      "offset": 50.399,
      "duration": 6.48
    },
    {
      "lang": "en",
      "text": "Labs, uh, the team behind Jurassic 2 and",
      "offset": 54.079,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "word tune, building large language",
      "offset": 56.879,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "models and tools for collaborative",
      "offset": 59.199,
      "duration": 4.481
    },
    {
      "lang": "en",
      "text": "reasoning. Welcome to the show, Y.",
      "offset": 60.96,
      "duration": 4.479
    },
    {
      "lang": "en",
      "text": "Fun to be here. Thanks for having me.",
      "offset": 63.68,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "Let's talk a little bit about what we",
      "offset": 65.439,
      "duration": 4.961
    },
    {
      "lang": "en",
      "text": "mean by reasoning, you know, here in",
      "offset": 67.36,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "2025.",
      "offset": 70.4,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "Are these machines actually reasoning?",
      "offset": 71.92,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "and how do you get the best out of them?",
      "offset": 74.4,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "Right now, so many experiments going on",
      "offset": 77.28,
      "duration": 4.879
    },
    {
      "lang": "en",
      "text": "in corporate America. So many people are",
      "offset": 79.84,
      "duration": 5.279
    },
    {
      "lang": "en",
      "text": "testing and starting to deploy AI",
      "offset": 82.159,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "technology from large language models or",
      "offset": 85.119,
      "duration": 4.881
    },
    {
      "lang": "en",
      "text": "with the basis of large language models.",
      "offset": 87.439,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "But there is some concern about the",
      "offset": 90,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "reasoning are these making the best",
      "offset": 91.6,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "decisions, hallucinations, etc. So what",
      "offset": 93.28,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "what is the state today? And maybe tell",
      "offset": 95.52,
      "duration": 4.239
    },
    {
      "lang": "en",
      "text": "us a little bit about your company AI21",
      "offset": 97.439,
      "duration": 2.72
    },
    {
      "lang": "en",
      "text": "Labs.",
      "offset": 99.759,
      "duration": 2.32
    },
    {
      "lang": "en",
      "text": "Maybe I'll start with the letter AI21",
      "offset": 100.159,
      "duration": 5.121
    },
    {
      "lang": "en",
      "text": "Labs. It's about uh 7 years old. We",
      "offset": 102.079,
      "duration": 6.801
    },
    {
      "lang": "en",
      "text": "definitely one of the uh main LLM",
      "offset": 105.28,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "builders although we took a slightly",
      "offset": 108.88,
      "duration": 4.559
    },
    {
      "lang": "en",
      "text": "different tack than most people recently",
      "offset": 110.96,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "with our Jamba family which is not a",
      "offset": 113.439,
      "duration": 5.201
    },
    {
      "lang": "en",
      "text": "pure transformer architecture for",
      "offset": 115.36,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "efficiency reasons and we can speak",
      "offset": 118.64,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "about that. Most of our effort now is",
      "offset": 120.24,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "around uh orchestration and planning of",
      "offset": 122.479,
      "duration": 6.48
    },
    {
      "lang": "en",
      "text": "these complex AI systems in clicker a",
      "offset": 125.6,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "product we call maestro which we",
      "offset": 128.959,
      "duration": 4.961
    },
    {
      "lang": "en",
      "text": "released but if that's directly relevant",
      "offset": 130.56,
      "duration": 6.96
    },
    {
      "lang": "en",
      "text": "to your question Jason about so you know",
      "offset": 133.92,
      "duration": 7.039
    },
    {
      "lang": "en",
      "text": "we in AI uh are guilty of using terms",
      "offset": 137.52,
      "duration": 5.439
    },
    {
      "lang": "en",
      "text": "that are so illdefined that they come",
      "offset": 140.959,
      "duration": 4.801
    },
    {
      "lang": "en",
      "text": "back to bite us and we can we can draw a",
      "offset": 142.959,
      "duration": 5.92
    },
    {
      "lang": "en",
      "text": "long list from AGI to agents to to",
      "offset": 145.76,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "reasoning but if",
      "offset": 148.879,
      "duration": 4.481
    },
    {
      "lang": "en",
      "text": "step back from the actual terms. The",
      "offset": 150.8,
      "duration": 4.719
    },
    {
      "lang": "en",
      "text": "issue as you pointed out in the",
      "offset": 153.36,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "enterprise is that there's a ton of",
      "offset": 155.519,
      "duration": 4.881
    },
    {
      "lang": "en",
      "text": "experimentation. Like two years ago,",
      "offset": 158,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "nobody paid attention. Maybe three years",
      "offset": 160.4,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "ago, you couldn't get a CEO or or you",
      "offset": 162.08,
      "duration": 4.879
    },
    {
      "lang": "en",
      "text": "know a chief innovation officer to pay",
      "offset": 165.12,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "attention. Now everybody's on top of",
      "offset": 166.959,
      "duration": 4.801
    },
    {
      "lang": "en",
      "text": "that. But for all the hundreds of use",
      "offset": 169.12,
      "duration": 4.479
    },
    {
      "lang": "en",
      "text": "cases in a given company that you see,",
      "offset": 171.76,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "the number of deployments is very small.",
      "offset": 173.599,
      "duration": 5.201
    },
    {
      "lang": "en",
      "text": "And the main reason is the issue of well",
      "offset": 175.68,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "there many reasons issues of compliance",
      "offset": 178.8,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "and safety and you know use cases new",
      "offset": 180.72,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "technology and it's all good but the",
      "offset": 183.2,
      "duration": 5.759
    },
    {
      "lang": "en",
      "text": "main reason is reliability and uh again",
      "offset": 185.12,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "the term hallucination maybe not the",
      "offset": 188.959,
      "duration": 3.441
    },
    {
      "lang": "en",
      "text": "best terms but these are probabistic",
      "offset": 190.48,
      "duration": 6.08
    },
    {
      "lang": "en",
      "text": "machines and um they're for sometimes",
      "offset": 192.4,
      "duration": 7.759
    },
    {
      "lang": "en",
      "text": "often they'll give you brilliant output",
      "offset": 196.56,
      "duration": 5.679
    },
    {
      "lang": "en",
      "text": "but if you're brilliant 95% of the time",
      "offset": 200.159,
      "duration": 4.241
    },
    {
      "lang": "en",
      "text": "and not just wrong but total garbage 5%",
      "offset": 202.239,
      "duration": 4.481
    },
    {
      "lang": "en",
      "text": "of the And that may be okay in consumer",
      "offset": 204.4,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "land but not in the enterprise. And so",
      "offset": 206.72,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "there are many studies that show that",
      "offset": 208.56,
      "duration": 5.679
    },
    {
      "lang": "en",
      "text": "the ratio of experiments in the",
      "offset": 210.48,
      "duration": 7.759
    },
    {
      "lang": "en",
      "text": "enterprise deployments is like 10 to1 20",
      "offset": 214.239,
      "duration": 4.961
    },
    {
      "lang": "en",
      "text": "to1",
      "offset": 218.239,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "and so that is super relevant. What it",
      "offset": 219.2,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "means is there's an enthusiasm for the",
      "offset": 221.599,
      "duration": 6.081
    },
    {
      "lang": "en",
      "text": "technology. But when it comes to mission",
      "offset": 223.84,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "critical applications, if you're doing",
      "offset": 227.68,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "something in accounting, if you're doing",
      "offset": 229.2,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "customer support, uh obviously if you're",
      "offset": 231.12,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "a developer and you're pushing code to a",
      "offset": 233.36,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "server, it needs to be a lot more",
      "offset": 235.36,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "reliable and and that's why humans are",
      "offset": 237.519,
      "duration": 4.561
    },
    {
      "lang": "en",
      "text": "in the loop. But with my show, I think",
      "offset": 239.36,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "the concept, and you'll correct me here",
      "offset": 242.08,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "if I'm wrong, is we have many different",
      "offset": 243.519,
      "duration": 5.201
    },
    {
      "lang": "en",
      "text": "LLMs and having them, as crazy as it",
      "offset": 245.76,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "sounds, work in concert with each other.",
      "offset": 248.72,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "Interesting concert my show. Um, and",
      "offset": 251.28,
      "duration": 5.519
    },
    {
      "lang": "en",
      "text": "having them check each other's work,",
      "offset": 254.4,
      "duration": 6.88
    },
    {
      "lang": "en",
      "text": "maybe trying to get them to um justify",
      "offset": 256.799,
      "duration": 8.321
    },
    {
      "lang": "en",
      "text": "their answer as it were, can result in",
      "offset": 261.28,
      "duration": 6.08
    },
    {
      "lang": "en",
      "text": "better output and more reliable systems.",
      "offset": 265.12,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "Correct. uh largely yes. Uh let me let",
      "offset": 267.36,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "me nuance this",
      "offset": 270.8,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "please. So some would like to take the",
      "offset": 272.32,
      "duration": 6.64
    },
    {
      "lang": "en",
      "text": "the LLM or as the new version of them",
      "offset": 275.199,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "sometime called LRN large reasoning",
      "offset": 278.96,
      "duration": 4.799
    },
    {
      "lang": "en",
      "text": "models which is really a misnomer but",
      "offset": 281.199,
      "duration": 6.321
    },
    {
      "lang": "en",
      "text": "system like you know 01 03 R1 and try to",
      "offset": 283.759,
      "duration": 6.561
    },
    {
      "lang": "en",
      "text": "get them to behave through guard rails",
      "offset": 287.52,
      "duration": 4.959
    },
    {
      "lang": "en",
      "text": "and alignment efforts and everything and",
      "offset": 290.32,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "all that's good to do and we do that but",
      "offset": 292.479,
      "duration": 5.041
    },
    {
      "lang": "en",
      "text": "that will never iron out the uh the the",
      "offset": 294.88,
      "duration": 6.48
    },
    {
      "lang": "en",
      "text": "the uh the variance in the models and so",
      "offset": 297.52,
      "duration": 6.959
    },
    {
      "lang": "en",
      "text": "what you really need to do is to put",
      "offset": 301.36,
      "duration": 6.24
    },
    {
      "lang": "en",
      "text": "logic on the outside to orchestrate and",
      "offset": 304.479,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "it's not just a matter of routing",
      "offset": 307.6,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "between you know this LLM or that LLM",
      "offset": 309.919,
      "duration": 5.201
    },
    {
      "lang": "en",
      "text": "sometimes you run code sometimes you use",
      "offset": 312.88,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "a tool you know you'll access a database",
      "offset": 315.12,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "you'll call you know a weather API what",
      "offset": 317.28,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "have you and something need to",
      "offset": 319.68,
      "duration": 2.959
    },
    {
      "lang": "en",
      "text": "orchestrate all of that and you're asked",
      "offset": 321.28,
      "duration": 3.759
    },
    {
      "lang": "en",
      "text": "to if you're right that you want to do",
      "offset": 322.639,
      "duration": 5.041
    },
    {
      "lang": "en",
      "text": "not only system testing but unit testing",
      "offset": 325.039,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "so every step of the way you have an",
      "offset": 327.68,
      "duration": 3.359
    },
    {
      "lang": "en",
      "text": "explicit plan and every step of the way",
      "offset": 329.199,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "you want to as well as as best you can",
      "offset": 331.039,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "validate how well you're doing. And",
      "offset": 333.919,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "sometimes you'll do it with the language",
      "offset": 337.039,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "models, what's called judge language",
      "offset": 339.199,
      "duration": 3.521
    },
    {
      "lang": "en",
      "text": "model. And often you'll just, for",
      "offset": 341.12,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "example, you want an output to be 6 to",
      "offset": 342.72,
      "duration": 6.64
    },
    {
      "lang": "en",
      "text": "800 words long. Just do the do the damn",
      "offset": 345.68,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "counting.",
      "offset": 349.36,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "Let's talk about agents specifically.",
      "offset": 350.16,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "This promise has captured people's",
      "offset": 353.36,
      "duration": 5.279
    },
    {
      "lang": "en",
      "text": "imagination because agents feel like a",
      "offset": 355.12,
      "duration": 6.72
    },
    {
      "lang": "en",
      "text": "way for humans to stop doing chores.",
      "offset": 358.639,
      "duration": 4.881
    },
    {
      "lang": "en",
      "text": "So much of what we do when we go to",
      "offset": 361.84,
      "duration": 4.639
    },
    {
      "lang": "en",
      "text": "work, when we try to build a business is",
      "offset": 363.52,
      "duration": 4.799
    },
    {
      "lang": "en",
      "text": "uh the actual product and the service",
      "offset": 366.479,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "we're providing to people. But we all",
      "offset": 368.319,
      "duration": 5.121
    },
    {
      "lang": "en",
      "text": "have to do our chores and cleaning stuff",
      "offset": 370.8,
      "duration": 6.959
    },
    {
      "lang": "en",
      "text": "up, normalizing data, just work that",
      "offset": 373.44,
      "duration": 7.039
    },
    {
      "lang": "en",
      "text": "humans find monotonous. Most humans and",
      "offset": 377.759,
      "duration": 5.201
    },
    {
      "lang": "en",
      "text": "they don't like to do uh digging dishes",
      "offset": 380.479,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "like the agents feel like the proper",
      "offset": 382.96,
      "duration": 6.799
    },
    {
      "lang": "en",
      "text": "solution for those. How close are we to",
      "offset": 385.919,
      "duration": 7.12
    },
    {
      "lang": "en",
      "text": "having agents at scale doing these",
      "offset": 389.759,
      "duration": 6.481
    },
    {
      "lang": "en",
      "text": "repetitive tasks? How often are people",
      "offset": 393.039,
      "duration": 6.481
    },
    {
      "lang": "en",
      "text": "actually building an agent that is in",
      "offset": 396.24,
      "duration": 5.92
    },
    {
      "lang": "en",
      "text": "2025 when we're recording this getting",
      "offset": 399.52,
      "duration": 5.519
    },
    {
      "lang": "en",
      "text": "the chore done reliably enough that",
      "offset": 402.16,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "humans can forget about that chore? Your",
      "offset": 405.039,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "mileage varies depends on the sore and",
      "offset": 407.52,
      "duration": 5.92
    },
    {
      "lang": "en",
      "text": "depend on the quote unquote agent. The",
      "offset": 411.039,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "problem is that people have been using",
      "offset": 413.44,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "the term agent now. It's so seductive",
      "offset": 414.88,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "for anything that smacks of any kind of",
      "offset": 417.44,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "automation and it'll come back to bite",
      "offset": 419.44,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "us. I call this agent washing. And so",
      "offset": 422.24,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "you're absolutely right that the biggest",
      "offset": 424.96,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "bang for the buck is when you try to get",
      "offset": 426.96,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "the technology to take care of fairly",
      "offset": 429.039,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "simple, fairly mundane stuff kind of",
      "offset": 431.68,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "like robotic process process automation",
      "offset": 433.919,
      "duration": 5.601
    },
    {
      "lang": "en",
      "text": "on steroids. So more and more stuff can",
      "offset": 436.72,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "be automated. Is that an agent or is",
      "offset": 439.52,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "this simply a program that you wrote",
      "offset": 442,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "that maybe use an LLM? Uh we don't need",
      "offset": 444.88,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "to get anal about the definition. But",
      "offset": 447.36,
      "duration": 4.959
    },
    {
      "lang": "en",
      "text": "typically when we speak about agents,",
      "offset": 450.24,
      "duration": 4.239
    },
    {
      "lang": "en",
      "text": "what do we have in mind? We have in mind",
      "offset": 452.319,
      "duration": 4.481
    },
    {
      "lang": "en",
      "text": "a system that's not a transactional call",
      "offset": 454.479,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "to an LLM. There's something that's more",
      "offset": 456.8,
      "duration": 6.399
    },
    {
      "lang": "en",
      "text": "ongoing. There's uh the AI system, the",
      "offset": 459.039,
      "duration": 6.72
    },
    {
      "lang": "en",
      "text": "agent can be proactive, not just respond",
      "offset": 463.199,
      "duration": 5.361
    },
    {
      "lang": "en",
      "text": "to our prompt. It takes uh it it",
      "offset": 465.759,
      "duration": 5.921
    },
    {
      "lang": "en",
      "text": "executes complicated flows, not just",
      "offset": 468.56,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "like a onestep thing. It uses multiple",
      "offset": 471.68,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "tools.",
      "offset": 474.24,
      "duration": 5.92
    },
    {
      "lang": "en",
      "text": "And as you do this, it gets diceier",
      "offset": 475.759,
      "duration": 7.521
    },
    {
      "lang": "en",
      "text": "because if a single call to an LLM",
      "offset": 480.16,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "carries some uncertainty, when you start",
      "offset": 483.28,
      "duration": 5.359
    },
    {
      "lang": "en",
      "text": "to compose them, at some point you get",
      "offset": 485.68,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "more uh noise and signal. And that's",
      "offset": 488.639,
      "duration": 6.24
    },
    {
      "lang": "en",
      "text": "where I think uh maybe some people are",
      "offset": 491.68,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "getting a little ahead of ahead of",
      "offset": 494.879,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "themselves. So simple road repetitive",
      "offset": 496.16,
      "duration": 5.439
    },
    {
      "lang": "en",
      "text": "stuff. Yes. More complicated stuff we we",
      "offset": 498.72,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "have work to do. It seems like there's",
      "offset": 501.599,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "been an investment in smaller more",
      "offset": 503.12,
      "duration": 5.199
    },
    {
      "lang": "en",
      "text": "narrow models. And some debate about",
      "offset": 505.28,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "that. Some people believe the large",
      "offset": 508.319,
      "duration": 3.041
    },
    {
      "lang": "en",
      "text": "models will figure it all out",
      "offset": 510,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "eventually. Other people think, hey, why",
      "offset": 511.36,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "not make a smaller model faster,",
      "offset": 513.68,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "cheaper, better, and uh more",
      "offset": 515.279,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "constrained. Maybe you could talk about",
      "offset": 517.839,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "the state of SMLS. I think the short",
      "offset": 519.12,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "answer is in consumer ad if you're",
      "offset": 522.159,
      "duration": 5.921
    },
    {
      "lang": "en",
      "text": "looking for a very general purpose chat",
      "offset": 524.8,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "let's call call a spade a spade a chat",
      "offset": 528.08,
      "duration": 6.16
    },
    {
      "lang": "en",
      "text": "GPT like uh experience there's probably",
      "offset": 530.48,
      "duration": 6.4
    },
    {
      "lang": "en",
      "text": "no replacement for a very large language",
      "offset": 534.24,
      "duration": 6.48
    },
    {
      "lang": "en",
      "text": "model that is being tuned to cover a",
      "offset": 536.88,
      "duration": 6.56
    },
    {
      "lang": "en",
      "text": "huge variety of cases because you can't",
      "offset": 540.72,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "anticipate the variety of input you get",
      "offset": 543.44,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "from consumers as you go to the",
      "offset": 546,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "enterprise and your needs are much more",
      "offset": 548.48,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "narrower There's several reasons to go",
      "offset": 550.64,
      "duration": 6.48
    },
    {
      "lang": "en",
      "text": "narrow. First of all is is just u um uh",
      "offset": 552.72,
      "duration": 6.799
    },
    {
      "lang": "en",
      "text": "cost. It's it's cost not only in terms",
      "offset": 557.12,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "of dollars but also latency. And so you",
      "offset": 559.519,
      "duration": 5.521
    },
    {
      "lang": "en",
      "text": "know uh and as you know we uh came up",
      "offset": 562.48,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "with this new family of models called",
      "offset": 565.04,
      "duration": 4.799
    },
    {
      "lang": "en",
      "text": "Jamba that is a hybrid statebased model",
      "offset": 566.48,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "and transformer that in terms of the",
      "offset": 569.839,
      "duration": 4.881
    },
    {
      "lang": "en",
      "text": "quality of the anterior you you you get",
      "offset": 572.48,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "it's competitive with the most models.",
      "offset": 574.72,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "in terms of latency and memory footprint",
      "offset": 577.44,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "there's just no comparison especially as",
      "offset": 580,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "the input as so-called the context",
      "offset": 582.24,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "length increases that kills you the",
      "offset": 583.92,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "transformer architecture",
      "offset": 586.399,
      "duration": 5.601
    },
    {
      "lang": "en",
      "text": "this is what you know 2017 uh the famous",
      "offset": 588.72,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "paper from Google thank you Google",
      "offset": 592,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "really moved the needle suddenly stuff",
      "offset": 594.48,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "happened in language that hadn't",
      "offset": 596.32,
      "duration": 3.519
    },
    {
      "lang": "en",
      "text": "happened before which did happen in",
      "offset": 598.08,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "vision and the reason is that the",
      "offset": 599.839,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "attention mechanism transformer allows",
      "offset": 601.36,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "you to as at the term suggest tend to",
      "offset": 603.519,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "very disperate part of the input. In",
      "offset": 606.16,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "vision, it doesn't so much matter if you",
      "offset": 608.399,
      "duration": 5.201
    },
    {
      "lang": "en",
      "text": "know to know that this here is a uh you",
      "offset": 610.8,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "know is a phone doesn't really matter",
      "offset": 613.6,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "what the pixel way over to the side is.",
      "offset": 615.68,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "But in language, there's nothing local.",
      "offset": 617.76,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "So that made the difference. Problem is",
      "offset": 619.6,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "that it's expensive. It's a quadratic",
      "offset": 621.36,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "complexity in the input or the context",
      "offset": 623.92,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "length as we call it. Now when we had",
      "offset": 625.6,
      "duration": 6.16
    },
    {
      "lang": "en",
      "text": "input of a,000,000 squared is fine, but",
      "offset": 628.24,
      "duration": 5.039
    },
    {
      "lang": "en",
      "text": "we're now pushing a million. A million",
      "offset": 631.76,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "squared is not fine. And so you need to",
      "offset": 633.279,
      "duration": 5.041
    },
    {
      "lang": "en",
      "text": "deal with that. Part of it is smaller",
      "offset": 635.44,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "language models that doesn't quite deal",
      "offset": 638.32,
      "duration": 5.759
    },
    {
      "lang": "en",
      "text": "with the context length side of things.",
      "offset": 640.64,
      "duration": 6.16
    },
    {
      "lang": "en",
      "text": "But then rethinking the architecture. So",
      "offset": 644.079,
      "duration": 4.641
    },
    {
      "lang": "en",
      "text": "the space model which is inherently",
      "offset": 646.8,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "linear and not quadratic and mixing it",
      "offset": 648.72,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "just a little bit transformer gives you",
      "offset": 651.04,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "the best of both worlds. What about",
      "offset": 652.8,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "verticalization of knowledge? Is there a",
      "offset": 654.56,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "movement to say, hey, this small",
      "offset": 657.2,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "language model is going to focus really",
      "offset": 659.92,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "on accounting to just put it in business",
      "offset": 662,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "uh categories. This one is just really",
      "offset": 665.2,
      "duration": 7.12
    },
    {
      "lang": "en",
      "text": "amazing at legal concepts. And you know",
      "offset": 668,
      "duration": 6.56
    },
    {
      "lang": "en",
      "text": "that when you throw this legal brief",
      "offset": 672.32,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "into it or on the accounting side, you",
      "offset": 674.56,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "throw this RFP into it, these are huge",
      "offset": 676.399,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "contact windows dumping cases of case",
      "offset": 679.04,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "law and trying to process them. Is it",
      "offset": 681.519,
      "duration": 5.361
    },
    {
      "lang": "en",
      "text": "just about the the speed and the cost or",
      "offset": 683.92,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "is it also about the accuracy because",
      "offset": 686.88,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "the model has been constrained to not",
      "offset": 689.2,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "have to worry about oh all the movies",
      "offset": 691.6,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "and songs ever written in the world and",
      "offset": 693.279,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "every blog post about those songs and",
      "offset": 695.04,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "music in the world. Is it actually going",
      "offset": 697.12,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "to result in a higher fidelity of",
      "offset": 699.36,
      "duration": 2.56
    },
    {
      "lang": "en",
      "text": "content?",
      "offset": 701.36,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "Short answer, yes. Uh long I'm sorry I'm",
      "offset": 701.92,
      "duration": 6.32
    },
    {
      "lang": "en",
      "text": "always nuanced. Uh but the longer answer",
      "offset": 705.279,
      "duration": 6.321
    },
    {
      "lang": "en",
      "text": "is that there's some general common",
      "offset": 708.24,
      "duration": 6.719
    },
    {
      "lang": "en",
      "text": "sense that the baseline model has",
      "offset": 711.6,
      "duration": 5.919
    },
    {
      "lang": "en",
      "text": "learned that you want to retain even if",
      "offset": 714.959,
      "duration": 5.841
    },
    {
      "lang": "en",
      "text": "it's just uh you know mastering correct",
      "offset": 717.519,
      "duration": 5.601
    },
    {
      "lang": "en",
      "text": "uh English you know language you know",
      "offset": 720.8,
      "duration": 6.64
    },
    {
      "lang": "en",
      "text": "grammar and so as you attain more uh",
      "offset": 723.12,
      "duration": 6.8
    },
    {
      "lang": "en",
      "text": "domain specific language it's okay to",
      "offset": 727.44,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "forget certain things but not others. So",
      "offset": 729.92,
      "duration": 6.719
    },
    {
      "lang": "en",
      "text": "the art here is to just remember the",
      "offset": 732.56,
      "duration": 4.719
    },
    {
      "lang": "en",
      "text": "right stuff.",
      "offset": 736.639,
      "duration": 2.961
    },
    {
      "lang": "en",
      "text": "Let's talk a little bit about agentto",
      "offset": 737.279,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "agent protocols. For people who don't",
      "offset": 739.6,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "know, A2A is a protocol for",
      "offset": 740.959,
      "duration": 5.281
    },
    {
      "lang": "en",
      "text": "interoperability between agents. You",
      "offset": 743.76,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "know, technologists are always looking",
      "offset": 746.24,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "at what's around the corner. If you do",
      "offset": 747.92,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "get your agents working well, let's say",
      "offset": 749.92,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "the accounting department agent doing",
      "offset": 752.16,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "purchase orders and paying bills, uh",
      "offset": 754.48,
      "duration": 5.359
    },
    {
      "lang": "en",
      "text": "eventually you might want that agent to",
      "offset": 757.2,
      "duration": 5.199
    },
    {
      "lang": "en",
      "text": "interact between companies, maybe to put",
      "offset": 759.839,
      "duration": 5.361
    },
    {
      "lang": "en",
      "text": "an RFP out to get five companies to bid",
      "offset": 762.399,
      "duration": 5.601
    },
    {
      "lang": "en",
      "text": "for, I don't know, the new shed you're",
      "offset": 765.2,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "building, uh or the new uh software that",
      "offset": 768,
      "duration": 6.399
    },
    {
      "lang": "en",
      "text": "you want written. And agentto agent",
      "offset": 770.88,
      "duration": 6.88
    },
    {
      "lang": "en",
      "text": "protocol is going to solve for that.",
      "offset": 774.399,
      "duration": 5.921
    },
    {
      "lang": "en",
      "text": "This is we're talking within the last 60",
      "offset": 777.76,
      "duration": 5.84
    },
    {
      "lang": "en",
      "text": "90 days this stuff is all starting to be",
      "offset": 780.32,
      "duration": 5.199
    },
    {
      "lang": "en",
      "text": "publicly released by Google other",
      "offset": 783.6,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "players and we're starting to see some",
      "offset": 785.519,
      "duration": 6.641
    },
    {
      "lang": "en",
      "text": "consensus from different technology",
      "offset": 789.2,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "companies and data sources that this is",
      "offset": 792.16,
      "duration": 4.479
    },
    {
      "lang": "en",
      "text": "the next big thing. Is anybody actually",
      "offset": 794.48,
      "duration": 4.479
    },
    {
      "lang": "en",
      "text": "got this in deployment now in your",
      "offset": 796.639,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "experience? What are the early results",
      "offset": 798.959,
      "duration": 4.241
    },
    {
      "lang": "en",
      "text": "like? What are people thinking this will",
      "offset": 801.04,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "do? No, I think it's too early for",
      "offset": 803.2,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "anything to have been in production even",
      "offset": 805.6,
      "duration": 5.039
    },
    {
      "lang": "en",
      "text": "in the ideal scenario. So this is not a",
      "offset": 807.92,
      "duration": 5.359
    },
    {
      "lang": "en",
      "text": "knock on A2A just too early. So first of",
      "offset": 810.639,
      "duration": 4.481
    },
    {
      "lang": "en",
      "text": "all, I think kudo to Google for",
      "offset": 813.279,
      "duration": 4.481
    },
    {
      "lang": "en",
      "text": "shephering this and a good start, but",
      "offset": 815.12,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "it's just a start and we have to realize",
      "offset": 817.76,
      "duration": 5.92
    },
    {
      "lang": "en",
      "text": "the limitations. So the vision that",
      "offset": 820.24,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "there's several things that I think",
      "offset": 823.68,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "excite people when they hear about",
      "offset": 825.2,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "multiple agents coordinating. Part of it",
      "offset": 826.8,
      "duration": 5.279
    },
    {
      "lang": "en",
      "text": "is the something from nothing. uh oh, I",
      "offset": 829.04,
      "duration": 4.239
    },
    {
      "lang": "en",
      "text": "don't need to think hard about the",
      "offset": 832.079,
      "duration": 3.361
    },
    {
      "lang": "en",
      "text": "problem. I'll just build a bunch myself.",
      "offset": 833.279,
      "duration": 4.881
    },
    {
      "lang": "en",
      "text": "We'll build a bunch of agents and then",
      "offset": 835.44,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "magic will happen when they come",
      "offset": 838.16,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "together. That historically uh has led",
      "offset": 839.519,
      "duration": 5.201
    },
    {
      "lang": "en",
      "text": "to disappointment. Often the magic isn't",
      "offset": 842.24,
      "duration": 6.959
    },
    {
      "lang": "en",
      "text": "the glue. It's good to compartmentalize",
      "offset": 844.72,
      "duration": 6.64
    },
    {
      "lang": "en",
      "text": "and and factor things out. That's always",
      "offset": 849.199,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "a good, but often the magic is how you",
      "offset": 851.36,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "put together things, what the algorithm",
      "offset": 854.399,
      "duration": 6.161
    },
    {
      "lang": "en",
      "text": "is. But I think as you said the promise",
      "offset": 856.88,
      "duration": 5.92
    },
    {
      "lang": "en",
      "text": "is that it's not only my agent speaking",
      "offset": 860.56,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "to my agents, it's my agents speaking to",
      "offset": 862.8,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "other agents in my company but that I",
      "offset": 865.12,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "didn't build but also outside my",
      "offset": 868.16,
      "duration": 6.479
    },
    {
      "lang": "en",
      "text": "company. And here uh I think um uh not",
      "offset": 869.92,
      "duration": 7.279
    },
    {
      "lang": "en",
      "text": "so fast. Uh there are two fundamental",
      "offset": 874.639,
      "duration": 5.521
    },
    {
      "lang": "en",
      "text": "problems. one is if you look at the",
      "offset": 877.199,
      "duration": 4.481
    },
    {
      "lang": "en",
      "text": "protocol",
      "offset": 880.16,
      "duration": 5.84
    },
    {
      "lang": "en",
      "text": "it's um there's a uh a a a a part of",
      "offset": 881.68,
      "duration": 7.2
    },
    {
      "lang": "en",
      "text": "what the agent communicates in JSON",
      "offset": 886,
      "duration": 5.92
    },
    {
      "lang": "en",
      "text": "which is its capabilities uh and other",
      "offset": 888.88,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "stuff where you know the contract it",
      "offset": 891.92,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "does with other agents. The problem is",
      "offset": 894.24,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "it's it specifies the syntax but not the",
      "offset": 896.56,
      "duration": 6.079
    },
    {
      "lang": "en",
      "text": "semantic not the meaning and that",
      "offset": 900.24,
      "duration": 5.599
    },
    {
      "lang": "en",
      "text": "historically has been the pitfall of",
      "offset": 902.639,
      "duration": 6.241
    },
    {
      "lang": "en",
      "text": "distributed object systems that objects",
      "offset": 905.839,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "advertise their capabilities but there's",
      "offset": 908.88,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "no reason for me to for my agent to",
      "offset": 911.199,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "understand what you meant when you put",
      "offset": 913.199,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "in language I know how to find uh you",
      "offset": 914.8,
      "duration": 5.599
    },
    {
      "lang": "en",
      "text": "know good flights well what is good",
      "offset": 918.399,
      "duration": 4.721
    },
    {
      "lang": "en",
      "text": "flights is it mean efficient time you",
      "offset": 920.399,
      "duration": 4.961
    },
    {
      "lang": "en",
      "text": "know so when you share semantics it can",
      "offset": 923.12,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "be done, but it's a big undertaking.",
      "offset": 925.36,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "It's a community kind of activity.",
      "offset": 928.16,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "That's number one. Number two is shared",
      "offset": 929.76,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "incentives. if you go outside the",
      "offset": 932,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "boundaries of even my own unit in",
      "offset": 933.839,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "company because we don't always share",
      "offset": 937.68,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "the same incentives even if we're in you",
      "offset": 939.519,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "know the same company but let alone so",
      "offset": 941.12,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "for example if I'm looking I have an",
      "offset": 943.279,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "agent that's trying to put together an",
      "offset": 945.519,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "itinerary for me and book a flight and",
      "offset": 947.12,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "it's speaking with your agent and you're",
      "offset": 949.44,
      "duration": 5.92
    },
    {
      "lang": "en",
      "text": "maybe you know you know an agent of one",
      "offset": 952,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "of the companies we do not have the same",
      "offset": 955.36,
      "duration": 6.399
    },
    {
      "lang": "en",
      "text": "incentive and so you need to put in some",
      "offset": 957.6,
      "duration": 6.56
    },
    {
      "lang": "en",
      "text": "control for that and actually so I I",
      "offset": 961.759,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "spent in my you know wearing my academic",
      "offset": 964.16,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "hat I spent a good fraction of my",
      "offset": 966.079,
      "duration": 4.241
    },
    {
      "lang": "en",
      "text": "academic work on on the area of multi-",
      "offset": 968.24,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "aent systems and in fact we have a a",
      "offset": 970.32,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "standard textbook in the area and a lot",
      "offset": 972.56,
      "duration": 4.959
    },
    {
      "lang": "en",
      "text": "of it has to do with crafting protocols",
      "offset": 975.12,
      "duration": 5.279
    },
    {
      "lang": "en",
      "text": "for multiple agents to get them to play",
      "offset": 977.519,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "nice together even though left to their",
      "offset": 980.399,
      "duration": 4.641
    },
    {
      "lang": "en",
      "text": "own devices they wouldn't a lot of game",
      "offset": 982.639,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "a lot a lot of game theory and stuff",
      "offset": 985.04,
      "duration": 2.56
    },
    {
      "lang": "en",
      "text": "like that",
      "offset": 987.04,
      "duration": 2.799
    },
    {
      "lang": "en",
      "text": "I mean if you think about what we went",
      "offset": 987.6,
      "duration": 4.239
    },
    {
      "lang": "en",
      "text": "through when we tried to have a semantic",
      "offset": 989.839,
      "duration": 5.841
    },
    {
      "lang": "en",
      "text": "web exist. Oh, hey, you're a a chef and",
      "offset": 991.839,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "you have a really silly example, but",
      "offset": 995.68,
      "duration": 3.519
    },
    {
      "lang": "en",
      "text": "you're putting your recipes online. We'd",
      "offset": 997.519,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "like you to make your recipe semantic.",
      "offset": 999.199,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "These are ingredients. These are steps,",
      "offset": 1001.199,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "you know, and and here's what the output",
      "offset": 1003.36,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "looks like and here's the original, you",
      "offset": 1004.959,
      "duration": 3.521
    },
    {
      "lang": "en",
      "text": "know, here's the temperature. We want",
      "offset": 1007.04,
      "duration": 2.799
    },
    {
      "lang": "en",
      "text": "all this stuff to be semantic. It was",
      "offset": 1008.48,
      "duration": 2.719
    },
    {
      "lang": "en",
      "text": "like, okay, yeah, I'll do all that for",
      "offset": 1009.839,
      "duration": 2.8
    },
    {
      "lang": "en",
      "text": "you. And then, you know, a bunch of",
      "offset": 1011.199,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "people just scrape all your recipes and",
      "offset": 1012.639,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "uh you get less traffic to your website.",
      "offset": 1015.04,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "Uh and the promise was, oh, I would get",
      "offset": 1017.839,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "more traffic. people would search for",
      "offset": 1019.92,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "these three ingredients and you know my",
      "offset": 1021.519,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "recipe might come up. So the devil is in",
      "offset": 1023.36,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "the details there and you know thinking",
      "offset": 1024.959,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "it through is critical. Let's end on",
      "offset": 1026.72,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "this. What's hyped? What's overhyped?",
      "offset": 1028.559,
      "duration": 2.88
    },
    {
      "lang": "en",
      "text": "You got a lot of founders listening here",
      "offset": 1030.16,
      "duration": 2.639
    },
    {
      "lang": "en",
      "text": "on this weekend startups. They're",
      "offset": 1031.439,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "building stuff. What's something they",
      "offset": 1032.799,
      "duration": 4.961
    },
    {
      "lang": "en",
      "text": "should be doing now that's obvious and",
      "offset": 1035.12,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "going to pay dividends for their",
      "offset": 1037.76,
      "duration": 4.799
    },
    {
      "lang": "en",
      "text": "startup. What are things that hey maybe",
      "offset": 1039.52,
      "duration": 5.279
    },
    {
      "lang": "en",
      "text": "agent to agent falls into this category?",
      "offset": 1042.559,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "you could become aware of there's an",
      "offset": 1044.799,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "opportunity here, but it might be a bit",
      "offset": 1046.959,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "too early to get significant gains from",
      "offset": 1049.039,
      "duration": 4.481
    },
    {
      "lang": "en",
      "text": "it. Where where should they be focusing",
      "offset": 1051.28,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "their time and effort in your mind? A",
      "offset": 1053.52,
      "duration": 3.519
    },
    {
      "lang": "en",
      "text": "little presumptuous for me to give a",
      "offset": 1055.52,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "definitive answer because there's so",
      "offset": 1057.039,
      "duration": 3.121
    },
    {
      "lang": "en",
      "text": "many kind of degrees of freedom here,",
      "offset": 1058.64,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "but I think that if you look for the",
      "offset": 1060.16,
      "duration": 6.32
    },
    {
      "lang": "en",
      "text": "maybe underhyped opportunities, maybe",
      "offset": 1063.6,
      "duration": 5.439
    },
    {
      "lang": "en",
      "text": "I'll mention two. one is the boring",
      "offset": 1066.48,
      "duration": 6.72
    },
    {
      "lang": "en",
      "text": "stuff. You know, getting uh workflows to",
      "offset": 1069.039,
      "duration": 7.201
    },
    {
      "lang": "en",
      "text": "be reliable is and again I'm I'm I'm",
      "offset": 1073.2,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "thinking enterprise. This is kind of my",
      "offset": 1076.24,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "lens I put through.",
      "offset": 1078.48,
      "duration": 2.96
    },
    {
      "lang": "en",
      "text": "That is the biggest blocker in the",
      "offset": 1079.76,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "enterprise right now. Getting the uh",
      "offset": 1081.44,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "workflows to be reliable and customizing",
      "offset": 1084.08,
      "duration": 6.719
    },
    {
      "lang": "en",
      "text": "them per deployment. That's hard work.",
      "offset": 1086.16,
      "duration": 6.879
    },
    {
      "lang": "en",
      "text": "But that's where I think the real pain",
      "offset": 1090.799,
      "duration": 5.681
    },
    {
      "lang": "en",
      "text": "is. The thing is it's not sexy. uh if",
      "offset": 1093.039,
      "duration": 5.121
    },
    {
      "lang": "en",
      "text": "you give a demo that did something",
      "offset": 1096.48,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "amazing once or maybe many times uh",
      "offset": 1098.16,
      "duration": 5.759
    },
    {
      "lang": "en",
      "text": "that's sexy but it's not sexy to show",
      "offset": 1101.12,
      "duration": 5.679
    },
    {
      "lang": "en",
      "text": "that things don't fail but that's where",
      "offset": 1103.919,
      "duration": 4.481
    },
    {
      "lang": "en",
      "text": "the real value is so I think there",
      "offset": 1106.799,
      "duration": 3.521
    },
    {
      "lang": "en",
      "text": "there's that's where I you know one area",
      "offset": 1108.4,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "I would focus in the area where I don't",
      "offset": 1110.32,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "know that it's uh you know underhyped",
      "offset": 1113.52,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "but I think it's underserved is",
      "offset": 1116.08,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "education",
      "offset": 1117.76,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "you know I was there in the early days",
      "offset": 1119.28,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "of online courses uh you know Corsera",
      "offset": 1121.2,
      "duration": 5.599
    },
    {
      "lang": "en",
      "text": "and Udacity starting in my corridor at",
      "offset": 1124.4,
      "duration": 6.48
    },
    {
      "lang": "en",
      "text": "at uh at Stanford and um and you know I",
      "offset": 1126.799,
      "duration": 6.641
    },
    {
      "lang": "en",
      "text": "have a an online course on gay theory",
      "offset": 1130.88,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "that's been seen by over a million",
      "offset": 1133.44,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "people but it doesn't begin to scratch",
      "offset": 1134.799,
      "duration": 5.681
    },
    {
      "lang": "en",
      "text": "the surface of what the real opportunity",
      "offset": 1138.32,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "is in proactive",
      "offset": 1140.48,
      "duration": 7.52
    },
    {
      "lang": "en",
      "text": "uh per student uh teaching. The issue is",
      "offset": 1143.84,
      "duration": 6.64
    },
    {
      "lang": "en",
      "text": "not how to get chatpt out of the",
      "offset": 1148,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "classroom so people don't cheat. The",
      "offset": 1150.48,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "issue is how to get the technology in",
      "offset": 1152.32,
      "duration": 5.599
    },
    {
      "lang": "en",
      "text": "the classroom and rethink what education",
      "offset": 1155.44,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "is really about, how we do it right with",
      "offset": 1157.919,
      "duration": 4.961
    },
    {
      "lang": "en",
      "text": "technology. So, uh that's an area that I",
      "offset": 1160.48,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "would really like to see kind of",
      "offset": 1162.88,
      "duration": 2.64
    },
    {
      "lang": "en",
      "text": "blossom.",
      "offset": 1164.799,
      "duration": 3.521
    },
    {
      "lang": "en",
      "text": "It is um super interesting. The first",
      "offset": 1165.52,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "step was getting all those courses",
      "offset": 1168.32,
      "duration": 4.719
    },
    {
      "lang": "en",
      "text": "online and somebody who uh went to form",
      "offset": 1170,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "university, didn't quite hit the IVs, I",
      "offset": 1173.039,
      "duration": 4.241
    },
    {
      "lang": "en",
      "text": "was always jealous like what's going on,",
      "offset": 1175.52,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "you know, in at MIT at Stanford, like",
      "offset": 1177.28,
      "duration": 4.639
    },
    {
      "lang": "en",
      "text": "how different is it than my experience?",
      "offset": 1180,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "And uh I was feeling particularly under",
      "offset": 1181.919,
      "duration": 7.12
    },
    {
      "lang": "en",
      "text": "uh resourced in macroeconomics, right?",
      "offset": 1186,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "And I was like, I really want to",
      "offset": 1189.039,
      "duration": 2.801
    },
    {
      "lang": "en",
      "text": "understand this. And I just went to",
      "offset": 1190.4,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "YouTube and I found courses at Stanford,",
      "offset": 1191.84,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "MIT, and I watched the courses and I was",
      "offset": 1193.76,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "like, wow, this is like alchemy.",
      "offset": 1195.76,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "They're trying to figure out how",
      "offset": 1198.72,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "macroeconomics works. But the fact that",
      "offset": 1200.08,
      "duration": 6.56
    },
    {
      "lang": "en",
      "text": "it was available for free on YouTube,",
      "offset": 1203.039,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "the same course that people were paying",
      "offset": 1206.64,
      "duration": 5.279
    },
    {
      "lang": "en",
      "text": "and had to qualify to be in the 0.1% of",
      "offset": 1209.039,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "people on the planet to get there was",
      "offset": 1211.919,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "available for free. And now you imagine",
      "offset": 1213.36,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "if it was adaptive learning and you",
      "offset": 1215.76,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "could answer some questions up front and",
      "offset": 1218.32,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "then I said, \"Yeah, you know, you should",
      "offset": 1220.96,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "really start with this third video or",
      "offset": 1222.24,
      "duration": 4.559
    },
    {
      "lang": "en",
      "text": "actually you're not ready for the first",
      "offset": 1225.28,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "two videos. you should do this",
      "offset": 1226.799,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "pre-calculus and maybe have this",
      "offset": 1228.4,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "statistics course first before you get",
      "offset": 1230.4,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "in there. Learn some basics about",
      "offset": 1232.08,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "statistics so you can actually um",
      "offset": 1233.76,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "understand the material better. Man,",
      "offset": 1236.4,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "that would be so amazing to have it be",
      "offset": 1238.32,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "adaptive and not leave any cuz as a",
      "offset": 1240.64,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "professor you you wind up leaving some",
      "offset": 1243.28,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "students behind and at what fork in the",
      "offset": 1244.88,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "road did they get disengaged is always",
      "offset": 1247.44,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "the question. Yeah,",
      "offset": 1249.76,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "absolutely. You know it's it's typical",
      "offset": 1250.72,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "when a new technology comes comes on you",
      "offset": 1253.36,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "you try to use it the way you use the",
      "offset": 1255.76,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "old technology. So television initially",
      "offset": 1257.679,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "was televised radio and then you over",
      "offset": 1260,
      "duration": 5.039
    },
    {
      "lang": "en",
      "text": "time you understood what the medium was",
      "offset": 1263.039,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "really good for. I think it's the time",
      "offset": 1265.039,
      "duration": 5.361
    },
    {
      "lang": "en",
      "text": "is ripe now uh with you know the flat",
      "offset": 1266.88,
      "duration": 6.08
    },
    {
      "lang": "en",
      "text": "world and everybody has having access to",
      "offset": 1270.4,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "uh you know computers and networking to",
      "offset": 1272.96,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "get AI to do to rethink education. Yeah,",
      "offset": 1275.12,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "absolutely. And you think about the role",
      "offset": 1278,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "of professors creating courses, creating",
      "offset": 1279.76,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "quizzes, even you can go into any LLM",
      "offset": 1282.72,
      "duration": 5.839
    },
    {
      "lang": "en",
      "text": "today, ask it to take uh Great",
      "offset": 1285.76,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "Expectations, Charles Dickens, and give",
      "offset": 1288.559,
      "duration": 4.881
    },
    {
      "lang": "en",
      "text": "you a series of Q&A and be your coach,",
      "offset": 1290.48,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "and you just give it that tiny prompt,",
      "offset": 1293.44,
      "duration": 4.239
    },
    {
      "lang": "en",
      "text": "and you could sit there with your phone",
      "offset": 1295.52,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "and have a personalized tutor that you",
      "offset": 1297.679,
      "duration": 3.521
    },
    {
      "lang": "en",
      "text": "would have had to spend, you know,",
      "offset": 1299.84,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "whatever, days or weeks to find them and",
      "offset": 1301.2,
      "duration": 3.599
    },
    {
      "lang": "en",
      "text": "pay hundreds of dollars and it's just",
      "offset": 1303.2,
      "duration": 3.359
    },
    {
      "lang": "en",
      "text": "available to everybody for free today.",
      "offset": 1304.799,
      "duration": 3.281
    },
    {
      "lang": "en",
      "text": "What an amazing discussion. Thanks so",
      "offset": 1306.559,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "much you for joining us.",
      "offset": 1308.08,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "Thank you. It was really, really fun.",
      "offset": 1309.679,
      "duration": 2.88
    },
    {
      "lang": "en",
      "text": "Thanks for having me.",
      "offset": 1311.52,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "You can learn more in Google Cloud's",
      "offset": 1312.559,
      "duration": 4.561
    },
    {
      "lang": "en",
      "text": "report, the future of AI perspectives",
      "offset": 1315.44,
      "duration": 5.719
    },
    {
      "lang": "en",
      "text": "for startups. Go to go.gle/futureofi.",
      "offset": 1317.12,
      "duration": 4.039
    },
    {
      "lang": "en",
      "text": "That's go.gle/futureofai",
      "offset": 1321.36,
      "duration": 3.24
    },
    {
      "lang": "en",
      "text": "and go check out Gemini. Man, I love",
      "offset": 1325.6,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "that deep research. And uh everybody, if",
      "offset": 1327.36,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "you want to get more of our startup",
      "offset": 1330.08,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "basics series from legal to accounting",
      "offset": 1331.6,
      "duration": 4.559
    },
    {
      "lang": "en",
      "text": "to marketing and now AI, go to this week",
      "offset": 1333.76,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "in startups.com/basics.",
      "offset": 1336.159,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "Thanks again for listening. We'll see",
      "offset": 1338.96,
      "duration": 4.44
    },
    {
      "lang": "en",
      "text": "you next time.",
      "offset": 1340.08,
      "duration": 3.32
    }
  ],
  "cleanText": "All right, everybody. Welcome back to thisweekinstartups. It's time again for our AI basics series. What is this? Ah man, founders ask us all the time the same questions over and over again. So we have done basics for legal. We've done it for marketing and growth tactics, obviously accounting, and here we are in the age of AI. People need to understand the best practices. And hey, it's moving pretty quickly. If you want to get caught up on your AI basics, go ahead and download this fantastic report by our partner Google Cloud. It's called the Future of AI: Perspectives for Startups featuring insights from 23 top AI experts. And today, one of them is with us. Yoav Shoham is here. He's a Stanford professor, ameritus as you know, and he is the co-founder of AI21 Labs, uh, the team behind Jurassic-2 and Wordtune, building large language models and tools for collaborative reasoning. Welcome to the show, Yoav.\nFun to be here. Thanks for having me.\nLet's talk a little bit about what we mean by reasoning, you know, here in 2025. Are these machines actually reasoning? And how do you get the best out of them? Right now, so many experiments going on in corporate America. So many people are testing and starting to deploy AI technology from large language models or with the basis of large language models. But there is some concern about the reasoning, are these making the best decisions, hallucinations, etc. So what what is the state today? And maybe tell us a little bit about your company AI21 Labs.\nMaybe I'll start with the letter AI21 Labs. It's about uh 7 years old. We definitely one of the uh main LLM builders, although we took a slightly different tack than most people recently with our Jamba family, which is not a pure transformer architecture for efficiency reasons, and we can speak about that. Most of our effort now is around uh orchestration and planning of these complex AI systems in a product we call Maestro, which we released. But if that's directly relevant to your question, Jason, about, so you know, we in AI uh are guilty of using terms that are so ill-defined that they come back to bite us, and we can we can draw a long list from AGI to agents to to reasoning, but if\nstep back from the actual terms. The issue, as you pointed out in the enterprise, is that there's a ton of experimentation. Like two years ago, nobody paid attention. Maybe three years ago, you couldn't get a CEO or or you know, a chief innovation officer to pay attention. Now everybody's on top of that. But for all the hundreds of use cases in a given company that you see, the number of deployments is very small. And the main reason is the issue of well, there are many reasons, issues of compliance and safety and you know, use cases, new technology, and it's all good, but the main reason is reliability. And uh, again, the term hallucination, maybe not the best terms, but these are probabilistic machines, and um, they're for sometimes, often they'll give you brilliant output, but if you're brilliant 95% of the time and not just wrong, but total garbage 5% of the time. And that may be okay in consumer land, but not in the enterprise. And so there are many studies that show that the ratio of experiments in the enterprise deployments is like 10 to 1, 20 to 1.\nAnd so that is super relevant. What it means is there's an enthusiasm for the technology. But when it comes to mission-critical applications, if you're doing something in accounting, if you're doing customer support, uh, obviously if you're a developer and you're pushing code to a server, it needs to be a lot more reliable, and and that's why humans are in the loop. But with Maestro, I think the concept, and you'll correct me here if I'm wrong, is we have many different LLMs and having them, as crazy as it sounds, work in concert with each other.\nInteresting concert, Maestro. Um, and having them check each other's work, maybe trying to get them to um, justify their answer as it were, can result in better output and more reliable systems.\nCorrect. Uh, largely yes. Uh, let me let me nuance this, please. So some would like to take the the LLM or as the new version of them, sometime called LRM, large reasoning models, which is really a misnomer, but system like, you know, 01, 03, R1, and try to get them to behave through guardrails and alignment efforts and everything, and all that's good to do, and we do that, but that will never iron out the uh, the the uh, the variance in the models. And so what you really need to do is to put logic on the outside to orchestrate, and it's not just a matter of routing between, you know, this LLM or that LLM, sometimes you run code, sometimes you use a tool, you know, you'll access a database, you'll call, you know, a weather API, what have you, and something need to orchestrate all of that, and you're asked to, if you're right, that you want to do not only system testing, but unit testing, so every step of the way you have an explicit plan, and every step of the way you want to as well as as best you can validate how well you're doing. And sometimes you'll do it with the language models, what's called judge language model. And often you'll just, for example, you want an output to be 6 to 800 words long. Just do the do the damn counting.\nLet's talk about agents specifically. This promise has captured people's imagination because agents feel like a way for humans to stop doing chores. So much of what we do when we go to work, when we try to build a business is uh, the actual product and the service we're providing to people. But we all have to do our chores and cleaning stuff up, normalizing data, just work that humans find monotonous. Most humans and they don't like to do uh, digging dishes, like the agents feel like the proper solution for those. How close are we to having agents at scale doing these repetitive tasks? How often are people actually building an agent that is in 2025, when we're recording this, getting the chore done reliably enough that humans can forget about that chore?\nYour mileage varies, depends on the sore and depend on the quote unquote agent. The problem is that people have been using the term agent now. It's so seductive for anything that smacks of any kind of automation, and it'll come back to bite us. I call this agent washing. And so you're absolutely right that the biggest bang for the buck is when you try to get the technology to take care of fairly simple, fairly mundane stuff, kind of like robotic process process automation on steroids. So more and more stuff can be automated. Is that an agent or is this simply a program that you wrote that maybe use an LLM? Uh, we don't need to get anal about the definition. But typically when we speak about agents, what do we have in mind? We have in mind a system that's not a transactional call to an LLM. There's something that's more ongoing. There's uh, the AI system, the agent can be proactive, not just respond to our prompt. It takes uh, it it executes complicated flows, not just like a one-step thing. It uses multiple tools.\nAnd as you do this, it gets diceier because if a single call to an LLM carries some uncertainty, when you start to compose them, at some point you get more uh, noise and signal. And that's where I think uh, maybe some people are getting a little ahead of ahead of themselves. So simple road repetitive stuff. Yes. More complicated stuff, we we have work to do. It seems like there's been an investment in smaller, more narrow models. And some debate about that. Some people believe the large models will figure it all out eventually. Other people think, hey, why not make a smaller model faster, cheaper, better, and uh, more constrained. Maybe you could talk about the state of SMLS.\nI think the short answer is in consumer ad, if you're looking for a very general purpose chat, let's call call a spade a spade, a chat GPT like uh, experience, there's probably no replacement for a very large language model that is being tuned to cover a huge variety of cases, because you can't anticipate the variety of input you get from consumers. As you go to the enterprise and your needs are much more narrower. There's several reasons to go narrow. First of all is is just u um uh, cost. It's it's cost not only in terms of dollars, but also latency. And so you know, uh, and as you know, we uh, came up with this new family of models called Jamba that is a hybrid state-based model and transformer that in terms of the quality of the anterior, you you you get, it's competitive with the most models. In terms of latency and memory footprint, there's just no comparison, especially as the input as so-called the context length increases, that kills you, the transformer architecture.\nThis is what, you know, 2017, uh, the famous paper from Google, thank you Google, really moved the needle, suddenly stuff happened in language that hadn't happened before, which did happen in vision, and the reason is that the attention mechanism transformer allows you to, as at the term suggest, tend to very disparate part of the input. In vision, it doesn't so much matter if you know to know that this here is a uh, you know, is a phone, doesn't really matter what the pixel way over to the side is. But in language, there's nothing local. So that made the difference. Problem is that it's expensive. It's a quadratic complexity in the input or the context length as we call it. Now when we had input of a,000,000, squared is fine, but we're now pushing a million. A million squared is not fine. And so you need to deal with that. Part of it is smaller language models that doesn't quite deal with the context length side of things. But then rethinking the architecture. So the space model, which is inherently linear and not quadratic and mixing it just a little bit transformer gives you the best of both worlds.\nWhat about verticalization of knowledge? Is there a movement to say, hey, this small language model is going to focus really on accounting, to just put it in business uh, categories. This one is just really amazing at legal concepts. And you know that when you throw this legal brief into it or on the accounting side, you throw this RFP into it, these are huge contact windows dumping cases of case law and trying to process them. Is it just about the the speed and the cost or is it also about the accuracy because the model has been constrained to not have to worry about oh, all the movies and songs ever written in the world and every blog post about those songs and music in the world. Is it actually going to result in a higher fidelity of content?\nShort answer, yes. Uh, long I'm sorry, I'm always nuanced. Uh, but the longer answer is that there's some general common sense that the baseline model has learned that you want to retain, even if it's just uh, you know, mastering correct uh, English, you know, language, you know, grammar, and so as you attain more uh, domain specific language, it's okay to forget certain things, but not others. So the art here is to just remember the right stuff.\nLet's talk a little bit about agent-to-agent protocols. For people who don't know, A2A is a protocol for interoperability between agents. You know, technologists are always looking at what's around the corner. If you do get your agents working well, let's say the accounting department agent doing purchase orders and paying bills, uh, eventually you might want that agent to interact between companies, maybe to put an RFP out to get five companies to bid for, I don't know, the new shed you're building, uh, or the new uh, software that you want written. And agent-to-agent protocol is going to solve for that.\nThis is we're talking within the last 60, 90 days, this stuff is all starting to be publicly released by Google, other players, and we're starting to see some consensus from different technology companies and data sources that this is the next big thing. Is anybody actually got this in deployment now in your experience? What are the early results like? What are people thinking this will do?\nNo, I think it's too early for anything to have been in production, even in the ideal scenario. So this is not a knock on A2A, just too early. So first of all, I think kudo to Google for shepherding this and a good start, but it's just a start, and we have to realize the limitations. So the vision that there's several things that I think excite people when they hear about multiple agents coordinating. Part of it is the something from nothing. Uh, oh, I don't need to think hard about the problem. I'll just build a bunch myself. We'll build a bunch of agents and then magic will happen when they come together. That historically uh, has led to disappointment. Often the magic isn't the glue. It's good to compartmentalize and and factor things out. That's always a good, but often the magic is how you put together things, what the algorithm is. But I think as you said, the promise is that it's not only my agent speaking to my agents, it's my agents speaking to other agents in my company, but that I didn't build, but also outside my company. And here uh, I think um, uh, not so fast. Uh, there are two fundamental problems. One is if you look at the protocol, it's um, there's a uh, a a a a part of what the agent communicates in JSON, which is its capabilities uh, and other stuff where you know, the contract it does with other agents. The problem is it specifies the syntax, but not the semantic, not the meaning, and that historically has been the pitfall of distributed object systems that objects advertise their capabilities, but there's no reason for me to for my agent to understand what you meant when you put in language, I know how to find uh, you know, good flights, well, what is good flights? Is it mean efficient time, you know, so when you share semantics, it can be done, but it's a big undertaking. It's a community kind of activity. That's number one. Number two is shared incentives. If you go outside the boundaries of even my own unit in company, because we don't always share the same incentives, even if we're in you know, the same company, but let alone, so for example, if I'm looking, I have an agent that's trying to put together an itinerary for me and book a flight, and it's speaking with your agent, and you're maybe you know, you know, an agent of one of the companies, we do not have the same incentive, and so you need to put in some control for that, and actually, so I I spent in my, you know, wearing my academic hat, I spent a good fraction of my academic work on on the area of multi-agent systems, and in fact, we have a a standard textbook in the area, and a lot of it has to do with crafting protocols for multiple agents to get them to play nice together, even though left to their own devices, they wouldn't, a lot of game, a lot, a lot of game theory and stuff like that.\nI mean, if you think about what we went through when we tried to have a semantic web exist. Oh, hey, you're a a chef, and you have a really silly example, but you're putting your recipes online. We'd like you to make your recipe semantic.\n\n\nThese are ingredients. These are steps, you know, and here's what the output looks like, and here's the original, you know, here's the temperature. We want all this stuff to be semantic. It was like, \"Okay, yeah, I'll do all that for you.\" And then, you know, a bunch of people just scrape all your recipes and uh you get less traffic to your website. Uh and the promise was, \"Oh, I would get more traffic. People would search for these three ingredients and you know my recipe might come up.\" So the devil is in the details there and you know thinking it through is critical. Let's end on this. What's hyped? What's overhyped? You got a lot of founders listening here on this week in startups. They're building stuff. What's something they should be doing now that's obvious and going to pay dividends for their startup? What are things that, hey, maybe agent-to-agent falls into this category? You could become aware of there's an opportunity here, but it might be a bit too early to get significant gains from it. Where should they be focusing their time and effort in your mind? A little presumptuous for me to give a definitive answer because there's so many kind of degrees of freedom here, but I think that if you look for the maybe underhyped opportunities, maybe I'll mention two. One is the boring stuff. You know, getting uh workflows to be reliable is, and again, I'm I'm I'm thinking enterprise. This is kind of my lens I put through. That is the biggest blocker in the enterprise right now. Getting the uh workflows to be reliable and customizing them per deployment. That's hard work. But that's where I think the real pain is. The thing is, it's not sexy. Uh if you give a demo that did something amazing once or maybe many times, uh that's sexy, but it's not sexy to show that things don't fail, but that's where the real value is. So I think there, there's that's where I, you know, one area I would focus in the area where I don't know that it's uh, you know, underhyped, but I think it's underserved is education. You know, I was there in the early days of online courses, uh, you know, Corsera and Udacity starting in my corridor at at uh at Stanford, and um, and you know, I have a an online course on gay theory that's been seen by over a million people, but it doesn't begin to scratch the surface of what the real opportunity is in proactive uh per student uh teaching. The issue is not how to get chatpt out of the classroom so people don't cheat. The issue is how to get the technology in the classroom and rethink what education is really about, how we do it right with technology. So, uh that's an area that I would really like to see kind of blossom. It is um super interesting. The first step was getting all those courses online and somebody who uh went to form university, didn't quite hit the IVs, I was always jealous like what's going on, you know, in at MIT at Stanford, like how different is it than my experience? And uh I was feeling particularly under uh resourced in macroeconomics, right? And I was like, I really want to understand this. And I just went to YouTube and I found courses at Stanford, MIT, and I watched the courses and I was like, \"Wow, this is like alchemy.\" They're trying to figure out how macroeconomics works. But the fact that it was available for free on YouTube, the same course that people were paying and had to qualify to be in the 0.1% of people on the planet to get there was available for free. And now you imagine if it was adaptive learning and you could answer some questions up front and then I said, \"Yeah, you know, you should really start with this third video or actually you're not ready for the first two videos. You should do this pre-calculus and maybe have this statistics course first before you get in there. Learn some basics about statistics so you can actually um understand the material better. Man, that would be so amazing to have it be adaptive and not leave any cuz as a professor you you wind up leaving some students behind and at what fork in the road did they get disengaged is always the question. Yeah, absolutely. You know it's it's typical when a new technology comes comes on, you you try to use it the way you use the old technology. So television initially was televised radio and then you over time you understood what the medium was really good for. I think it's the time is ripe now uh with you know the flat world and everybody has having access to uh you know computers and networking to get AI to do to rethink education. Yeah, absolutely. And you think about the role of professors creating courses, creating quizzes, even you can go into any LLM today, ask it to take uh Great Expectations, Charles Dickens, and give you a series of Q&A and be your coach, and you just give it that tiny prompt, and you could sit there with your phone and have a personalized tutor that you would have had to spend, you know, whatever, days or weeks to find them and pay hundreds of dollars and it's just available to everybody for free today. What an amazing discussion. Thanks so much you for joining us. Thank you. It was really, really fun. Thanks for having me. You can learn more in Google Cloud's report, the future of AI: Perspectives for startups. Go to go.gle/futureofai. That's go.gle/futureofai and go check out Gemini. Man, I love that deep research. And uh everybody, if you want to get more of our startup basics series from legal to accounting to marketing and now AI, go to thisweekinstartups.com/basics. Thanks again for listening. We'll see you next time.\n",
  "dumpedAt": "2025-07-21T18:43:26.222Z"
}