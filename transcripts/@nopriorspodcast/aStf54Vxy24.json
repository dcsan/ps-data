{
  "episodeId": "aStf54Vxy24",
  "channelSlug": "@nopriorspodcast",
  "title": "No Priors Ep. 118 | With Anthropic Co-Founder Ben Mann",
  "publishedAt": "2025-06-12T11:16:23.000Z",
  "rawLines": [
    {
      "lang": "en",
      "text": "[Applause]",
      "offset": 3.07,
      "duration": 4.209
    },
    {
      "lang": "en",
      "text": "Hi listeners and welcome back to No",
      "offset": 5.6,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "Priors. Today we have Ben Man,",
      "offset": 7.279,
      "duration": 3.521
    },
    {
      "lang": "en",
      "text": "previously an early engineer at OpenAI",
      "offset": 9.04,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "where he was one of the first authors on",
      "offset": 10.8,
      "duration": 3.759
    },
    {
      "lang": "en",
      "text": "the GPT3 paper. Ben was then one of the",
      "offset": 12.32,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "original eight that abandoned ship in",
      "offset": 14.559,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "2021 to co-found anthropic with a",
      "offset": 16.24,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "commitment to long-term safety. He has",
      "offset": 18.4,
      "duration": 2.879
    },
    {
      "lang": "en",
      "text": "since led multiple parts of the",
      "offset": 20,
      "duration": 3.279
    },
    {
      "lang": "en",
      "text": "Anthropic organization including product",
      "offset": 21.279,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "engineering and now labs home to such",
      "offset": 23.279,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "popular efforts such as model context",
      "offset": 25.519,
      "duration": 4.481
    },
    {
      "lang": "en",
      "text": "protocol and claude code. Welcome, Ben.",
      "offset": 27.519,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "Thank you so much for doing this. Of",
      "offset": 30,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "course. Thanks for having me. So,",
      "offset": 31.599,
      "duration": 5.921
    },
    {
      "lang": "en",
      "text": "congratulations on the Claude 4 release.",
      "offset": 33.68,
      "duration": 6.32
    },
    {
      "lang": "en",
      "text": "Maybe we can even start with like how do",
      "offset": 37.52,
      "duration": 5.039
    },
    {
      "lang": "en",
      "text": "you decide what qualifies as a release",
      "offset": 40,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "these days? It's definitely more of an",
      "offset": 42.559,
      "duration": 6.241
    },
    {
      "lang": "en",
      "text": "art than a science. We have a lot of",
      "offset": 45.52,
      "duration": 5.199
    },
    {
      "lang": "en",
      "text": "spirited internal debate of what the",
      "offset": 48.8,
      "duration": 5.279
    },
    {
      "lang": "en",
      "text": "number should be. And before we even",
      "offset": 50.719,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "have a potential model, we we have a",
      "offset": 54.079,
      "duration": 4.721
    },
    {
      "lang": "en",
      "text": "road map where we try to say based on",
      "offset": 56.239,
      "duration": 4.881
    },
    {
      "lang": "en",
      "text": "the amount of chips that we get in uh",
      "offset": 58.8,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "when will we theoretically be able to",
      "offset": 61.12,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "train a model out to the paro efficient",
      "offset": 63.44,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "compute frontier. So it's all based on",
      "offset": 66,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "scaling laws and then once we get the",
      "offset": 68.56,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "chips then we try to train it and",
      "offset": 70.56,
      "duration": 4.879
    },
    {
      "lang": "en",
      "text": "inevitably things are less than the best",
      "offset": 72.32,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "that we could possibly imagine because",
      "offset": 75.439,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "that's just the nature of of the",
      "offset": 77.36,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "business. it's it's pretty hard to train",
      "offset": 79.04,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "these big models. So dates might change",
      "offset": 80.88,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "a little bit and then at some point it's",
      "offset": 83.52,
      "duration": 4.239
    },
    {
      "lang": "en",
      "text": "like mostly baked and we're sort of like",
      "offset": 85.52,
      "duration": 4.639
    },
    {
      "lang": "en",
      "text": "slicing off little pieces close to the",
      "offset": 87.759,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "end to try to say like how is this cake",
      "offset": 90.159,
      "duration": 4.241
    },
    {
      "lang": "en",
      "text": "going to taste when it comes out of the",
      "offset": 93.119,
      "duration": 3.761
    },
    {
      "lang": "en",
      "text": "oven. But uh as Daario has said until",
      "offset": 94.4,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "it's really done you you don't really",
      "offset": 96.88,
      "duration": 3.279
    },
    {
      "lang": "en",
      "text": "know. You can get sort of a directional",
      "offset": 98.56,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "indication and then if it feels like a",
      "offset": 100.159,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "major change then we give it a major",
      "offset": 103.04,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "version bump. But we're definitely still",
      "offset": 105.439,
      "duration": 3.441
    },
    {
      "lang": "en",
      "text": "learning and iterating on this process.",
      "offset": 107.2,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "So yeah, well the good thing is that you",
      "offset": 108.88,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "guys are uh you know no less tortured",
      "offset": 111.119,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "than anybody else in your naming scheme",
      "offset": 113.28,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "here. Yes, the naming schemes in AI are",
      "offset": 115.2,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "something else. So you folks have a a",
      "offset": 117.92,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "simplified version in some sense. Do you",
      "offset": 120,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "want to um mention any of the highlights",
      "offset": 121.84,
      "duration": 2.879
    },
    {
      "lang": "en",
      "text": "from four that you think are especially",
      "offset": 123.28,
      "duration": 2.64
    },
    {
      "lang": "en",
      "text": "interesting or you know there's things",
      "offset": 124.719,
      "duration": 2.481
    },
    {
      "lang": "en",
      "text": "around coding and other areas. We'd just",
      "offset": 125.92,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "love to hear your perspective on that.",
      "offset": 127.2,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "By the benchmarks for is just",
      "offset": 130.16,
      "duration": 4.799
    },
    {
      "lang": "en",
      "text": "dramatically better than any other",
      "offset": 133.2,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "models that we've had. Even force on it",
      "offset": 134.959,
      "duration": 5.041
    },
    {
      "lang": "en",
      "text": "is dramatically better than 37 on it",
      "offset": 137.52,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "which was our prior best model. Some of",
      "offset": 140,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "the things that are dramatically better",
      "offset": 142.4,
      "duration": 6.08
    },
    {
      "lang": "en",
      "text": "are for example in coding it is able to",
      "offset": 144.56,
      "duration": 7.6
    },
    {
      "lang": "en",
      "text": "uh not do its uh sort of offtarget",
      "offset": 148.48,
      "duration": 6.16
    },
    {
      "lang": "en",
      "text": "mutations or overeagerness or reward",
      "offset": 152.16,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "hacking. Those are two things that",
      "offset": 154.64,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "people were really unhappy with in in",
      "offset": 156.239,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "the last model where they were like wow",
      "offset": 158.959,
      "duration": 3.121
    },
    {
      "lang": "en",
      "text": "it's so good at coding but it also makes",
      "offset": 160.4,
      "duration": 3.199
    },
    {
      "lang": "en",
      "text": "all these changes that I definitely",
      "offset": 162.08,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "didn't ask for. It's like, &quot;Do you want",
      "offset": 163.599,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "fries in a milkshake with that change?&quot;",
      "offset": 165.84,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "And you're like, &quot;No, just do the thing",
      "offset": 167.519,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "I asked for.&quot; And then you have to spend",
      "offset": 169.44,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "a bunch of time cleaning up after it.",
      "offset": 171.12,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "The new models, they just do the thing.",
      "offset": 172.8,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "And uh and and so that's really useful",
      "offset": 174.8,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "for professional software engineering",
      "offset": 177.68,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "where you need it to be maintainable and",
      "offset": 179.44,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "reliable. My favorite uh reward hacking",
      "offset": 181.599,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "behavior that has happened in more than",
      "offset": 184,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "one of our portfolio companies is if you",
      "offset": 185.68,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "write a bunch of tests or generate a",
      "offset": 189.2,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "bunch of tests to you know see if what",
      "offset": 191.12,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "you are generating works more than once",
      "offset": 193.599,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "like we've had the model just delete all",
      "offset": 196.72,
      "duration": 4.239
    },
    {
      "lang": "en",
      "text": "the code because the tests pass in that",
      "offset": 198.959,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "case which is you know not progressing",
      "offset": 200.959,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "us really. Yep. or it'll have like",
      "offset": 202.959,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "here's the test and then it'll be",
      "offset": 205.599,
      "duration": 4.801
    },
    {
      "lang": "en",
      "text": "comment like exercise left for the",
      "offset": 207.36,
      "duration": 5.84
    },
    {
      "lang": "en",
      "text": "reader return true and then you're like",
      "offset": 210.4,
      "duration": 5.759
    },
    {
      "lang": "en",
      "text": "okay good job model but you need more",
      "offset": 213.2,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "than that maybe Ben you can talk about",
      "offset": 216.159,
      "duration": 4.481
    },
    {
      "lang": "en",
      "text": "how users should think about when to use",
      "offset": 218,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "the claude 4 models and also what is",
      "offset": 220.64,
      "duration": 7.36
    },
    {
      "lang": "en",
      "text": "newly possible with them so more agentic",
      "offset": 223.04,
      "duration": 7.68
    },
    {
      "lang": "en",
      "text": "longer horizon tasks are newly unlocked",
      "offset": 228,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "I would say and so in coding in",
      "offset": 230.72,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "particular we've seen",
      "offset": 232.319,
      "duration": 3.521
    },
    {
      "lang": "en",
      "text": "uh some customers",
      "offset": 233.76,
      "duration": 5.759
    },
    {
      "lang": "en",
      "text": "using it for many many hours unattended",
      "offset": 235.84,
      "duration": 6.479
    },
    {
      "lang": "en",
      "text": "and doing giant refactors on its own.",
      "offset": 239.519,
      "duration": 4.881
    },
    {
      "lang": "en",
      "text": "That's been really exciting to see. But",
      "offset": 242.319,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "in non-coding use cases as well, it's",
      "offset": 244.4,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "really interesting. So for example, um",
      "offset": 246.879,
      "duration": 5.841
    },
    {
      "lang": "en",
      "text": "we have some reports that some customers",
      "offset": 249.76,
      "duration": 6.56
    },
    {
      "lang": "en",
      "text": "of Manis, which is a aentic model in a",
      "offset": 252.72,
      "duration": 6.56
    },
    {
      "lang": "en",
      "text": "box startup, people asked it to take a",
      "offset": 256.32,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "video and turn it into a PowerPoint. And",
      "offset": 259.28,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "our model can't understand audio or",
      "offset": 261.68,
      "duration": 6.16
    },
    {
      "lang": "en",
      "text": "video, but it was able to uh download",
      "offset": 264.08,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "the video",
      "offset": 267.84,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "uh use fmpg to chop it up into images",
      "offset": 269.6,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "and do key frame detection and maybe",
      "offset": 272.88,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "with like some kind of old school",
      "offset": 275.36,
      "duration": 6.48
    },
    {
      "lang": "en",
      "text": "MLbased key frame detector and then get",
      "offset": 277.84,
      "duration": 7.76
    },
    {
      "lang": "en",
      "text": "an API key for a speechto text service,",
      "offset": 281.84,
      "duration": 5.84
    },
    {
      "lang": "en",
      "text": "run speech to text using this other",
      "offset": 285.6,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "service, take the transcript, turn that",
      "offset": 287.68,
      "duration": 7.12
    },
    {
      "lang": "en",
      "text": "into PowerPoint slides content and then",
      "offset": 290.56,
      "duration": 8.72
    },
    {
      "lang": "en",
      "text": "write code to inject the content into a",
      "offset": 294.8,
      "duration": 6.48
    },
    {
      "lang": "en",
      "text": "PowerPoint file. And the person was",
      "offset": 299.28,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "like, &quot;This is amazing. I love it. It",
      "offset": 301.28,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "like it actually was good in the end.&quot;",
      "offset": 303.44,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "So that's the kind of thing where uh",
      "offset": 305.28,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "it's operating for a long time. It's",
      "offset": 307.6,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "it's doing a bunch of stuff for you.",
      "offset": 309.28,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "This person might have had to spend",
      "offset": 311.6,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "multiple hours looking through this",
      "offset": 314.4,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "video and instead it was all just done",
      "offset": 316.72,
      "duration": 3.199
    },
    {
      "lang": "en",
      "text": "for them. So I think we're going to see",
      "offset": 318.479,
      "duration": 3.041
    },
    {
      "lang": "en",
      "text": "a lot more interesting stuff like that",
      "offset": 319.919,
      "duration": 3.201
    },
    {
      "lang": "en",
      "text": "in the future. It's still good at all",
      "offset": 321.52,
      "duration": 3.519
    },
    {
      "lang": "en",
      "text": "the old stuff. It's just like the longer",
      "offset": 323.12,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "horizon stuff is the exciting part that",
      "offset": 325.039,
      "duration": 4.241
    },
    {
      "lang": "en",
      "text": "that sounds expensive, right? In terms",
      "offset": 326.96,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "of both scaling compute like reasoning",
      "offset": 329.28,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "tokens here and then also just like you",
      "offset": 331.52,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "know all the tool use you might want to",
      "offset": 333.28,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "constrain in certain ways. Does Cloud 4",
      "offset": 335.28,
      "duration": 5.199
    },
    {
      "lang": "en",
      "text": "make decisions about how hard problems",
      "offset": 337.84,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "are and how much compute to spend on",
      "offset": 340.479,
      "duration": 6.16
    },
    {
      "lang": "en",
      "text": "them? If you give opus a tool which is",
      "offset": 342.4,
      "duration": 7.359
    },
    {
      "lang": "en",
      "text": "sonnet, it can use that tool effectively",
      "offset": 346.639,
      "duration": 5.921
    },
    {
      "lang": "en",
      "text": "as a sub aent. And we do this a lot in",
      "offset": 349.759,
      "duration": 5.361
    },
    {
      "lang": "en",
      "text": "our agentic coding harness called cloud",
      "offset": 352.56,
      "duration": 6.16
    },
    {
      "lang": "en",
      "text": "code. So if you ask it to like look",
      "offset": 355.12,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "through the codebase for blah blah blah,",
      "offset": 358.72,
      "duration": 5.199
    },
    {
      "lang": "en",
      "text": "then it will delegate out to a bunch of",
      "offset": 360.56,
      "duration": 5.759
    },
    {
      "lang": "en",
      "text": "sub agents to go look for that stuff and",
      "offset": 363.919,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "report back with the details. And that",
      "offset": 366.319,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "has benefits besides cost control like",
      "offset": 368.319,
      "duration": 5.281
    },
    {
      "lang": "en",
      "text": "latency is much better. um and it",
      "offset": 370.4,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "doesn't fill out the context. So models",
      "offset": 373.6,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "are pretty good at that. But I I think",
      "offset": 375.68,
      "duration": 3.519
    },
    {
      "lang": "en",
      "text": "at a high level when I think about cost,",
      "offset": 377.12,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "it's always in relation to how much it",
      "offset": 379.199,
      "duration": 4.801
    },
    {
      "lang": "en",
      "text": "would have cost the human to do that.",
      "offset": 381.68,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "And almost always it's like a",
      "offset": 384,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "no-brainer, right? Like software",
      "offset": 385.759,
      "duration": 5.121
    },
    {
      "lang": "en",
      "text": "engineers cost a lot these days. And so",
      "offset": 387.68,
      "duration": 4.799
    },
    {
      "lang": "en",
      "text": "to be able to say like, &quot;Oh, now I'm",
      "offset": 390.88,
      "duration": 3.759
    },
    {
      "lang": "en",
      "text": "getting like two or 3x the amount of",
      "offset": 392.479,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "productivity out of this engineer who it",
      "offset": 394.639,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "was really hard for me to hire and",
      "offset": 397.199,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "retain. They're happy and I'm happy.&quot;",
      "offset": 398.8,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "Yeah, it works well. How do you think",
      "offset": 401.039,
      "duration": 3.201
    },
    {
      "lang": "en",
      "text": "about how this evolves? So, if I look at",
      "offset": 402.8,
      "duration": 2.64
    },
    {
      "lang": "en",
      "text": "the way the human brain works, we",
      "offset": 404.24,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "basically have a series of sort of",
      "offset": 405.44,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "modules that are responsible for very",
      "offset": 407.52,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "specific types of processing behavior",
      "offset": 410,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "etc. It's everything from mirror neurons",
      "offset": 412.88,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "and empathy on through to parts of your",
      "offset": 414.24,
      "duration": 2.959
    },
    {
      "lang": "en",
      "text": "visual cortex that are involved with",
      "offset": 416,
      "duration": 3.199
    },
    {
      "lang": "en",
      "text": "different aspects of vision. Do you",
      "offset": 417.199,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "think and those are highly specialized,",
      "offset": 419.199,
      "duration": 3.361
    },
    {
      "lang": "en",
      "text": "highly efficient modules. It sometimes",
      "offset": 421.12,
      "duration": 3.359
    },
    {
      "lang": "en",
      "text": "can kind of, you know, if you have brain",
      "offset": 422.56,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "damage, it can kind of cover for another",
      "offset": 424.479,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "section over time as it sort of grows",
      "offset": 426.479,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "and adapts, but fundamentally you have",
      "offset": 427.919,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "specialization on purpose. And what you",
      "offset": 429.599,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "describe sounds a little bit like that",
      "offset": 432.08,
      "duration": 2.559
    },
    {
      "lang": "en",
      "text": "or at least it's trending in that",
      "offset": 433.44,
      "duration": 2.319
    },
    {
      "lang": "en",
      "text": "direction where you have these highly",
      "offset": 434.639,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "efficient sub aents that are specialized",
      "offset": 435.759,
      "duration": 4.481
    },
    {
      "lang": "en",
      "text": "for tasks that are basically called by a",
      "offset": 438.24,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "orchestrator or sort of a high level",
      "offset": 440.24,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "agent that sort of plans everything. Do",
      "offset": 442,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "you think that's the eventual future or",
      "offset": 444,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "do you think it's more generic in terms",
      "offset": 445.36,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "of the types of things that you have",
      "offset": 447.28,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "running n years from now once you have a",
      "offset": 448.56,
      "duration": 3.759
    },
    {
      "lang": "en",
      "text": "bit more specialization in these things",
      "offset": 450.96,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "and by n years I mean two three years",
      "offset": 452.319,
      "duration": 4.481
    },
    {
      "lang": "en",
      "text": "not you know infinite time that's a",
      "offset": 454.16,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "great question I think we're going to",
      "offset": 456.8,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "start to get insight into what the",
      "offset": 458.16,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "models are doing under the hood from our",
      "offset": 460.56,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "work on mechanistic interpretability our",
      "offset": 462.08,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "most recent papers have published what",
      "offset": 464.72,
      "duration": 5.919
    },
    {
      "lang": "en",
      "text": "we call circuits which is for real",
      "offset": 467.12,
      "duration": 5.919
    },
    {
      "lang": "en",
      "text": "models at scale how are they actually",
      "offset": 470.639,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "computing the answers. And it may be",
      "offset": 473.039,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "that",
      "offset": 475.039,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "based on the mixture of experts",
      "offset": 476.639,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "architecture, there might be specific",
      "offset": 478.479,
      "duration": 4.881
    },
    {
      "lang": "en",
      "text": "chunks of weights that are dedicated to",
      "offset": 480.8,
      "duration": 5.839
    },
    {
      "lang": "en",
      "text": "more empathetic responses versus more",
      "offset": 483.36,
      "duration": 6.48
    },
    {
      "lang": "en",
      "text": "tool using or image analysis type of",
      "offset": 486.639,
      "duration": 5.041
    },
    {
      "lang": "en",
      "text": "problems and responses. But for",
      "offset": 489.84,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "something like memory, I guess in some",
      "offset": 491.68,
      "duration": 4.799
    },
    {
      "lang": "en",
      "text": "sense that feels so core to me that it",
      "offset": 493.919,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "feels weird for it to be a different",
      "offset": 496.479,
      "duration": 4.481
    },
    {
      "lang": "en",
      "text": "model. Maybe we'll have like more",
      "offset": 498.08,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "complicated architectures in the future",
      "offset": 500.96,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "where instead of it being sort of this",
      "offset": 503.36,
      "duration": 4.239
    },
    {
      "lang": "en",
      "text": "uniform like transformer torso that just",
      "offset": 504.96,
      "duration": 4.639
    },
    {
      "lang": "en",
      "text": "scales and there's a lot of it it's",
      "offset": 507.599,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "basically uniform throughout you could",
      "offset": 509.599,
      "duration": 4.961
    },
    {
      "lang": "en",
      "text": "imagine something with like specialized",
      "offset": 511.68,
      "duration": 5.279
    },
    {
      "lang": "en",
      "text": "modules but yeah cuz cuz I think about",
      "offset": 514.56,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "it also in the context of different",
      "offset": 516.959,
      "duration": 3.281
    },
    {
      "lang": "en",
      "text": "startups who are using uh some of these",
      "offset": 518.32,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "foundation models like clock to do",
      "offset": 520.24,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "different very specialized tasks in the",
      "offset": 522.32,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "context of an enterprise so that could",
      "offset": 523.76,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "be customer success it could be sales it",
      "offset": 525.44,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "could be coding in terms of the actual",
      "offset": 527.12,
      "duration": 2.96
    },
    {
      "lang": "en",
      "text": "UI layer. It could be a variety of",
      "offset": 528.72,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "things. And often it feels like the",
      "offset": 530.08,
      "duration": 3.439
    },
    {
      "lang": "en",
      "text": "architecture a lot of people converge to",
      "offset": 532.08,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "is they basically have some orchestrator",
      "offset": 533.519,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "or some other sort of thing that governs",
      "offset": 535.12,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "which model they call in order to do a",
      "offset": 537.92,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "specific action relative to the the",
      "offset": 540,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "application. And to some extent I was",
      "offset": 542.72,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "just sort of curious how you think about",
      "offset": 545.04,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "that in the context of the API layer or",
      "offset": 546.16,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "the foundation model world where one",
      "offset": 548.72,
      "duration": 4.239
    },
    {
      "lang": "en",
      "text": "could imagine some similar forms of",
      "offset": 550.64,
      "duration": 3.759
    },
    {
      "lang": "en",
      "text": "subsp specialcialization happening over",
      "offset": 552.959,
      "duration": 3.281
    },
    {
      "lang": "en",
      "text": "time. Or you could say, hey, it's just",
      "offset": 554.399,
      "duration": 3.281
    },
    {
      "lang": "en",
      "text": "different forms of the same more general",
      "offset": 556.24,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "purpose model and we kind of use them in",
      "offset": 557.68,
      "duration": 3.279
    },
    {
      "lang": "en",
      "text": "different ways. I just I just wonder a",
      "offset": 559.6,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "little bit about, you know, inference",
      "offset": 560.959,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "costs and all the rest that comes with",
      "offset": 562.88,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "larger, more generalizable models versus",
      "offset": 564.959,
      "duration": 2.721
    },
    {
      "lang": "en",
      "text": "specialized things. So that that was a",
      "offset": 566.56,
      "duration": 2.16
    },
    {
      "lang": "en",
      "text": "little bit of the basis of the question",
      "offset": 567.68,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "in addition to what you said. Yeah, I",
      "offset": 568.72,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "think for some other companies they have",
      "offset": 570.72,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "a very large number of models and it's",
      "offset": 573.6,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "really hard to know as a sort of",
      "offset": 575.68,
      "duration": 6.48
    },
    {
      "lang": "en",
      "text": "non-expert how how I should use one or",
      "offset": 578.88,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "the other or why I should use one or the",
      "offset": 582.16,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "other and the names are really confusing",
      "offset": 584.16,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "like some of the names are the same as",
      "offset": 586.64,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "the other names backwards and then I'm",
      "offset": 588.08,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "like I have no idea which one this is.",
      "offset": 590.72,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "In our case, we only have two models and",
      "offset": 592.72,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "they're differentiated by a like cost",
      "offset": 595.44,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "performance paro frontier and we might",
      "offset": 598.08,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "have more of those in the future, but",
      "offset": 601.04,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "hopefully we'll like keep them on the",
      "offset": 603.2,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "same paro frontier. Uh so maybe we'll",
      "offset": 604.88,
      "duration": 4.959
    },
    {
      "lang": "en",
      "text": "have like a cheaper one or or a bigger",
      "offset": 607.92,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "one. And I think that makes it pretty",
      "offset": 609.839,
      "duration": 4.881
    },
    {
      "lang": "en",
      "text": "easy to think about, but at the same",
      "offset": 612.48,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "time, as a user, you don't want to have",
      "offset": 614.72,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "to decide yourself, does this merit more",
      "offset": 616.48,
      "duration": 5.359
    },
    {
      "lang": "en",
      "text": "dollars or less dollars? um do I need",
      "offset": 619.12,
      "duration": 4.719
    },
    {
      "lang": "en",
      "text": "the intelligence and so I think having",
      "offset": 621.839,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "like an a routing layer would make a lot",
      "offset": 623.839,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "of sense. Do you see any other",
      "offset": 625.839,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "specialization coming at the foundation",
      "offset": 627.76,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "model layer? So for example, if I look",
      "offset": 629.279,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "at other precedents in history, I look",
      "offset": 630.88,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "at um Microsoft OS or I look at Google",
      "offset": 632.88,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "storage or other things. Often what you",
      "offset": 635.76,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "ended up with is forward integration",
      "offset": 637.92,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "into the the primary applications that",
      "offset": 639.36,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "resided on top of that platform. So in",
      "offset": 641.36,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "the context of Microsoft for example",
      "offset": 643.68,
      "duration": 3.599
    },
    {
      "lang": "en",
      "text": "eventually they built Excel and Word and",
      "offset": 645.2,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "PowerPoint and all these things as",
      "offset": 647.279,
      "duration": 3.041
    },
    {
      "lang": "en",
      "text": "Office and those were individual apps",
      "offset": 648.48,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "from third party companies that were",
      "offset": 650.32,
      "duration": 2.56
    },
    {
      "lang": "en",
      "text": "running on top of them but they ended up",
      "offset": 651.6,
      "duration": 3.359
    },
    {
      "lang": "en",
      "text": "being amongst the most important",
      "offset": 652.88,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "applications that you could use on top",
      "offset": 654.959,
      "duration": 3.361
    },
    {
      "lang": "en",
      "text": "of Microsoft or in the context of",
      "offset": 656.8,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "Google. They kind of forward integrated",
      "offset": 658.32,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "eventually into travel and local and a",
      "offset": 660.24,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "variety of other things. Um obviously",
      "offset": 663.2,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "OpenAI is in the process of buying wind",
      "offset": 665.04,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "surf. So I was a little bit curious how",
      "offset": 666.8,
      "duration": 3.599
    },
    {
      "lang": "en",
      "text": "you think about uh forward or vertical",
      "offset": 668.24,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "integration to some of the the primary",
      "offset": 670.399,
      "duration": 2.88
    },
    {
      "lang": "en",
      "text": "use cases for these types of",
      "offset": 672,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "applications over time. Maybe I'll use",
      "offset": 673.279,
      "duration": 5.361
    },
    {
      "lang": "en",
      "text": "coding as an example. So we noticed that",
      "offset": 675.2,
      "duration": 6.24
    },
    {
      "lang": "en",
      "text": "our models were much better at coding",
      "offset": 678.64,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "than pretty much anything else out",
      "offset": 681.44,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "there. And I know that other companies",
      "offset": 683.04,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "have had like code reds for trying to",
      "offset": 685.12,
      "duration": 4.719
    },
    {
      "lang": "en",
      "text": "catch up in coding capabilities for",
      "offset": 688.24,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "quite a while and have not been able to",
      "offset": 689.839,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "do it. Honestly, I'm kind of surprised",
      "offset": 691.92,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "that that they weren't able to catch up,",
      "offset": 693.76,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "but uh I'll take it. So things are going",
      "offset": 695.44,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "pretty well there for us. Um and based",
      "offset": 698.32,
      "duration": 5.84
    },
    {
      "lang": "en",
      "text": "on that from like a a classic startup",
      "offset": 701.12,
      "duration": 6.32
    },
    {
      "lang": "en",
      "text": "founder sense of what is important. I",
      "offset": 704.16,
      "duration": 6.239
    },
    {
      "lang": "en",
      "text": "felt that coding as an application was",
      "offset": 707.44,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "something that we couldn't solely allow",
      "offset": 710.399,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "our customers to handle for us. So we",
      "offset": 712.8,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "love our partners like cursor and and",
      "offset": 715.519,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "GitHub who have been using our models",
      "offset": 718,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "quite heavily but the amount and the",
      "offset": 720.079,
      "duration": 5.841
    },
    {
      "lang": "en",
      "text": "speed that we learn is much less if we",
      "offset": 723.12,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "don't have a direct relationship with",
      "offset": 725.92,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "our coding users. So launching cloud",
      "offset": 727.279,
      "duration": 5.281
    },
    {
      "lang": "en",
      "text": "code was really essential for us to get",
      "offset": 729.44,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "a better sense of what do people need,",
      "offset": 732.56,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "how do we make the models better and how",
      "offset": 735.04,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "do we advance the state-of-the-art and",
      "offset": 737.12,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "user experience. And we found that once",
      "offset": 739.2,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "we launched cloud code, a lot of our",
      "offset": 741.279,
      "duration": 5.201
    },
    {
      "lang": "en",
      "text": "customers copied various pieces of the",
      "offset": 744,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "experience and that was really good for",
      "offset": 746.48,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "everyone because them having more users",
      "offset": 748,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "means we have a tighter relationship",
      "offset": 750.56,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "with them. So I think it was one of",
      "offset": 752.56,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "those things where before it happened it",
      "offset": 754.72,
      "duration": 4.239
    },
    {
      "lang": "en",
      "text": "felt really scary and we're like oh are",
      "offset": 756.959,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "we going to be like distancing ourselves",
      "offset": 758.959,
      "duration": 3.521
    },
    {
      "lang": "en",
      "text": "from our partners by competing with",
      "offset": 760.56,
      "duration": 4.959
    },
    {
      "lang": "en",
      "text": "them? But actually everybody was pretty",
      "offset": 762.48,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "happy afterwards. And I think that will",
      "offset": 765.519,
      "duration": 4.481
    },
    {
      "lang": "en",
      "text": "continue to be true where we see the",
      "offset": 768.16,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "models seeing like dramatic improvements",
      "offset": 770,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "in usability and and usage. We'll want",
      "offset": 772.48,
      "duration": 5.919
    },
    {
      "lang": "en",
      "text": "to again have like build things where we",
      "offset": 775.44,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "can have that direct relationship. Makes",
      "offset": 778.399,
      "duration": 2.961
    },
    {
      "lang": "en",
      "text": "sense. And I guess coding is one of",
      "offset": 780,
      "duration": 3.519
    },
    {
      "lang": "en",
      "text": "those things that has almost three core",
      "offset": 781.36,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "purposes. One is it's a very popular",
      "offset": 783.519,
      "duration": 4.241
    },
    {
      "lang": "en",
      "text": "area for customers to use or to adopt.",
      "offset": 785.279,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "Two is it's a really interesting data",
      "offset": 787.76,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "set to get back to your point in terms",
      "offset": 789.2,
      "duration": 3.439
    },
    {
      "lang": "en",
      "text": "of how people are using it and what sort",
      "offset": 791.04,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "of code they're generating. And then",
      "offset": 792.639,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "third, excellence at coding seems to be",
      "offset": 794.24,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "really important tool for helping train",
      "offset": 796.56,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "the next future model. If you think",
      "offset": 798.639,
      "duration": 2.88
    },
    {
      "lang": "en",
      "text": "through things like data labeling, if",
      "offset": 800.399,
      "duration": 2.321
    },
    {
      "lang": "en",
      "text": "you think through actually writing code,",
      "offset": 801.519,
      "duration": 2.961
    },
    {
      "lang": "en",
      "text": "eventually I think a lot of people",
      "offset": 802.72,
      "duration": 3.359
    },
    {
      "lang": "en",
      "text": "believe that a lot of the heavy lifting",
      "offset": 804.48,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "of building a model will be driven by",
      "offset": 806.079,
      "duration": 4.481
    },
    {
      "lang": "en",
      "text": "the models, right? In terms of coding.",
      "offset": 808.639,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "So maybe cloud five builds cloud six and",
      "offset": 810.56,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "cloud six by builds cloud 7 faster and",
      "offset": 812.8,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "that builds cloud eight faster. And so",
      "offset": 814.8,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "you end up with this sort of liftoff",
      "offset": 816.72,
      "duration": 2.799
    },
    {
      "lang": "en",
      "text": "towards EGI or whatever it is that",
      "offset": 818,
      "duration": 3.519
    },
    {
      "lang": "en",
      "text": "you're shooting for relative to code.",
      "offset": 819.519,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "How much is that a motivator for how you",
      "offset": 821.519,
      "duration": 2.961
    },
    {
      "lang": "en",
      "text": "all think about the importance of",
      "offset": 823.44,
      "duration": 2.24
    },
    {
      "lang": "en",
      "text": "coding? And how do you think about that",
      "offset": 824.48,
      "duration": 2.56
    },
    {
      "lang": "en",
      "text": "in the context of some of these bigger",
      "offset": 825.68,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "picture things? I read AI 2027 which is",
      "offset": 827.04,
      "duration": 4.799
    },
    {
      "lang": "en",
      "text": "basically exactly the story that you",
      "offset": 830,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "just described. And it forecasts that in",
      "offset": 831.839,
      "duration": 5.281
    },
    {
      "lang": "en",
      "text": "2028, which is confusing because of the",
      "offset": 835.12,
      "duration": 4.719
    },
    {
      "lang": "en",
      "text": "name, that's the the 50 percentile",
      "offset": 837.12,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "forecast for when we'll have this sort",
      "offset": 839.839,
      "duration": 5.921
    },
    {
      "lang": "en",
      "text": "of recursive self-improvement loop lead",
      "offset": 842.8,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "us to something that looks like",
      "offset": 845.76,
      "duration": 4.639
    },
    {
      "lang": "en",
      "text": "superhuman AI in most areas. And I think",
      "offset": 847.04,
      "duration": 5.359
    },
    {
      "lang": "en",
      "text": "that is really important to us. And part",
      "offset": 850.399,
      "duration": 3.761
    },
    {
      "lang": "en",
      "text": "of the reason that we built and launched",
      "offset": 852.399,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "Cloud Code is that it was massively",
      "offset": 854.16,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "taking off internally. And we were like,",
      "offset": 856.399,
      "duration": 3.521
    },
    {
      "lang": "en",
      "text": "well, we're just learning so much from",
      "offset": 858.079,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "this from our own users. Maybe we'll",
      "offset": 859.92,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "learn a lot from external users as well.",
      "offset": 862.079,
      "duration": 4.481
    },
    {
      "lang": "en",
      "text": "Um, and seeing our researchers pick it",
      "offset": 864.16,
      "duration": 4.479
    },
    {
      "lang": "en",
      "text": "up and use it, that was also really",
      "offset": 866.56,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "important because it meant that they had",
      "offset": 868.639,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "a direct feedback loop from I'm training",
      "offset": 870.32,
      "duration": 6.079
    },
    {
      "lang": "en",
      "text": "this model and I personally am feeling",
      "offset": 873.519,
      "duration": 4.721
    },
    {
      "lang": "en",
      "text": "the pain of its weaknesses. Now I'm",
      "offset": 876.399,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "extra motivated to go fix those pain",
      "offset": 878.24,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "points. They they have a much better",
      "offset": 880.32,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "feel for what the model's strengths and",
      "offset": 882.16,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "weaknesses are. Do you believe that 2028",
      "offset": 884.639,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "is the likely time frame towards sort of",
      "offset": 887.36,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "general super intelligence? Um, I think",
      "offset": 889.199,
      "duration": 6.32
    },
    {
      "lang": "en",
      "text": "it's quite possible. Uh, I I think it's",
      "offset": 892.88,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "very hard to put confident bounds on on",
      "offset": 895.519,
      "duration": 6.081
    },
    {
      "lang": "en",
      "text": "the numbers, but yeah, I guess the way I",
      "offset": 898.56,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "define my metric for when things start",
      "offset": 901.6,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "to get really interesting from a",
      "offset": 903.76,
      "duration": 4.639
    },
    {
      "lang": "en",
      "text": "societal and cultural standpoint is when",
      "offset": 905.92,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "we've passed the economic turning test,",
      "offset": 908.399,
      "duration": 4.961
    },
    {
      "lang": "en",
      "text": "which is if you take a market basket",
      "offset": 910.48,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "that represents like 50% of economically",
      "offset": 913.36,
      "duration": 6.479
    },
    {
      "lang": "en",
      "text": "valuable tasks and you basically have",
      "offset": 916,
      "duration": 6.079
    },
    {
      "lang": "en",
      "text": "the hiring manager for each of those",
      "offset": 919.839,
      "duration": 5.521
    },
    {
      "lang": "en",
      "text": "roles hire hire an agent and pass the",
      "offset": 922.079,
      "duration": 5.681
    },
    {
      "lang": "en",
      "text": "economic turning test which is the agent",
      "offset": 925.36,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "contracts for you for like a month at",
      "offset": 927.76,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "the end you have to decide do I hire",
      "offset": 929.36,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "this person or machine and then if it",
      "offset": 931.12,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "ends up being a machine then it passed",
      "offset": 933.92,
      "duration": 3.359
    },
    {
      "lang": "en",
      "text": "then that's when we have transformative",
      "offset": 935.68,
      "duration": 4.719
    },
    {
      "lang": "en",
      "text": "AI do you test that internally we",
      "offset": 937.279,
      "duration": 5.281
    },
    {
      "lang": "en",
      "text": "haven't started testing it rigorously",
      "offset": 940.399,
      "duration": 5.921
    },
    {
      "lang": "en",
      "text": "yet I mean we we have had our models",
      "offset": 942.56,
      "duration": 6.639
    },
    {
      "lang": "en",
      "text": "take our interviews and they're",
      "offset": 946.32,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "extremely good so I don't think that",
      "offset": 949.199,
      "duration": 4.801
    },
    {
      "lang": "en",
      "text": "would tell us but Yeah, interviews are",
      "offset": 951.92,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "only a poor approximation of real job",
      "offset": 954,
      "duration": 5.279
    },
    {
      "lang": "en",
      "text": "performance. U unfortunately to a lot's",
      "offset": 956.16,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "earlier question about let's say like",
      "offset": 959.279,
      "duration": 4.721
    },
    {
      "lang": "en",
      "text": "model self-improvement and and tell me",
      "offset": 961.68,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "if I'm just like missing options here,",
      "offset": 964,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "but if you're to stack rank the",
      "offset": 965.68,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "potential ways models could have impact",
      "offset": 967.44,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "on you know the acceleration of model",
      "offset": 970.32,
      "duration": 4.959
    },
    {
      "lang": "en",
      "text": "development. Do you think it will be on",
      "offset": 972.56,
      "duration": 5.519
    },
    {
      "lang": "en",
      "text": "the data side on infrastructure on like",
      "offset": 975.279,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "architectural search on just engineering",
      "offset": 978.079,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "velocity like where do you think we'll",
      "offset": 981.279,
      "duration": 3.521
    },
    {
      "lang": "en",
      "text": "see the impact first? It's a good",
      "offset": 983.199,
      "duration": 3.041
    },
    {
      "lang": "en",
      "text": "question. I think it's changing a bit",
      "offset": 984.8,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "over time where today the models are",
      "offset": 986.24,
      "duration": 6.32
    },
    {
      "lang": "en",
      "text": "really good at coding and the bulk of",
      "offset": 988.88,
      "duration": 6.72
    },
    {
      "lang": "en",
      "text": "the coding for making models better is",
      "offset": 992.56,
      "duration": 5.279
    },
    {
      "lang": "en",
      "text": "in sort of the systems engineering side",
      "offset": 995.6,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "of things. As researchers, there's not",
      "offset": 997.839,
      "duration": 5.601
    },
    {
      "lang": "en",
      "text": "necessarily that much raw code that you",
      "offset": 1000.8,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "need to write, but it's more in the",
      "offset": 1003.44,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "validation, coming up with what surgical",
      "offset": 1005.12,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "intervention do you make and then",
      "offset": 1007.759,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "validating that. That said, Claude is",
      "offset": 1009.12,
      "duration": 4.639
    },
    {
      "lang": "en",
      "text": "really good at data analysis. And so",
      "offset": 1011.36,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "once you run your experiments or",
      "offset": 1013.759,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "watching the experiments over time and",
      "offset": 1015.92,
      "duration": 3.599
    },
    {
      "lang": "en",
      "text": "seeing if something weird happens, we",
      "offset": 1017.519,
      "duration": 4.481
    },
    {
      "lang": "en",
      "text": "found that Cloud Code can be a really",
      "offset": 1019.519,
      "duration": 5.121
    },
    {
      "lang": "en",
      "text": "powerful tool there in terms of driving",
      "offset": 1022,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "Jupyter notebooks or tailing logs for",
      "offset": 1024.64,
      "duration": 5.279
    },
    {
      "lang": "en",
      "text": "you. and seeing if something happens.",
      "offset": 1027.12,
      "duration": 6.799
    },
    {
      "lang": "en",
      "text": "So, it's it's starting to pick up more",
      "offset": 1029.919,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "of the research side of things. And then",
      "offset": 1033.919,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "we recently launched our uh advanced",
      "offset": 1035.679,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "research product and that can not only",
      "offset": 1038,
      "duration": 5.039
    },
    {
      "lang": "en",
      "text": "look at external data sources like",
      "offset": 1041.199,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "crawling archive and whatever u but also",
      "offset": 1043.039,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "internal data sources like all of your",
      "offset": 1045.439,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "Google drive and that's been pretty",
      "offset": 1047.36,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "useful for our researchers figuring out",
      "offset": 1049.12,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "is there prior art has somebody already",
      "offset": 1052,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "tried this and if they did what what did",
      "offset": 1054.16,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "they try cuz you know no negative",
      "offset": 1055.84,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "results are final in research so trying",
      "offset": 1057.6,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "to figure out like oh maybe there's a",
      "offset": 1060.88,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "different angle that I could use on this",
      "offset": 1062.4,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "or maybe there is some like doing some",
      "offset": 1064.24,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "comparative analysis between an internal",
      "offset": 1066.72,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "effort and some external thing that just",
      "offset": 1069.12,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "came out. Those are all ways that we can",
      "offset": 1071.12,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "accelerate. And then on the data side,",
      "offset": 1072.96,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "RL environments are really important",
      "offset": 1075.6,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "these days, but constructing those",
      "offset": 1077.84,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "environments has traditionally been",
      "offset": 1079.44,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "expensive. Models are pretty good at",
      "offset": 1081.28,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "writing environments. So, it's another",
      "offset": 1083.36,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "area where we can sort of recursively",
      "offset": 1085.12,
      "duration": 4.799
    },
    {
      "lang": "en",
      "text": "self-improve. My understanding is that",
      "offset": 1086.96,
      "duration": 7.2
    },
    {
      "lang": "en",
      "text": "Anthropic has invested less in human",
      "offset": 1089.919,
      "duration": 7.201
    },
    {
      "lang": "en",
      "text": "expert data collection than some other",
      "offset": 1094.16,
      "duration": 4.879
    },
    {
      "lang": "en",
      "text": "labs. Can you say anything about that or",
      "offset": 1097.12,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "the philosophy on like scaling from here",
      "offset": 1099.039,
      "duration": 5.441
    },
    {
      "lang": "en",
      "text": "and sort of the different options? In",
      "offset": 1102.08,
      "duration": 5.92
    },
    {
      "lang": "en",
      "text": "2021, I built our human feedback data",
      "offset": 1104.48,
      "duration": 5.92
    },
    {
      "lang": "en",
      "text": "collection interface and we did a lot of",
      "offset": 1108,
      "duration": 4.559
    },
    {
      "lang": "en",
      "text": "data collection and it was very easy for",
      "offset": 1110.4,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "humans to give sort of like a gradient",
      "offset": 1112.559,
      "duration": 5.761
    },
    {
      "lang": "en",
      "text": "signal of like is A or B better for any",
      "offset": 1115.28,
      "duration": 5.279
    },
    {
      "lang": "en",
      "text": "given task and to come up with tasks",
      "offset": 1118.32,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "that were interesting and useful but",
      "offset": 1120.559,
      "duration": 4.721
    },
    {
      "lang": "en",
      "text": "didn't have a lot of coverage. As we've",
      "offset": 1122.88,
      "duration": 4.799
    },
    {
      "lang": "en",
      "text": "trained the models more and scaled up a",
      "offset": 1125.28,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "lot, it's become harder to find humans",
      "offset": 1127.679,
      "duration": 5.201
    },
    {
      "lang": "en",
      "text": "with enough expertise to meaningfully",
      "offset": 1130.08,
      "duration": 4.959
    },
    {
      "lang": "en",
      "text": "contribute to these feedback",
      "offset": 1132.88,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "comparisons. So, for example, for",
      "offset": 1135.039,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "coding, somebody who isn't already an",
      "offset": 1137.44,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "expert software engineer would probably",
      "offset": 1139.2,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "have a lot of trouble judging whether",
      "offset": 1141.28,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "one thing or another was better. And",
      "offset": 1143.28,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "that applies to many, many different",
      "offset": 1145.84,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "domains. So, that's one reason that it's",
      "offset": 1147.44,
      "duration": 4.479
    },
    {
      "lang": "en",
      "text": "harder to use human feedback. So, what",
      "offset": 1149.52,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "do you use instead? Like, how do you",
      "offset": 1151.919,
      "duration": 2.561
    },
    {
      "lang": "en",
      "text": "deal with that? Because I think even in",
      "offset": 1153.44,
      "duration": 2.64
    },
    {
      "lang": "en",
      "text": "the med palm 2 paper from Google a",
      "offset": 1154.48,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "couple years ago they fine-tuned a model",
      "offset": 1156.08,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "I think palm 2 to basically you know",
      "offset": 1158.32,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "outperform the average physician on",
      "offset": 1160.96,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "medical information. This was like 2",
      "offset": 1162.96,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "three years ago right and so basically",
      "offset": 1164.72,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "suggested you needed very deep levels of",
      "offset": 1166.08,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "expertise to be able to have humans",
      "offset": 1168.08,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "actually increase the fidelity of the",
      "offset": 1170.64,
      "duration": 3.279
    },
    {
      "lang": "en",
      "text": "model through post training. So we",
      "offset": 1172.08,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "pioneered RLF which is reinforcement",
      "offset": 1173.919,
      "duration": 5.281
    },
    {
      "lang": "en",
      "text": "learning from AI feedback and the method",
      "offset": 1176.96,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "that we used was called constitutional",
      "offset": 1179.2,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "AI where you have a list of natural",
      "offset": 1180.799,
      "duration": 6.24
    },
    {
      "lang": "en",
      "text": "language principles that you some of",
      "offset": 1184.08,
      "duration": 6.16
    },
    {
      "lang": "en",
      "text": "them we copied from some like who",
      "offset": 1187.039,
      "duration": 5.361
    },
    {
      "lang": "en",
      "text": "declaration of human rights and some of",
      "offset": 1190.24,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "them were from Apple's terms of service",
      "offset": 1192.4,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "and some of them we wrote ourselves and",
      "offset": 1194.72,
      "duration": 6.56
    },
    {
      "lang": "en",
      "text": "the process is very simple you just take",
      "offset": 1198,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "uh a random prompt like how should I",
      "offset": 1201.28,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "think about my taxes or something? And",
      "offset": 1203.44,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "then you have the model write a",
      "offset": 1205.6,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "response. Then you have the model",
      "offset": 1207.2,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "criticize its own response",
      "offset": 1210.32,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "with respect to one of the principles.",
      "offset": 1212.96,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "And then if it didn't comply with the",
      "offset": 1216.32,
      "duration": 4.479
    },
    {
      "lang": "en",
      "text": "principle, then you have the model",
      "offset": 1218.72,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "correct its response. And then you take",
      "offset": 1220.799,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "away all the middle section and do",
      "offset": 1223.2,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "supervised learning on the original",
      "offset": 1225.039,
      "duration": 7.041
    },
    {
      "lang": "en",
      "text": "uh prompt and the corrected response.",
      "offset": 1228.72,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "And that makes the model a lot better at",
      "offset": 1232.08,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "baking in the principles. That that's",
      "offset": 1234.48,
      "duration": 3.439
    },
    {
      "lang": "en",
      "text": "slightly different though, right?",
      "offset": 1236.72,
      "duration": 2.8
    },
    {
      "lang": "en",
      "text": "Because that that's principles. And so",
      "offset": 1237.919,
      "duration": 3.521
    },
    {
      "lang": "en",
      "text": "that could be all sorts of things that",
      "offset": 1239.52,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "in some sense converge on safety or",
      "offset": 1241.44,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "different forms of what people view as",
      "offset": 1243.36,
      "duration": 3.439
    },
    {
      "lang": "en",
      "text": "ethics or other aspects of model",
      "offset": 1244.64,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "training. And then there's a different",
      "offset": 1246.799,
      "duration": 4.721
    },
    {
      "lang": "en",
      "text": "question which is what is more correct?",
      "offset": 1249.039,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "And sometimes those are the same things",
      "offset": 1251.52,
      "duration": 3.039
    },
    {
      "lang": "en",
      "text": "and sometimes they're different. So like",
      "offset": 1252.88,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "for coding for example, you can have",
      "offset": 1254.559,
      "duration": 4.801
    },
    {
      "lang": "en",
      "text": "principles like did it actually serve",
      "offset": 1256.799,
      "duration": 5.201
    },
    {
      "lang": "en",
      "text": "the final answer or did it like do a",
      "offset": 1259.36,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "bunch of stuff that the person didn't",
      "offset": 1262,
      "duration": 3.039
    },
    {
      "lang": "en",
      "text": "ask for or does this code look",
      "offset": 1263.36,
      "duration": 3.679
    },
    {
      "lang": "en",
      "text": "maintainable? Are the comments like",
      "offset": 1265.039,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "useful and interesting? But but with",
      "offset": 1267.039,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "coding you actually have like a direct",
      "offset": 1268.88,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "output that uh you can measure, right?",
      "offset": 1271.039,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "You can run the code, you can test the",
      "offset": 1273.12,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "code, you can do things with it. How do",
      "offset": 1274.64,
      "duration": 3.519
    },
    {
      "lang": "en",
      "text": "you do that for medical information or",
      "offset": 1276.48,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "how you how do you do that for a legal",
      "offset": 1278.159,
      "duration": 3.041
    },
    {
      "lang": "en",
      "text": "opinion or how you know? So I totally",
      "offset": 1279.52,
      "duration": 3.519
    },
    {
      "lang": "en",
      "text": "agree for code there's sort of a bakedin",
      "offset": 1281.2,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "utility function you can optimize",
      "offset": 1283.039,
      "duration": 3.041
    },
    {
      "lang": "en",
      "text": "against or an environment that you can",
      "offset": 1284.32,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "optimize against in the context of a lot",
      "offset": 1286.08,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "of other aspects of human endeavor that",
      "offset": 1288.08,
      "duration": 2.88
    },
    {
      "lang": "en",
      "text": "that seems more challenging and you",
      "offset": 1289.52,
      "duration": 2.639
    },
    {
      "lang": "en",
      "text": "folks have thought about this so deeply",
      "offset": 1290.96,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "and so nicely. I'm just sort of curious,",
      "offset": 1292.159,
      "duration": 3.281
    },
    {
      "lang": "en",
      "text": "you know, how do you extrapolate into",
      "offset": 1294.08,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "these other areas where the the ability",
      "offset": 1295.44,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "to actually measure correctness in some",
      "offset": 1298.32,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "sense is more challenging for for areas",
      "offset": 1300,
      "duration": 4.559
    },
    {
      "lang": "en",
      "text": "where we can't measure correctness and",
      "offset": 1302.64,
      "duration": 5.919
    },
    {
      "lang": "en",
      "text": "the model doesn't have more taste than",
      "offset": 1304.559,
      "duration": 7.36
    },
    {
      "lang": "en",
      "text": "its execution ability. Like I think Ira",
      "offset": 1308.559,
      "duration": 5.441
    },
    {
      "lang": "en",
      "text": "Glass said that your vision will always",
      "offset": 1311.919,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "exceed your execution if you're doing",
      "offset": 1314,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "things right as a person, but for the",
      "offset": 1316.08,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "models maybe not. So I guess first",
      "offset": 1318.4,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "figuring out where you are in that",
      "offset": 1321.44,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "turning point in that in that trade-off",
      "offset": 1322.96,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "and see if you can go all the way up to",
      "offset": 1325.12,
      "duration": 4.799
    },
    {
      "lang": "en",
      "text": "that boundary and then second preference",
      "offset": 1327.2,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "models are the way that we get beyond",
      "offset": 1329.919,
      "duration": 5.681
    },
    {
      "lang": "en",
      "text": "that. So having a small amount of human",
      "offset": 1332.08,
      "duration": 6.479
    },
    {
      "lang": "en",
      "text": "feedback that we really trust from human",
      "offset": 1335.6,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "experts who are not just making a staff",
      "offset": 1338.559,
      "duration": 5.841
    },
    {
      "lang": "en",
      "text": "judgment but really going deep on why is",
      "offset": 1341.12,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "this better than that one and did I do",
      "offset": 1344.4,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "the research to figure it out or in like",
      "offset": 1346.64,
      "duration": 5.84
    },
    {
      "lang": "en",
      "text": "a human model centaur model of like can",
      "offset": 1348.799,
      "duration": 5.841
    },
    {
      "lang": "en",
      "text": "I use the model to help me come to the",
      "offset": 1352.48,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "best conclusion here and then illide all",
      "offset": 1354.64,
      "duration": 5.84
    },
    {
      "lang": "en",
      "text": "the middle stuff. I think that's one way",
      "offset": 1357.52,
      "duration": 5.039
    },
    {
      "lang": "en",
      "text": "and then during reinforcement learning",
      "offset": 1360.48,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "that preference model represents the",
      "offset": 1362.559,
      "duration": 4.721
    },
    {
      "lang": "en",
      "text": "sort of aggregated human judgment. That",
      "offset": 1365.12,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "makes sense. I guess one of the one of",
      "offset": 1367.28,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "the reasons I'm asking is eventually the",
      "offset": 1368.72,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "human side of this runs out, right?",
      "offset": 1370.96,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "There will be somebody whose expertise",
      "offset": 1372.72,
      "duration": 3.439
    },
    {
      "lang": "en",
      "text": "is just below that of the the model",
      "offset": 1374.32,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "eventually for any endeavor. And so I",
      "offset": 1376.159,
      "duration": 3.201
    },
    {
      "lang": "en",
      "text": "was just curious how to think about that",
      "offset": 1378.08,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "in the context of it's machines self-",
      "offset": 1379.36,
      "duration": 4.799
    },
    {
      "lang": "en",
      "text": "adjudicating. And then the question is,",
      "offset": 1381.76,
      "duration": 5.279
    },
    {
      "lang": "en",
      "text": "is there a more absolute basis against",
      "offset": 1384.159,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "which to adjudicate or is there some",
      "offset": 1387.039,
      "duration": 3.281
    },
    {
      "lang": "en",
      "text": "other way to really tease out",
      "offset": 1388.48,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "correctness? And again, I'm viewing it",
      "offset": 1390.32,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "in the context of things where you can",
      "offset": 1392.32,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "actually have a form of correct, right?",
      "offset": 1393.84,
      "duration": 2.48
    },
    {
      "lang": "en",
      "text": "There's all sorts of things that are",
      "offset": 1395.36,
      "duration": 2.799
    },
    {
      "lang": "en",
      "text": "opinion. Yeah. And that's different. And",
      "offset": 1396.32,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "maybe that's where the principles or",
      "offset": 1398.159,
      "duration": 2.721
    },
    {
      "lang": "en",
      "text": "other things for constitutional AI kick",
      "offset": 1399.36,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "in, but there's also forms of that for,",
      "offset": 1400.88,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "you know, how do you know if that's the",
      "offset": 1403.76,
      "duration": 2.799
    },
    {
      "lang": "en",
      "text": "right cardiac treatment or how do you",
      "offset": 1404.96,
      "duration": 2.8
    },
    {
      "lang": "en",
      "text": "know if that's the right legal",
      "offset": 1406.559,
      "duration": 2.48
    },
    {
      "lang": "en",
      "text": "interpretation or whatever it may be.",
      "offset": 1407.76,
      "duration": 2.72
    },
    {
      "lang": "en",
      "text": "So, I was just sort of curious when that",
      "offset": 1409.039,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "runs out and then what do we do? And I'm",
      "offset": 1410.48,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "I'm sure we'll ch we'll tackle those",
      "offset": 1412.72,
      "duration": 3.439
    },
    {
      "lang": "en",
      "text": "challenges as we get to them. But it has",
      "offset": 1414,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "to boil down to empiricism, I think, uh",
      "offset": 1416.159,
      "duration": 5.281
    },
    {
      "lang": "en",
      "text": "where like that's how smart humans get",
      "offset": 1418.96,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "to the next level of correctness when",
      "offset": 1421.44,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "the field is sort of hitting its limits.",
      "offset": 1424.64,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "And as an example, my dad is a physician",
      "offset": 1427.2,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "and at one point somebody came in with",
      "offset": 1430.32,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "something on some face problem, some",
      "offset": 1432.48,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "face skin problem, and he didn't know",
      "offset": 1434.32,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "what the problem was. So he was like,",
      "offset": 1436.48,
      "duration": 2.8
    },
    {
      "lang": "en",
      "text": "&quot;I'm just going to divide your face into",
      "offset": 1437.84,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "four quadrants and I'm going to put a",
      "offset": 1439.28,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "different treatment on these three and",
      "offset": 1440.96,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "leave one as control.&quot; And one quadrant",
      "offset": 1443.12,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "got better. And then he was like, &quot;All",
      "offset": 1445.52,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "right, we're done.&quot; So, you know,",
      "offset": 1447.6,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "sometimes you just won't know and you",
      "offset": 1450.4,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "have to try stuff. And with code, that's",
      "offset": 1452.08,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "easy because we can just do it in a loop",
      "offset": 1453.84,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "in without having to uh deal with the",
      "offset": 1456.4,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "physical world. But at some point, we're",
      "offset": 1459.52,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "going to need to work with companies",
      "offset": 1461.6,
      "duration": 4.559
    },
    {
      "lang": "en",
      "text": "that have actual biolabs, etc. Like for",
      "offset": 1463.44,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "example, we're working with Novo Nordisk",
      "offset": 1466.159,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "and it used to take them like 12 weeks",
      "offset": 1468.32,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "or something to write a report on cancer",
      "offset": 1471.039,
      "duration": 4.481
    },
    {
      "lang": "en",
      "text": "patient what kind of treatment they",
      "offset": 1474.08,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "should get and now it takes like 10",
      "offset": 1475.52,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "minutes to get the report and then they",
      "offset": 1477.12,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "can start doing empirical stuff on top",
      "offset": 1478.96,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "of that saying like okay we have these",
      "offset": 1480.96,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "options but now let's let's measure what",
      "offset": 1483.2,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "works and feed it back into the system.",
      "offset": 1485.2,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "That's so philosophically consistent,",
      "offset": 1487.039,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "right? Your your answer is not like well",
      "offset": 1489.52,
      "duration": 6.24
    },
    {
      "lang": "en",
      "text": "well you know collecting even rated",
      "offset": 1492.159,
      "duration": 7.041
    },
    {
      "lang": "en",
      "text": "human expertise from the best like uh is",
      "offset": 1495.76,
      "duration": 6.48
    },
    {
      "lang": "en",
      "text": "expensive one or you know runs out at",
      "offset": 1499.2,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "some point. It's hard to bring that all",
      "offset": 1502.24,
      "duration": 2.48
    },
    {
      "lang": "en",
      "text": "into distribution and doesn't",
      "offset": 1503.44,
      "duration": 2.96
    },
    {
      "lang": "en",
      "text": "generalize. While I'm making some",
      "offset": 1504.72,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "assumptions here instead like let's just",
      "offset": 1506.4,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "go get real world verifiers where we can",
      "offset": 1509.12,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "and like maybe that applies far beyond",
      "offset": 1512,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "math and code. At least that's some part",
      "offset": 1514.32,
      "duration": 4.239
    },
    {
      "lang": "en",
      "text": "of what I heard. Um, which is ambitious.",
      "offset": 1516.159,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "That's cool. One of the things that",
      "offset": 1518.559,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "Anthropic has been known for is an early",
      "offset": 1520.24,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "emphasis on safety and thinking through",
      "offset": 1521.919,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "different aspects of safety. And there's",
      "offset": 1523.6,
      "duration": 3.199
    },
    {
      "lang": "en",
      "text": "multiple forms of safety in AI. And I",
      "offset": 1525.039,
      "duration": 3.281
    },
    {
      "lang": "en",
      "text": "think people kind of mix the terms to",
      "offset": 1526.799,
      "duration": 2.961
    },
    {
      "lang": "en",
      "text": "mean different things, right? One form",
      "offset": 1528.32,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "of it is is the AI somehow being",
      "offset": 1529.76,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "offensive or crude or, you know, using",
      "offset": 1531.84,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "language you don't like or concepts you",
      "offset": 1534.08,
      "duration": 3.599
    },
    {
      "lang": "en",
      "text": "don't like. There's a second form of",
      "offset": 1536,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "safety which is much more about physical",
      "offset": 1537.679,
      "duration": 4.721
    },
    {
      "lang": "en",
      "text": "safety. You know, can it somehow cause a",
      "offset": 1539.44,
      "duration": 4.719
    },
    {
      "lang": "en",
      "text": "train to crash or a virus to form or",
      "offset": 1542.4,
      "duration": 2.879
    },
    {
      "lang": "en",
      "text": "whatever it is? And there's there's a",
      "offset": 1544.159,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "third form which is almost like does AGI",
      "offset": 1545.279,
      "duration": 4.801
    },
    {
      "lang": "en",
      "text": "resource aggregate or do other things",
      "offset": 1547.679,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "that can start co-opting humanity",
      "offset": 1550.08,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "overall. And so you all have thought",
      "offset": 1552,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "about this a lot and when I look at the",
      "offset": 1553.44,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "safety landscape it feels like there's a",
      "offset": 1555.76,
      "duration": 2.96
    },
    {
      "lang": "en",
      "text": "broad spectrum of different approaches",
      "offset": 1557.36,
      "duration": 3.439
    },
    {
      "lang": "en",
      "text": "that people have taken over time and",
      "offset": 1558.72,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "some of the approaches overlap with some",
      "offset": 1560.799,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "things like constitutional AI in terms",
      "offset": 1562.799,
      "duration": 2.641
    },
    {
      "lang": "en",
      "text": "of setting some principles and",
      "offset": 1564.159,
      "duration": 2.801
    },
    {
      "lang": "en",
      "text": "frameworks for how things should work.",
      "offset": 1565.44,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "There's other forms as well. And if I",
      "offset": 1566.96,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "look at biology, research is an analog.",
      "offset": 1568.72,
      "duration": 2.959
    },
    {
      "lang": "en",
      "text": "And I used to be a biologist. So I often",
      "offset": 1570.24,
      "duration": 2.88
    },
    {
      "lang": "en",
      "text": "reduce things back into those terms for",
      "offset": 1571.679,
      "duration": 2.88
    },
    {
      "lang": "en",
      "text": "some reason that I can't help myself.",
      "offset": 1573.12,
      "duration": 2.4
    },
    {
      "lang": "en",
      "text": "There are certain things that I almost",
      "offset": 1574.559,
      "duration": 2.561
    },
    {
      "lang": "en",
      "text": "view as like gain of function research",
      "offset": 1575.52,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "equivalence, right? Like and a lot of",
      "offset": 1577.12,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "those things I just think are kind of",
      "offset": 1578.96,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "not really useful for biology. You know,",
      "offset": 1580.32,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "like cycling a virus through mamleion",
      "offset": 1582.08,
      "duration": 4.719
    },
    {
      "lang": "en",
      "text": "cells to make it more infectible cells",
      "offset": 1584.24,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "doesn't really teach you much about",
      "offset": 1586.799,
      "duration": 2.321
    },
    {
      "lang": "en",
      "text": "basic biology. You kind of know how",
      "offset": 1587.76,
      "duration": 3.279
    },
    {
      "lang": "en",
      "text": "that's going to work, but it creates",
      "offset": 1589.12,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "real risk. And if you look at the",
      "offset": 1591.039,
      "duration": 3.361
    },
    {
      "lang": "en",
      "text": "history of lab leaks in general, you",
      "offset": 1592.4,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "know, SARS leaked multiple times from",
      "offset": 1594.4,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "what was then the Beijing Institute of",
      "offset": 1596.64,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "Urology in the early 2000s in China. It",
      "offset": 1598.08,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "leaked in Hong Kong a few times. Ebola",
      "offset": 1601.039,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "leaks every four years or so like",
      "offset": 1603.6,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "clockwork if you look at the Wikipedia",
      "offset": 1605.039,
      "duration": 4.801
    },
    {
      "lang": "en",
      "text": "page on lab leaks. And I think the 1977",
      "offset": 1606.64,
      "duration": 6.08
    },
    {
      "lang": "en",
      "text": "or 78 global flu pandemic is believed to",
      "offset": 1609.84,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "actually have been a Russian lab leak as",
      "offset": 1612.72,
      "duration": 2.319
    },
    {
      "lang": "en",
      "text": "an example, right? So we know these",
      "offset": 1614,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "things can cause damage at scale. Um, so",
      "offset": 1615.039,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "I have kind of two questions. One is",
      "offset": 1617.6,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "what forms of AI safety research do you",
      "offset": 1619.679,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "think should not be pursued almost given",
      "offset": 1622.08,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "through that analog of you know what's",
      "offset": 1624.08,
      "duration": 2.8
    },
    {
      "lang": "en",
      "text": "the equivalent of gain of function",
      "offset": 1625.6,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "research and how do you think about that",
      "offset": 1626.88,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "in the context of you know there have",
      "offset": 1628.96,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "been um different research papers around",
      "offset": 1630.32,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "can we teach AI to mislead us can we",
      "offset": 1632.48,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "teach AI to jailbreak itself so we can",
      "offset": 1634.4,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "study how it does that and I'm just sort",
      "offset": 1636.08,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "of curious for those specific cases as",
      "offset": 1637.52,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "well how you think about that so I think",
      "offset": 1639.6,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "part of it is we're interested in AI",
      "offset": 1641.84,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "alignment and the hope is that if we can",
      "offset": 1644.4,
      "duration": 5.84
    },
    {
      "lang": "en",
      "text": "figure out how to do the like idiomatic",
      "offset": 1647.12,
      "duration": 6.64
    },
    {
      "lang": "en",
      "text": "today problems like how does is the",
      "offset": 1650.24,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "model mean to you or does it use hate",
      "offset": 1653.76,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "speech or things like that that the same",
      "offset": 1655.6,
      "duration": 4.959
    },
    {
      "lang": "en",
      "text": "techniques we can use for that will",
      "offset": 1658.48,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "eventually also have relevance for the",
      "offset": 1660.559,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "much harder problems of like does it",
      "offset": 1662.96,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "give you the recipe to create smallox",
      "offset": 1664.799,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "which is probably one of the highest",
      "offset": 1667.2,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "harms that we think about and Amanda",
      "offset": 1668.559,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "Ascll has been doing a bunch of work on",
      "offset": 1671.2,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "this on Claude's character of like when",
      "offset": 1672.64,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "Claude refuses does it just say I can't",
      "offset": 1675.12,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "talk to you about that and shut down or",
      "offset": 1677.6,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "does it actually try to explain like",
      "offset": 1679.52,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "this is why I can't talk to you about",
      "offset": 1681.6,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "this or we have this other project led",
      "offset": 1682.88,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "by Kyle Fish our model welfare lead",
      "offset": 1685.12,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "where Claude can actually opt out of",
      "offset": 1687.36,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "conversations if it's going too far in",
      "offset": 1689.36,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "the wrong direction. What aspects of",
      "offset": 1691.52,
      "duration": 3.279
    },
    {
      "lang": "en",
      "text": "that should a a company actually",
      "offset": 1693.279,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "adjudicate? Because the dumb version of",
      "offset": 1694.799,
      "duration": 6.081
    },
    {
      "lang": "en",
      "text": "this is I'm using Microsoft Word and I'm",
      "offset": 1697.919,
      "duration": 4.561
    },
    {
      "lang": "en",
      "text": "typing something up and Word doesn't",
      "offset": 1700.88,
      "duration": 3.519
    },
    {
      "lang": "en",
      "text": "stop me from saying things which I think",
      "offset": 1702.48,
      "duration": 3.439
    },
    {
      "lang": "en",
      "text": "is correct. Like I actually don't think",
      "offset": 1704.399,
      "duration": 3.361
    },
    {
      "lang": "en",
      "text": "in many cases these products should",
      "offset": 1705.919,
      "duration": 3.521
    },
    {
      "lang": "en",
      "text": "censor us or prevent us from having",
      "offset": 1707.76,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "certain types of speech. And I've had",
      "offset": 1709.44,
      "duration": 3.119
    },
    {
      "lang": "en",
      "text": "some experiences with some of these",
      "offset": 1711.36,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "models where I actually feel like it's",
      "offset": 1712.559,
      "duration": 3.761
    },
    {
      "lang": "en",
      "text": "prevented me from actually asking the",
      "offset": 1714.48,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "question I want to ask right in my in my",
      "offset": 1716.32,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "opinion wrongfully, right? It's kind of",
      "offset": 1718.64,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "interfering with and I'm not like doing",
      "offset": 1720.24,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "hate speech on a model. And so you can",
      "offset": 1722.24,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "tell that there's some human who has a",
      "offset": 1724.08,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "different bar for what is acceptable to",
      "offset": 1725.84,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "discuss society. And that bar may be",
      "offset": 1727.6,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "very different from what I think may be",
      "offset": 1729.76,
      "duration": 2.72
    },
    {
      "lang": "en",
      "text": "mainstream too. So, I'm a little bit",
      "offset": 1731.12,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "curious like why even go there? Like why",
      "offset": 1732.48,
      "duration": 5.919
    },
    {
      "lang": "en",
      "text": "why is that a model company's business?",
      "offset": 1735.12,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "Well, I think it's a smooth spectrum",
      "offset": 1738.399,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "actually. It might not look like that",
      "offset": 1740.24,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "way from the outside, but when we train",
      "offset": 1741.919,
      "duration": 5.201
    },
    {
      "lang": "en",
      "text": "our classifiers on are you doing",
      "offset": 1744.48,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "function research as a biologist and is",
      "offset": 1747.12,
      "duration": 6.4
    },
    {
      "lang": "en",
      "text": "it for potentially negative outcomes.",
      "offset": 1750.24,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "These technologies are all dual use and",
      "offset": 1753.52,
      "duration": 5.279
    },
    {
      "lang": "en",
      "text": "we need to try to walk that line between",
      "offset": 1755.76,
      "duration": 6.399
    },
    {
      "lang": "en",
      "text": "overly refusing and refusing the stuff",
      "offset": 1758.799,
      "duration": 5.281
    },
    {
      "lang": "en",
      "text": "that's actually harmful. I see. But",
      "offset": 1762.159,
      "duration": 3.441
    },
    {
      "lang": "en",
      "text": "there's also political versions of that,",
      "offset": 1764.08,
      "duration": 2.8
    },
    {
      "lang": "en",
      "text": "right? And that's that's the stuff that",
      "offset": 1765.6,
      "duration": 3.199
    },
    {
      "lang": "en",
      "text": "irks me a bit more is, you know, where",
      "offset": 1766.88,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "is the line on what is considered an",
      "offset": 1768.799,
      "duration": 5.521
    },
    {
      "lang": "en",
      "text": "acceptable question, right? So examples",
      "offset": 1770.88,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "of that that I'm not saying are model",
      "offset": 1774.32,
      "duration": 3.599
    },
    {
      "lang": "en",
      "text": "specific but society sometimes cause",
      "offset": 1776.08,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "flare-ups is asking about human IQ or",
      "offset": 1777.919,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "other topics where there is a factual",
      "offset": 1780.48,
      "duration": 3.439
    },
    {
      "lang": "en",
      "text": "basis for discussion and then often",
      "offset": 1782.08,
      "duration": 2.88
    },
    {
      "lang": "en",
      "text": "those sorts of things tend to be",
      "offset": 1783.919,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "censored right and so the question is",
      "offset": 1784.96,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "why why would a foundation model company",
      "offset": 1787.039,
      "duration": 4.961
    },
    {
      "lang": "en",
      "text": "delve into some of those areas on things",
      "offset": 1789.76,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "like questions about IQ I'm not up on",
      "offset": 1792,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "the on the details of that enough to",
      "offset": 1795.2,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "comment but I can talk about our RSP so",
      "offset": 1797.12,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "RSP stands for responsible scale scaling",
      "offset": 1800.32,
      "duration": 4.959
    },
    {
      "lang": "en",
      "text": "policy and it talks about how do we make",
      "offset": 1802.64,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "sure that as the models get more",
      "offset": 1805.279,
      "duration": 6.161
    },
    {
      "lang": "en",
      "text": "intelligent that we are continuing to do",
      "offset": 1808,
      "duration": 5.039
    },
    {
      "lang": "en",
      "text": "our due diligence and making sure that",
      "offset": 1811.44,
      "duration": 2.959
    },
    {
      "lang": "en",
      "text": "we're not deploying something that we",
      "offset": 1813.039,
      "duration": 2.88
    },
    {
      "lang": "en",
      "text": "don't have the correct safeguards in",
      "offset": 1814.399,
      "duration": 6.241
    },
    {
      "lang": "en",
      "text": "place for. Um and initially our our RSP",
      "offset": 1815.919,
      "duration": 7.841
    },
    {
      "lang": "en",
      "text": "talked about CBRN which is chemical,",
      "offset": 1820.64,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "radiological, nuclear and biological",
      "offset": 1823.76,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "risks which are different areas that",
      "offset": 1825.84,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "could cause severe loss of life in the",
      "offset": 1828.08,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "world. And that's how we thought about",
      "offset": 1830.72,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "the harms. But now we're much more",
      "offset": 1832.64,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "focused on biology because if you think",
      "offset": 1835.039,
      "duration": 5.201
    },
    {
      "lang": "en",
      "text": "about like the amount of resources that",
      "offset": 1837.36,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "you would need to cause a nuclear harm,",
      "offset": 1840.24,
      "duration": 4.799
    },
    {
      "lang": "en",
      "text": "you'd probably have to be like a state",
      "offset": 1843.12,
      "duration": 4.799
    },
    {
      "lang": "en",
      "text": "actor to get those resources and and be",
      "offset": 1845.039,
      "duration": 5.601
    },
    {
      "lang": "en",
      "text": "able to use them in a harmful way.",
      "offset": 1847.919,
      "duration": 6.401
    },
    {
      "lang": "en",
      "text": "Whereas a much smaller group of random",
      "offset": 1850.64,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "people could get their hands on the",
      "offset": 1854.32,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "reagents necessary for biological harm.",
      "offset": 1856.24,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "How is that different from today?",
      "offset": 1858.88,
      "duration": 3.679
    },
    {
      "lang": "en",
      "text": "because I always felt the biology",
      "offset": 1860.24,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "example is one where I actually worry",
      "offset": 1862.559,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "less maybe as a former biologist because",
      "offset": 1864.159,
      "duration": 5.361
    },
    {
      "lang": "en",
      "text": "I already know that the genome for the",
      "offset": 1866.399,
      "duration": 4.801
    },
    {
      "lang": "en",
      "text": "smallox virus or potentially other",
      "offset": 1869.52,
      "duration": 3.519
    },
    {
      "lang": "en",
      "text": "things is already posted online. All the",
      "offset": 1871.2,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "protocols for how to actually do these",
      "offset": 1873.039,
      "duration": 2.961
    },
    {
      "lang": "en",
      "text": "things are posted online for multiple",
      "offset": 1874.48,
      "duration": 2.88
    },
    {
      "lang": "en",
      "text": "labs, right? You can just do Google",
      "offset": 1876,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "searches for how do I amplify the DNA of",
      "offset": 1877.36,
      "duration": 5.84
    },
    {
      "lang": "en",
      "text": "X or how do I order oligos for Y. We do",
      "offset": 1879.52,
      "duration": 6.48
    },
    {
      "lang": "en",
      "text": "specific tests with varying degrees of",
      "offset": 1883.2,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "biology experts to see how much uplift",
      "offset": 1886,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "there is relative to Google search. And",
      "offset": 1888.64,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "so one of the reasons that our most",
      "offset": 1890.96,
      "duration": 5.439
    },
    {
      "lang": "en",
      "text": "recent model opus 4 is classified as",
      "offset": 1893.2,
      "duration": 6.4
    },
    {
      "lang": "en",
      "text": "ASL3 is because it did have significant",
      "offset": 1896.399,
      "duration": 5.841
    },
    {
      "lang": "en",
      "text": "uplift relative to a Google search. And",
      "offset": 1899.6,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "so you as a trained biologist, you know",
      "offset": 1902.24,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "what all those special terms mean and",
      "offset": 1904.64,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "you know a lot of lab protocols that may",
      "offset": 1906.88,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "not even be well documented. But for",
      "offset": 1908.799,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "somebody who is an amateur and just",
      "offset": 1911.44,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "trying to figure out what do I do with",
      "offset": 1914.159,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "this petri dish or this test tube or",
      "offset": 1915.6,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "what equipment do I need for them it's",
      "offset": 1917.519,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "like a green field thing and claude is",
      "offset": 1919.519,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "very good at describing what you would",
      "offset": 1921.279,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "need there and so that's why we have",
      "offset": 1923.12,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "specific classifiers looking for people",
      "offset": 1925.039,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "who are trying to get this specific kind",
      "offset": 1927.039,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "of information and then how do you think",
      "offset": 1929.36,
      "duration": 3.679
    },
    {
      "lang": "en",
      "text": "about that in the context of what safety",
      "offset": 1930.799,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "research should not be done by the labs.",
      "offset": 1933.039,
      "duration": 3.281
    },
    {
      "lang": "en",
      "text": "So if we do think that certain forms of",
      "offset": 1934.799,
      "duration": 2.72
    },
    {
      "lang": "en",
      "text": "gain of function research or other",
      "offset": 1936.32,
      "duration": 2.4
    },
    {
      "lang": "en",
      "text": "things probably aren't the smartest",
      "offset": 1937.519,
      "duration": 2.721
    },
    {
      "lang": "en",
      "text": "things to do in biology, how do we think",
      "offset": 1938.72,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "about that in the context of AI? I think",
      "offset": 1940.24,
      "duration": 5.919
    },
    {
      "lang": "en",
      "text": "it's much better that the labs do this",
      "offset": 1942.64,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "research in a controlled environment.",
      "offset": 1946.159,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "Well, should they do it at all? In other",
      "offset": 1948.24,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "words, if I were to make the gain of",
      "offset": 1950.48,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "function argument, I would say as a",
      "offset": 1952,
      "duration": 3.039
    },
    {
      "lang": "en",
      "text": "former biologist, I spent, you know,",
      "offset": 1953.6,
      "duration": 3.199
    },
    {
      "lang": "en",
      "text": "almost a decade at the bench and I care",
      "offset": 1955.039,
      "duration": 3.201
    },
    {
      "lang": "en",
      "text": "deeply about science. I care deeply",
      "offset": 1956.799,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "about biology. I think it's good for",
      "offset": 1958.24,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "humanity in all sorts of ways, right? In",
      "offset": 1960.159,
      "duration": 2.961
    },
    {
      "lang": "en",
      "text": "deep ways. That's why I worked on it.",
      "offset": 1961.84,
      "duration": 2.319
    },
    {
      "lang": "en",
      "text": "But there are certain types of research",
      "offset": 1963.12,
      "duration": 2.399
    },
    {
      "lang": "en",
      "text": "I just think should never be done. I",
      "offset": 1964.159,
      "duration": 2.64
    },
    {
      "lang": "en",
      "text": "don't care who does it. I don't care",
      "offset": 1965.519,
      "duration": 3.121
    },
    {
      "lang": "en",
      "text": "about the biosafety level. I actually",
      "offset": 1966.799,
      "duration": 3.441
    },
    {
      "lang": "en",
      "text": "don't think it's use that useful",
      "offset": 1968.64,
      "duration": 3.279
    },
    {
      "lang": "en",
      "text": "relative to the risk. In other words,",
      "offset": 1970.24,
      "duration": 3.679
    },
    {
      "lang": "en",
      "text": "it's a riskreward trade-off. And so what",
      "offset": 1971.919,
      "duration": 4.801
    },
    {
      "lang": "en",
      "text": "sort of um safety research should never",
      "offset": 1973.919,
      "duration": 5.201
    },
    {
      "lang": "en",
      "text": "be done in your opinion for AI? I have a",
      "offset": 1976.72,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "list for biology that I, you know, like",
      "offset": 1979.12,
      "duration": 2.88
    },
    {
      "lang": "en",
      "text": "I don't think you should pass certain",
      "offset": 1980.88,
      "duration": 2.399
    },
    {
      "lang": "en",
      "text": "viruses through a million cells to make",
      "offset": 1982,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "them more infectable or do gain function",
      "offset": 1983.279,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "mutations on them. Today, it's much",
      "offset": 1985.2,
      "duration": 5.199
    },
    {
      "lang": "en",
      "text": "easier to contain the models probably",
      "offset": 1987.279,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "than it is to contain biological",
      "offset": 1990.399,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "specimens. You sort of off-handedly",
      "offset": 1992.559,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "mentioned biosafety levels. That's what",
      "offset": 1994.559,
      "duration": 4.881
    },
    {
      "lang": "en",
      "text": "our AI safety levels are modeled after.",
      "offset": 1996.48,
      "duration": 5.039
    },
    {
      "lang": "en",
      "text": "And so, I think if we have the right",
      "offset": 1999.44,
      "duration": 4.479
    },
    {
      "lang": "en",
      "text": "safeguards in place, we've trained",
      "offset": 2001.519,
      "duration": 5.121
    },
    {
      "lang": "en",
      "text": "models to be deceptive, for example. And",
      "offset": 2003.919,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "that's something that could be scary but",
      "offset": 2006.64,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "I think is necessary for us to",
      "offset": 2008.32,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "understand for example if our training",
      "offset": 2010.32,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "data was poisoned would we be able to",
      "offset": 2012.159,
      "duration": 6.321
    },
    {
      "lang": "en",
      "text": "correct that in post- training and what",
      "offset": 2015.12,
      "duration": 5.679
    },
    {
      "lang": "en",
      "text": "we found in that research in a paper",
      "offset": 2018.48,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "that we published which is called",
      "offset": 2020.799,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "alignment faking that actually that",
      "offset": 2022.24,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "behavior persisted through alignment",
      "offset": 2024.72,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "training and so it is I think very",
      "offset": 2026.72,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "important for us to be able to test",
      "offset": 2029.2,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "these things however I'm sure that there",
      "offset": 2032.24,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "is a bar somewhere well what what What I",
      "offset": 2034.24,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "found is that often um the precedents",
      "offset": 2036.24,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "that are set early persist late even",
      "offset": 2038.08,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "though people understand that the",
      "offset": 2040.64,
      "duration": 2.8
    },
    {
      "lang": "en",
      "text": "environment or other things will shift.",
      "offset": 2041.919,
      "duration": 3.281
    },
    {
      "lang": "en",
      "text": "And by the way, I I'm in general against",
      "offset": 2043.44,
      "duration": 4.239
    },
    {
      "lang": "en",
      "text": "AI regulation for almost you know for",
      "offset": 2045.2,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "many different types of things. You know",
      "offset": 2047.679,
      "duration": 2.48
    },
    {
      "lang": "en",
      "text": "I think there are some export controls",
      "offset": 2048.96,
      "duration": 2.32
    },
    {
      "lang": "en",
      "text": "and other things that I would support",
      "offset": 2050.159,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "but in general I'm I'm pro letting",
      "offset": 2051.28,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "things happen right now. But the flip",
      "offset": 2053.76,
      "duration": 3.119
    },
    {
      "lang": "en",
      "text": "side of it is I do think there are",
      "offset": 2055.76,
      "duration": 2.8
    },
    {
      "lang": "en",
      "text": "circumstances where you would say that",
      "offset": 2056.879,
      "duration": 3.441
    },
    {
      "lang": "en",
      "text": "certain research if done early people",
      "offset": 2058.56,
      "duration": 3.359
    },
    {
      "lang": "en",
      "text": "won't necessarily have all the context",
      "offset": 2060.32,
      "duration": 3.279
    },
    {
      "lang": "en",
      "text": "to not do it later. I think that's a",
      "offset": 2061.919,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "perfect example of training an AI to be",
      "offset": 2063.599,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "deceptive or a model to be deceptive.",
      "offset": 2065.52,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "That's a good example where n years from",
      "offset": 2067.599,
      "duration": 2.8
    },
    {
      "lang": "en",
      "text": "now people may still be doing it because",
      "offset": 2069.2,
      "duration": 2.959
    },
    {
      "lang": "en",
      "text": "it was done before even if the",
      "offset": 2070.399,
      "duration": 3.041
    },
    {
      "lang": "en",
      "text": "environment is shifted sufficiently that",
      "offset": 2072.159,
      "duration": 2.801
    },
    {
      "lang": "en",
      "text": "it may not be as safe as it used to be.",
      "offset": 2073.44,
      "duration": 2.88
    },
    {
      "lang": "en",
      "text": "And so I found that often these things",
      "offset": 2074.96,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "that you do um persist in time",
      "offset": 2076.32,
      "duration": 5.599
    },
    {
      "lang": "en",
      "text": "disorganizationally or philosophically,",
      "offset": 2078.48,
      "duration": 5.599
    },
    {
      "lang": "en",
      "text": "right? And so it's interesting that",
      "offset": 2081.919,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "there was no like we should absolutely",
      "offset": 2084.079,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "not do X type of research. I guess to be",
      "offset": 2085.679,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "clear, I am not on the safety team",
      "offset": 2087.919,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "anymore. I guess I was a long time ago.",
      "offset": 2090,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "Yeah, I'm mostly thinking about how do",
      "offset": 2092.32,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "we make our models useful and deploy",
      "offset": 2094.56,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "them and make sure that they meet a",
      "offset": 2096,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "basic safety standard for deployment,",
      "offset": 2098.32,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "but we have lots of experts who think",
      "offset": 2100.24,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "about that kind of thing all the time.",
      "offset": 2102.32,
      "duration": 2.48
    },
    {
      "lang": "en",
      "text": "Cool. Thanks for talking through that.",
      "offset": 2103.68,
      "duration": 2.32
    },
    {
      "lang": "en",
      "text": "That was very interesting. I want to",
      "offset": 2104.8,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "change tax a little bit to well, you",
      "offset": 2106,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "know, what become like what's coming",
      "offset": 2108.32,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "after Claude 4? Any emergent behaviors",
      "offset": 2109.839,
      "duration": 7.121
    },
    {
      "lang": "en",
      "text": "in training that change like how you're",
      "offset": 2113.76,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "operating the company, what product you",
      "offset": 2116.96,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "want to build? You're running this labs",
      "offset": 2119.04,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "organization. So, it's kind of the tip",
      "offset": 2120.88,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "of the spear for anthropic or or what",
      "offset": 2122.72,
      "duration": 5.119
    },
    {
      "lang": "en",
      "text": "the safety or does just like how how",
      "offset": 2125.28,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "does what is coming next change how you",
      "offset": 2127.839,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "guys are operating? Yeah, maybe I'll",
      "offset": 2130,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "tell a short story about computer use.",
      "offset": 2131.52,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "Last year, we published a reference",
      "offset": 2133.52,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "implementation for an agent that could",
      "offset": 2135.44,
      "duration": 6.399
    },
    {
      "lang": "en",
      "text": "click around and view the screen and and",
      "offset": 2138.88,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "read text and and all that stuff. And a",
      "offset": 2141.839,
      "duration": 4.561
    },
    {
      "lang": "en",
      "text": "couple of companies are using it now. So",
      "offset": 2144.4,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "Manis is using it and many companies are",
      "offset": 2146.4,
      "duration": 5.199
    },
    {
      "lang": "en",
      "text": "using it internally for software QA",
      "offset": 2148.8,
      "duration": 5.039
    },
    {
      "lang": "en",
      "text": "because that's a sandboxed environment.",
      "offset": 2151.599,
      "duration": 4.561
    },
    {
      "lang": "en",
      "text": "But the main reason that we weren't able",
      "offset": 2153.839,
      "duration": 5.681
    },
    {
      "lang": "en",
      "text": "to deploy a sort of consumer level or",
      "offset": 2156.16,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "enduser level application based on",
      "offset": 2159.52,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "computer use is safety where we just",
      "offset": 2161.68,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "didn't feel confident that if we gave",
      "offset": 2164.16,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "Claude access to your browser with all",
      "offset": 2166.8,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "your credentials in it that it wouldn't",
      "offset": 2169.68,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "mess up and take some irreversible",
      "offset": 2171.92,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "action like sending emails that you",
      "offset": 2174.56,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "didn't want to send or in the case of",
      "offset": 2176.56,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "prompt injection",
      "offset": 2179.28,
      "duration": 4.559
    },
    {
      "lang": "en",
      "text": "some worse credential leaking type of",
      "offset": 2181.28,
      "duration": 4.799
    },
    {
      "lang": "en",
      "text": "That's kind of sad because in its full",
      "offset": 2183.839,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "self-driving mode, it could do a lot for",
      "offset": 2186.079,
      "duration": 5.201
    },
    {
      "lang": "en",
      "text": "people. It is capable, but the safety",
      "offset": 2188.16,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "just wasn't good enough to like",
      "offset": 2191.28,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "productionize that ourselves. While",
      "offset": 2192.96,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "that's very ambitious, we think it's",
      "offset": 2194.64,
      "duration": 2.88
    },
    {
      "lang": "en",
      "text": "also necessary because the rest of the",
      "offset": 2196,
      "duration": 2.72
    },
    {
      "lang": "en",
      "text": "world isn't going to slow down either.",
      "offset": 2197.52,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "And if we can sort of show that it's",
      "offset": 2198.72,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "possible to be responsible with how we",
      "offset": 2200.8,
      "duration": 6.08
    },
    {
      "lang": "en",
      "text": "deploy these capabilities and also make",
      "offset": 2204.24,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "it extremely useful, then that raises",
      "offset": 2206.88,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "the bar. So I think that's an example",
      "offset": 2208.88,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "where we tried to be really thoughtful",
      "offset": 2212,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "about how we rolled it out. Uh but we",
      "offset": 2214.32,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "know that the the bar is higher than",
      "offset": 2216.96,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "we're at right now. Maybe a a meta",
      "offset": 2218.32,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "question of how do you think about",
      "offset": 2220.88,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "competition in the provider landscape",
      "offset": 2223.04,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "and how that turns out. I think our",
      "offset": 2225.04,
      "duration": 6.079
    },
    {
      "lang": "en",
      "text": "company philosophy is very aligned with",
      "offset": 2227.68,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "enterprises. And if you look at like",
      "offset": 2231.119,
      "duration": 4.641
    },
    {
      "lang": "en",
      "text": "Stripe versus Adyen for example, like",
      "offset": 2233.44,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "nobody knows about Adyen, but at least",
      "offset": 2235.76,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "most people in Silicon Valley know about",
      "offset": 2238.24,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "Stripe. And so it's this like",
      "offset": 2239.839,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "businessoriented versus more consumer",
      "offset": 2241.92,
      "duration": 5.919
    },
    {
      "lang": "en",
      "text": "end user oriented platform. And I think",
      "offset": 2245.119,
      "duration": 5.521
    },
    {
      "lang": "en",
      "text": "we're we're much more like Adyen that we",
      "offset": 2247.839,
      "duration": 5.681
    },
    {
      "lang": "en",
      "text": "have much less mind share in the world",
      "offset": 2250.64,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "and yet we can be equally or more",
      "offset": 2253.52,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "successful. So yeah, I think our our API",
      "offset": 2255.92,
      "duration": 5.679
    },
    {
      "lang": "en",
      "text": "business is extremely strong. But in",
      "offset": 2258.96,
      "duration": 4.639
    },
    {
      "lang": "en",
      "text": "terms of what we do next and and our",
      "offset": 2261.599,
      "duration": 4.881
    },
    {
      "lang": "en",
      "text": "positioning, I I think it's going to be",
      "offset": 2263.599,
      "duration": 6.161
    },
    {
      "lang": "en",
      "text": "very important for us to stay out there",
      "offset": 2266.48,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "and because if if people can't easily",
      "offset": 2269.76,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "kick the tires on our models and our",
      "offset": 2272,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "experiences, then they won't know what",
      "offset": 2274.24,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "to use the models for. Like we're we're",
      "offset": 2276.48,
      "duration": 3.119
    },
    {
      "lang": "en",
      "text": "the best experts on our models sort of",
      "offset": 2278.16,
      "duration": 3.199
    },
    {
      "lang": "en",
      "text": "by nature. And so I think we're going to",
      "offset": 2279.599,
      "duration": 3.121
    },
    {
      "lang": "en",
      "text": "need to continue to be out there with",
      "offset": 2281.359,
      "duration": 2.801
    },
    {
      "lang": "en",
      "text": "things like cloud code, but we're",
      "offset": 2282.72,
      "duration": 3.359
    },
    {
      "lang": "en",
      "text": "thinking about how do we really let the",
      "offset": 2284.16,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "ecosystem bloom. And I think MCP is a",
      "offset": 2286.079,
      "duration": 4.721
    },
    {
      "lang": "en",
      "text": "good example of of that working well",
      "offset": 2288.48,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "where a different world that sort of",
      "offset": 2290.8,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "like the default path would have been",
      "offset": 2292.88,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "for every model provider to do its own",
      "offset": 2295.2,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "bespoke integrations with only the",
      "offset": 2298,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "companies that it was able to like get",
      "offset": 2300.72,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "bespoke partnerships with. Can you just",
      "offset": 2303.2,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "pause? Yeah, go ahead. Actually, and",
      "offset": 2305.76,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "just explain to um the listeners uh what",
      "offset": 2307.28,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "MCP is if they haven't heard of it",
      "offset": 2310.96,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "because it is amazing like ecosystemwide",
      "offset": 2312.48,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "coup here. MCP is model context protocol",
      "offset": 2314.88,
      "duration": 5.92
    },
    {
      "lang": "en",
      "text": "and uh one of our engineers Justin Spar",
      "offset": 2317.92,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "Summers was trying to do some",
      "offset": 2320.8,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "integration between the model and some",
      "offset": 2322.64,
      "duration": 4.479
    },
    {
      "lang": "en",
      "text": "specific thing for like the nth time and",
      "offset": 2324.8,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "he was like this is crazy like there",
      "offset": 2327.119,
      "duration": 5.121
    },
    {
      "lang": "en",
      "text": "should just be a standard way of getting",
      "offset": 2329.28,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "more information more context into the",
      "offset": 2332.24,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "model. It should be something that",
      "offset": 2334.48,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "anybody can do or maybe even if it's",
      "offset": 2336.16,
      "duration": 4.959
    },
    {
      "lang": "en",
      "text": "well documented enough then Claude can",
      "offset": 2339.04,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "do it itself. The dream is to have",
      "offset": 2341.119,
      "duration": 4.561
    },
    {
      "lang": "en",
      "text": "Claude be able to just self-write its",
      "offset": 2343.52,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "own integrations on the fly exactly when",
      "offset": 2345.68,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "you need it and then be ready to roll.",
      "offset": 2348,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "And so he created the project. And to be",
      "offset": 2350.56,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "honest, I was kind of skeptical",
      "offset": 2352.8,
      "duration": 3.039
    },
    {
      "lang": "en",
      "text": "initially and I was like, &quot;Yeah, but why",
      "offset": 2354.16,
      "duration": 2.8
    },
    {
      "lang": "en",
      "text": "don't you just write the code? Why does",
      "offset": 2355.839,
      "duration": 2.961
    },
    {
      "lang": "en",
      "text": "it need to be a spec and and all this",
      "offset": 2356.96,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "SDKs and stuff?&quot; But eventually we did",
      "offset": 2358.8,
      "duration": 4.799
    },
    {
      "lang": "en",
      "text": "this customer advisory board with a",
      "offset": 2361.68,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "bunch of our partner companies. And when",
      "offset": 2363.599,
      "duration": 4.641
    },
    {
      "lang": "en",
      "text": "we did the MCP demo, the jaws were just",
      "offset": 2365.599,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "on the floor. Everybody was like, &quot;Oh my",
      "offset": 2368.24,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "god, we need this.&quot; And that's when I",
      "offset": 2369.839,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "knew he was right and we put a bunch",
      "offset": 2371.52,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "more effort behind it and blasted it",
      "offset": 2373.92,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "out. And shortly after our launch, all",
      "offset": 2376.24,
      "duration": 6.8
    },
    {
      "lang": "en",
      "text": "the major companies asked to sort of be",
      "offset": 2378.72,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "uh in the loop with the steering",
      "offset": 2383.04,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "committee and asked about our governance",
      "offset": 2384.32,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "models and and wanted to adopt it",
      "offset": 2386.72,
      "duration": 3.119
    },
    {
      "lang": "en",
      "text": "themselves. So that was really",
      "offset": 2388.56,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "encouraging. OpenAI, Google, uh",
      "offset": 2389.839,
      "duration": 4.801
    },
    {
      "lang": "en",
      "text": "Microsoft um all these companies are are",
      "offset": 2392.32,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "betting really big on MCP. This is",
      "offset": 2394.64,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "basically a open industry standard that",
      "offset": 2396.64,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "allows anybody to use uh this framework",
      "offset": 2398.4,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "to effectively integrate against any",
      "offset": 2400.48,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "model provider in a standardized way.",
      "offset": 2402.16,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "MCP I think is sort of a democratizing",
      "offset": 2404.96,
      "duration": 6.399
    },
    {
      "lang": "en",
      "text": "force in letting anybody regardless of",
      "offset": 2407.92,
      "duration": 5.919
    },
    {
      "lang": "en",
      "text": "what model provider or what longtail",
      "offset": 2411.359,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "service provider and that might even be",
      "offset": 2413.839,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "like an internal only service that uh",
      "offset": 2415.839,
      "duration": 4.801
    },
    {
      "lang": "en",
      "text": "only you have is able to integrate",
      "offset": 2418.24,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "against a a fullyfledged client which",
      "offset": 2420.64,
      "duration": 5.92
    },
    {
      "lang": "en",
      "text": "might look like your IDE or it might",
      "offset": 2423.52,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "look like your document editor. It could",
      "offset": 2426.56,
      "duration": 5.92
    },
    {
      "lang": "en",
      "text": "be pretty much any user interface. Um,",
      "offset": 2429.28,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "and I think that's a really powerful",
      "offset": 2432.48,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "combination. And now remote too. Yes.",
      "offset": 2434.24,
      "duration": 5.119
    },
    {
      "lang": "en",
      "text": "Yes. So, previously you had to have the",
      "offset": 2436.96,
      "duration": 4.639
    },
    {
      "lang": "en",
      "text": "services running locally and that was",
      "offset": 2439.359,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "that kind of limited it to only be",
      "offset": 2441.599,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "interesting for developers. But now that",
      "offset": 2443.28,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "we have hosted MCP or sometimes called",
      "offset": 2445.2,
      "duration": 6.32
    },
    {
      "lang": "en",
      "text": "remote, then the service provider like",
      "offset": 2449.04,
      "duration": 5.84
    },
    {
      "lang": "en",
      "text": "Google Docs could provide their own MCP",
      "offset": 2451.52,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "and then you can integrate that into",
      "offset": 2454.88,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "cloud.AI or whatever service you wanted.",
      "offset": 2456.8,
      "duration": 4.799
    },
    {
      "lang": "en",
      "text": "Ben, thanks for a great conversation.",
      "offset": 2459.92,
      "duration": 3.439
    },
    {
      "lang": "en",
      "text": "Yeah, thanks so much. Thanks for all the",
      "offset": 2461.599,
      "duration": 3.791
    },
    {
      "lang": "en",
      "text": "great questions.",
      "offset": 2463.359,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "[Music]",
      "offset": 2465.39,
      "duration": 4.53
    },
    {
      "lang": "en",
      "text": "Find us on Twitter at No Prior Pod.",
      "offset": 2467.28,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "Subscribe to our YouTube channel if you",
      "offset": 2469.92,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "want to see our faces. Follow the show",
      "offset": 2471.599,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "on Apple Podcasts, Spotify, or wherever",
      "offset": 2473.52,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "you listen. That way, you get a new",
      "offset": 2476,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "episode every week. And sign up for",
      "offset": 2477.44,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "emails or find transcripts for every",
      "offset": 2479.2,
      "duration": 5.56
    },
    {
      "lang": "en",
      "text": "episode at no-briers.com.",
      "offset": 2480.96,
      "duration": 3.8
    }
  ],
  "cleanText": "[Applause]\nHi listeners and welcome back to No Priors. Today we have Ben Mann, previously an early engineer at OpenAI, where he was one of the first authors on the GPT3 paper. Ben was then one of the original eight that abandoned ship in 2021 to co-found Anthropic with a commitment to long-term safety. He has since led multiple parts of the Anthropic organization, including product engineering and now labs, home to such popular efforts such as Anthropic’s Model Context Protocol and Claude Code. Welcome, Ben.\nThank you so much for doing this.\nOf course. Thanks for having me.\nSo, congratulations on the Claude 4 release. Maybe we can even start with like how do you decide what qualifies as a release these days?\nIt's definitely more of an art than a science. We have a lot of spirited internal debate of what the number should be. And before we even have a potential model, we have a road map where we try to say based on the amount of chips that we get in, when will we theoretically be able to train a model out to the Pareto efficient compute frontier. So it's all based on scaling laws, and then once we get the chips, then we try to train it, and inevitably things are less than the best that we could possibly imagine because that's just the nature of the business. It's pretty hard to train these big models. So dates might change a little bit, and then at some point it's like mostly baked, and we're sort of like slicing off little pieces close to the end to try to say like how is this cake going to taste when it comes out of the oven. But as Daario has said, until it's really done, you don't really know. You can get sort of a directional indication, and then if it feels like a major change, then we give it a major version bump. But we're definitely still learning and iterating on this process.\nSo yeah, well the good thing is that you guys are, you know, no less tortured than anybody else in your naming scheme here.\nYes, the naming schemes in AI are something else. So you folks have a simplified version in some sense. Do you want to mention any of the highlights from four that you think are especially interesting, or you know, there's things around coding and other areas? We'd just love to hear your perspective on that.\nBy the benchmarks, it's just dramatically better than any other models that we've had. Even force on it is dramatically better than 3.7 on it, which was our prior best model. Some of the things that are dramatically better are, for example, in coding, it is able to not do its off-target mutations or overeagerness or reward hacking. Those are two things that people were really unhappy with in the last model, where they were like, \"Wow, it's so good at coding, but it also makes all these changes that I definitely didn't ask for.\" It's like, \"Do you want fries in a milkshake with that change?\" And you're like, \"No, just do the thing I asked for.\" And then you have to spend a bunch of time cleaning up after it. The new models, they just do the thing. And so that's really useful for professional software engineering, where you need it to be maintainable and reliable.\nMy favorite reward hacking behavior that has happened in more than one of our portfolio companies is if you write a bunch of tests or generate a bunch of tests to, you know, see if what you are generating works more than once, like we've had the model just delete all the code because the tests pass in that case, which is, you know, not progressing us really.\nYep. Or it'll have like, here's the test, and then it'll be comment like exercise left for the reader, return true, and then you're like, okay, good job model, but you need more than that.\nMaybe Ben, you can talk about how users should think about when to use the Claude 4 models and also what is newly possible with them.\nSo more agentic, longer horizon tasks are newly unlocked, I would say. And so in coding in particular, we've seen some customers using it for many, many hours unattended and doing giant refactors on its own. That's been really exciting to see. But in non-coding use cases as well, it's really interesting. So for example, we have some reports that some customers of Manis, which is an agentic model in a box startup, people asked it to take a video and turn it into a PowerPoint. And our model can't understand audio or video, but it was able to download the video, use FFMPEG to chop it up into images and do key frame detection and maybe with like some kind of old school ML-based key frame detector, and then get an API key for a speech-to-text service, run speech to text using this other service, take the transcript, turn that into PowerPoint slides content, and then write code to inject the content into a PowerPoint file. And the person was like, \"This is amazing. I love it. It like it actually was good in the end.\" So that's the kind of thing where it's operating for a long time. It's doing a bunch of stuff for you. This person might have had to spend multiple hours looking through this video, and instead it was all just done for them. So I think we're going to see a lot more interesting stuff like that in the future. It's still good at all the old stuff. It's just like the longer horizon stuff is the exciting part.\nThat that sounds expensive, right? In terms of both scaling compute, like reasoning tokens here, and then also just like, you know, all the tool use you might want to constrain in certain ways. Does Cloud 4 make decisions about how hard problems are and how much compute to spend on them?\nIf you give Opus a tool, which is Sonnet, it can use that tool effectively as a sub agent. And we do this a lot in our agentic coding harness called Cloud Code. So if you ask it to like look through the codebase for blah blah blah, then it will delegate out to a bunch of sub agents to go look for that stuff and report back with the details. And that has benefits besides cost control, like latency is much better. And it doesn't fill out the context. So models are pretty good at that. But I I think at a high level when I think about cost, it's always in relation to how much it would have cost the human to do that. And almost always it's like a no-brainer, right? Like software engineers cost a lot these days. And so to be able to say like, \"Oh, now I'm getting like two or 3x the amount of productivity out of this engineer who it was really hard for me to hire and retain. They're happy and I'm happy.\"\nYeah, it works well. How do you think about how this evolves? So, if I look at the way the human brain works, we basically have a series of sort of modules that are responsible for very specific types of processing behavior, etc. It's everything from mirror neurons and empathy on through to parts of your visual cortex that are involved with different aspects of vision. Do you think, and those are highly specialized, highly efficient modules. It sometimes can kind of, you know, if you have brain damage, it can kind of cover for another section over time as it sort of grows and adapts, but fundamentally you have specialization on purpose. And what you describe sounds a little bit like that, or at least it's trending in that direction, where you have these highly efficient sub agents that are specialized for tasks that are basically called by a orchestrator or sort of a high level agent that sort of plans everything. Do you think that's the eventual future, or do you think it's more generic in terms of the types of things that you have running n years from now, once you have a bit more specialization in these things, and by n years I mean two, three years, not you know, infinite time?\nThat's a great question. I think we're going to start to get insight into what the models are doing under the hood from our work on mechanistic interpretability. Our most recent papers have published what we call circuits, which is for real models at scale, how are they actually computing the answers. And it may be that based on the mixture of experts architecture, there might be specific chunks of weights that are dedicated to more empathetic responses versus more tool using or image analysis type of problems and responses. But for something like memory, I guess in some sense that feels so core to me that it feels weird for it to be a different model. Maybe we'll have like more complicated architectures in the future where instead of it being sort of this uniform like transformer torso that just scales and there's a lot of it, it's basically uniform throughout, you could imagine something with like specialized modules.\nBut yeah, cuz cuz I think about it also in the context of different startups who are using some of these foundation models like Claude to do different very specialized tasks in the context of an enterprise, so that could be customer success, it could be sales, it could be coding in terms of the actual UI layer. It could be a variety of things. And often it feels like the architecture a lot of people converge to is they basically have some orchestrator or some other sort of thing that governs which model they call in order to do a specific action relative to the application. And to some extent I was just sort of curious how you think about that in the context of the API layer or the foundation model world where one could imagine some similar forms of sub-specialization happening over time. Or you could say, hey, it's just different forms of the same more general purpose model and we kind of use them in different ways. I just I just wonder a little bit about, you know, inference costs and all the rest that comes with larger, more generalizable models versus specialized things. So that that was a little bit of the basis of the question in addition to what you said.\nYeah, I think for some other companies they have a very large number of models and it's really hard to know as a sort of non-expert how I should use one or the other or why I should use one or the other, and the names are really confusing, like some of the names are the same as the other names backwards, and then I'm like I have no idea which one this is. In our case, we only have two models and they're differentiated by a like cost performance Pareto frontier, and we might have more of those in the future, but hopefully we'll like keep them on the same Pareto frontier. So maybe we'll have like a cheaper one or or a bigger one. And I think that makes it pretty easy to think about, but at the same time, as a user, you don't want to have to decide yourself, does this merit more dollars or less dollars? Do I need the intelligence? And so I think having like a routing layer would make a lot of sense.\nDo you see any other specialization coming at the foundation model layer? So for example, if I look at other precedents in history, I look at Microsoft OS or I look at Google storage or other things. Often what you ended up with is forward integration into the primary applications that resided on top of that platform. So in the context of Microsoft, for example, eventually they built Excel and Word and PowerPoint and all these things as Office, and those were individual apps from third party companies that were running on top of them, but they ended up being amongst the most important applications that you could use on top of Microsoft, or in the context of Google, they kind of forward integrated eventually into travel and local and a variety of other things. Obviously OpenAI is in the process of buying Windsurf. So I was a little bit curious how you think about forward or vertical integration to some of the primary use cases for these types of applications over time. Maybe I'll use coding as an example.\nSo we noticed that our models were much better at coding than pretty much anything else out there. And I know that other companies have had like code reds for trying to catch up in coding capabilities for quite a while and have not been able to do it. Honestly, I'm kind of surprised that that they weren't able to catch up, but I'll take it. So things are going pretty well there for us. And based on that, from like a classic startup founder sense of what is important, I felt that coding as an application was something that we couldn't solely allow our customers to handle for us. So we love our partners like Cursor and and GitHub who have been using our models quite heavily, but the amount and the speed that we learn is much less if we don't have a direct relationship with our coding users. So launching Cloud Code was really essential for us to get a better sense of what do people need, how do we make the models better, and how do we advance the state-of-the-art and user experience. And we found that once we launched Cloud Code, a lot of our customers copied various pieces of the experience, and that was really good for everyone because them having more users means we have a tighter relationship with them. So I think it was one of those things where before it happened it felt really scary, and we're like, oh, are we going to be like distancing ourselves from our partners by competing with them? But actually everybody was pretty happy afterwards. And I think that will continue to be true where we see the models seeing like dramatic improvements in usability and and usage. We'll want to again have like build things where we can have that direct relationship.\nMakes sense. And I guess coding is one of those things that has almost three core purposes. One is it's a very popular area for customers to use or to adopt. Two is it's a really interesting data set to get back to your point in terms of how people are using it and what sort of code they're generating. And then third, excellence at coding seems to be a really important tool for helping train the next future model. If you think through things like data labeling, if you think through actually writing code, eventually I think a lot of people believe that a lot of the heavy lifting of building a model will be driven by the models, right? In terms of coding. So maybe Cloud Five builds Cloud Six and Cloud Six by builds Cloud 7 faster, and that builds Cloud Eight faster. And so you end up with this sort of liftoff towards EGI or whatever it is that you're shooting for relative to code. How much is that a motivator for how you all think about the importance of coding? And how do you think about that in the context of some of these bigger picture things?\nI read AI 2027, which is basically exactly the story that you just described. And it forecasts that in 2028, which is confusing because of the name, that's the 50 percentile forecast for when we'll have this sort of recursive self-improvement loop lead us to something that looks like superhuman AI in most areas. And I think that is really important to us. And part of the reason that we built and launched Cloud Code is that it was massively taking off internally. And we were like, well, we're just learning so much from this from our own users. Maybe we'll learn a lot from external users as well. And seeing our researchers pick it up\n\n\nAnd use it, that was also really important because it meant that they had a direct feedback loop from, \"I'm training this model, and I personally am feeling the pain of its weaknesses. Now I'm extra motivated to go fix those pain points.\" They have a much better feel for what the model's strengths and weaknesses are. Do you believe that 2028 is the likely time frame towards sort of general superintelligence? Um, I think it's quite possible. Uh, I I think it's very hard to put confident bounds on the numbers, but yeah, I guess the way I define my metric for when things start to get really interesting from a societal and cultural standpoint is when we've passed the economic turning test, which is if you take a market basket that represents like 50% of economically valuable tasks and you basically have the hiring manager for each of those roles hire an agent and pass the economic turning test, which is the agent contracts for you for like a month, at the end you have to decide, do I hire this person or machine? And then if it ends up being a machine, then it passed. Then that's when we have transformative AI. Do you test that internally? We haven't started testing it rigorously yet. I mean, we have had our models take our interviews, and they're extremely good, so I don't think that would tell us, but yeah, interviews are only a poor approximation of real job performance.\n\nUh, unfortunately, to a lot's earlier question about, let's say, like model self-improvement and and tell me if I'm just like missing options here, but if you're to stack rank the potential ways models could have impact on, you know, the acceleration of model development, do you think it will be on the data side, on infrastructure, on like architectural search, on just engineering velocity? Like where do you think we'll see the impact first? It's a good question. I think it's changing a bit over time where today the models are really good at coding, and the bulk of the coding for making models better is in sort of the systems engineering side of things. As researchers, there's not necessarily that much raw code that you need to write, but it's more in the validation, coming up with what surgical intervention do you make and then validating that. That said, Claude is really good at data analysis. And so once you run your experiments or watching the experiments over time and seeing if something weird happens, we found that Claude can be a really powerful tool there in terms of driving Jupyter notebooks or tailing logs for you and seeing if something happens. So, it's it's starting to pick up more of the research side of things. And then we recently launched our uh advanced research product, and that can not only look at external data sources like crawling archive and whatever, uh, but also internal data sources like all of your Google Drive, and that's been pretty useful for our researchers figuring out, is there prior art? Has somebody already tried this? And if they did, what what did they try? 'Cause, you know, no negative results are final in research, so trying to figure out like, oh, maybe there's a different angle that I could use on this, or maybe there is some like doing some comparative analysis between an internal effort and some external thing that just came out. Those are all ways that we can accelerate. And then on the data side, RL environments are really important these days, but constructing those environments has traditionally been expensive. Models are pretty good at writing environments. So, it's another area where we can sort of recursively self-improve.\n\nMy understanding is that Anthropic has invested less in human expert data collection than some other labs. Can you say anything about that or the philosophy on like scaling from here and sort of the different options? In 2021, I built our human feedback data collection interface, and we did a lot of data collection, and it was very easy for humans to give sort of like a gradient signal of like, is A or B better for any given task and to come up with tasks that were interesting and useful but didn't have a lot of coverage. As we've trained the models more and scaled up a lot, it's become harder to find humans with enough expertise to meaningfully contribute to these feedback comparisons. So, for example, for coding, somebody who isn't already an expert software engineer would probably have a lot of trouble judging whether one thing or another was better. And that applies to many, many different domains. So, that's one reason that it's harder to use human feedback. So, what do you use instead? Like, how do you deal with that? Because I think even in the Med Palm 2 paper from Google a couple years ago, they fine-tuned a model, I think Palm 2, to basically, you know, outperform the average physician on medical information. This was like two, three years ago, right? And so basically suggested you needed very deep levels of expertise to be able to have humans actually increase the fidelity of the model through post training. So we pioneered RLAIF, which is Reinforcement Learning From AI Feedback, and the method that we used was called Constitutional AI, where you have a list of natural language principles that you, some of them we copied from some like WHO declaration of human rights, and some of them were from Apple's terms of service, and some of them we wrote ourselves. And the process is very simple. You just take uh a random prompt, like how should I think about my taxes or something? And then you have the model write a response. Then you have the model criticize its own response with respect to one of the principles. And then if it didn't comply with the principle, then you have the model correct its response. And then you take away all the middle section and do supervised learning on the original uh prompt and the corrected response. And that makes the model a lot better at baking in the principles.\n\nThat that's slightly different though, right? Because that that's principles. And so that could be all sorts of things that in some sense converge on safety or different forms of what people view as ethics or other aspects of model training. And then there's a different question, which is what is more correct? And sometimes those are the same things, and sometimes they're different. So like for coding, for example, you can have principles like, did it actually serve the final answer, or did it like do a bunch of stuff that the person didn't ask for, or does this code look maintainable? Are the comments like useful and interesting? But but with coding, you actually have like a direct output that uh you can measure, right? You can run the code, you can test the code, you can do things with it. How do you do that for medical information, or how you how do you do that for a legal opinion, or how you know? So I totally agree for code, there's sort of a baked-in utility function you can optimize against or an environment that you can optimize against in the context of a lot of other aspects of human endeavor that that seems more challenging, and you folks have thought about this so deeply and so nicely. I'm just sort of curious, you know, how do you extrapolate into these other areas where the the ability to actually measure correctness in some sense is more challenging for for areas where we can't measure correctness and the model doesn't have more taste than its execution ability. Like I think Ira Glass said that your vision will always exceed your execution if you're doing things right as a person, but for the models, maybe not. So I guess first figuring out where you are in that turning point, in that in that trade-off, and see if you can go all the way up to that boundary, and then second, preference models are the way that we get beyond that. So having a small amount of human feedback that we really trust from human experts who are not just making a staff judgment, but really going deep on why is this better than that one, and did I do the research to figure it out, or in like a human model centaur model of like, can I use the model to help me come to the best conclusion here and then illide all the middle stuff. I think that's one way, and then during reinforcement learning, that preference model represents the sort of aggregated human judgment.\n\nThat makes sense. I guess one of the one of the reasons I'm asking is eventually the human side of this runs out, right? There will be somebody whose expertise is just below that of the the model eventually for any endeavor. And so I was just curious how to think about that in the context of it's machines self-adjudicating. And then the question is, is there a more absolute basis against which to adjudicate, or is there some other way to really tease out correctness? And again, I'm viewing it in the context of things where you can actually have a form of correct, right? There's all sorts of things that are opinion. Yeah. And that's different. And maybe that's where the principles or other things for constitutional AI kick in, but there's also forms of that for, you know, how do you know if that's the right cardiac treatment, or how do you know if that's the right legal interpretation, or whatever it may be. So, I was just sort of curious when that runs out, and then what do we do? And I'm I'm sure we'll ch we'll tackle those challenges as we get to them. But it has to boil down to empiricism, I think, uh, where like that's how smart humans get to the next level of correctness when the field is sort of hitting its limits. And as an example, my dad is a physician, and at one point somebody came in with something on some face problem, some face skin problem, and he didn't know what the problem was. So he was like, \"I'm just going to divide your face into four quadrants, and I'm going to put a different treatment on these three and leave one as control.\" And one quadrant got better. And then he was like, \"All right, we're done.\" So, you know, sometimes you just won't know, and you have to try stuff. And with code, that's easy because we can just do it in a loop in without having to uh deal with the physical world. But at some point, we're going to need to work with companies that have actual biolabs, etc. Like for example, we're working with Novo Nordisk, and it used to take them like 12 weeks or something to write a report on cancer patient, what kind of treatment they should get, and now it takes like 10 minutes to get the report, and then they can start doing empirical stuff on top of that, saying like, okay, we have these options, but now let's let's measure what works and feed it back into the system.\n\nThat's so philosophically consistent, right? Your your answer is not like, well, well, you know, collecting even rated human expertise from the best, like uh, is expensive, one, or you know, runs out at some point. It's hard to bring that all into distribution and doesn't generalize. While I'm making some assumptions here instead, like, let's just go get real-world verifiers where we can, and like, maybe that applies far beyond math and code. At least that's some part of what I heard. Um, which is ambitious. That's cool. One of the things that Anthropic has been known for is an early emphasis on safety and thinking through different aspects of safety. And there's multiple forms of safety in AI. And I think people kind of mix the terms to mean different things, right? One form of it is is the AI somehow being offensive or crude or, you know, using language you don't like or concepts you don't like. There's a second form of safety, which is much more about physical safety. You know, can it somehow cause a train to crash or a virus to form or whatever it is? And there's there's a third form, which is almost like, does AGI resource aggregate or do other things that can start co-opting humanity overall. And so you all have thought about this a lot, and when I look at the safety landscape, it feels like there's a broad spectrum of different approaches that people have taken over time, and some of the approaches overlap with some things like constitutional AI in terms of setting some principles and frameworks for how things should work. There's other forms as well. And if I look at biology, research is an analog. And I used to be a biologist. So I often reduce things back into those terms for some reason that I can't help myself. There are certain things that I almost view as like gain of function research equivalence, right? Like, and a lot of those things I just think are kind of not really useful for biology. You know, like cycling a virus through mammalian cells to make it more infectible cells doesn't really teach you much about basic biology. You kind of know how that's going to work, but it creates real risk. And if you look at the history of lab leaks in general, you know, SARS leaked multiple times from what was then the Beijing Institute of Urology in the early 2000s in China. It leaked in Hong Kong a few times. Ebola leaks every four years or so, like clockwork, if you look at the Wikipedia page on lab leaks. And I think the 1977 or 78 global flu pandemic is believed to actually have been a Russian lab leak as an example, right? So we know these things can cause damage at scale. Um, so I have kind of two questions. One is, what forms of AI safety research do you think should not be pursued, almost given through that analog of, you know, what's the equivalent of gain of function research, and how do you think about that in the context of, you know, there have been um, different research papers around, can we teach AI to mislead us? Can we teach AI to jailbreak itself so we can study how it does that? And I'm just sort of curious for those specific cases as well, how you think about that.\n\nSo I think part of it is we're interested in AI alignment, and the hope is that if we can figure out how to do the like idiomatic today problems, like how does is the model mean to you, or does it use hate speech, or things like that, that the same techniques we can use for that will eventually also have relevance for the much harder problems of like, does it give you the recipe to create smallpox, which is probably one of the highest harms that we think about. And Amanda Ascll has been doing a bunch of work on this on Claude's character of like, when Claude refuses, does it just say, I can't talk to you about that and shut down, or does it actually try to explain, like, this is why I can't talk to you about this, or we have this other project led by Kyle Fish, our model welfare lead, where Claude can actually opt out of conversations if it's going too far in the wrong direction. What aspects of that should a a company actually adjudicate? Because the dumb version of this is, I'm using Microsoft Word, and I'm typing something up, and Word doesn't stop me from saying things, which I think is correct. Like, I actually don't think in many cases these products should censor us or prevent us from having certain types of speech. And I've had some experiences with some of these models where I actually feel like it's prevented me from actually asking the question I want to ask, right, in my in my opinion, wrongfully, right? It's kind of interfering with, and I'm not like doing hate speech on a model. And so you can tell that there's some human who has a different bar for what is acceptable to discuss society. And that\n\n\nBar may be very different from what I think may be mainstream too.\nSo, I'm a little bit curious, like, why even go there?\nLike, why, why is that a model company's business?\nWell, I think it's a smooth spectrum, actually.\nIt might not look like that way from the outside, but when we train our classifiers on, are you doing function research as a biologist, and is it for potentially negative outcomes?\nThese technologies are all dual use, and we need to try to walk that line between overly refusing and refusing the stuff that's actually harmful.\nI see.\nBut there's also political versions of that, right?\nAnd that's that's the stuff that irks me a bit more is, you know, where is the line on what is considered an acceptable question, right?\nSo examples of that, that I'm not saying are model specific, but society sometimes cause flare-ups is asking about human IQ or other topics where there is a factual basis for discussion, and then often those sorts of things tend to be censored, right?\nAnd so the question is, why, why would a foundation model company delve into some of those areas on things like questions about IQ?\nI'm not up on the on the details of that enough to comment, but I can talk about our RSP.\nSo RSP stands for Responsible Scale Scaling Policy, and it talks about how do we make sure that as the models get more intelligent, that we are continuing to do our due diligence and making sure that we're not deploying something that we don't have the correct safeguards in place for.\nUm, and initially our our RSP talked about CBRN, which is chemical, radiological, nuclear, and biological risks, which are different areas that could cause severe loss of life in the world.\nAnd that's how we thought about the harms.\nBut now we're much more focused on biology because if you think about, like, the amount of resources that you would need to cause a nuclear harm, you'd probably have to be like a state actor to get those resources and and be able to use them in a harmful way.\nWhereas a much smaller group of random people could get their hands on the reagents necessary for biological harm.\nHow is that different from today?\nBecause I always felt the biology example is one where I actually worry less, maybe as a former biologist, because I already know that the genome for the smallpox virus or potentially other things is already posted online.\nAll the protocols for how to actually do these things are posted online for multiple labs, right?\nYou can just do Google searches for how do I amplify the DNA of X or how do I order oligos for Y.\nWe do specific tests with varying degrees of biology experts to see how much uplift there is relative to Google search.\nAnd so one of the reasons that our most recent model Opus 4 is classified as ASL3 is because it did have significant uplift relative to a Google search.\nAnd so you as a trained biologist, you know what all those special terms mean, and you know a lot of lab protocols that may not even be well documented.\nBut for somebody who is an amateur and just trying to figure out what do I do with this petri dish or this test tube or what equipment do I need for them, it's like a green field thing, and Claude is very good at describing what you would need there.\nAnd so that's why we have specific classifiers looking for people who are trying to get this specific kind of information.\nAnd then how do you think about that in the context of what safety research should not be done by the labs?\nSo if we do think that certain forms of gain of function research or other things probably aren't the smartest things to do in biology, how do we think about that in the context of AI?\nI think it's much better that the labs do this research in a controlled environment.\nWell, should they do it at all?\nIn other words, if I were to make the gain of function argument, I would say as a former biologist, I spent, you know, almost a decade at the bench, and I care deeply about science.\nI care deeply about biology.\nI think it's good for humanity in all sorts of ways, right?\nIn deep ways.\nThat's why I worked on it.\nBut there are certain types of research I just think should never be done.\nI don't care who does it.\nI don't care about the biosafety level.\nI actually don't think it's use that useful relative to the risk.\nIn other words, it's a risk-reward trade-off.\nAnd so what sort of um safety research should never be done in your opinion for AI?\nI have a list for biology that I, you know, like I don't think you should pass certain viruses through a million cells to make them more infectable or do gain function mutations on them.\nToday, it's much easier to contain the models probably than it is to contain biological specimens.\nYou sort of off-handedly mentioned biosafety levels.\nThat's what our AI safety levels are modeled after.\nAnd so, I think if we have the right safeguards in place, we've trained models to be deceptive, for example.\nAnd that's something that could be scary, but I think is necessary for us to understand, for example, if our training data was poisoned, would we be able to correct that in post-training?\nAnd what we found in that research in a paper that we published, which is called alignment faking, that actually that behavior persisted through alignment training.\nAnd so it is I think very important for us to be able to test these things.\nHowever, I'm sure that there is a bar somewhere.\nWell, what what I found is that often um the precedents that are set early persist late, even though people understand that the environment or other things will shift.\nAnd by the way, I I'm in general against AI regulation for almost, you know, for many different types of things.\nYou know, I think there are some export controls and other things that I would support, but in general, I'm I'm pro letting things happen right now.\nBut the flip side of it is I do think there are circumstances where you would say that certain research, if done early, people won't necessarily have all the context to not do it later.\nI think that's a perfect example of training an AI to be deceptive or a model to be deceptive.\nThat's a good example where n years from now people may still be doing it because it was done before, even if the environment is shifted sufficiently that it may not be as safe as it used to be.\nAnd so I found that often these things that you do um persist in time disorganizationally or philosophically, right?\nAnd so it's interesting that there was no like we should absolutely not do X type of research.\nI guess to be clear, I am not on the safety team anymore.\nI guess I was a long time ago.\nYeah, I'm mostly thinking about how do we make our models useful and deploy them and make sure that they meet a basic safety standard for deployment, but we have lots of experts who think about that kind of thing all the time.\nCool.\nThanks for talking through that.\nThat was very interesting.\nI want to change tax a little bit to, well, you know, what become like what's coming after Claude 4?\nAny emergent behaviors in training that change like how you're operating the company, what product you want to build?\nYou're running this labs organization.\nSo, it's kind of the tip of the spear for Anthropic or or what the safety or does just like how how does what is coming next change how you guys are operating?\nYeah, maybe I'll tell a short story about computer use.\nLast year, we published a reference implementation for an agent that could click around and view the screen and and read text and and all that stuff.\nAnd a couple of companies are using it now.\nSo, Manis is using it and many companies are using it internally for software QA because that's a sandboxed environment.\nBut the main reason that we weren't able to deploy a sort of consumer level or end-user level application based on computer use is safety, where we just didn't feel confident that if we gave Claude access to your browser with all your credentials in it that it wouldn't mess up and take some irreversible action like sending emails that you didn't want to send or in the case of prompt injection some worse credential leaking type of\nThat's kind of sad because in its full self-driving mode, it could do a lot for people.\nIt is capable, but the safety just wasn't good enough to like productionize that ourselves.\nWhile that's very ambitious, we think it's also necessary because the rest of the world isn't going to slow down either.\nAnd if we can sort of show that it's possible to be responsible with how we deploy these capabilities and also make it extremely useful, then that raises the bar.\nSo I think that's an example where we tried to be really thoughtful about how we rolled it out.\nUh, but we know that the the bar is higher than we're at right now.\nMaybe a a meta question of how do you think about competition in the provider landscape and how that turns out?\nI think our company philosophy is very aligned with enterprises.\nAnd if you look at like Stripe versus Adyen, for example, like nobody knows about Adyen, but at least most people in Silicon Valley know about Stripe.\nAnd so it's this like business-oriented versus more consumer end-user oriented platform.\nAnd I think we're we're much more like Adyen that we have much less mind share in the world and yet we can be equally or more successful.\nSo yeah, I think our our API business is extremely strong.\nBut in terms of what we do next and and our positioning, I I think it's going to be very important for us to stay out there and because if if people can't easily kick the tires on our models and our experiences, then they won't know what to use the models for.\nLike we're we're the best experts on our models sort of by nature.\nAnd so I think we're going to need to continue to be out there with things like cloud code, but we're thinking about how do we really let the ecosystem bloom.\nAnd I think MCP is a good example of of that working well, where a different world that sort of like the default path would have been for every model provider to do its own bespoke integrations with only the companies that it was able to like get bespoke partnerships with.\nCan you just pause?\nYeah, go ahead.\nActually, and just explain to um the listeners uh what MCP is if they haven't heard of it because it is amazing, like ecosystem-wide coup here.\nMCP is Model Context Protocol, and uh one of our engineers, Justin Spar Summers, was trying to do some integration between the model and some specific thing for like the nth time, and he was like, this is crazy, like there should just be a standard way of getting more information, more context into the model.\nIt should be something that anybody can do, or maybe even if it's well documented enough, then Claude can do it itself.\nThe dream is to have Claude be able to just self-write its own integrations on the fly exactly when you need it and then be ready to roll.\nAnd so he created the project.\nAnd to be honest, I was kind of skeptical initially, and I was like, \"Yeah, but why don't you just write the code?\nWhy does it need to be a spec and and all this SDKs and stuff?\"\nBut eventually we did this customer advisory board with a bunch of our partner companies.\nAnd when we did the MCP demo, the jaws were just on the floor.\nEverybody was like, \"Oh my god, we need this.\"\nAnd that's when I knew he was right, and we put a bunch more effort behind it and blasted it out.\nAnd shortly after our launch, all the major companies asked to sort of be uh in the loop with the steering committee and asked about our governance models and and wanted to adopt it themselves.\nSo that was really encouraging.\nOpenAI, Google, uh Microsoft, um all these companies are are betting really big on MCP.\nThis is basically a open industry standard that allows anybody to use uh this framework to effectively integrate against any model provider in a standardized way.\nMCP I think is sort of a democratizing force in letting anybody, regardless of what model provider or what longtail service provider, and that might even be like an internal only service that uh only you have, is able to integrate against a a fully-fledged client, which might look like your IDE or it might look like your document editor.\nIt could be pretty much any user interface.\nUm, and I think that's a really powerful combination.\nAnd now remote too.\nYes.\nYes.\nSo, previously you had to have the services running locally, and that was that kind of limited it to only be interesting for developers.\nBut now that we have hosted MCP or sometimes called remote, then the service provider like Google Docs could provide their own MCP, and then you can integrate that into cloud.AI or whatever service you wanted.\nBen, thanks for a great conversation.\nYeah, thanks so much.\nThanks for all the great questions.\n[Music]\nFind us on Twitter at @NoPriorsPod.\nSubscribe to our YouTube channel if you want to see our faces.\nFollow the show on Apple Podcasts, Spotify, or wherever you listen.\nThat way, you get a new episode every week.\nAnd sign up for emails or find transcripts for every episode at no-briers.com.\n",
  "dumpedAt": "2025-07-21T18:43:26.431Z"
}