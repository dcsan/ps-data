{
  "episodeId": "xqyy_Zs8Fgw",
  "channelSlug": "@nopriorspodcast",
  "title": "No Priors Ep. 123 | With ReflectionAI Co-Founder and CEO Misha Laskin",
  "publishedAt": "2025-07-17T10:01:39.000Z",
  "rawLines": [
    {
      "lang": "en",
      "text": "Hi listeners, welcome back to No Priors.",
      "offset": 5.279,
      "duration": 4.641
    },
    {
      "lang": "en",
      "text": "RL is back with a vengeance and one of",
      "offset": 7.919,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "the most talentdense new research labs",
      "offset": 9.92,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "has a product release, a new code",
      "offset": 12,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "comprehension agent. Reflection AI's",
      "offset": 14,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "co-founders, Misha Laskin and Jana",
      "offset": 16.88,
      "duration": 4.239
    },
    {
      "lang": "en",
      "text": "Santon, work together as leaders at",
      "offset": 18.8,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "Google DeepMind on groundbreaking",
      "offset": 21.119,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "projects like Alph Go, Alphazero, and",
      "offset": 22.96,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "Gemini. I talked to Misha about building",
      "offset": 25.119,
      "duration": 5.361
    },
    {
      "lang": "en",
      "text": "universal superhuman agents, the",
      "offset": 28.24,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "trickiness of reward modeling, bringing",
      "offset": 30.48,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "all knowledge work tasks under data",
      "offset": 32.96,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "distribution, how RL for language and",
      "offset": 34.8,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "robotics differs, the winds surf",
      "offset": 36.96,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "non-acquisition and the landscape from",
      "offset": 38.8,
      "duration": 3.599
    },
    {
      "lang": "en",
      "text": "here. Misha, welcome. Thank you for",
      "offset": 40.48,
      "duration": 2.48
    },
    {
      "lang": "en",
      "text": "doing this.",
      "offset": 42.399,
      "duration": 2.16
    },
    {
      "lang": "en",
      "text": ">> Yeah, thanks Sarah for having me.",
      "offset": 42.96,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": ">> So, it's been um about a wild like year",
      "offset": 44.559,
      "duration": 4.561
    },
    {
      "lang": "en",
      "text": "and a half since you guys started the",
      "offset": 47.6,
      "duration": 2.72
    },
    {
      "lang": "en",
      "text": "company. Is that about right?",
      "offset": 49.12,
      "duration": 2.56
    },
    {
      "lang": "en",
      "text": ">> Roughly a year and a half, maybe a bit",
      "offset": 50.32,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "less, but I'd say it's ballpark correct.",
      "offset": 51.68,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "Well, can you just start by describing",
      "offset": 53.76,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "you've said that the company's mission",
      "offset": 56.64,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "is to build super intelligent autonomous",
      "offset": 58,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "systems and we've talked before about",
      "offset": 59.92,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "why like this is the moment in time",
      "offset": 61.92,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "that's possible. What is different about",
      "offset": 63.44,
      "duration": 3.999
    },
    {
      "lang": "en",
      "text": "that from building just super",
      "offset": 65.68,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "intelligence which is now a sort of more",
      "offset": 67.439,
      "duration": 4.241
    },
    {
      "lang": "en",
      "text": "popular ambitious goal?",
      "offset": 70.08,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": ">> At a high level it's fairly synonymous.",
      "offset": 71.68,
      "duration": 5.84
    },
    {
      "lang": "en",
      "text": "Uh but maybe there are different ways of",
      "offset": 74.96,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "thinking about how to build super",
      "offset": 77.52,
      "duration": 2.88
    },
    {
      "lang": "en",
      "text": "intelligence and what that might look",
      "offset": 79.2,
      "duration": 2.72
    },
    {
      "lang": "en",
      "text": "like.",
      "offset": 80.4,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "I think on one spectrum there's an",
      "offset": 81.92,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "academic way to look at it uh which is",
      "offset": 84.4,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "uh and to some sense to some extent um",
      "offset": 87.68,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "super intelligence in that sense has",
      "offset": 90.08,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "already been achieved. So uh right Alph",
      "offset": 91.36,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "Go was a super intelligent system and",
      "offset": 94,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "there were other systems during that",
      "offset": 95.92,
      "duration": 2.559
    },
    {
      "lang": "en",
      "text": "time that were built that were super",
      "offset": 97.36,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "intelligent in narrow domains and I",
      "offset": 98.479,
      "duration": 4.561
    },
    {
      "lang": "en",
      "text": "think you can go for the goal of",
      "offset": 101.68,
      "duration": 4.479
    },
    {
      "lang": "en",
      "text": "building a very broad super intelligence",
      "offset": 103.04,
      "duration": 5.359
    },
    {
      "lang": "en",
      "text": "by you know kind of locking yourself up",
      "offset": 106.159,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "in an academic or it's not really an",
      "offset": 108.399,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "academic but kind of an industrial lab",
      "offset": 110.32,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "with um that is sort of kind of",
      "offset": 112.32,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "decoupled from uh product or customers",
      "offset": 114.159,
      "duration": 5.441
    },
    {
      "lang": "en",
      "text": "and kind of maps out all the benchmarks",
      "offset": 116.96,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "that are out there uh and build super",
      "offset": 119.6,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "intelligence that way. I think that is",
      "offset": 121.6,
      "duration": 6.159
    },
    {
      "lang": "en",
      "text": "that is one approach. Um I think the",
      "offset": 124.24,
      "duration": 6.719
    },
    {
      "lang": "en",
      "text": "other approach is to kind of think about",
      "offset": 127.759,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "what is super intelligence more",
      "offset": 130.959,
      "duration": 2.401
    },
    {
      "lang": "en",
      "text": "concretely. How is it going to be",
      "offset": 132.16,
      "duration": 2.48
    },
    {
      "lang": "en",
      "text": "deployed? What is it actually going to",
      "offset": 133.36,
      "duration": 3.599
    },
    {
      "lang": "en",
      "text": "look like in people's hands and build",
      "offset": 134.64,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "backwards from there. So I would kind of",
      "offset": 136.959,
      "duration": 4.481
    },
    {
      "lang": "en",
      "text": "say that that approach is more kind of",
      "offset": 139.68,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "co-designing product and research",
      "offset": 141.44,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "together. Now the kind of benefits of",
      "offset": 143.44,
      "duration": 3.519
    },
    {
      "lang": "en",
      "text": "that approach is that you're kind of uh",
      "offset": 145.44,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "m you're optimizing for real problems.",
      "offset": 146.959,
      "duration": 5.761
    },
    {
      "lang": "en",
      "text": "The cons to it is that you have to be a",
      "offset": 150.56,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "lot more focused, right? Because your",
      "offset": 152.72,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "product kind of defines the sort of",
      "offset": 154.4,
      "duration": 2.88
    },
    {
      "lang": "en",
      "text": "capabilities that you want to draw draw",
      "offset": 155.84,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "out of the system and you have to start",
      "offset": 157.28,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "out a lot more focused before expanding",
      "offset": 159.44,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "um across, you know, other product",
      "offset": 161.76,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "categories and other capabilities. So I",
      "offset": 163.28,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "would say that on the spectrum of",
      "offset": 165.44,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "companies that are kind of super",
      "offset": 167.2,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "intelligence um and just a research lab",
      "offset": 169.599,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "and then figure out what the product is,",
      "offset": 172,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "you know, once it's built as opposed to",
      "offset": 173.76,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "co-designing product and research",
      "offset": 175.76,
      "duration": 5.119
    },
    {
      "lang": "en",
      "text": "together to build very powerful systems",
      "offset": 177.76,
      "duration": 6.399
    },
    {
      "lang": "en",
      "text": "uh in what I would call kind of um ASI",
      "offset": 180.879,
      "duration": 4.801
    },
    {
      "lang": "en",
      "text": "complete categories. You can pick",
      "offset": 184.159,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "something that is uh maybe too small of",
      "offset": 185.68,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "a category to draw out a super",
      "offset": 187.76,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "intelligence. As long as you pick a",
      "offset": 189.84,
      "duration": 4.479
    },
    {
      "lang": "en",
      "text": "category that I would say is kind of big",
      "offset": 192.4,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "enough to be ASI complete um I think and",
      "offset": 194.319,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "this is kind of our approach at",
      "offset": 198,
      "duration": 2.56
    },
    {
      "lang": "en",
      "text": "reflection is it makes a lot more sense",
      "offset": 198.959,
      "duration": 4.241
    },
    {
      "lang": "en",
      "text": "to be focused and co-design those two",
      "offset": 200.56,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "things together the product and the",
      "offset": 203.2,
      "duration": 2.08
    },
    {
      "lang": "en",
      "text": "research",
      "offset": 204.72,
      "duration": 2.64
    },
    {
      "lang": "en",
      "text": ">> I want to come back to um choice of",
      "offset": 205.28,
      "duration": 5.039
    },
    {
      "lang": "en",
      "text": "initial problem uh in in a minute in",
      "offset": 207.36,
      "duration": 5.92
    },
    {
      "lang": "en",
      "text": "terms of just having the intuition and",
      "offset": 210.319,
      "duration": 5.041
    },
    {
      "lang": "en",
      "text": "the the confidence to say like we can go",
      "offset": 213.28,
      "duration": 3.599
    },
    {
      "lang": "en",
      "text": "do this as a team we're going to recruit",
      "offset": 215.36,
      "duration": 4.239
    },
    {
      "lang": "en",
      "text": "great people and go build reflection you",
      "offset": 216.879,
      "duration": 4.961
    },
    {
      "lang": "en",
      "text": "and your co-founder Giannis were working",
      "offset": 219.599,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "at Gemini together in key roles before",
      "offset": 221.84,
      "duration": 5.84
    },
    {
      "lang": "en",
      "text": "and previously you had been um part of",
      "offset": 224.799,
      "duration": 4.561
    },
    {
      "lang": "en",
      "text": "Peter Abil's lab who's an amazing",
      "offset": 227.68,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "researcher as well. Um you had described",
      "offset": 229.36,
      "duration": 4.799
    },
    {
      "lang": "en",
      "text": "to me as having like I believe the term",
      "offset": 231.84,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "you use was somewhat muscled your way",
      "offset": 234.159,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "into AI and deep learning from",
      "offset": 236.08,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "originally a physics background like how",
      "offset": 238.239,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "did you decide to go work on this and",
      "offset": 240.4,
      "duration": 2.72
    },
    {
      "lang": "en",
      "text": "end up in Peter's lab?",
      "offset": 241.92,
      "duration": 4.239
    },
    {
      "lang": "en",
      "text": ">> Yeah, as a as a kid uh I became really",
      "offset": 243.12,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "interested in physics u theoretical",
      "offset": 246.159,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "physics. Uh it was I mean probably a",
      "offset": 247.92,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "byproduct of I'm I'm Russian uh kind of",
      "offset": 249.599,
      "duration": 4.881
    },
    {
      "lang": "en",
      "text": "Israeli American and moved around and",
      "offset": 252.319,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "then when I landed in the states it was",
      "offset": 254.48,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "uh kind of in a desert in Washington",
      "offset": 256.72,
      "duration": 4.239
    },
    {
      "lang": "en",
      "text": "state uh learning a new language and so",
      "offset": 258.4,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "I had a lot of time in my hands and you",
      "offset": 260.959,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "know bumped into um my parents had uh",
      "offset": 263.44,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "had the Fman lectures uh in their in",
      "offset": 265.919,
      "duration": 5.441
    },
    {
      "lang": "en",
      "text": "their library and so I uh spent a lot of",
      "offset": 268.88,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "time you know just reading what what was",
      "offset": 271.36,
      "duration": 4.559
    },
    {
      "lang": "en",
      "text": "on the shelf and bumped into that and",
      "offset": 273.44,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "got really interested in physics. How",
      "offset": 275.919,
      "duration": 2.401
    },
    {
      "lang": "en",
      "text": "old were you?",
      "offset": 277.52,
      "duration": 2.56
    },
    {
      "lang": "en",
      "text": ">> I was so when my interest in physics",
      "offset": 278.32,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "started that was probably um around",
      "offset": 280.08,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "middle school and it really I think",
      "offset": 282.479,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "became the thing I wanted to do in in",
      "offset": 284.24,
      "duration": 4.239
    },
    {
      "lang": "en",
      "text": "high school. And the reason physics was",
      "offset": 286.08,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "so interesting was because it kind of",
      "offset": 288.479,
      "duration": 3.521
    },
    {
      "lang": "en",
      "text": "seemed like the science that was at the",
      "offset": 290.16,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "root of many of the things that became",
      "offset": 292,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "impactful. Um right so I was reading",
      "offset": 294.24,
      "duration": 4.239
    },
    {
      "lang": "en",
      "text": "about the history of the transistor and",
      "offset": 296.24,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "it was invented by a group of",
      "offset": 298.479,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "theoretical physicists. I was reading",
      "offset": 300.24,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "about you know how GPS works. So, turns",
      "offset": 302.08,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "out you need special relativity in order",
      "offset": 304.08,
      "duration": 5.679
    },
    {
      "lang": "en",
      "text": "to um accurately account for uh spatial",
      "offset": 306.16,
      "duration": 6.56
    },
    {
      "lang": "en",
      "text": "coordinates using using GPS. And so, I",
      "offset": 309.759,
      "duration": 6.241
    },
    {
      "lang": "en",
      "text": "felt that physics was kind of the the",
      "offset": 312.72,
      "duration": 5.84
    },
    {
      "lang": "en",
      "text": "root science to pursue. I I went in and",
      "offset": 316,
      "duration": 4.479
    },
    {
      "lang": "en",
      "text": "studied it, got my PhD in it. At the",
      "offset": 318.56,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "same time, I started seeing uh kind of",
      "offset": 320.479,
      "duration": 4.481
    },
    {
      "lang": "en",
      "text": "deep learning take off and really uh saw",
      "offset": 322.56,
      "duration": 5.919
    },
    {
      "lang": "en",
      "text": "kind of alpha go happen. And my sense",
      "offset": 324.96,
      "duration": 5.84
    },
    {
      "lang": "en",
      "text": "was that uh I want to pursue the kind of",
      "offset": 328.479,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "the root science. Uh but there is a such",
      "offset": 330.8,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "a thing as kind of the root science of",
      "offset": 333.919,
      "duration": 4.641
    },
    {
      "lang": "en",
      "text": "our time. Uh I think a lot of physics",
      "offset": 335.36,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "has uh is a field. It's very interesting",
      "offset": 338.56,
      "duration": 4.479
    },
    {
      "lang": "en",
      "text": "but it's crystallized a lot more than um",
      "offset": 340.56,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "you know than a new dynamic field that",
      "offset": 343.039,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "was being born out of nothing. uh and AI",
      "offset": 344.72,
      "duration": 4.479
    },
    {
      "lang": "en",
      "text": "to me felt like it was going through the",
      "offset": 347.12,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "moment uh that physics went to maybe a",
      "offset": 349.199,
      "duration": 5.121
    },
    {
      "lang": "en",
      "text": "hundred years ago that when I do problem",
      "offset": 351.84,
      "duration": 4.639
    },
    {
      "lang": "en",
      "text": "sets when I did problem sets in physics",
      "offset": 354.32,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "and the most exciting stuff that I was",
      "offset": 356.479,
      "duration": 3.361
    },
    {
      "lang": "en",
      "text": "working on there was basically the",
      "offset": 358.16,
      "duration": 2.96
    },
    {
      "lang": "en",
      "text": "things that people were discovering 100",
      "offset": 359.84,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "years ago. So I saw it kind of happening",
      "offset": 361.12,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "in front of my eyes and uh I just",
      "offset": 363.36,
      "duration": 4.559
    },
    {
      "lang": "en",
      "text": "decided that that was the science to bet",
      "offset": 365.12,
      "duration": 5.359
    },
    {
      "lang": "en",
      "text": "on. uh and in particular because it was",
      "offset": 367.919,
      "duration": 4.961
    },
    {
      "lang": "en",
      "text": "AlphaGo that was that inspired me",
      "offset": 370.479,
      "duration": 4.801
    },
    {
      "lang": "en",
      "text": "because it was just unbelievable to me",
      "offset": 372.88,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "you could train a neural network um to",
      "offset": 375.28,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "have such immense kind of basically",
      "offset": 377.84,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "reasoning capabilities, right? This",
      "offset": 380.24,
      "duration": 2.959
    },
    {
      "lang": "en",
      "text": "thing was able was super intelligent",
      "offset": 381.6,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "within the realm of go. Yeah, I decided",
      "offset": 383.199,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "that I needed to kind of get myself into",
      "offset": 385.36,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "the best reinforcement learning lab um I",
      "offset": 387.12,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "could. Um and Peter's was Peter's lab",
      "offset": 389.6,
      "duration": 4.719
    },
    {
      "lang": "en",
      "text": "was was that lab for me.",
      "offset": 393.12,
      "duration": 2.72
    },
    {
      "lang": "en",
      "text": ">> And then you and Giannis were working",
      "offset": 394.319,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "specifically on RL at Gemini. That's",
      "offset": 395.84,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "right. So, Giannis, my co-founder, was",
      "offset": 397.919,
      "duration": 5.681
    },
    {
      "lang": "en",
      "text": "the um overall RL lead for Gemini at the",
      "offset": 400,
      "duration": 6.72
    },
    {
      "lang": "en",
      "text": "time um for one and 1.5. Uh I was uh",
      "offset": 403.6,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "working very closely with him on his",
      "offset": 406.72,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "team. Yeah, it was a really exciting",
      "offset": 408.4,
      "duration": 3.519
    },
    {
      "lang": "en",
      "text": "time because you know we went both of us",
      "offset": 410.08,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "from being reinforcement learning",
      "offset": 411.919,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "researchers uh to um training large",
      "offset": 413.44,
      "duration": 5.759
    },
    {
      "lang": "en",
      "text": "language models at scale and we kind of",
      "offset": 417.039,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "saw at the end of that project of what's",
      "offset": 419.199,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "to come which was you know Gemini 1 1.5",
      "offset": 420.96,
      "duration": 4.799
    },
    {
      "lang": "en",
      "text": "lands and it became pretty clear to us",
      "offset": 423.52,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "that the next paradigm and effectively",
      "offset": 425.759,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "the the final paradigm um that we need",
      "offset": 428.16,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "to have in place before uh a you know",
      "offset": 431.039,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "what people used to call AGI or now I",
      "offset": 434.16,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "think the goalposts have shifted to ASI",
      "offset": 435.919,
      "duration": 5.201
    },
    {
      "lang": "en",
      "text": "is reached is just figuring out how to",
      "offset": 438.319,
      "duration": 4.961
    },
    {
      "lang": "en",
      "text": "scale reinforcement learning um on top",
      "offset": 441.12,
      "duration": 4.639
    },
    {
      "lang": "en",
      "text": "of large language models and the first",
      "offset": 443.28,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "instances of that have have been",
      "offset": 445.759,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "happening right over the last year. I",
      "offset": 447.199,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "think we're still actually a lot earlier",
      "offset": 449.199,
      "duration": 5.361
    },
    {
      "lang": "en",
      "text": "than people think. Uh but there is a web",
      "offset": 450.8,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "and things have started to work.",
      "offset": 454.56,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": ">> Yeah, I definitely uh I definitely want",
      "offset": 456.56,
      "duration": 3.199
    },
    {
      "lang": "en",
      "text": "to talk about what you think is solved",
      "offset": 458.24,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "and unsolved here. Um the entire field",
      "offset": 459.759,
      "duration": 5.521
    },
    {
      "lang": "en",
      "text": "has clearly gotten more focused on um",
      "offset": 462.96,
      "duration": 3.679
    },
    {
      "lang": "en",
      "text": "deep reinforcement learning over the",
      "offset": 465.28,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "last 18 months. you have this uh huge",
      "offset": 466.639,
      "duration": 6.721
    },
    {
      "lang": "en",
      "text": "product launch this week with Asimov. Um",
      "offset": 470.4,
      "duration": 4.239
    },
    {
      "lang": "en",
      "text": "can you just sort of describe what it",
      "offset": 473.36,
      "duration": 1.76
    },
    {
      "lang": "en",
      "text": "is?",
      "offset": 474.639,
      "duration": 4.481
    },
    {
      "lang": "en",
      "text": ">> So Asimov is uh the best code research",
      "offset": 475.12,
      "duration": 6.079
    },
    {
      "lang": "en",
      "text": "agent in the world. It's a comprehension",
      "offset": 479.12,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "agent, meaning that it's really designed",
      "offset": 481.199,
      "duration": 4.961
    },
    {
      "lang": "en",
      "text": "to kind of feel almost like a deep",
      "offset": 483.52,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "research for large code bases. The way a",
      "offset": 486.16,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "developer is supposed to feel",
      "offset": 489.52,
      "duration": 2.799
    },
    {
      "lang": "en",
      "text": "interacting with it is effectively like",
      "offset": 490.479,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "they have a principal level engineer who",
      "offset": 492.319,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "deeply understands their organization at",
      "offset": 494.56,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "their fingertips. Uh so it's very",
      "offset": 496.24,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "different from the existing set of tools",
      "offset": 499.44,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "that are focused primarily on code",
      "offset": 502,
      "duration": 3.599
    },
    {
      "lang": "en",
      "text": "generation like every single coding tool",
      "offset": 503.759,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "has some code generation and some",
      "offset": 505.599,
      "duration": 5.681
    },
    {
      "lang": "en",
      "text": "comprehension aspect. But as we spent a",
      "offset": 507.44,
      "duration": 7.12
    },
    {
      "lang": "en",
      "text": "lot of time kind of with our customers",
      "offset": 511.28,
      "duration": 6.639
    },
    {
      "lang": "en",
      "text": "um trying to understand why coding tools",
      "offset": 514.56,
      "duration": 5.279
    },
    {
      "lang": "en",
      "text": "and this is enterprise specific so I",
      "offset": 517.919,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "think I think the the world is different",
      "offset": 519.839,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "with startups but within enterprises",
      "offset": 521.279,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "when you you know they're adopting",
      "offset": 523.68,
      "duration": 3.599
    },
    {
      "lang": "en",
      "text": "coding tools and you see the impact that",
      "offset": 524.88,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "this is having um on their actual",
      "offset": 527.279,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "productivity and I think it's much lower",
      "offset": 528.88,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "than people uh expect um so it's uh in",
      "offset": 530.88,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "fact it's it's sometimes negative",
      "offset": 534.32,
      "duration": 2.8
    },
    {
      "lang": "en",
      "text": "sometimes negligible",
      "offset": 536.08,
      "duration": 3.759
    },
    {
      "lang": "en",
      "text": ">> did you see the recent meter report on",
      "offset": 537.12,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "that.",
      "offset": 539.839,
      "duration": 2.56
    },
    {
      "lang": "en",
      "text": ">> Yeah, the the meter report was very",
      "offset": 540.32,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "close to what I've been hearing when",
      "offset": 542.399,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "talking to engineering leaders within",
      "offset": 544.32,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "larger organizations. And it's not just",
      "offset": 546.32,
      "duration": 3.519
    },
    {
      "lang": "en",
      "text": "enterprises. It's I would say growth",
      "offset": 548,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "stage startups. It's any kind of",
      "offset": 549.839,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "engineering organization that has a",
      "offset": 551.6,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "sufficiently complex codebase and",
      "offset": 554,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "sufficiently large team that no one",
      "offset": 555.76,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "engineer can have the entire codebase",
      "offset": 558.64,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "kind of in their heads. And so",
      "offset": 560.56,
      "duration": 2.8
    },
    {
      "lang": "en",
      "text": "reflection is one of those places as",
      "offset": 562,
      "duration": 2.88
    },
    {
      "lang": "en",
      "text": "well. uh like we use our product",
      "offset": 563.36,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "actively uh because the you know",
      "offset": 564.88,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "training large language models is",
      "offset": 567.6,
      "duration": 2.72
    },
    {
      "lang": "en",
      "text": "complex and there's right the large",
      "offset": 568.8,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "language model code base there's there's",
      "offset": 570.32,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "the product codebase um knowledge is",
      "offset": 571.92,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "kind of scattered across engineers it",
      "offset": 574.16,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "it's not just in the codebase it exists",
      "offset": 576.24,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "in your chats and project management",
      "offset": 578,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "tools and um other places where",
      "offset": 580.48,
      "duration": 5.039
    },
    {
      "lang": "en",
      "text": "knowledge lives and so what we're",
      "offset": 582.399,
      "duration": 5.201
    },
    {
      "lang": "en",
      "text": "effectively building towards is this uh",
      "offset": 585.519,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "kind of omnisient oracle for",
      "offset": 587.6,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "organizations that uh you can go in uh",
      "offset": 589.2,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "ask",
      "offset": 592.56,
      "duration": 2.719
    },
    {
      "lang": "en",
      "text": "any question at kind of any level of",
      "offset": 593.76,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "complexity and it'll provide you an",
      "offset": 595.279,
      "duration": 4.721
    },
    {
      "lang": "en",
      "text": "answer at the level of what that",
      "offset": 597.76,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "principal level engineer would have",
      "offset": 600,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "given you or you know in the future as",
      "offset": 601.6,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "the product expands to other categories",
      "offset": 603.839,
      "duration": 4.961
    },
    {
      "lang": "en",
      "text": "um what the person who's most embedded",
      "offset": 606.16,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "in the organization understands um and",
      "offset": 608.8,
      "duration": 5.599
    },
    {
      "lang": "en",
      "text": "of course once you have that solved it",
      "offset": 611.92,
      "duration": 5.359
    },
    {
      "lang": "en",
      "text": "begets much more reliable agents that",
      "offset": 614.399,
      "duration": 5.361
    },
    {
      "lang": "en",
      "text": "act for you as well um but I think the",
      "offset": 617.279,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "world today is focused on I would say",
      "offset": 619.76,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "80% kind of action",
      "offset": 621.44,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "20% understanding. So 80% code",
      "offset": 623.44,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "generation, 20% comprehension. The",
      "offset": 625.92,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "actual problem is exactly the opposite.",
      "offset": 628.48,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "That when you look at what an engineer",
      "offset": 630.32,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "does in an organization, 80% of their",
      "offset": 632.16,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "time they're spending trying to",
      "offset": 634.399,
      "duration": 3.361
    },
    {
      "lang": "en",
      "text": "comprehend complex systems and um",
      "offset": 635.44,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "collaborating with teammates. And what",
      "offset": 637.76,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "is collaboration? It's usually someone",
      "offset": 639.36,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "asking someone else a question about a",
      "offset": 641.44,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "system that they don't know. And so that",
      "offset": 643.2,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "I think is kind of the problem at the",
      "offset": 645.92,
      "duration": 5.84
    },
    {
      "lang": "en",
      "text": "heart of what would prevent a super",
      "offset": 648.56,
      "duration": 5.279
    },
    {
      "lang": "en",
      "text": "intelligence from actually working",
      "offset": 651.76,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "within an organization. It's really this",
      "offset": 653.839,
      "duration": 4.801
    },
    {
      "lang": "en",
      "text": "kind of understanding and being able to",
      "offset": 656.48,
      "duration": 3.359
    },
    {
      "lang": "en",
      "text": "ingest from a lot of sources of",
      "offset": 658.64,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "information and from the team. And once",
      "offset": 659.839,
      "duration": 4.641
    },
    {
      "lang": "en",
      "text": "you have that then the action part I",
      "offset": 661.92,
      "duration": 5.599
    },
    {
      "lang": "en",
      "text": "think becomes uh I don't want to say",
      "offset": 664.48,
      "duration": 6.08
    },
    {
      "lang": "en",
      "text": "trivial but a lot easier. Like it to me",
      "offset": 667.519,
      "duration": 4.961
    },
    {
      "lang": "en",
      "text": "it seems like really 20% of the problem",
      "offset": 670.56,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "is teaching these agents how to act and",
      "offset": 672.48,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "it's more or less solved. That",
      "offset": 674.8,
      "duration": 2.56
    },
    {
      "lang": "en",
      "text": "definitely squares with both my",
      "offset": 676.16,
      "duration": 2.799
    },
    {
      "lang": "en",
      "text": "understanding of engineering and then my",
      "offset": 677.36,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "experience with coding agents",
      "offset": 678.959,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "personally, right? If if you think about",
      "offset": 680.8,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "the I don't know the like context load",
      "offset": 683.279,
      "duration": 4.481
    },
    {
      "lang": "en",
      "text": "time of just like trying to understand a",
      "offset": 685.36,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "new system or code anyone else has",
      "offset": 687.76,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "written or code your Asian has written",
      "offset": 689.92,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "in the end it's like you know very",
      "offset": 692.16,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "stupid um implementation that like if",
      "offset": 694.56,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "you had reasoned through it with context",
      "offset": 697.76,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "of the system you never would have made",
      "offset": 699.76,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "such a mistake or like a you know works",
      "offset": 701.2,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "in works in my environment type problem.",
      "offset": 703.68,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "Um and and so I I think that very much",
      "offset": 706.48,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "mirrors my you know intuitive",
      "offset": 709.04,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "understanding of engineering here.",
      "offset": 710.8,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "That's great as problem formation. What",
      "offset": 712.8,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "what makes ASMO different in terms of",
      "offset": 714.72,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "ability to understand better versus just",
      "offset": 716.8,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "generate code?",
      "offset": 719.36,
      "duration": 2.8
    },
    {
      "lang": "en",
      "text": ">> There are a few things. So I think this",
      "offset": 720.48,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "is kind of where you know why it is so",
      "offset": 722.16,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "important to co-design research and",
      "offset": 726,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "product because as a researcher you'd go",
      "offset": 727.76,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "in and say the answer is entirely in the",
      "offset": 730.16,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "agent design or the model or something",
      "offset": 732.72,
      "duration": 3.119
    },
    {
      "lang": "en",
      "text": "like this and as a product person you",
      "offset": 734.32,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "would say well it's in these product you",
      "offset": 735.839,
      "duration": 5.361
    },
    {
      "lang": "en",
      "text": "know differentiators like being able to",
      "offset": 738.8,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "draw not just from your codebase but",
      "offset": 741.2,
      "duration": 3.439
    },
    {
      "lang": "en",
      "text": "knowledge that lives you know in other",
      "offset": 742.72,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "sources of information or being able to",
      "offset": 744.639,
      "duration": 4.481
    },
    {
      "lang": "en",
      "text": "learn from kind of the engineering team",
      "offset": 746.72,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "to offload uh their tribal knowledge. So",
      "offset": 749.12,
      "duration": 4.959
    },
    {
      "lang": "en",
      "text": "right an engineer can go in and teach as",
      "offset": 751.68,
      "duration": 5.599
    },
    {
      "lang": "en",
      "text": "like hey uh we deploy our you know when",
      "offset": 754.079,
      "duration": 5.041
    },
    {
      "lang": "en",
      "text": "we say environment jobs it's on our team",
      "offset": 757.279,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "we mean this specific thing which we",
      "offset": 759.12,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "mean kind of Google bath jobs. So now",
      "offset": 761.2,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "when another engineer asks a question",
      "offset": 763.36,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "about environment jobs in the future the",
      "offset": 765.12,
      "duration": 2.88
    },
    {
      "lang": "en",
      "text": "system just knows what they're talking",
      "offset": 766.8,
      "duration": 2.88
    },
    {
      "lang": "en",
      "text": "about. A lot of knowledge is stored in",
      "offset": 768,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "engineers heads and I think you need um",
      "offset": 769.68,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "both of these things. you need to",
      "offset": 772.48,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "understand your customer really closely",
      "offset": 774.72,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "and develop differentiated product",
      "offset": 776.639,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "almost independently right of the models",
      "offset": 778.48,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "that are powering it. Um but then you",
      "offset": 780.24,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "also need to innovate on the research uh",
      "offset": 782.88,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "in terms of agent design and model",
      "offset": 786.24,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "training to actually drive the",
      "offset": 788.56,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "capabilities that you want to see out of",
      "offset": 790.48,
      "duration": 3.359
    },
    {
      "lang": "en",
      "text": "the system and this becomes an",
      "offset": 792.24,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "evaluation problem which is basically at",
      "offset": 793.839,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "the heart of any any frontier lab as",
      "offset": 795.92,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "well. This is uh I think the least",
      "offset": 798.079,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "spoken about part of what Frontier Labs",
      "offset": 799.839,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "do but possibly the most important which",
      "offset": 801.839,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "is figuring out how they evaluate like",
      "offset": 803.44,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "what makes Claude magically feel better",
      "offset": 805.279,
      "duration": 5.521
    },
    {
      "lang": "en",
      "text": "at code than um you know another model",
      "offset": 808.16,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "out there. Um they did something right",
      "offset": 810.8,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "in their evaluations. So when you look",
      "offset": 812.72,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "at this problem specifically there are",
      "offset": 816.48,
      "duration": 4.799
    },
    {
      "lang": "en",
      "text": "different capabilities that you need to",
      "offset": 818.72,
      "duration": 5.119
    },
    {
      "lang": "en",
      "text": "um train and and what we do is we really",
      "offset": 821.279,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "post train models where you know we",
      "offset": 823.839,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "really focus on on post training today.",
      "offset": 825.36,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "Some of these things are long context",
      "offset": 827.519,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "reasoning. Now when I say long context",
      "offset": 829.04,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "reasoning, I don't mean um I actually",
      "offset": 832.079,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "mean kind of small models with very long",
      "offset": 834.16,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "contexts that are able to go into giant",
      "offset": 836.639,
      "duration": 5.601
    },
    {
      "lang": "en",
      "text": "code bases, sort of suck up as much",
      "offset": 839.68,
      "duration": 5.279
    },
    {
      "lang": "en",
      "text": "information as they can and reason over",
      "offset": 842.24,
      "duration": 5.039
    },
    {
      "lang": "en",
      "text": "and output relevant stuff basically. So",
      "offset": 844.959,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "it's almost like neural retrieval. There",
      "offset": 847.279,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "are capabilities like um tool use and",
      "offset": 849.279,
      "duration": 5.041
    },
    {
      "lang": "en",
      "text": "multihop reasoning. So this is more for",
      "offset": 852.079,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "a you have your agent and it's designed",
      "offset": 854.32,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "with some tools and there are two ways",
      "offset": 856.48,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "of training um agentic models. One is in",
      "offset": 858.88,
      "duration": 5.84
    },
    {
      "lang": "en",
      "text": "this very general way where you just",
      "offset": 861.44,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "train it on thousands of environments",
      "offset": 864.72,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "and make it like the most general agent",
      "offset": 866.16,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "possible. And that is kind of almost",
      "offset": 867.92,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "like the pre-training of agents. Um and",
      "offset": 870,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "that's sort of what you know that's what",
      "offset": 872.079,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "a Frontier Lab does. Um that's what um",
      "offset": 874.079,
      "duration": 4.961
    },
    {
      "lang": "en",
      "text": "this there's a new release from uh Kimmy",
      "offset": 876.48,
      "duration": 5.039
    },
    {
      "lang": "en",
      "text": "2. That's kind of what that model does.",
      "offset": 879.04,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "And that's definitely part of it, but in",
      "offset": 881.519,
      "duration": 5.041
    },
    {
      "lang": "en",
      "text": "order to that that kind of gives you a",
      "offset": 884.48,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "nice general base to start from. Um, but",
      "offset": 886.56,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "then to drive a capability kind of",
      "offset": 889.76,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "depthwise like if you really want this",
      "offset": 892.56,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "reasoner that has, you know, search",
      "offset": 894.48,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "tools and, you know, ability to call",
      "offset": 896.399,
      "duration": 4.481
    },
    {
      "lang": "en",
      "text": "like these long reasoning context models",
      "offset": 898.32,
      "duration": 4.639
    },
    {
      "lang": "en",
      "text": "and other, you know, other tools that it",
      "offset": 900.88,
      "duration": 3.199
    },
    {
      "lang": "en",
      "text": "might want to interact with like, oh,",
      "offset": 902.959,
      "duration": 3.361
    },
    {
      "lang": "en",
      "text": "when do I when do I read from Jira? When",
      "offset": 904.079,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "do I read from um another tool? Like",
      "offset": 906.32,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "this is kind of a reasoning problem. If",
      "offset": 908.48,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "you train with those specific tools in",
      "offset": 910.56,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "mind, uh that's typically what people",
      "offset": 912.56,
      "duration": 3.519
    },
    {
      "lang": "en",
      "text": "refer to when they when they say tool",
      "offset": 914.32,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "use like they actually train for a",
      "offset": 916.079,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "specific set of tools and really drive",
      "offset": 918,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "like the capabilities um for those",
      "offset": 920.24,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "tools. So these are the kinds of",
      "offset": 922.399,
      "duration": 2.721
    },
    {
      "lang": "en",
      "text": "research problems that you need to solve",
      "offset": 923.44,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "in order to build the overall system",
      "offset": 925.12,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "that's the best in the world. It's not",
      "offset": 927.68,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "any one thing. It's all these things",
      "offset": 929.04,
      "duration": 4.799
    },
    {
      "lang": "en",
      "text": "combined. um and some examples of",
      "offset": 930.72,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "systems that are being trained for a",
      "offset": 933.839,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "specific set of tools. The thing that",
      "offset": 935.12,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "comes to mind is Gro the Groth 4 release",
      "offset": 936.959,
      "duration": 5.041
    },
    {
      "lang": "en",
      "text": "and they kind of showed a plot of their",
      "offset": 939.36,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "general model and then the model that",
      "offset": 942,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "was trained with a tool to um basically",
      "offset": 944.16,
      "duration": 5.679
    },
    {
      "lang": "en",
      "text": "climb on humanity's last exam and there",
      "offset": 947.12,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "was um some big noticeable difference",
      "offset": 949.839,
      "duration": 5.601
    },
    {
      "lang": "en",
      "text": "between the two. Now that's great, but I",
      "offset": 951.519,
      "duration": 7.68
    },
    {
      "lang": "en",
      "text": "think the downside of that is that does",
      "offset": 955.44,
      "duration": 5.92
    },
    {
      "lang": "en",
      "text": "humanity's last exam actually matter in",
      "offset": 959.199,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "any meaningful way for an end user. And",
      "offset": 961.36,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "I would argue that some weak",
      "offset": 964.639,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "correlation, but the answer is most",
      "offset": 966.8,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "likely no. Uh, and so you have to build",
      "offset": 968.24,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "the tools and train for the things that",
      "offset": 971.199,
      "duration": 3.121
    },
    {
      "lang": "en",
      "text": "users actually want. I think that",
      "offset": 972.88,
      "duration": 3.519
    },
    {
      "lang": "en",
      "text": "there's sort of no way around that. What",
      "offset": 974.32,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "can you share about how you evaluate",
      "offset": 976.399,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "either like technically or um",
      "offset": 978.8,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "philosophically that u makes simos",
      "offset": 980.639,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "performance great?",
      "offset": 983.199,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": ">> This is sort of why it makes sense to do",
      "offset": 984.24,
      "duration": 5.519
    },
    {
      "lang": "en",
      "text": "something like this as a startup. Um so",
      "offset": 987.279,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "the only the only advantage that you'll",
      "offset": 989.759,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "ever have as a startup um over a big",
      "offset": 991.44,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "incumbent um especially when there are",
      "offset": 993.759,
      "duration": 4.961
    },
    {
      "lang": "en",
      "text": "such talented teams out there uh is kind",
      "offset": 995.279,
      "duration": 5.281
    },
    {
      "lang": "en",
      "text": "of focus and velocity against the thing",
      "offset": 998.72,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "that you're focused on. Now I think you",
      "offset": 1000.56,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "need if you want to be playing in what",
      "offset": 1002.24,
      "duration": 6.159
    },
    {
      "lang": "en",
      "text": "is you know arguably I think the biggest",
      "offset": 1005.44,
      "duration": 5.839
    },
    {
      "lang": "en",
      "text": "category in AI which is coding then you",
      "offset": 1008.399,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "need you need to have the talent as well",
      "offset": 1011.279,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "to do it. Um but you know what do you do",
      "offset": 1013.839,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "if you don't have the billions of you",
      "offset": 1016.079,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "know of dollars to uh pre-train models.",
      "offset": 1017.519,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "The only way we can win I think is by",
      "offset": 1019.759,
      "duration": 4.721
    },
    {
      "lang": "en",
      "text": "being um very focused. So the way I",
      "offset": 1021.44,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "would you know describe what does it",
      "offset": 1024.48,
      "duration": 4.479
    },
    {
      "lang": "en",
      "text": "look like to work on uh a big model",
      "offset": 1026.24,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "within a you know within an incumbent",
      "offset": 1028.959,
      "duration": 5.761
    },
    {
      "lang": "en",
      "text": "lab is that you are one of like hundreds",
      "offset": 1031.12,
      "duration": 6.559
    },
    {
      "lang": "en",
      "text": "of evals there are teams you know when",
      "offset": 1034.72,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "you look at um the model card for let's",
      "offset": 1037.679,
      "duration": 5.601
    },
    {
      "lang": "en",
      "text": "say the 01 paper um that came out I",
      "offset": 1040.4,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "think last year if you look at the",
      "offset": 1043.28,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "distribution of what most people work on",
      "offset": 1044.799,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "in that on that paper was eval so you're",
      "offset": 1046.64,
      "duration": 5.279
    },
    {
      "lang": "en",
      "text": "one of you know many people doing all",
      "offset": 1049.039,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "sorts of eval",
      "offset": 1051.919,
      "duration": 4.721
    },
    {
      "lang": "en",
      "text": "um and spreading yourself in that sense,",
      "offset": 1053.36,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "you get something that's general, but",
      "offset": 1056.64,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "it's spread fairly thin. As a startup",
      "offset": 1058,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "and a startup that has a very focused",
      "offset": 1060.24,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "product that didn't um you know, that's",
      "offset": 1062.4,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "not kind of being too diffused and it's",
      "offset": 1064.16,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "pretty opinionated about what it is that",
      "offset": 1065.6,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "it's building. Your evals are basically",
      "offset": 1067.6,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "what you know in the startup lore when I",
      "offset": 1069.6,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "don't know Paul Graham would tell you to",
      "offset": 1071.919,
      "duration": 2.961
    },
    {
      "lang": "en",
      "text": "kind of go talk to customers like half",
      "offset": 1073.36,
      "duration": 2.72
    },
    {
      "lang": "en",
      "text": "the time build product, half the time",
      "offset": 1074.88,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "talk to customers. I think in the AI age",
      "offset": 1076.08,
      "duration": 5.839
    },
    {
      "lang": "en",
      "text": "it's um develop your evals based on what",
      "offset": 1078.48,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "customers are saying and what they're",
      "offset": 1081.919,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "doing. So you have to work with your",
      "offset": 1083.28,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "customers to look at what prompts it is",
      "offset": 1085.039,
      "duration": 4.961
    },
    {
      "lang": "en",
      "text": "that they're uh you know trying to solve",
      "offset": 1086.88,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "what general questions are they trying",
      "offset": 1090,
      "duration": 3.679
    },
    {
      "lang": "en",
      "text": "to unlock. So right there's very",
      "offset": 1091.76,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "specific pain points that um you know",
      "offset": 1093.679,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "we've identified like onboarding being",
      "offset": 1095.919,
      "duration": 4.481
    },
    {
      "lang": "en",
      "text": "one of them like in a big company uh it",
      "offset": 1097.76,
      "duration": 5.279
    },
    {
      "lang": "en",
      "text": "takes months to onboard an engineer. So",
      "offset": 1100.4,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "how do you develop evals that accelerate",
      "offset": 1103.039,
      "duration": 5.281
    },
    {
      "lang": "en",
      "text": "the onboarding of an engineer from you",
      "offset": 1106,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "know months to hopefully just a couple",
      "offset": 1108.32,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "of weeks now that you know all the",
      "offset": 1110.32,
      "duration": 2.96
    },
    {
      "lang": "en",
      "text": "questions that they had they can just",
      "offset": 1111.84,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "ask Azimov and um be able to onboard",
      "offset": 1113.28,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "much faster. So I think there's no",
      "offset": 1116.24,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "there's no silver bullet other than",
      "offset": 1118.08,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "coupling to the information coming from",
      "offset": 1120.16,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "customers but then being very scientific",
      "offset": 1123.36,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "in the evals that you develop across",
      "offset": 1125.52,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "them. So you have these let's say",
      "offset": 1127.36,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "customer needs let's say onboarding and",
      "offset": 1129.36,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "you know a bunch of others um and then",
      "offset": 1131.44,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "you have your system capabilities which",
      "offset": 1134.08,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "is well what do you need in order to",
      "offset": 1135.84,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "provide a good experience there um well",
      "offset": 1138,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "this customer is being onboarded onto a",
      "offset": 1140.72,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "giant codebase like it has uh you know",
      "offset": 1142.72,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "it might be a codebase that on its own",
      "offset": 1145.2,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "is like 100 million tokens or something",
      "offset": 1146.88,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "well then you need to figure out some",
      "offset": 1149.039,
      "duration": 4.481
    },
    {
      "lang": "en",
      "text": "way to reason over that giant codebase",
      "offset": 1151.6,
      "duration": 3.439
    },
    {
      "lang": "en",
      "text": "so you have kind of a long context",
      "offset": 1153.52,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "reasoning capability or you kind of look",
      "offset": 1155.039,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "at your agent and seeing like what's",
      "offset": 1157.36,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "preventing it from",
      "offset": 1158.64,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "satisfying this query from a from a",
      "offset": 1160.72,
      "duration": 4.959
    },
    {
      "lang": "en",
      "text": "user. Um and and so you kind of work",
      "offset": 1162.799,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "backwards and reverse engineer from what",
      "offset": 1165.679,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "a user is asking for to what",
      "offset": 1167.919,
      "duration": 2.88
    },
    {
      "lang": "en",
      "text": "capabilities you want to drive in your",
      "offset": 1169.28,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "system. But the important part I think",
      "offset": 1170.799,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "is to be able to tweak every part of the",
      "offset": 1172.72,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "system from you know the product",
      "offset": 1174.799,
      "duration": 3.521
    },
    {
      "lang": "en",
      "text": "features to the agent design to the",
      "offset": 1176.24,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "model training uh in order to build the",
      "offset": 1178.32,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "best overall system. And if you are",
      "offset": 1180.72,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "capped in which parts you can change",
      "offset": 1183.28,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "like if you can only change the product",
      "offset": 1185.039,
      "duration": 4.241
    },
    {
      "lang": "en",
      "text": "and agent design then you're actually",
      "offset": 1186.96,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "pretty limited in what you can do",
      "offset": 1189.28,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "because you're kind of at the mercy of",
      "offset": 1190.72,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "you know what um kind of these general",
      "offset": 1192.88,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "third party models can do. What I'm",
      "offset": 1195.2,
      "duration": 4.719
    },
    {
      "lang": "en",
      "text": "hearing from you is also that there is",
      "offset": 1197.6,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "some trade-off between uh having you",
      "offset": 1199.919,
      "duration": 5.841
    },
    {
      "lang": "en",
      "text": "know uh to serve all different kinds of",
      "offset": 1203.6,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "users and um optimizing across those",
      "offset": 1205.76,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "different evals because each one of the",
      "offset": 1208.96,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "teams that is thinking about a",
      "offset": 1211.36,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "particular use case or audience at a um",
      "offset": 1213.2,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "more general organization for example is",
      "offset": 1216.4,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "less likely to have the ability to work",
      "offset": 1218.88,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "through the entire pipeline from",
      "offset": 1221.28,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "training to product to to win their use",
      "offset": 1222.88,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "case. So the thing that was extremely",
      "offset": 1225.679,
      "duration": 3.041
    },
    {
      "lang": "en",
      "text": "satisfying about working on Gemini is",
      "offset": 1227.2,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "that you're driving research in the",
      "offset": 1228.72,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "frontier and there's something very",
      "offset": 1230.48,
      "duration": 3.439
    },
    {
      "lang": "en",
      "text": "gratifying about that. The downside was",
      "offset": 1231.84,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "that you were so far away removed from",
      "offset": 1233.919,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "product that it was kind of a broken",
      "offset": 1236.24,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "telephone game of talking to there kind",
      "offset": 1238.159,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "of four different people that",
      "offset": 1241.2,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "information flowed through before the",
      "offset": 1242.799,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "model got into a customer's hands. that",
      "offset": 1244.72,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "coupling was very loose and I think it's",
      "offset": 1246.799,
      "duration": 6.561
    },
    {
      "lang": "en",
      "text": "very true that um just because uh a",
      "offset": 1249.6,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "company might have the best model in",
      "offset": 1253.36,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "some general set of um academic",
      "offset": 1255.28,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "benchmarks doesn't actually mean they",
      "offset": 1257.36,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "have the best product. Uh and I think",
      "offset": 1259.2,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "what we're seeing is when things really",
      "offset": 1261.2,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "fit together. It's usually that there's",
      "offset": 1263.44,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "a you know a tight coupling between a",
      "offset": 1265.36,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "product and a model that it's a whole",
      "offset": 1268.48,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "system. It's not just the model alone.",
      "offset": 1271.12,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "Um obviously the first big example of",
      "offset": 1272.88,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "that was uh chat GBT right chat GBT is",
      "offset": 1275.2,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "kind of an incredible product that was",
      "offset": 1278.32,
      "duration": 3.599
    },
    {
      "lang": "en",
      "text": "coupled with the model and the model was",
      "offset": 1279.84,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "post-trained for the prompts that are",
      "offset": 1281.919,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "coming in from users for chat from chat",
      "offset": 1283.36,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "GBT like there was a reason why it was",
      "offset": 1285.039,
      "duration": 4.721
    },
    {
      "lang": "en",
      "text": "you know when I saw the first coding",
      "offset": 1287.52,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "blog post that chat GBT produced for me",
      "offset": 1289.76,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "that was that was just insane that was",
      "offset": 1292.72,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "like an insane magical moment and they",
      "offset": 1294.96,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "post trained specifically for that and I",
      "offset": 1296.88,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "think there's an another example of that",
      "offset": 1299.6,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "happening right now with cloud code. Um,",
      "offset": 1302.08,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "that's kind of tight model to product",
      "offset": 1304.08,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "coupling and and so I really think that",
      "offset": 1306.24,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "that's it's important to really be able",
      "offset": 1308.96,
      "duration": 2.88
    },
    {
      "lang": "en",
      "text": "to do both at a great degree of",
      "offset": 1310.4,
      "duration": 2.32
    },
    {
      "lang": "en",
      "text": "excellence.",
      "offset": 1311.84,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": ">> What is an example as you guys open up",
      "offset": 1312.72,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "the weight list that you want users to",
      "offset": 1315.36,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "try where it should just be like obvious",
      "offset": 1317.36,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "that the answers are are better than",
      "offset": 1319.52,
      "duration": 3.519
    },
    {
      "lang": "en",
      "text": "other coding agents?",
      "offset": 1321.6,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": ">> I think the kinds of um queries that it",
      "offset": 1323.039,
      "duration": 4.481
    },
    {
      "lang": "en",
      "text": "tends to be better at are I guess what",
      "offset": 1326,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "we would call semantic queries. So let's",
      "offset": 1327.52,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "say like an example of a query where",
      "offset": 1330.48,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "this is not the best system to use. It's",
      "offset": 1332.4,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "like file level. If you're looking at a",
      "offset": 1334.24,
      "duration": 3.439
    },
    {
      "lang": "en",
      "text": "file and there's like a specific thing",
      "offset": 1336.4,
      "duration": 2.399
    },
    {
      "lang": "en",
      "text": "in that file and you're just trying to",
      "offset": 1337.679,
      "duration": 3.201
    },
    {
      "lang": "en",
      "text": "get quick answer to it, you don't really",
      "offset": 1338.799,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "need the hammer of like a deep research",
      "offset": 1340.88,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "like experience. Um you don't need to",
      "offset": 1343.039,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "wait, you know, like tens of seconds or",
      "offset": 1344.64,
      "duration": 5.519
    },
    {
      "lang": "en",
      "text": "a minute or two uh to to get that answer",
      "offset": 1346.64,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "because that should just be delivered",
      "offset": 1350.159,
      "duration": 5.601
    },
    {
      "lang": "en",
      "text": "snappily. But if you um don't exactly",
      "offset": 1351.28,
      "duration": 6.639
    },
    {
      "lang": "en",
      "text": "know where you're looking for and you",
      "offset": 1355.76,
      "duration": 3.279
    },
    {
      "lang": "en",
      "text": "you know you don't know the function",
      "offset": 1357.919,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "name or you don't you know something and",
      "offset": 1359.039,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "this is kind of the hard problems that",
      "offset": 1361.039,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "engineers are usually in like there's a",
      "offset": 1362.88,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "flaky test. I mean you know that this",
      "offset": 1364.88,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "test is flaky but that's where your",
      "offset": 1366.88,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "knowledge stops right and that's when",
      "offset": 1369.76,
      "duration": 2.96
    },
    {
      "lang": "en",
      "text": "you usually go to Slack and ask an",
      "offset": 1371.12,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "engineer like this test is flaky what's",
      "offset": 1372.72,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "going on? Does anyone know? Um, you",
      "offset": 1374.64,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "know, we've had, uh, the way we've used",
      "offset": 1377.12,
      "duration": 4.799
    },
    {
      "lang": "en",
      "text": "it is when you're training these models,",
      "offset": 1379.52,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "there's a lot of infrastructure work",
      "offset": 1381.919,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "that goes into it and, um, it fails in",
      "offset": 1383.12,
      "duration": 6.24
    },
    {
      "lang": "en",
      "text": "interesting ways all the time. Uh, and",
      "offset": 1385.76,
      "duration": 5.84
    },
    {
      "lang": "en",
      "text": "asking things like, you know, my jobs",
      "offset": 1389.36,
      "duration": 4.799
    },
    {
      "lang": "en",
      "text": "are running slowly, five times more",
      "offset": 1391.6,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "slowly than usually. Why is that? Right?",
      "offset": 1394.159,
      "duration": 6.161
    },
    {
      "lang": "en",
      "text": "That's kind of a vague query that would",
      "offset": 1396.64,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "be very hard to answer with existing",
      "offset": 1400.32,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "systems. um especially since the",
      "offset": 1402,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "knowledge around that query might live",
      "offset": 1405.12,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "not just in the codebase. So in the",
      "offset": 1407.12,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "example that I just brought up um when",
      "offset": 1408.88,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "this was happening that our kind of",
      "offset": 1411.12,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "environment jobs were slowing down uh it",
      "offset": 1412.64,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "turned out that two different teams kind",
      "offset": 1415.6,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "of infrastructure and research team",
      "offset": 1417.44,
      "duration": 4.239
    },
    {
      "lang": "en",
      "text": "submitted um pull requests that were",
      "offset": 1419.36,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "they passed tests. It wasn't that um",
      "offset": 1421.679,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "they were wrong, but they kind of",
      "offset": 1423.6,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "conflicted together in a way that caused",
      "offset": 1425.679,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "this kind of um effectively a race",
      "offset": 1427.52,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "condition uh and slowed everyone's jobs",
      "offset": 1429.36,
      "duration": 4.799
    },
    {
      "lang": "en",
      "text": "down. And these are the kinds of bugs",
      "offset": 1431.84,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "that actually engineers spend, you know,",
      "offset": 1434.159,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "that's where you have like two or three",
      "offset": 1436.32,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "engineers who spend a few days trying to",
      "offset": 1437.919,
      "duration": 4.721
    },
    {
      "lang": "en",
      "text": "solve one of these. Um so I think these",
      "offset": 1439.6,
      "duration": 6.559
    },
    {
      "lang": "en",
      "text": "kinds of semantic queries um tend to be",
      "offset": 1442.64,
      "duration": 5.279
    },
    {
      "lang": "en",
      "text": "the place where where a product like",
      "offset": 1446.159,
      "duration": 3.281
    },
    {
      "lang": "en",
      "text": "this shines. In the same way that when",
      "offset": 1447.919,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "you think of uh what kind of query would",
      "offset": 1449.44,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "you ask chat GBT to you know when it",
      "offset": 1451.279,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "just needs to use kind of the browser",
      "offset": 1454.4,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "tool so it's like a quick factual thing",
      "offset": 1455.679,
      "duration": 3.761
    },
    {
      "lang": "en",
      "text": "like you wouldn't invoke the deep",
      "offset": 1458,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "research experience but when you wanted",
      "offset": 1459.44,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "to compile kind of a a lot of",
      "offset": 1462.24,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "information around some more nebulous",
      "offset": 1465.12,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "query uh I think that's where people",
      "offset": 1468,
      "duration": 3.039
    },
    {
      "lang": "en",
      "text": "seem to find a lot of value with deep",
      "offset": 1469.6,
      "duration": 4.559
    },
    {
      "lang": "en",
      "text": "research so I think a similar kind of um",
      "offset": 1471.039,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "mindset holds here",
      "offset": 1474.159,
      "duration": 4.481
    },
    {
      "lang": "en",
      "text": ">> one thing I would do you know working on",
      "offset": 1475.919,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "new system with principal engineer next",
      "offset": 1478.64,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "to me is just have them explain the",
      "offset": 1480.559,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "entire system, right? Um uh because I",
      "offset": 1482.08,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "want to have that context where I can't",
      "offset": 1484.88,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "I can't even tell the agent what to do.",
      "offset": 1486.64,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "Um and so I'm I'm curious from a product",
      "offset": 1488.799,
      "duration": 5.841
    },
    {
      "lang": "en",
      "text": "perspective like uh the way you have you",
      "offset": 1490.88,
      "duration": 6.48
    },
    {
      "lang": "en",
      "text": "know memory for agents or even for teams",
      "offset": 1494.64,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "is an increasingly popular idea. There's",
      "offset": 1497.36,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "lots of ideas about how um how to do it.",
      "offset": 1499.039,
      "duration": 5.361
    },
    {
      "lang": "en",
      "text": "I think there are not many examples of",
      "offset": 1501.6,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "like collaborative memory in production",
      "offset": 1504.4,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "in a useful way yet but I'm sure it is",
      "offset": 1506.24,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "coming. Um have you guys designed it in",
      "offset": 1508.4,
      "duration": 4.639
    },
    {
      "lang": "en",
      "text": "a form like I can understand too? Yes,",
      "offset": 1510.48,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "that's so this is actually one of the",
      "offset": 1513.039,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "more fun things to I think work on in",
      "offset": 1515.52,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "product today and I think it's one of",
      "offset": 1517.919,
      "duration": 3.441
    },
    {
      "lang": "en",
      "text": "the more fun kind of features to work on",
      "offset": 1519.52,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "at the company is um how do you design a",
      "offset": 1521.36,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "teamwide memory because",
      "offset": 1524.72,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": ">> there are all sorts of details around",
      "offset": 1527.12,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "well who can edit the memory um who can",
      "offset": 1529.2,
      "duration": 6.079
    },
    {
      "lang": "en",
      "text": "view different parts of the memory uh",
      "offset": 1532.08,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": ">> how do you you know how do you maintain",
      "offset": 1535.279,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "a kind of repository of of this memory",
      "offset": 1536.96,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "for people to edit and view",
      "offset": 1539.36,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": ">> you have to have a concept of authority",
      "offset": 1540.64,
      "duration": 2.88
    },
    {
      "lang": "en",
      "text": "right? People are going to say things",
      "offset": 1542.4,
      "duration": 1.84
    },
    {
      "lang": "en",
      "text": "that are wrong.",
      "offset": 1543.52,
      "duration": 2.32
    },
    {
      "lang": "en",
      "text": ">> The way it's worked with customers we've",
      "offset": 1544.24,
      "duration": 3.679
    },
    {
      "lang": "en",
      "text": "started working with is uh they",
      "offset": 1545.84,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "typically have they want to start off",
      "offset": 1547.919,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "with kind of a group of trusted kind of",
      "offset": 1549.6,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "senior staff level plus engineers who",
      "offset": 1551.52,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "are kind of the gatekeepers which is a",
      "offset": 1554.4,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "very I think common notion. Um you have",
      "offset": 1556.08,
      "duration": 4.719
    },
    {
      "lang": "en",
      "text": "permissions right and ownerships uh",
      "offset": 1558.48,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "ownership structure and code bases and",
      "offset": 1560.799,
      "duration": 3.041
    },
    {
      "lang": "en",
      "text": "they basically are the ones who kind of",
      "offset": 1562.48,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "populate the memory first um and then",
      "offset": 1563.84,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "sort of expand the scope. But it I think",
      "offset": 1566,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "it works. It's it's actually a much more",
      "offset": 1567.679,
      "duration": 4.561
    },
    {
      "lang": "en",
      "text": "complex feature to build uh because it",
      "offset": 1569.44,
      "duration": 5.599
    },
    {
      "lang": "en",
      "text": "touches on um yeah or wide permissions.",
      "offset": 1572.24,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "Um there's some parts of the code where",
      "offset": 1575.039,
      "duration": 3.441
    },
    {
      "lang": "en",
      "text": "a certain engineer should be able to",
      "offset": 1577.2,
      "duration": 2.8
    },
    {
      "lang": "en",
      "text": "edit the memory but other engineers",
      "offset": 1578.48,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "shouldn't. Um and so it it actually",
      "offset": 1580,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "starts looking like the new way of um",
      "offset": 1582.24,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "versioning code effectively, right? It's",
      "offset": 1585.36,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "kind of a GitHub++",
      "offset": 1587.36,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "uh because you're not versioning the",
      "offset": 1590,
      "duration": 2.88
    },
    {
      "lang": "en",
      "text": "code, you're kind of versioning the meta",
      "offset": 1591.2,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "knowledge around it that helps language",
      "offset": 1592.88,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "models understand it better. Uh but",
      "offset": 1594.64,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "definitely that is something that we",
      "offset": 1597.2,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "built but I think it's a a thing to",
      "offset": 1598.799,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "iterate a lot until you kind of get the",
      "offset": 1600.72,
      "duration": 2.959
    },
    {
      "lang": "en",
      "text": "right design here because you're",
      "offset": 1602.64,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "effectively building kind of yeah a new",
      "offset": 1603.679,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "a new git from scratch. Yeah, it's",
      "offset": 1605.76,
      "duration": 3.279
    },
    {
      "lang": "en",
      "text": "interesting and you're you're trying to",
      "offset": 1607.679,
      "duration": 3.761
    },
    {
      "lang": "en",
      "text": "design some sort of permissions into it",
      "offset": 1609.039,
      "duration": 4.721
    },
    {
      "lang": "en",
      "text": "versus like you know dominant system",
      "offset": 1611.44,
      "duration": 5.839
    },
    {
      "lang": "en",
      "text": "today in actual version control is like",
      "offset": 1613.76,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "you know at best pull request review",
      "offset": 1617.279,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "right like you just",
      "offset": 1619.36,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": ">> you try and like somebody in the",
      "offset": 1620.799,
      "duration": 5.601
    },
    {
      "lang": "en",
      "text": "organization um with the ability to",
      "offset": 1623.76,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "review makes a determination as to",
      "offset": 1626.4,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "whether or not Misha should be able to",
      "offset": 1628.4,
      "duration": 2.96
    },
    {
      "lang": "en",
      "text": "make this change or not actually based",
      "offset": 1629.6,
      "duration": 2.72
    },
    {
      "lang": "en",
      "text": "on the content",
      "offset": 1631.36,
      "duration": 3.439
    },
    {
      "lang": "en",
      "text": ">> and I think actually it's going to look",
      "offset": 1632.32,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "not too dissimilar from that right where",
      "offset": 1634.799,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "if you want to change the agents the the",
      "offset": 1636.88,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "teamwide memory then it probably is",
      "offset": 1638.96,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "going to look something like a pull",
      "offset": 1641.52,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "request where the person who really",
      "offset": 1643.2,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "understands that system uh approves or",
      "offset": 1644.96,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "you know edits it or something like",
      "offset": 1648.4,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "this. I don't think it's going to look",
      "offset": 1650.64,
      "duration": 1.76
    },
    {
      "lang": "en",
      "text": "too dissimilar.",
      "offset": 1651.52,
      "duration": 2.639
    },
    {
      "lang": "en",
      "text": ">> That's quite different from like",
      "offset": 1652.4,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "traditional role-based like group",
      "offset": 1654.159,
      "duration": 5.281
    },
    {
      "lang": "en",
      "text": "hierarchical access control that is",
      "offset": 1657.12,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "quite static, right? And it makes sense",
      "offset": 1659.44,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "to me that it would look perhaps a",
      "offset": 1661.12,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "little bit more gitlike in that the you",
      "offset": 1663.12,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "know the person who knows what part of",
      "offset": 1666.24,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "the codebase you are editing or creating",
      "offset": 1668.48,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "creating or editing knowledge about is",
      "offset": 1672,
      "duration": 3.039
    },
    {
      "lang": "en",
      "text": "going to evolve over time as the",
      "offset": 1673.84,
      "duration": 2.88
    },
    {
      "lang": "en",
      "text": "codebase evolves over time and the team",
      "offset": 1675.039,
      "duration": 2.64
    },
    {
      "lang": "en",
      "text": "does as well.",
      "offset": 1676.72,
      "duration": 2.88
    },
    {
      "lang": "en",
      "text": ">> Yeah, exactly. But I think this is also",
      "offset": 1677.679,
      "duration": 5.041
    },
    {
      "lang": "en",
      "text": "how um it was very common um at you know",
      "offset": 1679.6,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "at Google and I think other places as",
      "offset": 1682.72,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "well for different parts of the codebase",
      "offset": 1684.48,
      "duration": 3.439
    },
    {
      "lang": "en",
      "text": "to have owners and so there are like",
      "offset": 1686.48,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "these ownership files um that we have as",
      "offset": 1687.919,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "well and basically if you're on the",
      "offset": 1690.08,
      "duration": 4.719
    },
    {
      "lang": "en",
      "text": "ownership file then the review has to go",
      "offset": 1692.159,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "through you or through it has to be",
      "offset": 1694.799,
      "duration": 3.201
    },
    {
      "lang": "en",
      "text": "approved by at least one of the members",
      "offset": 1696.48,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "of the ownership file and as people move",
      "offset": 1698,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "around teams and so forth um the",
      "offset": 1700.559,
      "duration": 3.441
    },
    {
      "lang": "en",
      "text": "ownership files themselves get updated.",
      "offset": 1702.24,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "So I think a pretty similar structure is",
      "offset": 1704,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "probably going to hold here, but it's a",
      "offset": 1706.32,
      "duration": 4.719
    },
    {
      "lang": "en",
      "text": "lot more nuanced than building kind of",
      "offset": 1708.32,
      "duration": 4.959
    },
    {
      "lang": "en",
      "text": "an individual memory which is just kind",
      "offset": 1711.039,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "of personal to you and lives on your",
      "offset": 1713.279,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "computer in your you know agents MD file",
      "offset": 1715.12,
      "duration": 2.88
    },
    {
      "lang": "en",
      "text": "or something.",
      "offset": 1717.44,
      "duration": 2.64
    },
    {
      "lang": "en",
      "text": ">> Uh okay, if we zoom out and place like",
      "offset": 1718,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "reflection overall in context a little",
      "offset": 1720.08,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "bit and talk about the larger",
      "offset": 1722.24,
      "duration": 1.6
    },
    {
      "lang": "en",
      "text": "environment.",
      "offset": 1723.2,
      "duration": 1.52
    },
    {
      "lang": "en",
      "text": ">> Sounds good. Yeah,",
      "offset": 1723.84,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": ">> you know, coding as a as a root problem",
      "offset": 1724.72,
      "duration": 7.12
    },
    {
      "lang": "en",
      "text": "in this era of AI research um is",
      "offset": 1727.76,
      "duration": 7.68
    },
    {
      "lang": "en",
      "text": "somewhat commonly held belief, right? Um",
      "offset": 1731.84,
      "duration": 7.6
    },
    {
      "lang": "en",
      "text": "I I think a criticism of companies that",
      "offset": 1735.44,
      "duration": 6.8
    },
    {
      "lang": "en",
      "text": "went after pre-training focused on",
      "offset": 1739.44,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "coding was in reality like you actually",
      "offset": 1742.24,
      "duration": 4.559
    },
    {
      "lang": "en",
      "text": "you needed language you needed a lot of",
      "offset": 1744.88,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "the capabilities who can say exactly",
      "offset": 1746.799,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "which but the the the reasoning",
      "offset": 1749.039,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "capabilities that could be elicited from",
      "offset": 1750.72,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "large pre-trained models to do code",
      "offset": 1752.72,
      "duration": 3.679
    },
    {
      "lang": "en",
      "text": "anyway and so you had to do all of the",
      "offset": 1754.88,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "work without the general use. Is it",
      "offset": 1756.399,
      "duration": 4.481
    },
    {
      "lang": "en",
      "text": "specifically the availability of",
      "offset": 1758.96,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "pre-trained models um that are more",
      "offset": 1760.88,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "capable and open- source that made you",
      "offset": 1763.84,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "feel like we can go after um super",
      "offset": 1765.52,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "intelligent like autonomous systems in",
      "offset": 1768.72,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "coding without spending the pre-training",
      "offset": 1771.2,
      "duration": 4.959
    },
    {
      "lang": "en",
      "text": "dollars up front as a as a new lab or",
      "offset": 1774.32,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "help me think about that logic a little",
      "offset": 1776.159,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "bit more. I think that that's roughly",
      "offset": 1777.6,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "correct for kind of, you know, these",
      "offset": 1780.08,
      "duration": 5.599
    },
    {
      "lang": "en",
      "text": "sort of why you can get into the game",
      "offset": 1782,
      "duration": 7.679
    },
    {
      "lang": "en",
      "text": "sort of short term. Um, a bet that we",
      "offset": 1785.679,
      "duration": 5.681
    },
    {
      "lang": "en",
      "text": "made, you know, when we were starting a",
      "offset": 1789.679,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "company a year and a half ago was that",
      "offset": 1791.36,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "there were pretty decent openweight",
      "offset": 1793.76,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "models out there that pre-training, you",
      "offset": 1795.279,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "know, we kind of saw pre-training as",
      "offset": 1797.52,
      "duration": 3.759
    },
    {
      "lang": "en",
      "text": "starting to more or less converge on",
      "offset": 1799.44,
      "duration": 3.599
    },
    {
      "lang": "en",
      "text": "kind of a known paradigm. There's sort",
      "offset": 1801.279,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "of a there's a known big data set on the",
      "offset": 1803.039,
      "duration": 3.441
    },
    {
      "lang": "en",
      "text": "internet. Yes, there are going to be",
      "offset": 1805.44,
      "duration": 3.119
    },
    {
      "lang": "en",
      "text": "some algorithmic innovations, but you're",
      "offset": 1806.48,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "basically extracting signal from an",
      "offset": 1808.559,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "extremely noisy data set. And we felt",
      "offset": 1810.72,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "like there's only so much signal that",
      "offset": 1812.96,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "one would be able to extract without",
      "offset": 1816.24,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "getting into just absurd dollars for",
      "offset": 1818.24,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "scaling this in terms of what you're",
      "offset": 1820.559,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "trying to get out of it. So, what we",
      "offset": 1822.159,
      "duration": 4.801
    },
    {
      "lang": "en",
      "text": "thought would happen is that there'd be",
      "offset": 1824.24,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "decent openweight models. Um, I think",
      "offset": 1826.96,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "the quality of the openweight frontier",
      "offset": 1830,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "has um surprised me. um they're actually",
      "offset": 1832.24,
      "duration": 5.039
    },
    {
      "lang": "en",
      "text": "the models are better than I thought",
      "offset": 1835.6,
      "duration": 4.959
    },
    {
      "lang": "en",
      "text": "they would be and we thought that you",
      "offset": 1837.279,
      "duration": 6.321
    },
    {
      "lang": "en",
      "text": "can just focus on you know we're in this",
      "offset": 1840.559,
      "duration": 6.561
    },
    {
      "lang": "en",
      "text": "brief period in history right now where",
      "offset": 1843.6,
      "duration": 6.959
    },
    {
      "lang": "en",
      "text": "um the RL flops are still manageable",
      "offset": 1847.12,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "like you can you can you can really have",
      "offset": 1850.559,
      "duration": 4.641
    },
    {
      "lang": "en",
      "text": "a best-in-class um product if you're",
      "offset": 1852.24,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "focused and yes you'll need to put you",
      "offset": 1855.2,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "know you still need a decent amount of",
      "offset": 1857.76,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "GPUs but from a but from a flops",
      "offset": 1859.12,
      "duration": 4.559
    },
    {
      "lang": "en",
      "text": "perspective it's nowhere near where",
      "offset": 1861.919,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "pre-training like two magnitudes off.",
      "offset": 1863.679,
      "duration": 6.161
    },
    {
      "lang": "en",
      "text": ">> Exactly. Right. So you can get into it",
      "offset": 1866.399,
      "duration": 6.561
    },
    {
      "lang": "en",
      "text": "and kind of build out a both kind of the",
      "offset": 1869.84,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "product and a research arm. Our thought",
      "offset": 1872.96,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "was that this was the time where you can",
      "offset": 1875.36,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "actually start a um you know a",
      "offset": 1877.84,
      "duration": 6.16
    },
    {
      "lang": "en",
      "text": "generational frontier lab that does not",
      "offset": 1880.88,
      "duration": 6.88
    },
    {
      "lang": "en",
      "text": "need to be coupled to a you know to a a",
      "offset": 1884,
      "duration": 7.44
    },
    {
      "lang": "en",
      "text": "big cloud provider. uh because if you do",
      "offset": 1887.76,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "it right, you'll actually be able to",
      "offset": 1891.44,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "generate um you know, sufficient",
      "offset": 1893.12,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "revenues to not have to be acquired or",
      "offset": 1894.96,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "find, you know, some strange deal where",
      "offset": 1897.6,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "um the cloud provider kind of owns you.",
      "offset": 1899.84,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "And that was kind of the model, I think,",
      "offset": 1901.919,
      "duration": 3.201
    },
    {
      "lang": "en",
      "text": "of a lot of what Frontier Labs look like",
      "offset": 1903.12,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "preLLMs. Um I think we're already",
      "offset": 1905.12,
      "duration": 3.439
    },
    {
      "lang": "en",
      "text": "starting to see that, you know, this",
      "offset": 1907.519,
      "duration": 2.321
    },
    {
      "lang": "en",
      "text": "kind of more of a fieldwide thing",
      "offset": 1908.559,
      "duration": 2.881
    },
    {
      "lang": "en",
      "text": "independently of Reflection, right? you",
      "offset": 1909.84,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "look at how fast like Anthropics revenue",
      "offset": 1911.44,
      "duration": 4.479
    },
    {
      "lang": "en",
      "text": "is growing. Um I think right they're",
      "offset": 1913.679,
      "duration": 4.561
    },
    {
      "lang": "en",
      "text": "kind of in the spot where um it's like a",
      "offset": 1915.919,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "massive revenue generating business",
      "offset": 1918.24,
      "duration": 3.679
    },
    {
      "lang": "en",
      "text": "that's growing at an unprecedented rate.",
      "offset": 1920,
      "duration": 3.679
    },
    {
      "lang": "en",
      "text": "That is but but that was very much the",
      "offset": 1921.919,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "ethos that uh we can come in, we don't",
      "offset": 1923.679,
      "duration": 5.281
    },
    {
      "lang": "en",
      "text": "need to pre-train um you can get by with",
      "offset": 1925.679,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "um you know two orders of magnitude less",
      "offset": 1928.96,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "compute um and really get something",
      "offset": 1931.279,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "something out there that's really good.",
      "offset": 1934,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "Um I think that roughly speaking, you",
      "offset": 1935.919,
      "duration": 5.041
    },
    {
      "lang": "en",
      "text": "know, you won't need the amount of",
      "offset": 1939.44,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "compute that I think a frontier lab",
      "offset": 1940.96,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "needs uh today um as you're focused, but",
      "offset": 1942.64,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "you'll still need kind of um you know,",
      "offset": 1946,
      "duration": 4.799
    },
    {
      "lang": "en",
      "text": "an order of magnitude less. So uh I",
      "offset": 1947.84,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "think that the capitalization",
      "offset": 1950.799,
      "duration": 2.961
    },
    {
      "lang": "en",
      "text": "requirements are still high. There's no",
      "offset": 1952.24,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "way of avoiding that. Um, but I'd say",
      "offset": 1953.76,
      "duration": 5.279
    },
    {
      "lang": "en",
      "text": "they're uh and asmtoically they're",
      "offset": 1956.96,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "probably the same, but asmtoically",
      "offset": 1959.039,
      "duration": 4.961
    },
    {
      "lang": "en",
      "text": "the idea is that at that point you just",
      "offset": 1962.24,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "have a gener generational business that",
      "offset": 1964,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "can that can raise capital off of that.",
      "offset": 1965.84,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": ">> I guess part of my read at this point in",
      "offset": 1968.159,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "time is and maybe it was always true but",
      "offset": 1970.08,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "especially now is your actual",
      "offset": 1972.08,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "capabilities in terms of understanding",
      "offset": 1974.08,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "what eval to go after, how to design",
      "offset": 1976.32,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "reward models. there's perhaps like less",
      "offset": 1978.48,
      "duration": 6.319
    },
    {
      "lang": "en",
      "text": "understanding and more dispersion in the",
      "offset": 1981.6,
      "duration": 7.199
    },
    {
      "lang": "en",
      "text": "field in uh post-training strategies",
      "offset": 1984.799,
      "duration": 6.321
    },
    {
      "lang": "en",
      "text": "versus like as you said more maturity in",
      "offset": 1988.799,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "pre-training right now because you can",
      "offset": 1991.12,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "if it was a simple question of scaling",
      "offset": 1992.799,
      "duration": 5.041
    },
    {
      "lang": "en",
      "text": "RL and language models people would be",
      "offset": 1995.76,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "doing it more aggressively right now",
      "offset": 1997.84,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "right um and so actually maybe that's a",
      "offset": 1999.919,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "a good question for you like how would",
      "offset": 2002.32,
      "duration": 3.599
    },
    {
      "lang": "en",
      "text": "you describe the challenges in sol",
      "offset": 2004.08,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "solving scaling here like why why are we",
      "offset": 2005.919,
      "duration": 6.081
    },
    {
      "lang": "en",
      "text": "only able as a field to put like a much",
      "offset": 2008.88,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "smaller amount of compute to work here",
      "offset": 2012,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "and still get like best in best-in-class",
      "offset": 2014.08,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "results versus pre-training skilled",
      "offset": 2016.72,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "GPUs. Right now",
      "offset": 2018.64,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": ">> I'd say that there are two categories or",
      "offset": 2019.76,
      "duration": 5.84
    },
    {
      "lang": "en",
      "text": "one would think that um things fall into",
      "offset": 2022.88,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "um one is more around the problem",
      "offset": 2025.6,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "limitations of the problem structure and",
      "offset": 2028.64,
      "duration": 3.279
    },
    {
      "lang": "en",
      "text": "the other one is well maybe the",
      "offset": 2030.24,
      "duration": 3.439
    },
    {
      "lang": "en",
      "text": "structure is fine but you need um",
      "offset": 2031.919,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "algorithmic advances to really drive the",
      "offset": 2033.679,
      "duration": 4.641
    },
    {
      "lang": "en",
      "text": "next frontier forward. There's, you",
      "offset": 2036.24,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "know, I'd say it's some mixture of both,",
      "offset": 2038.32,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "but the the biggest way I put is on the",
      "offset": 2040.159,
      "duration": 5.441
    },
    {
      "lang": "en",
      "text": "problem structure. So, if you the thing",
      "offset": 2042.72,
      "duration": 5.359
    },
    {
      "lang": "en",
      "text": "that I led for Gemini was reward models.",
      "offset": 2045.6,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "I built out um the reward models that",
      "offset": 2048.079,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "were used to um post- train Gemini 1",
      "offset": 2050,
      "duration": 6.399
    },
    {
      "lang": "en",
      "text": "1.5. And I thought is that if you have a",
      "offset": 2053.119,
      "duration": 5.841
    },
    {
      "lang": "en",
      "text": "reward that accurately uh basically",
      "offset": 2056.399,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "describes the outcome of any arbitrary",
      "offset": 2058.96,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "task that you throw at it, then that's",
      "offset": 2061.919,
      "duration": 4.561
    },
    {
      "lang": "en",
      "text": "that's it. you know at that point it's",
      "offset": 2064.72,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "just algorithmic advances but even the",
      "offset": 2066.48,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "like very simple RL methods we have",
      "offset": 2069.119,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "today um will be able to get a lot out",
      "offset": 2070.8,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "of this like they'll only be bound by",
      "offset": 2073.359,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "their exploration abilities that's the",
      "offset": 2075.44,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "only thing right but if today um you",
      "offset": 2077.52,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "know we certainly are not in this world",
      "offset": 2081.2,
      "duration": 2.959
    },
    {
      "lang": "en",
      "text": "where we have clean rewards for every",
      "offset": 2082.48,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "task we could imagine and so we're kind",
      "offset": 2084.159,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "of making as a field have to make sort",
      "offset": 2086.32,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "of various shortcuts and compromises to",
      "offset": 2089.359,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "that so you'll have things like LLM is",
      "offset": 2091.2,
      "duration": 6.24
    },
    {
      "lang": "en",
      "text": "judge with um different rubrics and that",
      "offset": 2094.399,
      "duration": 5.361
    },
    {
      "lang": "en",
      "text": "works to some extent but um it",
      "offset": 2097.44,
      "duration": 4.639
    },
    {
      "lang": "en",
      "text": "inevitably a noisy or like stocastic",
      "offset": 2099.76,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "reward inevitably gets hacked. So you",
      "offset": 2102.079,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "kind of need a lot of these and um you",
      "offset": 2104.48,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "know and there's only so much you can",
      "offset": 2106.4,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "extract out of them. Uh then you have",
      "offset": 2108,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "sources that do have ground truth",
      "offset": 2110.64,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "rewards but um there are not many of",
      "offset": 2112.4,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "them and so you have to hope that by",
      "offset": 2114.72,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "optimizing against those you'll get some",
      "offset": 2116.24,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "generalization effects and so I think",
      "offset": 2118.4,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "that the fundamental problem is like the",
      "offset": 2120.32,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "reward problem. You can either go in and",
      "offset": 2123.28,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "say, \"I'm just gonna all I'm going to",
      "offset": 2125.52,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "focus on is kind of rewards.\" Um or you",
      "offset": 2127.359,
      "duration": 5.921
    },
    {
      "lang": "en",
      "text": "can say, \"I'm going to take things as",
      "offset": 2130.4,
      "duration": 6.8
    },
    {
      "lang": "en",
      "text": "they are and just be more um creative in",
      "offset": 2133.28,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "the methods that leverage the rewards",
      "offset": 2137.2,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "that have them today.\" And and so",
      "offset": 2138.96,
      "duration": 2.879
    },
    {
      "lang": "en",
      "text": "examples of that are basically every",
      "offset": 2140.24,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "synthetic generation pipeline is some",
      "offset": 2141.839,
      "duration": 6.321
    },
    {
      "lang": "en",
      "text": "example of this. Um so it's it's a messy",
      "offset": 2144.16,
      "duration": 5.439
    },
    {
      "lang": "en",
      "text": "problem, but I think it's fundamentally",
      "offset": 2148.16,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "a like we're in a rewardbound world. I",
      "offset": 2149.599,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "don't think there's going to be any",
      "offset": 2152.4,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "breakthrough that all of a sudden you",
      "offset": 2153.68,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "know we go from we didn't have rewards",
      "offset": 2155.76,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "for everything to we do because the",
      "offset": 2158.24,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "reward problem in itself is at the time",
      "offset": 2160.8,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "I called I thought it was AGI complete",
      "offset": 2163.04,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "now I'd say it's ASI complete but by the",
      "offset": 2164.64,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "time you have a neural network that can",
      "offset": 2166.72,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "accurately verify any outcome that is",
      "offset": 2168.64,
      "duration": 4.959
    },
    {
      "lang": "en",
      "text": "probably a super intelligence and so",
      "offset": 2171.68,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "then it goes back to again evaluations",
      "offset": 2173.599,
      "duration": 5.201
    },
    {
      "lang": "en",
      "text": "what if you're training your rewards",
      "offset": 2176.72,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "your reward models on something like",
      "offset": 2178.8,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "what are you evaluating against what are",
      "offset": 2180.32,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "the tasks that um you want it to be good",
      "offset": 2182.16,
      "duration": 6.16
    },
    {
      "lang": "en",
      "text": "at. So that's kind of um how I think",
      "offset": 2184.4,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "about it. I think it's a fundamentally",
      "offset": 2188.32,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "reward model uh or rewards bound field.",
      "offset": 2189.52,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "Um and then there's also kind of",
      "offset": 2192.56,
      "duration": 5.039
    },
    {
      "lang": "en",
      "text": "algorithmic progress in terms of uh the",
      "offset": 2194.56,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "RL methods we have today are quite bad I",
      "offset": 2197.599,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "would say at um exploration and credit",
      "offset": 2200,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "assignment like they they're sort of",
      "offset": 2201.68,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "just like uh the fundamental algorithms",
      "offset": 2204,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "are take the things that work and make",
      "offset": 2206.4,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "them happen more frequently and the",
      "offset": 2208.4,
      "duration": 2.64
    },
    {
      "lang": "en",
      "text": "things that don't work and h and make",
      "offset": 2209.76,
      "duration": 3.599
    },
    {
      "lang": "en",
      "text": "them happen less frequently but they",
      "offset": 2211.04,
      "duration": 4.559
    },
    {
      "lang": "en",
      "text": "don't discern at all along your say",
      "offset": 2213.359,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "reasoning chain which part of the",
      "offset": 2215.599,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "reasoning uh was correct and which part",
      "offset": 2217.2,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "was incorrect. And so that's why you get",
      "offset": 2219.359,
      "duration": 3.441
    },
    {
      "lang": "en",
      "text": "these reasoning chains that are kind of",
      "offset": 2221.04,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "garden path meandering. Like they'll",
      "offset": 2222.8,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "explore all sorts of things that are,",
      "offset": 2224.56,
      "duration": 3.519
    },
    {
      "lang": "en",
      "text": "you know, completely unnecessary and",
      "offset": 2226.4,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "don't look at all like the kind of",
      "offset": 2228.079,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "structured thinking that a person would",
      "offset": 2229.76,
      "duration": 2.96
    },
    {
      "lang": "en",
      "text": "have. That's how the algorithm works. It",
      "offset": 2231.119,
      "duration": 3.361
    },
    {
      "lang": "en",
      "text": "doesn't uh it doesn't actually look at",
      "offset": 2232.72,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "there's no credit assignment step on any",
      "offset": 2234.48,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "atomic level. Uh and so that I would say",
      "offset": 2236.4,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "falls into more algorithmic progress",
      "offset": 2238.96,
      "duration": 2.399
    },
    {
      "lang": "en",
      "text": "bottlenecks.",
      "offset": 2240.48,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": ">> Can I ask you for a few uh like hot",
      "offset": 2241.359,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "takes quickly?",
      "offset": 2244.16,
      "duration": 2.32
    },
    {
      "lang": "en",
      "text": ">> Yeah, let's go for it. What do you think",
      "offset": 2245.04,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "of all of these efforts either in-house",
      "offset": 2246.48,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "with, you know, labs and vendors or",
      "offset": 2249.04,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "young companies just creating software",
      "offset": 2251.92,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "environments that look like popular",
      "offset": 2254.56,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "software to train agents in, right?",
      "offset": 2256.64,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "Copies of Airbnb or Amazon or Salesforce",
      "offset": 2258.8,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "or Excel.",
      "offset": 2261.44,
      "duration": 2.399
    },
    {
      "lang": "en",
      "text": ">> Personally, I maybe the take is not very",
      "offset": 2262.16,
      "duration": 3.439
    },
    {
      "lang": "en",
      "text": "hot. I'm very like bullish on it because",
      "offset": 2263.839,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "how else are you going to maybe the hot",
      "offset": 2265.599,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "take is that there's no such thing as",
      "offset": 2267.52,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "generalization. There's just bring the",
      "offset": 2269.359,
      "duration": 3.201
    },
    {
      "lang": "en",
      "text": "test distribution into train.",
      "offset": 2270.88,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": ">> Okay, that is an aggressive take. Wow.",
      "offset": 2272.56,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "Yeah.",
      "offset": 2274.72,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "So as long as like your yeah train",
      "offset": 2275.68,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "distribution looks something like what",
      "offset": 2278,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "you would actually want to evaluate for",
      "offset": 2279.839,
      "duration": 5.841
    },
    {
      "lang": "en",
      "text": "um then you know users will experience",
      "offset": 2281.92,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "experience it as generalization. I think",
      "offset": 2285.68,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "you know I I think there is some",
      "offset": 2287.68,
      "duration": 2.56
    },
    {
      "lang": "en",
      "text": "generalization that happens in these",
      "offset": 2288.96,
      "duration": 4.879
    },
    {
      "lang": "en",
      "text": "models but um we probably as as users",
      "offset": 2290.24,
      "duration": 5.359
    },
    {
      "lang": "en",
      "text": "overestimate it because we don't",
      "offset": 2293.839,
      "duration": 4.801
    },
    {
      "lang": "en",
      "text": "actually see how they were made but then",
      "offset": 2295.599,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "you know yeah if you saw oh this",
      "offset": 2298.64,
      "duration": 2.719
    },
    {
      "lang": "en",
      "text": "synthetic environment was actually very",
      "offset": 2300,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "similar to the thing I was asking about.",
      "offset": 2301.359,
      "duration": 3.281
    },
    {
      "lang": "en",
      "text": "So it makes sense why the model would be",
      "offset": 2303.04,
      "duration": 2.799
    },
    {
      "lang": "en",
      "text": "would be good at that.",
      "offset": 2304.64,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": ">> Maybe",
      "offset": 2305.839,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "six months ago, I think you you you said",
      "offset": 2307.76,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "like I think it's possible we have my",
      "offset": 2310.24,
      "duration": 4.879
    },
    {
      "lang": "en",
      "text": "definition of ASI in a couple years. Um",
      "offset": 2312.72,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "do you still believe that's true?",
      "offset": 2315.119,
      "duration": 3.521
    },
    {
      "lang": "en",
      "text": ">> I I still do believe that's true. Um I",
      "offset": 2316.4,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "think that where I think we'll be in a",
      "offset": 2318.64,
      "duration": 2.88
    },
    {
      "lang": "en",
      "text": "couple years from now is that there will",
      "offset": 2320.24,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "be kind of definitive um super",
      "offset": 2321.52,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "intelligence in",
      "offset": 2324.079,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "some meaningful categories of work. And",
      "offset": 2326.56,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "so for example when I say coding I don't",
      "offset": 2328.48,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "mean all of coding there but there will",
      "offset": 2330.32,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "be a super intelligence within some kind",
      "offset": 2332.32,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "of slivers some meaningful slivers of",
      "offset": 2335.28,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "coding that are driving um I would say",
      "offset": 2337.28,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "immense progress in the companies that",
      "offset": 2340.32,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "can benefit from that and",
      "offset": 2342.48,
      "duration": 4.639
    },
    {
      "lang": "en",
      "text": ">> the reason why I would say that the",
      "offset": 2344.88,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "problem of ASI would have been solved by",
      "offset": 2347.119,
      "duration": 4.801
    },
    {
      "lang": "en",
      "text": "then is because you've kind of um at",
      "offset": 2349.04,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "that point it's just a matter of",
      "offset": 2351.92,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "operationalizing like what you know you",
      "offset": 2353.119,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "know it just so happened that these",
      "offset": 2355.2,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "particular cate categories like you",
      "offset": 2357.119,
      "duration": 2.881
    },
    {
      "lang": "en",
      "text": "might have a super intelligent front-end",
      "offset": 2358.48,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "developer because there's so much data",
      "offset": 2360,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "distribution for that on the internet",
      "offset": 2362.24,
      "duration": 3.359
    },
    {
      "lang": "en",
      "text": "and it's easier to make synthetic data",
      "offset": 2363.92,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "for that. But at that point, you have",
      "offset": 2365.599,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "the recipe and it's just a matter of um",
      "offset": 2367.28,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "making kind of economic decisions of is",
      "offset": 2370,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "it worth sinking in x amount of dollars",
      "offset": 2372.56,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "to get the data in this category um to",
      "offset": 2374.88,
      "duration": 5.199
    },
    {
      "lang": "en",
      "text": "get kind of something um close to super",
      "offset": 2377.68,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "intelligence there. Um an example of",
      "offset": 2380.079,
      "duration": 5.361
    },
    {
      "lang": "en",
      "text": "that is what happened with reinforcement",
      "offset": 2382.24,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "learning before language models. um",
      "offset": 2385.44,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "effectively the blueprint for building",
      "offset": 2387.28,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "super intelligent systems was developed.",
      "offset": 2390.32,
      "duration": 4.799
    },
    {
      "lang": "en",
      "text": "It happened with um the Atari games,",
      "offset": 2392.32,
      "duration": 6.16
    },
    {
      "lang": "en",
      "text": "Alph Go um you know then Dota 5 and",
      "offset": 2395.119,
      "duration": 6.48
    },
    {
      "lang": "en",
      "text": "Alphaar were near super intelligent",
      "offset": 2398.48,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "systems and if OpenAI and DeFi had sunk",
      "offset": 2401.599,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "more compute into them they would have",
      "offset": 2404.24,
      "duration": 2.8
    },
    {
      "lang": "en",
      "text": "definitely become super intelligent.",
      "offset": 2405.44,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "It's just that at that point it didn't",
      "offset": 2407.04,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "really make s it economically like why",
      "offset": 2408.48,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "would you do that? Then this is a",
      "offset": 2410.88,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "definitional issue because I I was going",
      "offset": 2412.4,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "to ask like help me understand your view",
      "offset": 2414.24,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "of like I don't like one of the big",
      "offset": 2416.56,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "criticisms of RL overall has been lack",
      "offset": 2418.48,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "of generalization. Um that's been just",
      "offset": 2420.8,
      "duration": 4.559
    },
    {
      "lang": "en",
      "text": "kind of a general question for this",
      "offset": 2422.96,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "direction. I do have friends at every",
      "offset": 2425.359,
      "duration": 5.361
    },
    {
      "lang": "en",
      "text": "large research lab that somewhat you",
      "offset": 2428.32,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "know some I mean tell me if you hear uh",
      "offset": 2430.72,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "something of a different tenor or just",
      "offset": 2432.64,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "believe differently.",
      "offset": 2434,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "They believe we're going to have systems",
      "offset": 2436,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "that are much more capable than humans",
      "offset": 2438.72,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "and many types of knowledge work, but",
      "offset": 2440.48,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "they believe less in generalization. And",
      "offset": 2442.64,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "so in a resigned way, they're also, as",
      "offset": 2444.64,
      "duration": 2.8
    },
    {
      "lang": "en",
      "text": "you're saying, like I guess we're just",
      "offset": 2446.32,
      "duration": 2.24
    },
    {
      "lang": "en",
      "text": "going to bring all of it under",
      "offset": 2447.44,
      "duration": 3.679
    },
    {
      "lang": "en",
      "text": "distribution one way or another.",
      "offset": 2448.56,
      "duration": 4.559
    },
    {
      "lang": "en",
      "text": ">> But that means like, you know, it's a",
      "offset": 2451.119,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "little bit different than my my view of",
      "offset": 2453.119,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "like it's",
      "offset": 2454.96,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": ">> um at at some point you're you're just",
      "offset": 2456.319,
      "duration": 4.561
    },
    {
      "lang": "en",
      "text": "you know, you have enough capability",
      "offset": 2459.2,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "that the rest you get for free, right?",
      "offset": 2460.88,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "the rest sort of useful capability you",
      "offset": 2463.119,
      "duration": 3.761
    },
    {
      "lang": "en",
      "text": "get for free.",
      "offset": 2466,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": ">> I think I kind of have a similar",
      "offset": 2466.88,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "viewpoint to to the people you describe.",
      "offset": 2469.76,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "Um",
      "offset": 2472.48,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "I think the generalization capabilities",
      "offset": 2474.079,
      "duration": 4.881
    },
    {
      "lang": "en",
      "text": "of these things has been weaker. First",
      "offset": 2476.319,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "of all, it's all mind-blowing that this",
      "offset": 2478.96,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "exists. So um we went from fundamental",
      "offset": 2480.319,
      "duration": 4.721
    },
    {
      "lang": "en",
      "text": "existential crises and generalization",
      "offset": 2483.28,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "like this was the field of reinforcement",
      "offset": 2485.04,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "learning before language models was we",
      "offset": 2486.56,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "have these systems and we can make",
      "offset": 2489.2,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "amazing you know at like very narrow",
      "offset": 2490.64,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "tasks. We have absolutely no answer for",
      "offset": 2492.88,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "generalization like zero. Um and we went",
      "offset": 2494.64,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "from that to things that you know feel",
      "offset": 2497.68,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "like they're generalizing. They're",
      "offset": 2500.4,
      "duration": 2.8
    },
    {
      "lang": "en",
      "text": "certainly generalizing much better than",
      "offset": 2501.599,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "um anything we had before. Um but it's",
      "offset": 2503.2,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "likely because the training",
      "offset": 2506.079,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "distributions are so broad. Uh so at",
      "offset": 2507.119,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "least the way I think about it is more",
      "offset": 2510.16,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "um kind of output as a user is the",
      "offset": 2512.319,
      "duration": 4.481
    },
    {
      "lang": "en",
      "text": "system you know super intelligent in",
      "offset": 2515.04,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "some meaningful categories of work and",
      "offset": 2516.8,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "then from a research perspective is it",
      "offset": 2518.72,
      "duration": 5.359
    },
    {
      "lang": "en",
      "text": "obvious how to make it general for",
      "offset": 2521.2,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "anything that you might care about and",
      "offset": 2524.079,
      "duration": 2.721
    },
    {
      "lang": "en",
      "text": "at that point again it's just a matter",
      "offset": 2525.44,
      "duration": 2.639
    },
    {
      "lang": "en",
      "text": "of economics maybe there are some",
      "offset": 2526.8,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "categories where um collecting the data",
      "offset": 2528.079,
      "duration": 4.721
    },
    {
      "lang": "en",
      "text": "is so expensive and the return on",
      "offset": 2531.119,
      "duration": 4.801
    },
    {
      "lang": "en",
      "text": "investment is low where um effectively",
      "offset": 2532.8,
      "duration": 5.279
    },
    {
      "lang": "en",
      "text": "just better to have crafts people than",
      "offset": 2535.92,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "super intellig AIS. Um, so I think we're",
      "offset": 2538.079,
      "duration": 4.481
    },
    {
      "lang": "en",
      "text": "moving into this kind of jag world of",
      "offset": 2540.4,
      "duration": 5.919
    },
    {
      "lang": "en",
      "text": "jagged super intelligence where you have",
      "offset": 2542.56,
      "duration": 5.759
    },
    {
      "lang": "en",
      "text": "a handful of these super intelligences",
      "offset": 2546.319,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "for categories that matter maybe",
      "offset": 2548.319,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "subsumed into one model at some point",
      "offset": 2550.4,
      "duration": 4.719
    },
    {
      "lang": "en",
      "text": "but at first it'll probably be um again",
      "offset": 2552.319,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "I think there will be a few companies",
      "offset": 2555.119,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "that have kind of product model coupling",
      "offset": 2556.48,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "that you know that is super intelligent",
      "offset": 2559.2,
      "duration": 3.119
    },
    {
      "lang": "en",
      "text": "in different categories. I think an",
      "offset": 2560.8,
      "duration": 3.519
    },
    {
      "lang": "en",
      "text": "example of again starting to see the",
      "offset": 2562.319,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "first glimpses of super intelligence but",
      "offset": 2564.319,
      "duration": 3.201
    },
    {
      "lang": "en",
      "text": "in a way that hasn't really transferred",
      "offset": 2565.839,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "to anything",
      "offset": 2567.52,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "meaningful yet is well we have these",
      "offset": 2569.359,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "like uh super intelligent test takers",
      "offset": 2572.96,
      "duration": 4.879
    },
    {
      "lang": "en",
      "text": "now like you know Amy the Amy benchmark",
      "offset": 2575.359,
      "duration": 5.681
    },
    {
      "lang": "en",
      "text": "is completely saturated code forces and",
      "offset": 2577.839,
      "duration": 5.041
    },
    {
      "lang": "en",
      "text": "um other competitive um coding",
      "offset": 2581.04,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "environments the models are almost best",
      "offset": 2582.88,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "in the world and within the year will",
      "offset": 2584.96,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "probably be just the best in the world",
      "offset": 2586.56,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "and yet we have the so we have the test",
      "offset": 2588.64,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "competitive coding agents. Then you go",
      "offset": 2591.92,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "into you know a company and you ask them",
      "offset": 2594.24,
      "duration": 4.879
    },
    {
      "lang": "en",
      "text": "have these things been helpful and they",
      "offset": 2596.96,
      "duration": 2.639
    },
    {
      "lang": "en",
      "text": "say",
      "offset": 2599.119,
      "duration": 1.921
    },
    {
      "lang": "en",
      "text": ">> it's uneven. Yeah.",
      "offset": 2599.599,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": ">> Yeah. Right. they so in the in the parts",
      "offset": 2601.04,
      "duration": 4.559
    },
    {
      "lang": "en",
      "text": "of work that are really meaningful that",
      "offset": 2603.92,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "would you want to see these things",
      "offset": 2605.599,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "driving um meaningful kind of increase",
      "offset": 2607.04,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "in in GDP and I think right the only way",
      "offset": 2609.52,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "you you'll see that is if you go into a",
      "offset": 2612.16,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "company and there's kind of you know a",
      "offset": 2613.92,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "universal understanding that yeah my",
      "offset": 2615.92,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "engineers are double digit percentage",
      "offset": 2618.16,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "points as a whole every single one of",
      "offset": 2620.16,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "them more productive right that's the",
      "offset": 2621.76,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "kind of thing that if you that starts",
      "offset": 2623.68,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "happening across every field then you'll",
      "offset": 2625.52,
      "duration": 5.599
    },
    {
      "lang": "en",
      "text": "see double- digit increases in GDP so I",
      "offset": 2627.52,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "think that the kind of benchmark maxing",
      "offset": 2631.119,
      "duration": 5.281
    },
    {
      "lang": "en",
      "text": "that's um and it's a bit different than",
      "offset": 2633.52,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "benchmark maxing used to be before",
      "offset": 2636.4,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "because you have benchmark maxing that",
      "offset": 2637.92,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "is weekly correlated to customer",
      "offset": 2639.68,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "outcomes but it still looks very similar",
      "offset": 2641.76,
      "duration": 6.24
    },
    {
      "lang": "en",
      "text": "to taking a board game training RL agent",
      "offset": 2644.56,
      "duration": 6.24
    },
    {
      "lang": "en",
      "text": "on it getting kind of a landmark um",
      "offset": 2648,
      "duration": 5.119
    },
    {
      "lang": "en",
      "text": "result in super intelligence and then",
      "offset": 2650.8,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "making a claim that you know super",
      "offset": 2653.119,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "intelligence is solved. I think uh the",
      "offset": 2654.88,
      "duration": 4.719
    },
    {
      "lang": "en",
      "text": "reality is that",
      "offset": 2656.72,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "deployment of it is half the problem",
      "offset": 2659.599,
      "duration": 4.641
    },
    {
      "lang": "en",
      "text": "which which it goes back to kind of",
      "offset": 2662.4,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "evaluating on customer problems and",
      "offset": 2664.24,
      "duration": 2.879
    },
    {
      "lang": "en",
      "text": "building product together with the",
      "offset": 2665.92,
      "duration": 1.76
    },
    {
      "lang": "en",
      "text": "models.",
      "offset": 2667.119,
      "duration": 2.641
    },
    {
      "lang": "en",
      "text": ">> So you must have seen the the news of",
      "offset": 2667.68,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "the um windsurf nonacquisition into",
      "offset": 2669.76,
      "duration": 6.16
    },
    {
      "lang": "en",
      "text": "either open AAI but non-acquisition into",
      "offset": 2672.96,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "uh Google deep mind. What do you make of",
      "offset": 2675.92,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "it? We're seeing this verticalization",
      "offset": 2677.68,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "basically happen across categories that",
      "offset": 2679.92,
      "duration": 6.24
    },
    {
      "lang": "en",
      "text": "um are material to to frontier",
      "offset": 2683.44,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "intelligence and uh one could argue that",
      "offset": 2686.16,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "the first verticalized category was",
      "offset": 2688.72,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "actually search right through chat GPT",
      "offset": 2690.4,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "um that's sort of a place where openi",
      "offset": 2692.72,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "verticalized first and coding has",
      "offset": 2694.24,
      "duration": 5.119
    },
    {
      "lang": "en",
      "text": "obviously emerged as another uh kind of",
      "offset": 2696.96,
      "duration": 5.119
    },
    {
      "lang": "en",
      "text": "frontier level category that right could",
      "offset": 2699.359,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "um like all these companies have",
      "offset": 2702.079,
      "duration": 2.321
    },
    {
      "lang": "en",
      "text": "aspirations of",
      "offset": 2703.28,
      "duration": 1.76
    },
    {
      "lang": "en",
      "text": ">> ASI",
      "offset": 2704.4,
      "duration": 2.48
    },
    {
      "lang": "en",
      "text": ">> yeah ASI and I think you know being",
      "offset": 2705.04,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "basically trillion ion dollar companies",
      "offset": 2706.88,
      "duration": 2.56
    },
    {
      "lang": "en",
      "text": "or more. I don't think that it's really",
      "offset": 2708.24,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "the economics that are the driving",
      "offset": 2709.44,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "factor, but it's more that if you want",
      "offset": 2711.28,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "to sustain frontier research, that's",
      "offset": 2713.2,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "kind of what you have to become. And so",
      "offset": 2714.88,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "coding has clearly become one of these",
      "offset": 2717.28,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "categories where uh verticalization is",
      "offset": 2719.44,
      "duration": 6.32
    },
    {
      "lang": "en",
      "text": "um extremely important. And I think that",
      "offset": 2722.48,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "there's there are kind of two sides of",
      "offset": 2725.76,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "the story. one on the frontier lab side",
      "offset": 2728.24,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "and the other on the kind of more of you",
      "offset": 2729.76,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "know product side like a startup that",
      "offset": 2732.64,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "builds product but does not have its",
      "offset": 2734.079,
      "duration": 4.481
    },
    {
      "lang": "en",
      "text": "intelligence um in house. So I think on",
      "offset": 2735.68,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "the on the frontier lab side I think",
      "offset": 2738.56,
      "duration": 3.759
    },
    {
      "lang": "en",
      "text": "this is exactly kind of what Giannis and",
      "offset": 2740.48,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "I noticed when we were um working in",
      "offset": 2742.319,
      "duration": 5.121
    },
    {
      "lang": "en",
      "text": "Gemini is that your model is so far away",
      "offset": 2744.4,
      "duration": 6.08
    },
    {
      "lang": "en",
      "text": "from the product that oftentimes even",
      "offset": 2747.44,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "even though you have the best model does",
      "offset": 2750.48,
      "duration": 2.639
    },
    {
      "lang": "en",
      "text": "not at all mean that you have the best",
      "offset": 2751.92,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "product. So like there's a reason why uh",
      "offset": 2753.119,
      "duration": 5.121
    },
    {
      "lang": "en",
      "text": "basically startups are the places where",
      "offset": 2755.839,
      "duration": 4.801
    },
    {
      "lang": "en",
      "text": "uh kind of adoption of coding tools took",
      "offset": 2758.24,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "off rather than the frontier labs. And",
      "offset": 2760.64,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "so there's a verticalization happening",
      "offset": 2763.04,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "there. And some are going to do it",
      "offset": 2764.4,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "successfully and some are not. Um I",
      "offset": 2766.24,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "think that that's kind of we're already",
      "offset": 2768.56,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "starting to see that with cloud code",
      "offset": 2770,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "really being an example of a successful",
      "offset": 2772,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "verticalization. Um I don't think it's",
      "offset": 2774.079,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "guaranteed that a big lab can you know",
      "offset": 2777.52,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "buy their way to uh to the end user",
      "offset": 2779.839,
      "duration": 5.441
    },
    {
      "lang": "en",
      "text": "because the fundamental problems of your",
      "offset": 2783.2,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "you know research team being far away",
      "offset": 2785.28,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "from your product team will still be",
      "offset": 2787.359,
      "duration": 4.641
    },
    {
      "lang": "en",
      "text": "true and and the company having you know",
      "offset": 2789.04,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "a hundred different focus areas will",
      "offset": 2792,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "still be true. So I don't think that",
      "offset": 2793.68,
      "duration": 3.679
    },
    {
      "lang": "en",
      "text": "acquiring an asset will change that",
      "offset": 2795.28,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "fundamentally but it does underscore the",
      "offset": 2797.359,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "importance of verticalization. And then",
      "offset": 2799.2,
      "duration": 4.639
    },
    {
      "lang": "en",
      "text": "from the startup side, I think it",
      "offset": 2801.599,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "actually puts companies that are in",
      "offset": 2803.839,
      "duration": 5.681
    },
    {
      "lang": "en",
      "text": "these kind of um critical path",
      "offset": 2807.119,
      "duration": 6.561
    },
    {
      "lang": "en",
      "text": "categories like search and coding um in",
      "offset": 2809.52,
      "duration": 6.079
    },
    {
      "lang": "en",
      "text": "a pretty existential place if they can't",
      "offset": 2813.68,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "build their own frontier models. Not all",
      "offset": 2815.599,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "frontier labs will be able to",
      "offset": 2817.839,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "verticalize correctly, but some will.",
      "offset": 2819.2,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "maybe one will and that's going to be",
      "offset": 2821.359,
      "duration": 5.521
    },
    {
      "lang": "en",
      "text": "enough I think to kind of right take the",
      "offset": 2823.92,
      "duration": 6.56
    },
    {
      "lang": "en",
      "text": "thunder out from a you know from a",
      "offset": 2826.88,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "company that's built um a great user",
      "offset": 2830.48,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "experience on top of someone else's",
      "offset": 2832.4,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "model um and I think some of those",
      "offset": 2834.319,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "dynamics are probably starting to play",
      "offset": 2836.96,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "out as well like I think that uh there",
      "offset": 2838.4,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "are some question marks around if you're",
      "offset": 2840.48,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "on this critical path category um and",
      "offset": 2842.88,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "you don't have your own intelligence um",
      "offset": 2845.28,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "you know how do you compete when your",
      "offset": 2847.92,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "competitor and you know just basically",
      "offset": 2850.24,
      "duration": 5.119
    },
    {
      "lang": "en",
      "text": "subsidize their product a lot more than",
      "offset": 2853.04,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "you can. Um right because you're",
      "offset": 2855.359,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "effectively as a as a startup that's",
      "offset": 2856.88,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "building on top of these things to grow",
      "offset": 2859.04,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "quickly you're subsidizing you know the",
      "offset": 2860.64,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "margin that you know an Anthropic or",
      "offset": 2862.48,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "Gemini or whatever is making um and",
      "offset": 2864.16,
      "duration": 6.24
    },
    {
      "lang": "en",
      "text": "Google and Anthropic and OpenAI can",
      "offset": 2868,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "subsidize their products a lot more than",
      "offset": 2870.4,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "you can. Uh so I think that companies",
      "offset": 2872,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "that are",
      "offset": 2875.2,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "don't own their intelligence or are not",
      "offset": 2876.96,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "kind of deeply integrated into a",
      "offset": 2878.72,
      "duration": 3.359
    },
    {
      "lang": "en",
      "text": "customer in some way that makes them",
      "offset": 2880.8,
      "duration": 3.279
    },
    {
      "lang": "en",
      "text": "hard to remove find themselves in this",
      "offset": 2882.079,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "pretty um existential place as it",
      "offset": 2884.079,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "becomes clear to the frontier labs that",
      "offset": 2886.24,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "this is a category they need to",
      "offset": 2888.16,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "verticalize around. I work with a few",
      "offset": 2889.28,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "robotics companies and so um much of my",
      "offset": 2891.52,
      "duration": 6.319
    },
    {
      "lang": "en",
      "text": "lens on RL comes from that and I think",
      "offset": 2894.96,
      "duration": 6.159
    },
    {
      "lang": "en",
      "text": "it is like far less clear in robotics",
      "offset": 2897.839,
      "duration": 6.48
    },
    {
      "lang": "en",
      "text": "that you know RL will be a dominant part",
      "offset": 2901.119,
      "duration": 6.401
    },
    {
      "lang": "en",
      "text": "of the uh training versus imitation",
      "offset": 2904.319,
      "duration": 4.641
    },
    {
      "lang": "en",
      "text": "learning. You'll actually appreciate",
      "offset": 2907.52,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "this on on imitation from humans using",
      "offset": 2908.96,
      "duration": 6.8
    },
    {
      "lang": "en",
      "text": "tools, right? Um because we run this I",
      "offset": 2911.839,
      "duration": 5.921
    },
    {
      "lang": "en",
      "text": "I'm going to like describe this idea",
      "offset": 2915.76,
      "duration": 4.799
    },
    {
      "lang": "en",
      "text": "that is um nuts, but I I think it's just",
      "offset": 2917.76,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "funny. We run this grant program twice a",
      "offset": 2920.559,
      "duration": 5.201
    },
    {
      "lang": "en",
      "text": "year for amazing people um using ML in",
      "offset": 2923.04,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "different fields. Uh and it's called",
      "offset": 2925.76,
      "duration": 6.079
    },
    {
      "lang": "en",
      "text": "embed. Uh and one of uh one of the ideas",
      "offset": 2928.4,
      "duration": 6.56
    },
    {
      "lang": "en",
      "text": "I had as a joke recently was well like",
      "offset": 2931.839,
      "duration": 5.361
    },
    {
      "lang": "en",
      "text": "you just record everything, right? like",
      "offset": 2934.96,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "not obviously just the code base, but",
      "offset": 2937.2,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "like your Slack and all your",
      "offset": 2939.52,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "documentation and all your conversations",
      "offset": 2941.599,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "because you are a software engineering",
      "offset": 2943.76,
      "duration": 5.359
    },
    {
      "lang": "en",
      "text": "team. And I'm 100% sure that I can take",
      "offset": 2945.28,
      "duration": 6.48
    },
    {
      "lang": "en",
      "text": "that data set if you ship something into",
      "offset": 2949.119,
      "duration": 4.641
    },
    {
      "lang": "en",
      "text": "production to an end customer that has",
      "offset": 2951.76,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "real issues at any scale and sell it to",
      "offset": 2953.76,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "a friend who's a researcher at a lab",
      "offset": 2956.64,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "working on this stuff. Um, and so you",
      "offset": 2958.16,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "have some floor value that is millions",
      "offset": 2960.24,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "of dollars for your, you know, couple",
      "offset": 2962,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "person company and like bonuses like",
      "offset": 2964.24,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "maybe the software company works, right?",
      "offset": 2966.16,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "Obviously, this is like very noisy and",
      "offset": 2968.64,
      "duration": 3.439
    },
    {
      "lang": "en",
      "text": "I'm I'm mostly joking, but I'm I'm",
      "offset": 2970.079,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "curious how you think about uh like",
      "offset": 2972.079,
      "duration": 4.721
    },
    {
      "lang": "en",
      "text": "exploring",
      "offset": 2975.119,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "nonRL",
      "offset": 2976.8,
      "duration": 3.039
    },
    {
      "lang": "en",
      "text": "data sets that could be useful to you",
      "offset": 2978.319,
      "duration": 1.921
    },
    {
      "lang": "en",
      "text": "here.",
      "offset": 2979.839,
      "duration": 2.161
    },
    {
      "lang": "en",
      "text": ">> If that company existed, right, we would",
      "offset": 2980.24,
      "duration": 2.96
    },
    {
      "lang": "en",
      "text": "uh we would definitely pay for their",
      "offset": 2982,
      "duration": 2
    },
    {
      "lang": "en",
      "text": "data.",
      "offset": 2983.2,
      "duration": 2.639
    },
    {
      "lang": "en",
      "text": ">> There we go. See, it's not an idiot",
      "offset": 2984,
      "duration": 3.359
    },
    {
      "lang": "en",
      "text": "idea.",
      "offset": 2985.839,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "Yeah, it's uh yeah, especially if",
      "offset": 2987.359,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "there's diversity. Um I think that'd be",
      "offset": 2989.359,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": ">> I can sell the whole set.",
      "offset": 2991.68,
      "duration": 6.56
    },
    {
      "lang": "en",
      "text": ">> Yeah. So is the question around um",
      "offset": 2993.44,
      "duration": 7.119
    },
    {
      "lang": "en",
      "text": "how do you leverage alternative sources",
      "offset": 2998.24,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "of data?",
      "offset": 3000.559,
      "duration": 3.201
    },
    {
      "lang": "en",
      "text": ">> Yeah. The the question is um I I think",
      "offset": 3001.52,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "there is like uh I I don't want to like",
      "offset": 3003.76,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "overanalogize to robotics, right? But",
      "offset": 3006.64,
      "duration": 5.199
    },
    {
      "lang": "en",
      "text": "within robotics, you have learning from",
      "offset": 3009.76,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "world models, you have learning from",
      "offset": 3011.839,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "sim, you have learning from embodied",
      "offset": 3013.44,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "data that uh of different types, right?",
      "offset": 3016.079,
      "duration": 5.361
    },
    {
      "lang": "en",
      "text": "Um imitation, then you have RL. I I",
      "offset": 3018.88,
      "duration": 5.84
    },
    {
      "lang": "en",
      "text": "think it's like much less clear that you",
      "offset": 3021.44,
      "duration": 6.48
    },
    {
      "lang": "en",
      "text": "can use RL for a lot of robotics today,",
      "offset": 3024.72,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "especially some of the harder like",
      "offset": 3027.92,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "manipulation problems. And I'm curious",
      "offset": 3028.96,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "just given you know your team has this",
      "offset": 3031.04,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "enormous strength in RL's like a",
      "offset": 3032.96,
      "duration": 4.879
    },
    {
      "lang": "en",
      "text": "starting premise how you look at other",
      "offset": 3034.96,
      "duration": 6.159
    },
    {
      "lang": "en",
      "text": "types of data to create the you know uh",
      "offset": 3037.839,
      "duration": 5.921
    },
    {
      "lang": "en",
      "text": "coding agent experiences you want. So I",
      "offset": 3041.119,
      "duration": 5.521
    },
    {
      "lang": "en",
      "text": "was actually um a robotics researcher",
      "offset": 3043.76,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "for like in reinforcement learning that",
      "offset": 3046.64,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "Peter Beiel's lab is a robotics lab and",
      "offset": 3048.24,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "it was you know it was a mixture like",
      "offset": 3051.76,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "Peter's lab was always around in the",
      "offset": 3053.52,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "intelligence problem and robotics as",
      "offset": 3055.599,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "being a domain where you study it and",
      "offset": 3057.2,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "one of the you know the reason I came to",
      "offset": 3059.76,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "lead reward models for Gemini was",
      "offset": 3062,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "because that's the question I was",
      "offset": 3063.76,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "studying with robotics I was you know we",
      "offset": 3066,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "had these RL algorithms for getting",
      "offset": 3068.72,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "robots to do some very narrow tasks like",
      "offset": 3070.96,
      "duration": 5.84
    },
    {
      "lang": "en",
      "text": "moving blocks and um you know various",
      "offset": 3073.76,
      "duration": 6.319
    },
    {
      "lang": "en",
      "text": "kind of narrow tasks in simulation. And",
      "offset": 3076.8,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "the question was well how do we get",
      "offset": 3080.079,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "generalized um yeah manipulators and um",
      "offset": 3082.16,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "you know just how how do we build this",
      "offset": 3085.599,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "all into one system and it seemed like",
      "offset": 3087.44,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "the rewards were bottleneck. So this a",
      "offset": 3089.92,
      "duration": 4.639
    },
    {
      "lang": "en",
      "text": "lot of what I was studying before uh",
      "offset": 3092.4,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "starting you know getting into language",
      "offset": 3094.559,
      "duration": 5.121
    },
    {
      "lang": "en",
      "text": "models was how do we design reward",
      "offset": 3096.24,
      "duration": 6.319
    },
    {
      "lang": "en",
      "text": "functions or models for um for robotics",
      "offset": 3099.68,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "or you know for 3D video games like",
      "offset": 3102.559,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "Minecraft or something like this that",
      "offset": 3104.4,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "have I think similar challenges",
      "offset": 3105.839,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "scientifically the challenge is that if",
      "offset": 3107.92,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "we if you think that language model",
      "offset": 3111.119,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "rewards are hackable uh vision language",
      "offset": 3112.8,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "model rewards or you know like other",
      "offset": 3115.44,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "sensory signal rewards are infinitely",
      "offset": 3117.2,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "more hackable they are much more",
      "offset": 3119.839,
      "duration": 5.201
    },
    {
      "lang": "en",
      "text": "short-lived than um than than rewards.",
      "offset": 3122.16,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "Like you can think of like language as",
      "offset": 3125.04,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "just a compressed representation of the",
      "offset": 3126.64,
      "duration": 4.479
    },
    {
      "lang": "en",
      "text": "world that we have that we are kind of",
      "offset": 3128.8,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "magically have to start with. Um whereas",
      "offset": 3131.119,
      "duration": 5.281
    },
    {
      "lang": "en",
      "text": "if you're processing pixels or sensory",
      "offset": 3133.68,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "motor signal um this is raw signal that",
      "offset": 3136.4,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "has a lot more noise in it. And so if",
      "offset": 3139.68,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "you train a neural network that is sort",
      "offset": 3141.92,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "of trying to detect whether this thing",
      "offset": 3143.68,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "was manipulated correctly or this thing",
      "offset": 3145.92,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "was you know moved correctly then that",
      "offset": 3148,
      "duration": 5.839
    },
    {
      "lang": "en",
      "text": "thing is just infinitely more hackable",
      "offset": 3151.68,
      "duration": 3.439
    },
    {
      "lang": "en",
      "text": "than anything you have in language",
      "offset": 3153.839,
      "duration": 3.361
    },
    {
      "lang": "en",
      "text": "models. So the same problems be blow up",
      "offset": 3155.119,
      "duration": 5.281
    },
    {
      "lang": "en",
      "text": "and become much larger. Uh and so that's",
      "offset": 3157.2,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "actually why I changed to uh language",
      "offset": 3160.4,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "models because I felt that this was a",
      "offset": 3162.96,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "fundamental problem but you know we now",
      "offset": 3165.04,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "have these confounding factors of these",
      "offset": 3166.64,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "noisy signals coming in. I think that in",
      "offset": 3168.16,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "at least in a generalizable way, that's",
      "offset": 3170.4,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "why it's really hard to get um",
      "offset": 3172.079,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "reinforcement learning to work um with",
      "offset": 3173.52,
      "duration": 6.079
    },
    {
      "lang": "en",
      "text": "robotics. Um the one place where it",
      "offset": 3176.559,
      "duration": 4.961
    },
    {
      "lang": "en",
      "text": "really does work well is when you have a",
      "offset": 3179.599,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "clean reward signal, which has happens",
      "offset": 3181.52,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "to be in these like locomotion like",
      "offset": 3183.119,
      "duration": 4.801
    },
    {
      "lang": "en",
      "text": "scenarios. So there's a lot of work on",
      "offset": 3184.72,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": ">> like building very robust sim to real",
      "offset": 3187.92,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "locomotion pipelines and it's because",
      "offset": 3190.24,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "it's kind of um locomotion is just your",
      "offset": 3192.24,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "body like you don't have to manipulate",
      "offset": 3194.88,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "the world around you and so you can",
      "offset": 3196.64,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "actually build reward signals that are",
      "offset": 3198.24,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "like oh you know your quadriped is",
      "offset": 3199.92,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "moving at this velocity without damaging",
      "offset": 3202.48,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "its body kind of thing. Maybe it's a bit",
      "offset": 3204.24,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "of a roundabout answer to the question,",
      "offset": 3205.92,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "but it's that I think these two fields",
      "offset": 3207.68,
      "duration": 4.879
    },
    {
      "lang": "en",
      "text": "are very different in the data",
      "offset": 3210.4,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "distribution they that they support and",
      "offset": 3212.559,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "the kind of imitation learning data for",
      "offset": 3214.64,
      "duration": 2.88
    },
    {
      "lang": "en",
      "text": "language models is of course the",
      "offset": 3216.24,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "internet right it's of course you know",
      "offset": 3217.52,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "we've people who've gathered all this",
      "offset": 3219.44,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "data on you know how we write and so",
      "offset": 3221.839,
      "duration": 4.881
    },
    {
      "lang": "en",
      "text": "forth and so aside from that when we're",
      "offset": 3223.44,
      "duration": 6.8
    },
    {
      "lang": "en",
      "text": "generating synthetic data um",
      "offset": 3226.72,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "there is the only scalable path is",
      "offset": 3230.24,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "really reinforcement learning the other",
      "offset": 3232.72,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "thing that I'll say here is that when",
      "offset": 3234.559,
      "duration": 5.921
    },
    {
      "lang": "en",
      "text": "you're collecting data for robotics um",
      "offset": 3237.04,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "you can do it in like this teaop way",
      "offset": 3240.48,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "like it's sort of um these are things",
      "offset": 3242.4,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "like the things that we try to are",
      "offset": 3244.319,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "trying to train robots to do are very",
      "offset": 3245.92,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "intuitive for humans as well I mean",
      "offset": 3247.359,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "actually more intuitive for humans right",
      "offset": 3249.2,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "people are master manipulators so you",
      "offset": 3250.96,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "can have a lot of kind of teop like um",
      "offset": 3254,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "data collection",
      "offset": 3256.4,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": ">> the things that we want language models",
      "offset": 3258.079,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "to do um are sort of you know at the",
      "offset": 3260.24,
      "duration": 6.319
    },
    {
      "lang": "en",
      "text": "level of um it's really hard to collect",
      "offset": 3264.079,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "data of you know the chain of thought",
      "offset": 3266.559,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "process that goes on in like a human's",
      "offset": 3268.559,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "head um when they're trying to solve",
      "offset": 3270.4,
      "duration": 3.439
    },
    {
      "lang": "en",
      "text": "some task and that's kind of the data",
      "offset": 3272.16,
      "duration": 3.439
    },
    {
      "lang": "en",
      "text": "that you need and so for that reason I",
      "offset": 3273.839,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "think language models favor this more",
      "offset": 3275.599,
      "duration": 4.801
    },
    {
      "lang": "en",
      "text": "like synthetic data RL like approach",
      "offset": 3278.079,
      "duration": 4.881
    },
    {
      "lang": "en",
      "text": "where um well it's easier for us to like",
      "offset": 3280.4,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "verify whether the thing was done or not",
      "offset": 3282.96,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "than it is to actually generate all that",
      "offset": 3284.8,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "data from a person specifically",
      "offset": 3287.04,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": ">> maybe we just need like a like a network",
      "offset": 3288.8,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "interface",
      "offset": 3290.64,
      "duration": 2.56
    },
    {
      "lang": "en",
      "text": ">> to get the chance out",
      "offset": 3291.92,
      "duration": 2.96
    },
    {
      "lang": "en",
      "text": ">> yeah maybe I I mean, that's kind of",
      "offset": 3293.2,
      "duration": 2.8
    },
    {
      "lang": "en",
      "text": "actually when Jiannis and I were",
      "offset": 3294.88,
      "duration": 2.239
    },
    {
      "lang": "en",
      "text": "starting the company, we were we were",
      "offset": 3296,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "thinking about, well, what like, you",
      "offset": 3297.119,
      "duration": 4.801
    },
    {
      "lang": "en",
      "text": "know, maybe we just like, yeah, somehow",
      "offset": 3299.68,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "like have people speak into a microphone",
      "offset": 3301.92,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "as they're doing tasks um in order to",
      "offset": 3304.16,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "capture that.",
      "offset": 3306.64,
      "duration": 1.679
    },
    {
      "lang": "en",
      "text": ">> Just stream it.",
      "offset": 3307.28,
      "duration": 3.039
    },
    {
      "lang": "en",
      "text": ">> Yeah. And it seemed um you know,",
      "offset": 3308.319,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "logistically very hard to pull off.",
      "offset": 3310.319,
      "duration": 5.601
    },
    {
      "lang": "en",
      "text": ">> Um okay, one uh one final uh uh question",
      "offset": 3312.24,
      "duration": 6.48
    },
    {
      "lang": "en",
      "text": "about um sort of reflections path from",
      "offset": 3315.92,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "here. At what point do you this is a",
      "offset": 3318.72,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "decision you get to make in the future",
      "offset": 3320.96,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "but at what point do you try to look at",
      "offset": 3322.16,
      "duration": 4.959
    },
    {
      "lang": "en",
      "text": "other problems beyond engineering and",
      "offset": 3324.4,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "coding? Um uh like do you do you feel",
      "offset": 3327.119,
      "duration": 4.641
    },
    {
      "lang": "en",
      "text": "like there's a level of sufficient depth",
      "offset": 3330,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "where you should just go attack",
      "offset": 3331.76,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "different domains?",
      "offset": 3333.76,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": ">> Thing that makes coding as um a category",
      "offset": 3334.96,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "special is that it's not um it's not",
      "offset": 3337.839,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "synonymous with software engineering.",
      "offset": 3340.72,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "It's just kind of how we think about the",
      "offset": 3342.24,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "market today. The reason code is special",
      "offset": 3343.92,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "is if you believe that uh the way a",
      "offset": 3345.76,
      "duration": 5.039
    },
    {
      "lang": "en",
      "text": "language model will interact with almost",
      "offset": 3348.72,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "any piece of software is through",
      "offset": 3350.799,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "function calls and therefore code then",
      "offset": 3352.24,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "if you build very capable reasoners um",
      "offset": 3354.4,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "coding reasoners that you know are sort",
      "offset": 3357.28,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "of purpose-built for organization. So",
      "offset": 3359.68,
      "duration": 3.439
    },
    {
      "lang": "en",
      "text": "you've solved the kind of long context",
      "offset": 3361.44,
      "duration": 3.119
    },
    {
      "lang": "en",
      "text": "how do I reason over a bunch of",
      "offset": 3363.119,
      "duration": 2.72
    },
    {
      "lang": "en",
      "text": "information disparate sources of",
      "offset": 3364.559,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "information problem and I can act on",
      "offset": 3365.839,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "pieces of software through code then",
      "offset": 3368.24,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "you've kind of built a system like the",
      "offset": 3370.24,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "technology that um will generalize at",
      "offset": 3371.92,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "least operationally across other",
      "offset": 3374.96,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "categories of work and so",
      "offset": 3376.64,
      "duration": 7.04
    },
    {
      "lang": "en",
      "text": "the way I think about it is more first",
      "offset": 3380,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "just build not trying to get you know",
      "offset": 3383.68,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "too ahead of yourself of kind of just",
      "offset": 3385.68,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "first build the kind of most depthwise",
      "offset": 3387.52,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "comprehensive ion system for um software",
      "offset": 3390.64,
      "duration": 7.04
    },
    {
      "lang": "en",
      "text": "engineers. Uh this will naturally induce",
      "offset": 3393.52,
      "duration": 6.48
    },
    {
      "lang": "en",
      "text": "more reliable coding agents. Um right,",
      "offset": 3397.68,
      "duration": 5.119
    },
    {
      "lang": "en",
      "text": "you can plug that in as an MCP to your",
      "offset": 3400,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "favorite IDE or um coding agent. Um you",
      "offset": 3402.799,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "know, or use, you know, one of our own",
      "offset": 3406,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "um right, you can kind of plug that into",
      "offset": 3408.319,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "whatever surface area makes sense for",
      "offset": 3410.16,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "the customer and then sort of naturally",
      "offset": 3412.64,
      "duration": 4.479
    },
    {
      "lang": "en",
      "text": "start seeing where um you're getting",
      "offset": 3415.04,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "pulled from there. And the reason I",
      "offset": 3417.119,
      "duration": 3.521
    },
    {
      "lang": "en",
      "text": "think this will work is because we're",
      "offset": 3419.04,
      "duration": 2.799
    },
    {
      "lang": "en",
      "text": "this is kind of what we're already",
      "offset": 3420.64,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "seeing right in the um you know how do",
      "offset": 3421.839,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "you make the system useful for product",
      "offset": 3424.559,
      "duration": 4.881
    },
    {
      "lang": "en",
      "text": "managers um or uh technical support",
      "offset": 3426.559,
      "duration": 5.201
    },
    {
      "lang": "en",
      "text": "people um and then you know I think",
      "offset": 3429.44,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "moving on to things like sales or",
      "offset": 3431.76,
      "duration": 3.359
    },
    {
      "lang": "en",
      "text": "something like this but um there are",
      "offset": 3433.68,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "already places where uh you know",
      "offset": 3435.119,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "customers are pulling us in different in",
      "offset": 3437.68,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "in different directions. It's just kind",
      "offset": 3439.52,
      "duration": 3.599
    },
    {
      "lang": "en",
      "text": "of a matter of whether you engage on",
      "offset": 3441.04,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "that today or not. And I think that the",
      "offset": 3443.119,
      "duration": 5.041
    },
    {
      "lang": "en",
      "text": "risk that a startup has is that you know",
      "offset": 3446,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "you see a lot of shiny areas where you",
      "offset": 3448.16,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "can go and you start kind of going",
      "offset": 3449.92,
      "duration": 5.199
    },
    {
      "lang": "en",
      "text": "diffuse before you've really um nailed",
      "offset": 3451.76,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "um a category. So I think it's really",
      "offset": 3455.119,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "important to be focused and not diffused",
      "offset": 3456.96,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "in a in the short term and that if you",
      "offset": 3459.359,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "kind of build the right as we we kind of",
      "offset": 3461.92,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "think about as a contextual core for an",
      "offset": 3464.079,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "organization in this case an engineering",
      "offset": 3466.24,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "organization then you can naturally",
      "offset": 3467.92,
      "duration": 4.639
    },
    {
      "lang": "en",
      "text": "start expanding that into adjacent areas",
      "offset": 3470.079,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "of work in that enterprise.",
      "offset": 3472.559,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": ">> Okay, last question Misha where would",
      "offset": 3474.559,
      "duration": 4.641
    },
    {
      "lang": "en",
      "text": "you characterize us as like being on the",
      "offset": 3476.64,
      "duration": 4.719
    },
    {
      "lang": "en",
      "text": "path toward deployment of these",
      "offset": 3479.2,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "capabilities in in different fields? I",
      "offset": 3481.359,
      "duration": 5.041
    },
    {
      "lang": "en",
      "text": "think we're a lot earlier than most",
      "offset": 3484.24,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "people think. Uh that this is going to",
      "offset": 3486.4,
      "duration": 5.199
    },
    {
      "lang": "en",
      "text": "be one of those areas where the",
      "offset": 3489.04,
      "duration": 5.039
    },
    {
      "lang": "en",
      "text": "technological building blocks um outpace",
      "offset": 3491.599,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "their deployment. And so yeah, within",
      "offset": 3494.079,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "the next couple of years, uh the",
      "offset": 3495.76,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "blueprint roughly for you know how to",
      "offset": 3498.16,
      "duration": 4.959
    },
    {
      "lang": "en",
      "text": "build ASIS will have been set more or",
      "offset": 3500.48,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "less like uh maybe there are still some",
      "offset": 3503.119,
      "duration": 5.121
    },
    {
      "lang": "en",
      "text": "um efficiency",
      "offset": 3505.92,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "breakthroughs that need to happen. Um",
      "offset": 3508.24,
      "duration": 2.8
    },
    {
      "lang": "en",
      "text": "but more or less there will be a",
      "offset": 3510,
      "duration": 2.96
    },
    {
      "lang": "en",
      "text": "blueprint for how do you build a super",
      "offset": 3511.04,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "intelligence in a particular category",
      "offset": 3512.96,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "actually going in and deploying it and",
      "offset": 3514.64,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "and building it for you know specific",
      "offset": 3516.4,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "categories of work. There are going to",
      "offset": 3518.48,
      "duration": 3.119
    },
    {
      "lang": "en",
      "text": "be a lot of product and kind of research",
      "offset": 3519.68,
      "duration": 4.879
    },
    {
      "lang": "en",
      "text": "innovation specific to those categories.",
      "offset": 3521.599,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "um that will probably make this a",
      "offset": 3524.559,
      "duration": 4.881
    },
    {
      "lang": "en",
      "text": "multi-deade thing. Um so I don't think",
      "offset": 3527.119,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "that it's a couple of years from now and",
      "offset": 3529.44,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "uh GDP starts growing 10% um you know",
      "offset": 3531.599,
      "duration": 5.601
    },
    {
      "lang": "en",
      "text": "year-over-year globally. I think we're",
      "offset": 3534.24,
      "duration": 5.359
    },
    {
      "lang": "en",
      "text": "actually going to get there. Uh but it's",
      "offset": 3537.2,
      "duration": 5.119
    },
    {
      "lang": "en",
      "text": "going to be a kind of multi-deade",
      "offset": 3539.599,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "uh endeavor. I tend to kind of um see a",
      "offset": 3542.319,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "lot of patterns um now in kind of real",
      "offset": 3544.559,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "world deployment with uh reinforcement",
      "offset": 3546.64,
      "duration": 4.959
    },
    {
      "lang": "en",
      "text": "learning um research as it worked again",
      "offset": 3548.96,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "before large language models. Um and",
      "offset": 3551.599,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "before large language models, it used to",
      "offset": 3554.48,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "be you kind of you pick an environment",
      "offset": 3555.92,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "like you pick go, you pick um Starcraft,",
      "offset": 3557.76,
      "duration": 6.48
    },
    {
      "lang": "en",
      "text": "you pick something else and you go and",
      "offset": 3561.28,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "try to solve it with, you know, some",
      "offset": 3564.24,
      "duration": 2.64
    },
    {
      "lang": "en",
      "text": "combination of imitation learning and",
      "offset": 3565.52,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "reinforcement learning. And when you",
      "offset": 3566.88,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "look at all those projects, these were",
      "offset": 3569.28,
      "duration": 2.88
    },
    {
      "lang": "en",
      "text": "basically things that were called",
      "offset": 3570.88,
      "duration": 4.239
    },
    {
      "lang": "en",
      "text": "strikes within within DeepMind. Um and",
      "offset": 3572.16,
      "duration": 5.84
    },
    {
      "lang": "en",
      "text": "each strike uh within and outside of",
      "offset": 3575.119,
      "duration": 4.801
    },
    {
      "lang": "en",
      "text": "deep mind is was a bit of a snowflake.",
      "offset": 3578,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "Like the reinforcement learning methods",
      "offset": 3579.92,
      "duration": 4.639
    },
    {
      "lang": "en",
      "text": "and environment setup for go was at a",
      "offset": 3582.079,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "high level conceptually similar but in",
      "offset": 3584.559,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "the detailed implementation level very",
      "offset": 3586.799,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "different from Starcraft, very different",
      "offset": 3588.48,
      "duration": 5.359
    },
    {
      "lang": "en",
      "text": "from um Dota 5. And so I think that",
      "offset": 3590.48,
      "duration": 6.879
    },
    {
      "lang": "en",
      "text": "that's sort of we're going into every",
      "offset": 3593.839,
      "duration": 5.121
    },
    {
      "lang": "en",
      "text": "big category having a different",
      "offset": 3597.359,
      "duration": 3.121
    },
    {
      "lang": "en",
      "text": "environment, right? And different kinds",
      "offset": 3598.96,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "of agents with different tools. And that",
      "offset": 3600.48,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "means that you'll need to you'll have",
      "offset": 3603.119,
      "duration": 3.761
    },
    {
      "lang": "en",
      "text": "like general base models that you can",
      "offset": 3605.04,
      "duration": 3.519
    },
    {
      "lang": "en",
      "text": "start with, but you'll need to",
      "offset": 3606.88,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "post-train things in specific ways for",
      "offset": 3608.559,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "those categories. And we're starting to",
      "offset": 3611.04,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "see that already in the sense that the",
      "offset": 3612.72,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "model that powers OpenAI's codeex is not",
      "offset": 3615.359,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "the O series of models. It's a model",
      "offset": 3617.68,
      "duration": 3.439
    },
    {
      "lang": "en",
      "text": "called codeex which was post trained for",
      "offset": 3619.28,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "that environment. The deep research",
      "offset": 3621.119,
      "duration": 3.361
    },
    {
      "lang": "en",
      "text": "models like that's a specific",
      "offset": 3623.04,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "environment. Um they're also postrains",
      "offset": 3624.48,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "for that environment. And I think we'll",
      "offset": 3626.64,
      "duration": 5.199
    },
    {
      "lang": "en",
      "text": "basically see more and more of that that",
      "offset": 3629.92,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "any category that has a sufficiently",
      "offset": 3631.839,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "large business around it um that",
      "offset": 3633.76,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "requires an int an intelligence score to",
      "offset": 3635.839,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "power it there will be all sorts of",
      "offset": 3638,
      "duration": 3.359
    },
    {
      "lang": "en",
      "text": "interesting design decisions at the",
      "offset": 3639.92,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "research and product level of how do you",
      "offset": 3641.359,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "actually gain the most performance out",
      "offset": 3643.52,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "of this particular category. So uh I",
      "offset": 3645.359,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "think we'll kind of see a lot more kind",
      "offset": 3648.48,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "of depth first uh players emerge over",
      "offset": 3650.079,
      "duration": 5.361
    },
    {
      "lang": "en",
      "text": "the coming decade or so. I'm making a",
      "offset": 3653.2,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "bet on it. And I also think that like",
      "offset": 3655.44,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "part of to to your point about choosing",
      "offset": 3657.44,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "like the problem for the era, we don't",
      "offset": 3659.68,
      "duration": 5.119
    },
    {
      "lang": "en",
      "text": "get to choose at conviction a problem",
      "offset": 3662.4,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "for a hundred years, but we do get to",
      "offset": 3664.799,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "choose for like this decade or so,",
      "offset": 3667.52,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "right? and and you know if you actually",
      "offset": 3670.799,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "believe it's going to be a very",
      "offset": 3672.72,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "long-term endeavor to get to the sort of",
      "offset": 3674.96,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "productivity and abundance you described",
      "offset": 3677.2,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "but we are going to get there then you",
      "offset": 3678.72,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "know the other thing you think about is",
      "offset": 3681.2,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "like like path to supporting the cost",
      "offset": 3682.88,
      "duration": 5.199
    },
    {
      "lang": "en",
      "text": "for bringing anything under distribution",
      "offset": 3686.4,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "during a particular period right and so",
      "offset": 3688.079,
      "duration": 4.561
    },
    {
      "lang": "en",
      "text": "I'd say like in the you know we've",
      "offset": 3690.72,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "already backed companies in in some of",
      "offset": 3692.64,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "these areas but like let's say in life",
      "offset": 3694.48,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "sciences or material science like it is",
      "offset": 3697.68,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "more expensive",
      "offset": 3699.92,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "to collect, you know, types of data you",
      "offset": 3701.28,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "might need. And that might be a a longer",
      "offset": 3704.24,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "endeavor or one that you have to figure",
      "offset": 3706.64,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "out how to fund, right? Or in robotics.",
      "offset": 3708.079,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "And so, um, I think it's a really",
      "offset": 3710,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "interesting timing question of like any",
      "offset": 3711.599,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "of these really big categories. But I",
      "offset": 3713.52,
      "duration": 2.96
    },
    {
      "lang": "en",
      "text": "believe coding is this era.",
      "offset": 3715.28,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": ">> I think coding is this era as well. Um",
      "offset": 3716.48,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "this one I think will take longer than",
      "offset": 3719.04,
      "duration": 5.279
    },
    {
      "lang": "en",
      "text": "um people thought as well because again",
      "offset": 3721.28,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "enterprise there's organizational",
      "offset": 3724.319,
      "duration": 5.681
    },
    {
      "lang": "en",
      "text": "problems just much different uh than um",
      "offset": 3726.4,
      "duration": 5.679
    },
    {
      "lang": "en",
      "text": "the benchmarks that we have today but I",
      "offset": 3730,
      "duration": 3.359
    },
    {
      "lang": "en",
      "text": "think it will be one of the faster ones.",
      "offset": 3732.079,
      "duration": 2.72
    },
    {
      "lang": "en",
      "text": "So I don't think that's kind of a decade",
      "offset": 3733.359,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "out that's uh that's within the next um",
      "offset": 3734.799,
      "duration": 6.8
    },
    {
      "lang": "en",
      "text": "you know say dozen dozens of months kind",
      "offset": 3737.599,
      "duration": 6.801
    },
    {
      "lang": "en",
      "text": "of thing. So uh I think the the next",
      "offset": 3741.599,
      "duration": 5.681
    },
    {
      "lang": "en",
      "text": "sort of gen generational companies in in",
      "offset": 3744.4,
      "duration": 5.679
    },
    {
      "lang": "en",
      "text": "coding um are definitely being built",
      "offset": 3747.28,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "today.",
      "offset": 3750.079,
      "duration": 1.76
    },
    {
      "lang": "en",
      "text": ">> Well, congratulations on the release,",
      "offset": 3750.48,
      "duration": 2.24
    },
    {
      "lang": "en",
      "text": "Misha. Thanks.",
      "offset": 3751.839,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": ">> Yeah, thank you Sarah.",
      "offset": 3752.72,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": ">> Find us on Twitter at No Priors Pod.",
      "offset": 3755.52,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "Subscribe to our YouTube channel if you",
      "offset": 3758.16,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "want to see our faces. Follow the show",
      "offset": 3759.839,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "on Apple Podcasts, Spotify, or wherever",
      "offset": 3761.76,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "you listen. That way you get a new",
      "offset": 3764.319,
      "duration": 3.121
    },
    {
      "lang": "en",
      "text": "episode every week. And sign up for",
      "offset": 3765.68,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "emails or find transcripts for every",
      "offset": 3767.44,
      "duration": 5.56
    },
    {
      "lang": "en",
      "text": "episode at no-priers.com.",
      "offset": 3769.2,
      "duration": 3.8
    }
  ],
  "cleanText": "Hi listeners, welcome back to No Priors.\nRL is back with a vengeance and one of the most talent-dense new research labs has a product release, a new code comprehension agent.\nReflectionAI's co-founders, Misha Laskin and Jana Santon, work together as leaders at Google DeepMind on groundbreaking projects like Alph Go, Alphazero, and Gemini.\nI talked to Misha about building universal superhuman agents, the trickiness of reward modeling, bringing all knowledge work tasks under data distribution, how RL for language and robotics differs, the Windsurf non-acquisition and the landscape from here.\nMisha, welcome.\nThank you for doing this.\n>> Yeah, thanks Sarah for having me.\n>> So, it's been um about a wild like year and a half since you guys started the company.\nIs that about right?\n>> Roughly a year and a half, maybe a bit less, but I'd say it's ballpark correct.\nWell, can you just start by describing you've said that the company's mission is to build super intelligent autonomous systems and we've talked before about why like this is the moment in time that's possible.\nWhat is different about that from building just super intelligence which is now a sort of more popular ambitious goal?\n>> At a high level it's fairly synonymous.\nUh but maybe there are different ways of thinking about how to build super intelligence and what that might look like.\nI think on one spectrum there's an academic way to look at it uh which is uh and to some sense to some extent um super intelligence in that sense has already been achieved.\nSo uh right Alph Go was a super intelligent system and there were other systems during that time that were built that were super intelligent in narrow domains and I think you can go for the goal of building a very broad super intelligence by you know kind of locking yourself up in an academic or it's not really an academic but kind of an industrial lab with um that is sort of kind of decoupled from uh product or customers and kind of maps out all the benchmarks that are out there uh and build super intelligence that way.\nI think that is that is one approach.\nUm I think the other approach is to kind of think about what is super intelligence more concretely.\nHow is it going to be deployed?\nWhat is it actually going to look like in people's hands and build backwards from there.\nSo I would kind of say that that approach is more kind of co-designing product and research together.\nNow the kind of benefits of that approach is that you're kind of uh m you're optimizing for real problems.\nThe cons to it is that you have to be a lot more focused, right?\nBecause your product kind of defines the sort of capabilities that you want to draw draw out of the system and you have to start out a lot more focused before expanding um across, you know, other product categories and other capabilities.\nSo I would say that on the spectrum of companies that are kind of super intelligence um and just a research lab and then figure out what the product is, you know, once it's built as opposed to co-designing product and research together to build very powerful systems uh in what I would call kind of um ASI complete categories.\nYou can pick something that is uh maybe too small of a category to draw out a super intelligence.\nAs long as you pick a category that I would say is kind of big enough to be ASI complete um I think and this is kind of our approach at reflection is it makes a lot more sense to be focused and co-design those two things together the product and the research\n>> I want to come back to um choice of initial problem uh in in a minute in terms of just having the intuition and the the confidence to say like we can go do this as a team we're going to recruit great people and go build reflection you and your co-founder Giannis were working at Gemini together in key roles before and previously you had been um part of Peter Abil's lab who's an amazing researcher as well.\nUm you had described to me as having like I believe the term you use was somewhat muscled your way into AI and deep learning from originally a physics background like how did you decide to go work on this and end up in Peter's lab?\n>> Yeah, as a as a kid uh I became really interested in physics u theoretical physics.\nUh it was I mean probably a byproduct of I'm I'm Russian uh kind of Israeli American and moved around and then when I landed in the states it was uh kind of in a desert in Washington state uh learning a new language and so I had a lot of time in my hands and you know bumped into um my parents had uh had the Fman lectures uh in their in their library and so I uh spent a lot of time you know just reading what what was on the shelf and bumped into that and got really interested in physics.\nHow old were you?\n>> I was so when my interest in physics started that was probably um around middle school and it really I think became the thing I wanted to do in in high school.\nAnd the reason physics was so interesting was because it kind of seemed like the science that was at the root of many of the things that became impactful.\nUm right so I was reading about the history of the transistor and it was invented by a group of theoretical physicists.\nI was reading about you know how GPS works.\nSo, turns out you need special relativity in order to um accurately account for uh spatial coordinates using using GPS.\nAnd so, I felt that physics was kind of the the root science to pursue.\nI I went in and studied it, got my PhD in it.\nAt the same time, I started seeing uh kind of deep learning take off and really uh saw kind of alpha go happen.\nAnd my sense was that uh I want to pursue the kind of the root science.\nUh but there is a such a thing as kind of the root science of our time.\nUh I think a lot of physics has uh is a field.\nIt's very interesting but it's crystallized a lot more than um you know than a new dynamic field that was being born out of nothing.\nuh and AI to me felt like it was going through the moment uh that physics went to maybe a hundred years ago that when I do problem sets when I did problem sets in physics and the most exciting stuff that I was working on there was basically the things that people were discovering 100 years ago.\nSo I saw it kind of happening in front of my eyes and uh I just decided that that was the science to bet on.\nuh and in particular because it was AlphaGo that was that inspired me because it was just unbelievable to me you could train a neural network um to have such immense kind of basically reasoning capabilities, right?\nThis thing was able was super intelligent within the realm of go.\nYeah, I decided that I needed to kind of get myself into the best reinforcement learning lab um I could.\nUm and Peter's was Peter's lab was was that lab for me.\n>> And then you and Giannis were working specifically on RL at Gemini.\nThat's right.\nSo, Giannis, my co-founder, was the um overall RL lead for Gemini at the time um for one and 1.5.\nUh I was uh working very closely with him on his team.\nYeah, it was a really exciting time because you know we went both of us from being reinforcement learning researchers uh to um training large language models at scale and we kind of saw at the end of that project of what's to come which was you know Gemini 1 1.5 lands and it became pretty clear to us that the next paradigm and effectively the the final paradigm um that we need to have in place before uh a you know what people used to call AGI or now I think the goalposts have shifted to ASI is reached is just figuring out how to scale reinforcement learning um on top of large language models and the first instances of that have have been happening right over the last year.\nI think we're still actually a lot earlier than people think.\nUh but there is a web and things have started to work.\n>> Yeah, I definitely uh I definitely want to talk about what you think is solved and unsolved here.\nUm the entire field has clearly gotten more focused on um deep reinforcement learning over the last 18 months.\nyou have this uh huge product launch this week with Asimov.\nUm can you just sort of describe what it is?\n>> So Asimov is uh the best code research agent in the world.\nIt's a comprehension agent, meaning that it's really designed to kind of feel almost like a deep research for large code bases.\nThe way a developer is supposed to feel interacting with it is effectively like they have a principal level engineer who deeply understands their organization at their fingertips.\nUh so it's very different from the existing set of tools that are focused primarily on code generation like every single coding tool has some code generation and some comprehension aspect.\nBut as we spent a lot of time kind of with our customers um trying to understand why coding tools and this is enterprise specific so I think I think the the world is different with startups but within enterprises when you you know they're adopting coding tools and you see the impact that this is having um on their actual productivity and I think it's much lower than people uh expect um so it's uh in fact it's it's sometimes negative sometimes negligible\n>> did you see the recent meter report on that.\n>> Yeah, the the meter report was very close to what I've been hearing when talking to engineering leaders within larger organizations.\nAnd it's not just enterprises.\nIt's I would say growth stage startups.\nIt's any kind of engineering organization that has a sufficiently complex codebase and sufficiently large team that no one engineer can have the entire codebase kind of in their heads.\nAnd so reflection is one of those places as well.\nuh like we use our product actively uh because the you know training large language models is complex and there's right the large language model code base there's there's the product codebase um knowledge is kind of scattered across engineers it it's not just in the codebase it exists in your chats and project management tools and um other places where knowledge lives and so what we're effectively building towards is this uh kind of omnisient oracle for organizations that uh you can go in uh ask any question at kind of any level of complexity and it'll provide you an answer at the level of what that principal level engineer would have given you or you know in the future as the product expands to other categories um what the person who's most embedded in the organization understands um and of course once you have that solved it begets much more reliable agents that act for you as well um but I think the world today is focused on I would say 80% kind of action 20% understanding.\nSo 80% code generation, 20% comprehension.\nThe actual problem is exactly the opposite.\nThat when you look at what an engineer does in an organization, 80% of their time they're spending trying to comprehend complex systems and um collaborating with teammates.\nAnd what is collaboration?\nIt's usually someone asking someone else a question about a system that they don't know.\nAnd so that I think is kind of the problem at the heart of what would prevent a super intelligence from actually working within an organization.\nIt's really this kind of understanding and being able to ingest from a lot of sources of information and from the team.\nAnd once you have that then the action part I think becomes uh I don't want to say trivial but a lot easier.\nLike it to me it seems like really 20% of the problem is teaching these agents how to act and it's more or less solved.\nThat definitely squares with both my understanding of engineering and then my experience with coding agents personally, right?\nIf if you think about the I don't know the like context load time of just like trying to understand a new system or code anyone else has written or code your Asian has written in the end it's like you know very stupid um implementation that like if you had reasoned through it with context of the system you never would have made such a mistake or like a you know works in works in my environment type problem.\nUm and and so I I think that very much mirrors my you know intuitive understanding of engineering here.\nThat's great as problem formation.\nWhat what makes ASMO different in terms of ability to understand better versus just generate code?\n>> There are a few things.\nSo I think this is kind of where you know why it is so important to co-design research and product because as a researcher you'd go in and say the answer is entirely in the agent design or the model or something like this and as a product person you would say well it's in these product you know differentiators like being able to draw not just from your codebase but knowledge that lives you know in other sources of information or being able to learn from kind of the engineering team to offload uh their tribal knowledge.\nSo right an engineer can go in and teach as like hey uh we deploy our you know when we say environment jobs it's on our team we mean this specific thing which we mean kind of Google bath jobs.\nSo now when another engineer asks a question about environment jobs in the future the system just knows what they're talking about.\nA lot of knowledge is stored in engineers heads and I think you need um both of these things.\nyou need to understand your customer really closely and develop differentiated product almost independently right of the models that are powering it.\nUm but then you also need to innovate on the research uh in terms of agent design and model training to actually drive the capabilities that you want to see out of the system and this becomes an evaluation problem which is basically at the heart of any any frontier lab as well.\nThis is uh I think the least spoken about part of what Frontier Labs do but possibly the most important which is figuring out how they evaluate like what makes Claude magically feel better at code than um you know another model out there.\nUm they did something right in their evaluations.\nSo when you look at this problem specifically there are different capabilities that you need to um train and and what we do is we really post train models where you know we really focus on on post training today.\nSome of these things are long context reasoning.\nNow when I say long context reasoning, I don't mean um I actually mean kind of small models with very long contexts that are able to go into giant code bases, sort of suck up as much information as they can and reason over and output relevant stuff basically.\nSo it's almost like neural retrieval.\nThere are capabilities like um tool use and multihop reasoning.\nSo this is more for a you have your agent and it's designed with some tools and there are two ways of training um agentic models.\nOne is in this very general way where you just train it on thousands of environments and make it like the most general agent possible.\nAnd that is kind of almost like the pre-training of agents.\nUm and that's sort of what you know that's what a Frontier Lab does.\nUm that's what um this there's a new release from uh Kimmy 2.\nThat's kind of what that model does.\nAnd that's definitely part of it, but in order to that that kind of gives you a nice general base to start from.\nUm, but then to drive a capability kind of depthwise like if you really want this reasoner that has, you know, search tools and, you know, ability to call like these long reasoning context models and other, you know, other tools that it might want to interact with like\n\n\nWhen do I read from Jira? When do I read from another tool? Like, this is kind of a reasoning problem. If you train with those specific tools in mind, that's typically what people refer to when they say tool use, like they actually train for a specific set of tools and really drive the capabilities for those tools. So these are the kinds of research problems that you need to solve in order to build the overall system that's the best in the world. It's not any one thing; it's all these things combined. And some examples of systems that are being trained for a specific set of tools. The thing that comes to mind is Gro, the Groth 4 release, and they kind of showed a plot of their general model and then the model that was trained with a tool to basically climb on humanity's last exam, and there was some big noticeable difference between the two. Now that's great, but I think the downside of that is, does humanity's last exam actually matter in any meaningful way for an end user? And I would argue that some weak correlation, but the answer is most likely no. And so you have to build the tools and train for the things that users actually want. I think that there's sort of no way around that. What can you share about how you evaluate, either technically or philosophically, that makes Azimov's performance great?\n\nThis is sort of why it makes sense to do something like this as a startup. The only advantage that you'll ever have as a startup over a big incumbent, especially when there are such talented teams out there, is kind of focus and velocity against the thing that you're focused on. Now I think you need, if you want to be playing in what is, you know, arguably I think the biggest category in AI, which is coding, then you need to have the talent as well to do it. But you know, what do you do if you don't have the billions of dollars to pre-train models? The only way we can win, I think, is by being very focused. So the way I would describe what it looks like to work on a big model within an incumbent lab is that you are one of like hundreds of evals. There are teams, you know, when you look at the model card for, let's say, the 01 paper that came out, I think, last year, if you look at the distribution of what most people work on in that paper was eval. So you're one of many people doing all sorts of eval and spreading yourself in that sense, you get something that's general, but it's spread fairly thin. As a startup and a startup that has a very focused product that didn't, you know, that's not kind of being too diffused and it's pretty opinionated about what it is that it's building, your evals are basically what you know in the startup lore when, I don't know, Paul Graham would tell you to kind of go talk to customers, like half the time build product, half the time talk to customers. I think in the AI age, it's develop your evals based on what customers are saying and what they're doing. So you have to work with your customers to look at what prompts it is that they're trying to solve, what general questions are they trying to unlock. So right, there's very specific pain points that we've identified, like onboarding being one of them. Like in a big company, it takes months to onboard an engineer. So how do you develop evals that accelerate the onboarding of an engineer from, you know, months to hopefully just a couple of weeks? Now that you know all the questions that they had, they can just ask Azimov and be able to onboard much faster. So I think there's no silver bullet other than coupling to the information coming from customers, but then being very scientific in the evals that you develop across them. So you have these, let's say, customer needs, let's say onboarding and, you know, a bunch of others, and then you have your system capabilities, which is, well, what do you need in order to provide a good experience there? Well, this customer is being onboarded onto a giant codebase, like it has, you know, it might be a codebase that on its own is like 100 million tokens or something. Well, then you need to figure out some way to reason over that giant codebase, so you have kind of a long context reasoning capability, or you kind of look at your agent and seeing like what's preventing it from satisfying this query from a user. And so you kind of work backwards and reverse engineer from what a user is asking for to what capabilities you want to drive in your system. But the important part, I think, is to be able to tweak every part of the system from, you know, the product features to the agent design to the model training in order to build the best overall system. And if you are capped in which parts you can change, like if you can only change the product and agent design, then you're actually pretty limited in what you can do because you're kind of at the mercy of, you know, what these general third-party models can do. What I'm hearing from you is also that there is some trade-off between having, you know, to serve all different kinds of users and optimizing across those different evals because each one of the teams that is thinking about a particular use case or audience at a more general organization, for example, is less likely to have the ability to work through the entire pipeline from training to product to win their use case. So the thing that was extremely satisfying about working on Gemini is that you're driving research in the frontier, and there's something very gratifying about that. The downside was that you were so far away removed from product that it was kind of a broken telephone game of talking to, there were kind of four different people that information flowed through before the model got into a customer's hands. That coupling was very loose, and I think it's very true that just because a company might have the best model in some general set of academic benchmarks doesn't actually mean they have the best product. And I think what we're seeing is when things really fit together, it's usually that there's a tight coupling between a product and a model, that it's a whole system. It's not just the model alone. Obviously, the first big example of that was chat GBT, right? Chat GBT is kind of an incredible product that was coupled with the model, and the model was post-trained for the prompts that are coming in from users for chat from chat GBT. Like there was a reason why it was, you know, when I saw the first coding blog post that chat GBT produced for me, that was, that was just insane, that was like an insane magical moment, and they post-trained specifically for that, and I think there's an another example of that happening right now with cloud code. That's kind of tight model to product coupling, and so I really think that that's it's important to really be able to do both at a great degree of excellence.\n\nWhat is an example as you guys open up the weight list that you want users to try where it should just be like obvious that the answers are better than other coding agents?\n\nI think the kinds of queries that it tends to be better at are, I guess, what we would call semantic queries. So let's say, like an example of a query where this is not the best system to use. It's like file level. If you're looking at a file and there's like a specific thing in that file and you're just trying to get a quick answer to it, you don't really need the hammer of like a deep research-like experience. You don't need to wait, you know, like tens of seconds or a minute or two to get that answer because that should just be delivered snappily. But if you don't exactly know where you're looking for and you, you know, you don't know the function name or you don't, you know, something, and this is kind of the hard problems that engineers are usually in, like there's a flaky test. I mean, you know that this test is flaky, but that's where your knowledge stops, right? And that's when you usually go to Slack and ask an engineer, like, this test is flaky, what's going on? Does anyone know? You know, we've had, the way we've used it is when you're training these models, there's a lot of infrastructure work that goes into it, and it fails in interesting ways all the time. And asking things like, you know, my jobs are running slowly, five times more slowly than usually. Why is that? Right? That's kind of a vague query that would be very hard to answer with existing systems, especially since the knowledge around that query might live not just in the codebase. So in the example that I just brought up, when this was happening that our kind of environment jobs were slowing down, it turned out that two different teams, kind of infrastructure and research team, submitted pull requests that were, they passed tests. It wasn't that they were wrong, but they kind of conflicted together in a way that caused this kind of effectively a race condition and slowed everyone's jobs down. And these are the kinds of bugs that actually engineers spend, you know, that's where you have like two or three engineers who spend a few days trying to solve one of these. So I think these kinds of semantic queries tend to be the place where a product like this shines. In the same way that when you think of what kind of query would you ask chat GBT to, you know, when it just needs to use kind of the browser tool, so it's like a quick factual thing, like you wouldn't invoke the deep research experience, but when you wanted to compile kind of a lot of information around some more nebulous query, I think that's where people seem to find a lot of value with deep research, so I think a similar kind of mindset holds here.\n\nOne thing I would do, you know, working on a new system with a principal engineer next to me, is just have them explain the entire system, right? Because I want to have that context where I can't, I can't even tell the agent what to do. And so I'm curious from a product perspective, like the way you have, you know, memory for agents or even for teams is an increasingly popular idea. There's lots of ideas about how to do it. I think there are not many examples of like collaborative memory in production in a useful way yet, but I'm sure it is coming. Have you guys designed it in a form like I can understand too? Yes, that's so this is actually one of the more fun things to, I think, work on in product today, and I think it's one of the more fun kind of features to work on at the company is how do you design a teamwide memory because there are all sorts of details around, well, who can edit the memory, who can view different parts of the memory, how do you, you know, how do you maintain a kind of repository of this memory for people to edit and view? You have to have a concept of authority, right? People are going to say things that are wrong.\n\nThe way it's worked with customers we've started working with is they typically have, they want to start off with kind of a group of trusted kind of senior staff level plus engineers who are kind of the gatekeepers, which is a very, I think, common notion. You have permissions, right, and ownerships, ownership structure and code bases, and they basically are the ones who kind of populate the memory first and then sort of expand the scope. But it, I think, it works. It's actually a much more complex feature to build because it touches on, yeah, or wide permissions. There's some parts of the code where a certain engineer should be able to edit the memory, but other engineers shouldn't. And so it actually starts looking like the new way of versioning code effectively, right? It's kind of a GitHub++. Because you're not versioning the code, you're kind of versioning the meta knowledge around it that helps language models understand it better. But definitely that is something that we built, but I think it's a thing to iterate a lot until you kind of get the right design here because you're effectively building kind of, yeah, a new git from scratch. Yeah, it's interesting and you're you're trying to design some sort of permissions into it versus like, you know, dominant system today in actual version control is like, you know, at best pull request review, right? Like you just, you try and like somebody in the organization with the ability to review makes a determination as to whether or not Misha should be able to make this change or not actually based on the content. And I think actually it's going to look not too dissimilar from that, right? Where if you want to change the agents, the teamwide memory, then it probably is going to look something like a pull request where the person who really understands that system approves or, you know, edits it or something like this. I don't think it's going to look too dissimilar.\n\nThat's quite different from like traditional role-based like group hierarchical access control that is quite static, right? And it makes sense to me that it would look perhaps a little bit more gitlike in that the, you know, the person who knows what part of the codebase you are editing or creating, creating or editing knowledge about is going to evolve over time as the codebase evolves over time and the team does as well.\n\nYeah, exactly. But I think this is also how it was very common at, you know, at Google and I think other places as well for different parts of the codebase to have owners, and so there are like these ownership files that we have as well, and basically if you're on the ownership file, then the review has to go through you or through it has to be approved by at least one of the members of the ownership file, and as people move around teams and so forth, the ownership files themselves get updated. So I think a pretty similar structure is probably going to hold here, but it's a lot more nuanced than building kind of an individual memory which is just kind of personal to you and lives on your computer in your, you know, agents MD file or something.\n\nOkay, if we zoom out and place like ReflectionAI overall in context a little bit and talk about the larger environment.\n\nSounds good. Yeah, you know, coding as a root problem in this era of AI research is a somewhat commonly held belief, right? I think a criticism of companies that went after pre-training focused on coding was in reality, like you actually, you needed language, you needed a lot of the capabilities, who can say exactly which, but the reasoning capabilities that could be elicited from large pre-trained models to do code anyway, and so you had to do all of the work without the general use. Is it specifically the availability of pre-trained models that are more capable and open-source that made you feel like we can go after super intelligent, like autonomous systems in coding without spending the pre-training doll?\n\n\nArs up front as a new lab or help me think about that logic a little bit more.\nI think that that's roughly correct for kind of, you know, these sort of why you can get into the game sort of short term.\nUm, a bet that we made, you know, when we were starting a company a year and a half ago was that there were pretty decent openweight models out there that pre-training, you know, we kind of saw pre-training as starting to more or less converge on kind of a known paradigm.\nThere's sort of a there's a known big data set on the internet.\nYes, there are going to be some algorithmic innovations, but you're basically extracting signal from an extremely noisy data set.\nAnd we felt like there's only so much signal that one would be able to extract without getting into just absurd dollars for scaling this in terms of what you're trying to get out of it.\nSo, what we thought would happen is that there'd be decent openweight models.\nUm, I think the quality of the openweight frontier has surprised me.\nUm, they're actually the models are better than I thought they would be, and we thought that you can just focus on, you know, we're in this brief period in history right now where um the RL flops are still manageable, like you can, you can really have a best-in-class um product if you're focused, and yes, you'll need to put, you know, you still need a decent amount of GPUs, but from a, but from a flops perspective, it's nowhere near where pre-training, like two magnitudes off.\n>> Exactly.\nRight.\nSo you can get into it and kind of build out a both kind of the product and a research arm.\nOur thought was that this was the time where you can actually start a um, you know, a generational frontier lab that does not need to be coupled to a, you know, to a big cloud provider.\nUh, because if you do it right, you'll actually be able to generate um, you know, sufficient revenues to not have to be acquired or find, you know, some strange deal where um the cloud provider kind of owns you.\nAnd that was kind of the model, I think, of a lot of what Frontier Labs look like pre-LLMs.\nUm, I think we're already starting to see that, you know, this kind of more of a fieldwide thing independently of Reflection, right?\nYou look at how fast like Anthropic's revenue is growing.\nUm, I think right, they're kind of in the spot where um it's like a massive revenue generating business that's growing at an unprecedented rate.\nThat is, but but that was very much the ethos that uh we can come in, we don't need to pre-train, um you can get by with um, you know, two orders of magnitude less compute, um and really get something something out there that's really good.\nUm, I think that roughly speaking, you know, you won't need the amount of compute that I think a frontier lab needs uh today, um as you're focused, but you'll still need kind of um, you know, an order of magnitude less.\nSo uh I think that the capitalization requirements are still high.\nThere's no way of avoiding that.\nUm, but I'd say they're uh and asmtoically they're probably the same, but asmtoically the idea is that at that point you just have a generational business that can that can raise capital off of that.\n>> I guess part of my read at this point in time is, and maybe it was always true, but especially now is your actual capabilities in terms of understanding what Eval to go after, how to design reward models.\nThere's perhaps like less understanding and more dispersion in the field in uh post-training strategies versus like, as you said, more maturity in pre-training right now because you can, if it was a simple question of scaling RL and language models, people would be doing it more aggressively right now, right?\nUm, and so actually maybe that's a a good question for you, like how would you describe the challenges in solving scaling here, like why, why are we only able as a field to put like a much smaller amount of compute to work here and still get like best in best-in-class results versus pre-training skilled GPUs?\nRight now.\n>> I'd say that there are two categories or one would think that um things fall into.\nUm, one is more around the problem limitations of the problem structure, and the other one is, well, maybe the structure is fine, but you need um algorithmic advances to really drive the next frontier forward.\nThere's, you know, I'd say it's some mixture of both, but the the biggest way I put is on the problem structure.\nSo, if you the thing that I led for Gemini was reward models.\nI built out um the reward models that were used to um post-train Gemini 1.5.\nAnd I thought is that if you have a reward that accurately uh basically describes the outcome of any arbitrary task that you throw at it, then that's that's it.\nYou know, at that point it's just algorithmic advances, but even the like very simple RL methods we have today um will be able to get a lot out of this, like they'll only be bound by their exploration abilities, that's the only thing, right?\nBut if today um, you know, we certainly are not in this world where we have clean rewards for every task we could imagine, and so we're kind of making as a field have to make sort of various shortcuts and compromises to that, so you'll have things like LLM is judge with um different rubrics, and that works to some extent, but um it inevitably a noisy or like stocastic reward inevitably gets hacked.\nSo you kind of need a lot of these, and um, you know, and there's only so much you can extract out of them.\nUh, then you have sources that do have ground truth rewards, but um there are not many of them, and so you have to hope that by optimizing against those you'll get some generalization effects, and so I think that the fundamental problem is like the reward problem.\nYou can either go in and say, \"I'm just gonna all I'm going to focus on is kind of rewards.\"\nUm or you can say, \"I'm going to take things as they are and just be more um creative in the methods that leverage the rewards that have them today.\"\nAnd and so examples of that are basically every synthetic generation pipeline is some example of this.\nUm so it's it's a messy problem, but I think it's fundamentally a like we're in a rewardbound world.\nI don't think there's going to be any breakthrough that all of a sudden, you know, we go from we didn't have rewards for everything to we do, because the reward problem in itself is at the time I called I thought it was AGI complete, now I'd say it's ASI complete, but by the time you have a neural network that can accurately verify any outcome, that is probably a super intelligence, and so then it goes back to again evaluations, what if you're training your rewards, your reward models on something like what are you evaluating against, what are the tasks that um you want it to be good at.\nSo that's kind of um how I think about it.\nI think it's a fundamentally reward model uh or rewards bound field.\nUm, and then there's also kind of algorithmic progress in terms of uh the RL methods we have today are quite bad, I would say, at um exploration and credit assignment, like they they're sort of just like uh the fundamental algorithms are take the things that work and make them happen more frequently and the things that don't work and h and make them happen less frequently, but they don't discern at all along your say reasoning chain which part of the reasoning uh was correct and which part was incorrect.\nAnd so that's why you get these reasoning chains that are kind of garden path meandering.\nLike they'll explore all sorts of things that are, you know, completely unnecessary and don't look at all like the kind of structured thinking that a person would have.\nThat's how the algorithm works.\nIt doesn't uh it doesn't actually look at there's no credit assignment step on any atomic level.\nUh, and so that I would say falls into more algorithmic progress bottlenecks.\n>> Can I ask you for a few uh like hot takes quickly?\n>> Yeah, let's go for it.\nWhat do you think of all of these efforts either in-house with, you know, labs and vendors or young companies just creating software environments that look like popular software to train agents in, right?\nCopies of Airbnb or Amazon or Salesforce or Excel.\n>> Personally, I maybe the take is not very hot.\nI'm very like bullish on it because how else are you going to, maybe the hot take is that there's no such thing as generalization.\nThere's just bring the test distribution into train.\n>> Okay, that is an aggressive take.\nWow.\nYeah.\nSo as long as like your yeah train distribution looks something like what you would actually want to evaluate for um then you know users will experience experience it as generalization.\nI think you know I I think there is some generalization that happens in these models, but um we probably as as users overestimate it because we don't actually see how they were made, but then you know yeah, if you saw, oh, this synthetic environment was actually very similar to the thing I was asking about.\nSo it makes sense why the model would be would be good at that.\n>> Maybe six months ago, I think you you you said like I think it's possible we have my definition of ASI in a couple years.\nUm, do you still believe that's true?\n>> I I still do believe that's true.\nUm, I think that where I think we'll be in a couple years from now is that there will be kind of definitive um super intelligence in some meaningful categories of work.\nAnd so for example, when I say coding, I don't mean all of coding there, but there will be a super intelligence within some kind of slivers, some meaningful slivers of coding that are driving um immense progress in the companies that can benefit from that, and\n>> the reason why I would say that the problem of ASI would have been solved by then is because you've kind of um at that point it's just a matter of operationalizing, like what you know, you know, it just so happened that these particular cate categories, like you might have a super intelligent front-end developer because there's so much data distribution for that on the internet and it's easier to make synthetic data for that.\nBut at that point, you have the recipe and it's just a matter of um making kind of economic decisions of is it worth sinking in x amount of dollars to get the data in this category um to get kind of something um close to super intelligence there.\nUm an example of that is what happened with reinforcement learning before language models.\nUm effectively the blueprint for building super intelligent systems was developed.\nIt happened with um the Atari games, Alph Go, um you know, then Dota 5 and AlphaStar were near super intelligent systems, and if OpenAI and DeFi had sunk more compute into them, they would have definitely become super intelligent.\nIt's just that at that point it didn't really make s it economically, like why would you do that?\nThen this is a definitional issue because I I was going to ask like help me understand your view of like I don't like one of the big criticisms of RL overall has been lack of generalization.\nUm that's been just kind of a general question for this direction.\nI do have friends at every large research lab that somewhat, you know, some I mean tell me if you hear uh something of a different tenor or just believe differently.\nThey believe we're going to have systems that are much more capable than humans and many types of knowledge work, but they believe less in generalization.\nAnd so in a resigned way, they're also, as you're saying, like I guess we're just going to bring all of it under distribution one way or another.\n>> But that means like, you know, it's a little bit different than my my view of like it's\n>> um at at some point you're you're just you know, you have enough capability that the rest you get for free, right?\nThe rest sort of useful capability you get for free.\n>> I think I kind of have a similar viewpoint to to the people you describe.\nUm, I think the generalization capabilities of these things has been weaker.\nFirst of all, it's all mind-blowing that this exists.\nSo um we went from fundamental existential crises and generalization, like this was the field of reinforcement learning before language models was we have these systems and we can make amazing, you know, at like very narrow tasks.\nWe have absolutely no answer for generalization, like zero.\nUm, and we went from that to things that you know feel like they're generalizing.\nThey're certainly generalizing much better than um anything we had before.\nUm, but it's likely because the training distributions are so broad.\nUh, so at least the way I think about it is more um kind of output as a user is the system, you know, super intelligent in some meaningful categories of work, and then from a research perspective, is it obvious how to make it general for anything that you might care about, and at that point again, it's just a matter of economics, maybe there are some categories where um collecting the data is so expensive and the return on investment is low where um effectively just better to have crafts people than super intellig AIS.\nUm, so I think we're moving into this kind of jag world of jagged super intelligence where you have a handful of these super intelligences for categories that matter, maybe subsumed into one model at some point, but at first it'll probably be um again, I think there will be a few companies that have kind of product model coupling that you know, that is super intelligent in different categories.\nI think an example of again starting to see the first glimpses of super intelligence, but in a way that hasn't really transferred to anything meaningful yet is, well, we have these like uh super intelligent test takers now, like you know, Amy, the Amy benchmark is completely saturated, code forces and um other competitive um coding environments, the models are almost best in the world, and within the year will probably be just the best in the world, and yet we have the so we have the test competitive coding agents.\nThen you go into you know a company and you ask them have these things been helpful and they say\n>> it's uneven.\nYeah.\n>> Yeah.\nRight.\nThey so in the in the parts of work that are really meaningful that would you want to see these things driving um meaningful kind of increase in in GDP, and I think right, the only way you you'll see that is if you go into a company and there's kind of you know a universal understanding that yeah, my engineers are double digit percentage points as a whole, every single one of them more productive, right?\nThat's the kind of thing that if you that starts happening across every field, then you'll see double- digit increases in GDP, so I think that the kind of benchmark maxing that's um and it's a bit different than benchmark maxing used to be before because you have benchmark maxing that is weekly correlated to customer outcomes, but it still looks very similar to taking a board game training RL agent on it, getting kind of a landmark um result in super intelligence and then making a claim that you know super intelligence is solved.\nI think uh the reality is that deployment of it is half the problem, which which it goes back to kind of evaluating on customer problems and building product together with.\n\n\nThe models.\n\n>> So you must have seen the news of the, um, Windsurf non-acquisition into either OpenAI, but non-acquisition into, uh, Google DeepMind. What do you make of it? We're seeing this verticalization basically happen across categories that, um, are material to frontier intelligence, and, uh, one could argue that the first verticalized category was actually search, right, through chat GPT. Um, that's sort of a place where OpenAI verticalized first, and coding has obviously emerged as another, uh, kind of frontier level category that, right, could, um, like all these companies have aspirations of,\n\n>> ASI.\n\n>> Yeah, ASI, and I think, you know, being basically trillion-dollar companies or more. I don't think that it's really the economics that are the driving factor, but it's more that if you want to sustain frontier research, that's kind of what you have to become. And so coding has clearly become one of these categories where, uh, verticalization is, um, extremely important. And I think that there's, there are kind of two sides of the story: one on the frontier lab side and the other on the kind of more of, you know, product side, like a startup that builds product but does not have its intelligence, um, in-house. So I think on the, on the frontier lab side, I think this is exactly kind of what Giannis and I noticed when we were, um, working in Gemini, is that your model is so far away from the product that oftentimes, even though you have the best model, does not at all mean that you have the best product. So, like, there's a reason why, uh, basically startups are the places where, uh, kind of adoption of coding tools took off rather than the frontier labs. And so there's a verticalization happening there. And some are going to do it successfully, and some are not. Um, I think that that's kind of, we're already starting to see that with Cloud Code really being an example of a successful verticalization. Um, I don't think it's guaranteed that a big lab can, you know, buy their way to, uh, to the end user because the fundamental problems of your, you know, research team being far away from your product team will still be true, and, and the company having, you know, a hundred different focus areas will still be true. So I don't think that acquiring an asset will change that fundamentally, but it does underscore the importance of verticalization. And then from the startup side, I think it actually puts companies that are in these kind of, um, critical path categories, like search and coding, um, in a pretty existential place if they can't build their own frontier models. Not all frontier labs will be able to verticalize correctly, but some will. Maybe one will, and that's going to be enough, I think, to kind of, right, take the thunder out from a, you know, from a company that's built, um, a great user experience on top of someone else's model. Um, and I think some of those dynamics are probably starting to play out as well. Like I think that, uh, there are some question marks around if you're on this critical path category, um, and you don't have your own intelligence, um, you know, how do you compete when your competitor, and you know, just basically subsidize their product a lot more than you can? Um, right, because you're effectively, as a, as a startup that's building on top of these things, to grow quickly, you're subsidizing, you know, the margin that, you know, an Anthropic or Gemini or whatever is making, um, and Google and Anthropic and OpenAI can subsidize their products a lot more than you can. Uh, so I think that companies that don't own their intelligence or are not kind of deeply integrated into a customer in some way that makes them hard to remove, find themselves in this pretty, um, existential place as it becomes clear to the frontier labs that this is a category they need to verticalize around. I work with a few robotics companies, and so, um, much of my lens on RL comes from that, and I think it is like far less clear in robotics that, you know, RL will be a dominant part of the, uh, training versus imitation learning. You'll actually appreciate this on, on imitation from humans using tools, right? Um, because we run this, I, I'm going to like describe this idea that is, um, nuts, but I, I think it's just funny. We run this grant program twice a year for amazing people, um, using ML in different fields. Uh, and it's called Embed. Uh, and one of, uh, one of the ideas I had as a joke recently was, well, like, you just record everything, right? Like, not obviously just the codebase, but like your Slack and all your documentation and all your conversations because you are a software engineering team. And I'm 100% sure that I can take that data set if you ship something into production to an end customer that has real issues at any scale and sell it to a friend who's a researcher at a lab working on this stuff. Um, and so you have some floor value that is millions of dollars for your, you know, couple-person company and like bonuses, like maybe the software company works, right? Obviously, this is like very noisy, and I'm, I'm mostly joking, but I'm, I'm curious how you think about, uh, like exploring non-RL data sets that could be useful to you here.\n\n>> If that company existed, right, we would, uh, we would definitely pay for their data.\n\n>> There we go. See, it's not an idiot idea.\n\n>> Yeah, it's, uh, yeah, especially if there's diversity. Um, I think that'd be,\n\n>> I can sell the whole set.\n\n>> Yeah. So is the question around, um, how do you leverage alternative sources of data?\n\n>> Yeah. The, the question is, um, I, I think there is like, uh, I, I don't want to like over-analogize to robotics, right? But within robotics, you have learning from world models, you have learning from sim, you have learning from embodied data that, uh, of different types, right? Um, imitation, then you have RL. I, I think it's like much less clear that you can use RL for a lot of robotics today, especially some of the harder, like, manipulation problems. And I'm curious, just given, you know, your team has this enormous strength in RL, it's like a starting premise, how you look at other types of data to create the, you know, uh, coding agent experiences you want. So I was actually, um, a robotics researcher for, like, in reinforcement learning, that Peter Beiel's lab is a robotics lab, and it was, you know, it was a mixture, like Peter's lab was always around in the intelligence problem and robotics as being a domain where you study it, and one of the, you know, the reason I came to lead reward models for Gemini was because that's the question I was studying with robotics. I was, you know, we had these RL algorithms for getting robots to do some very narrow tasks, like moving blocks and, um, you know, various kind of narrow tasks in simulation. And the question was, well, how do we get generalized, um, yeah, manipulators and, um, you know, just how, how do we build this all into one system? And it seemed like the rewards were the bottleneck. So this, a lot of what I was studying before, uh, starting, you know, getting into language models was how do we design reward functions or models for, um, for robotics or, you know, for 3D video games, like Minecraft or something like this, that have, I think, similar challenges scientifically. The challenge is that if we, if you think that language model rewards are hackable, uh, vision language model rewards or, you know, like other sensory signal rewards are infinitely more hackable. They are much more short-lived than, um, than rewards. Like you can think of, like, language as just a compressed representation of the world that we have that we are kind of magically have to start with. Um, whereas if you're processing pixels or sensory motor signal, um, this is raw signal that has a lot more noise in it. And so if you train a neural network that is sort of trying to detect whether this thing was manipulated correctly or this thing was, you know, moved correctly, then that thing is just infinitely more hackable than anything you have in language models. So the same problems blow up and become much larger. Uh, and so that's actually why I changed to, uh, language models because I felt that this was a fundamental problem, but, you know, we now have these confounding factors of these noisy signals coming in. I think that in, at least in a generalizable way, that's why it's really hard to get, um, reinforcement learning to work, um, with robotics. Um, the one place where it really does work well is when you have a clean reward signal, which has happens to be in these, like, locomotion, like, scenarios. So there's a lot of work on,\n\n>> like building very robust sim-to-real locomotion pipelines, and it's because it's kind of, um, locomotion is just your body, like you don't have to manipulate the world around you, and so you can actually build reward signals that are like, oh, you know, your quadriped is moving at this velocity without damaging its body, kind of thing. Maybe it's a bit of a roundabout answer to the question, but it's that I think these two fields are very different in the data distribution they that they support, and the kind of imitation learning data for language models is, of course, the internet, right? It's of course, you know, we've people who've gathered all this data on, you know, how we write and so forth. And so aside from that, when we're generating synthetic data, um, there is the only scalable path is really reinforcement learning. The other thing that I'll say here is that when you're collecting data for robotics, um, you can do it in like this teleop way, like it's sort of, um, these are things like the things that we try to are trying to train robots to do are very intuitive for humans as well. I mean, actually more intuitive for humans, right? People are master manipulators, so you can have a lot of kind of teleop-like, um, data collection.\n\n>> The things that we want language models to do, um, are sort of, you know, at the level of, um, it's really hard to collect data of, you know, the chain of thought process that goes on in, like, a human's head, um, when they're trying to solve some task, and that's kind of the data that you need. And so for that reason, I think language models favor this more, like, synthetic data RL-like approach where, um, well, it's easier for us to, like, verify whether the thing was done or not than it is to actually generate all that data from a person specifically.\n\n>> Maybe we just need like a, like a network interface.\n\n>> to get the chance out.\n\n>> Yeah, maybe. I, I mean, that's kind of actually when Jiannis and I were starting the company, we were, we were thinking about, well, what, like, you know, maybe we just, like, yeah, somehow, like, have people speak into a microphone as they're doing tasks, um, in order to capture that.\n\n>> Just stream it.\n\n>> Yeah. And it seemed, um, you know, logistically very hard to pull off.\n\n>> Um, okay, one, uh, one final, uh, uh, question about, um, sort of ReflectionAI's path from here. At what point do you, this is a decision you get to make in the future, but at what point do you try to look at other problems beyond engineering and coding? Um, uh, like, do you, do you feel like there's a level of sufficient depth where you should just go attack different domains?\n\n>> The thing that makes coding as, um, a category special is that it's not, um, it's not synonymous with software engineering. It's just kind of how we think about the market today. The reason code is special is if you believe that, uh, the way a language model will interact with almost any piece of software is through function calls and therefore code, then if you build very capable reasoners, um, coding reasoners that, you know, are sort of purpose-built for organization. So you've solved the kind of long context, how do I reason over a bunch of information, disparate sources of information problem, and I can act on pieces of software through code, then you've kind of built a system, like the technology that, um, will generalize at least operationally across other categories of work. And so the way I think about it is more, first, just build, not trying to get, you know, too ahead of yourself of kind of just first build the kind of most depthwise, comprehensive ion system for, um, software engineers. Uh, this will naturally induce more reliable coding agents. Um, right, you can plug that in as an MCP to your favorite IDE or, um, coding agent. Um, you know, or use, you know, one of our own, um, right, you can kind of plug that into whatever surface area makes sense for the customer and then sort of naturally start seeing where, um, you're getting pulled from there. And the reason I think this will work is because we're, this is kind of what we're already seeing, right, in the, um, you know, how do you make the system useful for product managers, um, or, uh, technical support people, um, and then, you know, I think moving on to things like sales or something like this, but, um, there are already places where, uh, you know, customers are pulling us in different, in, in different directions. It's just kind of a matter of whether you engage on that today or not. And I think that the risk that a startup has is that, you know, you see a lot of shiny areas where you can go, and you start kind of going diffuse before you've really, um, nailed, um, a category. So I think it's really important to be focused and not diffused in a, in the short term, and that if you kind of build the right, as we, we kind of think about as a contextual core for an organization, in this case, an engineering organization, then you can naturally start expanding that into adjacent areas of work in that enterprise.\n\n>> Okay, last question, Misha, where would you characterize us as, like, being on the path toward deployment of these capabilities in, in different fields? I think we're a lot earlier than most people think. Uh, that this is going to be one of those areas where the technological building blocks, um, outpace their deployment. And so, yeah, within the next couple of years, uh, the blueprint roughly for, you know, how to build ASIs will have been set, more or less, like, uh, maybe there are still some, um, efficiency breakthroughs that need to happen. Um, but more or less, there will be a blueprint for how do you build a superintelligence in a particular category, actually going in and deploying it and and building it for, you know, specific categories of work. There are going to be a lot of product and kind of research innovation specific to those categories. Um, that will probably make this a multi-decade thing. Um, so I don't think that it's a couple of years from now and, uh, GDP starts growing 10% um, you know, year-over-year globally. I think we're actually going to get there. Uh, but it's going to be a kind of multi-decade, uh, endeavor. I tend to kind of, um, see a lot of patterns, um, now in kind of real-world deployment with, uh, reinforcement learning, um, research as it worked again before large language models. Um, and before large language models, it used to be you kind of, you pick an environment, like you pick Go, you pick, um, Starcraft, you pick something else, and you go and try to solve it with, you know, some combination of imitation learning and reinforcement learning. And when you look at all those projects, these were basically things that were called strikes within, within DeepMind. Um, and each strike, uh, within and outside of DeepMind is was a bit of a snowflake. Like the reinforcement learning methods and environment setup for Go was at a high level conceptually similar, but in the detailed implementation level, very\n\n\nDifferent from Starcraft, very different from um Dota 5.\nAnd so I think that that's sort of we're going into every big category having a different environment, right?\nAnd different kinds of agents with different tools.\nAnd that means that you'll need to you'll have like general base models that you can start with, but you'll need to post-train things in specific ways for those categories.\nAnd we're starting to see that already in the sense that the model that powers OpenAI's codeex is not the O series of models.\nIt's a model called codeex which was post trained for that environment.\nThe deep research models like that's a specific environment.\nUm they're also postrains for that environment.\nAnd I think we'll basically see more and more of that that any category that has a sufficiently large business around it um that requires an int an intelligence score to power it there will be all sorts of interesting design decisions at the research and product level of how do you actually gain the most performance out of this particular category.\nSo uh I think we'll kind of see a lot more kind of depth first uh players emerge over the coming decade or so.\nI'm making a bet on it.\nAnd I also think that like part of to to your point about choosing like the problem for the era, we don't get to choose at conviction a problem for a hundred years, but we do get to choose for like this decade or so, right?\nAnd and you know if you actually believe it's going to be a very long-term endeavor to get to the sort of productivity and abundance you described but we are going to get there then you know the other thing you think about is like like path to supporting the cost for bringing anything under distribution during a particular period right and so I'd say like in the you know we've already backed companies in in some of these areas but like let's say in life sciences or material science like it is more expensive to collect, you know, types of data you might need.\nAnd that might be a a longer endeavor or one that you have to figure out how to fund, right?\nOr in robotics.\nAnd so, um, I think it's a really interesting timing question of like any of these really big categories.\nBut I believe coding is this era.\n>> I think coding is this era as well.\nUm this one I think will take longer than um people thought as well because again enterprise there's organizational problems just much different uh than um the benchmarks that we have today but I think it will be one of the faster ones.\nSo I don't think that's kind of a decade out that's uh that's within the next um you know say dozen dozens of months kind of thing.\nSo uh I think the the next sort of gen generational companies in in coding um are definitely being built today.\n>> Well, congratulations on the release, Misha.\nThanks.\n>> Yeah, thank you Sarah.\n>> Find us on Twitter at No Priors Pod.\nSubscribe to our YouTube channel if you want to see our faces.\nFollow the show on Apple Podcasts, Spotify, or wherever you listen.\nThat way you get a new episode every week.\nAnd sign up for emails or find transcripts for every episode at no-priers.com.\n",
  "dumpedAt": "2025-07-21T18:43:25.576Z"
}