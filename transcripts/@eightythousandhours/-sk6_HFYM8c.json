{
  "episodeId": "-sk6_HFYM8c",
  "channelSlug": "@eightythousandhours",
  "title": "The cases for and against AGI by 2030 (article by Benjamin Todd)",
  "publishedAt": "2025-05-12T13:38:54.000Z",
  "rawLines": [
    {
      "lang": "en",
      "text": "Hey, this is Benjamin Todd. More and more \npeople have been saying that we might have AGI,  ",
      "offset": 0.48,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "artificial general intelligence, before 2030. \nIs that really plausible? I wrote this article  ",
      "offset": 5.92,
      "duration": 6.48
    },
    {
      "lang": "en",
      "text": "to look into the case for and against and try \nand summarise all the key things you need to  ",
      "offset": 12.4,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "know about that argument. I definitely \ndon't think it's guaranteed to happen,  ",
      "offset": 16.64,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "but I think you can make a surprisingly good \nargument for it. That's what we're going to  ",
      "offset": 20.96,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "dive into here. You can see all the images \nand many footnotes in the original article.",
      "offset": 25.52,
      "duration": 7.6
    },
    {
      "lang": "en",
      "text": "The Case for AGI by 2030.",
      "offset": 33.12,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "In recent months, the CEOs of leading AI \ncompanies have grown increasingly confident  ",
      "offset": 36.4,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "about rapid progress. In November, OpenAI's \nSam Altman went from saying he expects the  ",
      "offset": 40.64,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "rate of progress continues to by January, we \nare now confident we know how to build AGI.",
      "offset": 46.08,
      "duration": 6.64
    },
    {
      "lang": "en",
      "text": "Also in January, Anthropic CEO Dario Amodei \nsaid, I'm more confident than I've ever been  ",
      "offset": 52.72,
      "duration": 5.92
    },
    {
      "lang": "en",
      "text": "that we're close to powerful capabilities \nin the next two to three years. Google  ",
      "offset": 58.64,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "DeepMind's more cautious CEO, Demis \nHassabis, has switched from saying as  ",
      "offset": 63.04,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "soon as 10 years in autumn to by January \nwe're probably three to five years away.",
      "offset": 66.96,
      "duration": 6.16
    },
    {
      "lang": "en",
      "text": "What explains this shift? Is it just \nhype or could we really have AGI by 2030?  ",
      "offset": 73.12,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "In this article I look at the \nfour drivers of recent progress,  ",
      "offset": 79.76,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "estimate how far those drivers can continue, \nand explain why they're likely to continue for  ",
      "offset": 83.68,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "at least four more years. And that means we should \nexpect major additional AI progress in that time.",
      "offset": 88.56,
      "duration": 6.56
    },
    {
      "lang": "en",
      "text": "In particular, while in 2024 progress in \nLLM chatbots seemed to slow, a new approach  ",
      "offset": 95.12,
      "duration": 6.48
    },
    {
      "lang": "en",
      "text": "started to work, teaching the models to reason \nusing what's called reinforcement learning,  ",
      "offset": 101.6,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "which I'll explain later in the article. In \njust a year, this technique let them surpass  ",
      "offset": 106.4,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "human PhDs at answering difficult scientific \nreasoning questions and achieve expert level  ",
      "offset": 112.16,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "performance on one hour coding tasks. We \ndon't know how capable AI will become,  ",
      "offset": 117.52,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "but just extrapolating the recent rate of \nprogress suggests that by 2028 we could reach  ",
      "offset": 122.4,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "AI models with beyond human reasoning abilities, \nexpert level knowledge of every domain, and that  ",
      "offset": 127.6,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "can autonomously complete multi week projects, \nand progress would likely continue from there.  ",
      "offset": 133.04,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "No longer just chatbots, these agent models \ncould satisfy many people's definitions of AGI,  ",
      "offset": 138.96,
      "duration": 6.16
    },
    {
      "lang": "en",
      "text": "roughly AI systems that match human \nperformance at almost all knowledge work.  \n  ",
      "offset": 145.12,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "I give a much more detailed \ndefinition of AGI in the footnotes.",
      "offset": 149.76,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "This would mean that while the company CEOs are \nprobably a bit overoptimistic, there's enough  ",
      "offset": 153.36,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "evidence to take their position very seriously, \nand it's also important not to get caught up  ",
      "offset": 158.32,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "in definitions. Ultimately, what matters is that \nthese models could start to accelerate AI research  ",
      "offset": 162.8,
      "duration": 5.92
    },
    {
      "lang": "en",
      "text": "itself, unlocking vastly greater numbers of more \ncapable AI workers. And then in turn, sufficient  ",
      "offset": 168.72,
      "duration": 6.4
    },
    {
      "lang": "en",
      "text": "automation could trigger explosive economic \ngrowth and 100 years of scientific progress  ",
      "offset": 175.12,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "in 10 -- a transition society isn't prepared \nfor. While all this might sound outlandish,  ",
      "offset": 180,
      "duration": 6.64
    },
    {
      "lang": "en",
      "text": "it's within the range of possibilities \nthat many experts think is possible.  ",
      "offset": 186.64,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "This article aims to give you a primer on what you \nneed to know to understand why they think that,  ",
      "offset": 191.04,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "and also the best arguments against that position.",
      "offset": 196,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "I've been writing about AGI since 2014. Back \nthen, AGI arriving within five years seemed  ",
      "offset": 199.6,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "very unlikely, but today the situation seems \ndramatically different. We can see the outlines  ",
      "offset": 205.6,
      "duration": 6.24
    },
    {
      "lang": "en",
      "text": "of how AGI might work and exactly who could \nbuild it, and in fact, the next five years  ",
      "offset": 211.84,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "seems unusually crucial. The basic drivers of AI \nprogress, investments in computational power and  ",
      "offset": 217.44,
      "duration": 6.8
    },
    {
      "lang": "en",
      "text": "algorithmic research, cannot continue increasing \nat current rates much beyond 2030. That means that  ",
      "offset": 224.24,
      "duration": 6.48
    },
    {
      "lang": "en",
      "text": "we either reach AI systems capable of triggering \nan acceleration soon, or progress will most likely  ",
      "offset": 230.72,
      "duration": 5.92
    },
    {
      "lang": "en",
      "text": "slow significantly. Either way, the next five \nyears is when we'll find out. Let's see why.",
      "offset": 236.64,
      "duration": 7.44
    },
    {
      "lang": "en",
      "text": "The article in a nutshell. Four key factors \nare driving AI progress: larger base models,  ",
      "offset": 244.08,
      "duration": 6.88
    },
    {
      "lang": "en",
      "text": "teaching models to reason, increasing how \nlong models think about each question,  ",
      "offset": 250.96,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "and building agent scaffolding \nfor multi step tasks.  \n  ",
      "offset": 255.52,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "These in turn are underpinned by increasing \ncomputational power to run and train AI systems,  ",
      "offset": 259.44,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "as well as increasing human capital \ngoing into algorithmic research.  ",
      "offset": 264.96,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "All of these drivers are set to continue until \n2028 and perhaps until 2032. This means in that  ",
      "offset": 269.84,
      "duration": 7.68
    },
    {
      "lang": "en",
      "text": "time we should expect major further advances \nin AI performance. We don't know how large  ",
      "offset": 277.52,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "these advances will be, but extrapolating \nrecent trends on benchmarks suggests that  ",
      "offset": 282.88,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "we'll reach systems with beyond human performance \nin coding and scientific reasoning and that can  ",
      "offset": 288,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "autonomously complete multi week projects. \nWhether we call these systems AGI or not,  ",
      "offset": 292.88,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "they could be sufficient to enable AI research \nitself, robotics, the technology industry,  ",
      "offset": 298.32,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "and scientific research all to accelerate, \nleading to transformative impacts on society.  \n  ",
      "offset": 303.84,
      "duration": 6.88
    },
    {
      "lang": "en",
      "text": "Alternatively, AI might fail to overcome \nissues with ill defined high context work  ",
      "offset": 310.72,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "over long time horizons and remain a tool \neven if much improved compared to today.  ",
      "offset": 315.76,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "Increasing AI performance requires exponential \ngrowth and investment in the research workforce.  ",
      "offset": 321.6,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "At current rates, we will likely start to reach \nbottlenecks around 2030. Simplifying a bit,  ",
      "offset": 327.36,
      "duration": 6.16
    },
    {
      "lang": "en",
      "text": "that means we'll either likely reach AGI by \naround 2030 or see progress slow significantly.",
      "offset": 333.52,
      "duration": 6.96
    },
    {
      "lang": "en",
      "text": "Hybrid scenarios are also possible, but the \nnext five years seems especially crucial.",
      "offset": 340.48,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "Section 1: What's driven recent \nAI progress and will it continue?",
      "offset": 346.96,
      "duration": 5.92
    },
    {
      "lang": "en",
      "text": "Entering the deep learning era.",
      "offset": 352.88,
      "duration": 2.72
    },
    {
      "lang": "en",
      "text": "In 2022, Yann LeCun, the chief AI scientist \nat Meta and Turing Award winner, said,  ",
      "offset": 355.6,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "and I'm sorry I can't do a French accent. \n“I take an object, I put it on the table,  ",
      "offset": 360.88,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "and I push the table. It’s completely \nobvious to you that the object will be  ",
      "offset": 365.6,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "pushed with the table…There’s no text in the \nworld I believe that explains this. If you  ",
      "offset": 369.76,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "train a machine as powerful as could be…your \nGPT-5000, it’s never gonna learn about this.”",
      "offset": 375.2,
      "duration": 6.08
    },
    {
      "lang": "en",
      "text": "But within just two months of LeCun's statement, \nGPT-3.5 could answer this easily. And that's not  ",
      "offset": 381.28,
      "duration": 6.72
    },
    {
      "lang": "en",
      "text": "the only example of experts being wrong \nfooted. Before 2011, AI was famously  ",
      "offset": 388,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "dead. But that totally changed when conceptual \ninsights from the ‘70s and ‘80s combined with  ",
      "offset": 393.2,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "massive amounts of data and computing power to \nproduce the deep learning paradigm. Since then,  ",
      "offset": 398.88,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "we've repeatedly seen AI systems going from total \nincompetence to greater than human performance in  ",
      "offset": 404.56,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "many tasks within just a couple of years. For \nexample, in 2022, Midjourney could not draw an  ",
      "offset": 410,
      "duration": 6.4
    },
    {
      "lang": "en",
      "text": "otter on a plane using Wifi. But just two years \nlater, Veo 2 can make a hyperrealistic movie.  \n  ",
      "offset": 416.4,
      "duration": 6.96
    },
    {
      "lang": "en",
      "text": "In 2019, GPT-2 could just about stay on topic for \na couple of paragraphs, and that was considered  ",
      "offset": 423.36,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "remarkable progress at the time. Critics like \nLeCun were quick to point out that GPT-2 couldn't  ",
      "offset": 428.88,
      "duration": 5.84
    },
    {
      "lang": "en",
      "text": "reason, show common sense, exhibit understanding \nof the physical world, and so on. But many of  ",
      "offset": 434.72,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "these limitations were overcome within just a \ncouple of years. Over and over again, it's been  ",
      "offset": 440.48,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "dangerous to bet against deep learning. Today, \neven LeCun says he expects AGI in several years.",
      "offset": 445.84,
      "duration": 6.64
    },
    {
      "lang": "en",
      "text": "And the limitations of current systems aren't what  ",
      "offset": 452.48,
      "duration": 2.16
    },
    {
      "lang": "en",
      "text": "to focus on anyway. The more interesting \nquestion is where might this be heading?  ",
      "offset": 454.64,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "What explains the leap from GPT-2 to 4, \nand could we see another leap like that?",
      "offset": 459.52,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "So what's coming up? At the broadest \nlevel, AI progress has been driven  ",
      "offset": 465.2,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "by more computational power, called compute, and \nbetter algorithms. Both are improving rapidly.  \n  ",
      "offset": 469.2,
      "duration": 6.64
    },
    {
      "lang": "en",
      "text": "More specifically, we can break down \nrecent progress into four key drivers,  ",
      "offset": 475.84,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "which I'll explain through \nthe rest of the article.",
      "offset": 480.08,
      "duration": 2.72
    },
    {
      "lang": "en",
      "text": "The first is called scaling pre-training. \nThat lets you create a base model with  ",
      "offset": 482.8,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "basic intelligence, a basic \nunderstanding of the world.",
      "offset": 487.84,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "Secondly is using reinforcement learning \nto teach that base model to reason about  ",
      "offset": 491.28,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "complicated problems like in maths and coding.",
      "offset": 496.4,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "Third is having the model think longer about each  ",
      "offset": 500.08,
      "duration": 2.88
    },
    {
      "lang": "en",
      "text": "question or each problem it's posed. This \nis called increasing test time compute.",
      "offset": 502.96,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "And then fourth is building an \nagent scaffolding around that  ",
      "offset": 508.72,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "model which lets it complete complex \ntasks and take actions in the world.",
      "offset": 512.24,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "In the rest of this section, I'll explain how each \nof these works and try to project them forward. As  ",
      "offset": 517.36,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "GPT would say, delve in and you'll understand \nthe basics of how AI is being improved.  \n  ",
      "offset": 522.56,
      "duration": 5.92
    },
    {
      "lang": "en",
      "text": "Then in section 2, I'll use this \nto forecast future AI progress,  ",
      "offset": 528.48,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "and then finally explain why it makes \nthe next five years especially crucial.",
      "offset": 532.8,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "So the first driver: scaling pre-training to \ncreate base models with basic intelligence.  ",
      "offset": 538,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "People often imagine that AI progress \nrequires huge intellectual breakthroughs,  ",
      "offset": 543.92,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "but a lot of it is more like engineering: just do \na lot more of the same and the models get better.  ",
      "offset": 547.92,
      "duration": 6.32
    },
    {
      "lang": "en",
      "text": "In the leap from GPT-2 to 4, the biggest driver \nof progress was just applying dramatically more  ",
      "offset": 554.24,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "computational power to the same techniques, \nespecially to what's called pre-training.",
      "offset": 559.28,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "Modern AI works by using artificial neural \nnets involving billions of interconnected  ",
      "offset": 564.48,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "parameters organised into layers. \nDuring pre-training -- a misleading  ",
      "offset": 569.28,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "name which simply means it's the first \ntype of training -- here's what happens: ",
      "offset": 574.08,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "Data is fed into the network, \nsuch as the image of a cat. ",
      "offset": 578.96,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "The values of the parameters in that neural net \nthen convert that data into a predicted output,  ",
      "offset": 583.12,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "such as a description, This is a cat.\nThe accuracy of those outputs is graded  ",
      "offset": 588.88,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "versus the reference data.\nThen the model's parameters  ",
      "offset": 594.4,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "are adjusted in a way that's expected to \nincrease the accuracy of those predictions.",
      "offset": 598.08,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "This is repeated over and over with trillions \nof pieces of data until the model becomes  ",
      "offset": 603.84,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "better and better at predicting accurately. This \nmethod has been used to train all kinds of AI,  ",
      "offset": 608.16,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "but it's been most useful when used to predict \nlanguage. The data is the text on the internet,  ",
      "offset": 613.6,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "and LLMs are trained to predict gaps in that \ntext. More computational power for training,  ",
      "offset": 619.28,
      "duration": 6.48
    },
    {
      "lang": "en",
      "text": "so-called training compute, means that \nyou can use more parameters, which means  ",
      "offset": 625.76,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "the model can learn more sophisticated \nand more abstract patterns in the data.",
      "offset": 630,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "It also means you can just use more data for \ntraining. Since we entered the deep learning  ",
      "offset": 634.88,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "era around 2011, the number of \ncalculations used to train AI  ",
      "offset": 639.84,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "models has been growing at a staggering \nrate, more than four times per year.  ",
      "offset": 644.16,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "That's the amount of additional computing power \nused for training the largest AI model each year.  ",
      "offset": 649.12,
      "duration": 5.92
    },
    {
      "lang": "en",
      "text": "This in turn has been enabled by spending far more \nmoney, as well as using much more efficient chips.",
      "offset": 655.04,
      "duration": 6.16
    },
    {
      "lang": "en",
      "text": "Historically, each time training \ncompute has increased 10 times,  ",
      "offset": 661.2,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "there's been a steady gain in performance \nacross many tasks and benchmarks. For example,  ",
      "offset": 665.04,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "as training compute has grown a thousandfold, \nAI models have steadily improved at answering  ",
      "offset": 669.92,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "diverse questions, from common sense reasoning to \nunderstanding social situations and physics. This  ",
      "offset": 675.12,
      "duration": 6.96
    },
    {
      "lang": "en",
      "text": "is demonstrated on the BIG-Bench Hard benchmark. \nThis is a benchmark of diverse questions  ",
      "offset": 682.08,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "specifically chosen to challenge LLMs.  \n \nIn the article you can see a graph showing  ",
      "offset": 687.6,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "a linear increase in performance as \ntraining compute is scaled up. Likewise,  ",
      "offset": 692.56,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "OpenAI created a coding model that could solve \nsimple coding problems. Then they used 100,000  ",
      "offset": 697.76,
      "duration": 5.84
    },
    {
      "lang": "en",
      "text": "times more compute to train an improved version. \nThey showed that as training compute increased,  ",
      "offset": 703.6,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "the model correctly answered progressively more \ndifficult questions. These test problems weren't  ",
      "offset": 709.2,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "in the original training data, so this wasn't \nmerely better searched through memorised problems.",
      "offset": 714.64,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "This relationship between training computes \nand performance is called a scaling law.  ",
      "offset": 720.16,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "Papers about these laws have been published \nby 2020. To those following this research,  ",
      "offset": 724.64,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "GPT-4 wasn't a surprise. It was \njust a continuation of trend.",
      "offset": 729.68,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "The second contribution to pretraining is \nalgorithmic efficiency. Training compute has  ",
      "offset": 734.96,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "not only increased, but researchers have found far \nmore efficient ways to use it. Every two years,  ",
      "offset": 739.92,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "the compute needed to get the same performance \nacross a wide range of models has decreased  ",
      "offset": 745.92,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "tenfold. In the article I show the example of \nimage recognition algorithms. The amount of  ",
      "offset": 750.24,
      "duration": 6.24
    },
    {
      "lang": "en",
      "text": "compute to get the same accuracy at recognising \nimages has decreased roughly 10 times every two  ",
      "offset": 756.48,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "years. But a very similar pattern applies \nacross a wide range of algorithms. These  ",
      "offset": 762.48,
      "duration": 6.16
    },
    {
      "lang": "en",
      "text": "gains usually make the models much cheaper to \nrun. DeepSeek-V3 was reported in the media as  ",
      "offset": 768.64,
      "duration": 5.92
    },
    {
      "lang": "en",
      "text": "a revolutionary efficiency breakthrough, but in \nfact it was roughly on this preexisting trend.  ",
      "offset": 774.56,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "It was released roughly two years after GPT-4 and \nit's about 10 times more efficient than GPT-4.",
      "offset": 780.56,
      "duration": 6.32
    },
    {
      "lang": "en",
      "text": "Now, algorithmic efficiency means that not only \nis four times as much compute used on training  ",
      "offset": 786.88,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "each year, but also that compute goes about three \ntimes further each year. The two effects multiply  ",
      "offset": 792.24,
      "duration": 6.64
    },
    {
      "lang": "en",
      "text": "together to mean that effective compute has \nincreased around 12 times each year. This is  ",
      "offset": 798.88,
      "duration": 5.84
    },
    {
      "lang": "en",
      "text": "an insane rate of increase. For instance, \nthe famous Moore's law about semiconductor  ",
      "offset": 804.72,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "efficiency is only 35% growth per year. This \nAI growth is over 10 times as large. That means  ",
      "offset": 809.36,
      "duration": 7.76
    },
    {
      "lang": "en",
      "text": "that the computer chips that were used to train \nGPT-4 over three months could have been used to  ",
      "offset": 817.12,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "train the model with the performance of GPT-2 \nabout 300,000 times over just four years later.",
      "offset": 822.32,
      "duration": 6.72
    },
    {
      "lang": "en",
      "text": "This increase in effective compute took \nus from a model that was just about able  ",
      "offset": 829.6,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "to string some sentences together to \nGPT-4 being able to do things like: ",
      "offset": 834.24,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "Beat most high schoolers at college entrance exams\nConverse in natural language -- which in the long  ",
      "offset": 838.96,
      "duration": 5.557
    },
    {
      "lang": "en",
      "text": "forgotten past was considered a mark of \ntrue intelligence called the Turing Test ",
      "offset": 844.517,
      "duration": 4.763
    },
    {
      "lang": "en",
      "text": "Solve the Winograd schemas, a \ntest of common sense reasoning  ",
      "offset": 849.28,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "that in the 2010s was regarded \nas requiring true understanding ",
      "offset": 852.56,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "And create art that most people can't \ndistinguish from the human produced stuff.",
      "offset": 856.8,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "So how much further can this driver \nof progress, pretraining, continue  ",
      "offset": 862.4,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "to scale? If current trends continue, then by \naround 2028 someone will have trained a model  ",
      "offset": 866.16,
      "duration": 6.48
    },
    {
      "lang": "en",
      "text": "with 300,000 times more effective compute than \nGPT-4. That's the same as the increase that we  ",
      "offset": 872.64,
      "duration": 6.24
    },
    {
      "lang": "en",
      "text": "saw from GPT-2 to 4. So if that was spent on \npretraining, we could call that hypothetical  ",
      "offset": 878.88,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "model GPT-6. And so far we seem to be on \nthat trend. GPT-4.5 was released in early  ",
      "offset": 884.56,
      "duration": 7.2
    },
    {
      "lang": "en",
      "text": "2025 and forecasters expect a GPT-5 size model \nto be released in the second half of the year.",
      "offset": 891.76,
      "duration": 7.44
    },
    {
      "lang": "en",
      "text": "Can the trend continue all the way to GPT-6? The \nCEO of Anthropic, Dario Amodei, projects that a  ",
      "offset": 899.2,
      "duration": 7.12
    },
    {
      "lang": "en",
      "text": "GPT-6 size model will cost about $10 billion to \ntrain. That's expensive, but still affordable for  ",
      "offset": 906.32,
      "duration": 6.4
    },
    {
      "lang": "en",
      "text": "companies like Google, Microsoft, and Meta, which \nearn $50 to $100 billion in profits each year. In  ",
      "offset": 912.72,
      "duration": 6.88
    },
    {
      "lang": "en",
      "text": "fact, these companies are already building \ndata centres big enough for such training  ",
      "offset": 919.6,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "runs. And that was before the hundred billion \ndollar plus Stargate project was announced.",
      "offset": 922.8,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "In addition, frontier models are already \ngenerating over $10 billion of revenue,  ",
      "offset": 928.32,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "and that has been more than tripling each \nyear. So soon AI revenue alone will be able  ",
      "offset": 933.28,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "to pay for a $10 billion training run. I'll \ndiscuss what could bottleneck this process  ",
      "offset": 938.56,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "more later. But the most plausible bottleneck \nis training data. GPT-4 already used the most  ",
      "offset": 943.92,
      "duration": 6.4
    },
    {
      "lang": "en",
      "text": "easily accessible data on the internet for \ntraining, and we only have one internet.  \n  ",
      "offset": 950.32,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "However, the best analysis I've found, \nby Epoch AI, suggests that there will  ",
      "offset": 955.6,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "be enough data to carry out a GPT-6 training \nrun by 2028. And even if that isn't the case,  ",
      "offset": 960.16,
      "duration": 6.4
    },
    {
      "lang": "en",
      "text": "it's no longer crucial -- because the AI companies  ",
      "offset": 966.56,
      "duration": 2.8
    },
    {
      "lang": "en",
      "text": "have discovered a way to circumvent the \ndata bottleneck, as I'll explain next.",
      "offset": 969.36,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "So the second driver of progress is training the \nmodels to reason with reinforcement learning.  ",
      "offset": 975.36,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "People often say ChatGPT is just predicting the \nnext word, but that's never been quite true.  ",
      "offset": 980.96,
      "duration": 5.84
    },
    {
      "lang": "en",
      "text": "Raw prediction of words from the internet \nproduces outputs that are regularly crazy,  ",
      "offset": 986.8,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "as you might expect given that it's the \nInternet. GPT only became truly useful  ",
      "offset": 991.12,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "with the addition of reinforcement learning \nfrom human feedback, RLHF. In this process,  ",
      "offset": 996.64,
      "duration": 6.72
    },
    {
      "lang": "en",
      "text": "outputs from the base model are \nshown to human raters. Then secondly,  ",
      "offset": 1003.36,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "the raters are asked to judge which are most \nuseful. Then third, the model is adjusted in a  ",
      "offset": 1007.92,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "way that's expected to produce more outputs like \nthe helpful ones, which is called reinforcement.",
      "offset": 1013.04,
      "duration": 6.48
    },
    {
      "lang": "en",
      "text": "A model that's undergone RLHF isn't \njust predicting the next token,  ",
      "offset": 1019.52,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "it's predicting what human \nraters will find most helpful.  ",
      "offset": 1024.4,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "You can think of the initial LLM as providing a \nfoundation of conceptual structure, but RLHF is  ",
      "offset": 1028.16,
      "duration": 6.16
    },
    {
      "lang": "en",
      "text": "essential for directing that structure towards \na particular useful end. RLHF is just one form  ",
      "offset": 1034.32,
      "duration": 6.48
    },
    {
      "lang": "en",
      "text": "of post training. Post training is named because \nit happens after pretraining, though in fact both  ",
      "offset": 1040.8,
      "duration": 5.92
    },
    {
      "lang": "en",
      "text": "are simply types of training. There are many \nother kinds of post training enhancements,  ",
      "offset": 1046.72,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "including things as simple as letting the \nmodel access a calculator or the internet.",
      "offset": 1051.68,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "But there's one that's especially crucial \nright now: reinforcement learning to train  ",
      "offset": 1056.64,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "the models to reason. The idea is that instead of \ntraining the model to do what humans find helpful,  ",
      "offset": 1060.96,
      "duration": 6.24
    },
    {
      "lang": "en",
      "text": "it's trained to correctly answer \nproblems. Here's the process: ",
      "offset": 1067.2,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "Show the model a problem with a \nverifiable answer, like a math puzzle. ",
      "offset": 1072.32,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "Ask it to produce a chain of reasoning to solve \nthat problem, which is called chain of thought. ",
      "offset": 1076.4,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "If the answer is correct, adjust the model \nin a way that's expected to produce more  ",
      "offset": 1081.68,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "outputs like that: reinforcement.\nRepeat that process over and over.",
      "offset": 1085.84,
      "duration": 6.16
    },
    {
      "lang": "en",
      "text": "This process teaches the LLM to construct \nlong chains of hopefully correct reasoning  ",
      "offset": 1092,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "about logical problems. Before 2023, this \ndidn't really seem to work. That's because  ",
      "offset": 1096.8,
      "duration": 6.16
    },
    {
      "lang": "en",
      "text": "if each step of reasoning is too unreliable, \nthe chains quickly go wrong. And if you can't  ",
      "offset": 1102.96,
      "duration": 5.92
    },
    {
      "lang": "en",
      "text": "even get close to a right answer, then you \ncan't give the model any reinforcement.  \n  ",
      "offset": 1108.88,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "But in 2024, just as many were saying that AI \nprogress had stalled, this new paradigm was  ",
      "offset": 1114.16,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "in fact starting to take off. Consider the GPQA \nDiamond benchmark, a set of scientific questions  ",
      "offset": 1120.16,
      "duration": 7.28
    },
    {
      "lang": "en",
      "text": "designed so that people with PhDs in the field \ncan mostly answer them but non experts can't,  ",
      "offset": 1127.44,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "even with 30 minutes of access to Google. \nIt contains questions like advanced quantum  ",
      "offset": 1133.44,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "physics that I can't make any sense of, \neven though I studied physics at university.",
      "offset": 1138.88,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "In 2023, GPT-4 performed only slightly better \nthan random guessing on this benchmark. That  ",
      "offset": 1143.84,
      "duration": 6.4
    },
    {
      "lang": "en",
      "text": "means it could handle the reasoning required \nfor high school level science problems,  ",
      "offset": 1150.24,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "but it couldn't manage PhD level reasoning. \nHowever, in October 2024, OpenAI took the GPT-4o  ",
      "offset": 1154.32,
      "duration": 8.16
    },
    {
      "lang": "en",
      "text": "base model and used reinforcement learning \nto create o1. o1 achieved 70% accuracy at  ",
      "offset": 1162.48,
      "duration": 7.12
    },
    {
      "lang": "en",
      "text": "this benchmark, making it about equal to PhDs in \nthe relevant field at answering these questions.",
      "offset": 1169.6,
      "duration": 6.96
    },
    {
      "lang": "en",
      "text": "It's no longer tenable to claim these models \nare just regurgitating their training data.  ",
      "offset": 1176.56,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "Neither the answers nor the chains of reasoning \nrequired to produce them exist on the internet.  ",
      "offset": 1181.2,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "Most people aren't answering PhD level \nscience questions in their daily life,  ",
      "offset": 1186.8,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "so they simply haven't noticed this progress. \nThey still think of LLMs as basic chatbots.",
      "offset": 1190.64,
      "duration": 5.92
    },
    {
      "lang": "en",
      "text": "And it turns out o1 was just the start. \nAt the beginning of a new paradigm,  ",
      "offset": 1196.56,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "it's possible to get gains especially quickly. \nJust three months after o1, OpenAI released  ",
      "offset": 1201.36,
      "duration": 6.48
    },
    {
      "lang": "en",
      "text": "results from o3. o3 is the second version. It's \nnamed that because O2 is a telecom company.  ",
      "offset": 1207.84,
      "duration": 6.32
    },
    {
      "lang": "en",
      "text": "But please don't ask me to explain any other \npart of OpenAI's model-naming practices.  \n  ",
      "offset": 1214.16,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "o3 is probably just o1, but with even \nmore reinforcement learning and another  ",
      "offset": 1219.12,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "change I'll explain shortly. o3 surpassed \nhuman-level expert performance on GPQA. Now,  ",
      "offset": 1224.08,
      "duration": 7.12
    },
    {
      "lang": "en",
      "text": "reinforcement learning should be most useful \nfor problems that have verifiable answers,  ",
      "offset": 1231.2,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "such as in science, maths and coding. And in fact \no3 performs much better in all of these areas  ",
      "offset": 1235.52,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "than its base model GPT-4o. Most benchmarks \nof maths questions have now been saturated,  ",
      "offset": 1241.28,
      "duration": 6.72
    },
    {
      "lang": "en",
      "text": "which means that leading models can \nget basically every question right.",
      "offset": 1248,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "In response, the research group Epoch AI created \nFrontier Math, a benchmark of insanely hard  ",
      "offset": 1252.64,
      "duration": 6.24
    },
    {
      "lang": "en",
      "text": "mathematical problems. The easiest 20% \nare similar to Olympiad level problems.  ",
      "offset": 1258.88,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "The most difficult are, according to Fields \nMedalist Terence Tao, extremely challenging.  ",
      "offset": 1264.16,
      "duration": 5.84
    },
    {
      "lang": "en",
      "text": "They would typically need an expert in \nthat branch of mathematics to solve them.",
      "offset": 1270,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "Previous models, including o1, could hardly solve \nany of these questions. But in December 2024,  ",
      "offset": 1274.4,
      "duration": 7.2
    },
    {
      "lang": "en",
      "text": "OpenAI tested a version of o3 \nwith better scaffolding than  ",
      "offset": 1281.6,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "the now publicly released version, \nwhich they claimed could solve 25%.  ",
      "offset": 1285.04,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "More recent testing of Google's Gemini 2.5 after \nthis article was released showed that it could  ",
      "offset": 1290.16,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "solve about 20% of problems on the Maths Olympiad, \nso it would be about in line with these results.",
      "offset": 1295.28,
      "duration": 6.16
    },
    {
      "lang": "en",
      "text": "At the time, these results went entirely \nunreported in the media. In fact, on the  ",
      "offset": 1301.44,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "very day of the o3 results, the Wall Street \nJournal was running a story about how GPT-5  ",
      "offset": 1306.32,
      "duration": 5.92
    },
    {
      "lang": "en",
      "text": "was behind and expensive. But this misses the \ncrucial point that GPT-5 is no longer necessary.  ",
      "offset": 1312.24,
      "duration": 7.04
    },
    {
      "lang": "en",
      "text": "A new paradigm has started which can make even \nfaster gains than before, even without GPT-5.",
      "offset": 1319.28,
      "duration": 7.44
    },
    {
      "lang": "en",
      "text": "In January, DeepSeek replicated many of \no1's results. Their paper revealed that  ",
      "offset": 1326.72,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "even basically the simplest possible version of \nthe process works. That suggests there's a huge  ",
      "offset": 1332.4,
      "duration": 5.84
    },
    {
      "lang": "en",
      "text": "amount more to try. DeepSeek R1 also reveals \nits entire chain of reasoning to the user,  ",
      "offset": 1338.24,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "and from that we can see its sophistication \nand surprisingly human quality. It'll  ",
      "offset": 1344.8,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "reflect on its answers, backtrack when wrong, \nconsider multiple hypotheses, have insights,  ",
      "offset": 1349.68,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "and more. All of this behaviour emerges \nout of simple reinforcement learning.",
      "offset": 1354.88,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "OpenAI researcher Sabastian Bubeck observed, \n“No tactic was given to the model. Everything  ",
      "offset": 1360.56,
      "duration": 5.84
    },
    {
      "lang": "en",
      "text": "is emergent. Everything is learned through \nreinforcement learning. This is insane.”",
      "offset": 1366.4,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "The compute for the reinforcement learning \nstage of training DeepSeek R1 likely only  ",
      "offset": 1371.92,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "cost about $1 million. If that keeps working, \nthen OpenAI, Anthropic, and Google could now  ",
      "offset": 1376.4,
      "duration": 6.32
    },
    {
      "lang": "en",
      "text": "spend billions of dollars on the same process, \napproximately a 1000 times scaleup. One reason  ",
      "offset": 1382.72,
      "duration": 6.56
    },
    {
      "lang": "en",
      "text": "this is possible is that the models generate \ntheir own data. This might sound circular,  ",
      "offset": 1389.28,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "and the idea that synthetic data causes model \ncollapse has been widely discussed, but there's  ",
      "offset": 1394.8,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "nothing circular in this case. You can ask o1 \nto solve 100,000 math problems and then only  ",
      "offset": 1400.32,
      "duration": 6.48
    },
    {
      "lang": "en",
      "text": "take the cases where it got the right answer, \nand then use those to train the next model.",
      "offset": 1406.8,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "Because the solutions can be quickly verified, \nyou've generated more examples of genuinely  ",
      "offset": 1412.16,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "good reasoning. And in fact this data is \nmuch higher quality than the data you'll  ",
      "offset": 1416.96,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "find on the internet because it contains that \nwhole chain of reasoning and it's known to be  ",
      "offset": 1421.68,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "correct. Not something the internet is famous \nfor. This potentially creates a flywheel. Have  ",
      "offset": 1426.48,
      "duration": 6.32
    },
    {
      "lang": "en",
      "text": "your model solve a bunch of problems, use \nthose solutions to train the next model,  ",
      "offset": 1432.8,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "the next model can solve even harder problems, \nthat generates even more solutions, and so on.  \n  ",
      "offset": 1437.6,
      "duration": 5.92
    },
    {
      "lang": "en",
      "text": "If the models can already perform PhD level \nreasoning, the next stage would be researcher  ",
      "offset": 1444.96,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "level reasoning and then generating novel \ninsights. This likely explains the unusually  ",
      "offset": 1449.84,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "optimistic statements from the AI company leaders \nthat I mentioned at the start. Sam Altman's  ",
      "offset": 1455.12,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "shift in opinion coincides exactly with the o3 \nrelease in December 2024. Although most powerful  ",
      "offset": 1460.16,
      "duration": 6.32
    },
    {
      "lang": "en",
      "text": "in verifiable domains, the reasoning skills \ndeveloped will probably generalise at least a bit.  ",
      "offset": 1466.48,
      "duration": 6.08
    },
    {
      "lang": "en",
      "text": "It's common to see an AI model get \nreasoning training in one domain,  ",
      "offset": 1472.56,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "like coding problems, and then also \nimprove in other domains that weren't  ",
      "offset": 1476.08,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "part of that training process. In more fuzzy \ndomains, like business strategy or writing,  ",
      "offset": 1480.16,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "it's harder to quickly judge success. So the \nprocess of reinforcement learning will take  ",
      "offset": 1485.28,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "longer. But we should expect it to work \nto some degree, and it's a major focus of  ",
      "offset": 1489.68,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "the companies right now. Exactly how well it \nwill work is a crucial question going forward.",
      "offset": 1494.24,
      "duration": 7.44
    },
    {
      "lang": "en",
      "text": "The third driver of progress: \nincreasing how long models think.",
      "offset": 1501.68,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "If you could only think about a problem for a \nminute, you probably wouldn't get very far. If  ",
      "offset": 1506.72,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "you could think for a month, you'd make a lot more \nprogress, even though your raw intelligence isn't  ",
      "offset": 1511.76,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "higher. LLMs used to be unable to think about \na problem for more than about a minute before  ",
      "offset": 1517.28,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "mistakes would compound or they would drift off \ntopic, which really limited what they could do.  ",
      "offset": 1522.88,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "But as models have become more reliable at \nreasoning, they've become better at thinking  ",
      "offset": 1527.92,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "for longer. OpenAI showed that you can have o1 \nthink 100 times longer than normal and get linear  ",
      "offset": 1532.48,
      "duration": 6.48
    },
    {
      "lang": "en",
      "text": "increases in accuracy on coding problems. \nThis is called using test time compute:  ",
      "offset": 1538.96,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "compute spent when the model is \nbeing run rather than trained.  \n  ",
      "offset": 1544.72,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "If GPT-4o could think usefully for about a minute, \no1 and DeepSeek seem like they can think for the  ",
      "offset": 1548.56,
      "duration": 7.12
    },
    {
      "lang": "en",
      "text": "equivalent of about an hour. As reasoning models \nget more reliable, they will be able to think for  ",
      "offset": 1555.68,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "longer and longer. At current rates, we'll soon \nhave models that can think for a month and then  ",
      "offset": 1560.88,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "a year. It's particularly intriguing to consider \nwhat happens if they could think indefinitely.  ",
      "offset": 1565.92,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "That would mean that given sufficient compute, \nand assuming progress is possible in principle,  ",
      "offset": 1571.52,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "they could continuously improve \ntheir answers to any question.",
      "offset": 1576.64,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "Using more test time compute \ncan be used to solve problems  ",
      "offset": 1580.8,
      "duration": 2.8
    },
    {
      "lang": "en",
      "text": "via brute force. One technique \nis to try to solve a problem 10,  ",
      "offset": 1583.6,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "100 or 1000 times and then to pick the \nsolution with the most votes. This is probably  ",
      "offset": 1587.76,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "another way that o3 was able to beat o1.  \n \nThe immediate practical upshot of all this  ",
      "offset": 1593.04,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "is that you can pay more to get more advanced \ncapabilities earlier. Quantitatively, in 2026,  ",
      "offset": 1597.92,
      "duration": 6.88
    },
    {
      "lang": "en",
      "text": "I'll expect you'll be able to pay 100,000 \ntimes more to get performance that would have  ",
      "offset": 1604.8,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "previously only been accessible in 2028. Most \nusers, of course, won't be willing to do this,  ",
      "offset": 1609.52,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "but if you have a crucial engineering, scientific, \nor business problem, even $1 million is a bargain.",
      "offset": 1615.52,
      "duration": 7.44
    },
    {
      "lang": "en",
      "text": "In particular, AI researchers may be able to \nuse this technique to create another flywheel  ",
      "offset": 1622.96,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "for AI research. This is a process called \niterated distillation and amplification,  ",
      "offset": 1628.4,
      "duration": 6.16
    },
    {
      "lang": "en",
      "text": "which you can read about in an article I link \nto. But here's roughly how it would work: ",
      "offset": 1634.56,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "Have your model think for longer to get \nbetter answers. This is called amplification. ",
      "offset": 1640.16,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "Use those answers to train a new model. \nThat new model can now produce almost  ",
      "offset": 1645.84,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "the same answers immediately without needing to \nthink for longer, which is called distillation. ",
      "offset": 1651.12,
      "duration": 6.24
    },
    {
      "lang": "en",
      "text": "Now take that new distilled model and \nhave it think for longer. It'll be able  ",
      "offset": 1657.36,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "to generate even more and better \nanswers than the original model.",
      "offset": 1662.64,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "Then you can repeat that process over and over. \nThis process is essentially how DeepMind made  ",
      "offset": 1666.8,
      "duration": 5.92
    },
    {
      "lang": "en",
      "text": "AlphaZero superhuman at go within a couple \nof days even without using any human data.",
      "offset": 1672.72,
      "duration": 7.36
    },
    {
      "lang": "en",
      "text": "The fourth driver of progress: \nbuilding better agents.",
      "offset": 1680.08,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "GPT-4 resembles a co-worker on their first \nday of work who is smart and knowledgeable,  ",
      "offset": 1684.96,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "but only answers a question or two before \nleaving the company. Unsurprisingly,  ",
      "offset": 1689.84,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "this is only a little bit useful, but the \nAI companies are now turning chatbots into  ",
      "offset": 1694.32,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "agents. An AI agent is capable of doing a \nlong chain of tasks in pursuit of a goal.  \n  ",
      "offset": 1699.84,
      "duration": 6.88
    },
    {
      "lang": "en",
      "text": "For example, if you want to build an app, rather \nthan asking the model for help with each step,  ",
      "offset": 1706.72,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "question by question, you'd simply say, Build an \napp that does X. It'll then ask you clarifying  ",
      "offset": 1711.36,
      "duration": 6.24
    },
    {
      "lang": "en",
      "text": "questions, build a prototype, test, fix bugs, \nand deliver a finished product -- much more  ",
      "offset": 1717.6,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "like a great human software engineer would. \nAgents work by taking a reasoning model and  ",
      "offset": 1723.12,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "then giving it a memory and access \ntools, which is called a scaffolding.",
      "offset": 1728.48,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "Here's how it works: ",
      "offset": 1733.36,
      "duration": 1.84
    },
    {
      "lang": "en",
      "text": "You tell the reasoning module a goal and \nit makes a plan to achieve that goal. ",
      "offset": 1735.2,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "And based on that plan, it uses the tools \nit's been given access to take some actions. ",
      "offset": 1740,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "The results of those actions are \nfed back into the memory module. ",
      "offset": 1745.44,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "The reasoning module then \nupdates the plan based on that. ",
      "offset": 1749.12,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "And then the loop continues until the goal is \nachieved or it's determined not to be possible.",
      "offset": 1752.56,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "AI agents already work a bit. SWE-bench Verified \nis a benchmark of real world software engineering  ",
      "offset": 1758.08,
      "duration": 7.12
    },
    {
      "lang": "en",
      "text": "problems taken from GitHub that typically take \nabout an hour to complete. GPT-4 basically can't  ",
      "offset": 1765.2,
      "duration": 6.4
    },
    {
      "lang": "en",
      "text": "do these problems because they involve using \nmultiple applications on your computer. However,  ",
      "offset": 1771.6,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "when put into a simple agent scaffolding, \nGPT-4 can solve about 20% of these problems.  ",
      "offset": 1776.72,
      "duration": 6.56
    },
    {
      "lang": "en",
      "text": "Claude Sonnet 3.5 could solve about 50%, and O3 \nreportedly could solve over 70%. This means O3  ",
      "offset": 1783.28,
      "duration": 8.8
    },
    {
      "lang": "en",
      "text": "is basically as good as professional software \nengineers at completing these discrete tasks.  ",
      "offset": 1792.08,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "In fact, on competition coding problems, o3 \nwould have ranked about top 200 in the world.  \n  ",
      "offset": 1797.6,
      "duration": 6.56
    },
    {
      "lang": "en",
      "text": "Now consider perhaps the world's most important \nbenchmark: METR’s set of difficult AI research  ",
      "offset": 1804.16,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "engineering problems called RE-bench. These \ninclude problems like fine tuning models or  ",
      "offset": 1810.16,
      "duration": 5.84
    },
    {
      "lang": "en",
      "text": "predicting experimental results that engineers \ntackle to improve cutting-edge AI systems.  ",
      "offset": 1816,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "These problems were chosen to be genuinely \ndifficult problems that closely approximate  ",
      "offset": 1822,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "actual AI research engineering. A simple \nagent built on o1 and Claude Sonnet 3.5  ",
      "offset": 1826.72,
      "duration": 6.96
    },
    {
      "lang": "en",
      "text": "turns out to be better than human experts when \ngiven two hours. This performance exceeded the  ",
      "offset": 1833.68,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "expectations of many forecasters and we \nhaven't even seen the results of o3 yet.",
      "offset": 1839.04,
      "duration": 5.84
    },
    {
      "lang": "en",
      "text": "However, AI performance increases more slowly \nthan human performance when given more time.  ",
      "offset": 1844.88,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "So it turns out that human experts still \nsurpass the AIs around the four-hour mark.  ",
      "offset": 1850.16,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "So the AIs are better over two hours, but then \nthe humans are better over four hours or more.  ",
      "offset": 1855.36,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "But the AI models are catching up fast.  \n \nGPT-4o was only able to do tasks that took  ",
      "offset": 1860.72,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "humans about 30 minutes. To measure this rate \nof increase more precisely, METR made a broader  ",
      "offset": 1866.32,
      "duration": 6.08
    },
    {
      "lang": "en",
      "text": "benchmark of computer use tasks categorised \nby how long they normally took humans to do,  ",
      "offset": 1872.4,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "which they called time horizon. GPT-2 was only \nable to do tasks that took humans a few seconds,  ",
      "offset": 1877.2,
      "duration": 6.24
    },
    {
      "lang": "en",
      "text": "GPT-4 a few minutes, and the latest reasoning \nmodels like o1 could do tasks that took humans  ",
      "offset": 1883.44,
      "duration": 5.92
    },
    {
      "lang": "en",
      "text": "just under an hour. This time is doubling \nroughly every seven months. If that trend  ",
      "offset": 1889.36,
      "duration": 6.08
    },
    {
      "lang": "en",
      "text": "continues to the end of 2028, AI will \nbe able to do AI research engineering  ",
      "offset": 1895.44,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "and software engineering tasks that take \nseveral weeks as well as many human experts.",
      "offset": 1900,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "And interestingly, it looks like the \ntrend since 2024 has been even faster,  ",
      "offset": 1905.36,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "doubling every four months. And \nsince this article was published,  ",
      "offset": 1910.08,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "o3 was tested and it appears to be on the new \neven faster trend. This trend could be due to  ",
      "offset": 1914.16,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "the new reasoning models paradigm that started \nin 2024, unlocking a faster rate of progress.  ",
      "offset": 1919.6,
      "duration": 5.92
    },
    {
      "lang": "en",
      "text": "If the faster trend continues, then we'll \nhave models that can do multiweek software  ",
      "offset": 1925.52,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "engineering tasks in under two years, \nalmost twice as fast progress as before.",
      "offset": 1929.36,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "AI models are also increasingly \nunderstanding their context.  ",
      "offset": 1934.96,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "They can correctly answer questions about \ntheir own architecture, past outputs,  ",
      "offset": 1938.32,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "whether they're being trained or deployed \n-- another precondition for agency.",
      "offset": 1942.32,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "On a lighter note, while Claude 3.5 \nis still terrible at playing Pokemon,  ",
      "offset": 1947.2,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "just a year ago Claude 3 couldn't really play at \nall. So we could say that AIs still don't make  ",
      "offset": 1951.52,
      "duration": 6.08
    },
    {
      "lang": "en",
      "text": "great agents, but they are improving fast.  \n \nThese results and graphs explain why although  ",
      "offset": 1957.6,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "AI models can be very intelligent at answering \nquestions, they haven't yet automated many jobs.  ",
      "offset": 1963.28,
      "duration": 7.04
    },
    {
      "lang": "en",
      "text": "Most jobs are not just a list of discrete one \nhour tasks. They involve figuring out what to do,  ",
      "offset": 1970.32,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "coordinating with a team, long novel \nprojects with lots of context, and so on.  ",
      "offset": 1975.92,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "If even in one of AI's strongest areas, software \nengineering, it can only do tasks that take under  ",
      "offset": 1981.04,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "an hour, then it's a long way from being \nable to fully replace software engineers.",
      "offset": 1986.08,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "However, the trend suggests that there's a \ngood chance this soon changes. As we said,  ",
      "offset": 1991.2,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "if we project the 2020 onwards rate of progress \nforward, then we'll be reaching models that  ",
      "offset": 1996.16,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "can do one day and one week tasks within a \ncouple of years. An AI that could do one day  ",
      "offset": 2002.16,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "or one week tasks would be able to automate \ndramatically more work than current models.  ",
      "offset": 2007.84,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "Companies could start to hire hundreds of digital \nworkers overseen by a small number of humans.",
      "offset": 2012.4,
      "duration": 5.92
    },
    {
      "lang": "en",
      "text": "So how far can this trend of improving agents \ncontinue? OpenAI dubbed 2025 the year of agents.  ",
      "offset": 2018.32,
      "duration": 7.92
    },
    {
      "lang": "en",
      "text": "While AI agent scaffolding is still primitive, \nit's the top priority for the leading labs,  ",
      "offset": 2026.24,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "and that means we should expect more progress. \nMore concretely, gains will come from hooking  ",
      "offset": 2031.2,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "up the agent scaffolding to ever more powerful \nreasoning models, giving the agent a better,  ",
      "offset": 2036.72,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "more reliable planning brain. Those in turn \nwill be based on base models that have been  ",
      "offset": 2041.68,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "trained on a lot more video data, which might \nmake the agents much better at perception,  ",
      "offset": 2046.4,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "a major bottleneck currently. \nThe models are often unable to  ",
      "offset": 2050.88,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "do things like recognise a button on \na website, but that could get solved.",
      "offset": 2054.72,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "Once agents start working a bit, that unlocks \nmore progress. You can set an agent a task  ",
      "offset": 2059.76,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "like making a purchase or writing a popular \ntweet. Then if it succeeds, use reinforcement  ",
      "offset": 2065.04,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "learning to make it more likely to succeed next \ntime. In addition, each successfully completed  ",
      "offset": 2070.64,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "task can be used as training data for the \nnext generation of agents. The world is  ",
      "offset": 2076.16,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "ultimately an unending source of data, which lets \nthe agents naturally develop a causal model of the  ",
      "offset": 2081.28,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "world. Any of these measures listed above could \nsignificantly increase the reliability of agents.  ",
      "offset": 2086.32,
      "duration": 6.16
    },
    {
      "lang": "en",
      "text": "And as we've seen several times in this article, \nreliability improvements can suddenly unlock new  ",
      "offset": 2092.48,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "capabilities. Even a simple task, like finding \nand booking a hotel that meets your preferences,  ",
      "offset": 2097.76,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "requires tens of steps. With a 90% chance \nof completing each step correctly, there's  ",
      "offset": 2103.76,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "only a 10% chance of completing 20 steps. \nHowever, with a 99% reliability per step,  ",
      "offset": 2109.12,
      "duration": 6.32
    },
    {
      "lang": "en",
      "text": "the overall chance of success of all 20 steps \nleaps from 10% to 80%: the difference between  ",
      "offset": 2115.44,
      "duration": 6.48
    },
    {
      "lang": "en",
      "text": "an agent that's not very useful to a very useful \none. So progress could feel quite explosive.",
      "offset": 2121.92,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "All this said, agency is the most uncertain of the \nfour drivers. We don't yet have great benchmarks  ",
      "offset": 2127.92,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "to measure it. And so while there might be a lot \nof progress at navigating certain types of tasks,  ",
      "offset": 2133.28,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "progress could remain slow on other dimensions. A \nfew significant areas of weakness could hamstring  ",
      "offset": 2138.24,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "AIs’ applications. More fundamental breakthroughs \nmight be required to make it really work.  ",
      "offset": 2143.52,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "Nonetheless, the recent trends \nand the improvements already  ",
      "offset": 2149.52,
      "duration": 2.88
    },
    {
      "lang": "en",
      "text": "in the pipeline mean I expect \nto see significant progress.",
      "offset": 2152.4,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "How good will AI become by 2030? \nThe four drivers projected forwards.",
      "offset": 2157.68,
      "duration": 6.4
    },
    {
      "lang": "en",
      "text": "Let's recap everything we've covered so \nfar. Looking ahead the next two years,  ",
      "offset": 2164.08,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "all four drivers of AI progress seem set to \ncontinue and to build on each other. A base model  ",
      "offset": 2169.12,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "trained with 500 times more effective compute \nthan GPT-4 will be released, which we could  ",
      "offset": 2174.88,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "call GPT-5. That model could be trained to reason \nwith up to 100 times more compute than o1. So we  ",
      "offset": 2179.6,
      "duration": 7.2
    },
    {
      "lang": "en",
      "text": "could call that o5. It'll be able to think for the \nequivalent of a month per task when needed. It'll  ",
      "offset": 2186.8,
      "duration": 7.28
    },
    {
      "lang": "en",
      "text": "be hooked up to an improved agent scaffolding \nand further reinforced to be more agentic.",
      "offset": 2194.08,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "And that won't be the end. The leading \ncompanies are on track to carry out $10  ",
      "offset": 2199.68,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "billion training runs by 2028. That would be \nenough to pre-train a GPT-6 sized base model  ",
      "offset": 2203.76,
      "duration": 6.56
    },
    {
      "lang": "en",
      "text": "and to do another 100 times more reinforcement \nlearning or some other combination of the two.",
      "offset": 2210.32,
      "duration": 5.92
    },
    {
      "lang": "en",
      "text": "In addition, new drivers like reasoning models \nseem to appear roughly every one to two years.  ",
      "offset": 2216.24,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "So we should project at least one more discovery \nlike this in the next four years, and there's some  ",
      "offset": 2221.44,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "chance we might see an even more fundamental \nadvance, more akin to deep learning itself.",
      "offset": 2226.88,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "In the article you can see a table \nsummarising the four drivers of  ",
      "offset": 2232.08,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "progress over the last four years and how \nthey might evolve over the next four years.",
      "offset": 2236,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "Putting all this together, people who picture the \nfuture as slightly better chatbots are making a  ",
      "offset": 2241.12,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "mistake. Absent a major disruption, perhaps like \nan invasion of Taiwan or a major economic crisis,  ",
      "offset": 2245.84,
      "duration": 6.64
    },
    {
      "lang": "en",
      "text": "progress is not going to plateau here. The \nmultitrillion dollar question is how advanced  ",
      "offset": 2252.48,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "AI will get. Ultimately, no one knows, but one \nway to get a more precise answer is to extrapolate  ",
      "offset": 2258,
      "duration": 6.96
    },
    {
      "lang": "en",
      "text": "progress on benchmarks measuring AI capabilities, \nsuch as those I've mentioned earlier.",
      "offset": 2264.96,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "Since all the drivers of progress are \ncontinuing at similar rates to the past,  ",
      "offset": 2270.64,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "we can roughly extrapolate the recent \nrate of progress. In the article I have  ",
      "offset": 2275.04,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "a summary of all the benchmarks we've \ndiscussed, plus a couple of others,  ",
      "offset": 2279.76,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "and where we might expect them to be \nin 2026. Most of them seem set to be  ",
      "offset": 2283.12,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "saturated, including BIG-Bench Hard, SWE-bench \nVerified, GPQA Diamond, most math benchmarks.",
      "offset": 2288.24,
      "duration": 9.68
    },
    {
      "lang": "en",
      "text": "More interesting is perhaps Humanity's Last \nExam, a compilation of 3,000 questions at the  ",
      "offset": 2297.92,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "frontier of human knowledge. Previously models \ncould only answer under 3% of these in 2022,  ",
      "offset": 2303.2,
      "duration": 6.56
    },
    {
      "lang": "en",
      "text": "but by the end of 2024 that had risen to 9%, \nand by February 2025 that had already hit  ",
      "offset": 2309.76,
      "duration": 6.48
    },
    {
      "lang": "en",
      "text": "25%. Projecting to 2026, I’d guess somewhere \nbetween 40% unsaturated. With frontier math,  ",
      "offset": 2316.24,
      "duration": 7.92
    },
    {
      "lang": "en",
      "text": "as we've said, that's risen from 0% in 2022 to \nmaybe about 25% today, and I would guess perhaps  ",
      "offset": 2324.16,
      "duration": 8.08
    },
    {
      "lang": "en",
      "text": "50% to saturated by the end of 2026. Finally, on \nMETR’s time horizon benchmark, in 2022, models  ",
      "offset": 2332.24,
      "duration": 8.64
    },
    {
      "lang": "en",
      "text": "could do tasks that humans could do in about one \nminute. By the end of 2024 that had risen to 30  ",
      "offset": 2340.88,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "minutes. And if we project forward the slower \nrate of progress, by the end of 2026 they'll be  ",
      "offset": 2346.32,
      "duration": 6.48
    },
    {
      "lang": "en",
      "text": "able to do tasks that humans can do in six hours. \nAt the faster rate of progress that we seem to  ",
      "offset": 2352.8,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "have been on since 2024, that would be almost \ntwice as long. So roughly one day long tasks.",
      "offset": 2357.6,
      "duration": 7.04
    },
    {
      "lang": "en",
      "text": "Putting all this together implies that in two \nyears we should expect AI systems that have  ",
      "offset": 2364.64,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "expert level knowledge of every field, can \nanswer math and science questions as well as  ",
      "offset": 2368.96,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "many professional researchers, are better than \nhumans at coding, have general reasoning skills  ",
      "offset": 2373.52,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "better than almost all humans, can autonomously \ncomplete many day long tasks on a computer,  ",
      "offset": 2379.04,
      "duration": 5.92
    },
    {
      "lang": "en",
      "text": "and are still rapidly improving. The next \nleap might take us to beyond human level  ",
      "offset": 2384.96,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "problem solving, the ability to answer as yet \nunsolved scientific questions independently.",
      "offset": 2390.4,
      "duration": 6.24
    },
    {
      "lang": "en",
      "text": "So what jobs would these systems be able to \ndo? Many bottlenecks hinder real world AI  ",
      "offset": 2396.64,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "agent deployment, even for those tasks that can \nbe done on computer. These include regulation,  ",
      "offset": 2402.4,
      "duration": 6.96
    },
    {
      "lang": "en",
      "text": "reluctance to let AIs make decisions, \ninsufficient reliability, institutional inertia,  ",
      "offset": 2409.36,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "and lack of physical presence. Initially, \npowerful systems will also be expensive,  ",
      "offset": 2415.36,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "and their deployment will be limited by \navailable compute, so they will be directed  ",
      "offset": 2420.64,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "at only the most valuable tasks. That means \nthat most of the economy will probably still  ",
      "offset": 2424.8,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "continue much as normal for a while. You'll \nstill consult human doctors even if they have  ",
      "offset": 2429.6,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "AI tools advising them. You'll get coffee \nfrom human baristas and hire human plumbers.",
      "offset": 2434.24,
      "duration": 6.08
    },
    {
      "lang": "en",
      "text": "However, there are a few crucial \nareas where despite these bottlenecks,  ",
      "offset": 2440.32,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "these systems could be more rapidly \ndeployed with major consequences.  ",
      "offset": 2443.84,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "The first of these is software engineering. This \nis where AI is being most aggressively applied  ",
      "offset": 2448.4,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "today. Google has said about 25% of their new code \nis written by AI. And actually since I wrote this  ",
      "offset": 2453.44,
      "duration": 7.44
    },
    {
      "lang": "en",
      "text": "article, that's risen to maybe 50%. Y Combinator \nstartups say that for some of their companies it's  ",
      "offset": 2460.88,
      "duration": 6.8
    },
    {
      "lang": "en",
      "text": "95%, and those companies are growing several \ntimes faster than before. If coding becomes 10  ",
      "offset": 2467.68,
      "duration": 6.8
    },
    {
      "lang": "en",
      "text": "times cheaper, we'll use far more of it. Maybe \nfairly soon we'll see billion dollar software  ",
      "offset": 2474.48,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "startups with a small number of human employees \nmanaging the equivalent of hundreds of AI agents.",
      "offset": 2479.6,
      "duration": 6.32
    },
    {
      "lang": "en",
      "text": "When OpenAI launched, it became the fastest \ngrowing startup of all time in terms of  ",
      "offset": 2485.92,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "revenue. Since then, several other AI companies \nhave taken the record. Most recently Cursor,  ",
      "offset": 2489.84,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "a coding agent. It reached $100 \nmillion of annual recurring revenue  ",
      "offset": 2495.6,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "several times faster than previously very \nsuccessful software startups in the past.  ",
      "offset": 2500.16,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "So even this very narrow application of AI \ncould still produce hundreds of billions of  ",
      "offset": 2505.2,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "dollars of economic value pretty quickly, \nsufficient to fund continued AI scaling.",
      "offset": 2509.36,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "And AI's application to the economy could expand \nsignificantly from there. Epoch AI, for instance,  ",
      "offset": 2515.36,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "estimate that perhaps a third of work tasks \ncould be performed remotely through a computer,  ",
      "offset": 2521.12,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "and that automation only of those tasks \ncould more than double the economy.",
      "offset": 2525.68,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "The second area is scientific research. The \ncreators of AlphaFold already won the Nobel  ",
      "offset": 2530.08,
      "duration": 6.08
    },
    {
      "lang": "en",
      "text": "Prize for designing an AI that solves \nprotein folding. A recent study found  ",
      "offset": 2536.16,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "that an AI tool made top material science \nresearchers 80% faster at finding novel  ",
      "offset": 2540.8,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "materials. And I expect many more results \nlike this once scientists have adapted AI  ",
      "offset": 2546,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "to solve specific problems, for instance by \ntraining on genetic or cosmological data.",
      "offset": 2551.28,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "Future models might even have genuinely novel \ninsights simply by asking them. But even if not,  ",
      "offset": 2556.96,
      "duration": 6.56
    },
    {
      "lang": "en",
      "text": "a lot of science is amenable to brute \nforce. In particular, any domain that's  ",
      "offset": 2563.52,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "mainly virtual but has verifiable answers, \nsuch as mathematics, economic modelling,  ",
      "offset": 2568.08,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "theoretical physics, computer science, research \ncould be accelerated by just generating thousands  ",
      "offset": 2572.8,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "of ideas and then verifying which ones work. \nIn fact, even in an experimental field like  ",
      "offset": 2577.84,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "biology research, it's also bottlenecked by \nthings like programming and data analysis,  ",
      "offset": 2582.72,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "constraints that could be substantially alleviated \nby AI. A single invention like nuclear weapons can  ",
      "offset": 2587.44,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "change the course of history, so the impact \nof any acceleration here could be dramatic.",
      "offset": 2593.44,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "A field that's especially amenable to acceleration \nis AI research itself. Besides being fully  ",
      "offset": 2599.44,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "virtual, it's the field that AI researchers \nunderstand best, have huge incentives to automate,  ",
      "offset": 2604.96,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "and face no barriers to deploying AI in. \nInitially, this will look like researchers  ",
      "offset": 2610.08,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "using intern level AI agents to unblock them on \nspecific tasks like software engineering capacity,  ",
      "offset": 2615.12,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "which is a major bottleneck, or even to help them \nbrainstorm ideas. Later, it could look like having  ",
      "offset": 2620.4,
      "duration": 6.08
    },
    {
      "lang": "en",
      "text": "the models read all the literature, generate \nthousands of ideas to improve the algorithms,  ",
      "offset": 2626.48,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "and automatically testing those algorithms \nin small scale experiments. An AI model has  ",
      "offset": 2630.96,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "already produced an AI research paper that was \naccepted to a conference workshop. In the article,  ",
      "offset": 2636.48,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "I linked to a long list of other ways that AI is \nalready being applied to speed up AI research.  \n  ",
      "offset": 2641.36,
      "duration": 6.08
    },
    {
      "lang": "en",
      "text": "Given all this, it's quite plausible that \nwe'll have AI agents doing AI research  ",
      "offset": 2647.44,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "before people have figured out all the \nkinks that enable AI to do most remote  ",
      "offset": 2651.36,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "workshops. Broad economic application of AI is \ntherefore not necessarily a good way to gauge  ",
      "offset": 2654.96,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "AI progress. It might follow explosively after AI \ncapabilities have already advanced substantially.",
      "offset": 2660.96,
      "duration": 6.48
    },
    {
      "lang": "en",
      "text": "So what's the best case against \nimpressive AI progress by 2030?",
      "offset": 2668.4,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "Here's the strongest case against it in my \nmind: first, concede that AI will likely  ",
      "offset": 2673.12,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "become superhuman at clearly defined discrete \ntasks, which means that we'll see continued  ",
      "offset": 2678.16,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "rapid progress on benchmarks, but it'll remain \npoor at ill defined high context and long time  ",
      "offset": 2683.36,
      "duration": 6.4
    },
    {
      "lang": "en",
      "text": "horizon tasks. That's because these kinds of tasks \ndon't have clearly and quickly verifiable answers,  ",
      "offset": 2689.76,
      "duration": 7.2
    },
    {
      "lang": "en",
      "text": "so they can't be trained easily with \nreinforcement learning. They're also not  ",
      "offset": 2696.96,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "normally contained in the training data either.  \n \nThat could mean the rate of progress on these  ",
      "offset": 2701.12,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "kinds of tasks will be slow and might even hit \na plateau. If you also argue that AI is very  ",
      "offset": 2706.16,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "bad at these types of tasks today, then even after \nfour to six more years of progress, it might still  ",
      "offset": 2711.2,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "be bad. Secondly, argue that most knowledge work \njobs consist significantly of these long horizon,  ",
      "offset": 2716.24,
      "duration": 6.72
    },
    {
      "lang": "en",
      "text": "messy high context tasks. For example, software \nengineers spend a lot of their time figuring out  ",
      "offset": 2722.96,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "what to build, coordinating with others and \nunderstanding massive codebases, rather than  ",
      "offset": 2728.24,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "just knocking off a list of well defined tasks. So \neven if their productivity at coding increases 10  ",
      "offset": 2733.2,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "times, if coding is only 50% of their work, their \nproductivity will only roughly double. A prime  ",
      "offset": 2738.64,
      "duration": 6.56
    },
    {
      "lang": "en",
      "text": "example of a messy ill defined task is whatever's \ninvolved with having novel research taste.  \n  ",
      "offset": 2745.2,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "So you could argue that this task, which \nis especially important for unlocking an  ",
      "offset": 2750.88,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "acceleration, is likely to be the hardest \nto automate. In this kind of scenario,  ",
      "offset": 2754.72,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "we'll have extremely smart and knowledgeable \nAI assistants and perhaps an acceleration in  ",
      "offset": 2759.92,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "some limited virtual domains, perhaps \nlike mathematics research, but AIs will  ",
      "offset": 2764.64,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "remain tools and humans will remain the main \neconomic and scientific bottleneck. Human AI  ",
      "offset": 2768.96,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "researchers will see their productivity increase, \nbut not enough to start a positive feedback loop.  ",
      "offset": 2774.72,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "AI progress will remain bottlenecked by novel \ninsights, human coordination, and compute.",
      "offset": 2780.4,
      "duration": 5.84
    },
    {
      "lang": "en",
      "text": "These limits , maybe combined with problems \nfinding a business model and other barriers  ",
      "offset": 2786.24,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "to deploying AI, could mean that the \nmodels won't create enough revenue to  ",
      "offset": 2790,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "justify training runs over $10 billion. That'll \nmean progress slows massively after about 2028.  ",
      "offset": 2793.76,
      "duration": 7.28
    },
    {
      "lang": "en",
      "text": "Then once progress slows, the profit margins \non frontier models could collapse, because  ",
      "offset": 2801.04,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "after one or two years, competitors will release \nfree versions that are basically just as good.  ",
      "offset": 2806,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "And once the profit margins are down, that will \nmake it even harder to fund continued scaling.",
      "offset": 2810.88,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "So I think that's the strongest case against \nI can make. The primary counterargument is the  ",
      "offset": 2816.08,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "earlier graph from METR: models are improving \nat acting over longer and longer time horizons,  ",
      "offset": 2820.56,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "which requires deeper contextual understanding \nand handling of more abstract complex tasks.  ",
      "offset": 2826.24,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "Projecting this trend forward suggests much more \nautonomous models within four years. And as I've  ",
      "offset": 2832.24,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "shown, this could be achieved via many incremental \nadvances of the type I've sketched, but it might  ",
      "offset": 2837.6,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "also happen via a more fundamental innovation that \narises in the coming years. The human brain itself  ",
      "offset": 2842.56,
      "duration": 6.48
    },
    {
      "lang": "en",
      "text": "proves that such capabilities are possible.  \n \nMoreover, long horizon tasks can most likely be  ",
      "offset": 2849.04,
      "duration": 5.84
    },
    {
      "lang": "en",
      "text": "broken down into shorter tasks, like making a \nplan, executing the first step, and so on. If  ",
      "offset": 2854.88,
      "duration": 6.48
    },
    {
      "lang": "en",
      "text": "AI gets good enough at shorter tasks, then long \nhorizon tasks might rapidly start to work too.",
      "offset": 2861.36,
      "duration": 6.72
    },
    {
      "lang": "en",
      "text": "This is then perhaps the central \nquestion of AI forecasting right now:  ",
      "offset": 2868.08,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "Will the horizon over which AIs can \nact plateau or continue to improve  ",
      "offset": 2872.32,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "or perhaps even accelerate like it \nseemed like it maybe is recently?",
      "offset": 2876.56,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "Here are some other ways AI progress \ncould be slower or unimpressive: ",
      "offset": 2881.04,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "Disembodied cognitive labour could turn \nout not to be very useful even in science,  ",
      "offset": 2885.12,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "because innovation, you could argue, \narises mainly out of learning by  ",
      "offset": 2889.52,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "doing across the whole economy. Broader \nautomation, which will take much longer,  ",
      "offset": 2893.12,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "could be required for innovation.\nSecond, pre training could have  ",
      "offset": 2897.52,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "big diminishing returns, so maybe \nGPT-5 and 6 will be disappointing.  ",
      "offset": 2901.6,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "That could be due to diminishing data quality.\nAI could continue to be bad at visual perception,  ",
      "offset": 2906.48,
      "duration": 6.08
    },
    {
      "lang": "en",
      "text": "limiting its ability to use a \ncomputer -- see Moravec’s paradox. ",
      "offset": 2912.56,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "More generally, AI capabilities could remain \nvery spiky, perhaps weak on dimensions that  ",
      "offset": 2916.88,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "aren't yet even well understood, and these weak \nspots could really limit their application. ",
      "offset": 2921.68,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "Benchmarks could seriously overstate progress \ndue to issues with data contamination and the  ",
      "offset": 2927.36,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "difficulty of capturing messy tasks.\nAn economic crisis, Taiwan conflict,  ",
      "offset": 2932,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "other disaster, or massive regulatory crackdown \ncould delay investment by several years.",
      "offset": 2937.12,
      "duration": 5.92
    },
    {
      "lang": "en",
      "text": "There could be other unforeseen bottlenecks. \nThe planning fallacy is the observation that  ",
      "offset": 2943.04,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "everything takes longer than it \nexpects. And the reason for the  ",
      "offset": 2948.48,
      "duration": 2.72
    },
    {
      "lang": "en",
      "text": "planning fallacy is we don't anticipate all \nof the ways that something can go wrong.  \n  ",
      "offset": 2951.2,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "For deeper exploration of the skeptical view, see \n“Are we on the brink of AGI?” by Steve Newman,  ",
      "offset": 2956,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "“The promise of reasoning models” \nby Matthew Barnnett, “A bear case:  ",
      "offset": 2961.52,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "My predictions regarding AI progress,” by Thane \nRuthenis, and the Dwarkesh podcast with Epoch AI.",
      "offset": 2965.68,
      "duration": 7.2
    },
    {
      "lang": "en",
      "text": "Ultimately, the evidence will never \nbe decisive one way or another,  ",
      "offset": 2972.88,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "and estimates will rely on judgement calls over \nwhich people can reasonably differ. However,  ",
      "offset": 2976.48,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "I find it hard to look at the evidence and not \nput significant probability on AGI by 2030.",
      "offset": 2981.44,
      "duration": 6.56
    },
    {
      "lang": "en",
      "text": "When do the experts expect AGI to arrive?",
      "offset": 2988,
      "duration": 2.72
    },
    {
      "lang": "en",
      "text": "I've made some big claims, and as a non-expert, \nit would be great if there were some experts who  ",
      "offset": 2991.52,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "could just tell us what to think. Unfortunately \nthere aren't. There are only different groups,  ",
      "offset": 2996.48,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "each with different drawbacks.  \n \nI reviewed the views of these different  ",
      "offset": 3001.68,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "groups of experts in a separate article, but one \nstriking point is that every group has shortened  ",
      "offset": 3005.44,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "their estimates dramatically. Today even many \nAI sceptics think AGI will be achieved in 20  ",
      "offset": 3011.2,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "years -- mid-career for today's college students. \nSince 2020 the mean estimate on Metaculus for when  ",
      "offset": 3017.2,
      "duration": 7.2
    },
    {
      "lang": "en",
      "text": "AGI will be developed has plummeted from \n50 years to 5 years. There's problems with  ",
      "offset": 3024.4,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "the definition used on Metaculus, but this graph \nreflects a broader trend of declining estimates.",
      "offset": 3029.12,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "My overall read is that AGI by 2030 \nis within scope of expert opinion,  ",
      "offset": 3034.72,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "so dismissing it as sci-fi is not justified.  ",
      "offset": 3039.68,
      "duration": 2.88
    },
    {
      "lang": "en",
      "text": "Indeed, the people who know the most about \nthe technology seem to have the shortest  ",
      "offset": 3043.28,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "timelines. Of course, many experts also think \nit'll take much longer, but if 30% of experts  ",
      "offset": 3046.72,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "think a plane will explode and the other 70% \nsay it'll be fine, as non-experts, we shouldn't  ",
      "offset": 3052.16,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "conclude that it definitely won't. If something \nis uncertain, that doesn't mean it won't happen.",
      "offset": 3057.36,
      "duration": 7.2
    },
    {
      "lang": "en",
      "text": "Section 3: Why the next five years are crucial.",
      "offset": 3064.56,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "It's natural to assume that since we don't know \nwhen AGI will arrive, it might arrive soon,  ",
      "offset": 3068.88,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "or maybe in the 2030s or the 2040s and so on. \nAlthough that's a common perspective, I'm not sure  ",
      "offset": 3073.44,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "it's right. As we've seen, the core drivers of AI \nprogress are more compute and better algorithms.  ",
      "offset": 3079.44,
      "duration": 6.72
    },
    {
      "lang": "en",
      "text": "That means more powerful AI is most likely to be \ndiscovered when compute and the labour used to  ",
      "offset": 3086.16,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "improve AIs is growing most dramatically.  \n \nRight now, the total compute available for  ",
      "offset": 3091.36,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "training and running AI is growing about \nthree times per year, and the workforce  ",
      "offset": 3096.8,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "is growing rapidly too. That means that each \nyear the number of AI models that can be run  ",
      "offset": 3101.2,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "increases three times. In addition, three times \nmore compute can be used for training, and that  ",
      "offset": 3107.2,
      "duration": 6.16
    },
    {
      "lang": "en",
      "text": "training can use better algorithms, which means \nthey get more capable as well as more numerous.",
      "offset": 3113.36,
      "duration": 5.92
    },
    {
      "lang": "en",
      "text": "Earlier I argued these trends \ncan continue till 2028,  ",
      "offset": 3119.28,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "but now we'll show that it most likely \nruns into bottlenecks shortly thereafter.",
      "offset": 3122.8,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "The first bottleneck is money. Google, \nMicrosoft and Meta are spending tens  ",
      "offset": 3127.92,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "of billions of dollars to build AI chip clusters \nthat could train a GPT-6 size model in 2028. But  ",
      "offset": 3132.4,
      "duration": 6.72
    },
    {
      "lang": "en",
      "text": "another 10 times scaleup would require hundreds \nof billions of investments. That's still doable,  ",
      "offset": 3139.12,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "but it's more than their current annual profits \nand would be similar to another Apollo programme  ",
      "offset": 3144.72,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "or Manhattan Project in scale. Then GPT-8 would \nrequire trillions of dollars. AI would need to  ",
      "offset": 3149.52,
      "duration": 6.88
    },
    {
      "lang": "en",
      "text": "become a top military priority or already be \ngenerating trillions of dollars of revenues  ",
      "offset": 3156.4,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "to generate that type of investment, and that \nwould probably already be AGI if we had that.",
      "offset": 3161.12,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "Second, even if the money is available, there \nwill be other bottlenecks such as the following: ",
      "offset": 3166.8,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "Electricity: Current levels of \nAI chip sales, if sustained,  ",
      "offset": 3172.16,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "will mean that AI chips will use about 4% of \nUS electricity by 2028, but another 10 times  ",
      "offset": 3176.08,
      "duration": 6.48
    },
    {
      "lang": "en",
      "text": "scaleup would require 40% of US electricity. \nThat's possible, but it would require building  ",
      "offset": 3182.56,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "a lot of power plants pretty fast.\nChip production: Taiwan Semiconductor  ",
      "offset": 3187.76,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "Manufacturing Company, TSMC, manufactures \nall of the world's leading AI chips,  ",
      "offset": 3193.36,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "but its most advanced capacity is still \nmostly used for mobile phones. That means  ",
      "offset": 3198.72,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "that TSMC can still produce five times more \nAI chips than it does now. However, reaching  ",
      "offset": 3203.04,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "50 times more chips would be a huge challenge, \nrequiring massive construction of chip fabs. ",
      "offset": 3209.04,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "Third, latency limitations could also \nprevent training runs as large as GPT-7.",
      "offset": 3215.04,
      "duration": 5.84
    },
    {
      "lang": "en",
      "text": "So most likely the rate of growth in compute \nused for training slows around 2028 to 2032.  ",
      "offset": 3220.88,
      "duration": 6.96
    },
    {
      "lang": "en",
      "text": "Algorithmic progress is also very rapid \nright now, but as each discovery gets made,  ",
      "offset": 3227.84,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "the next one becomes harder and harder because \nthe easier ones get taken first. That means  ",
      "offset": 3233.44,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "maintaining a constant rate of progress requires \nexponentially growing research workforce. In 2021,  ",
      "offset": 3238.56,
      "duration": 6.72
    },
    {
      "lang": "en",
      "text": "OpenAI had about 300 employees. Today it has \nabout 3,000. Anthropic and DeepMind have also  ",
      "offset": 3245.28,
      "duration": 6.8
    },
    {
      "lang": "en",
      "text": "grown more than three times, and new companies \nhave entered the space. The number of ML papers  ",
      "offset": 3252.08,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "produced per year has roughly doubled every two \nyears. It's hard to know exactly how to define  ",
      "offset": 3257.44,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "the workforce of people who are truly advancing \nAI capabilities versus just selling the product  ",
      "offset": 3262.88,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "or doing other broader ML research. But if the \nworkforce needs to double every one to three  ",
      "offset": 3267.76,
      "duration": 5.92
    },
    {
      "lang": "en",
      "text": "years to maintain recent progress, that can only \nlast so long before the talent pool runs out.  \n  ",
      "offset": 3273.68,
      "duration": 6.24
    },
    {
      "lang": "en",
      "text": "My read is that growth can easily \ncontinue until the end of the decade,  ",
      "offset": 3279.92,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "but will probably start to slow in the early \n2030s, unless by then AI has already become  ",
      "offset": 3283.28,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "good enough to substitute for AI researchers. \nAlgorithmic progress also depends on increasing  ",
      "offset": 3288.8,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "compute, because more compute enables more \nexperiments. In fact, with enough compute,  ",
      "offset": 3294.08,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "researchers can even conduct brute \nforce searches for optimal algorithms.  ",
      "offset": 3299.52,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "That means that slowing compute growth will \ncorrespondingly slow algorithmic progress too.",
      "offset": 3303.76,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "If compute and algorithmic efficiency increased \nby only 50% annually, rather than the threefold  ",
      "offset": 3308.72,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "per year they've been increasing recently, \na leap equivalent to the leap from GPT-3 to  ",
      "offset": 3313.92,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "4 would take over 14 years instead of the two \nand a half that it actually did. Slower growth  ",
      "offset": 3319.12,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "of compute and the workforce also reduces the \nprobability of discovering a new AI paradigm.",
      "offset": 3324.72,
      "duration": 5.84
    },
    {
      "lang": "en",
      "text": "So putting all this together, there's a race:  ",
      "offset": 3330.56,
      "duration": 2.32
    },
    {
      "lang": "en",
      "text": "Can AI models improve enough to generate enough \nrevenue to pay for their next round of training  ",
      "offset": 3332.88,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "before it's no longer affordable? Can the \nmodels start to contribute to algorithmic  ",
      "offset": 3337.76,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "research before we run out of human \nresearchers to throw at the problem?",
      "offset": 3342.48,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "The moment of truth will be around 2028 to \n2032: either progress slows or AI itself  ",
      "offset": 3346.48,
      "duration": 8
    },
    {
      "lang": "en",
      "text": "overcomes these bottlenecks, allowing \nprogress to continue or even accelerate.",
      "offset": 3354.48,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "Two potential futures for AI.",
      "offset": 3360,
      "duration": 2.72
    },
    {
      "lang": "en",
      "text": "If AI capable of contributing to AI \nresearch isn't achieved before around 2030,  ",
      "offset": 3362.72,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "then the annual probability of its discovery \ndecreases substantially. Progress, of course,  ",
      "offset": 3368.08,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "won't suddenly halt, it'll slow \nmore gradually. In the article,  ",
      "offset": 3373.12,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "you can see a graph where I look at the \nprobability of AGI being discovered each year.  ",
      "offset": 3377.12,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "I think it's increasing from now until around \n2027, and then it starts to gradually decline,  ",
      "offset": 3382.24,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "reaching much lower levels, perhaps 10 \ntimes lower than today, by the mid-2030s.",
      "offset": 3387.84,
      "duration": 6.16
    },
    {
      "lang": "en",
      "text": "So roughly, we can plan for two scenarios. Either \nwe hit AI that can cause transformative effects by  ",
      "offset": 3394,
      "duration": 6.16
    },
    {
      "lang": "en",
      "text": "2030, AI progress continues or even accelerates, \nand we probably enter a period of explosive  ",
      "offset": 3400.16,
      "duration": 6.08
    },
    {
      "lang": "en",
      "text": "change; or AI progress will slow. The models \nwill get much better at clearly defined tasks,  ",
      "offset": 3406.24,
      "duration": 6.24
    },
    {
      "lang": "en",
      "text": "but they won't be able to do the ill defined \nlong horizon work required to unlock a new  ",
      "offset": 3412.48,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "growth regime. We'll see a lot of AI automation, \nbut otherwise the world will look much more  ",
      "offset": 3416.88,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "like normal. We'll know a lot more about which \nscenario we're in within the next few years.  \n  ",
      "offset": 3422.4,
      "duration": 6.16
    },
    {
      "lang": "en",
      "text": "I roughly think of these two scenarios as a \n50/50, though my estimates can vary between 30%  ",
      "offset": 3429.12,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "and 80% depending on the day. And of course, \nhybrid scenarios are also possible. Scaling  ",
      "offset": 3435.12,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "could slow more gradually or be delayed several \nyears by a Taiwan conflict pushing AGI into the  ",
      "offset": 3440.56,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "early ‘30s. But I find it useful to just start \nwith a simple model. And of course the numbers  ",
      "offset": 3445.84,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "you put on each scenario also depend on your \ndefinition of AGI, and also what kind of AGI you  ",
      "offset": 3451.2,
      "duration": 6.16
    },
    {
      "lang": "en",
      "text": "think will be transformative. I'm most interested \nin forecasting AI that can meaningfully contribute  ",
      "offset": 3457.36,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "to AI research. AGI in the sense of a model that \ncan do almost all remote work tasks cheaper and  ",
      "offset": 3462.88,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "better than a human may well take longer due \nto a long tail of deployment bottlenecks.  \n  ",
      "offset": 3468.24,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "On the other hand, AGI in the sense \nof better than almost all humans  ",
      "offset": 3474.08,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "at reasoning when given an hour, \nseems to be basically here already.",
      "offset": 3477.44,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "Conclusion.",
      "offset": 3482.72,
      "duration": 1.6
    },
    {
      "lang": "en",
      "text": "So, will we have AGI by 2030? Whatever the \nexact definition, significant evidence supports  ",
      "offset": 3484.32,
      "duration": 6.56
    },
    {
      "lang": "en",
      "text": "this possibility. We may only need to sustain \ncurrent trends for a few more years to get there.  ",
      "offset": 3490.88,
      "duration": 5.92
    },
    {
      "lang": "en",
      "text": "We're never going to have decisive evidence either \nway, but it seems clearly overconfident to me to  ",
      "offset": 3497.44,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "think that the probability before 2030 is \nbelow 10%. Given the massive implications  ",
      "offset": 3502.56,
      "duration": 5.84
    },
    {
      "lang": "en",
      "text": "and serious risks, that's enough evidence to \ntake this possibility extremely seriously.",
      "offset": 3508.4,
      "duration": 5.92
    },
    {
      "lang": "en",
      "text": "Today's situation feels like February 2020, just \nbefore the COVID lockdowns. A clear trend suggests  ",
      "offset": 3514.32,
      "duration": 6.4
    },
    {
      "lang": "en",
      "text": "imminent massive change, yet most people continue \ntheir lives as normal. In an upcoming article,  ",
      "offset": 3520.72,
      "duration": 6.16
    },
    {
      "lang": "en",
      "text": "I'll argue that AGI automating much of \nremote work and doubling the economy  ",
      "offset": 3526.88,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "could be a conservative outcome. If AI can \ndo AI research, the gap between AGI and  ",
      "offset": 3531.36,
      "duration": 6.16
    },
    {
      "lang": "en",
      "text": "superintelligence -- AI that's more capable than \nhumans at almost all tasks -- could be short.",
      "offset": 3537.52,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "This could enable the equivalent of a \nmassive expansion in the research workforce,  ",
      "offset": 3543.52,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "potentially delivering a century's worth of \nscientific progress in under a decade. Robotics,  ",
      "offset": 3548.4,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "bioengineering, and space settlements could all \narrive far sooner than is commonly anticipated.  ",
      "offset": 3553.52,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "The next five years would be the start of \none of the most pivotal periods in history.",
      "offset": 3559.04,
      "duration": 6.16
    },
    {
      "lang": "en",
      "text": "So thank you for listening. This was the \nfirst chapter in a new guide to how to  ",
      "offset": 3565.2,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "help AI go well that I'm writing with \n80,000 Hours. You can see a summary of  ",
      "offset": 3569.2,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "the guide on 80000hours.org/agi/guide/summary. It \nincludes a summary of our current thoughts about  ",
      "offset": 3573.2,
      "duration": 7.44
    },
    {
      "lang": "en",
      "text": "what to do about this issue, and also some \ntactical advice on how to switch into it.  \n  ",
      "offset": 3580.64,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "If you already know you'd like to \nswitch, apply to speak to the team  ",
      "offset": 3585.52,
      "duration": 2.8
    },
    {
      "lang": "en",
      "text": "one on one. They can help you with planning, \njob opportunities, and introductions to people  ",
      "offset": 3588.32,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "in the field. Otherwise, stay tuned for \nmore chapters. Thanks for listening. Bye.",
      "offset": 3592.96,
      "duration": 8.88
    }
  ],
  "cleanText": "Hey, this is Benjamin Todd. More and more people have been saying that we might have AGI, artificial general intelligence, before 2030. Is that really plausible? I wrote this article to look into the case for and against and try and summarise all the key things you need to know about that argument. I definitely don't think it's guaranteed to happen, but I think you can make a surprisingly good argument for it. That's what we're going to dive into here. You can see all the images and many footnotes in the original article.\n\nThe Case for AGI by 2030.\n\nIn recent months, the CEOs of leading AI companies have grown increasingly confident about rapid progress. In November, OpenAI's Sam Altman went from saying he expects the rate of progress continues to by January, we are now confident we know how to build AGI.\n\nAlso in January, Anthropic CEO Dario Amodei said, \"I'm more confident than I've ever been that we're close to powerful capabilities in the next two to three years.\" Google DeepMind's more cautious CEO, Demis Hassabis, has switched from saying as soon as 10 years in autumn to by January we're probably three to five years away.\n\nWhat explains this shift? Is it just hype or could we really have AGI by 2030? In this article I look at the four drivers of recent progress, estimate how far those drivers can continue, and explain why they're likely to continue for at least four more years. And that means we should expect major additional AI progress in that time.\n\nIn particular, while in 2024 progress in LLM chatbots seemed to slow, a new approach started to work, teaching the models to reason using what's called reinforcement learning, which I'll explain later in the article. In just a year, this technique let them surpass human PhDs at answering difficult scientific reasoning questions and achieve expert level performance on one hour coding tasks. We don't know how capable AI will become, but just extrapolating the recent rate of progress suggests that by 2028 we could reach AI models with beyond human reasoning abilities, expert level knowledge of every domain, and that can autonomously complete multi week projects, and progress would likely continue from there. No longer just chatbots, these agent models could satisfy many people's definitions of AGI, roughly AI systems that match human performance at almost all knowledge work.\n\nI give a much more detailed definition of AGI in the footnotes.\n\nThis would mean that while the company CEOs are probably a bit overoptimistic, there's enough evidence to take their position very seriously, and it's also important not to get caught up in definitions. Ultimately, what matters is that these models could start to accelerate AI research itself, unlocking vastly greater numbers of more capable AI workers. And then in turn, sufficient automation could trigger explosive economic growth and 100 years of scientific progress in 10 -- a transition society isn't prepared for. While all this might sound outlandish, it's within the range of possibilities that many experts think is possible. This article aims to give you a primer on what you need to know to understand why they think that, and also the best arguments against that position.\n\nI've been writing about AGI since 2014. Back then, AGI arriving within five years seemed very unlikely, but today the situation seems dramatically different. We can see the outlines of how AGI might work and exactly who could build it, and in fact, the next five years seems unusually crucial. The basic drivers of AI progress, investments in computational power and algorithmic research, cannot continue increasing at current rates much beyond 2030. That means that we either reach AI systems capable of triggering an acceleration soon, or progress will most likely slow significantly. Either way, the next five years is when we'll find out. Let's see why.\n\nThe article in a nutshell. Four key factors are driving AI progress: larger base models, teaching models to reason, increasing how long models think about each question, and building agent scaffolding for multi step tasks.\n\nThese in turn are underpinned by increasing computational power to run and train AI systems, as well as increasing human capital going into algorithmic research. All of these drivers are set to continue until 2028 and perhaps until 2032. This means in that time we should expect major further advances in AI performance. We don't know how large these advances will be, but extrapolating recent trends on benchmarks suggests that we'll reach systems with beyond human performance in coding and scientific reasoning and that can autonomously complete multi week projects. Whether we call these systems AGI or not, they could be sufficient to enable AI research itself, robotics, the technology industry, and scientific research all to accelerate, leading to transformative impacts on society.\n\nAlternatively, AI might fail to overcome issues with ill defined high context work over long time horizons and remain a tool even if much improved compared to today. Increasing AI performance requires exponential growth and investment in the research workforce. At current rates, we will likely start to reach bottlenecks around 2030. Simplifying a bit, that means we'll either likely reach AGI by around 2030 or see progress slow significantly.\n\nHybrid scenarios are also possible, but the next five years seems especially crucial.\n\nSection 1: What's driven recent AI progress and will it continue?\n\nEntering the deep learning era.\n\nIn 2022, Yann LeCun, the chief AI scientist at Meta and Turing Award winner, said, and I'm sorry I can't do a French accent. “I take an object, I put it on the table, and I push the table. It’s completely obvious to you that the object will be pushed with the table…There’s no text in the world I believe that explains this. If you train a machine as powerful as could be…your GPT-5000, it’s never gonna learn about this.”\n\nBut within just two months of LeCun's statement, GPT-3.5 could answer this easily. And that's not the only example of experts being wrong footed. Before 2011, AI was famously dead. But that totally changed when conceptual insights from the ‘70s and ‘80s combined with massive amounts of data and computing power to produce the deep learning paradigm. Since then, we've repeatedly seen AI systems going from total incompetence to greater than human performance in many tasks within just a couple of years. For example, in 2022, Midjourney could not draw an otter on a plane using Wifi. But just two years later, Veo 2 can make a hyperrealistic movie.\n\nIn 2019, GPT-2 could just about stay on topic for a couple of paragraphs, and that was considered remarkable progress at the time. Critics like LeCun were quick to point out that GPT-2 couldn't reason, show common sense, exhibit understanding of the physical world, and so on. But many of these limitations were overcome within just a couple of years. Over and over again, it's been dangerous to bet against deep learning. Today, even LeCun says he expects AGI in several years.\n\nAnd the limitations of current systems aren't what to focus on anyway. The more interesting question is where might this be heading? What explains the leap from GPT-2 to 4, and could we see another leap like that?\n\nSo what's coming up? At the broadest level, AI progress has been driven by more computational power, called compute, and better algorithms. Both are improving rapidly.\n\nMore specifically, we can break down recent progress into four key drivers, which I'll explain through the rest of the article.\n\nThe first is called scaling pre-training. That lets you create a base model with basic intelligence, a basic understanding of the world.\n\nSecondly is using reinforcement learning to teach that base model to reason about complicated problems like in maths and coding.\n\nThird is having the model think longer about each question or each problem it's posed. This is called increasing test time compute.\n\nAnd then fourth is building an agent scaffolding around that model which lets it complete complex tasks and take actions in the world.\n\nIn the rest of this section, I'll explain how each of these works and try to project them forward. As GPT would say, delve in and you'll understand the basics of how AI is being improved.\n\nThen in section 2, I'll use this to forecast future AI progress, and then finally explain why it makes the next five years especially crucial.\n\nSo the first driver: scaling pre-training to create base models with basic intelligence. People often imagine that AI progress requires huge intellectual breakthroughs, but a lot of it is more like engineering: just do a lot more of the same and the models get better. In the leap from GPT-2 to 4, the biggest driver of progress was just applying dramatically more computational power to the same techniques, especially to what's called pre-training.\n\nModern AI works by using artificial neural nets involving billions of interconnected parameters organised into layers. During pre-training -- a misleading name which simply means it's the first type of training -- here's what happens: Data is fed into the network, such as the image of a cat. The values of the parameters in that neural net then convert that data into a predicted output, such as a description, \"This is a cat.\"\n\nThe accuracy of those outputs is graded versus the reference data.\n\nThen the model's parameters are adjusted in a way that's expected to increase the accuracy of those predictions.\n\nThis is repeated over and over with trillions of pieces of data until the model becomes better and better at predicting accurately. This method has been used to train all kinds of AI, but it's been most useful when used to predict language. The data is the text on the internet, and LLMs are trained to predict gaps in that text. More computational power for training, so-called training compute, means that you can use more parameters, which means the model can learn more sophisticated and more abstract patterns in the data.\n\nIt also means you can just use more data for training. Since we entered the deep learning era around 2011, the number of calculations used to train AI models has been growing at a staggering rate, more than four times per year. That's the amount of additional computing power used for training the largest AI model each year. This in turn has been enabled by spending far more money, as well as using much more efficient chips.\n\nHistorically, each time training compute has increased 10 times, there's been a steady gain in performance across many tasks and benchmarks. For example, as training compute has grown a thousandfold, AI models have steadily improved at answering diverse questions, from common sense reasoning to understanding social situations and physics. This is demonstrated on the BIG-Bench Hard benchmark. This is a benchmark of diverse questions specifically chosen to challenge LLMs.\n\nIn the article you can see a graph showing a linear increase in performance as training compute is scaled up. Likewise, OpenAI created a coding model that could solve simple coding problems. Then they used 100,000 times more compute to train an improved version. They showed that as training compute increased, the model correctly answered progressively more difficult questions. These test problems weren't in the original training data, so this wasn't merely better searched through memorised problems.\n\nThis relationship between training computes and performance is called a scaling law. Papers about these laws have been published by 2020. To those following this research, GPT-4 wasn't a surprise. It was just a continuation of trend.\n\nThe second contribution to pretraining is algorithmic efficiency. Training compute has not only increased, but researchers have found far more efficient ways to use it. Every two years, the compute needed to get the same performance across a wide range of models has decreased tenfold. In the article I show the example of image recognition algorithms. The amount of compute to get the same accuracy at recognising images has decreased roughly 10 times every two years. But a very similar pattern applies across a wide range of algorithms. These gains usually make the models much cheaper to run. DeepSeek-V3 was reported in the media as a revolutionary efficiency breakthrough, but in fact it was roughly on this preexisting trend. It was released roughly two years after GPT-4 and it's about 10 times more efficient than GPT-4.\n\nNow, algorithmic efficiency means that not only is four times as much compute used on training each year, but also that compute goes about three times further each year. The two effects multiply together to mean that effective compute has increased around 12 times each year. This is an insane rate of increase. For instance, the famous Moore's law about semiconductor efficiency is only 35% growth per year. This AI growth is over 10 times as large. That means that the computer chips that were used to train GPT-4 over three months could have been used to train the model with the performance of GPT-2 about 300,000 times over just four years later.\n\nThis increase in effective compute took us from a model that was just about able to string some sentences together to GPT-4 being able to do things like:\n\n*   Beat most high schoolers at college entrance exams\n*   Converse in natural language -- which in the long forgotten past was considered a mark of true intelligence called the Turing Test\n*   Solve the Winograd schemas, a test of common sense reasoning that in the 2010s was regarded as requiring true understanding\n*   And create art that most people can't distinguish from the human produced stuff.\n\nSo how much further can this driver of progress, pretraining, continue to scale? If current trends continue, then by around 2028 someone will have trained a model with 300,000 times more effective compute than GPT-4. That's the same as the increase that we saw from GPT-2 to 4. So if that was spent on pretraining, we could call that hypothetical model GPT-6. And so far we seem to be on that trend. GPT-4.5 was released in early 2025 and forecasters expect a GPT-5 size model to be released in the second half of the year.\n\nCan the trend continue all the way to GPT-6? The CEO of Anthropic, Dario Amodei, projects that a GPT-6 size model will cost about $10 billion to train. That's expensive, but still affordable for companies like Google, Microsoft, and Meta, which earn $50 to $100 billion in profits each year. In fact, these companies are already building data centres big enough\n\n\nFor such training runs.\nAnd that was before the hundred billion dollar plus Stargate project was announced.\nIn addition, frontier models are already generating over $10 billion of revenue, and that has been more than tripling each year.\nSo soon AI revenue alone will be able to pay for a $10 billion training run.\nI'll discuss what could bottleneck this process more later.\nBut the most plausible bottleneck is training data.\nGPT-4 already used the most easily accessible data on the internet for training, and we only have one internet.\n\nHowever, the best analysis I've found, by Epoch AI, suggests that there will be enough data to carry out a GPT-6 training run by 2028.\nAnd even if that isn't the case, it's no longer crucial -- because the AI companies have discovered a way to circumvent the data bottleneck, as I'll explain next.\nSo the second driver of progress is training the models to reason with reinforcement learning.\nPeople often say ChatGPT is just predicting the next word, but that's never been quite true.\nRaw prediction of words from the internet produces outputs that are regularly crazy, as you might expect given that it's the Internet.\nGPT only became truly useful with the addition of reinforcement learning from human feedback, RLHF.\nIn this process, outputs from the base model are shown to human raters.\nThen secondly, the raters are asked to judge which are most useful.\nThen third, the model is adjusted in a way that's expected to produce more outputs like the helpful ones, which is called reinforcement.\nA model that's undergone RLHF isn't just predicting the next token, it's predicting what human raters will find most helpful.\nYou can think of the initial LLM as providing a foundation of conceptual structure, but RLHF is essential for directing that structure towards a particular useful end.\nRLHF is just one form of post training.\nPost training is named because it happens after pretraining, though in fact both are simply types of training.\nThere are many other kinds of post training enhancements, including things as simple as letting the model access a calculator or the internet.\nBut there's one that's especially crucial right now: reinforcement learning to train the models to reason.\nThe idea is that instead of training the model to do what humans find helpful, it's trained to correctly answer problems.\nHere's the process:\nShow the model a problem with a verifiable answer, like a math puzzle.\nAsk it to produce a chain of reasoning to solve that problem, which is called chain of thought.\nIf the answer is correct, adjust the model in a way that's expected to produce more outputs like that: reinforcement.\nRepeat that process over and over.\nThis process teaches the LLM to construct long chains of hopefully correct reasoning about logical problems.\nBefore 2023, this didn't really seem to work.\nThat's because if each step of reasoning is too unreliable, the chains quickly go wrong.\nAnd if you can't even get close to a right answer, then you can't give the model any reinforcement.\n\nBut in 2024, just as many were saying that AI progress had stalled, this new paradigm was in fact starting to take off.\nConsider the GPQA Diamond benchmark, a set of scientific questions designed so that people with PhDs in the field can mostly answer them but non experts can't, even with 30 minutes of access to Google.\nIt contains questions like advanced quantum physics that I can't make any sense of, even though I studied physics at university.\nIn 2023, GPT-4 performed only slightly better than random guessing on this benchmark.\nThat means it could handle the reasoning required for high school level science problems, but it couldn't manage PhD level reasoning.\nHowever, in October 2024, OpenAI took the GPT-4o base model and used reinforcement learning to create o1.\no1 achieved 70% accuracy at this benchmark, making it about equal to PhDs in the relevant field at answering these questions.\nIt's no longer tenable to claim these models are just regurgitating their training data.\nNeither the answers nor the chains of reasoning required to produce them exist on the internet.\nMost people aren't answering PhD level science questions in their daily life, so they simply haven't noticed this progress.\nThey still think of LLMs as basic chatbots.\nAnd it turns out o1 was just the start.\nAt the beginning of a new paradigm, it's possible to get gains especially quickly.\nJust three months after o1, OpenAI released results from o3.\no3 is the second version.\nIt's named that because O2 is a telecom company.\nBut please don't ask me to explain any other part of OpenAI's model-naming practices.\n\no3 is probably just o1, but with even more reinforcement learning and another change I'll explain shortly.\no3 surpassed human-level expert performance on GPQA.\nNow, reinforcement learning should be most useful for problems that have verifiable answers, such as in science, maths and coding.\nAnd in fact o3 performs much better in all of these areas than its base model GPT-4o.\nMost benchmarks of maths questions have now been saturated, which means that leading models can get basically every question right.\nIn response, the research group Epoch AI created Frontier Math, a benchmark of insanely hard mathematical problems.\nThe easiest 20% are similar to Olympiad level problems.\nThe most difficult are, according to Fields Medalist Terence Tao, extremely challenging.\nThey would typically need an expert in that branch of mathematics to solve them.\nPrevious models, including o1, could hardly solve any of these questions.\nBut in December 2024, OpenAI tested a version of o3 with better scaffolding than the now publicly released version, which they claimed could solve 25%.\nMore recent testing of Google's Gemini 2.5 after this article was released showed that it could solve about 20% of problems on the Maths Olympiad, so it would be about in line with these results.\nAt the time, these results went entirely unreported in the media.\nIn fact, on the very day of the o3 results, the Wall Street Journal was running a story about how GPT-5 was behind and expensive.\nBut this misses the crucial point that GPT-5 is no longer necessary.\nA new paradigm has started which can make even faster gains than before, even without GPT-5.\nIn January, DeepSeek replicated many of o1's results.\nTheir paper revealed that even basically the simplest possible version of the process works.\nThat suggests there's a huge amount more to try.\nDeepSeek R1 also reveals its entire chain of reasoning to the user, and from that we can see its sophistication and surprisingly human quality.\nIt'll reflect on its answers, backtrack when wrong, consider multiple hypotheses, have insights, and more.\nAll of this behaviour emerges out of simple reinforcement learning.\nOpenAI researcher Sabastian Bubeck observed, “No tactic was given to the model.\nEverything is emergent.\nEverything is learned through reinforcement learning.\nThis is insane.”\nThe compute for the reinforcement learning stage of training DeepSeek R1 likely only cost about $1 million.\nIf that keeps working, then OpenAI, Anthropic, and Google could now spend billions of dollars on the same process, approximately a 1000 times scaleup.\nOne reason this is possible is that the models generate their own data.\nThis might sound circular, and the idea that synthetic data causes model collapse has been widely discussed, but there's nothing circular in this case.\nYou can ask o1 to solve 100,000 math problems and then only take the cases where it got the right answer, and then use those to train the next model.\nBecause the solutions can be quickly verified, you've generated more examples of genuinely good reasoning.\nAnd in fact this data is much higher quality than the data you'll find on the internet because it contains that whole chain of reasoning and it's known to be correct.\nNot something the internet is famous for.\nThis potentially creates a flywheel.\nHave your model solve a bunch of problems, use those solutions to train the next model, the next model can solve even harder problems, that generates even more solutions, and so on.\n\nIf the models can already perform PhD level reasoning, the next stage would be researcher level reasoning and then generating novel insights.\nThis likely explains the unusually optimistic statements from the AI company leaders that I mentioned at the start.\nSam Altman's shift in opinion coincides exactly with the o3 release in December 2024.\nAlthough most powerful in verifiable domains, the reasoning skills developed will probably generalise at least a bit.\nIt's common to see an AI model get reasoning training in one domain, like coding problems, and then also improve in other domains that weren't part of that training process.\nIn more fuzzy domains, like business strategy or writing, it's harder to quickly judge success.\nSo the process of reinforcement learning will take longer.\nBut we should expect it to work to some degree, and it's a major focus of the companies right now.\nExactly how well it will work is a crucial question going forward.\nThe third driver of progress: increasing how long models think.\nIf you could only think about a problem for a minute, you probably wouldn't get very far.\nIf you could think for a month, you'd make a lot more progress, even though your raw intelligence isn't higher.\nLLMs used to be unable to think about a problem for more than about a minute before mistakes would compound or they would drift off topic, which really limited what they could do.\nBut as models have become more reliable at reasoning, they've become better at thinking for longer.\nOpenAI showed that you can have o1 think 100 times longer than normal and get linear increases in accuracy on coding problems.\nThis is called using test time compute: compute spent when the model is being run rather than trained.\n\nIf GPT-4o could think usefully for about a minute, o1 and DeepSeek seem like they can think for the equivalent of about an hour.\nAs reasoning models get more reliable, they will be able to think for longer and longer.\nAt current rates, we'll soon have models that can think for a month and then a year.\nIt's particularly intriguing to consider what happens if they could think indefinitely.\nThat would mean that given sufficient compute, and assuming progress is possible in principle, they could continuously improve their answers to any question.\nUsing more test time compute can be used to solve problems via brute force.\nOne technique is to try to solve a problem 10, 100 or 1000 times and then to pick the solution with the most votes.\nThis is probably another way that o3 was able to beat o1.\n\nThe immediate practical upshot of all this is that you can pay more to get more advanced capabilities earlier.\nQuantitatively, in 2026, I'll expect you'll be able to pay 100,000 times more to get performance that would have previously only been accessible in 2028.\nMost users, of course, won't be willing to do this, but if you have a crucial engineering, scientific, or business problem, even $1 million is a bargain.\nIn particular, AI researchers may be able to use this technique to create another flywheel for AI research.\nThis is a process called iterated distillation and amplification, which you can read about in an article I link to.\nBut here's roughly how it would work:\nHave your model think for longer to get better answers.\nThis is called amplification.\nUse those answers to train a new model.\nThat new model can now produce almost the same answers immediately without needing to think for longer, which is called distillation.\nNow take that new distilled model and have it think for longer.\nIt'll be able to generate even more and better answers than the original model.\nThen you can repeat that process over and over.\nThis process is essentially how DeepMind made AlphaZero superhuman at go within a couple of days even without using any human data.\nThe fourth driver of progress: building better agents.\nGPT-4 resembles a co-worker on their first day of work who is smart and knowledgeable, but only answers a question or two before leaving the company.\nUnsurprisingly, this is only a little bit useful, but the AI companies are now turning chatbots into agents.\nAn AI agent is capable of doing a long chain of tasks in pursuit of a goal.\n\nFor example, if you want to build an app, rather than asking the model for help with each step, question by question, you'd simply say, Build an app that does X.\nIt'll then ask you clarifying questions, build a prototype, test, fix bugs, and deliver a finished product -- much more like a great human software engineer would.\nAgents work by taking a reasoning model and then giving it a memory and access tools, which is called a scaffolding.\nHere's how it works:\nYou tell the reasoning module a goal and it makes a plan to achieve that goal.\nAnd based on that plan, it uses the tools it's been given access to take some actions.\nThe results of those actions are fed back into the memory module.\nThe reasoning module then updates the plan based on that.\nAnd then the loop continues until the goal is achieved or it's determined not to be possible.\nAI agents already work a bit.\nSWE-bench Verified is a benchmark of real world software engineering problems taken from GitHub that typically take about an hour to complete.\nGPT-4 basically can't do these problems because they involve using multiple applications on your computer.\nHowever, when put into a simple agent scaffolding, GPT-4 can solve about 20% of these problems.\nClaude Sonnet 3.5 could solve about 50%, and O3 reportedly could solve over 70%.\nThis means O3 is basically as good as professional software engineers at completing these discrete tasks.\nIn fact, on competition coding problems, o3 would have ranked about top 200 in the world.\n\nNow consider perhaps the world's most important benchmark: METR’s set of difficult AI research engineering problems called RE-bench.\nThese include problems like fine tuning models or predicting experimental results that engineers tackle to improve cutting-edge AI systems.\nThese problems were chosen to be genuinely difficult problems that closely approximate actual AI research engineering.\nA simple agent built on o1 and Claude Sonnet 3.5 turns out to be better than human experts when given two hours.\nThis performance exceeded the expectations of many forecasters and we haven't even seen the results of o3 yet.\nHowever\n\n\nAI performance increases more slowly than human performance when given more time.\nSo it turns out that human experts still surpass the AIs around the four-hour mark.\nSo the AIs are better over two hours, but then the humans are better over four hours or more.\nBut the AI models are catching up fast.\n\nGPT-4o was only able to do tasks that took humans about 30 minutes.\nTo measure this rate of increase more precisely, METR made a broader benchmark of computer use tasks categorized by how long they normally took humans to do, which they called time horizon.\nGPT-2 was only able to do tasks that took humans a few seconds, GPT-4 a few minutes, and the latest reasoning models like o1 could do tasks that took humans just under an hour.\nThis time is doubling roughly every seven months.\nIf that trend continues to the end of 2028, AI will be able to do AI research engineering and software engineering tasks that take several weeks as well as many human experts.\nAnd interestingly, it looks like the trend since 2024 has been even faster, doubling every four months.\nAnd since this article was published, o3 was tested and it appears to be on the new even faster trend.\nThis trend could be due to the new reasoning models paradigm that started in 2024, unlocking a faster rate of progress.\nIf the faster trend continues, then we'll have models that can do multiweek software engineering tasks in under two years, almost twice as fast progress as before.\nAI models are also increasingly understanding their context.\nThey can correctly answer questions about their own architecture, past outputs, whether they're being trained or deployed -- another precondition for agency.\nOn a lighter note, while Claude 3.5 is still terrible at playing Pokemon, just a year ago Claude 3 couldn't really play at all.\nSo we could say that AIs still don't make great agents, but they are improving fast.\n\nThese results and graphs explain why although AI models can be very intelligent at answering questions, they haven't yet automated many jobs.\nMost jobs are not just a list of discrete one hour tasks.\nThey involve figuring out what to do, coordinating with a team, long novel projects with lots of context, and so on.\nIf even in one of AI's strongest areas, software engineering, it can only do tasks that take under an hour, then it's a long way from being able to fully replace software engineers.\nHowever, the trend suggests that there's a good chance this soon changes.\nAs we said, if we project the 2020 onwards rate of progress forward, then we'll be reaching models that can do one day and one week tasks within a couple of years.\nAn AI that could do one day or one week tasks would be able to automate dramatically more work than current models.\nCompanies could start to hire hundreds of digital workers overseen by a small number of humans.\nSo how far can this trend of improving agents continue?\nOpenAI dubbed 2025 the year of agents.\nWhile AI agent scaffolding is still primitive, it's the top priority for the leading labs, and that means we should expect more progress.\nMore concretely, gains will come from hooking up the agent scaffolding to ever more powerful reasoning models, giving the agent a better, more reliable planning brain.\nThose in turn will be based on base models that have been trained on a lot more video data, which might make the agents much better at perception, a major bottleneck currently.\nThe models are often unable to do things like recognize a button on a website, but that could get solved.\nOnce agents start working a bit, that unlocks more progress.\nYou can set an agent a task like making a purchase or writing a popular tweet.\nThen if it succeeds, use reinforcement learning to make it more likely to succeed next time.\nIn addition, each successfully completed task can be used as training data for the next generation of agents.\nThe world is ultimately an unending source of data, which lets the agents naturally develop a causal model of the world.\nAny of these measures listed above could significantly increase the reliability of agents.\nAnd as we've seen several times in this article, reliability improvements can suddenly unlock new capabilities.\nEven a simple task, like finding and booking a hotel that meets your preferences, requires tens of steps.\nWith a 90% chance of completing each step correctly, there's only a 10% chance of completing 20 steps.\nHowever, with a 99% reliability per step, the overall chance of success of all 20 steps leaps from 10% to 80%: the difference between an agent that's not very useful to a very useful one.\nSo progress could feel quite explosive.\nAll this said, agency is the most uncertain of the four drivers.\nWe don't yet have great benchmarks to measure it.\nAnd so while there might be a lot of progress at navigating certain types of tasks, progress could remain slow on other dimensions.\nA few significant areas of weakness could hamstring AIs’ applications.\nMore fundamental breakthroughs might be required to make it really work.\nNonetheless, the recent trends and the improvements already in the pipeline mean I expect to see significant progress.\nHow good will AI become by 2030?\nThe four drivers projected forwards.\nLet's recap everything we've covered so far.\nLooking ahead the next two years, all four drivers of AI progress seem set to continue and to build on each other.\nA base model trained with 500 times more effective compute than GPT-4 will be released, which we could call GPT-5.\nThat model could be trained to reason with up to 100 times more compute than o1.\nSo we could call that o5.\nIt'll be able to think for the equivalent of a month per task when needed.\nIt'll be hooked up to an improved agent scaffolding and further reinforced to be more agentic.\nAnd that won't be the end.\nThe leading companies are on track to carry out $10 billion training runs by 2028.\nThat would be enough to pre-train a GPT-6 sized base model and to do another 100 times more reinforcement learning or some other combination of the two.\nIn addition, new drivers like reasoning models seem to appear roughly every one to two years.\nSo we should project at least one more discovery like this in the next four years, and there's some chance we might see an even more fundamental advance, more akin to deep learning itself.\nIn the article you can see a table summarizing the four drivers of progress over the last four years and how they might evolve over the next four years.\nPutting all this together, people who picture the future as slightly better chatbots are making a mistake.\nAbsent a major disruption, perhaps like an invasion of Taiwan or a major economic crisis, progress is not going to plateau here.\nThe multitrillion dollar question is how advanced AI will get.\nUltimately, no one knows, but one way to get a more precise answer is to extrapolate progress on benchmarks measuring AI capabilities, such as those I've mentioned earlier.\nSince all the drivers of progress are continuing at similar rates to the past, we can roughly extrapolate the recent rate of progress.\nIn the article I have a summary of all the benchmarks we've discussed, plus a couple of others, and where we might expect them to be in 2026.\nMost of them seem set to be saturated, including BIG-Bench Hard, SWE-bench Verified, GPQA Diamond, most math benchmarks.\nMore interesting is perhaps Humanity's Last Exam, a compilation of 3,000 questions at the frontier of human knowledge.\nPreviously models could only answer under 3% of these in 2022, but by the end of 2024 that had risen to 9%, and by February 2025 that had already hit 25%.\nProjecting to 2026, I’d guess somewhere between 40% unsaturated.\nWith frontier math, as we've said, that's risen from 0% in 2022 to maybe about 25% today, and I would guess perhaps 50% to saturated by the end of 2026.\nFinally, on METR’s time horizon benchmark, in 2022, models could do tasks that humans could do in about one minute.\nBy the end of 2024 that had risen to 30 minutes.\nAnd if we project forward the slower rate of progress, by the end of 2026 they'll be able to do tasks that humans can do in six hours.\nAt the faster rate of progress that we seem to have been on since 2024, that would be almost twice as long.\nSo roughly one day long tasks.\nPutting all this together implies that in two years we should expect AI systems that have expert level knowledge of every field, can answer math and science questions as well as many professional researchers, are better than humans at coding, have general reasoning skills better than almost all humans, can autonomously complete many day long tasks on a computer, and are still rapidly improving.\nThe next leap might take us to beyond human level problem solving, the ability to answer as yet unsolved scientific questions independently.\nSo what jobs would these systems be able to do?\nMany bottlenecks hinder real world AI agent deployment, even for those tasks that can be done on computer.\nThese include regulation, reluctance to let AIs make decisions, insufficient reliability, institutional inertia, and lack of physical presence.\nInitially, powerful systems will also be expensive, and their deployment will be limited by available compute, so they will be directed at only the most valuable tasks.\nThat means that most of the economy will probably still continue much as normal for a while.\nYou'll still consult human doctors even if they have AI tools advising them.\nYou'll get coffee from human baristas and hire human plumbers.\nHowever, there are a few crucial areas where despite these bottlenecks, these systems could be more rapidly deployed with major consequences.\nThe first of these is software engineering.\nThis is where AI is being most aggressively applied today.\nGoogle has said about 25% of their new code is written by AI.\nAnd actually since I wrote this article, that's risen to maybe 50%.\nY Combinator startups say that for some of their companies it's 95%, and those companies are growing several times faster than before.\nIf coding becomes 10 times cheaper, we'll use far more of it.\nMaybe fairly soon we'll see billion dollar software startups with a small number of human employees managing the equivalent of hundreds of AI agents.\nWhen OpenAI launched, it became the fastest growing startup of all time in terms of revenue.\nSince then, several other AI companies have taken the record.\nMost recently Cursor, a coding agent.\nIt reached $100 million of annual recurring revenue several times faster than previously very successful software startups in the past.\nSo even this very narrow application of AI could still produce hundreds of billions of dollars of economic value pretty quickly, sufficient to fund continued AI scaling.\nAnd AI's application to the economy could expand significantly from there.\nEpoch AI, for instance, estimate that perhaps a third of work tasks could be performed remotely through a computer, and that automation only of those tasks could more than double the economy.\nThe second area is scientific research.\nThe creators of AlphaFold already won the Nobel Prize for designing an AI that solves protein folding.\nA recent study found that an AI tool made top material science researchers 80% faster at finding novel materials.\nAnd I expect many more results like this once scientists have adapted AI to solve specific problems, for instance by training on genetic or cosmological data.\nFuture models might even have genuinely novel insights simply by asking them.\nBut even if not, a lot of science is amenable to brute force.\nIn particular, any domain that's mainly virtual but has verifiable answers, such as mathematics, economic modeling, theoretical physics, computer science, research could be accelerated by just generating thousands of ideas and then verifying which ones work.\nIn fact, even in an experimental field like biology research, it's also bottlenecked by things like programming and data analysis, constraints that could be substantially alleviated by AI.\nA single invention like nuclear weapons can change the course of history, so the impact of any acceleration here could be dramatic.\nA field that's especially amenable to acceleration is AI research itself.\nBesides being fully virtual, it's the field that AI researchers understand best, have huge incentives to automate, and face no barriers to deploying AI in.\nInitially, this will look like researchers using intern level AI agents to unblock them on specific tasks like software engineering capacity, which is a major bottleneck, or even to help them brainstorm ideas.\nLater, it could look like having the models read all the literature, generate thousands of ideas to improve the algorithms, and automatically testing those algorithms in small scale experiments.\nAn AI model has already produced an AI research paper that was accepted to a conference workshop.\nIn the article, I linked to a long list of other ways that AI is already being applied to speed up AI research.\n\nGiven all this, it's quite plausible that we'll have AI agents doing AI research before people have figured out all the kinks that enable AI to do most remote workshops.\nBroad economic application of AI is therefore not necessarily a good way to gauge AI progress.\nIt might follow explosively after AI capabilities have already advanced substantially.\nSo what's the best case against impressive AI progress by 2030?\nHere's the strongest case against it in my mind: first, concede that AI will likely become superhuman at clearly defined discrete tasks, which means that we'll see continued rapid progress on benchmarks, but it'll remain poor at ill defined high context and long time horizon tasks.\nThat's because these kinds of tasks don't have clearly and quickly verifiable answers, so they can't be trained easily with reinforcement learning.\nThey're also not normally contained in the training data either.\n\nThat could mean the rate of progress on these kinds of tasks will be slow and might even hit a plateau.\nIf you also argue that AI is very bad at these types of tasks today, then even after four to six more years of progress, it might still be bad.\nSecondly, argue that most knowledge work jobs consist significantly of these long horizon, messy high context tasks.\nFor example, software engineers spend a lot of their time figuring out what to build, coordinating with others and understanding massive codebases, rather than just knocking off a list of well defined tasks.\nSo even if their productivity at coding increases 10 times, if coding is only 50% of their work, their productivity will only roughly double.\nA prime example of a messy ill defined task is whatever's involved with having novel research taste.\n\n\nI argue that this task, which is especially important for unlocking an acceleration, is likely to be the hardest to automate.\nIn this kind of scenario, we'll have extremely smart and knowledgeable AI assistants and perhaps an acceleration in some limited virtual domains, perhaps like mathematics research, but AIs will remain tools and humans will remain the main economic and scientific bottleneck.\nHuman AI researchers will see their productivity increase, but not enough to start a positive feedback loop.\nAI progress will remain bottlenecked by novel insights, human coordination, and compute.\nThese limits, maybe combined with problems finding a business model and other barriers to deploying AI, could mean that the models won't create enough revenue to justify training runs over $10 billion.\nThat'll mean progress slows massively after about 2028.\nThen once progress slows, the profit margins on frontier models could collapse, because after one or two years, competitors will release free versions that are basically just as good.\nAnd once the profit margins are down, that will make it even harder to fund continued scaling.\nSo I think that's the strongest case against AGI I can make.\nThe primary counterargument is the earlier graph from METR: models are improving at acting over longer and longer time horizons, which requires deeper contextual understanding and handling of more abstract complex tasks.\nProjecting this trend forward suggests much more autonomous models within four years.\nAnd as I've shown, this could be achieved via many incremental advances of the type I've sketched, but it might also happen via a more fundamental innovation that arises in the coming years.\nThe human brain itself proves that such capabilities are possible.\n\nMoreover, long horizon tasks can most likely be broken down into shorter tasks, like making a plan, executing the first step, and so on.\nIf AI gets good enough at shorter tasks, then long horizon tasks might rapidly start to work too.\nThis is then perhaps the central question of AI forecasting right now: Will the horizon over which AIs can act plateau or continue to improve or perhaps even accelerate like it seemed like it maybe is recently?\nHere are some other ways AI progress could be slower or unimpressive: Disembodied cognitive labour could turn out not to be very useful even in science, because innovation, you could argue, arises mainly out of learning by doing across the whole economy.\nBroader automation, which will take much longer, could be required for innovation.\nSecond, pre training could have big diminishing returns, so maybe GPT-5 and 6 will be disappointing.\nThat could be due to diminishing data quality.\nAI could continue to be bad at visual perception, limiting its ability to use a computer -- see Moravec’s paradox.\nMore generally, AI capabilities could remain very spiky, perhaps weak on dimensions that aren't yet even well understood, and these weak spots could really limit their application.\nBenchmarks could seriously overstate progress due to issues with data contamination and the difficulty of capturing messy tasks.\nAn economic crisis, Taiwan conflict, other disaster, or massive regulatory crackdown could delay investment by several years.\nThere could be other unforeseen bottlenecks.\nThe planning fallacy is the observation that everything takes longer than it expects.\nAnd the reason for the planning fallacy is we don't anticipate all of the ways that something can go wrong.\n\nFor deeper exploration of the skeptical view, see “Are we on the brink of AGI?” by Steve Newman, “The promise of reasoning models” by Matthew Barnnett, “A bear case: My predictions regarding AI progress,” by Thane Ruthenis, and the Dwarkesh podcast with Epoch AI.\nUltimately, the evidence will never be decisive one way or another, and estimates will rely on judgement calls over which people can reasonably differ.\nHowever, I find it hard to look at the evidence and not put significant probability on AGI by 2030.\nWhen do the experts expect AGI to arrive?\nI've made some big claims, and as a non-expert, it would be great if there were some experts who could just tell us what to think.\nUnfortunately there aren't.\nThere are only different groups, each with different drawbacks.\n\nI reviewed the views of these different groups of experts in a separate article, but one striking point is that every group has shortened their estimates dramatically.\nToday even many AI sceptics think AGI will be achieved in 20 years -- mid-career for today's college students.\nSince 2020 the mean estimate on Metaculus for when AGI will be developed has plummeted from 50 years to 5 years.\nThere's problems with the definition used on Metaculus, but this graph reflects a broader trend of declining estimates.\nMy overall read is that AGI by 2030 is within scope of expert opinion, so dismissing it as sci-fi is not justified.\nIndeed, the people who know the most about the technology seem to have the shortest timelines.\nOf course, many experts also think it'll take much longer, but if 30% of experts think a plane will explode and the other 70% say it'll be fine, as non-experts, we shouldn't conclude that it definitely won't.\nIf something is uncertain, that doesn't mean it won't happen.\nSection 3: Why the next five years are crucial.\nIt's natural to assume that since we don't know when AGI will arrive, it might arrive soon, or maybe in the 2030s or the 2040s and so on.\nAlthough that's a common perspective, I'm not sure it's right.\nAs we've seen, the core drivers of AI progress are more compute and better algorithms.\nThat means more powerful AI is most likely to be discovered when compute and the labour used to improve AIs is growing most dramatically.\n\nRight now, the total compute available for training and running AI is growing about three times per year, and the workforce is growing rapidly too.\nThat means that each year the number of AI models that can be run increases three times.\nIn addition, three times more compute can be used for training, and that training can use better algorithms, which means they get more capable as well as more numerous.\nEarlier I argued these trends can continue till 2028, but now we'll show that it most likely runs into bottlenecks shortly thereafter.\nThe first bottleneck is money.\nGoogle, Microsoft and Meta are spending tens of billions of dollars to build AI chip clusters that could train a GPT-6 size model in 2028.\nBut another 10 times scaleup would require hundreds of billions of investments.\nThat's still doable, but it's more than their current annual profits and would be similar to another Apollo programme or Manhattan Project in scale.\nThen GPT-8 would require trillions of dollars.\nAI would need to become a top military priority or already be generating trillions of dollars of revenues to generate that type of investment, and that would probably already be AGI if we had that.\nSecond, even if the money is available, there will be other bottlenecks such as the following: Electricity: Current levels of AI chip sales, if sustained, will mean that AI chips will use about 4% of US electricity by 2028, but another 10 times scaleup would require 40% of US electricity.\nThat's possible, but it would require building a lot of power plants pretty fast.\nChip production: Taiwan Semiconductor Manufacturing Company, TSMC, manufactures all of the world's leading AI chips, but its most advanced capacity is still mostly used for mobile phones.\nThat means that TSMC can still produce five times more AI chips than it does now.\nHowever, reaching 50 times more chips would be a huge challenge, requiring massive construction of chip fabs.\nThird, latency limitations could also prevent training runs as large as GPT-7.\nSo most likely the rate of growth in compute used for training slows around 2028 to 2032.\nAlgorithmic progress is also very rapid right now, but as each discovery gets made, the next one becomes harder and harder because the easier ones get taken first.\nThat means maintaining a constant rate of progress requires exponentially growing research workforce.\nIn 2021, OpenAI had about 300 employees.\nToday it has about 3,000.\nAnthropic and DeepMind have also grown more than three times, and new companies have entered the space.\nThe number of ML papers produced per year has roughly doubled every two years.\nIt's hard to know exactly how to define the workforce of people who are truly advancing AI capabilities versus just selling the product or doing other broader ML research.\nBut if the workforce needs to double every one to three years to maintain recent progress, that can only last so long before the talent pool runs out.\n\nMy read is that growth can easily continue until the end of the decade, but will probably start to slow in the early 2030s, unless by then AI has already become good enough to substitute for AI researchers.\nAlgorithmic progress also depends on increasing compute, because more compute enables more experiments.\nIn fact, with enough compute, researchers can even conduct brute force searches for optimal algorithms.\nThat means that slowing compute growth will correspondingly slow algorithmic progress too.\nIf compute and algorithmic efficiency increased by only 50% annually, rather than the threefold per year they've been increasing recently, a leap equivalent to the leap from GPT-3 to 4 would take over 14 years instead of the two and a half that it actually did.\nSlower growth of compute and the workforce also reduces the probability of discovering a new AI paradigm.\nSo putting all this together, there's a race: Can AI models improve enough to generate enough revenue to pay for their next round of training before it's no longer affordable?\nCan the models start to contribute to algorithmic research before we run out of human researchers to throw at the problem?\nThe moment of truth will be around 2028 to 2032: either progress slows or AI itself overcomes these bottlenecks, allowing progress to continue or even accelerate.\nTwo potential futures for AI.\nIf AI capable of contributing to AI research isn't achieved before around 2030, then the annual probability of its discovery decreases substantially.\nProgress, of course, won't suddenly halt, it'll slow more gradually.\nIn the article, you can see a graph where I look at the probability of AGI being discovered each year.\nI think it's increasing from now until around 2027, and then it starts to gradually decline, reaching much lower levels, perhaps 10 times lower than today, by the mid-2030s.\nSo roughly, we can plan for two scenarios.\nEither we hit AI that can cause transformative effects by 2030, AI progress continues or even accelerates, and we probably enter a period of explosive change; or AI progress will slow.\nThe models will get much better at clearly defined tasks, but they won't be able to do the ill defined long horizon work required to unlock a new growth regime.\nWe'll see a lot of AI automation, but otherwise the world will look much more like normal.\nWe'll know a lot more about which scenario we're in within the next few years.\n\nI roughly think of these two scenarios as a 50/50, though my estimates can vary between 30% and 80% depending on the day.\nAnd of course, hybrid scenarios are also possible.\nScaling could slow more gradually or be delayed several years by a Taiwan conflict pushing AGI into the early ‘30s.\nBut I find it useful to just start with a simple model.\nAnd of course the numbers you put on each scenario also depend on your definition of AGI, and also what kind of AGI you think will be transformative.\nI'm most interested in forecasting AI that can meaningfully contribute to AI research.\nAGI in the sense of a model that can do almost all remote work tasks cheaper and better than a human may well take longer due to a long tail of deployment bottlenecks.\n\nOn the other hand, AGI in the sense of better than almost all humans at reasoning when given an hour, seems to be basically here already.\nConclusion.\nSo, will we have AGI by 2030?\nWhatever the exact definition, significant evidence supports this possibility.\nWe may only need to sustain current trends for a few more years to get there.\nWe're never going to have decisive evidence either way, but it seems clearly overconfident to me to think that the probability before 2030 is below 10%.\nGiven the massive implications and serious risks, that's enough evidence to take this possibility extremely seriously.\nToday's situation feels like February 2020, just before the COVID lockdowns.\nA clear trend suggests imminent massive change, yet most people continue their lives as normal.\nIn an upcoming article, I'll argue that AGI automating much of remote work and doubling the economy could be a conservative outcome.\nIf AI can do AI research, the gap between AGI and superintelligence -- AI that's more capable than humans at almost all tasks -- could be short.\nThis could enable the equivalent of a massive expansion in the research workforce, potentially delivering a century's worth of scientific progress in under a decade.\nRobotics, bioengineering, and space settlements could all arrive far sooner than is commonly anticipated.\nThe next five years would be the start of one of the most pivotal periods in history.\nSo thank you for listening.\nThis was the first chapter in a new guide to how to help AI go well that I'm writing with 80,000 Hours.\nYou can see a summary of the guide on 80000hours.org/agi/guide/summary.\nIt includes a summary of our current thoughts about what to do about this issue, and also some tactical advice on how to switch into it.\n\nIf you already know you'd like to switch, apply to speak to the team one on one.\nThey can help you with planning, job opportunities, and introductions to people in the field.\nOtherwise, stay tuned for more chapters.\nThanks for listening.\nBye.\n",
  "dumpedAt": "2025-07-21T18:43:25.809Z"
}