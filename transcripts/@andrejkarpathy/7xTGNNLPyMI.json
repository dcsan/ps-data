{
  "episodeId": "7xTGNNLPyMI",
  "channelSlug": "@andrejkarpathy",
  "title": "Deep Dive into LLMs like ChatGPT",
  "publishedAt": "2025-02-05T18:23:47.000Z",
  "rawLines": [
    {
      "lang": "en",
      "text": "hi everyone so I've wanted to make this",
      "offset": 0.719,
      "duration": 4.681
    },
    {
      "lang": "en",
      "text": "video for a while it is a comprehensive",
      "offset": 2.76,
      "duration": 5.32
    },
    {
      "lang": "en",
      "text": "but General audience introduction to",
      "offset": 5.4,
      "duration": 5.8
    },
    {
      "lang": "en",
      "text": "large language models like Chachi PT and",
      "offset": 8.08,
      "duration": 4.519
    },
    {
      "lang": "en",
      "text": "what I'm hoping to achieve in this video",
      "offset": 11.2,
      "duration": 3.439
    },
    {
      "lang": "en",
      "text": "is to give you kind of mental models for",
      "offset": 12.599,
      "duration": 4.641
    },
    {
      "lang": "en",
      "text": "thinking through what it is that this",
      "offset": 14.639,
      "duration": 5.081
    },
    {
      "lang": "en",
      "text": "tool is it is obviously magical and",
      "offset": 17.24,
      "duration": 5.199
    },
    {
      "lang": "en",
      "text": "amazing in some respects it's uh really",
      "offset": 19.72,
      "duration": 4.2
    },
    {
      "lang": "en",
      "text": "good at some things not very good at",
      "offset": 22.439,
      "duration": 3
    },
    {
      "lang": "en",
      "text": "other things and there's also a lot of",
      "offset": 23.92,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "sharp edges to be aware of so what is",
      "offset": 25.439,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "behind this text box you can put",
      "offset": 28.08,
      "duration": 4.12
    },
    {
      "lang": "en",
      "text": "anything in there and press enter but uh",
      "offset": 29.679,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "what should we be putting there and what",
      "offset": 32.2,
      "duration": 4.519
    },
    {
      "lang": "en",
      "text": "are these words generated back how does",
      "offset": 34.559,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "this work and what what are you talking",
      "offset": 36.719,
      "duration": 3.721
    },
    {
      "lang": "en",
      "text": "to exactly so I'm hoping to get at all",
      "offset": 38.239,
      "duration": 3.961
    },
    {
      "lang": "en",
      "text": "those topics in this video we're going",
      "offset": 40.44,
      "duration": 3.599
    },
    {
      "lang": "en",
      "text": "to go through the entire pipeline of how",
      "offset": 42.2,
      "duration": 3.4
    },
    {
      "lang": "en",
      "text": "this stuff is built but I'm going to",
      "offset": 44.039,
      "duration": 4.121
    },
    {
      "lang": "en",
      "text": "keep everything uh sort of accessible to",
      "offset": 45.6,
      "duration": 4.92
    },
    {
      "lang": "en",
      "text": "a general audience so let's take a look",
      "offset": 48.16,
      "duration": 3.64
    },
    {
      "lang": "en",
      "text": "at first how you build something like",
      "offset": 50.52,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "chpt and along the way I'm going to talk",
      "offset": 51.8,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "about um you know some of the sort of",
      "offset": 53.8,
      "duration": 5.919
    },
    {
      "lang": "en",
      "text": "cognitive psychological implications of",
      "offset": 56.92,
      "duration": 5.959
    },
    {
      "lang": "en",
      "text": "the tools okay so let's build Chachi PT",
      "offset": 59.719,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "so there's going to be multiple stages",
      "offset": 62.879,
      "duration": 4.121
    },
    {
      "lang": "en",
      "text": "arranged sequentially the first stage is",
      "offset": 64.439,
      "duration": 5.161
    },
    {
      "lang": "en",
      "text": "called the pre-training stage and the",
      "offset": 67,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "first step of the pre-training stage is",
      "offset": 69.6,
      "duration": 3.72
    },
    {
      "lang": "en",
      "text": "to download and process the internet now",
      "offset": 71.08,
      "duration": 3.56
    },
    {
      "lang": "en",
      "text": "to get a sense of what this roughly",
      "offset": 73.32,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "looks like I recommend looking at this",
      "offset": 74.64,
      "duration": 5.839
    },
    {
      "lang": "en",
      "text": "URL here so um this company called",
      "offset": 76.84,
      "duration": 6.599
    },
    {
      "lang": "en",
      "text": "hugging face uh collected and created",
      "offset": 80.479,
      "duration": 5.801
    },
    {
      "lang": "en",
      "text": "and curated this data set called Fine",
      "offset": 83.439,
      "duration": 5.161
    },
    {
      "lang": "en",
      "text": "web and they go into a lot of detail on",
      "offset": 86.28,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "this block post on how how they",
      "offset": 88.6,
      "duration": 3.799
    },
    {
      "lang": "en",
      "text": "constructed the fine web data set and",
      "offset": 90.119,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "all of the major llm providers like open",
      "offset": 92.399,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "AI anthropic and Google and so on will",
      "offset": 94.28,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "have some equivalent internally of",
      "offset": 96.399,
      "duration": 4.76
    },
    {
      "lang": "en",
      "text": "something like the fine web data set so",
      "offset": 98.84,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "roughly what are we trying to achieve",
      "offset": 101.159,
      "duration": 3.32
    },
    {
      "lang": "en",
      "text": "here we're trying to get ton of text",
      "offset": 102.36,
      "duration": 3.439
    },
    {
      "lang": "en",
      "text": "from the internet from publicly",
      "offset": 104.479,
      "duration": 3.481
    },
    {
      "lang": "en",
      "text": "available sources so we're trying to",
      "offset": 105.799,
      "duration": 4.721
    },
    {
      "lang": "en",
      "text": "have a huge quantity of very high",
      "offset": 107.96,
      "duration": 5.159
    },
    {
      "lang": "en",
      "text": "quality documents and we also want very",
      "offset": 110.52,
      "duration": 4.599
    },
    {
      "lang": "en",
      "text": "large diversity of documents because we",
      "offset": 113.119,
      "duration": 3.64
    },
    {
      "lang": "en",
      "text": "want to have a lot of knowledge inside",
      "offset": 115.119,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "these models so we want large diversity",
      "offset": 116.759,
      "duration": 4.801
    },
    {
      "lang": "en",
      "text": "of high quality documents and we want",
      "offset": 119.439,
      "duration": 4.6
    },
    {
      "lang": "en",
      "text": "many many of them and achieving this is",
      "offset": 121.56,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "uh quite complicated and as you can see",
      "offset": 124.039,
      "duration": 4.521
    },
    {
      "lang": "en",
      "text": "here takes multiple stages to do well so",
      "offset": 125.64,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "let's take a look at what some of these",
      "offset": 128.56,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "stages look like in a bit for now I'd",
      "offset": 129.8,
      "duration": 3.4
    },
    {
      "lang": "en",
      "text": "like to just like to note that for",
      "offset": 131.76,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "example the fine web data set which is",
      "offset": 133.2,
      "duration": 3.319
    },
    {
      "lang": "en",
      "text": "fairly representative what you would see",
      "offset": 134.8,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "in a production grade application",
      "offset": 136.519,
      "duration": 3.881
    },
    {
      "lang": "en",
      "text": "actually ends up being only about 44",
      "offset": 138.64,
      "duration": 4.959
    },
    {
      "lang": "en",
      "text": "terabyt of dis space um you can get a",
      "offset": 140.4,
      "duration": 4.76
    },
    {
      "lang": "en",
      "text": "USB stick for like a terabyte very",
      "offset": 143.599,
      "duration": 3.481
    },
    {
      "lang": "en",
      "text": "easily or I think this could fit on a",
      "offset": 145.16,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "single hard drive almost today so this",
      "offset": 147.08,
      "duration": 4.519
    },
    {
      "lang": "en",
      "text": "is not a huge amount of data at the end",
      "offset": 149.48,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "of the day even though the internet is",
      "offset": 151.599,
      "duration": 3.881
    },
    {
      "lang": "en",
      "text": "very very large we're working with text",
      "offset": 153.319,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "and we're also filtering it aggressively",
      "offset": 155.48,
      "duration": 3.88
    },
    {
      "lang": "en",
      "text": "so we end up with about 44 terabytes in",
      "offset": 157.319,
      "duration": 5.041
    },
    {
      "lang": "en",
      "text": "this example so let's take a look at uh",
      "offset": 159.36,
      "duration": 5.32
    },
    {
      "lang": "en",
      "text": "kind of what this data looks like and",
      "offset": 162.36,
      "duration": 4.92
    },
    {
      "lang": "en",
      "text": "what some of these stages uh also are so",
      "offset": 164.68,
      "duration": 3.8
    },
    {
      "lang": "en",
      "text": "the starting point for a lot of these",
      "offset": 167.28,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "efforts and something that contributes",
      "offset": 168.48,
      "duration": 4.28
    },
    {
      "lang": "en",
      "text": "most of the data by the end of it is",
      "offset": 170.48,
      "duration": 5.56
    },
    {
      "lang": "en",
      "text": "Data from common crawl so common craw is",
      "offset": 172.76,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "an organization that has been basically",
      "offset": 176.04,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "scouring the internet since 2007 so as",
      "offset": 177.48,
      "duration": 5.679
    },
    {
      "lang": "en",
      "text": "of 2024 for example common CW has",
      "offset": 180.76,
      "duration": 4.759
    },
    {
      "lang": "en",
      "text": "indexed 2.7 billion web",
      "offset": 183.159,
      "duration": 4.881
    },
    {
      "lang": "en",
      "text": "pages uh and uh they have all these",
      "offset": 185.519,
      "duration": 4.28
    },
    {
      "lang": "en",
      "text": "crawlers going around the internet and",
      "offset": 188.04,
      "duration": 3.08
    },
    {
      "lang": "en",
      "text": "what you end up doing basically is you",
      "offset": 189.799,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "start with a few seed web pages and then",
      "offset": 191.12,
      "duration": 3.88
    },
    {
      "lang": "en",
      "text": "you follow all the links and you just",
      "offset": 193.319,
      "duration": 2.84
    },
    {
      "lang": "en",
      "text": "keep following links and you keep",
      "offset": 195,
      "duration": 2.48
    },
    {
      "lang": "en",
      "text": "indexing all the information and you end",
      "offset": 196.159,
      "duration": 2.841
    },
    {
      "lang": "en",
      "text": "up with a ton of data of the internet",
      "offset": 197.48,
      "duration": 3.96
    },
    {
      "lang": "en",
      "text": "over time so this is usually the",
      "offset": 199,
      "duration": 5.08
    },
    {
      "lang": "en",
      "text": "starting point for a lot of the uh for a",
      "offset": 201.44,
      "duration": 4.84
    },
    {
      "lang": "en",
      "text": "lot of these efforts now this common C",
      "offset": 204.08,
      "duration": 3.879
    },
    {
      "lang": "en",
      "text": "data is quite raw and is filtered in",
      "offset": 206.28,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "many many different ways",
      "offset": 207.959,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "so here they Pro they document this is",
      "offset": 210.2,
      "duration": 4.84
    },
    {
      "lang": "en",
      "text": "the same diagram they document a little",
      "offset": 213.159,
      "duration": 3.561
    },
    {
      "lang": "en",
      "text": "bit the kind of processing that happens",
      "offset": 215.04,
      "duration": 4.479
    },
    {
      "lang": "en",
      "text": "in these stages so the first thing here",
      "offset": 216.72,
      "duration": 4.68
    },
    {
      "lang": "en",
      "text": "is something called URL",
      "offset": 219.519,
      "duration": 4.36
    },
    {
      "lang": "en",
      "text": "filtering so what that is referring to",
      "offset": 221.4,
      "duration": 5.559
    },
    {
      "lang": "en",
      "text": "is that there's these block",
      "offset": 223.879,
      "duration": 3.08
    },
    {
      "lang": "en",
      "text": "lists of uh basically URLs that are or",
      "offset": 227.04,
      "duration": 5.559
    },
    {
      "lang": "en",
      "text": "domains that uh you don't want to be",
      "offset": 230.36,
      "duration": 3.959
    },
    {
      "lang": "en",
      "text": "getting data from so usually this",
      "offset": 232.599,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "includes things like U malware websites",
      "offset": 234.319,
      "duration": 4.601
    },
    {
      "lang": "en",
      "text": "spam websites marketing websites uh",
      "offset": 236.599,
      "duration": 4.441
    },
    {
      "lang": "en",
      "text": "racist websites adult sites and things",
      "offset": 238.92,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "like that so there's a ton of different",
      "offset": 241.04,
      "duration": 3
    },
    {
      "lang": "en",
      "text": "types of websites that are just",
      "offset": 242.68,
      "duration": 3.639
    },
    {
      "lang": "en",
      "text": "eliminated at this stage because we",
      "offset": 244.04,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "don't want them in our data set um the",
      "offset": 246.319,
      "duration": 4.521
    },
    {
      "lang": "en",
      "text": "second part is text extraction you have",
      "offset": 248.76,
      "duration": 3.479
    },
    {
      "lang": "en",
      "text": "to remember that all these web pages",
      "offset": 250.84,
      "duration": 3.64
    },
    {
      "lang": "en",
      "text": "this is the raw HTML of these web pages",
      "offset": 252.239,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "that are being saved by these crawlers",
      "offset": 254.48,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "so when I go to inspect",
      "offset": 256.799,
      "duration": 4.601
    },
    {
      "lang": "en",
      "text": "here this is what the raw HTML actually",
      "offset": 258.56,
      "duration": 4.84
    },
    {
      "lang": "en",
      "text": "looks like you'll notice that it's got",
      "offset": 261.4,
      "duration": 5.48
    },
    {
      "lang": "en",
      "text": "all this markup uh like lists and stuff",
      "offset": 263.4,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "like that and there's CSS and all this",
      "offset": 266.88,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "kind of stuff so this is um computer",
      "offset": 268.84,
      "duration": 4.84
    },
    {
      "lang": "en",
      "text": "code almost for these web pages but what",
      "offset": 271.28,
      "duration": 4.28
    },
    {
      "lang": "en",
      "text": "we really want is we just want this text",
      "offset": 273.68,
      "duration": 3.48
    },
    {
      "lang": "en",
      "text": "right we just want the text of this web",
      "offset": 275.56,
      "duration": 3.32
    },
    {
      "lang": "en",
      "text": "page and we don't want the navigation",
      "offset": 277.16,
      "duration": 3.319
    },
    {
      "lang": "en",
      "text": "and things like that so there's a lot of",
      "offset": 278.88,
      "duration": 3.879
    },
    {
      "lang": "en",
      "text": "filtering and processing uh and heris",
      "offset": 280.479,
      "duration": 4.761
    },
    {
      "lang": "en",
      "text": "that go into uh adequately filtering for",
      "offset": 282.759,
      "duration": 5.521
    },
    {
      "lang": "en",
      "text": "just their uh good content of these web",
      "offset": 285.24,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "pages the next stage here is language",
      "offset": 288.28,
      "duration": 5.479
    },
    {
      "lang": "en",
      "text": "filtering so for example fine web",
      "offset": 290.52,
      "duration": 5.8
    },
    {
      "lang": "en",
      "text": "filters uh using a language classifier",
      "offset": 293.759,
      "duration": 4.801
    },
    {
      "lang": "en",
      "text": "they try to guess what language every",
      "offset": 296.32,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "single web page is in and then they only",
      "offset": 298.56,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "keep web pages that have more than 65%",
      "offset": 300.479,
      "duration": 3.641
    },
    {
      "lang": "en",
      "text": "of English as an",
      "offset": 302.56,
      "duration": 3.479
    },
    {
      "lang": "en",
      "text": "example and so you can get a sense that",
      "offset": 304.12,
      "duration": 3.359
    },
    {
      "lang": "en",
      "text": "this is like a design decision that",
      "offset": 306.039,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "different companies can uh can uh take",
      "offset": 307.479,
      "duration": 5.321
    },
    {
      "lang": "en",
      "text": "for themselves what fraction of all",
      "offset": 310.12,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "different types of languages are we",
      "offset": 312.8,
      "duration": 3.119
    },
    {
      "lang": "en",
      "text": "going to include in our data set because",
      "offset": 314.039,
      "duration": 3.641
    },
    {
      "lang": "en",
      "text": "for example if we filter out all of the",
      "offset": 315.919,
      "duration": 3.481
    },
    {
      "lang": "en",
      "text": "Spanish as an example then you might",
      "offset": 317.68,
      "duration": 3.56
    },
    {
      "lang": "en",
      "text": "imagine that our model later will not be",
      "offset": 319.4,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "very good at Spanish because it's just",
      "offset": 321.24,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "never seen that much data of that",
      "offset": 322.52,
      "duration": 3.959
    },
    {
      "lang": "en",
      "text": "language and so different companies can",
      "offset": 324.36,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "focus on multilingual performance to uh",
      "offset": 326.479,
      "duration": 4.44
    },
    {
      "lang": "en",
      "text": "to a different degree as an example so",
      "offset": 328.84,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "fine web is quite focused on English and",
      "offset": 330.919,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "so their language model if they end up",
      "offset": 333.4,
      "duration": 3.4
    },
    {
      "lang": "en",
      "text": "training one later will be very good at",
      "offset": 335,
      "duration": 3.479
    },
    {
      "lang": "en",
      "text": "English but not may be very good at",
      "offset": 336.8,
      "duration": 2.92
    },
    {
      "lang": "en",
      "text": "other",
      "offset": 338.479,
      "duration": 3.241
    },
    {
      "lang": "en",
      "text": "languages after language filtering",
      "offset": 339.72,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "there's a few other filtering steps and",
      "offset": 341.72,
      "duration": 5.24
    },
    {
      "lang": "en",
      "text": "D duplication and things like that um",
      "offset": 343.4,
      "duration": 5.72
    },
    {
      "lang": "en",
      "text": "finishing with for example the pii",
      "offset": 346.96,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "removal this is personally identifiable",
      "offset": 349.12,
      "duration": 5.359
    },
    {
      "lang": "en",
      "text": "information so as an example addresses",
      "offset": 352.24,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "Social Security numbers and things like",
      "offset": 354.479,
      "duration": 3.201
    },
    {
      "lang": "en",
      "text": "that you would try to detect them and",
      "offset": 356,
      "duration": 2.96
    },
    {
      "lang": "en",
      "text": "you would try to filter out those kinds",
      "offset": 357.68,
      "duration": 2.56
    },
    {
      "lang": "en",
      "text": "of web pages from the the data set as",
      "offset": 358.96,
      "duration": 3.72
    },
    {
      "lang": "en",
      "text": "well so there's a lot of stages here and",
      "offset": 360.24,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "I won't go into full detail but it is a",
      "offset": 362.68,
      "duration": 3.959
    },
    {
      "lang": "en",
      "text": "fairly extensive part of the",
      "offset": 365.28,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "pre-processing and you end up with for",
      "offset": 366.639,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "example the fine web data set so when",
      "offset": 368.72,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "you click in on it uh you can see some",
      "offset": 370.8,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "examples here of what this actually ends",
      "offset": 372.72,
      "duration": 3.479
    },
    {
      "lang": "en",
      "text": "up looking like and anyone can download",
      "offset": 374.24,
      "duration": 5.079
    },
    {
      "lang": "en",
      "text": "this on the huging phase web page and so",
      "offset": 376.199,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "here are some examples of the final text",
      "offset": 379.319,
      "duration": 5.081
    },
    {
      "lang": "en",
      "text": "that ends up in the training set so this",
      "offset": 381.319,
      "duration": 6.201
    },
    {
      "lang": "en",
      "text": "is some article about tornadoes in",
      "offset": 384.4,
      "duration": 6.48
    },
    {
      "lang": "en",
      "text": "2012 um so there's some t tadoes in 2020",
      "offset": 387.52,
      "duration": 5.48
    },
    {
      "lang": "en",
      "text": "in 2012 and what",
      "offset": 390.88,
      "duration": 5.4
    },
    {
      "lang": "en",
      "text": "happened uh this next one is something",
      "offset": 393,
      "duration": 5.56
    },
    {
      "lang": "en",
      "text": "about did you know you have two little",
      "offset": 396.28,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "yellow 9vt battery sized adrenal glands",
      "offset": 398.56,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "in your body okay so this is some kind",
      "offset": 401,
      "duration": 5.919
    },
    {
      "lang": "en",
      "text": "of a odd medical",
      "offset": 403.68,
      "duration": 5.32
    },
    {
      "lang": "en",
      "text": "article so just think of these as",
      "offset": 406.919,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "basically uh web pages on the internet",
      "offset": 409,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "filtered just for the text in various",
      "offset": 411.639,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "ways and now we have a ton of text 40",
      "offset": 413.8,
      "duration": 4.959
    },
    {
      "lang": "en",
      "text": "terabytes off it and that now is the",
      "offset": 416.759,
      "duration": 4.041
    },
    {
      "lang": "en",
      "text": "starting point for the next step of this",
      "offset": 418.759,
      "duration": 3.961
    },
    {
      "lang": "en",
      "text": "stage now I wanted to give you an",
      "offset": 420.8,
      "duration": 3.32
    },
    {
      "lang": "en",
      "text": "intuitive sense of where we are right",
      "offset": 422.72,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "now so I took the first 200 web pages",
      "offset": 424.12,
      "duration": 5.079
    },
    {
      "lang": "en",
      "text": "here and remember we have tons of them",
      "offset": 426.639,
      "duration": 4.601
    },
    {
      "lang": "en",
      "text": "and I just take all that text and I just",
      "offset": 429.199,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "put it all together concatenate it and",
      "offset": 431.24,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "so this is what we end up with we just",
      "offset": 433.52,
      "duration": 5.119
    },
    {
      "lang": "en",
      "text": "get this just just raw text raw internet",
      "offset": 435,
      "duration": 5.96
    },
    {
      "lang": "en",
      "text": "text and there's a ton of it even in",
      "offset": 438.639,
      "duration": 3.96
    },
    {
      "lang": "en",
      "text": "these 200 web pages so I can continue",
      "offset": 440.96,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "zooming out here and we just have this",
      "offset": 442.599,
      "duration": 5.561
    },
    {
      "lang": "en",
      "text": "like massive tapestry of Text data and",
      "offset": 444.879,
      "duration": 5.32
    },
    {
      "lang": "en",
      "text": "this text data has all these p patterns",
      "offset": 448.16,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "and what we want to do now is we want to",
      "offset": 450.199,
      "duration": 3.161
    },
    {
      "lang": "en",
      "text": "start training neural networks on this",
      "offset": 451.84,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "data so the neural networks can",
      "offset": 453.36,
      "duration": 6.04
    },
    {
      "lang": "en",
      "text": "internalize and model how this text",
      "offset": 455.28,
      "duration": 7.359
    },
    {
      "lang": "en",
      "text": "flows right so we just have this giant",
      "offset": 459.4,
      "duration": 6.079
    },
    {
      "lang": "en",
      "text": "texture of text and now we want to get",
      "offset": 462.639,
      "duration": 5.721
    },
    {
      "lang": "en",
      "text": "neural Nets that mimic it okay now",
      "offset": 465.479,
      "duration": 5.801
    },
    {
      "lang": "en",
      "text": "before we plug text into neural networks",
      "offset": 468.36,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "we have to decide how we're going to",
      "offset": 471.28,
      "duration": 3.319
    },
    {
      "lang": "en",
      "text": "represent this text uh and how we're",
      "offset": 472.52,
      "duration": 4.679
    },
    {
      "lang": "en",
      "text": "going to feed it in now the way our",
      "offset": 474.599,
      "duration": 4.04
    },
    {
      "lang": "en",
      "text": "technology works for these neuron Lots",
      "offset": 477.199,
      "duration": 2.761
    },
    {
      "lang": "en",
      "text": "is that they expect",
      "offset": 478.639,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "a one-dimensional sequence of symbols",
      "offset": 479.96,
      "duration": 5.959
    },
    {
      "lang": "en",
      "text": "and they want a finite set of symbols",
      "offset": 482.879,
      "duration": 5.201
    },
    {
      "lang": "en",
      "text": "that are possible and so we have to",
      "offset": 485.919,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "decide what are the symbols and then we",
      "offset": 488.08,
      "duration": 3.679
    },
    {
      "lang": "en",
      "text": "have to represent our data as",
      "offset": 490.159,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "one-dimensional sequence of those",
      "offset": 491.759,
      "duration": 4.681
    },
    {
      "lang": "en",
      "text": "symbols so right now what we have is a",
      "offset": 494.24,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "onedimensional sequence of text it",
      "offset": 496.44,
      "duration": 4.28
    },
    {
      "lang": "en",
      "text": "starts here and it goes here and then it",
      "offset": 498.56,
      "duration": 3.639
    },
    {
      "lang": "en",
      "text": "comes here Etc so this is a",
      "offset": 500.72,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "onedimensional sequence even though on",
      "offset": 502.199,
      "duration": 3.881
    },
    {
      "lang": "en",
      "text": "my monitor of course it's laid out in a",
      "offset": 503.84,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "two-dimensional way but it goes from",
      "offset": 506.08,
      "duration": 3.679
    },
    {
      "lang": "en",
      "text": "left to right and top to bottom right so",
      "offset": 507.759,
      "duration": 4.481
    },
    {
      "lang": "en",
      "text": "it's a one-dimensional sequence of text",
      "offset": 509.759,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "now this being computers of course",
      "offset": 512.24,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "there's an underlying representation",
      "offset": 513.919,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "here so if I do what's called utf8 uh",
      "offset": 515.44,
      "duration": 5.719
    },
    {
      "lang": "en",
      "text": "encode this text then I can get the raw",
      "offset": 518.159,
      "duration": 6.041
    },
    {
      "lang": "en",
      "text": "bits that correspond to this text in the",
      "offset": 521.159,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "computer and that's what uh that looks",
      "offset": 524.2,
      "duration": 6.04
    },
    {
      "lang": "en",
      "text": "like this so it turns out that for",
      "offset": 526.519,
      "duration": 6.801
    },
    {
      "lang": "en",
      "text": "example this very first bar here is the",
      "offset": 530.24,
      "duration": 5.8
    },
    {
      "lang": "en",
      "text": "first uh eight bits as an",
      "offset": 533.32,
      "duration": 5.759
    },
    {
      "lang": "en",
      "text": "example so what is this thing right this",
      "offset": 536.04,
      "duration": 5.88
    },
    {
      "lang": "en",
      "text": "is um representation that we are looking",
      "offset": 539.079,
      "duration": 5.481
    },
    {
      "lang": "en",
      "text": "for uh in in a certain sense we have",
      "offset": 541.92,
      "duration": 5
    },
    {
      "lang": "en",
      "text": "exactly two possible symbols zero and",
      "offset": 544.56,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "one and we have a very long sequence of",
      "offset": 546.92,
      "duration": 7.32
    },
    {
      "lang": "en",
      "text": "it right now as it turns out um this",
      "offset": 550.16,
      "duration": 6.32
    },
    {
      "lang": "en",
      "text": "sequence length is actually going to be",
      "offset": 554.24,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "very finite and precious resource uh in",
      "offset": 556.48,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "our neural network and we actually don't",
      "offset": 559.2,
      "duration": 3.879
    },
    {
      "lang": "en",
      "text": "want extremely long sequences of just",
      "offset": 561.04,
      "duration": 4.68
    },
    {
      "lang": "en",
      "text": "two symbols instead what we want is we",
      "offset": 563.079,
      "duration": 6.88
    },
    {
      "lang": "en",
      "text": "want to trade off uh this um symbol",
      "offset": 565.72,
      "duration": 7.2
    },
    {
      "lang": "en",
      "text": "size uh of this vocabulary as we call it",
      "offset": 569.959,
      "duration": 5.32
    },
    {
      "lang": "en",
      "text": "and the resulting sequence length so we",
      "offset": 572.92,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "don't want just two symbols and",
      "offset": 575.279,
      "duration": 3.401
    },
    {
      "lang": "en",
      "text": "extremely long sequences we're going to",
      "offset": 576.44,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "want more symbols and shorter sequences",
      "offset": 578.68,
      "duration": 6.159
    },
    {
      "lang": "en",
      "text": "okay so one naive way of compressing or",
      "offset": 582.12,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "decreasing the length of our sequence",
      "offset": 584.839,
      "duration": 4.761
    },
    {
      "lang": "en",
      "text": "here is to basically uh consider some",
      "offset": 586.36,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "group of consecutive bits for example",
      "offset": 589.6,
      "duration": 5.359
    },
    {
      "lang": "en",
      "text": "eight bits and group them into a single",
      "offset": 591.88,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "what's called bite so because uh these",
      "offset": 594.959,
      "duration": 5.081
    },
    {
      "lang": "en",
      "text": "bits are either on or off if we take a",
      "offset": 597.88,
      "duration": 3.88
    },
    {
      "lang": "en",
      "text": "group of eight of them there turns out",
      "offset": 600.04,
      "duration": 4.239
    },
    {
      "lang": "en",
      "text": "to be only 256 possible combinations of",
      "offset": 601.76,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "how these bits could be on or off and so",
      "offset": 604.279,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "therefore we can re repesent this",
      "offset": 606.48,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "sequence into a sequence of bytes",
      "offset": 607.88,
      "duration": 5.639
    },
    {
      "lang": "en",
      "text": "instead so this sequence of bytes will",
      "offset": 610.64,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "be eight times shorter but now we have",
      "offset": 613.519,
      "duration": 5.56
    },
    {
      "lang": "en",
      "text": "256 possible symbols so every number",
      "offset": 616.24,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "here goes from 0 to",
      "offset": 619.079,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "255 now I really encourage you to think",
      "offset": 620.8,
      "duration": 4.36
    },
    {
      "lang": "en",
      "text": "of these not as numbers but as unique",
      "offset": 622.92,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "IDs or like unique symbols so maybe it's",
      "offset": 625.16,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "a bit more maybe it's better to actually",
      "offset": 628.04,
      "duration": 4.039
    },
    {
      "lang": "en",
      "text": "think of these to replace every one of",
      "offset": 630.44,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "these with a unique Emoji you'd get",
      "offset": 632.079,
      "duration": 5.281
    },
    {
      "lang": "en",
      "text": "something like this so um we basically",
      "offset": 634.04,
      "duration": 4.919
    },
    {
      "lang": "en",
      "text": "have a sequence of emojis and there's",
      "offset": 637.36,
      "duration": 3.96
    },
    {
      "lang": "en",
      "text": "256 possible emojis you can think of it",
      "offset": 638.959,
      "duration": 5.88
    },
    {
      "lang": "en",
      "text": "that way now it turns out that in",
      "offset": 641.32,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "production for state-of-the-art language",
      "offset": 644.839,
      "duration": 3.56
    },
    {
      "lang": "en",
      "text": "models uh you actually want to go even",
      "offset": 646.44,
      "duration": 3.88
    },
    {
      "lang": "en",
      "text": "Beyond this you want to continue to",
      "offset": 648.399,
      "duration": 4.12
    },
    {
      "lang": "en",
      "text": "shrink the length of the sequence uh",
      "offset": 650.32,
      "duration": 4.519
    },
    {
      "lang": "en",
      "text": "because again it is a precious resource",
      "offset": 652.519,
      "duration": 5.201
    },
    {
      "lang": "en",
      "text": "in return for more symbols in your",
      "offset": 654.839,
      "duration": 5.24
    },
    {
      "lang": "en",
      "text": "vocabulary and the way this is done is",
      "offset": 657.72,
      "duration": 4.44
    },
    {
      "lang": "en",
      "text": "done by running what's called The Bite",
      "offset": 660.079,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "pair encoding algorithm and the way this",
      "offset": 662.16,
      "duration": 4.2
    },
    {
      "lang": "en",
      "text": "works is we're basically looking for",
      "offset": 664.399,
      "duration": 5.88
    },
    {
      "lang": "en",
      "text": "consecutive bytes or symbols that are",
      "offset": 666.36,
      "duration": 7.479
    },
    {
      "lang": "en",
      "text": "very common so for example turns out",
      "offset": 670.279,
      "duration": 6.761
    },
    {
      "lang": "en",
      "text": "that the sequence 116 followed by 32 is",
      "offset": 673.839,
      "duration": 5.201
    },
    {
      "lang": "en",
      "text": "quite common and occurs very frequently",
      "offset": 677.04,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "so what we're going to do is we're going",
      "offset": 679.04,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "to group uh this um pair into a new",
      "offset": 680.32,
      "duration": 6.319
    },
    {
      "lang": "en",
      "text": "symbol so we're going to Mint a symbol",
      "offset": 684.48,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "with an ID 256 and we're going to",
      "offset": 686.639,
      "duration": 5.961
    },
    {
      "lang": "en",
      "text": "rewrite every single uh pair 11632 with",
      "offset": 688.88,
      "duration": 5.639
    },
    {
      "lang": "en",
      "text": "this new symbol and then can we can",
      "offset": 692.6,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "iterate this algorithm as many times as",
      "offset": 694.519,
      "duration": 4.201
    },
    {
      "lang": "en",
      "text": "we wish and each time when we mint a new",
      "offset": 696.2,
      "duration": 4.52
    },
    {
      "lang": "en",
      "text": "symbol we're decreasing the length and",
      "offset": 698.72,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "we're increasing the symbol size and in",
      "offset": 700.72,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "practice it turns out that a pretty good",
      "offset": 703.6,
      "duration": 4.479
    },
    {
      "lang": "en",
      "text": "setting of um the basically the",
      "offset": 705.36,
      "duration": 4.44
    },
    {
      "lang": "en",
      "text": "vocabulary size turns out to be about",
      "offset": 708.079,
      "duration": 4.2
    },
    {
      "lang": "en",
      "text": "100,000 possible symbols so in",
      "offset": 709.8,
      "duration": 5.599
    },
    {
      "lang": "en",
      "text": "particular GPT 4 uses",
      "offset": 712.279,
      "duration": 4.68
    },
    {
      "lang": "en",
      "text": "100,",
      "offset": 715.399,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "277 symbols",
      "offset": 716.959,
      "duration": 7.201
    },
    {
      "lang": "en",
      "text": "um and this process of converting from",
      "offset": 719.959,
      "duration": 7.12
    },
    {
      "lang": "en",
      "text": "raw text into these symbols or as we",
      "offset": 724.16,
      "duration": 6.239
    },
    {
      "lang": "en",
      "text": "call them tokens is the process called",
      "offset": 727.079,
      "duration": 5.681
    },
    {
      "lang": "en",
      "text": "tokenization so let's now take a look at",
      "offset": 730.399,
      "duration": 5.201
    },
    {
      "lang": "en",
      "text": "how gp4 performs tokenization conting",
      "offset": 732.76,
      "duration": 5.439
    },
    {
      "lang": "en",
      "text": "from text to tokens and from tokens back",
      "offset": 735.6,
      "duration": 4.359
    },
    {
      "lang": "en",
      "text": "to text and what this actually looks",
      "offset": 738.199,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "like so one website I like to use to",
      "offset": 739.959,
      "duration": 4.721
    },
    {
      "lang": "en",
      "text": "explore these token representations is",
      "offset": 741.88,
      "duration": 5.24
    },
    {
      "lang": "en",
      "text": "called tick tokenizer and so come here",
      "offset": 744.68,
      "duration": 4.719
    },
    {
      "lang": "en",
      "text": "to the drop down and select CL 100 a",
      "offset": 747.12,
      "duration": 5.24
    },
    {
      "lang": "en",
      "text": "base which is the gp4 base model",
      "offset": 749.399,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "tokenizer and here on the left you can",
      "offset": 752.36,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "put in text and it shows you the",
      "offset": 754.279,
      "duration": 6.281
    },
    {
      "lang": "en",
      "text": "tokenization of that text so for example",
      "offset": 756.12,
      "duration": 7.519
    },
    {
      "lang": "en",
      "text": "heo space",
      "offset": 760.56,
      "duration": 5.56
    },
    {
      "lang": "en",
      "text": "world so hello world turns out to be",
      "offset": 763.639,
      "duration": 5.56
    },
    {
      "lang": "en",
      "text": "exactly two Tokens The Token hello which",
      "offset": 766.12,
      "duration": 5.519
    },
    {
      "lang": "en",
      "text": "is the token with ID",
      "offset": 769.199,
      "duration": 5.481
    },
    {
      "lang": "en",
      "text": "15339 and the token space",
      "offset": 771.639,
      "duration": 6.121
    },
    {
      "lang": "en",
      "text": "world that is the token 1",
      "offset": 774.68,
      "duration": 7.68
    },
    {
      "lang": "en",
      "text": "1917 so um hello space world now if I",
      "offset": 777.76,
      "duration": 7.079
    },
    {
      "lang": "en",
      "text": "was to join these two for example I'm",
      "offset": 782.36,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "going to get again two tokens but it's",
      "offset": 784.839,
      "duration": 4.881
    },
    {
      "lang": "en",
      "text": "the token H followed by the token L",
      "offset": 786.44,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "world without the",
      "offset": 789.72,
      "duration": 5.64
    },
    {
      "lang": "en",
      "text": "H um if I put in two Spa two spaces here",
      "offset": 791.72,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "between hello and world it's again a",
      "offset": 795.36,
      "duration": 3.88
    },
    {
      "lang": "en",
      "text": "different uh tokenization there's a new",
      "offset": 796.76,
      "duration": 5.319
    },
    {
      "lang": "en",
      "text": "token 220",
      "offset": 799.24,
      "duration": 4.959
    },
    {
      "lang": "en",
      "text": "here okay so you can play with this and",
      "offset": 802.079,
      "duration": 4.601
    },
    {
      "lang": "en",
      "text": "see what happens here also keep in mind",
      "offset": 804.199,
      "duration": 4.521
    },
    {
      "lang": "en",
      "text": "this is not uh this is case sensitive so",
      "offset": 806.68,
      "duration": 4.2
    },
    {
      "lang": "en",
      "text": "if this is a capital H it is something",
      "offset": 808.72,
      "duration": 6.44
    },
    {
      "lang": "en",
      "text": "else or if it's uh hello world then",
      "offset": 810.88,
      "duration": 5.72
    },
    {
      "lang": "en",
      "text": "actually this ends up being three tokens",
      "offset": 815.16,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "instead of just two",
      "offset": 816.6,
      "duration": 2.72
    },
    {
      "lang": "en",
      "text": "tokens yeah so you can play with this",
      "offset": 821.24,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "and get an sort of like an intuitive",
      "offset": 823.24,
      "duration": 3.959
    },
    {
      "lang": "en",
      "text": "sense of uh what these tokens work like",
      "offset": 824.68,
      "duration": 3.719
    },
    {
      "lang": "en",
      "text": "we're actually going to loop around to",
      "offset": 827.199,
      "duration": 2.88
    },
    {
      "lang": "en",
      "text": "tokenization a bit later in the video",
      "offset": 828.399,
      "duration": 2.841
    },
    {
      "lang": "en",
      "text": "for now I just wanted to show you the",
      "offset": 830.079,
      "duration": 3.721
    },
    {
      "lang": "en",
      "text": "website and I wanted to uh show you that",
      "offset": 831.24,
      "duration": 4.76
    },
    {
      "lang": "en",
      "text": "this text basically at the end of the",
      "offset": 833.8,
      "duration": 3.959
    },
    {
      "lang": "en",
      "text": "day so for example if I take one line",
      "offset": 836,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "here this is what GT4 will see it as so",
      "offset": 837.759,
      "duration": 6.601
    },
    {
      "lang": "en",
      "text": "this text will be a sequence of length",
      "offset": 841.12,
      "duration": 7.079
    },
    {
      "lang": "en",
      "text": "62 this is the sequence here and this is",
      "offset": 844.36,
      "duration": 7.159
    },
    {
      "lang": "en",
      "text": "how the chunks of text correspond to",
      "offset": 848.199,
      "duration": 8.401
    },
    {
      "lang": "en",
      "text": "these symbols and again there's 100,",
      "offset": 851.519,
      "duration": 7.88
    },
    {
      "lang": "en",
      "text": "27777 possible symbols and we now have",
      "offset": 856.6,
      "duration": 5.08
    },
    {
      "lang": "en",
      "text": "one-dimensional sequences of those",
      "offset": 859.399,
      "duration": 4.961
    },
    {
      "lang": "en",
      "text": "symbols so um yeah we're going to come",
      "offset": 861.68,
      "duration": 4.719
    },
    {
      "lang": "en",
      "text": "back to tokenization but that's uh for",
      "offset": 864.36,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "now where we are okay so what I've done",
      "offset": 866.399,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "now is I've taken this uh sequence of",
      "offset": 868.36,
      "duration": 3.96
    },
    {
      "lang": "en",
      "text": "text that we have here in the data set",
      "offset": 870.399,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "and I have re-represented it using our",
      "offset": 872.32,
      "duration": 5.16
    },
    {
      "lang": "en",
      "text": "tokenizer into a sequence of tokens and",
      "offset": 874.079,
      "duration": 6.12
    },
    {
      "lang": "en",
      "text": "this is what that looks like now so for",
      "offset": 877.48,
      "duration": 4.2
    },
    {
      "lang": "en",
      "text": "example when we go back to the Fine web",
      "offset": 880.199,
      "duration": 3.521
    },
    {
      "lang": "en",
      "text": "data set they mentioned that not only is",
      "offset": 881.68,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "this 44 terab of dis space but this is",
      "offset": 883.72,
      "duration": 6.84
    },
    {
      "lang": "en",
      "text": "about a 15 trillion token sequence of um",
      "offset": 885.759,
      "duration": 7.961
    },
    {
      "lang": "en",
      "text": "in this data set and so here these are",
      "offset": 890.56,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "just some of the first uh one or two or",
      "offset": 893.72,
      "duration": 4.84
    },
    {
      "lang": "en",
      "text": "three or a few thousand here I think uh",
      "offset": 896.32,
      "duration": 4.959
    },
    {
      "lang": "en",
      "text": "tokens of this data set but there's 15",
      "offset": 898.56,
      "duration": 5.32
    },
    {
      "lang": "en",
      "text": "trillion here uh to keep in mind and",
      "offset": 901.279,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "again keep in mind one more time that",
      "offset": 903.88,
      "duration": 3.319
    },
    {
      "lang": "en",
      "text": "all of these represent little text",
      "offset": 905.759,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "chunks they're all just like atoms of",
      "offset": 907.199,
      "duration": 4.521
    },
    {
      "lang": "en",
      "text": "these sequences and the numbers here",
      "offset": 909.839,
      "duration": 3.401
    },
    {
      "lang": "en",
      "text": "don't make any sense they're just uh",
      "offset": 911.72,
      "duration": 5.72
    },
    {
      "lang": "en",
      "text": "they're just unique IDs okay so now we",
      "offset": 913.24,
      "duration": 6.399
    },
    {
      "lang": "en",
      "text": "get to the fun part which is the uh",
      "offset": 917.44,
      "duration": 4.04
    },
    {
      "lang": "en",
      "text": "neural network training and this is",
      "offset": 919.639,
      "duration": 3.361
    },
    {
      "lang": "en",
      "text": "where a lot of the heavy lifting happens",
      "offset": 921.48,
      "duration": 3.08
    },
    {
      "lang": "en",
      "text": "computationally when you're training",
      "offset": 923,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "these neural networks so what we do here",
      "offset": 924.56,
      "duration": 6.199
    },
    {
      "lang": "en",
      "text": "in this this step is we want to model",
      "offset": 928.44,
      "duration": 3.759
    },
    {
      "lang": "en",
      "text": "the statistical relationships of how",
      "offset": 930.759,
      "duration": 3.041
    },
    {
      "lang": "en",
      "text": "these tokens follow each other in the",
      "offset": 932.199,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "sequence so what we do is we come into",
      "offset": 933.8,
      "duration": 6.24
    },
    {
      "lang": "en",
      "text": "the data and we take Windows of tokens",
      "offset": 936.12,
      "duration": 7.279
    },
    {
      "lang": "en",
      "text": "so we take a window of tokens uh from",
      "offset": 940.04,
      "duration": 4.719
    },
    {
      "lang": "en",
      "text": "this data fairly",
      "offset": 943.399,
      "duration": 5.601
    },
    {
      "lang": "en",
      "text": "randomly and um the windows length can",
      "offset": 944.759,
      "duration": 6.841
    },
    {
      "lang": "en",
      "text": "range anywhere anywhere between uh zero",
      "offset": 949,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "tokens actually all the way up to some",
      "offset": 951.6,
      "duration": 5.479
    },
    {
      "lang": "en",
      "text": "maximum size that we decide on uh so for",
      "offset": 954.04,
      "duration": 4.479
    },
    {
      "lang": "en",
      "text": "example in practice you could see a",
      "offset": 957.079,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "token with Windows of say 8,000 tokens",
      "offset": 958.519,
      "duration": 5
    },
    {
      "lang": "en",
      "text": "now in principle we can use arbitrary",
      "offset": 961.48,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "window lengths of tokens uh but uh",
      "offset": 963.519,
      "duration": 7.44
    },
    {
      "lang": "en",
      "text": "processing very long uh basically U",
      "offset": 967.48,
      "duration": 5.279
    },
    {
      "lang": "en",
      "text": "window sequences would just be very",
      "offset": 970.959,
      "duration": 4.041
    },
    {
      "lang": "en",
      "text": "computationally expensive so we just",
      "offset": 972.759,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "kind of decide that say 8,000 is a good",
      "offset": 975,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "number or 4,000 or 16,000 and we crop it",
      "offset": 976.68,
      "duration": 5.719
    },
    {
      "lang": "en",
      "text": "there now in this example I'm going to",
      "offset": 979.88,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "be uh taking the first four tokens just",
      "offset": 982.399,
      "duration": 5.721
    },
    {
      "lang": "en",
      "text": "so everything fits nicely so these",
      "offset": 985.48,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "tokens",
      "offset": 988.12,
      "duration": 4.199
    },
    {
      "lang": "en",
      "text": "we're going to take a window of four",
      "offset": 990.04,
      "duration": 7.44
    },
    {
      "lang": "en",
      "text": "tokens this bar view in and space single",
      "offset": 992.319,
      "duration": 6.76
    },
    {
      "lang": "en",
      "text": "which are these token",
      "offset": 997.48,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "IDs and now what we're trying to do here",
      "offset": 999.079,
      "duration": 3.56
    },
    {
      "lang": "en",
      "text": "is we're trying to basically predict the",
      "offset": 1001.24,
      "duration": 4.44
    },
    {
      "lang": "en",
      "text": "token that comes next in the sequence so",
      "offset": 1002.639,
      "duration": 6.64
    },
    {
      "lang": "en",
      "text": "3962 comes next right so what we do now",
      "offset": 1005.68,
      "duration": 6.279
    },
    {
      "lang": "en",
      "text": "here is that we call this the context",
      "offset": 1009.279,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "these four tokens are context and they",
      "offset": 1011.959,
      "duration": 4.12
    },
    {
      "lang": "en",
      "text": "feed into a neural",
      "offset": 1014.399,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "network and this is the input to the",
      "offset": 1016.079,
      "duration": 3.801
    },
    {
      "lang": "en",
      "text": "neural network",
      "offset": 1018,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "now I'm going to go into the detail of",
      "offset": 1019.88,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "what's inside this neural network in a",
      "offset": 1021.839,
      "duration": 3
    },
    {
      "lang": "en",
      "text": "little bit for now it's important to",
      "offset": 1023.24,
      "duration": 2.959
    },
    {
      "lang": "en",
      "text": "understand is the input and the output",
      "offset": 1024.839,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "of the neural net so the input are",
      "offset": 1026.199,
      "duration": 5.921
    },
    {
      "lang": "en",
      "text": "sequences of tokens of variable length",
      "offset": 1028.919,
      "duration": 5.16
    },
    {
      "lang": "en",
      "text": "anywhere between zero and some maximum",
      "offset": 1032.12,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "size like 8,000 the output now is a",
      "offset": 1034.079,
      "duration": 7.12
    },
    {
      "lang": "en",
      "text": "prediction for what comes next so",
      "offset": 1037.64,
      "duration": 6.159
    },
    {
      "lang": "en",
      "text": "because our vocabulary has",
      "offset": 1041.199,
      "duration": 5.48
    },
    {
      "lang": "en",
      "text": "100277 possible tokens the neural",
      "offset": 1043.799,
      "duration": 4.52
    },
    {
      "lang": "en",
      "text": "network is going to Output exactly that",
      "offset": 1046.679,
      "duration": 2.681
    },
    {
      "lang": "en",
      "text": "many numbers",
      "offset": 1048.319,
      "duration": 2.6
    },
    {
      "lang": "en",
      "text": "and all of those numbers correspond to",
      "offset": 1049.36,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "the probability of that token as coming",
      "offset": 1050.919,
      "duration": 4.841
    },
    {
      "lang": "en",
      "text": "next in the sequence so it's making",
      "offset": 1053.84,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "guesses about what comes",
      "offset": 1055.76,
      "duration": 3.88
    },
    {
      "lang": "en",
      "text": "next um in the beginning this neural",
      "offset": 1057.28,
      "duration": 5.399
    },
    {
      "lang": "en",
      "text": "network is randomly initialized so um",
      "offset": 1059.64,
      "duration": 4.6
    },
    {
      "lang": "en",
      "text": "and we're going to see in a little bit",
      "offset": 1062.679,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "what that means but it's a it's a it's a",
      "offset": 1064.24,
      "duration": 4.04
    },
    {
      "lang": "en",
      "text": "random transformation so these",
      "offset": 1066.52,
      "duration": 3.24
    },
    {
      "lang": "en",
      "text": "probabilities in the very beginning of",
      "offset": 1068.28,
      "duration": 3
    },
    {
      "lang": "en",
      "text": "the training are also going to be kind",
      "offset": 1069.76,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "of random uh so here I have three",
      "offset": 1071.28,
      "duration": 4.2
    },
    {
      "lang": "en",
      "text": "examples but keep in mind that there's",
      "offset": 1073.6,
      "duration": 4.52
    },
    {
      "lang": "en",
      "text": "100,000 numbers here um so the",
      "offset": 1075.48,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "probability of this token space",
      "offset": 1078.12,
      "duration": 3.559
    },
    {
      "lang": "en",
      "text": "Direction neural network is saying that",
      "offset": 1079.72,
      "duration": 6.079
    },
    {
      "lang": "en",
      "text": "this is 4% likely right now 11799 is 2%",
      "offset": 1081.679,
      "duration": 6.36
    },
    {
      "lang": "en",
      "text": "and then here the probility of 3962",
      "offset": 1085.799,
      "duration": 5.601
    },
    {
      "lang": "en",
      "text": "which is post is 3% now of course we've",
      "offset": 1088.039,
      "duration": 5.88
    },
    {
      "lang": "en",
      "text": "sampled this window from our data set so",
      "offset": 1091.4,
      "duration": 4.639
    },
    {
      "lang": "en",
      "text": "we know what comes next we know and",
      "offset": 1093.919,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "that's the label we know that the",
      "offset": 1096.039,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "correct answer is that 3962 actually",
      "offset": 1098.08,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "comes next in the sequence so now what",
      "offset": 1099.96,
      "duration": 5.959
    },
    {
      "lang": "en",
      "text": "we have is this mathematical process for",
      "offset": 1102.96,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "doing an update to the neural network we",
      "offset": 1105.919,
      "duration": 4.76
    },
    {
      "lang": "en",
      "text": "have the way of tuning it and uh we're",
      "offset": 1108.08,
      "duration": 3.959
    },
    {
      "lang": "en",
      "text": "going to go into a little bit of of",
      "offset": 1110.679,
      "duration": 4.041
    },
    {
      "lang": "en",
      "text": "detail in a bit but basically we know",
      "offset": 1112.039,
      "duration": 6.12
    },
    {
      "lang": "en",
      "text": "that this probability here of 3% we want",
      "offset": 1114.72,
      "duration": 5.88
    },
    {
      "lang": "en",
      "text": "this probability to be higher and we",
      "offset": 1118.159,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "want the probabilities of all the other",
      "offset": 1120.6,
      "duration": 3.4
    },
    {
      "lang": "en",
      "text": "tokens to be",
      "offset": 1122.08,
      "duration": 3.959
    },
    {
      "lang": "en",
      "text": "lower and so we have a way of",
      "offset": 1124,
      "duration": 4.919
    },
    {
      "lang": "en",
      "text": "mathematically calculating how to adjust",
      "offset": 1126.039,
      "duration": 5.721
    },
    {
      "lang": "en",
      "text": "and update the neural network so that",
      "offset": 1128.919,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "the correct answer has a slightly higher",
      "offset": 1131.76,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "probability so if I do an update to the",
      "offset": 1133.559,
      "duration": 5.681
    },
    {
      "lang": "en",
      "text": "neural network now the next time I Fe",
      "offset": 1135.679,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "this particular sequence of four tokens",
      "offset": 1139.24,
      "duration": 3.48
    },
    {
      "lang": "en",
      "text": "into neural network the neural network",
      "offset": 1140.799,
      "duration": 3.201
    },
    {
      "lang": "en",
      "text": "will be slightly adjusted now and it",
      "offset": 1142.72,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "will say Okay post is maybe 4% and case",
      "offset": 1144,
      "duration": 4.6
    },
    {
      "lang": "en",
      "text": "now maybe is",
      "offset": 1147.12,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "1% and uh Direction could become 2% or",
      "offset": 1148.6,
      "duration": 5.48
    },
    {
      "lang": "en",
      "text": "something like that and so we have a way",
      "offset": 1152.08,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "of nudging of slightly updating the",
      "offset": 1154.08,
      "duration": 5.599
    },
    {
      "lang": "en",
      "text": "neuronet to um basically give a higher",
      "offset": 1156.159,
      "duration": 4.841
    },
    {
      "lang": "en",
      "text": "probability to the correct token that",
      "offset": 1159.679,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "comes next in the sequence and now you",
      "offset": 1161,
      "duration": 4.6
    },
    {
      "lang": "en",
      "text": "just have to remember that this process",
      "offset": 1163.039,
      "duration": 6.441
    },
    {
      "lang": "en",
      "text": "happens not just for uh this um token",
      "offset": 1165.6,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "here where these four fed in and",
      "offset": 1169.48,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "predicted this one this process happens",
      "offset": 1171.28,
      "duration": 5
    },
    {
      "lang": "en",
      "text": "at the same time for all of these tokens",
      "offset": 1173.799,
      "duration": 4.481
    },
    {
      "lang": "en",
      "text": "in the entire data set and so in",
      "offset": 1176.28,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "practice we sample little windows little",
      "offset": 1178.28,
      "duration": 4.279
    },
    {
      "lang": "en",
      "text": "batches of Windows and then at every",
      "offset": 1180.28,
      "duration": 4.519
    },
    {
      "lang": "en",
      "text": "single one of these tokens we want to",
      "offset": 1182.559,
      "duration": 4.041
    },
    {
      "lang": "en",
      "text": "adjust our neural network so that the",
      "offset": 1184.799,
      "duration": 3.24
    },
    {
      "lang": "en",
      "text": "probability of that token becomes",
      "offset": 1186.6,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "slightly higher and this all happens in",
      "offset": 1188.039,
      "duration": 4.201
    },
    {
      "lang": "en",
      "text": "parallel in large batches of these",
      "offset": 1190.2,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "tokens and this is the process of",
      "offset": 1192.24,
      "duration": 3.559
    },
    {
      "lang": "en",
      "text": "training the neural network it's a",
      "offset": 1194.28,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "sequence of updating it so that it's",
      "offset": 1195.799,
      "duration": 5.681
    },
    {
      "lang": "en",
      "text": "predictions match up the statistics of",
      "offset": 1198.76,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "what actually happens in your training",
      "offset": 1201.48,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "set and its probabilities become",
      "offset": 1202.679,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "consistent with the uh statistical",
      "offset": 1205.32,
      "duration": 4.44
    },
    {
      "lang": "en",
      "text": "patterns of how these tokens follow each",
      "offset": 1208.039,
      "duration": 3.961
    },
    {
      "lang": "en",
      "text": "other in the data so let's now briefly",
      "offset": 1209.76,
      "duration": 3.64
    },
    {
      "lang": "en",
      "text": "get into the internals of these neural",
      "offset": 1212,
      "duration": 2.919
    },
    {
      "lang": "en",
      "text": "networks just to give you a sense of",
      "offset": 1213.4,
      "duration": 4.04
    },
    {
      "lang": "en",
      "text": "what's inside so neural network",
      "offset": 1214.919,
      "duration": 4.601
    },
    {
      "lang": "en",
      "text": "internals so as I mentioned we have",
      "offset": 1217.44,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "these inputs uh that are sequences of",
      "offset": 1219.52,
      "duration": 5.24
    },
    {
      "lang": "en",
      "text": "tokens in this case this is four input",
      "offset": 1222.24,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "tokens but this can be anywhere between",
      "offset": 1224.76,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "zero up to let's say 8,000 tokens in",
      "offset": 1226.72,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "principle this can be an infinite number",
      "offset": 1230.28,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "of tokens we just uh it would just be",
      "offset": 1231.76,
      "duration": 4.12
    },
    {
      "lang": "en",
      "text": "too computationally expensive to process",
      "offset": 1233.96,
      "duration": 3.719
    },
    {
      "lang": "en",
      "text": "an infinite number of tokens so we just",
      "offset": 1235.88,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "crop it at a certain length and that",
      "offset": 1237.679,
      "duration": 3.561
    },
    {
      "lang": "en",
      "text": "becomes the maximum context length of",
      "offset": 1239.32,
      "duration": 3.239
    },
    {
      "lang": "en",
      "text": "that uh",
      "offset": 1241.24,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "model now these inputs X are mixed up in",
      "offset": 1242.559,
      "duration": 6.36
    },
    {
      "lang": "en",
      "text": "a giant mathematical expression together",
      "offset": 1246.2,
      "duration": 5.56
    },
    {
      "lang": "en",
      "text": "with the parameters or the weights of",
      "offset": 1248.919,
      "duration": 4.76
    },
    {
      "lang": "en",
      "text": "these neural networks so here I'm",
      "offset": 1251.76,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "showing six example parameters and their",
      "offset": 1253.679,
      "duration": 6.761
    },
    {
      "lang": "en",
      "text": "setting but in practice these uh um",
      "offset": 1256.64,
      "duration": 5.159
    },
    {
      "lang": "en",
      "text": "modern neural networks will have",
      "offset": 1260.44,
      "duration": 4.359
    },
    {
      "lang": "en",
      "text": "billions of these uh parameters and in",
      "offset": 1261.799,
      "duration": 4.481
    },
    {
      "lang": "en",
      "text": "the beginning these parameters are",
      "offset": 1264.799,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "completely randomly set now with a",
      "offset": 1266.28,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "random setting of parameters you might",
      "offset": 1269.039,
      "duration": 4.601
    },
    {
      "lang": "en",
      "text": "expect that this uh this neural network",
      "offset": 1271.08,
      "duration": 4.28
    },
    {
      "lang": "en",
      "text": "would make random predictions and it",
      "offset": 1273.64,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "does in the beginning it's totally",
      "offset": 1275.36,
      "duration": 4.199
    },
    {
      "lang": "en",
      "text": "random predictions but it's through this",
      "offset": 1276.84,
      "duration": 5.719
    },
    {
      "lang": "en",
      "text": "process of iteratively updating the",
      "offset": 1279.559,
      "duration": 5.321
    },
    {
      "lang": "en",
      "text": "network uh as and we call that process",
      "offset": 1282.559,
      "duration": 5.561
    },
    {
      "lang": "en",
      "text": "training a neural network so uh that the",
      "offset": 1284.88,
      "duration": 4.52
    },
    {
      "lang": "en",
      "text": "setting of these parameters gets",
      "offset": 1288.12,
      "duration": 3.559
    },
    {
      "lang": "en",
      "text": "adjusted such that the outputs of our",
      "offset": 1289.4,
      "duration": 4.639
    },
    {
      "lang": "en",
      "text": "neural network becomes consistent with",
      "offset": 1291.679,
      "duration": 4.6
    },
    {
      "lang": "en",
      "text": "the patterns seen in our training",
      "offset": 1294.039,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "set so think of these parameters as kind",
      "offset": 1296.279,
      "duration": 5
    },
    {
      "lang": "en",
      "text": "of like knobs on a DJ set and as you're",
      "offset": 1299.159,
      "duration": 3.801
    },
    {
      "lang": "en",
      "text": "twiddling these knobs you're getting",
      "offset": 1301.279,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "different uh predictions for every",
      "offset": 1302.96,
      "duration": 6.199
    },
    {
      "lang": "en",
      "text": "possible uh token sequence input and",
      "offset": 1305.36,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "training in neural network just means",
      "offset": 1309.159,
      "duration": 3.64
    },
    {
      "lang": "en",
      "text": "discovering a setting of parameters that",
      "offset": 1310.64,
      "duration": 4.039
    },
    {
      "lang": "en",
      "text": "seems to be consistent with the",
      "offset": 1312.799,
      "duration": 3.561
    },
    {
      "lang": "en",
      "text": "statistics of the training",
      "offset": 1314.679,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "set now let me just give you an example",
      "offset": 1316.36,
      "duration": 3.559
    },
    {
      "lang": "en",
      "text": "what this giant mathematical expression",
      "offset": 1318.679,
      "duration": 3
    },
    {
      "lang": "en",
      "text": "looks like just to give you a sense and",
      "offset": 1319.919,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "modern networks are massive expressions",
      "offset": 1321.679,
      "duration": 4.36
    },
    {
      "lang": "en",
      "text": "with trillions of terms probably but let",
      "offset": 1323.84,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "me just show you a simple example here",
      "offset": 1326.039,
      "duration": 4.041
    },
    {
      "lang": "en",
      "text": "it would look something like this I mean",
      "offset": 1328.64,
      "duration": 2.76
    },
    {
      "lang": "en",
      "text": "these are the kinds of Expressions just",
      "offset": 1330.08,
      "duration": 3.64
    },
    {
      "lang": "en",
      "text": "to show you that it's not very scary we",
      "offset": 1331.4,
      "duration": 5.8
    },
    {
      "lang": "en",
      "text": "have inputs x uh like X1 x2 in this case",
      "offset": 1333.72,
      "duration": 6.24
    },
    {
      "lang": "en",
      "text": "two example inputs and they get mixed up",
      "offset": 1337.2,
      "duration": 5.719
    },
    {
      "lang": "en",
      "text": "with the weights of the network w0 W1 2",
      "offset": 1339.96,
      "duration": 7.04
    },
    {
      "lang": "en",
      "text": "3 Etc and this mixing is simple things",
      "offset": 1342.919,
      "duration": 6.601
    },
    {
      "lang": "en",
      "text": "like multiplication addition addition",
      "offset": 1347,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "exponentiation division Etc and it is",
      "offset": 1349.52,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "the subject of neural network",
      "offset": 1352.76,
      "duration": 3.799
    },
    {
      "lang": "en",
      "text": "architecture research to design",
      "offset": 1354,
      "duration": 5.32
    },
    {
      "lang": "en",
      "text": "effective mathematical Expressions uh",
      "offset": 1356.559,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "that have a lot of uh kind of convenient",
      "offset": 1359.32,
      "duration": 3.64
    },
    {
      "lang": "en",
      "text": "characteristics they are expressive",
      "offset": 1361.279,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "they're optimizable they're paralyzable",
      "offset": 1362.96,
      "duration": 5.24
    },
    {
      "lang": "en",
      "text": "Etc and so but uh at the end of the day",
      "offset": 1365.279,
      "duration": 4.361
    },
    {
      "lang": "en",
      "text": "these are these are not complex",
      "offset": 1368.2,
      "duration": 3.88
    },
    {
      "lang": "en",
      "text": "expressions and basically they mix up",
      "offset": 1369.64,
      "duration": 4.68
    },
    {
      "lang": "en",
      "text": "the inputs with the parameters to make",
      "offset": 1372.08,
      "duration": 5.56
    },
    {
      "lang": "en",
      "text": "predictions and we're optimizing uh the",
      "offset": 1374.32,
      "duration": 5.32
    },
    {
      "lang": "en",
      "text": "parameters of this neural network so",
      "offset": 1377.64,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "that the predictions come out consistent",
      "offset": 1379.64,
      "duration": 4.6
    },
    {
      "lang": "en",
      "text": "with the training set now I would like",
      "offset": 1381.72,
      "duration": 4.52
    },
    {
      "lang": "en",
      "text": "to show you an actual production grade",
      "offset": 1384.24,
      "duration": 3.64
    },
    {
      "lang": "en",
      "text": "example of what these neural networks",
      "offset": 1386.24,
      "duration": 3.559
    },
    {
      "lang": "en",
      "text": "look like so for that I encourage you to",
      "offset": 1387.88,
      "duration": 3.96
    },
    {
      "lang": "en",
      "text": "go to this website that has a very nice",
      "offset": 1389.799,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "visualization of one of these",
      "offset": 1391.84,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "networks so this is what you will find",
      "offset": 1393.96,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "on this website and this neural network",
      "offset": 1396.4,
      "duration": 5.32
    },
    {
      "lang": "en",
      "text": "here that is used in production settings",
      "offset": 1399.48,
      "duration": 4.6
    },
    {
      "lang": "en",
      "text": "has this special kind of structure this",
      "offset": 1401.72,
      "duration": 5
    },
    {
      "lang": "en",
      "text": "network is called the Transformer and",
      "offset": 1404.08,
      "duration": 4.52
    },
    {
      "lang": "en",
      "text": "this particular one as an example has 8",
      "offset": 1406.72,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "5,000 roughly",
      "offset": 1408.6,
      "duration": 4.6
    },
    {
      "lang": "en",
      "text": "parameters now here on the top we take",
      "offset": 1410.88,
      "duration": 5.32
    },
    {
      "lang": "en",
      "text": "the inputs which are the token",
      "offset": 1413.2,
      "duration": 6.56
    },
    {
      "lang": "en",
      "text": "sequences and then information flows",
      "offset": 1416.2,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "through the neural network until the",
      "offset": 1419.76,
      "duration": 5.399
    },
    {
      "lang": "en",
      "text": "output which here are the logit softmax",
      "offset": 1421.88,
      "duration": 4.6
    },
    {
      "lang": "en",
      "text": "but these are the predictions for what",
      "offset": 1425.159,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "comes next what token comes",
      "offset": 1426.48,
      "duration": 5.88
    },
    {
      "lang": "en",
      "text": "next and then here there's a sequence of",
      "offset": 1428.679,
      "duration": 5.561
    },
    {
      "lang": "en",
      "text": "Transformations and all these",
      "offset": 1432.36,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "intermediate values that get produced",
      "offset": 1434.24,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "inside this mathematical expression s it",
      "offset": 1436.44,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "is sort of predicting what comes next so",
      "offset": 1438.559,
      "duration": 6.081
    },
    {
      "lang": "en",
      "text": "as an example these tokens are embedded",
      "offset": 1441.24,
      "duration": 4.799
    },
    {
      "lang": "en",
      "text": "into kind of like this distributed",
      "offset": 1444.64,
      "duration": 3.399
    },
    {
      "lang": "en",
      "text": "representation as it's called so every",
      "offset": 1446.039,
      "duration": 4.201
    },
    {
      "lang": "en",
      "text": "possible token has kind of like a vector",
      "offset": 1448.039,
      "duration": 3.88
    },
    {
      "lang": "en",
      "text": "that represents it inside the neural",
      "offset": 1450.24,
      "duration": 5.039
    },
    {
      "lang": "en",
      "text": "network so first we embed the tokens and",
      "offset": 1451.919,
      "duration": 6.321
    },
    {
      "lang": "en",
      "text": "then those values uh kind of like flow",
      "offset": 1455.279,
      "duration": 5.441
    },
    {
      "lang": "en",
      "text": "through this diagram and these are all",
      "offset": 1458.24,
      "duration": 3.88
    },
    {
      "lang": "en",
      "text": "very simple mathematical Expressions",
      "offset": 1460.72,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "individually so we have layer norms and",
      "offset": 1462.12,
      "duration": 5
    },
    {
      "lang": "en",
      "text": "Matrix multiplications and uh soft Maxes",
      "offset": 1464.24,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "and so on so here kind of like the",
      "offset": 1467.12,
      "duration": 4.559
    },
    {
      "lang": "en",
      "text": "attention block of this Transformer and",
      "offset": 1468.88,
      "duration": 4.679
    },
    {
      "lang": "en",
      "text": "then information kind of flows through",
      "offset": 1471.679,
      "duration": 3.801
    },
    {
      "lang": "en",
      "text": "into the multi-layer perceptron block",
      "offset": 1473.559,
      "duration": 5
    },
    {
      "lang": "en",
      "text": "and so on and all these numbers here",
      "offset": 1475.48,
      "duration": 4.679
    },
    {
      "lang": "en",
      "text": "these are the intermediate values of the",
      "offset": 1478.559,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "expression and uh you can almost think",
      "offset": 1480.159,
      "duration": 4.601
    },
    {
      "lang": "en",
      "text": "of these as kind of like the firing",
      "offset": 1482.24,
      "duration": 5.64
    },
    {
      "lang": "en",
      "text": "rates of these synthetic neurons but I",
      "offset": 1484.76,
      "duration": 5.639
    },
    {
      "lang": "en",
      "text": "would caution you to uh not um kind of",
      "offset": 1487.88,
      "duration": 4.679
    },
    {
      "lang": "en",
      "text": "think of it too much like neurons",
      "offset": 1490.399,
      "duration": 3.361
    },
    {
      "lang": "en",
      "text": "because these are extremely simple",
      "offset": 1492.559,
      "duration": 2.761
    },
    {
      "lang": "en",
      "text": "neurons compared to the neurons you",
      "offset": 1493.76,
      "duration": 3.399
    },
    {
      "lang": "en",
      "text": "would find in your brain your biological",
      "offset": 1495.32,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "neurons are very complex dynamical",
      "offset": 1497.159,
      "duration": 3.88
    },
    {
      "lang": "en",
      "text": "processes that have memory and so on",
      "offset": 1499,
      "duration": 3.88
    },
    {
      "lang": "en",
      "text": "there's no memory in this expression",
      "offset": 1501.039,
      "duration": 3.321
    },
    {
      "lang": "en",
      "text": "it's a fixed mathematical expression",
      "offset": 1502.88,
      "duration": 3.64
    },
    {
      "lang": "en",
      "text": "from input to Output with no memory it's",
      "offset": 1504.36,
      "duration": 3.08
    },
    {
      "lang": "en",
      "text": "just a",
      "offset": 1506.52,
      "duration": 2.759
    },
    {
      "lang": "en",
      "text": "stateless so these are very simple",
      "offset": 1507.44,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "neurons in comparison to biological",
      "offset": 1509.279,
      "duration": 2.921
    },
    {
      "lang": "en",
      "text": "neurons but you can still kind of",
      "offset": 1510.72,
      "duration": 2.839
    },
    {
      "lang": "en",
      "text": "loosely think of this as like a",
      "offset": 1512.2,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "synthetic piece of uh brain tissue if",
      "offset": 1513.559,
      "duration": 4.12
    },
    {
      "lang": "en",
      "text": "you if you like uh to think about it",
      "offset": 1515.96,
      "duration": 5.16
    },
    {
      "lang": "en",
      "text": "that way so information flows through",
      "offset": 1517.679,
      "duration": 6.641
    },
    {
      "lang": "en",
      "text": "all these neurons fire until we get to",
      "offset": 1521.12,
      "duration": 5.559
    },
    {
      "lang": "en",
      "text": "the predictions now I'm not actually",
      "offset": 1524.32,
      "duration": 4.479
    },
    {
      "lang": "en",
      "text": "going to dwell too much on the precise",
      "offset": 1526.679,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "kind of like mathematical details of all",
      "offset": 1528.799,
      "duration": 3.161
    },
    {
      "lang": "en",
      "text": "these Transformations honestly I don't",
      "offset": 1530.279,
      "duration": 3.64
    },
    {
      "lang": "en",
      "text": "think it's that important to get into",
      "offset": 1531.96,
      "duration": 3.319
    },
    {
      "lang": "en",
      "text": "what's really important to understand is",
      "offset": 1533.919,
      "duration": 4.521
    },
    {
      "lang": "en",
      "text": "that this is a mathematical function it",
      "offset": 1535.279,
      "duration": 6.241
    },
    {
      "lang": "en",
      "text": "is uh parameterized by some fixed set of",
      "offset": 1538.44,
      "duration": 5.599
    },
    {
      "lang": "en",
      "text": "parameters like say 85,000 of them and",
      "offset": 1541.52,
      "duration": 4.519
    },
    {
      "lang": "en",
      "text": "it is a way of transforming inputs into",
      "offset": 1544.039,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "outputs and as we twiddle the parameters",
      "offset": 1546.039,
      "duration": 4.52
    },
    {
      "lang": "en",
      "text": "we are getting uh different kinds of",
      "offset": 1548.679,
      "duration": 3.961
    },
    {
      "lang": "en",
      "text": "predictions and then we need to find a",
      "offset": 1550.559,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "good setting of these parameters so that",
      "offset": 1552.64,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "the predictions uh sort of match up with",
      "offset": 1554.399,
      "duration": 4.801
    },
    {
      "lang": "en",
      "text": "the patterns seen in training set",
      "offset": 1556.559,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "so that's the Transformer okay so I've",
      "offset": 1559.2,
      "duration": 4.28
    },
    {
      "lang": "en",
      "text": "shown you the internals of the neural",
      "offset": 1562.159,
      "duration": 2.921
    },
    {
      "lang": "en",
      "text": "network and we talked a bit about the",
      "offset": 1563.48,
      "duration": 3.88
    },
    {
      "lang": "en",
      "text": "process of training it I want to cover",
      "offset": 1565.08,
      "duration": 4.92
    },
    {
      "lang": "en",
      "text": "one more major stage of working with",
      "offset": 1567.36,
      "duration": 4.52
    },
    {
      "lang": "en",
      "text": "these networks and that is the stage",
      "offset": 1570,
      "duration": 4.2
    },
    {
      "lang": "en",
      "text": "called inference so in inference what",
      "offset": 1571.88,
      "duration": 4.279
    },
    {
      "lang": "en",
      "text": "we're doing is we're generating new data",
      "offset": 1574.2,
      "duration": 4.76
    },
    {
      "lang": "en",
      "text": "from the model and so uh we want to",
      "offset": 1576.159,
      "duration": 4.841
    },
    {
      "lang": "en",
      "text": "basically see what kind of patterns it",
      "offset": 1578.96,
      "duration": 4.199
    },
    {
      "lang": "en",
      "text": "has internalized in the parameters of",
      "offset": 1581,
      "duration": 5.679
    },
    {
      "lang": "en",
      "text": "its Network so to generate from the",
      "offset": 1583.159,
      "duration": 5.721
    },
    {
      "lang": "en",
      "text": "model is relatively straightforward",
      "offset": 1586.679,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "we start with some tokens that are",
      "offset": 1588.88,
      "duration": 3.679
    },
    {
      "lang": "en",
      "text": "basically your prefix like what you want",
      "offset": 1590.84,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "to start with so say we want to start",
      "offset": 1592.559,
      "duration": 4.641
    },
    {
      "lang": "en",
      "text": "with the token 91 well we feed it into",
      "offset": 1594.44,
      "duration": 3.479
    },
    {
      "lang": "en",
      "text": "the",
      "offset": 1597.2,
      "duration": 2.719
    },
    {
      "lang": "en",
      "text": "network and remember that the network",
      "offset": 1597.919,
      "duration": 5.281
    },
    {
      "lang": "en",
      "text": "gives us probabilities right it gives us",
      "offset": 1599.919,
      "duration": 5.401
    },
    {
      "lang": "en",
      "text": "this probability Vector here so what we",
      "offset": 1603.2,
      "duration": 3.959
    },
    {
      "lang": "en",
      "text": "can do now is we can basically flip a",
      "offset": 1605.32,
      "duration": 6.76
    },
    {
      "lang": "en",
      "text": "biased coin so um we can sample uh",
      "offset": 1607.159,
      "duration": 7.76
    },
    {
      "lang": "en",
      "text": "basically a token based on this",
      "offset": 1612.08,
      "duration": 5.079
    },
    {
      "lang": "en",
      "text": "probability distribution so the tokens",
      "offset": 1614.919,
      "duration": 4.441
    },
    {
      "lang": "en",
      "text": "that are given High probability by the",
      "offset": 1617.159,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "model are more likely to be sampled when",
      "offset": 1619.36,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "you flip this biased coin you can think",
      "offset": 1621.559,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "of it that way so we sample from the",
      "offset": 1623.679,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "distribution to get a single unique",
      "offset": 1625.799,
      "duration": 5.641
    },
    {
      "lang": "en",
      "text": "token so for example token 860 comes",
      "offset": 1628,
      "duration": 6.08
    },
    {
      "lang": "en",
      "text": "next uh so 860 in this case when we're",
      "offset": 1631.44,
      "duration": 4.68
    },
    {
      "lang": "en",
      "text": "generating from model could come next",
      "offset": 1634.08,
      "duration": 4.599
    },
    {
      "lang": "en",
      "text": "now 860 is a relatively likely token it",
      "offset": 1636.12,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "might not be the only possible token in",
      "offset": 1638.679,
      "duration": 3.041
    },
    {
      "lang": "en",
      "text": "this case there could be many other",
      "offset": 1640.52,
      "duration": 3.08
    },
    {
      "lang": "en",
      "text": "tokens that could have been sampled but",
      "offset": 1641.72,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "we could see that 86c is a relatively",
      "offset": 1643.6,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "likely token as an example and indeed in",
      "offset": 1645.24,
      "duration": 4.559
    },
    {
      "lang": "en",
      "text": "our training examp example here 860 does",
      "offset": 1647.52,
      "duration": 6.72
    },
    {
      "lang": "en",
      "text": "follow 91 so let's now say that we um",
      "offset": 1649.799,
      "duration": 6.88
    },
    {
      "lang": "en",
      "text": "continue the process so after 91 there's",
      "offset": 1654.24,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "a60 we append it and we again ask what",
      "offset": 1656.679,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "is the third token let's sample and",
      "offset": 1659.36,
      "duration": 5.24
    },
    {
      "lang": "en",
      "text": "let's just say that it's 287 exactly as",
      "offset": 1662.039,
      "duration": 5.88
    },
    {
      "lang": "en",
      "text": "here let's do that again we come back in",
      "offset": 1664.6,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "now we have a sequence of three and we",
      "offset": 1667.919,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "ask what is the likely fourth token and",
      "offset": 1669.96,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "we sample from that and get this one and",
      "offset": 1672.559,
      "duration": 5.681
    },
    {
      "lang": "en",
      "text": "now let's say we do it one more time we",
      "offset": 1675.64,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "take those four we sample and we get",
      "offset": 1678.24,
      "duration": 4.679
    },
    {
      "lang": "en",
      "text": "this one and this",
      "offset": 1680.44,
      "duration": 6.44
    },
    {
      "lang": "en",
      "text": "13659 uh this is not actually uh 3962 as",
      "offset": 1682.919,
      "duration": 6.681
    },
    {
      "lang": "en",
      "text": "we had before so this token is the token",
      "offset": 1686.88,
      "duration": 5.96
    },
    {
      "lang": "en",
      "text": "article uh instead so viewing a single",
      "offset": 1689.6,
      "duration": 5.88
    },
    {
      "lang": "en",
      "text": "article and so in this case we didn't",
      "offset": 1692.84,
      "duration": 4.52
    },
    {
      "lang": "en",
      "text": "exactly reproduce the sequence that we",
      "offset": 1695.48,
      "duration": 4.84
    },
    {
      "lang": "en",
      "text": "saw here in the training data so keep in",
      "offset": 1697.36,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "mind that these systems are stochastic",
      "offset": 1700.32,
      "duration": 5.479
    },
    {
      "lang": "en",
      "text": "they have um we're sampling and we're",
      "offset": 1702.64,
      "duration": 6.12
    },
    {
      "lang": "en",
      "text": "flipping coins and sometimes we lock out",
      "offset": 1705.799,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "and we reproduce some like small chunk",
      "offset": 1708.76,
      "duration": 4.039
    },
    {
      "lang": "en",
      "text": "of the text and training set but",
      "offset": 1710.919,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "sometimes we're uh we're getting a token",
      "offset": 1712.799,
      "duration": 5.521
    },
    {
      "lang": "en",
      "text": "that was not verbatim part of any of the",
      "offset": 1715.559,
      "duration": 4.801
    },
    {
      "lang": "en",
      "text": "documents in the training data so we're",
      "offset": 1718.32,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "going to get sort of like remixes of the",
      "offset": 1720.36,
      "duration": 4.52
    },
    {
      "lang": "en",
      "text": "data that we saw in the training because",
      "offset": 1723.2,
      "duration": 3.88
    },
    {
      "lang": "en",
      "text": "at every step of the way we can flip and",
      "offset": 1724.88,
      "duration": 3.799
    },
    {
      "lang": "en",
      "text": "get a slightly different token and then",
      "offset": 1727.08,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "once that token makes it in if you",
      "offset": 1728.679,
      "duration": 3.88
    },
    {
      "lang": "en",
      "text": "sample the next one and so on you very",
      "offset": 1730.6,
      "duration": 4.52
    },
    {
      "lang": "en",
      "text": "quickly uh start to generate token",
      "offset": 1732.559,
      "duration": 4.521
    },
    {
      "lang": "en",
      "text": "streams that are very different from the",
      "offset": 1735.12,
      "duration": 3.559
    },
    {
      "lang": "en",
      "text": "token streams that UR",
      "offset": 1737.08,
      "duration": 3.56
    },
    {
      "lang": "en",
      "text": "in the training documents so",
      "offset": 1738.679,
      "duration": 3.521
    },
    {
      "lang": "en",
      "text": "statistically they will have similar",
      "offset": 1740.64,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "properties but um they are not identical",
      "offset": 1742.2,
      "duration": 4.52
    },
    {
      "lang": "en",
      "text": "to your training data they're kind of",
      "offset": 1745.2,
      "duration": 3.88
    },
    {
      "lang": "en",
      "text": "like inspired by the training data and",
      "offset": 1746.72,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "so in this case we got a slightly",
      "offset": 1749.08,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "different sequence and why would we get",
      "offset": 1750.64,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "article you might imagine that article",
      "offset": 1752.76,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "is a relatively likely token in the",
      "offset": 1754.799,
      "duration": 6.201
    },
    {
      "lang": "en",
      "text": "context of bar viewing single Etc and",
      "offset": 1756.84,
      "duration": 5.48
    },
    {
      "lang": "en",
      "text": "you can imagine that the word article",
      "offset": 1761,
      "duration": 3.679
    },
    {
      "lang": "en",
      "text": "followed this context window somewhere",
      "offset": 1762.32,
      "duration": 4.479
    },
    {
      "lang": "en",
      "text": "in the training documents uh to some",
      "offset": 1764.679,
      "duration": 4.12
    },
    {
      "lang": "en",
      "text": "extent and we just happen to sample it",
      "offset": 1766.799,
      "duration": 4.36
    },
    {
      "lang": "en",
      "text": "here at that stage so basically",
      "offset": 1768.799,
      "duration": 4.681
    },
    {
      "lang": "en",
      "text": "inference is just uh predicting from",
      "offset": 1771.159,
      "duration": 4.281
    },
    {
      "lang": "en",
      "text": "these distributions one at a time we",
      "offset": 1773.48,
      "duration": 3.799
    },
    {
      "lang": "en",
      "text": "continue feeding back tokens and getting",
      "offset": 1775.44,
      "duration": 4.52
    },
    {
      "lang": "en",
      "text": "the next one and we uh we're always",
      "offset": 1777.279,
      "duration": 4.721
    },
    {
      "lang": "en",
      "text": "flipping these coins and depending on",
      "offset": 1779.96,
      "duration": 5.599
    },
    {
      "lang": "en",
      "text": "how lucky or unlucky we get um we might",
      "offset": 1782,
      "duration": 5
    },
    {
      "lang": "en",
      "text": "get very different kinds of patterns",
      "offset": 1785.559,
      "duration": 3.881
    },
    {
      "lang": "en",
      "text": "depending on how we sample from these",
      "offset": 1787,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "probability distributions so that's",
      "offset": 1789.44,
      "duration": 5.839
    },
    {
      "lang": "en",
      "text": "inference so in most common scenarios uh",
      "offset": 1791.64,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "basically downloading the internet and",
      "offset": 1795.279,
      "duration": 3.561
    },
    {
      "lang": "en",
      "text": "tokenizing it is is a pre-processing",
      "offset": 1797.24,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "step you do that a single time and then",
      "offset": 1798.84,
      "duration": 5.439
    },
    {
      "lang": "en",
      "text": "uh once you have your token sequence we",
      "offset": 1801.88,
      "duration": 4.76
    },
    {
      "lang": "en",
      "text": "can start training networks and in",
      "offset": 1804.279,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "Practical cases you would try to train",
      "offset": 1806.64,
      "duration": 3.399
    },
    {
      "lang": "en",
      "text": "many different networks of different",
      "offset": 1808.6,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "kinds of uh settings and different kinds",
      "offset": 1810.039,
      "duration": 3.48
    },
    {
      "lang": "en",
      "text": "of arrangements and different kinds of",
      "offset": 1811.96,
      "duration": 3.48
    },
    {
      "lang": "en",
      "text": "sizes and so you''ll be doing a lot of",
      "offset": 1813.519,
      "duration": 4.561
    },
    {
      "lang": "en",
      "text": "neural network training and um then once",
      "offset": 1815.44,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "you have a neural network and you train",
      "offset": 1818.08,
      "duration": 3.56
    },
    {
      "lang": "en",
      "text": "it and you have some specific set of",
      "offset": 1819.519,
      "duration": 4.721
    },
    {
      "lang": "en",
      "text": "parameters that you're happy with um",
      "offset": 1821.64,
      "duration": 4.12
    },
    {
      "lang": "en",
      "text": "then you can take the model and you can",
      "offset": 1824.24,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "do inference and you can actually uh",
      "offset": 1825.76,
      "duration": 4.36
    },
    {
      "lang": "en",
      "text": "generate data from the model and when",
      "offset": 1828,
      "duration": 3.519
    },
    {
      "lang": "en",
      "text": "you're on chat GPT and you're talking",
      "offset": 1830.12,
      "duration": 3.72
    },
    {
      "lang": "en",
      "text": "with a model uh that model is trained",
      "offset": 1831.519,
      "duration": 4.921
    },
    {
      "lang": "en",
      "text": "and has been trained by open aai many",
      "offset": 1833.84,
      "duration": 4.76
    },
    {
      "lang": "en",
      "text": "months ago probably and they have a",
      "offset": 1836.44,
      "duration": 5
    },
    {
      "lang": "en",
      "text": "specific set of Weights that work well",
      "offset": 1838.6,
      "duration": 4.28
    },
    {
      "lang": "en",
      "text": "and when you're talking to the model all",
      "offset": 1841.44,
      "duration": 3.16
    },
    {
      "lang": "en",
      "text": "of that is just inference there's no",
      "offset": 1842.88,
      "duration": 4.2
    },
    {
      "lang": "en",
      "text": "more training those parameters are held",
      "offset": 1844.6,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "fixed and you're just talking to the",
      "offset": 1847.08,
      "duration": 4.479
    },
    {
      "lang": "en",
      "text": "model sort of uh you're giving it some",
      "offset": 1849.32,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "of the tokens and it's kind of",
      "offset": 1851.559,
      "duration": 3.321
    },
    {
      "lang": "en",
      "text": "completing token sequences and that's",
      "offset": 1853.159,
      "duration": 3.961
    },
    {
      "lang": "en",
      "text": "what you're seeing uh generated when you",
      "offset": 1854.88,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "actually use the model on CH GPT so that",
      "offset": 1857.12,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "model then just does inference alone so",
      "offset": 1859.6,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "let's now look at an example of training",
      "offset": 1862.32,
      "duration": 3.64
    },
    {
      "lang": "en",
      "text": "an inference that is kind of concrete",
      "offset": 1864.08,
      "duration": 2.92
    },
    {
      "lang": "en",
      "text": "and gives you a sense of what this",
      "offset": 1865.96,
      "duration": 2.8
    },
    {
      "lang": "en",
      "text": "actually looks like uh when these models",
      "offset": 1867,
      "duration": 3.96
    },
    {
      "lang": "en",
      "text": "are trained now the example that I would",
      "offset": 1868.76,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "like to work with and that I'm",
      "offset": 1870.96,
      "duration": 3.319
    },
    {
      "lang": "en",
      "text": "particularly fond of is that of opening",
      "offset": 1872.2,
      "duration": 5.24
    },
    {
      "lang": "en",
      "text": "eyes gpt2 so GPT uh stands for",
      "offset": 1874.279,
      "duration": 5.321
    },
    {
      "lang": "en",
      "text": "generatively pre-trained Transformer and",
      "offset": 1877.44,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "this is the second iteration of the GPT",
      "offset": 1879.6,
      "duration": 4.36
    },
    {
      "lang": "en",
      "text": "series by open AI when you are talking",
      "offset": 1881.519,
      "duration": 4.76
    },
    {
      "lang": "en",
      "text": "to chat GPT today the model that is",
      "offset": 1883.96,
      "duration": 3.959
    },
    {
      "lang": "en",
      "text": "underlying all of the magic of that",
      "offset": 1886.279,
      "duration": 4.12
    },
    {
      "lang": "en",
      "text": "interaction is GPT 4 so the fourth",
      "offset": 1887.919,
      "duration": 5.161
    },
    {
      "lang": "en",
      "text": "iteration of that series now gpt2 was",
      "offset": 1890.399,
      "duration": 5.961
    },
    {
      "lang": "en",
      "text": "published in 2019 by openi in this paper",
      "offset": 1893.08,
      "duration": 6.04
    },
    {
      "lang": "en",
      "text": "that I have right here and the reason I",
      "offset": 1896.36,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "like gpt2 is that it is the first time",
      "offset": 1899.12,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "that a recognizably modern stack came",
      "offset": 1901.88,
      "duration": 6.88
    },
    {
      "lang": "en",
      "text": "together so um all of the pieces of gpd2",
      "offset": 1904.48,
      "duration": 6.12
    },
    {
      "lang": "en",
      "text": "are recognizable today by modern",
      "offset": 1908.76,
      "duration": 3.279
    },
    {
      "lang": "en",
      "text": "standards it's just everything has",
      "offset": 1910.6,
      "duration": 3.559
    },
    {
      "lang": "en",
      "text": "gotten bigger now I'm not going to be",
      "offset": 1912.039,
      "duration": 3.721
    },
    {
      "lang": "en",
      "text": "able to go into the full details of this",
      "offset": 1914.159,
      "duration": 2.921
    },
    {
      "lang": "en",
      "text": "paper of course because it is a",
      "offset": 1915.76,
      "duration": 3.759
    },
    {
      "lang": "en",
      "text": "technical publication but some of the",
      "offset": 1917.08,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "details that I would like to highlight",
      "offset": 1919.519,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "are as follows gpt2 was a Transformer",
      "offset": 1920.76,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "neural network just like you were just",
      "offset": 1923.6,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "like the neural networks you would work",
      "offset": 1925.72,
      "duration": 4.6
    },
    {
      "lang": "en",
      "text": "with today it was it had 1.6 billion",
      "offset": 1926.96,
      "duration": 5.24
    },
    {
      "lang": "en",
      "text": "parameters right so these are the",
      "offset": 1930.32,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "parameters that we looked at here it",
      "offset": 1932.2,
      "duration": 4.76
    },
    {
      "lang": "en",
      "text": "would have 1.6 billion of them today",
      "offset": 1934.399,
      "duration": 3.88
    },
    {
      "lang": "en",
      "text": "modern Transformers would have a lot",
      "offset": 1936.96,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "closer to a trillion or several hundred",
      "offset": 1938.279,
      "duration": 3.64
    },
    {
      "lang": "en",
      "text": "billion",
      "offset": 1940.32,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "probably the maximum context length here",
      "offset": 1941.919,
      "duration": 7
    },
    {
      "lang": "en",
      "text": "was 1,24 tokens so it is when we are",
      "offset": 1944.96,
      "duration": 7.24
    },
    {
      "lang": "en",
      "text": "sampling chunks of Windows of tokens",
      "offset": 1948.919,
      "duration": 5.48
    },
    {
      "lang": "en",
      "text": "from the data set we're never taking",
      "offset": 1952.2,
      "duration": 4.479
    },
    {
      "lang": "en",
      "text": "more than 1,24 tokens and so when you",
      "offset": 1954.399,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "are trying to predict the next token in",
      "offset": 1956.679,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "a sequence you will never have more than",
      "offset": 1958,
      "duration": 5.159
    },
    {
      "lang": "en",
      "text": "1,24 tokens uh kind of in your context",
      "offset": 1960.039,
      "duration": 5.48
    },
    {
      "lang": "en",
      "text": "in order to make that prediction now",
      "offset": 1963.159,
      "duration": 4.201
    },
    {
      "lang": "en",
      "text": "this is also tiny by modern standards",
      "offset": 1965.519,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "today the token uh the context lengths",
      "offset": 1967.36,
      "duration": 5.679
    },
    {
      "lang": "en",
      "text": "would be a lot closer to um couple",
      "offset": 1969.519,
      "duration": 5.481
    },
    {
      "lang": "en",
      "text": "hundred thousand or maybe even a million",
      "offset": 1973.039,
      "duration": 3.721
    },
    {
      "lang": "en",
      "text": "and so you have a lot more context a lot",
      "offset": 1975,
      "duration": 3.639
    },
    {
      "lang": "en",
      "text": "more tokens in history history and you",
      "offset": 1976.76,
      "duration": 3.279
    },
    {
      "lang": "en",
      "text": "can make a lot better prediction about",
      "offset": 1978.639,
      "duration": 3.321
    },
    {
      "lang": "en",
      "text": "the next token in the sequence in that",
      "offset": 1980.039,
      "duration": 4.561
    },
    {
      "lang": "en",
      "text": "way and finally gpt2 was trained on",
      "offset": 1981.96,
      "duration": 4.839
    },
    {
      "lang": "en",
      "text": "approximately 100 billion tokens and",
      "offset": 1984.6,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "this is also fairly small by modern",
      "offset": 1986.799,
      "duration": 3.48
    },
    {
      "lang": "en",
      "text": "standards as I mentioned the fine web",
      "offset": 1988.6,
      "duration": 3.72
    },
    {
      "lang": "en",
      "text": "data set that we looked at here the fine",
      "offset": 1990.279,
      "duration": 4.481
    },
    {
      "lang": "en",
      "text": "web data set has 15 trillion tokens uh",
      "offset": 1992.32,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "so 100 billion is is quite",
      "offset": 1994.76,
      "duration": 4.039
    },
    {
      "lang": "en",
      "text": "small",
      "offset": 1996.96,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "now uh I actually tried to reproduce uh",
      "offset": 1998.799,
      "duration": 4.801
    },
    {
      "lang": "en",
      "text": "gpt2 for fun as part of this project",
      "offset": 2001.44,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "called lm. C so you can see my rup of",
      "offset": 2003.6,
      "duration": 6.4
    },
    {
      "lang": "en",
      "text": "doing that in this post on GitHub under",
      "offset": 2007.12,
      "duration": 6.399
    },
    {
      "lang": "en",
      "text": "the lm. C repository so in particular",
      "offset": 2010,
      "duration": 6.96
    },
    {
      "lang": "en",
      "text": "the cost of training gpd2 in 2019 what",
      "offset": 2013.519,
      "duration": 5.801
    },
    {
      "lang": "en",
      "text": "was estimated to be approximately",
      "offset": 2016.96,
      "duration": 4.36
    },
    {
      "lang": "en",
      "text": "$40,000 but today you can do",
      "offset": 2019.32,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "significantly better than that and in",
      "offset": 2021.32,
      "duration": 4.239
    },
    {
      "lang": "en",
      "text": "particular here it took about one day",
      "offset": 2022.76,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "and about",
      "offset": 2025.559,
      "duration": 4.12
    },
    {
      "lang": "en",
      "text": "$600 uh but this wasn't even trying too",
      "offset": 2027.24,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "hard I think you could really bring this",
      "offset": 2029.679,
      "duration": 5.801
    },
    {
      "lang": "en",
      "text": "down to about $100 today now why is it",
      "offset": 2031.48,
      "duration": 5.919
    },
    {
      "lang": "en",
      "text": "that the costs have come down so much",
      "offset": 2035.48,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "well number one these data sets have",
      "offset": 2037.399,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "gotten a lot better and the way we",
      "offset": 2039.399,
      "duration": 3.88
    },
    {
      "lang": "en",
      "text": "filter them extract them and prepare",
      "offset": 2041.399,
      "duration": 4.28
    },
    {
      "lang": "en",
      "text": "them has gotten a lot more refined and",
      "offset": 2043.279,
      "duration": 4.761
    },
    {
      "lang": "en",
      "text": "so the data set is of just a lot higher",
      "offset": 2045.679,
      "duration": 4.761
    },
    {
      "lang": "en",
      "text": "quality so that's one thing but really",
      "offset": 2048.04,
      "duration": 3.799
    },
    {
      "lang": "en",
      "text": "the biggest difference is that our",
      "offset": 2050.44,
      "duration": 3.439
    },
    {
      "lang": "en",
      "text": "computers have gotten much faster in",
      "offset": 2051.839,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "terms of the hardware and we're going to",
      "offset": 2053.879,
      "duration": 3.48
    },
    {
      "lang": "en",
      "text": "look at that in a second and also the",
      "offset": 2055.359,
      "duration": 5
    },
    {
      "lang": "en",
      "text": "software for uh running these models and",
      "offset": 2057.359,
      "duration": 5.161
    },
    {
      "lang": "en",
      "text": "really squeezing out all all the speed",
      "offset": 2060.359,
      "duration": 5.161
    },
    {
      "lang": "en",
      "text": "from the hardware as it is possible uh",
      "offset": 2062.52,
      "duration": 4.559
    },
    {
      "lang": "en",
      "text": "that software has also gotten much",
      "offset": 2065.52,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "better as as everyone has focused on",
      "offset": 2067.079,
      "duration": 3.08
    },
    {
      "lang": "en",
      "text": "these models and try to run them very",
      "offset": 2068.72,
      "duration": 2.76
    },
    {
      "lang": "en",
      "text": "very",
      "offset": 2070.159,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "quickly now I'm not going to be able to",
      "offset": 2071.48,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "go into the full detail of this gpd2",
      "offset": 2074.48,
      "duration": 3.32
    },
    {
      "lang": "en",
      "text": "reproduction and this is a long",
      "offset": 2076.52,
      "duration": 3.399
    },
    {
      "lang": "en",
      "text": "technical post but I would like to still",
      "offset": 2077.8,
      "duration": 3.799
    },
    {
      "lang": "en",
      "text": "give you an intuitive sense for what it",
      "offset": 2079.919,
      "duration": 3.281
    },
    {
      "lang": "en",
      "text": "looks like to actually train one of",
      "offset": 2081.599,
      "duration": 3.32
    },
    {
      "lang": "en",
      "text": "these models as a researcher like what",
      "offset": 2083.2,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "are you looking at and what does it look",
      "offset": 2084.919,
      "duration": 3.041
    },
    {
      "lang": "en",
      "text": "like what does it feel like so let me",
      "offset": 2086.24,
      "duration": 3.8
    },
    {
      "lang": "en",
      "text": "give you a sense of that a little bit",
      "offset": 2087.96,
      "duration": 3.24
    },
    {
      "lang": "en",
      "text": "okay so this is what it looks like let",
      "offset": 2090.04,
      "duration": 2.92
    },
    {
      "lang": "en",
      "text": "me slide this",
      "offset": 2091.2,
      "duration": 4.36
    },
    {
      "lang": "en",
      "text": "over so what I'm doing here is I'm",
      "offset": 2092.96,
      "duration": 5.72
    },
    {
      "lang": "en",
      "text": "training a gpt2 model right now",
      "offset": 2095.56,
      "duration": 5.4
    },
    {
      "lang": "en",
      "text": "and um what's happening here is that",
      "offset": 2098.68,
      "duration": 6.36
    },
    {
      "lang": "en",
      "text": "every single line here like this one is",
      "offset": 2100.96,
      "duration": 7.84
    },
    {
      "lang": "en",
      "text": "one update to the model so remember how",
      "offset": 2105.04,
      "duration": 6.96
    },
    {
      "lang": "en",
      "text": "here we are um basically making the",
      "offset": 2108.8,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "prediction better for every one of these",
      "offset": 2112,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "tokens and we are updating these weights",
      "offset": 2114,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "or parameters of the neural net so here",
      "offset": 2115.92,
      "duration": 4.76
    },
    {
      "lang": "en",
      "text": "every single line is One update to the",
      "offset": 2118.64,
      "duration": 3.88
    },
    {
      "lang": "en",
      "text": "neural network where we change its",
      "offset": 2120.68,
      "duration": 3.64
    },
    {
      "lang": "en",
      "text": "parameters by a little bit so that it is",
      "offset": 2122.52,
      "duration": 3.599
    },
    {
      "lang": "en",
      "text": "better at predicting next token and",
      "offset": 2124.32,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "sequence in particular every single line",
      "offset": 2126.119,
      "duration": 6.361
    },
    {
      "lang": "en",
      "text": "here is improving the prediction on 1",
      "offset": 2128.56,
      "duration": 7.32
    },
    {
      "lang": "en",
      "text": "million tokens in the training set so",
      "offset": 2132.48,
      "duration": 6.639
    },
    {
      "lang": "en",
      "text": "we've basically taken 1 million tokens",
      "offset": 2135.88,
      "duration": 5.959
    },
    {
      "lang": "en",
      "text": "out of this data set and we've tried to",
      "offset": 2139.119,
      "duration": 5.641
    },
    {
      "lang": "en",
      "text": "improve the prediction of that token as",
      "offset": 2141.839,
      "duration": 5.081
    },
    {
      "lang": "en",
      "text": "coming next in a sequence on all 1",
      "offset": 2144.76,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "million of them",
      "offset": 2146.92,
      "duration": 4.28
    },
    {
      "lang": "en",
      "text": "simultaneously and at every single one",
      "offset": 2149.079,
      "duration": 3.481
    },
    {
      "lang": "en",
      "text": "of these steps we are making an update",
      "offset": 2151.2,
      "duration": 4.28
    },
    {
      "lang": "en",
      "text": "to the network for that now the number",
      "offset": 2152.56,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "to watch closely is this number called",
      "offset": 2155.48,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "loss and the loss is a single number",
      "offset": 2157.92,
      "duration": 4.919
    },
    {
      "lang": "en",
      "text": "that is telling you how well your neural",
      "offset": 2160.76,
      "duration": 4.52
    },
    {
      "lang": "en",
      "text": "network is performing right now and it",
      "offset": 2162.839,
      "duration": 5.961
    },
    {
      "lang": "en",
      "text": "is created so that low loss is good so",
      "offset": 2165.28,
      "duration": 5.559
    },
    {
      "lang": "en",
      "text": "you'll see that the loss is decreasing",
      "offset": 2168.8,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "as we make more updates to the neural",
      "offset": 2170.839,
      "duration": 3.48
    },
    {
      "lang": "en",
      "text": "nut which corresponds to making better",
      "offset": 2172.56,
      "duration": 3.88
    },
    {
      "lang": "en",
      "text": "predictions on the next token in a",
      "offset": 2174.319,
      "duration": 4.961
    },
    {
      "lang": "en",
      "text": "sequence and so the loss is the number",
      "offset": 2176.44,
      "duration": 4.28
    },
    {
      "lang": "en",
      "text": "that you are watching as a neural",
      "offset": 2179.28,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "network researcher and you are kind of",
      "offset": 2180.72,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "waiting you're twiddling your thumbs uh",
      "offset": 2182.56,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "you're drinking coffee and you're making",
      "offset": 2184.48,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "sure that this looks good so that with",
      "offset": 2186.48,
      "duration": 4.639
    },
    {
      "lang": "en",
      "text": "every update your loss is improving and",
      "offset": 2188.96,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "the network is getting better at",
      "offset": 2191.119,
      "duration": 4.881
    },
    {
      "lang": "en",
      "text": "prediction now here you see that we are",
      "offset": 2192.96,
      "duration": 5.84
    },
    {
      "lang": "en",
      "text": "processing 1 million tokens per update",
      "offset": 2196,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "each update takes about 7 Seconds",
      "offset": 2198.8,
      "duration": 5.039
    },
    {
      "lang": "en",
      "text": "roughly and here we are going to process",
      "offset": 2201.2,
      "duration": 5.8
    },
    {
      "lang": "en",
      "text": "a total of 32,000 steps of",
      "offset": 2203.839,
      "duration": 6.441
    },
    {
      "lang": "en",
      "text": "optimization so 32,000 steps with 1",
      "offset": 2207,
      "duration": 5.72
    },
    {
      "lang": "en",
      "text": "million tokens each is about 33 billion",
      "offset": 2210.28,
      "duration": 4.44
    },
    {
      "lang": "en",
      "text": "tokens that we are going to process and",
      "offset": 2212.72,
      "duration": 5.24
    },
    {
      "lang": "en",
      "text": "we're currently only about 420 step 20",
      "offset": 2214.72,
      "duration": 6.56
    },
    {
      "lang": "en",
      "text": "out of 32,000 so we are still only a bit",
      "offset": 2217.96,
      "duration": 5.399
    },
    {
      "lang": "en",
      "text": "more than 1% done because I've only been",
      "offset": 2221.28,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "running this for 10 or 15 minutes or",
      "offset": 2223.359,
      "duration": 2.96
    },
    {
      "lang": "en",
      "text": "something like",
      "offset": 2225.04,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "that now every 20 steps I have",
      "offset": 2226.319,
      "duration": 4.841
    },
    {
      "lang": "en",
      "text": "configured this optimization to do",
      "offset": 2229.2,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "inference so what you're seeing here is",
      "offset": 2231.16,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "the model is predicting the next token",
      "offset": 2233.359,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "in a sequence and so you sort of start",
      "offset": 2235.079,
      "duration": 4.481
    },
    {
      "lang": "en",
      "text": "it randomly and then you continue",
      "offset": 2237.52,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "plugging in the tokens so we're running",
      "offset": 2239.56,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "this inference step and this is the",
      "offset": 2241.599,
      "duration": 3.401
    },
    {
      "lang": "en",
      "text": "model sort of predicting the next token",
      "offset": 2243.72,
      "duration": 2.599
    },
    {
      "lang": "en",
      "text": "in the sequence and every time you see",
      "offset": 2245,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "something appear that's a new",
      "offset": 2246.319,
      "duration": 8.04
    },
    {
      "lang": "en",
      "text": "token um so let's just look at this and",
      "offset": 2249.24,
      "duration": 6.48
    },
    {
      "lang": "en",
      "text": "you can see that this is not yet very",
      "offset": 2254.359,
      "duration": 3
    },
    {
      "lang": "en",
      "text": "coherent and keep in mind that this is",
      "offset": 2255.72,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "only 1% of the way through training and",
      "offset": 2257.359,
      "duration": 3.96
    },
    {
      "lang": "en",
      "text": "so the model is not yet very good at",
      "offset": 2259.64,
      "duration": 2.719
    },
    {
      "lang": "en",
      "text": "predicting the next token in the",
      "offset": 2261.319,
      "duration": 3.441
    },
    {
      "lang": "en",
      "text": "sequence so what comes out is actually",
      "offset": 2262.359,
      "duration": 4.76
    },
    {
      "lang": "en",
      "text": "kind of a little bit of gibberish right",
      "offset": 2264.76,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "but it still has a little bit of like",
      "offset": 2267.119,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "local coherence so since she is mine",
      "offset": 2268.599,
      "duration": 4.52
    },
    {
      "lang": "en",
      "text": "it's a part of the information should",
      "offset": 2271.599,
      "duration": 4.361
    },
    {
      "lang": "en",
      "text": "discuss my father great companions",
      "offset": 2273.119,
      "duration": 5.96
    },
    {
      "lang": "en",
      "text": "Gordon showed me sitting over at and Etc",
      "offset": 2275.96,
      "duration": 5
    },
    {
      "lang": "en",
      "text": "so I know it doesn't look very good but",
      "offset": 2279.079,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "let's actually scroll up and see what it",
      "offset": 2280.96,
      "duration": 5.08
    },
    {
      "lang": "en",
      "text": "looked like when I started the",
      "offset": 2284.119,
      "duration": 6.24
    },
    {
      "lang": "en",
      "text": "optimization so all the way here at",
      "offset": 2286.04,
      "duration": 6.039
    },
    {
      "lang": "en",
      "text": "step",
      "offset": 2290.359,
      "duration": 4.921
    },
    {
      "lang": "en",
      "text": "one so after 20 steps of optimization",
      "offset": 2292.079,
      "duration": 4.961
    },
    {
      "lang": "en",
      "text": "you see that what we're getting here is",
      "offset": 2295.28,
      "duration": 3.24
    },
    {
      "lang": "en",
      "text": "looks completely random and of course",
      "offset": 2297.04,
      "duration": 3.24
    },
    {
      "lang": "en",
      "text": "that's because the model has only had 20",
      "offset": 2298.52,
      "duration": 3.599
    },
    {
      "lang": "en",
      "text": "updates to its parameters and so it's",
      "offset": 2300.28,
      "duration": 3.319
    },
    {
      "lang": "en",
      "text": "giving you random text because it's a",
      "offset": 2302.119,
      "duration": 3.801
    },
    {
      "lang": "en",
      "text": "random Network and so you can see that",
      "offset": 2303.599,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "at least in comparison to this model is",
      "offset": 2305.92,
      "duration": 3.96
    },
    {
      "lang": "en",
      "text": "starting to do much better and indeed if",
      "offset": 2307.92,
      "duration": 4.679
    },
    {
      "lang": "en",
      "text": "we waited the entire 32,000 steps the",
      "offset": 2309.88,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "model will have improved the point that",
      "offset": 2312.599,
      "duration": 3.801
    },
    {
      "lang": "en",
      "text": "it's actually uh generating fairly",
      "offset": 2314.2,
      "duration": 4.76
    },
    {
      "lang": "en",
      "text": "coherent English uh and the tokens",
      "offset": 2316.4,
      "duration": 5.64
    },
    {
      "lang": "en",
      "text": "stream correctly um and uh they they",
      "offset": 2318.96,
      "duration": 5.879
    },
    {
      "lang": "en",
      "text": "kind of make up English a a lot",
      "offset": 2322.04,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "better",
      "offset": 2324.839,
      "duration": 4.721
    },
    {
      "lang": "en",
      "text": "um so this has to run for about a day or",
      "offset": 2326.44,
      "duration": 5.919
    },
    {
      "lang": "en",
      "text": "two more now and so uh at this stage we",
      "offset": 2329.56,
      "duration": 3.96
    },
    {
      "lang": "en",
      "text": "just make sure that the loss is",
      "offset": 2332.359,
      "duration": 4.041
    },
    {
      "lang": "en",
      "text": "decreasing everything is looking good um",
      "offset": 2333.52,
      "duration": 4.559
    },
    {
      "lang": "en",
      "text": "and we just have to wait",
      "offset": 2336.4,
      "duration": 5.719
    },
    {
      "lang": "en",
      "text": "and now um let me turn now to the um",
      "offset": 2338.079,
      "duration": 7
    },
    {
      "lang": "en",
      "text": "story of the computation that's required",
      "offset": 2342.119,
      "duration": 4.361
    },
    {
      "lang": "en",
      "text": "because of course I'm not running this",
      "offset": 2345.079,
      "duration": 3.441
    },
    {
      "lang": "en",
      "text": "optimization on my laptop that would be",
      "offset": 2346.48,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "way too expensive uh because we have to",
      "offset": 2348.52,
      "duration": 4.36
    },
    {
      "lang": "en",
      "text": "run this neural network and we have to",
      "offset": 2351.04,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "improve it and we have we need all this",
      "offset": 2352.88,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "data and so on so you can't run this too",
      "offset": 2354.64,
      "duration": 4.12
    },
    {
      "lang": "en",
      "text": "well on your computer uh because the",
      "offset": 2356.8,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "network is just too large uh so all of",
      "offset": 2358.76,
      "duration": 4.359
    },
    {
      "lang": "en",
      "text": "this is running on the computer that is",
      "offset": 2361.28,
      "duration": 3.799
    },
    {
      "lang": "en",
      "text": "out there in the cloud and I want to",
      "offset": 2363.119,
      "duration": 3.881
    },
    {
      "lang": "en",
      "text": "basically address the compute side of",
      "offset": 2365.079,
      "duration": 3.641
    },
    {
      "lang": "en",
      "text": "the store of training these models and",
      "offset": 2367,
      "duration": 3.24
    },
    {
      "lang": "en",
      "text": "what that looks like so let's take a",
      "offset": 2368.72,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "look okay so the computer that I'm",
      "offset": 2370.24,
      "duration": 5.24
    },
    {
      "lang": "en",
      "text": "running this optimization on is this 8X",
      "offset": 2372.24,
      "duration": 7.359
    },
    {
      "lang": "en",
      "text": "h100 node so there are eight h100s in a",
      "offset": 2375.48,
      "duration": 7.119
    },
    {
      "lang": "en",
      "text": "single node or a single computer now I",
      "offset": 2379.599,
      "duration": 4.76
    },
    {
      "lang": "en",
      "text": "am renting this computer and it is",
      "offset": 2382.599,
      "duration": 2.961
    },
    {
      "lang": "en",
      "text": "somewhere in the cloud I'm not sure",
      "offset": 2384.359,
      "duration": 3.321
    },
    {
      "lang": "en",
      "text": "where it is physically actually the",
      "offset": 2385.56,
      "duration": 3.559
    },
    {
      "lang": "en",
      "text": "place I like to rent from is called",
      "offset": 2387.68,
      "duration": 2.56
    },
    {
      "lang": "en",
      "text": "Lambda but there are many other",
      "offset": 2389.119,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "companies who provide this service so",
      "offset": 2390.24,
      "duration": 5.48
    },
    {
      "lang": "en",
      "text": "when you scroll down you can see that uh",
      "offset": 2392.319,
      "duration": 5.561
    },
    {
      "lang": "en",
      "text": "they have some on demand pricing for",
      "offset": 2395.72,
      "duration": 5.84
    },
    {
      "lang": "en",
      "text": "um sort of computers that have these uh",
      "offset": 2397.88,
      "duration": 5.719
    },
    {
      "lang": "en",
      "text": "h100s which are gpus and I'm going to",
      "offset": 2401.56,
      "duration": 4.44
    },
    {
      "lang": "en",
      "text": "show you what they look like in a second",
      "offset": 2403.599,
      "duration": 6.601
    },
    {
      "lang": "en",
      "text": "but on demand 8times Nvidia h100 uh",
      "offset": 2406,
      "duration": 7.839
    },
    {
      "lang": "en",
      "text": "GPU this machine comes for $3 per GPU",
      "offset": 2410.2,
      "duration": 6.56
    },
    {
      "lang": "en",
      "text": "per hour for example so you can rent",
      "offset": 2413.839,
      "duration": 4.441
    },
    {
      "lang": "en",
      "text": "these and then you get a machine in a",
      "offset": 2416.76,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "cloud and you can uh go in and you can",
      "offset": 2418.28,
      "duration": 3.319
    },
    {
      "lang": "en",
      "text": "train these",
      "offset": 2420.2,
      "duration": 5.48
    },
    {
      "lang": "en",
      "text": "models and these uh gpus they look like",
      "offset": 2421.599,
      "duration": 7.52
    },
    {
      "lang": "en",
      "text": "this so this is one h100 GPU uh this is",
      "offset": 2425.68,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "kind of what it looks like and you slot",
      "offset": 2429.119,
      "duration": 3.561
    },
    {
      "lang": "en",
      "text": "this into your computer and gpus are",
      "offset": 2430.48,
      "duration": 4.28
    },
    {
      "lang": "en",
      "text": "this uh perfect fit for training your",
      "offset": 2432.68,
      "duration": 3.88
    },
    {
      "lang": "en",
      "text": "networks because they are very",
      "offset": 2434.76,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "computationally expensive but they",
      "offset": 2436.56,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "display a lot of parallelism in the",
      "offset": 2438.52,
      "duration": 3.64
    },
    {
      "lang": "en",
      "text": "computation so you can have many",
      "offset": 2440.56,
      "duration": 4.12
    },
    {
      "lang": "en",
      "text": "independent workers kind of um working",
      "offset": 2442.16,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "all at the same time in solving uh the",
      "offset": 2444.68,
      "duration": 5.88
    },
    {
      "lang": "en",
      "text": "matrix multiplication that's under the",
      "offset": 2448.16,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "hood of training these neural",
      "offset": 2450.56,
      "duration": 4.279
    },
    {
      "lang": "en",
      "text": "networks so this is just one of these",
      "offset": 2452.88,
      "duration": 3.959
    },
    {
      "lang": "en",
      "text": "h100s but actually you would put them",
      "offset": 2454.839,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "you would put multiple of them together",
      "offset": 2456.839,
      "duration": 3.561
    },
    {
      "lang": "en",
      "text": "so you could stack eight of them into a",
      "offset": 2458.68,
      "duration": 3.639
    },
    {
      "lang": "en",
      "text": "single node and then you can stack",
      "offset": 2460.4,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "multiple nodes into an entire data",
      "offset": 2462.319,
      "duration": 4.881
    },
    {
      "lang": "en",
      "text": "center or an entire system",
      "offset": 2464.24,
      "duration": 6.76
    },
    {
      "lang": "en",
      "text": "so when we look at a data",
      "offset": 2467.2,
      "duration": 3.8
    },
    {
      "lang": "en",
      "text": "center can't spell when we look at a",
      "offset": 2472.319,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "data center we start to see things that",
      "offset": 2475,
      "duration": 3.319
    },
    {
      "lang": "en",
      "text": "look like this right so we have one GPU",
      "offset": 2476.4,
      "duration": 3.48
    },
    {
      "lang": "en",
      "text": "goes to eight gpus goes to a single",
      "offset": 2478.319,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "system goes to many systems and so these",
      "offset": 2479.88,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "are the bigger data centers and there of",
      "offset": 2482.4,
      "duration": 3.959
    },
    {
      "lang": "en",
      "text": "course would be much much more expensive",
      "offset": 2483.96,
      "duration": 4.68
    },
    {
      "lang": "en",
      "text": "um and what's happening is that all the",
      "offset": 2486.359,
      "duration": 4.881
    },
    {
      "lang": "en",
      "text": "big tech companies really desire these",
      "offset": 2488.64,
      "duration": 4.479
    },
    {
      "lang": "en",
      "text": "gpus so they can train all these",
      "offset": 2491.24,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "language models because they are so",
      "offset": 2493.119,
      "duration": 4.2
    },
    {
      "lang": "en",
      "text": "powerful and that has is fundamentally",
      "offset": 2495.079,
      "duration": 3.801
    },
    {
      "lang": "en",
      "text": "what has driven the stock price of",
      "offset": 2497.319,
      "duration": 4.641
    },
    {
      "lang": "en",
      "text": "Nvidia to be $3.4 trillion today as an",
      "offset": 2498.88,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "example and why Nvidia has kind of",
      "offset": 2501.96,
      "duration": 5.159
    },
    {
      "lang": "en",
      "text": "exploded so this is the Gold Rush the",
      "offset": 2504.88,
      "duration": 5.199
    },
    {
      "lang": "en",
      "text": "Gold Rush is getting the gpus getting",
      "offset": 2507.119,
      "duration": 4.881
    },
    {
      "lang": "en",
      "text": "enough of them so they can all",
      "offset": 2510.079,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "collaborate to perform this optimization",
      "offset": 2512,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "and they're what are they all doing",
      "offset": 2515.359,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "they're all collaborating to predict the",
      "offset": 2516.88,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "next token on a data set like the fine",
      "offset": 2519.119,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "web data",
      "offset": 2521.68,
      "duration": 3.639
    },
    {
      "lang": "en",
      "text": "set this is the computational workflow",
      "offset": 2522.96,
      "duration": 3.8
    },
    {
      "lang": "en",
      "text": "that that basically is extremely",
      "offset": 2525.319,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "expensive the more gpus you have the",
      "offset": 2526.76,
      "duration": 4.12
    },
    {
      "lang": "en",
      "text": "more tokens you can try to predict and",
      "offset": 2529.079,
      "duration": 3.801
    },
    {
      "lang": "en",
      "text": "improve on and you're going to process",
      "offset": 2530.88,
      "duration": 4.28
    },
    {
      "lang": "en",
      "text": "this data set faster and you can iterate",
      "offset": 2532.88,
      "duration": 3.719
    },
    {
      "lang": "en",
      "text": "faster and get a bigger Network and",
      "offset": 2535.16,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "train a bigger Network and so on so this",
      "offset": 2536.599,
      "duration": 4.361
    },
    {
      "lang": "en",
      "text": "is what all those machines are look like",
      "offset": 2539.319,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "are uh are doing and this is why all of",
      "offset": 2540.96,
      "duration": 5.639
    },
    {
      "lang": "en",
      "text": "this is such a big deal and for example",
      "offset": 2544.359,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "this is a",
      "offset": 2546.599,
      "duration": 3.48
    },
    {
      "lang": "en",
      "text": "article from like about a month ago or",
      "offset": 2548.599,
      "duration": 3.321
    },
    {
      "lang": "en",
      "text": "so this is why it's a big deal that for",
      "offset": 2550.079,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "example Elon Musk is getting 100,000",
      "offset": 2551.92,
      "duration": 6.679
    },
    {
      "lang": "en",
      "text": "gpus uh in a single Data Center and all",
      "offset": 2554.559,
      "duration": 6.121
    },
    {
      "lang": "en",
      "text": "of these gpus are extremely expensive",
      "offset": 2558.599,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "are going to take a ton of power and all",
      "offset": 2560.68,
      "duration": 2.84
    },
    {
      "lang": "en",
      "text": "of them are just trying to predict the",
      "offset": 2562.44,
      "duration": 3.159
    },
    {
      "lang": "en",
      "text": "next token in the sequence and improve",
      "offset": 2563.52,
      "duration": 5.72
    },
    {
      "lang": "en",
      "text": "the network uh by doing so and uh get",
      "offset": 2565.599,
      "duration": 5.161
    },
    {
      "lang": "en",
      "text": "probably a lot more coherent text than",
      "offset": 2569.24,
      "duration": 3.72
    },
    {
      "lang": "en",
      "text": "what we're seeing here a lot faster okay",
      "offset": 2570.76,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "so unfortunately I do not have a couple",
      "offset": 2572.96,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "10 or hundred million of dollars to",
      "offset": 2575,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "spend on training a really big model",
      "offset": 2577.2,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "like this but luckily we can turn to",
      "offset": 2579.24,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "some big tech companies who train these",
      "offset": 2581.28,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "models routinely and release some of",
      "offset": 2584.04,
      "duration": 4.559
    },
    {
      "lang": "en",
      "text": "them once they are done training so",
      "offset": 2586.48,
      "duration": 3.879
    },
    {
      "lang": "en",
      "text": "they've spent a huge amount of compute",
      "offset": 2588.599,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "to train this network and they release",
      "offset": 2590.359,
      "duration": 3.161
    },
    {
      "lang": "en",
      "text": "the network at the end of the",
      "offset": 2592.119,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "optimization so it's very useful because",
      "offset": 2593.52,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "they've done a lot of compute for that",
      "offset": 2595.559,
      "duration": 3.641
    },
    {
      "lang": "en",
      "text": "so there are many companies who train",
      "offset": 2598,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "these models routinely but actually not",
      "offset": 2599.2,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "many of them release uh these what's",
      "offset": 2601.28,
      "duration": 4.36
    },
    {
      "lang": "en",
      "text": "called base models so the model that",
      "offset": 2603.44,
      "duration": 3.96
    },
    {
      "lang": "en",
      "text": "comes out at the end here is is what's",
      "offset": 2605.64,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "called a base model what is a base model",
      "offset": 2607.4,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "it's a token simulator right it's an",
      "offset": 2609.8,
      "duration": 5.92
    },
    {
      "lang": "en",
      "text": "internet text token simulator and so",
      "offset": 2612.04,
      "duration": 6.12
    },
    {
      "lang": "en",
      "text": "that is not by itself useful yet because",
      "offset": 2615.72,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "what we want is what's called an",
      "offset": 2618.16,
      "duration": 3.199
    },
    {
      "lang": "en",
      "text": "assistant we want to ask questions and",
      "offset": 2619.48,
      "duration": 4.04
    },
    {
      "lang": "en",
      "text": "have it respond to answers these models",
      "offset": 2621.359,
      "duration": 4.2
    },
    {
      "lang": "en",
      "text": "won't do that they just uh create sort",
      "offset": 2623.52,
      "duration": 5.24
    },
    {
      "lang": "en",
      "text": "of remixes of the internet they dream",
      "offset": 2625.559,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "internet pages so the base models are",
      "offset": 2628.76,
      "duration": 4.12
    },
    {
      "lang": "en",
      "text": "not very often released because they're",
      "offset": 2631.559,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "kind of just only a step one of a few",
      "offset": 2632.88,
      "duration": 3.56
    },
    {
      "lang": "en",
      "text": "other steps that we still need to take",
      "offset": 2635.16,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "to get in system",
      "offset": 2636.44,
      "duration": 5
    },
    {
      "lang": "en",
      "text": "however a few releases have been made so",
      "offset": 2638.28,
      "duration": 6.12
    },
    {
      "lang": "en",
      "text": "as an example the gbt2 model released",
      "offset": 2641.44,
      "duration": 6.679
    },
    {
      "lang": "en",
      "text": "the 1.6 billion sorry 1.5 billion model",
      "offset": 2644.4,
      "duration": 6.32
    },
    {
      "lang": "en",
      "text": "back in 2019 and this gpt2 model is a",
      "offset": 2648.119,
      "duration": 5.681
    },
    {
      "lang": "en",
      "text": "base model now what is a model release",
      "offset": 2650.72,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "what does it look like to release these",
      "offset": 2653.8,
      "duration": 4.36
    },
    {
      "lang": "en",
      "text": "models so this is the gpt2 repository on",
      "offset": 2655.119,
      "duration": 5
    },
    {
      "lang": "en",
      "text": "GitHub well you need two things",
      "offset": 2658.16,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "basically to release model number one we",
      "offset": 2660.119,
      "duration": 7.681
    },
    {
      "lang": "en",
      "text": "need the um python code usually that",
      "offset": 2662.96,
      "duration": 7.08
    },
    {
      "lang": "en",
      "text": "describes the sequence of operations in",
      "offset": 2667.8,
      "duration": 7.16
    },
    {
      "lang": "en",
      "text": "detail that they make in their model so",
      "offset": 2670.04,
      "duration": 6.519
    },
    {
      "lang": "en",
      "text": "um if you remember",
      "offset": 2674.96,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "back this",
      "offset": 2676.559,
      "duration": 4.28
    },
    {
      "lang": "en",
      "text": "Transformer the sequence of steps that",
      "offset": 2678.8,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "are taken here in this neural network is",
      "offset": 2680.839,
      "duration": 5.041
    },
    {
      "lang": "en",
      "text": "what is being described by this code so",
      "offset": 2682.88,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "this code is sort of implementing the",
      "offset": 2685.88,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "what's called forward pass of this",
      "offset": 2687.44,
      "duration": 4.44
    },
    {
      "lang": "en",
      "text": "neural network so we need the specific",
      "offset": 2689,
      "duration": 4.559
    },
    {
      "lang": "en",
      "text": "details of exactly how they wired up",
      "offset": 2691.88,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "that neural network so this is just",
      "offset": 2693.559,
      "duration": 3.881
    },
    {
      "lang": "en",
      "text": "computer code and it's usually just a",
      "offset": 2695.88,
      "duration": 3.239
    },
    {
      "lang": "en",
      "text": "couple hundred lines of code it's not",
      "offset": 2697.44,
      "duration": 4.2
    },
    {
      "lang": "en",
      "text": "it's not that crazy and uh this is all",
      "offset": 2699.119,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "fairly understandable and usually fairly",
      "offset": 2701.64,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "standard what's not standard are the",
      "offset": 2703.2,
      "duration": 4.119
    },
    {
      "lang": "en",
      "text": "parameters that's where the actual value",
      "offset": 2705.24,
      "duration": 4.04
    },
    {
      "lang": "en",
      "text": "is what are the parameters of this",
      "offset": 2707.319,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "neural network because there's 1.6",
      "offset": 2709.28,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "billion of them and we need the correct",
      "offset": 2711.319,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "setting or a really good setting and so",
      "offset": 2713.119,
      "duration": 4.521
    },
    {
      "lang": "en",
      "text": "that's why in addition to this source",
      "offset": 2715.64,
      "duration": 4.36
    },
    {
      "lang": "en",
      "text": "code they release the parameters which",
      "offset": 2717.64,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "in this case is roughly 1.5 billion",
      "offset": 2720,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "parameters and these are just numbers so",
      "offset": 2723,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "it's one single list of 1.5 billion",
      "offset": 2725.2,
      "duration": 5.08
    },
    {
      "lang": "en",
      "text": "numbers the precise and good setting of",
      "offset": 2727.48,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "all the knobs such that the tokens come",
      "offset": 2730.28,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "out",
      "offset": 2732.44,
      "duration": 5
    },
    {
      "lang": "en",
      "text": "well so uh you need those two things to",
      "offset": 2733.96,
      "duration": 5.56
    },
    {
      "lang": "en",
      "text": "get a base model",
      "offset": 2737.44,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "release",
      "offset": 2739.52,
      "duration": 4.2
    },
    {
      "lang": "en",
      "text": "now gpt2 was released but that's",
      "offset": 2741.28,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "actually a fairly old model as I",
      "offset": 2743.72,
      "duration": 2.68
    },
    {
      "lang": "en",
      "text": "mentioned so actually the model we're",
      "offset": 2744.96,
      "duration": 4.2
    },
    {
      "lang": "en",
      "text": "going to turn to is called llama 3 and",
      "offset": 2746.4,
      "duration": 3.8
    },
    {
      "lang": "en",
      "text": "that's the one that I would like to show",
      "offset": 2749.16,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "you next so llama 3 so gpt2 again was",
      "offset": 2750.2,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "1.6 billion parameters trained on 100",
      "offset": 2754.28,
      "duration": 4.36
    },
    {
      "lang": "en",
      "text": "billion tokens Lama 3 is a much bigger",
      "offset": 2755.96,
      "duration": 4.599
    },
    {
      "lang": "en",
      "text": "model and much more modern model it is",
      "offset": 2758.64,
      "duration": 5.32
    },
    {
      "lang": "en",
      "text": "released and trained by meta and it is a",
      "offset": 2760.559,
      "duration": 6.601
    },
    {
      "lang": "en",
      "text": "45 billion parameter model trained on 15",
      "offset": 2763.96,
      "duration": 5.56
    },
    {
      "lang": "en",
      "text": "trillion tokens in very much the same",
      "offset": 2767.16,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "way just much much",
      "offset": 2769.52,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "bigger um and meta has also made a",
      "offset": 2771.079,
      "duration": 6.961
    },
    {
      "lang": "en",
      "text": "release of llama 3 and that was part of",
      "offset": 2774.96,
      "duration": 4.04
    },
    {
      "lang": "en",
      "text": "this",
      "offset": 2778.04,
      "duration": 3.24
    },
    {
      "lang": "en",
      "text": "paper so with this paper that goes into",
      "offset": 2779,
      "duration": 4.28
    },
    {
      "lang": "en",
      "text": "a lot of detail the biggest base model",
      "offset": 2781.28,
      "duration": 5.799
    },
    {
      "lang": "en",
      "text": "that they released is the Lama 3.1 4.5",
      "offset": 2783.28,
      "duration": 6.92
    },
    {
      "lang": "en",
      "text": "405 billion parameter model so this is",
      "offset": 2787.079,
      "duration": 5
    },
    {
      "lang": "en",
      "text": "the base model and then in addition to",
      "offset": 2790.2,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "the base model you see here",
      "offset": 2792.079,
      "duration": 3.24
    },
    {
      "lang": "en",
      "text": "foreshadowing for later sections of the",
      "offset": 2793.48,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "video they also released the instruct",
      "offset": 2795.319,
      "duration": 4.121
    },
    {
      "lang": "en",
      "text": "model and the instruct means that this",
      "offset": 2797.4,
      "duration": 4.04
    },
    {
      "lang": "en",
      "text": "is an assistant you can ask it questions",
      "offset": 2799.44,
      "duration": 3.639
    },
    {
      "lang": "en",
      "text": "and it will give you answers we still",
      "offset": 2801.44,
      "duration": 3.8
    },
    {
      "lang": "en",
      "text": "have yet to cover that part later for",
      "offset": 2803.079,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "now let's just look at this base model",
      "offset": 2805.24,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "this token simulator and let's play with",
      "offset": 2807,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "it and try to think about you know what",
      "offset": 2809.4,
      "duration": 4.12
    },
    {
      "lang": "en",
      "text": "is this thing and how does it work and",
      "offset": 2811.079,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "um what do we get at the end of this",
      "offset": 2813.52,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "optimization if you let this run Until",
      "offset": 2815.079,
      "duration": 4.721
    },
    {
      "lang": "en",
      "text": "the End uh for a very big neural network",
      "offset": 2817.2,
      "duration": 5
    },
    {
      "lang": "en",
      "text": "on a lot of data so my favorite place to",
      "offset": 2819.8,
      "duration": 5.16
    },
    {
      "lang": "en",
      "text": "interact with the base models is this um",
      "offset": 2822.2,
      "duration": 4.639
    },
    {
      "lang": "en",
      "text": "company called hyperbolic which is",
      "offset": 2824.96,
      "duration": 4.879
    },
    {
      "lang": "en",
      "text": "basically serving the base model of the",
      "offset": 2826.839,
      "duration": 6.52
    },
    {
      "lang": "en",
      "text": "405b Llama 3.1 so when you go to the",
      "offset": 2829.839,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "website and I think you may have to",
      "offset": 2833.359,
      "duration": 3.161
    },
    {
      "lang": "en",
      "text": "register and so on make sure that in the",
      "offset": 2834.559,
      "duration": 4.04
    },
    {
      "lang": "en",
      "text": "models make sure that you are using",
      "offset": 2836.52,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "llama 3.1 405 billion base it must be",
      "offset": 2838.599,
      "duration": 6.281
    },
    {
      "lang": "en",
      "text": "the base model and then here let's say",
      "offset": 2842.2,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "the max tokens is how many tokens we're",
      "offset": 2844.88,
      "duration": 3.239
    },
    {
      "lang": "en",
      "text": "going to be gener rating so let's just",
      "offset": 2846.359,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "decrease this to be a bit less just so",
      "offset": 2848.119,
      "duration": 4.041
    },
    {
      "lang": "en",
      "text": "we don't waste compute we just want the",
      "offset": 2850.04,
      "duration": 4.68
    },
    {
      "lang": "en",
      "text": "next 128 tokens and leave the other",
      "offset": 2852.16,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "stuff alone I'm not going to go into the",
      "offset": 2854.72,
      "duration": 4.28
    },
    {
      "lang": "en",
      "text": "full detail here um now fundamentally",
      "offset": 2856,
      "duration": 5.559
    },
    {
      "lang": "en",
      "text": "what's going to happen here is identical",
      "offset": 2859,
      "duration": 4.2
    },
    {
      "lang": "en",
      "text": "to what happens here during inference",
      "offset": 2861.559,
      "duration": 3.881
    },
    {
      "lang": "en",
      "text": "for us so this is just going to continue",
      "offset": 2863.2,
      "duration": 3.96
    },
    {
      "lang": "en",
      "text": "the token sequence of whatever you",
      "offset": 2865.44,
      "duration": 4.36
    },
    {
      "lang": "en",
      "text": "prefix you're going to give it so I want",
      "offset": 2867.16,
      "duration": 4.679
    },
    {
      "lang": "en",
      "text": "to first show you that this model here",
      "offset": 2869.8,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "is not yet an assistant so you can for",
      "offset": 2871.839,
      "duration": 4.361
    },
    {
      "lang": "en",
      "text": "example ask it what is 2 plus 2 it's not",
      "offset": 2873.88,
      "duration": 4.36
    },
    {
      "lang": "en",
      "text": "going to tell you oh it's four uh what",
      "offset": 2876.2,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "else can I help you with it's not going",
      "offset": 2878.24,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "to do that because what is 2 plus 2 is",
      "offset": 2879.72,
      "duration": 5.599
    },
    {
      "lang": "en",
      "text": "going to be tokenized and then those",
      "offset": 2882.64,
      "duration": 5.24
    },
    {
      "lang": "en",
      "text": "tokens just act as a prefix and then",
      "offset": 2885.319,
      "duration": 3.8
    },
    {
      "lang": "en",
      "text": "what the model is going to do now is",
      "offset": 2887.88,
      "duration": 2.4
    },
    {
      "lang": "en",
      "text": "just going to get the probability for",
      "offset": 2889.119,
      "duration": 3.161
    },
    {
      "lang": "en",
      "text": "the next token and it's just a glorified",
      "offset": 2890.28,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "autocomplete it's a very very expensive",
      "offset": 2892.28,
      "duration": 5.16
    },
    {
      "lang": "en",
      "text": "autocomplete of what comes next um",
      "offset": 2894.52,
      "duration": 4.44
    },
    {
      "lang": "en",
      "text": "depending on the statistics of what it",
      "offset": 2897.44,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "saw in its training documents which are",
      "offset": 2898.96,
      "duration": 3.08
    },
    {
      "lang": "en",
      "text": "basically web",
      "offset": 2900.8,
      "duration": 4.44
    },
    {
      "lang": "en",
      "text": "pages so let's just uh hit enter to see",
      "offset": 2902.04,
      "duration": 6.72
    },
    {
      "lang": "en",
      "text": "what tokens it comes up with as a",
      "offset": 2905.24,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "continuation okay so here it kind of",
      "offset": 2911.04,
      "duration": 3.039
    },
    {
      "lang": "en",
      "text": "actually answered the question and",
      "offset": 2912.92,
      "duration": 2.24
    },
    {
      "lang": "en",
      "text": "started to go off into some",
      "offset": 2914.079,
      "duration": 3.641
    },
    {
      "lang": "en",
      "text": "philosophical territory uh let's try it",
      "offset": 2915.16,
      "duration": 4.52
    },
    {
      "lang": "en",
      "text": "again so let me copy and paste and let's",
      "offset": 2917.72,
      "duration": 6.52
    },
    {
      "lang": "en",
      "text": "try again from scratch what is 2 plus",
      "offset": 2919.68,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "two so okay so it just goes off again so",
      "offset": 2925.64,
      "duration": 5.159
    },
    {
      "lang": "en",
      "text": "notice one more thing that I want to",
      "offset": 2929.559,
      "duration": 4.121
    },
    {
      "lang": "en",
      "text": "stress is that the system uh I think",
      "offset": 2930.799,
      "duration": 4.52
    },
    {
      "lang": "en",
      "text": "every time you put it in it just kind of",
      "offset": 2933.68,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "starts from scratch",
      "offset": 2935.319,
      "duration": 4.361
    },
    {
      "lang": "en",
      "text": "so it doesn't uh the system here is",
      "offset": 2938.16,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "stochastic so for the same prefix of",
      "offset": 2939.68,
      "duration": 4.36
    },
    {
      "lang": "en",
      "text": "tokens we're always getting a different",
      "offset": 2942.4,
      "duration": 4.12
    },
    {
      "lang": "en",
      "text": "answer and the reason for that is that",
      "offset": 2944.04,
      "duration": 4.559
    },
    {
      "lang": "en",
      "text": "we get this probity distribution and we",
      "offset": 2946.52,
      "duration": 3.88
    },
    {
      "lang": "en",
      "text": "sample from it and we always get",
      "offset": 2948.599,
      "duration": 3.281
    },
    {
      "lang": "en",
      "text": "different samples and we sort of always",
      "offset": 2950.4,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "go into a different territory uh",
      "offset": 2951.88,
      "duration": 6.08
    },
    {
      "lang": "en",
      "text": "afterwards so here in this case um I",
      "offset": 2953.92,
      "duration": 5.48
    },
    {
      "lang": "en",
      "text": "don't know what this is let's try one",
      "offset": 2957.96,
      "duration": 3.599
    },
    {
      "lang": "en",
      "text": "more",
      "offset": 2959.4,
      "duration": 2.159
    },
    {
      "lang": "en",
      "text": "time so it just continues on so it's",
      "offset": 2962.96,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "just doing the stuff that it's saw on",
      "offset": 2965.359,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "the internet right um and it's just kind",
      "offset": 2966.48,
      "duration": 4.52
    },
    {
      "lang": "en",
      "text": "of like regurgitating those uh",
      "offset": 2969.2,
      "duration": 3.56
    },
    {
      "lang": "en",
      "text": "statistical",
      "offset": 2971,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "patterns so first things it's not an",
      "offset": 2972.76,
      "duration": 6.16
    },
    {
      "lang": "en",
      "text": "assistant yet it's a token autocomplete",
      "offset": 2975.72,
      "duration": 6.52
    },
    {
      "lang": "en",
      "text": "and second it is a stochastic system now",
      "offset": 2978.92,
      "duration": 5.399
    },
    {
      "lang": "en",
      "text": "the crucial thing is that even though",
      "offset": 2982.24,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "this model is not yet by itself very",
      "offset": 2984.319,
      "duration": 4.681
    },
    {
      "lang": "en",
      "text": "useful for a lot of applications just",
      "offset": 2986.4,
      "duration": 6.32
    },
    {
      "lang": "en",
      "text": "yet um it is still very useful because",
      "offset": 2989,
      "duration": 5.359
    },
    {
      "lang": "en",
      "text": "in the task of predicting the next token",
      "offset": 2992.72,
      "duration": 4.119
    },
    {
      "lang": "en",
      "text": "in the sequence the model has learned a",
      "offset": 2994.359,
      "duration": 5.041
    },
    {
      "lang": "en",
      "text": "lot about the world and it has stored",
      "offset": 2996.839,
      "duration": 4.361
    },
    {
      "lang": "en",
      "text": "all that knowledge in the parameters of",
      "offset": 2999.4,
      "duration": 4.919
    },
    {
      "lang": "en",
      "text": "the network so remember that our text",
      "offset": 3001.2,
      "duration": 5
    },
    {
      "lang": "en",
      "text": "looked like this right internet web",
      "offset": 3004.319,
      "duration": 4.641
    },
    {
      "lang": "en",
      "text": "pages and now all of this is sort of",
      "offset": 3006.2,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "compressed in the weights of the network",
      "offset": 3008.96,
      "duration": 6.119
    },
    {
      "lang": "en",
      "text": "so you can think of um these 405 billion",
      "offset": 3011.4,
      "duration": 5.439
    },
    {
      "lang": "en",
      "text": "parameters is a kind of compression of",
      "offset": 3015.079,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "the internet you can think of the",
      "offset": 3016.839,
      "duration": 4.841
    },
    {
      "lang": "en",
      "text": "45 billion parameters is kind of like a",
      "offset": 3019.24,
      "duration": 5.839
    },
    {
      "lang": "en",
      "text": "zip file uh but it's not a loss less",
      "offset": 3021.68,
      "duration": 5.48
    },
    {
      "lang": "en",
      "text": "compression it's a loss C compression",
      "offset": 3025.079,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "we're kind of like left with kind of a",
      "offset": 3027.16,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "gal of the internet and we can generate",
      "offset": 3028.76,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "from it right now we can elicit some of",
      "offset": 3031.079,
      "duration": 4.801
    },
    {
      "lang": "en",
      "text": "this knowledge by prompting the base",
      "offset": 3034.04,
      "duration": 4.36
    },
    {
      "lang": "en",
      "text": "model uh accordingly so for example",
      "offset": 3035.88,
      "duration": 4.439
    },
    {
      "lang": "en",
      "text": "here's a prompt that might work to",
      "offset": 3038.4,
      "duration": 3.24
    },
    {
      "lang": "en",
      "text": "elicit some of that knowledge that's",
      "offset": 3040.319,
      "duration": 3.641
    },
    {
      "lang": "en",
      "text": "hiding in the parameters here's my top",
      "offset": 3041.64,
      "duration": 4.479
    },
    {
      "lang": "en",
      "text": "10 list of the top landmarks to see in",
      "offset": 3043.96,
      "duration": 4.04
    },
    {
      "lang": "en",
      "text": "the",
      "offset": 3046.119,
      "duration": 3.96
    },
    {
      "lang": "en",
      "text": "pairs",
      "offset": 3048,
      "duration": 4.52
    },
    {
      "lang": "en",
      "text": "um and I'm doing it this way because I'm",
      "offset": 3050.079,
      "duration": 4.28
    },
    {
      "lang": "en",
      "text": "trying to Prime the model to now",
      "offset": 3052.52,
      "duration": 3.559
    },
    {
      "lang": "en",
      "text": "continue this list so let's see if that",
      "offset": 3054.359,
      "duration": 3.121
    },
    {
      "lang": "en",
      "text": "works when I press",
      "offset": 3056.079,
      "duration": 4.561
    },
    {
      "lang": "en",
      "text": "enter okay so you see that it started a",
      "offset": 3057.48,
      "duration": 4.76
    },
    {
      "lang": "en",
      "text": "list and it's now kind of giving me some",
      "offset": 3060.64,
      "duration": 2.6
    },
    {
      "lang": "en",
      "text": "of those",
      "offset": 3062.24,
      "duration": 2.839
    },
    {
      "lang": "en",
      "text": "landmarks and now notice that it's",
      "offset": 3063.24,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "trying to give a lot of information here",
      "offset": 3065.079,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "now you might not be able to actually",
      "offset": 3067,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "fully trust some of the information here",
      "offset": 3069.16,
      "duration": 3.08
    },
    {
      "lang": "en",
      "text": "remember that this is all just a",
      "offset": 3070.92,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "recollection of some of the internet",
      "offset": 3072.24,
      "duration": 4.839
    },
    {
      "lang": "en",
      "text": "documents and so the things that occur",
      "offset": 3074.44,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "very frequently in the internet data are",
      "offset": 3077.079,
      "duration": 4.28
    },
    {
      "lang": "en",
      "text": "probably more likely to be remembered",
      "offset": 3079.48,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "correctly compared to things that happen",
      "offset": 3081.359,
      "duration": 4.2
    },
    {
      "lang": "en",
      "text": "very infrequently so you can't fully",
      "offset": 3083.48,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "trust some of the things that and some",
      "offset": 3085.559,
      "duration": 2.841
    },
    {
      "lang": "en",
      "text": "of the information that is here because",
      "offset": 3087.24,
      "duration": 3.079
    },
    {
      "lang": "en",
      "text": "it's all just a vague recollection of",
      "offset": 3088.4,
      "duration": 4.36
    },
    {
      "lang": "en",
      "text": "Internet documents because the",
      "offset": 3090.319,
      "duration": 4.561
    },
    {
      "lang": "en",
      "text": "information is not stored explicitly in",
      "offset": 3092.76,
      "duration": 4.12
    },
    {
      "lang": "en",
      "text": "any of the parameters it's all just the",
      "offset": 3094.88,
      "duration": 3.719
    },
    {
      "lang": "en",
      "text": "recollection that said we did get",
      "offset": 3096.88,
      "duration": 3.439
    },
    {
      "lang": "en",
      "text": "something that is probably approximately",
      "offset": 3098.599,
      "duration": 3.72
    },
    {
      "lang": "en",
      "text": "correct and I don't actually have the",
      "offset": 3100.319,
      "duration": 3.721
    },
    {
      "lang": "en",
      "text": "expertise to verify that this is roughly",
      "offset": 3102.319,
      "duration": 4.04
    },
    {
      "lang": "en",
      "text": "correct but you see that we've elicited",
      "offset": 3104.04,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "a lot of the knowledge of the model and",
      "offset": 3106.359,
      "duration": 5
    },
    {
      "lang": "en",
      "text": "this knowledge is not precise and exact",
      "offset": 3108.92,
      "duration": 4.76
    },
    {
      "lang": "en",
      "text": "this knowledge is vague and",
      "offset": 3111.359,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "probabilistic and statistical and the",
      "offset": 3113.68,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "kinds of things that occur often are the",
      "offset": 3115.76,
      "duration": 3.319
    },
    {
      "lang": "en",
      "text": "kinds of things that are more likely to",
      "offset": 3117.839,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "be remembered um in the model now I want",
      "offset": 3119.079,
      "duration": 4.961
    },
    {
      "lang": "en",
      "text": "to show you a few more examples of this",
      "offset": 3122.559,
      "duration": 3.401
    },
    {
      "lang": "en",
      "text": "model's Behavior the first thing I want",
      "offset": 3124.04,
      "duration": 4.36
    },
    {
      "lang": "en",
      "text": "to show you is this example I went to",
      "offset": 3125.96,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "the Wikipedia page for zebra and let me",
      "offset": 3128.4,
      "duration": 5.08
    },
    {
      "lang": "en",
      "text": "just copy paste the first uh even one",
      "offset": 3130.68,
      "duration": 3.879
    },
    {
      "lang": "en",
      "text": "sentence",
      "offset": 3133.48,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "here and let me put it here now when I",
      "offset": 3134.559,
      "duration": 5.361
    },
    {
      "lang": "en",
      "text": "click enter what kind of uh completion",
      "offset": 3137.559,
      "duration": 5.881
    },
    {
      "lang": "en",
      "text": "are we going to get so let me just hit",
      "offset": 3139.92,
      "duration": 7.04
    },
    {
      "lang": "en",
      "text": "enter there are three living species",
      "offset": 3143.44,
      "duration": 6.24
    },
    {
      "lang": "en",
      "text": "etc etc what the model is producing here",
      "offset": 3146.96,
      "duration": 4.68
    },
    {
      "lang": "en",
      "text": "is an exact regurgitation of this",
      "offset": 3149.68,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "Wikipedia entry it is reciting this",
      "offset": 3151.64,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "Wikipedia entry purely from memory and",
      "offset": 3153.76,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "this memory is stored in its parameters",
      "offset": 3156.44,
      "duration": 4.919
    },
    {
      "lang": "en",
      "text": "and so it is possible that at some point",
      "offset": 3159.2,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "in these 512 tokens the model will uh",
      "offset": 3161.359,
      "duration": 5.081
    },
    {
      "lang": "en",
      "text": "stray away from the Wikipedia entry but",
      "offset": 3164.24,
      "duration": 3.72
    },
    {
      "lang": "en",
      "text": "you can see that it has huge chunks of",
      "offset": 3166.44,
      "duration": 3.639
    },
    {
      "lang": "en",
      "text": "it memorized here uh let me see for",
      "offset": 3167.96,
      "duration": 3.72
    },
    {
      "lang": "en",
      "text": "example if this sentence",
      "offset": 3170.079,
      "duration": 5.201
    },
    {
      "lang": "en",
      "text": "occurs by now okay so this so we're",
      "offset": 3171.68,
      "duration": 6.919
    },
    {
      "lang": "en",
      "text": "still on track let me check",
      "offset": 3175.28,
      "duration": 5.519
    },
    {
      "lang": "en",
      "text": "here okay we're still on",
      "offset": 3178.599,
      "duration": 5.881
    },
    {
      "lang": "en",
      "text": "track it will eventually uh stray",
      "offset": 3180.799,
      "duration": 6.241
    },
    {
      "lang": "en",
      "text": "away okay so this thing is just recited",
      "offset": 3184.48,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "to a very large extent it will",
      "offset": 3187.04,
      "duration": 4.12
    },
    {
      "lang": "en",
      "text": "eventually deviate uh because it won't",
      "offset": 3188.799,
      "duration": 4.28
    },
    {
      "lang": "en",
      "text": "be able to remember exactly now the",
      "offset": 3191.16,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "reason that this happens is because",
      "offset": 3193.079,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "these models can be extremely good at",
      "offset": 3194.52,
      "duration": 4.12
    },
    {
      "lang": "en",
      "text": "memorization and usually this is not",
      "offset": 3196.599,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "what you want in the final model and",
      "offset": 3198.64,
      "duration": 3.24
    },
    {
      "lang": "en",
      "text": "this is something called regurgitation",
      "offset": 3200.28,
      "duration": 4.559
    },
    {
      "lang": "en",
      "text": "and it's usually undesirable to site uh",
      "offset": 3201.88,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "things uh directly uh that you have",
      "offset": 3204.839,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "trained on now the reason that this",
      "offset": 3206.76,
      "duration": 4.799
    },
    {
      "lang": "en",
      "text": "happens actually is because for a lot of",
      "offset": 3209.24,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "documents like for example Wikipedia",
      "offset": 3211.559,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "when these documents are deemed to be of",
      "offset": 3213.4,
      "duration": 3.719
    },
    {
      "lang": "en",
      "text": "very high quality as a source like for",
      "offset": 3215.24,
      "duration": 4.92
    },
    {
      "lang": "en",
      "text": "example Wikipedia it is very often uh",
      "offset": 3217.119,
      "duration": 4.881
    },
    {
      "lang": "en",
      "text": "the case that when you train the model",
      "offset": 3220.16,
      "duration": 4.12
    },
    {
      "lang": "en",
      "text": "you will preferentially sample from",
      "offset": 3222,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "those sources so basically the model has",
      "offset": 3224.28,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "probably done a few epochs on this data",
      "offset": 3226.48,
      "duration": 4.119
    },
    {
      "lang": "en",
      "text": "meaning that it has seen this web page",
      "offset": 3228.68,
      "duration": 4.119
    },
    {
      "lang": "en",
      "text": "like maybe probably 10 times or so and",
      "offset": 3230.599,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "it's a bit like you like when you read",
      "offset": 3232.799,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "some kind of a text many many times say",
      "offset": 3234.28,
      "duration": 4.279
    },
    {
      "lang": "en",
      "text": "you read something a 100 times uh then",
      "offset": 3236.559,
      "duration": 3.721
    },
    {
      "lang": "en",
      "text": "you'll be able to recite it and it's",
      "offset": 3238.559,
      "duration": 3.24
    },
    {
      "lang": "en",
      "text": "very similar for this model if it sees",
      "offset": 3240.28,
      "duration": 2.96
    },
    {
      "lang": "en",
      "text": "something way too often it's going to be",
      "offset": 3241.799,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "able to recite it later from memory",
      "offset": 3243.24,
      "duration": 4.599
    },
    {
      "lang": "en",
      "text": "except these models can be a lot more",
      "offset": 3245.96,
      "duration": 4.599
    },
    {
      "lang": "en",
      "text": "efficient um like per presentation than",
      "offset": 3247.839,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "human so probably it's only seen this",
      "offset": 3250.559,
      "duration": 3.481
    },
    {
      "lang": "en",
      "text": "Wikipedia entry 10 times but basically",
      "offset": 3252.319,
      "duration": 4.04
    },
    {
      "lang": "en",
      "text": "it has remembered this article exactly",
      "offset": 3254.04,
      "duration": 4.279
    },
    {
      "lang": "en",
      "text": "in its parameters okay the next thing I",
      "offset": 3256.359,
      "duration": 3.041
    },
    {
      "lang": "en",
      "text": "want to show you is something that the",
      "offset": 3258.319,
      "duration": 3.201
    },
    {
      "lang": "en",
      "text": "model has definitely not seen during its",
      "offset": 3259.4,
      "duration": 5
    },
    {
      "lang": "en",
      "text": "training so for example if we go to the",
      "offset": 3261.52,
      "duration": 5.16
    },
    {
      "lang": "en",
      "text": "paper uh and then we navigate to the",
      "offset": 3264.4,
      "duration": 6.8
    },
    {
      "lang": "en",
      "text": "pre-training data we'll see here that uh",
      "offset": 3266.68,
      "duration": 6.639
    },
    {
      "lang": "en",
      "text": "the data set has a knowledge cut off",
      "offset": 3271.2,
      "duration": 4.68
    },
    {
      "lang": "en",
      "text": "until the end of 2023 so it will not",
      "offset": 3273.319,
      "duration": 5.201
    },
    {
      "lang": "en",
      "text": "have seen documents after this point and",
      "offset": 3275.88,
      "duration": 4.04
    },
    {
      "lang": "en",
      "text": "certainly it has not seen anything about",
      "offset": 3278.52,
      "duration": 4.52
    },
    {
      "lang": "en",
      "text": "the 2024 election and how it turned out",
      "offset": 3279.92,
      "duration": 6.159
    },
    {
      "lang": "en",
      "text": "now if we Prime the model with the",
      "offset": 3283.04,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "tokens from the future it will continue",
      "offset": 3286.079,
      "duration": 4.52
    },
    {
      "lang": "en",
      "text": "the token sequence and it will just take",
      "offset": 3289.04,
      "duration": 2.84
    },
    {
      "lang": "en",
      "text": "its best guess according to the",
      "offset": 3290.599,
      "duration": 2.76
    },
    {
      "lang": "en",
      "text": "knowledge that it has in its own",
      "offset": 3291.88,
      "duration": 3.239
    },
    {
      "lang": "en",
      "text": "parameters so let's take a look at what",
      "offset": 3293.359,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "that could look like",
      "offset": 3295.119,
      "duration": 4.601
    },
    {
      "lang": "en",
      "text": "so the Republican Party kit",
      "offset": 3297.04,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "Trump okay president of the United",
      "offset": 3299.72,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "States from",
      "offset": 3301.92,
      "duration": 3.24
    },
    {
      "lang": "en",
      "text": "2017 and let's see what it says after",
      "offset": 3302.92,
      "duration": 4.28
    },
    {
      "lang": "en",
      "text": "this point so for example the model will",
      "offset": 3305.16,
      "duration": 4.28
    },
    {
      "lang": "en",
      "text": "have to guess at the running mate and",
      "offset": 3307.2,
      "duration": 4.52
    },
    {
      "lang": "en",
      "text": "who it's against Etc so let's hit",
      "offset": 3309.44,
      "duration": 4.6
    },
    {
      "lang": "en",
      "text": "enter so here thingss that Mike Pence",
      "offset": 3311.72,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "was the running mate instead of JD Vance",
      "offset": 3314.04,
      "duration": 6.72
    },
    {
      "lang": "en",
      "text": "and the ticket was against Hillary",
      "offset": 3317.4,
      "duration": 5.88
    },
    {
      "lang": "en",
      "text": "Clinton and Tim Kane so this is kind of",
      "offset": 3320.76,
      "duration": 4.44
    },
    {
      "lang": "en",
      "text": "a interesting parallel universe",
      "offset": 3323.28,
      "duration": 3.039
    },
    {
      "lang": "en",
      "text": "potentially of what could have happened",
      "offset": 3325.2,
      "duration": 3.56
    },
    {
      "lang": "en",
      "text": "happened according to the LM let's get a",
      "offset": 3326.319,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "different sample so the identical prompt",
      "offset": 3328.76,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "and let's",
      "offset": 3331.039,
      "duration": 4.441
    },
    {
      "lang": "en",
      "text": "resample so here the running mate was",
      "offset": 3333.48,
      "duration": 4.599
    },
    {
      "lang": "en",
      "text": "Ronda santis and they ran against Joe",
      "offset": 3335.48,
      "duration": 5.24
    },
    {
      "lang": "en",
      "text": "Biden and Camala Harris so this is again",
      "offset": 3338.079,
      "duration": 4.52
    },
    {
      "lang": "en",
      "text": "a different parallel universe so the",
      "offset": 3340.72,
      "duration": 3.48
    },
    {
      "lang": "en",
      "text": "model will take educated guesses and it",
      "offset": 3342.599,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "will continue the token sequence based",
      "offset": 3344.2,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "on this knowledge um and it will just",
      "offset": 3345.799,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "kind of like all of what we're seeing",
      "offset": 3348.2,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "here is what's called hallucination the",
      "offset": 3349.72,
      "duration": 5.079
    },
    {
      "lang": "en",
      "text": "model is just taking its best guess uh",
      "offset": 3351.96,
      "duration": 4.92
    },
    {
      "lang": "en",
      "text": "in a probalistic manner the next thing I",
      "offset": 3354.799,
      "duration": 3.401
    },
    {
      "lang": "en",
      "text": "would like to show you is that even",
      "offset": 3356.88,
      "duration": 3.199
    },
    {
      "lang": "en",
      "text": "though this is a base model and not yet",
      "offset": 3358.2,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "an assistant model it can still be",
      "offset": 3360.079,
      "duration": 4.121
    },
    {
      "lang": "en",
      "text": "utilized in Practical applications if",
      "offset": 3362.039,
      "duration": 4.601
    },
    {
      "lang": "en",
      "text": "you are clever with your prompt design",
      "offset": 3364.2,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "so here's something that we would call a",
      "offset": 3366.64,
      "duration": 2.84
    },
    {
      "lang": "en",
      "text": "few shot",
      "offset": 3368.359,
      "duration": 3.96
    },
    {
      "lang": "en",
      "text": "prompt so what it is here is that I have",
      "offset": 3369.48,
      "duration": 6.96
    },
    {
      "lang": "en",
      "text": "10 words or 10 pairs and each pair is a",
      "offset": 3372.319,
      "duration": 7.48
    },
    {
      "lang": "en",
      "text": "word of English column and then a the",
      "offset": 3376.44,
      "duration": 6.24
    },
    {
      "lang": "en",
      "text": "translation in Korean and we have 10 of",
      "offset": 3379.799,
      "duration": 5.641
    },
    {
      "lang": "en",
      "text": "them and what the model does here is at",
      "offset": 3382.68,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "the end we have teacher column and then",
      "offset": 3385.44,
      "duration": 2.919
    },
    {
      "lang": "en",
      "text": "here's where we're going to do a",
      "offset": 3387.48,
      "duration": 4.28
    },
    {
      "lang": "en",
      "text": "completion of say just five tokens and",
      "offset": 3388.359,
      "duration": 5.081
    },
    {
      "lang": "en",
      "text": "these models have what we call in",
      "offset": 3391.76,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "context learning abilities and what",
      "offset": 3393.44,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "that's referring to is that as it is",
      "offset": 3395.76,
      "duration": 4.68
    },
    {
      "lang": "en",
      "text": "reading this context it is learning sort",
      "offset": 3397.44,
      "duration": 4.359
    },
    {
      "lang": "en",
      "text": "of in",
      "offset": 3400.44,
      "duration": 3.359
    },
    {
      "lang": "en",
      "text": "place that there's some kind of a",
      "offset": 3401.799,
      "duration": 4.681
    },
    {
      "lang": "en",
      "text": "algorithmic pattern going on in my data",
      "offset": 3403.799,
      "duration": 5
    },
    {
      "lang": "en",
      "text": "and it knows to continue that pattern",
      "offset": 3406.48,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "and this is called kind of like Inc",
      "offset": 3408.799,
      "duration": 4.441
    },
    {
      "lang": "en",
      "text": "context learning so it takes on the role",
      "offset": 3410.16,
      "duration": 4.639
    },
    {
      "lang": "en",
      "text": "of a",
      "offset": 3413.24,
      "duration": 4.839
    },
    {
      "lang": "en",
      "text": "translator and when we hit uh completion",
      "offset": 3414.799,
      "duration": 5.081
    },
    {
      "lang": "en",
      "text": "we see that the teacher translation is",
      "offset": 3418.079,
      "duration": 5.24
    },
    {
      "lang": "en",
      "text": "Sim which is correct um and so this is",
      "offset": 3419.88,
      "duration": 5.159
    },
    {
      "lang": "en",
      "text": "how you can build apps by being clever",
      "offset": 3423.319,
      "duration": 3.401
    },
    {
      "lang": "en",
      "text": "with your prompting even though we still",
      "offset": 3425.039,
      "duration": 3.56
    },
    {
      "lang": "en",
      "text": "just have a base model for now and it",
      "offset": 3426.72,
      "duration": 4.839
    },
    {
      "lang": "en",
      "text": "relies on what we call this um uh in",
      "offset": 3428.599,
      "duration": 5.601
    },
    {
      "lang": "en",
      "text": "context learning ability and it is done",
      "offset": 3431.559,
      "duration": 4.361
    },
    {
      "lang": "en",
      "text": "by constructing what's called a few shot",
      "offset": 3434.2,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "prompt okay and finally I want to show",
      "offset": 3435.92,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "you that there is a clever way to",
      "offset": 3437.96,
      "duration": 3.639
    },
    {
      "lang": "en",
      "text": "actually instantiate a whole language",
      "offset": 3439.44,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "model assistant just by prompting and",
      "offset": 3441.599,
      "duration": 5.041
    },
    {
      "lang": "en",
      "text": "the trick to it is that we're structure",
      "offset": 3444.96,
      "duration": 4.52
    },
    {
      "lang": "en",
      "text": "a prompt to look like a web page that is",
      "offset": 3446.64,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "a conversation between a helpful AI",
      "offset": 3449.48,
      "duration": 4.76
    },
    {
      "lang": "en",
      "text": "assistant and a human and then the model",
      "offset": 3451.92,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "will continue that conversation so",
      "offset": 3454.24,
      "duration": 4.359
    },
    {
      "lang": "en",
      "text": "actually to write the prompt I turned to",
      "offset": 3456.64,
      "duration": 4.919
    },
    {
      "lang": "en",
      "text": "chat gbt itself which is kind of meta",
      "offset": 3458.599,
      "duration": 5.041
    },
    {
      "lang": "en",
      "text": "but I told it I want to create an llm",
      "offset": 3461.559,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "assistant but all I have is the base",
      "offset": 3463.64,
      "duration": 6.479
    },
    {
      "lang": "en",
      "text": "model so can you please write my um uh",
      "offset": 3465.24,
      "duration": 7.079
    },
    {
      "lang": "en",
      "text": "prompt and this is what it came up with",
      "offset": 3470.119,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "which is actually quite good so here's a",
      "offset": 3472.319,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "conversation between an AI assistant and",
      "offset": 3474.28,
      "duration": 2.36
    },
    {
      "lang": "en",
      "text": "a human",
      "offset": 3475.839,
      "duration": 2.24
    },
    {
      "lang": "en",
      "text": "the AI assistant is knowledgeable",
      "offset": 3476.64,
      "duration": 2.959
    },
    {
      "lang": "en",
      "text": "helpful capable of answering wide",
      "offset": 3478.079,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "variety of questions Etc and then here",
      "offset": 3479.599,
      "duration": 5.681
    },
    {
      "lang": "en",
      "text": "it's not enough to just give it a sort",
      "offset": 3483.359,
      "duration": 4.281
    },
    {
      "lang": "en",
      "text": "of description it works much better if",
      "offset": 3485.28,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "you create this fot prompt so here's a",
      "offset": 3487.64,
      "duration": 5.399
    },
    {
      "lang": "en",
      "text": "few terms of human assistant human",
      "offset": 3490,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "assistant and we have uh you know a few",
      "offset": 3493.039,
      "duration": 4.921
    },
    {
      "lang": "en",
      "text": "turns of conversation and then here at",
      "offset": 3495.76,
      "duration": 3.359
    },
    {
      "lang": "en",
      "text": "the end is we're going to be putting the",
      "offset": 3497.96,
      "duration": 3.72
    },
    {
      "lang": "en",
      "text": "actual query that we like so let me copy",
      "offset": 3499.119,
      "duration": 6.161
    },
    {
      "lang": "en",
      "text": "paste this into the base model prompt",
      "offset": 3501.68,
      "duration": 7.119
    },
    {
      "lang": "en",
      "text": "and now let me do human column and this",
      "offset": 3505.28,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "is where we put our actual prompt why is",
      "offset": 3508.799,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "the sky",
      "offset": 3511.28,
      "duration": 5.839
    },
    {
      "lang": "en",
      "text": "blue and uh let's uh",
      "offset": 3512.799,
      "duration": 7.24
    },
    {
      "lang": "en",
      "text": "run assistant the sky appears blue due",
      "offset": 3517.119,
      "duration": 4.44
    },
    {
      "lang": "en",
      "text": "to the phenomenon called R lights",
      "offset": 3520.039,
      "duration": 3.961
    },
    {
      "lang": "en",
      "text": "scattering etc etc so you see that the",
      "offset": 3521.559,
      "duration": 3.721
    },
    {
      "lang": "en",
      "text": "base model is just continuing the",
      "offset": 3524,
      "duration": 3.599
    },
    {
      "lang": "en",
      "text": "sequence but because the sequence looks",
      "offset": 3525.28,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "like this conversation it takes on that",
      "offset": 3527.599,
      "duration": 4.76
    },
    {
      "lang": "en",
      "text": "role but it is a little subtle because",
      "offset": 3529.92,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "here it just uh you know it ends the",
      "offset": 3532.359,
      "duration": 3.321
    },
    {
      "lang": "en",
      "text": "assistant and then just you know",
      "offset": 3534.48,
      "duration": 2.639
    },
    {
      "lang": "en",
      "text": "hallucinate Ates the next question by",
      "offset": 3535.68,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "the human Etc so it'll just continue",
      "offset": 3537.119,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "going on and on uh but you can see that",
      "offset": 3538.72,
      "duration": 5.16
    },
    {
      "lang": "en",
      "text": "we have sort of accomplished the task",
      "offset": 3541.28,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "and if you just took this why is the sky",
      "offset": 3543.88,
      "duration": 5.439
    },
    {
      "lang": "en",
      "text": "blue and if we just refresh this and put",
      "offset": 3546.16,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "it here then of course we don't expect",
      "offset": 3549.319,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "this to work with a base model right",
      "offset": 3550.96,
      "duration": 3.159
    },
    {
      "lang": "en",
      "text": "we're just going to who knows what we're",
      "offset": 3552.359,
      "duration": 3
    },
    {
      "lang": "en",
      "text": "going to get okay we're just going to",
      "offset": 3554.119,
      "duration": 2.24
    },
    {
      "lang": "en",
      "text": "get more",
      "offset": 3555.359,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "questions okay so this is one way to",
      "offset": 3556.359,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "create an assistant even though you may",
      "offset": 3559.359,
      "duration": 4.641
    },
    {
      "lang": "en",
      "text": "only have a base model okay so this is",
      "offset": 3561.559,
      "duration": 4.721
    },
    {
      "lang": "en",
      "text": "the kind of brief summary of the things",
      "offset": 3564,
      "duration": 4.52
    },
    {
      "lang": "en",
      "text": "we talked about over the last few",
      "offset": 3566.28,
      "duration": 6.44
    },
    {
      "lang": "en",
      "text": "minutes now let me zoom out",
      "offset": 3568.52,
      "duration": 6.279
    },
    {
      "lang": "en",
      "text": "here and this is kind of like what we've",
      "offset": 3572.72,
      "duration": 4.92
    },
    {
      "lang": "en",
      "text": "talked about so far we wish to train LM",
      "offset": 3574.799,
      "duration": 5.921
    },
    {
      "lang": "en",
      "text": "assistants like chpt we've discussed the",
      "offset": 3577.64,
      "duration": 4.6
    },
    {
      "lang": "en",
      "text": "first stage of that which is the",
      "offset": 3580.72,
      "duration": 3.319
    },
    {
      "lang": "en",
      "text": "pre-training stage and we saw that",
      "offset": 3582.24,
      "duration": 3.119
    },
    {
      "lang": "en",
      "text": "really what it comes down to is we take",
      "offset": 3584.039,
      "duration": 3.32
    },
    {
      "lang": "en",
      "text": "Internet documents we break them up into",
      "offset": 3585.359,
      "duration": 4.041
    },
    {
      "lang": "en",
      "text": "these tokens these atoms of little text",
      "offset": 3587.359,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "chunks and then we predict token",
      "offset": 3589.4,
      "duration": 4.84
    },
    {
      "lang": "en",
      "text": "sequences using neural networks the",
      "offset": 3591.44,
      "duration": 5.24
    },
    {
      "lang": "en",
      "text": "output of this entire stage is this base",
      "offset": 3594.24,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "model it is the setting of The",
      "offset": 3596.68,
      "duration": 4.879
    },
    {
      "lang": "en",
      "text": "parameters of this network and this base",
      "offset": 3598.319,
      "duration": 4.961
    },
    {
      "lang": "en",
      "text": "model is basically an internet document",
      "offset": 3601.559,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "simulator on the token level so it can",
      "offset": 3603.28,
      "duration": 5.16
    },
    {
      "lang": "en",
      "text": "just uh it can generate token sequences",
      "offset": 3605.72,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "that have the same kind of like",
      "offset": 3608.44,
      "duration": 4.28
    },
    {
      "lang": "en",
      "text": "statistics as Internet documents and we",
      "offset": 3610.039,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "saw that we can use it in some",
      "offset": 3612.72,
      "duration": 2.48
    },
    {
      "lang": "en",
      "text": "applications but we actually need to do",
      "offset": 3613.72,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "better we want an assistant we want to",
      "offset": 3615.2,
      "duration": 3.599
    },
    {
      "lang": "en",
      "text": "be able to ask questions and we want the",
      "offset": 3617.24,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "model to give us answers and so we need",
      "offset": 3618.799,
      "duration": 4.921
    },
    {
      "lang": "en",
      "text": "to now go into the second stage which is",
      "offset": 3621.24,
      "duration": 5.119
    },
    {
      "lang": "en",
      "text": "called the post-training stage so we",
      "offset": 3623.72,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "take our base model our internet",
      "offset": 3626.359,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "document simulator and hand it off to",
      "offset": 3628.039,
      "duration": 3.881
    },
    {
      "lang": "en",
      "text": "post training so we're now going to",
      "offset": 3629.96,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "discuss a few ways to do what's called",
      "offset": 3631.92,
      "duration": 4.52
    },
    {
      "lang": "en",
      "text": "post training of these models these",
      "offset": 3633.799,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "stages in post training are going to be",
      "offset": 3636.44,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "computationally much less expensive most",
      "offset": 3638.039,
      "duration": 4.28
    },
    {
      "lang": "en",
      "text": "of the computational work all of the",
      "offset": 3640.44,
      "duration": 4.919
    },
    {
      "lang": "en",
      "text": "massive data centers um and all of the",
      "offset": 3642.319,
      "duration": 5.361
    },
    {
      "lang": "en",
      "text": "sort of heavy compute and millions of",
      "offset": 3645.359,
      "duration": 5.161
    },
    {
      "lang": "en",
      "text": "dollars are the pre-training stage but",
      "offset": 3647.68,
      "duration": 5.24
    },
    {
      "lang": "en",
      "text": "now we go into the slightly cheaper but",
      "offset": 3650.52,
      "duration": 4.36
    },
    {
      "lang": "en",
      "text": "still extremely important stage called",
      "offset": 3652.92,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "post trining where we turn this llm",
      "offset": 3654.88,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "model into an assistant so let's take a",
      "offset": 3657.24,
      "duration": 5.079
    },
    {
      "lang": "en",
      "text": "look at how we can get our model to not",
      "offset": 3659.44,
      "duration": 5.32
    },
    {
      "lang": "en",
      "text": "sample internet documents but to give",
      "offset": 3662.319,
      "duration": 5.201
    },
    {
      "lang": "en",
      "text": "answers to questions so in other words",
      "offset": 3664.76,
      "duration": 4.12
    },
    {
      "lang": "en",
      "text": "what we want to do is we want to start",
      "offset": 3667.52,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "thinking about conversations and these",
      "offset": 3668.88,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "are conversations that can be multi-turn",
      "offset": 3670.96,
      "duration": 5
    },
    {
      "lang": "en",
      "text": "so so uh there can be multiple turns and",
      "offset": 3673.039,
      "duration": 4.241
    },
    {
      "lang": "en",
      "text": "they are in the simplest case a",
      "offset": 3675.96,
      "duration": 3.32
    },
    {
      "lang": "en",
      "text": "conversation between a human and an",
      "offset": 3677.28,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "assistant and so for example we can",
      "offset": 3679.28,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "imagine the conversation could look",
      "offset": 3681.2,
      "duration": 2.879
    },
    {
      "lang": "en",
      "text": "something like this when a human says",
      "offset": 3682.4,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "what is 2 plus2 the assistant should re",
      "offset": 3684.079,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "respond with something like 2 plus 2 is",
      "offset": 3685.92,
      "duration": 3.8
    },
    {
      "lang": "en",
      "text": "4 when a human follows up and says what",
      "offset": 3687.359,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "if it was star instead of a plus",
      "offset": 3689.72,
      "duration": 3.16
    },
    {
      "lang": "en",
      "text": "assistant could respond with something",
      "offset": 3691.68,
      "duration": 1.919
    },
    {
      "lang": "en",
      "text": "like",
      "offset": 3692.88,
      "duration": 3.32
    },
    {
      "lang": "en",
      "text": "this um and similar here this is another",
      "offset": 3693.599,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "example showing that the assistant could",
      "offset": 3696.2,
      "duration": 2.879
    },
    {
      "lang": "en",
      "text": "also have some kind of a personality",
      "offset": 3697.52,
      "duration": 4.36
    },
    {
      "lang": "en",
      "text": "here uh that it's kind of like nice and",
      "offset": 3699.079,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "then here in the third example I'm",
      "offset": 3701.88,
      "duration": 3
    },
    {
      "lang": "en",
      "text": "showing that when a human is asking for",
      "offset": 3703.079,
      "duration": 4.121
    },
    {
      "lang": "en",
      "text": "something that we uh don't wish to help",
      "offset": 3704.88,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "with we can produce what's called",
      "offset": 3707.2,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "refusal we can say that we cannot help",
      "offset": 3708.72,
      "duration": 4.599
    },
    {
      "lang": "en",
      "text": "with that so in other words what we want",
      "offset": 3710.64,
      "duration": 4.52
    },
    {
      "lang": "en",
      "text": "to do now is we want to think through",
      "offset": 3713.319,
      "duration": 3.72
    },
    {
      "lang": "en",
      "text": "how in a system should interact with the",
      "offset": 3715.16,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "human and we want to program the",
      "offset": 3717.039,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "assistant and Its Behavior in these",
      "offset": 3719.079,
      "duration": 4.52
    },
    {
      "lang": "en",
      "text": "conversations now because this is neural",
      "offset": 3721.44,
      "duration": 3.399
    },
    {
      "lang": "en",
      "text": "networks we're not going to be",
      "offset": 3723.599,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "programming these explicitly in code",
      "offset": 3724.839,
      "duration": 3.801
    },
    {
      "lang": "en",
      "text": "we're not going to be able to program",
      "offset": 3727.52,
      "duration": 2.92
    },
    {
      "lang": "en",
      "text": "the assistant in that way because this",
      "offset": 3728.64,
      "duration": 3.8
    },
    {
      "lang": "en",
      "text": "is neural networks everything is done",
      "offset": 3730.44,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "through neural network training on data",
      "offset": 3732.44,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "sets and so because of that we are going",
      "offset": 3734.2,
      "duration": 5.24
    },
    {
      "lang": "en",
      "text": "to be implicitly programming the",
      "offset": 3737.48,
      "duration": 4.2
    },
    {
      "lang": "en",
      "text": "assistant by creating data sets of",
      "offset": 3739.44,
      "duration": 4.04
    },
    {
      "lang": "en",
      "text": "conversations so these are three",
      "offset": 3741.68,
      "duration": 3.8
    },
    {
      "lang": "en",
      "text": "independent examples of conversations in",
      "offset": 3743.48,
      "duration": 4.28
    },
    {
      "lang": "en",
      "text": "a data dat set an actual data set and",
      "offset": 3745.48,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "I'm going to show you examples will be",
      "offset": 3747.76,
      "duration": 3.24
    },
    {
      "lang": "en",
      "text": "much larger it could have hundreds of",
      "offset": 3749.319,
      "duration": 3.081
    },
    {
      "lang": "en",
      "text": "thousands of conversations that are",
      "offset": 3751,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "multi- turn very long Etc and would",
      "offset": 3752.4,
      "duration": 4.959
    },
    {
      "lang": "en",
      "text": "cover a diverse breath of topics but",
      "offset": 3754.839,
      "duration": 4.801
    },
    {
      "lang": "en",
      "text": "here I'm only showing three examples but",
      "offset": 3757.359,
      "duration": 5.601
    },
    {
      "lang": "en",
      "text": "the way this works basically is uh a",
      "offset": 3759.64,
      "duration": 5.919
    },
    {
      "lang": "en",
      "text": "assistant is being programmed by example",
      "offset": 3762.96,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "and where is this data coming from like",
      "offset": 3765.559,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "2 * 2al 4 same as 2 plus 2 Etc where",
      "offset": 3767.44,
      "duration": 4.28
    },
    {
      "lang": "en",
      "text": "does that come from this comes from",
      "offset": 3770.119,
      "duration": 4.601
    },
    {
      "lang": "en",
      "text": "Human labelers so we will basically give",
      "offset": 3771.72,
      "duration": 4.68
    },
    {
      "lang": "en",
      "text": "human labelers some conversational",
      "offset": 3774.72,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "context and we will ask them to um",
      "offset": 3776.4,
      "duration": 4.199
    },
    {
      "lang": "en",
      "text": "basically give the ideal assistant",
      "offset": 3778.72,
      "duration": 4.839
    },
    {
      "lang": "en",
      "text": "response in this situation and a human",
      "offset": 3780.599,
      "duration": 5.641
    },
    {
      "lang": "en",
      "text": "will write out the ideal response for an",
      "offset": 3783.559,
      "duration": 4.921
    },
    {
      "lang": "en",
      "text": "assistant in any situation and then",
      "offset": 3786.24,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "we're going to get the model to",
      "offset": 3788.48,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "basically train on this and to imitate",
      "offset": 3790.4,
      "duration": 3.639
    },
    {
      "lang": "en",
      "text": "those kinds of",
      "offset": 3792.559,
      "duration": 3.72
    },
    {
      "lang": "en",
      "text": "responses so the way this works then is",
      "offset": 3794.039,
      "duration": 3.721
    },
    {
      "lang": "en",
      "text": "we are going to take our base model",
      "offset": 3796.279,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "which we produced in the preing stage",
      "offset": 3797.76,
      "duration": 4.2
    },
    {
      "lang": "en",
      "text": "and this base model was trained on",
      "offset": 3800.359,
      "duration": 3.48
    },
    {
      "lang": "en",
      "text": "internet documents we're now going to",
      "offset": 3801.96,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "take that data set of internet documents",
      "offset": 3803.839,
      "duration": 3.48
    },
    {
      "lang": "en",
      "text": "and we're gonna throw it out and we're",
      "offset": 3805.24,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "going to substitute a new data set and",
      "offset": 3807.319,
      "duration": 3.24
    },
    {
      "lang": "en",
      "text": "that's going to be a data set of",
      "offset": 3809.48,
      "duration": 2.599
    },
    {
      "lang": "en",
      "text": "conversations and we're going to",
      "offset": 3810.559,
      "duration": 3.401
    },
    {
      "lang": "en",
      "text": "continue training the model on these",
      "offset": 3812.079,
      "duration": 3.561
    },
    {
      "lang": "en",
      "text": "conversations on this new data set of",
      "offset": 3813.96,
      "duration": 3.639
    },
    {
      "lang": "en",
      "text": "conversations and what happens is that",
      "offset": 3815.64,
      "duration": 4.919
    },
    {
      "lang": "en",
      "text": "the model will very rapidly adjust and",
      "offset": 3817.599,
      "duration": 5.321
    },
    {
      "lang": "en",
      "text": "will sort of like learn the statistics",
      "offset": 3820.559,
      "duration": 4.961
    },
    {
      "lang": "en",
      "text": "of how this assistant responds to human",
      "offset": 3822.92,
      "duration": 5.56
    },
    {
      "lang": "en",
      "text": "queries and then later during inference",
      "offset": 3825.52,
      "duration": 6.039
    },
    {
      "lang": "en",
      "text": "we'll be able to basically um Prime the",
      "offset": 3828.48,
      "duration": 5.599
    },
    {
      "lang": "en",
      "text": "assistant and get the response and it",
      "offset": 3831.559,
      "duration": 4.52
    },
    {
      "lang": "en",
      "text": "will be imitating what the humans will",
      "offset": 3834.079,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "human labelers would do in that",
      "offset": 3836.079,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "situation if that makes sense so we're",
      "offset": 3837.359,
      "duration": 3.801
    },
    {
      "lang": "en",
      "text": "going to see examples of that and this",
      "offset": 3840.079,
      "duration": 3.161
    },
    {
      "lang": "en",
      "text": "is going to become bit more concrete I",
      "offset": 3841.16,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "also wanted to mention that this",
      "offset": 3843.24,
      "duration": 2.96
    },
    {
      "lang": "en",
      "text": "post-training stage we're going to",
      "offset": 3845.079,
      "duration": 2.641
    },
    {
      "lang": "en",
      "text": "basically just continue training the",
      "offset": 3846.2,
      "duration": 4.76
    },
    {
      "lang": "en",
      "text": "model but um the pre-training stage can",
      "offset": 3847.72,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "in practice take roughly three months of",
      "offset": 3850.96,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "training on many thousands of computers",
      "offset": 3853,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "the post-training stage will typically",
      "offset": 3855.359,
      "duration": 4.76
    },
    {
      "lang": "en",
      "text": "be much shorter like 3 hours for example",
      "offset": 3856.839,
      "duration": 4.681
    },
    {
      "lang": "en",
      "text": "um and that's because the data set of",
      "offset": 3860.119,
      "duration": 3.24
    },
    {
      "lang": "en",
      "text": "conversations that we're going to create",
      "offset": 3861.52,
      "duration": 4.559
    },
    {
      "lang": "en",
      "text": "here manually is much much smaller than",
      "offset": 3863.359,
      "duration": 5.601
    },
    {
      "lang": "en",
      "text": "the data set of text on the internet and",
      "offset": 3866.079,
      "duration": 5.401
    },
    {
      "lang": "en",
      "text": "so this training will be very short but",
      "offset": 3868.96,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "fundamentally we're just going to take",
      "offset": 3871.48,
      "duration": 3.559
    },
    {
      "lang": "en",
      "text": "our base model we're going to continue",
      "offset": 3873.2,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "training using the exact same algorithm",
      "offset": 3875.039,
      "duration": 4.201
    },
    {
      "lang": "en",
      "text": "the exact same everything except we're",
      "offset": 3877.279,
      "duration": 3.401
    },
    {
      "lang": "en",
      "text": "swapping out the data set for",
      "offset": 3879.24,
      "duration": 3.879
    },
    {
      "lang": "en",
      "text": "conversations so the questions now are",
      "offset": 3880.68,
      "duration": 4.28
    },
    {
      "lang": "en",
      "text": "what are these conversations how do we",
      "offset": 3883.119,
      "duration": 3.801
    },
    {
      "lang": "en",
      "text": "represent them how do we get the model",
      "offset": 3884.96,
      "duration": 4.28
    },
    {
      "lang": "en",
      "text": "to see conversations instead of just raw",
      "offset": 3886.92,
      "duration": 5.84
    },
    {
      "lang": "en",
      "text": "text and then what are the outcomes of",
      "offset": 3889.24,
      "duration": 5.48
    },
    {
      "lang": "en",
      "text": "um this kind of training and what do you",
      "offset": 3892.76,
      "duration": 4.12
    },
    {
      "lang": "en",
      "text": "get in a certain like psychological",
      "offset": 3894.72,
      "duration": 4.2
    },
    {
      "lang": "en",
      "text": "sense uh when we talk about the model so",
      "offset": 3896.88,
      "duration": 4.239
    },
    {
      "lang": "en",
      "text": "let's turn to those questions now so",
      "offset": 3898.92,
      "duration": 3.359
    },
    {
      "lang": "en",
      "text": "let's start by talking about the",
      "offset": 3901.119,
      "duration": 4.2
    },
    {
      "lang": "en",
      "text": "tokenization of conversations everything",
      "offset": 3902.279,
      "duration": 4.76
    },
    {
      "lang": "en",
      "text": "in these models has to be turned into",
      "offset": 3905.319,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "tokens because everything is just about",
      "offset": 3907.039,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "token sequences so how do we turn",
      "offset": 3908.839,
      "duration": 4.121
    },
    {
      "lang": "en",
      "text": "conversations into token sequences is",
      "offset": 3910.88,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "the question and so for that we need to",
      "offset": 3912.96,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "design some kind of ending coding and uh",
      "offset": 3915.039,
      "duration": 3.721
    },
    {
      "lang": "en",
      "text": "this is kind of similar to maybe if",
      "offset": 3917.359,
      "duration": 3.361
    },
    {
      "lang": "en",
      "text": "you're familiar you don't have to be",
      "offset": 3918.76,
      "duration": 4.76
    },
    {
      "lang": "en",
      "text": "with for example the TCP IP packet in um",
      "offset": 3920.72,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "on the internet there are precise rules",
      "offset": 3923.52,
      "duration": 3.599
    },
    {
      "lang": "en",
      "text": "and protocols for how you represent",
      "offset": 3925.44,
      "duration": 3.72
    },
    {
      "lang": "en",
      "text": "information how everything is structured",
      "offset": 3927.119,
      "duration": 3.24
    },
    {
      "lang": "en",
      "text": "together so that you have all this kind",
      "offset": 3929.16,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "of data laid out in a way that is",
      "offset": 3930.359,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "written out on a paper and that everyone",
      "offset": 3932.68,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "can agree on and so it's the same thing",
      "offset": 3934.52,
      "duration": 3.96
    },
    {
      "lang": "en",
      "text": "now happening in llms we need some kind",
      "offset": 3936.68,
      "duration": 3.599
    },
    {
      "lang": "en",
      "text": "of data structures and we need to have",
      "offset": 3938.48,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "some rules around how these data",
      "offset": 3940.279,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "structures like conversations get",
      "offset": 3941.76,
      "duration": 5.16
    },
    {
      "lang": "en",
      "text": "encoded and decoded to and from tokens",
      "offset": 3943.559,
      "duration": 5.321
    },
    {
      "lang": "en",
      "text": "and so I want to show you now how I",
      "offset": 3946.92,
      "duration": 3
    },
    {
      "lang": "en",
      "text": "would",
      "offset": 3948.88,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "recreate uh this conversation in the",
      "offset": 3949.92,
      "duration": 4.52
    },
    {
      "lang": "en",
      "text": "token space so if you go to Tech",
      "offset": 3952.4,
      "duration": 3.879
    },
    {
      "lang": "en",
      "text": "tokenizer",
      "offset": 3954.44,
      "duration": 4.359
    },
    {
      "lang": "en",
      "text": "I can take that conversation and this is",
      "offset": 3956.279,
      "duration": 4.921
    },
    {
      "lang": "en",
      "text": "how it is represented in uh for the",
      "offset": 3958.799,
      "duration": 5
    },
    {
      "lang": "en",
      "text": "language model so here we have we are",
      "offset": 3961.2,
      "duration": 5.24
    },
    {
      "lang": "en",
      "text": "iterating a user and an assistant in",
      "offset": 3963.799,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "this two- turn",
      "offset": 3966.44,
      "duration": 3.8
    },
    {
      "lang": "en",
      "text": "conversation and what you're seeing here",
      "offset": 3968.119,
      "duration": 3.561
    },
    {
      "lang": "en",
      "text": "is it looks ugly but it's actually",
      "offset": 3970.24,
      "duration": 3.599
    },
    {
      "lang": "en",
      "text": "relatively simple the way it gets turned",
      "offset": 3971.68,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "into a token sequence here at the end is",
      "offset": 3973.839,
      "duration": 4.561
    },
    {
      "lang": "en",
      "text": "a little bit complicated but at the end",
      "offset": 3976.24,
      "duration": 3.48
    },
    {
      "lang": "en",
      "text": "this conversation between a user and",
      "offset": 3978.4,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "assistant ends up being 49 tokens it is",
      "offset": 3979.72,
      "duration": 5.119
    },
    {
      "lang": "en",
      "text": "a one-dimensional sequence of 49 tokens",
      "offset": 3982.559,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "and these are the tokens",
      "offset": 3984.839,
      "duration": 4.841
    },
    {
      "lang": "en",
      "text": "okay and all the different llms will",
      "offset": 3986.48,
      "duration": 5.119
    },
    {
      "lang": "en",
      "text": "have a slightly different format or",
      "offset": 3989.68,
      "duration": 3.599
    },
    {
      "lang": "en",
      "text": "protocols and it's a little bit of a",
      "offset": 3991.599,
      "duration": 4.641
    },
    {
      "lang": "en",
      "text": "wild west right now but for example GPT",
      "offset": 3993.279,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "40 does it in the following way you have",
      "offset": 3996.24,
      "duration": 6.119
    },
    {
      "lang": "en",
      "text": "this special token called imore start",
      "offset": 3999.039,
      "duration": 5.121
    },
    {
      "lang": "en",
      "text": "and this is short for IM imaginary",
      "offset": 4002.359,
      "duration": 3.641
    },
    {
      "lang": "en",
      "text": "monologue uh the",
      "offset": 4004.16,
      "duration": 5.439
    },
    {
      "lang": "en",
      "text": "start then you have to specify um I",
      "offset": 4006,
      "duration": 4.68
    },
    {
      "lang": "en",
      "text": "don't actually know why it's called that",
      "offset": 4009.599,
      "duration": 3.24
    },
    {
      "lang": "en",
      "text": "to be honest then you have to specify",
      "offset": 4010.68,
      "duration": 4.04
    },
    {
      "lang": "en",
      "text": "whose turn it is so for example user",
      "offset": 4012.839,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "which is a token 4",
      "offset": 4014.72,
      "duration": 5.599
    },
    {
      "lang": "en",
      "text": "28 then you have internal monologue",
      "offset": 4016.92,
      "duration": 6.08
    },
    {
      "lang": "en",
      "text": "separator and then it's the exact",
      "offset": 4020.319,
      "duration": 5.161
    },
    {
      "lang": "en",
      "text": "question so the tokens of the question",
      "offset": 4023,
      "duration": 4.119
    },
    {
      "lang": "en",
      "text": "and then you have to close it so I am",
      "offset": 4025.48,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "end the end of the imaginary monologue",
      "offset": 4027.119,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "so",
      "offset": 4029.64,
      "duration": 3.399
    },
    {
      "lang": "en",
      "text": "basically the question from a user of",
      "offset": 4030.72,
      "duration": 5.319
    },
    {
      "lang": "en",
      "text": "what is 2 plus two ends up being the",
      "offset": 4033.039,
      "duration": 6.401
    },
    {
      "lang": "en",
      "text": "token sequence of these tokens and now",
      "offset": 4036.039,
      "duration": 4.721
    },
    {
      "lang": "en",
      "text": "the important thing to mention here is",
      "offset": 4039.44,
      "duration": 4.639
    },
    {
      "lang": "en",
      "text": "that IM start this is not text right IM",
      "offset": 4040.76,
      "duration": 6.319
    },
    {
      "lang": "en",
      "text": "start is a special token that gets added",
      "offset": 4044.079,
      "duration": 6.48
    },
    {
      "lang": "en",
      "text": "it's a new token and um this token has",
      "offset": 4047.079,
      "duration": 5.801
    },
    {
      "lang": "en",
      "text": "never been trained on so far it is a new",
      "offset": 4050.559,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "token that we create in a post-training",
      "offset": 4052.88,
      "duration": 4.76
    },
    {
      "lang": "en",
      "text": "stage and we introduce and so these",
      "offset": 4054.64,
      "duration": 5.8
    },
    {
      "lang": "en",
      "text": "special tokens like IM seep IM start Etc",
      "offset": 4057.64,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "are introduced and interspersed with",
      "offset": 4060.44,
      "duration": 4.839
    },
    {
      "lang": "en",
      "text": "text so that they sort of um get the",
      "offset": 4062.76,
      "duration": 4.68
    },
    {
      "lang": "en",
      "text": "model to learn that hey this is a the",
      "offset": 4065.279,
      "duration": 4.441
    },
    {
      "lang": "en",
      "text": "start of a turn for who is it start of",
      "offset": 4067.44,
      "duration": 4.2
    },
    {
      "lang": "en",
      "text": "the turn for the start of the turn is",
      "offset": 4069.72,
      "duration": 4.28
    },
    {
      "lang": "en",
      "text": "for the user and then this is what the",
      "offset": 4071.64,
      "duration": 5.08
    },
    {
      "lang": "en",
      "text": "user says and then the user ends and",
      "offset": 4074,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "then it's a new start of a turn and it",
      "offset": 4076.72,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "is by the assistant and then what does",
      "offset": 4078.72,
      "duration": 4.119
    },
    {
      "lang": "en",
      "text": "the assistant say well these are the",
      "offset": 4081.2,
      "duration": 4.359
    },
    {
      "lang": "en",
      "text": "tokens of what the assistant says Etc",
      "offset": 4082.839,
      "duration": 4.041
    },
    {
      "lang": "en",
      "text": "and so this conversation is not turned",
      "offset": 4085.559,
      "duration": 4.121
    },
    {
      "lang": "en",
      "text": "into the sequence of tokens the specific",
      "offset": 4086.88,
      "duration": 4.239
    },
    {
      "lang": "en",
      "text": "details here are not actually that",
      "offset": 4089.68,
      "duration": 3.32
    },
    {
      "lang": "en",
      "text": "important all I'm trying to show you in",
      "offset": 4091.119,
      "duration": 4.68
    },
    {
      "lang": "en",
      "text": "concrete terms is that our conversations",
      "offset": 4093,
      "duration": 3.96
    },
    {
      "lang": "en",
      "text": "which we think of as kind of like a",
      "offset": 4095.799,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "structured object end up being turned",
      "offset": 4096.96,
      "duration": 4.839
    },
    {
      "lang": "en",
      "text": "via some encoding into onedimensional",
      "offset": 4099.4,
      "duration": 5.799
    },
    {
      "lang": "en",
      "text": "sequences of tokens and so because this",
      "offset": 4101.799,
      "duration": 5.4
    },
    {
      "lang": "en",
      "text": "is one dimensional sequence of tokens we",
      "offset": 4105.199,
      "duration": 3.881
    },
    {
      "lang": "en",
      "text": "can apply all the stuff that we applied",
      "offset": 4107.199,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "before now it's just a sequence of",
      "offset": 4109.08,
      "duration": 3.96
    },
    {
      "lang": "en",
      "text": "tokens and now we can train a language",
      "offset": 4110.88,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "model on it and so we're just predicting",
      "offset": 4113.04,
      "duration": 4.119
    },
    {
      "lang": "en",
      "text": "the next token in a sequence uh just",
      "offset": 4115.12,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "like before and um we can represent and",
      "offset": 4117.159,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "train on conversations and then what",
      "offset": 4119.92,
      "duration": 4.04
    },
    {
      "lang": "en",
      "text": "does it look like at test time during",
      "offset": 4122.359,
      "duration": 4.521
    },
    {
      "lang": "en",
      "text": "inference so say we've trained a model",
      "offset": 4123.96,
      "duration": 5.16
    },
    {
      "lang": "en",
      "text": "and we've trained a model on these kinds",
      "offset": 4126.88,
      "duration": 4.439
    },
    {
      "lang": "en",
      "text": "of data sets of conversations and now we",
      "offset": 4129.12,
      "duration": 3.199
    },
    {
      "lang": "en",
      "text": "want to",
      "offset": 4131.319,
      "duration": 3.241
    },
    {
      "lang": "en",
      "text": "inference so during inference what does",
      "offset": 4132.319,
      "duration": 3.641
    },
    {
      "lang": "en",
      "text": "this look like when you're on on chash",
      "offset": 4134.56,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "apt well you come to chash apt and you",
      "offset": 4135.96,
      "duration": 5.16
    },
    {
      "lang": "en",
      "text": "have say like a dialogue with it and the",
      "offset": 4138.719,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "way this works is",
      "offset": 4141.12,
      "duration": 5.079
    },
    {
      "lang": "en",
      "text": "basically um say that this was already",
      "offset": 4143.359,
      "duration": 4.561
    },
    {
      "lang": "en",
      "text": "filled in so like what is 2 plus 2 2",
      "offset": 4146.199,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "plus 2 is four and now you issue what if",
      "offset": 4147.92,
      "duration": 5.96
    },
    {
      "lang": "en",
      "text": "it was times I am end and what basically",
      "offset": 4150.359,
      "duration": 5.761
    },
    {
      "lang": "en",
      "text": "ends up happening um on the servers of",
      "offset": 4153.88,
      "duration": 4.12
    },
    {
      "lang": "en",
      "text": "open AI or something like that is they",
      "offset": 4156.12,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "put in I start assistant I amep and this",
      "offset": 4158,
      "duration": 6.719
    },
    {
      "lang": "en",
      "text": "is where they end it right here so they",
      "offset": 4161.88,
      "duration": 5.479
    },
    {
      "lang": "en",
      "text": "construct this context and now they",
      "offset": 4164.719,
      "duration": 4.721
    },
    {
      "lang": "en",
      "text": "start sampling from the model so it's at",
      "offset": 4167.359,
      "duration": 3.32
    },
    {
      "lang": "en",
      "text": "this stage that they will go to the",
      "offset": 4169.44,
      "duration": 2.96
    },
    {
      "lang": "en",
      "text": "model and say okay what is a good for",
      "offset": 4170.679,
      "duration": 3.881
    },
    {
      "lang": "en",
      "text": "sequence what is a good first token what",
      "offset": 4172.4,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "is a good second token what is a good",
      "offset": 4174.56,
      "duration": 3.799
    },
    {
      "lang": "en",
      "text": "third token and this is where the LM",
      "offset": 4176.64,
      "duration": 4.719
    },
    {
      "lang": "en",
      "text": "takes over and creates a response like",
      "offset": 4178.359,
      "duration": 5.241
    },
    {
      "lang": "en",
      "text": "for example response that looks",
      "offset": 4181.359,
      "duration": 3.521
    },
    {
      "lang": "en",
      "text": "something like this but it doesn't have",
      "offset": 4183.6,
      "duration": 3.119
    },
    {
      "lang": "en",
      "text": "to be identical to this but it will have",
      "offset": 4184.88,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "the flavor of this if this kind of a",
      "offset": 4186.719,
      "duration": 5.681
    },
    {
      "lang": "en",
      "text": "conversation was in the data set so um",
      "offset": 4188.88,
      "duration": 6.04
    },
    {
      "lang": "en",
      "text": "that's roughly how the protocol Works",
      "offset": 4192.4,
      "duration": 4.12
    },
    {
      "lang": "en",
      "text": "although the details of this protocol",
      "offset": 4194.92,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "are not important so again my goal is",
      "offset": 4196.52,
      "duration": 4.639
    },
    {
      "lang": "en",
      "text": "that just to show you that everything",
      "offset": 4199.48,
      "duration": 2.92
    },
    {
      "lang": "en",
      "text": "ends up being just a one-dimensional",
      "offset": 4201.159,
      "duration": 2.961
    },
    {
      "lang": "en",
      "text": "token sequence so we can apply",
      "offset": 4202.4,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "everything we've already seen but we're",
      "offset": 4204.12,
      "duration": 4.559
    },
    {
      "lang": "en",
      "text": "now training on conversations and we're",
      "offset": 4206.56,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "now uh basically generating",
      "offset": 4208.679,
      "duration": 4.52
    },
    {
      "lang": "en",
      "text": "conversations as well okay so now I",
      "offset": 4210.96,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "would like to turn to what these data",
      "offset": 4213.199,
      "duration": 3.201
    },
    {
      "lang": "en",
      "text": "sets look like in practice the first",
      "offset": 4214.4,
      "duration": 3.279
    },
    {
      "lang": "en",
      "text": "paper that I would like to show you and",
      "offset": 4216.4,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "the first effort in this direction is",
      "offset": 4217.679,
      "duration": 5.681
    },
    {
      "lang": "en",
      "text": "this paper from openai in 2022 and this",
      "offset": 4220.48,
      "duration": 5.4
    },
    {
      "lang": "en",
      "text": "paper was called instruct GPT or the",
      "offset": 4223.36,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "technique that they developed and this",
      "offset": 4225.88,
      "duration": 3.16
    },
    {
      "lang": "en",
      "text": "was the first time that opena has kind",
      "offset": 4227.44,
      "duration": 2.92
    },
    {
      "lang": "en",
      "text": "of talked about how you can take",
      "offset": 4229.04,
      "duration": 3.56
    },
    {
      "lang": "en",
      "text": "language models and fine-tune them on",
      "offset": 4230.36,
      "duration": 4.44
    },
    {
      "lang": "en",
      "text": "conversations and so this paper has a",
      "offset": 4232.6,
      "duration": 3.48
    },
    {
      "lang": "en",
      "text": "number of details that I would like to",
      "offset": 4234.8,
      "duration": 3.24
    },
    {
      "lang": "en",
      "text": "take you through so the first stop I",
      "offset": 4236.08,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "would like to make is in section 3.4",
      "offset": 4238.04,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "where they talk about the human",
      "offset": 4240.159,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "contractors that they hired uh in this",
      "offset": 4241.64,
      "duration": 5.84
    },
    {
      "lang": "en",
      "text": "case from upwork or through scale AI to",
      "offset": 4244.08,
      "duration": 5.88
    },
    {
      "lang": "en",
      "text": "uh construct these conversations and so",
      "offset": 4247.48,
      "duration": 4.759
    },
    {
      "lang": "en",
      "text": "there are human labelers involved whose",
      "offset": 4249.96,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "job it is professionally to create these",
      "offset": 4252.239,
      "duration": 4.281
    },
    {
      "lang": "en",
      "text": "conversations and these labelers are",
      "offset": 4254.52,
      "duration": 4.28
    },
    {
      "lang": "en",
      "text": "asked to come up with prompts and then",
      "offset": 4256.52,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "they are asked to also complete the",
      "offset": 4258.8,
      "duration": 4.52
    },
    {
      "lang": "en",
      "text": "ideal assistant responses and so these",
      "offset": 4260.76,
      "duration": 3.8
    },
    {
      "lang": "en",
      "text": "are the kinds of prompts that people",
      "offset": 4263.32,
      "duration": 3.399
    },
    {
      "lang": "en",
      "text": "came up with so these are human labelers",
      "offset": 4264.56,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "so list five ideas for how to regain",
      "offset": 4266.719,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "enthusiasm for my career what are the",
      "offset": 4268.64,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "top 10 science fiction books I should",
      "offset": 4270.64,
      "duration": 3.32
    },
    {
      "lang": "en",
      "text": "read next and there's many different",
      "offset": 4272,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "types of uh kind of prompts here so",
      "offset": 4273.96,
      "duration": 4.759
    },
    {
      "lang": "en",
      "text": "translate this sentence from uh to",
      "offset": 4276.88,
      "duration": 4.68
    },
    {
      "lang": "en",
      "text": "Spanish Etc and so there's many things",
      "offset": 4278.719,
      "duration": 5
    },
    {
      "lang": "en",
      "text": "here that people came up with they first",
      "offset": 4281.56,
      "duration": 4.119
    },
    {
      "lang": "en",
      "text": "come up with the prompt and then they",
      "offset": 4283.719,
      "duration": 4.281
    },
    {
      "lang": "en",
      "text": "also uh answer that prompt and they give",
      "offset": 4285.679,
      "duration": 4.801
    },
    {
      "lang": "en",
      "text": "the ideal assistant response now how do",
      "offset": 4288,
      "duration": 4.28
    },
    {
      "lang": "en",
      "text": "they know what is the ideal assistant",
      "offset": 4290.48,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "response that they should write for",
      "offset": 4292.28,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "these prompts so when we scroll down a",
      "offset": 4293.92,
      "duration": 3.88
    },
    {
      "lang": "en",
      "text": "little bit further we see that here we",
      "offset": 4295.88,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "have this excerpt of labeling",
      "offset": 4297.8,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "instructions uh that are given to the",
      "offset": 4299.56,
      "duration": 4.44
    },
    {
      "lang": "en",
      "text": "human labelers so the company that is",
      "offset": 4301.4,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "developing the language model like for",
      "offset": 4304,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "example open AI writes up labeling",
      "offset": 4305.32,
      "duration": 4.28
    },
    {
      "lang": "en",
      "text": "instructions for how the humans should",
      "offset": 4307.44,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "create ideal responses and so here for",
      "offset": 4309.6,
      "duration": 5.039
    },
    {
      "lang": "en",
      "text": "example is an excerpt uh of these kinds",
      "offset": 4312.56,
      "duration": 3.639
    },
    {
      "lang": "en",
      "text": "of labeling instruction instructions on",
      "offset": 4314.639,
      "duration": 2.961
    },
    {
      "lang": "en",
      "text": "High level you're asking people to be",
      "offset": 4316.199,
      "duration": 3.761
    },
    {
      "lang": "en",
      "text": "helpful truthful and harmless and you",
      "offset": 4317.6,
      "duration": 4.2
    },
    {
      "lang": "en",
      "text": "can pause the video if you'd like to see",
      "offset": 4319.96,
      "duration": 4.279
    },
    {
      "lang": "en",
      "text": "more here but on a high level basically",
      "offset": 4321.8,
      "duration": 4.359
    },
    {
      "lang": "en",
      "text": "just just answer try to be helpful try",
      "offset": 4324.239,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "to be truthful and don't answer",
      "offset": 4326.159,
      "duration": 4.121
    },
    {
      "lang": "en",
      "text": "questions that we don't want um kind of",
      "offset": 4328.159,
      "duration": 5.08
    },
    {
      "lang": "en",
      "text": "the system to handle uh later in chat",
      "offset": 4330.28,
      "duration": 6.28
    },
    {
      "lang": "en",
      "text": "gbt and so roughly speaking the company",
      "offset": 4333.239,
      "duration": 4.881
    },
    {
      "lang": "en",
      "text": "comes up with the labeling instructions",
      "offset": 4336.56,
      "duration": 3.119
    },
    {
      "lang": "en",
      "text": "usually they are not this short usually",
      "offset": 4338.12,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "there are hundreds of pages and people",
      "offset": 4339.679,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "have to study them professionally and",
      "offset": 4341.56,
      "duration": 4.679
    },
    {
      "lang": "en",
      "text": "then they write out the ideal assistant",
      "offset": 4343.76,
      "duration": 4.52
    },
    {
      "lang": "en",
      "text": "responses uh following those labeling",
      "offset": 4346.239,
      "duration": 4.561
    },
    {
      "lang": "en",
      "text": "instructions so this is a very human",
      "offset": 4348.28,
      "duration": 4.439
    },
    {
      "lang": "en",
      "text": "heavy process as it was described in",
      "offset": 4350.8,
      "duration": 4.12
    },
    {
      "lang": "en",
      "text": "this paper now the data set for instruct",
      "offset": 4352.719,
      "duration": 4.561
    },
    {
      "lang": "en",
      "text": "GPT was never actually released by openi",
      "offset": 4354.92,
      "duration": 4.719
    },
    {
      "lang": "en",
      "text": "but we do have some open- Source um",
      "offset": 4357.28,
      "duration": 3.56
    },
    {
      "lang": "en",
      "text": "reproductions that were're trying to",
      "offset": 4359.639,
      "duration": 3.321
    },
    {
      "lang": "en",
      "text": "follow this kind of a setup and collect",
      "offset": 4360.84,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "their own data so one that I'm familiar",
      "offset": 4362.96,
      "duration": 5.08
    },
    {
      "lang": "en",
      "text": "with for example is the effort of open",
      "offset": 4365.08,
      "duration": 5.32
    },
    {
      "lang": "en",
      "text": "Assistant from a while back and this is",
      "offset": 4368.04,
      "duration": 4.28
    },
    {
      "lang": "en",
      "text": "just one of I think many examples but I",
      "offset": 4370.4,
      "duration": 4.12
    },
    {
      "lang": "en",
      "text": "just want to show you an example so",
      "offset": 4372.32,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "here's so these were people on the",
      "offset": 4374.52,
      "duration": 3.4
    },
    {
      "lang": "en",
      "text": "internet that were asked to basically",
      "offset": 4376.4,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "create these conversations similar to",
      "offset": 4377.92,
      "duration": 5.279
    },
    {
      "lang": "en",
      "text": "what um open I did with human labelers",
      "offset": 4379.6,
      "duration": 5.88
    },
    {
      "lang": "en",
      "text": "and so here's an entry of a person who",
      "offset": 4383.199,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "came up with this BR can you write a",
      "offset": 4385.48,
      "duration": 3.239
    },
    {
      "lang": "en",
      "text": "short introduction to the relevance of",
      "offset": 4387.28,
      "duration": 2.359
    },
    {
      "lang": "en",
      "text": "the term",
      "offset": 4388.719,
      "duration": 3.881
    },
    {
      "lang": "en",
      "text": "manop uh in economics please use",
      "offset": 4389.639,
      "duration": 5.681
    },
    {
      "lang": "en",
      "text": "examples Etc and then the same person or",
      "offset": 4392.6,
      "duration": 4.599
    },
    {
      "lang": "en",
      "text": "potentially a different person will",
      "offset": 4395.32,
      "duration": 3.48
    },
    {
      "lang": "en",
      "text": "write up the response so here's the",
      "offset": 4397.199,
      "duration": 4.761
    },
    {
      "lang": "en",
      "text": "assistant response to this and so then",
      "offset": 4398.8,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "the same person or different person will",
      "offset": 4401.96,
      "duration": 4.92
    },
    {
      "lang": "en",
      "text": "actually write out this ideal",
      "offset": 4403.76,
      "duration": 5.72
    },
    {
      "lang": "en",
      "text": "response and then this is an example of",
      "offset": 4406.88,
      "duration": 3.759
    },
    {
      "lang": "en",
      "text": "maybe how the conversation could",
      "offset": 4409.48,
      "duration": 3.88
    },
    {
      "lang": "en",
      "text": "continue now explain it to a dog and",
      "offset": 4410.639,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "then you can try to come up with a",
      "offset": 4413.36,
      "duration": 3.24
    },
    {
      "lang": "en",
      "text": "slightly a simpler explanation or",
      "offset": 4414.8,
      "duration": 5.16
    },
    {
      "lang": "en",
      "text": "something like that now this then",
      "offset": 4416.6,
      "duration": 5.119
    },
    {
      "lang": "en",
      "text": "becomes the label and we end up training",
      "offset": 4419.96,
      "duration": 5.239
    },
    {
      "lang": "en",
      "text": "on this so what happens during training",
      "offset": 4421.719,
      "duration": 6.361
    },
    {
      "lang": "en",
      "text": "is that um of course we're not going to",
      "offset": 4425.199,
      "duration": 5.321
    },
    {
      "lang": "en",
      "text": "have a full coverage of all the possible",
      "offset": 4428.08,
      "duration": 5.8
    },
    {
      "lang": "en",
      "text": "questions that um the model will",
      "offset": 4430.52,
      "duration": 5.679
    },
    {
      "lang": "en",
      "text": "encounter at test time during inference",
      "offset": 4433.88,
      "duration": 3.96
    },
    {
      "lang": "en",
      "text": "we can't possibly cover all the possible",
      "offset": 4436.199,
      "duration": 2.801
    },
    {
      "lang": "en",
      "text": "prompts that people are going to be",
      "offset": 4437.84,
      "duration": 4.2
    },
    {
      "lang": "en",
      "text": "asking in the future but if we have a",
      "offset": 4439,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "like a data set of a few of these",
      "offset": 4442.04,
      "duration": 4.599
    },
    {
      "lang": "en",
      "text": "examples then the model during training",
      "offset": 4443.88,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "will start to take on this Persona of",
      "offset": 4446.639,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "this helpful truthful harmless assistant",
      "offset": 4449.08,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "and it's all programmed by example and",
      "offset": 4452.159,
      "duration": 4.801
    },
    {
      "lang": "en",
      "text": "so these are all examples of behavior",
      "offset": 4454.76,
      "duration": 3.64
    },
    {
      "lang": "en",
      "text": "and if you have conversations of these",
      "offset": 4456.96,
      "duration": 2.92
    },
    {
      "lang": "en",
      "text": "example behaviors and you have enough of",
      "offset": 4458.4,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "them like 100,00 and you train on it the",
      "offset": 4459.88,
      "duration": 3.96
    },
    {
      "lang": "en",
      "text": "model sort of starts to understand the",
      "offset": 4462.4,
      "duration": 3.64
    },
    {
      "lang": "en",
      "text": "statistical pattern and it kind of takes",
      "offset": 4463.84,
      "duration": 4.359
    },
    {
      "lang": "en",
      "text": "on this personality of this",
      "offset": 4466.04,
      "duration": 4.28
    },
    {
      "lang": "en",
      "text": "assistant now it's possible that when",
      "offset": 4468.199,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "you get the exact same question like",
      "offset": 4470.32,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "this at test time it's possible that the",
      "offset": 4472.36,
      "duration": 6.48
    },
    {
      "lang": "en",
      "text": "answer will be recited as exactly what",
      "offset": 4475.6,
      "duration": 5.119
    },
    {
      "lang": "en",
      "text": "was in the training set but more likely",
      "offset": 4478.84,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "than that is that the model will kind of",
      "offset": 4480.719,
      "duration": 5.161
    },
    {
      "lang": "en",
      "text": "like do something of a similar Vibe um",
      "offset": 4483.08,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "and we will understand that this is the",
      "offset": 4485.88,
      "duration": 5.279
    },
    {
      "lang": "en",
      "text": "kind of answer that you want um so",
      "offset": 4487.32,
      "duration": 4.879
    },
    {
      "lang": "en",
      "text": "that's what we're doing we're",
      "offset": 4491.159,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "programming the system um by example and",
      "offset": 4492.199,
      "duration": 6.04
    },
    {
      "lang": "en",
      "text": "the system adopts statistically this",
      "offset": 4495.56,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "Persona of this helpful truthful",
      "offset": 4498.239,
      "duration": 4.601
    },
    {
      "lang": "en",
      "text": "harmless assistant which is kind of like",
      "offset": 4500.6,
      "duration": 3.8
    },
    {
      "lang": "en",
      "text": "reflected in the labeling instructions",
      "offset": 4502.84,
      "duration": 3.56
    },
    {
      "lang": "en",
      "text": "that the company creates now I want to",
      "offset": 4504.4,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "show you that the state-of-the-art has",
      "offset": 4506.4,
      "duration": 3.279
    },
    {
      "lang": "en",
      "text": "kind of advanced in the last 2 or 3",
      "offset": 4508.08,
      "duration": 4.559
    },
    {
      "lang": "en",
      "text": "years uh since the instr GPT paper so in",
      "offset": 4509.679,
      "duration": 4.921
    },
    {
      "lang": "en",
      "text": "particular it's not very common for",
      "offset": 4512.639,
      "duration": 3.641
    },
    {
      "lang": "en",
      "text": "humans to be doing all the heavy lifting",
      "offset": 4514.6,
      "duration": 3.559
    },
    {
      "lang": "en",
      "text": "just by themselves anymore and that's",
      "offset": 4516.28,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "because we now have language models and",
      "offset": 4518.159,
      "duration": 2.961
    },
    {
      "lang": "en",
      "text": "these language models are helping us",
      "offset": 4519.56,
      "duration": 3.679
    },
    {
      "lang": "en",
      "text": "create these data sets and conversations",
      "offset": 4521.12,
      "duration": 4.039
    },
    {
      "lang": "en",
      "text": "so it is very rare that the people will",
      "offset": 4523.239,
      "duration": 3.121
    },
    {
      "lang": "en",
      "text": "like literally just write out the",
      "offset": 4525.159,
      "duration": 3.401
    },
    {
      "lang": "en",
      "text": "response from scratch it is a lot more",
      "offset": 4526.36,
      "duration": 3.48
    },
    {
      "lang": "en",
      "text": "likely that they will use an existing",
      "offset": 4528.56,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "llm to basically like uh come up with an",
      "offset": 4529.84,
      "duration": 4.2
    },
    {
      "lang": "en",
      "text": "answer and then they will edit it or",
      "offset": 4532.32,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "things like that so there's many",
      "offset": 4534.04,
      "duration": 3.56
    },
    {
      "lang": "en",
      "text": "different ways in which now llms have",
      "offset": 4535.52,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "started to kind of permeate this",
      "offset": 4537.6,
      "duration": 5.88
    },
    {
      "lang": "en",
      "text": "posttraining Set uh stack and llms are",
      "offset": 4539.679,
      "duration": 5.56
    },
    {
      "lang": "en",
      "text": "basically used pervasively to help",
      "offset": 4543.48,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "create these massive data sets of",
      "offset": 4545.239,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "conversations so I don't want to show",
      "offset": 4546.76,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "like Ultra chat is one um such example",
      "offset": 4549.08,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "of like a more modern data set of",
      "offset": 4552.04,
      "duration": 4.119
    },
    {
      "lang": "en",
      "text": "conversations it is to a very large",
      "offset": 4553.88,
      "duration": 4.359
    },
    {
      "lang": "en",
      "text": "extent synthetic but uh I believe",
      "offset": 4556.159,
      "duration": 3.441
    },
    {
      "lang": "en",
      "text": "there's some human involvement I could",
      "offset": 4558.239,
      "duration": 2.92
    },
    {
      "lang": "en",
      "text": "be wrong with that usually there will be",
      "offset": 4559.6,
      "duration": 3.16
    },
    {
      "lang": "en",
      "text": "a little bit of human but there will be",
      "offset": 4561.159,
      "duration": 5.08
    },
    {
      "lang": "en",
      "text": "a huge amount of synthetic help um and",
      "offset": 4562.76,
      "duration": 5.959
    },
    {
      "lang": "en",
      "text": "this is all kind of like uh constructed",
      "offset": 4566.239,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "in different ways and Ultra chat is just",
      "offset": 4568.719,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "one example of many sft data sets that",
      "offset": 4570.159,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "currently exist and the only thing I",
      "offset": 4572.159,
      "duration": 3.801
    },
    {
      "lang": "en",
      "text": "want to show you is that uh these data",
      "offset": 4574.08,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "sets have now millions of conversations",
      "offset": 4575.96,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "uh these conversations are mostly",
      "offset": 4578.08,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "synthetic but they're probably edited to",
      "offset": 4579.56,
      "duration": 4.2
    },
    {
      "lang": "en",
      "text": "some extent by humans and they span a",
      "offset": 4581.36,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "huge diversity of sort of",
      "offset": 4583.76,
      "duration": 7.919
    },
    {
      "lang": "en",
      "text": "um uh areas and so on so these are",
      "offset": 4587.12,
      "duration": 6.599
    },
    {
      "lang": "en",
      "text": "fairly extensive artifacts by now and",
      "offset": 4591.679,
      "duration": 4.201
    },
    {
      "lang": "en",
      "text": "there's all these like sft mixtures as",
      "offset": 4593.719,
      "duration": 3.881
    },
    {
      "lang": "en",
      "text": "they're called so you have a mixture of",
      "offset": 4595.88,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "like lots of different types and sources",
      "offset": 4597.6,
      "duration": 3.4
    },
    {
      "lang": "en",
      "text": "and it's partially synthetic partially",
      "offset": 4599.4,
      "duration": 4.799
    },
    {
      "lang": "en",
      "text": "human and it's kind of like um gone in",
      "offset": 4601,
      "duration": 5.639
    },
    {
      "lang": "en",
      "text": "that direction since uh but roughly",
      "offset": 4604.199,
      "duration": 4.52
    },
    {
      "lang": "en",
      "text": "speaking we still have sft data sets",
      "offset": 4606.639,
      "duration": 3.881
    },
    {
      "lang": "en",
      "text": "they're made up of conversations we're",
      "offset": 4608.719,
      "duration": 4.241
    },
    {
      "lang": "en",
      "text": "training on them um just like we did",
      "offset": 4610.52,
      "duration": 4.84
    },
    {
      "lang": "en",
      "text": "before and",
      "offset": 4612.96,
      "duration": 4.12
    },
    {
      "lang": "en",
      "text": "uh I guess like the last thing to note",
      "offset": 4615.36,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "is that I want to dispel a little bit of",
      "offset": 4617.08,
      "duration": 5.4
    },
    {
      "lang": "en",
      "text": "the magic of talking to an AI like when",
      "offset": 4620,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "you go to chat GPT and you give it a",
      "offset": 4622.48,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "question and then you hit enter uh what",
      "offset": 4624.48,
      "duration": 5.679
    },
    {
      "lang": "en",
      "text": "is coming back is kind of like",
      "offset": 4627.84,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "statistically aligned with what's",
      "offset": 4630.159,
      "duration": 3.961
    },
    {
      "lang": "en",
      "text": "happening in the training set and these",
      "offset": 4632.4,
      "duration": 4.12
    },
    {
      "lang": "en",
      "text": "training sets I mean they really just",
      "offset": 4634.12,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "have a seed in humans following labeling",
      "offset": 4636.52,
      "duration": 5.159
    },
    {
      "lang": "en",
      "text": "instructions so what are you actually",
      "offset": 4639.4,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "talking to in chat GPT or how should you",
      "offset": 4641.679,
      "duration": 4.121
    },
    {
      "lang": "en",
      "text": "think about it well it's not coming from",
      "offset": 4644.12,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "some magical AI like roughly speaking",
      "offset": 4645.8,
      "duration": 3.96
    },
    {
      "lang": "en",
      "text": "it's coming from something that is",
      "offset": 4648.44,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "statistically imitating human labelers",
      "offset": 4649.76,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "which comes from labeling instructions",
      "offset": 4652.28,
      "duration": 4.12
    },
    {
      "lang": "en",
      "text": "written by these companies and so you're",
      "offset": 4654.48,
      "duration": 4.12
    },
    {
      "lang": "en",
      "text": "kind of imitating this uh you're kind of",
      "offset": 4656.4,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "getting um it's almost as if you're",
      "offset": 4658.6,
      "duration": 4.44
    },
    {
      "lang": "en",
      "text": "asking human labeler and imagine that",
      "offset": 4660.48,
      "duration": 4.719
    },
    {
      "lang": "en",
      "text": "the answer that is given to you uh from",
      "offset": 4663.04,
      "duration": 4.76
    },
    {
      "lang": "en",
      "text": "chbt is some kind of a simulation of a",
      "offset": 4665.199,
      "duration": 5.401
    },
    {
      "lang": "en",
      "text": "human labeler uh and it's kind of like",
      "offset": 4667.8,
      "duration": 5.399
    },
    {
      "lang": "en",
      "text": "asking what would a human labeler say in",
      "offset": 4670.6,
      "duration": 5.92
    },
    {
      "lang": "en",
      "text": "this kind of a conversation",
      "offset": 4673.199,
      "duration": 5.641
    },
    {
      "lang": "en",
      "text": "and uh it's not just like this human",
      "offset": 4676.52,
      "duration": 3.8
    },
    {
      "lang": "en",
      "text": "labeler is not just like a random person",
      "offset": 4678.84,
      "duration": 2.76
    },
    {
      "lang": "en",
      "text": "from the internet because these",
      "offset": 4680.32,
      "duration": 2.919
    },
    {
      "lang": "en",
      "text": "companies actually hire experts so for",
      "offset": 4681.6,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "example when you are asking questions",
      "offset": 4683.239,
      "duration": 3.521
    },
    {
      "lang": "en",
      "text": "about code and so on the human labelers",
      "offset": 4684.8,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "that would be in um involved in creation",
      "offset": 4686.76,
      "duration": 3.879
    },
    {
      "lang": "en",
      "text": "of these conversation data sets they",
      "offset": 4688.96,
      "duration": 3.64
    },
    {
      "lang": "en",
      "text": "will usually be usually be educated",
      "offset": 4690.639,
      "duration": 4.481
    },
    {
      "lang": "en",
      "text": "expert people and you're kind of like",
      "offset": 4692.6,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "asking a question of like a simulation",
      "offset": 4695.12,
      "duration": 4.68
    },
    {
      "lang": "en",
      "text": "of those people if that makes sense so",
      "offset": 4697.32,
      "duration": 3.879
    },
    {
      "lang": "en",
      "text": "you're not talking to a magical AI",
      "offset": 4699.8,
      "duration": 3
    },
    {
      "lang": "en",
      "text": "you're talking to an average labeler",
      "offset": 4701.199,
      "duration": 3.081
    },
    {
      "lang": "en",
      "text": "this average labeler is probably fairly",
      "offset": 4702.8,
      "duration": 2.52
    },
    {
      "lang": "en",
      "text": "highly skilled",
      "offset": 4704.28,
      "duration": 2.48
    },
    {
      "lang": "en",
      "text": "but you're talking to kind of like an",
      "offset": 4705.32,
      "duration": 3.96
    },
    {
      "lang": "en",
      "text": "instantaneous simulation of that kind of",
      "offset": 4706.76,
      "duration": 5.439
    },
    {
      "lang": "en",
      "text": "a person that would be hired uh in the",
      "offset": 4709.28,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "construction of these data sets so let",
      "offset": 4712.199,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "me give you one more specific example",
      "offset": 4714.56,
      "duration": 3.96
    },
    {
      "lang": "en",
      "text": "before we move on for example when I go",
      "offset": 4716.199,
      "duration": 4.561
    },
    {
      "lang": "en",
      "text": "to chpt and I say recommend the top five",
      "offset": 4718.52,
      "duration": 4.119
    },
    {
      "lang": "en",
      "text": "landmarks who see in Paris and then I",
      "offset": 4720.76,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "hit",
      "offset": 4722.639,
      "duration": 4.881
    },
    {
      "lang": "en",
      "text": "enter",
      "offset": 4724.52,
      "duration": 3
    },
    {
      "lang": "en",
      "text": "uh okay here we go okay when I hit enter",
      "offset": 4729.08,
      "duration": 6.2
    },
    {
      "lang": "en",
      "text": "what's coming out here how do I think",
      "offset": 4732.4,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "about it well it's not some kind of a",
      "offset": 4735.28,
      "duration": 3.359
    },
    {
      "lang": "en",
      "text": "magical AI that has gone out and",
      "offset": 4736.8,
      "duration": 3.48
    },
    {
      "lang": "en",
      "text": "researched all the landmarks and then",
      "offset": 4738.639,
      "duration": 3.281
    },
    {
      "lang": "en",
      "text": "ranked them using its infinite",
      "offset": 4740.28,
      "duration": 3.879
    },
    {
      "lang": "en",
      "text": "intelligence Etc what I'm getting is a",
      "offset": 4741.92,
      "duration": 5.4
    },
    {
      "lang": "en",
      "text": "statistical simulation of a labeler that",
      "offset": 4744.159,
      "duration": 5
    },
    {
      "lang": "en",
      "text": "was hired by open AI you can think about",
      "offset": 4747.32,
      "duration": 5.839
    },
    {
      "lang": "en",
      "text": "it roughly in that way and so if this",
      "offset": 4749.159,
      "duration": 6.841
    },
    {
      "lang": "en",
      "text": "specific um question is in the",
      "offset": 4753.159,
      "duration": 4.801
    },
    {
      "lang": "en",
      "text": "posttraining data set somewhere at open",
      "offset": 4756,
      "duration": 4.76
    },
    {
      "lang": "en",
      "text": "aai then I'm very likely to see an",
      "offset": 4757.96,
      "duration": 4.12
    },
    {
      "lang": "en",
      "text": "answer that is probably very very",
      "offset": 4760.76,
      "duration": 3.479
    },
    {
      "lang": "en",
      "text": "similar to what that human labeler would",
      "offset": 4762.08,
      "duration": 3.32
    },
    {
      "lang": "en",
      "text": "have put down",
      "offset": 4764.239,
      "duration": 2.92
    },
    {
      "lang": "en",
      "text": "for those five landmarks how does the",
      "offset": 4765.4,
      "duration": 3.16
    },
    {
      "lang": "en",
      "text": "human labeler come up with this well",
      "offset": 4767.159,
      "duration": 2.761
    },
    {
      "lang": "en",
      "text": "they go off and they go on the internet",
      "offset": 4768.56,
      "duration": 2.48
    },
    {
      "lang": "en",
      "text": "and they kind of do their own little",
      "offset": 4769.92,
      "duration": 2.84
    },
    {
      "lang": "en",
      "text": "research for 20 minutes and they just",
      "offset": 4771.04,
      "duration": 4.36
    },
    {
      "lang": "en",
      "text": "come up with a list right now so if they",
      "offset": 4772.76,
      "duration": 4.439
    },
    {
      "lang": "en",
      "text": "come up with this list and this is in",
      "offset": 4775.4,
      "duration": 3.799
    },
    {
      "lang": "en",
      "text": "the data set I'm probably very likely to",
      "offset": 4777.199,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "see what they submitted as the correct",
      "offset": 4779.199,
      "duration": 5.48
    },
    {
      "lang": "en",
      "text": "answer from the assistant now if this",
      "offset": 4781.6,
      "duration": 4.84
    },
    {
      "lang": "en",
      "text": "specific query is not part of the post",
      "offset": 4784.679,
      "duration": 3.721
    },
    {
      "lang": "en",
      "text": "training data set then what I'm getting",
      "offset": 4786.44,
      "duration": 4.759
    },
    {
      "lang": "en",
      "text": "here is a little bit more emergent uh",
      "offset": 4788.4,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "because uh the model kind of understands",
      "offset": 4791.199,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "the statistically",
      "offset": 4793.52,
      "duration": 4.04
    },
    {
      "lang": "en",
      "text": "um the kinds of landmarks that are in",
      "offset": 4795.199,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "this training set are usually the",
      "offset": 4797.56,
      "duration": 3.159
    },
    {
      "lang": "en",
      "text": "prominent landmarks the landmarks that",
      "offset": 4799.199,
      "duration": 3.721
    },
    {
      "lang": "en",
      "text": "people usually want to see the kinds of",
      "offset": 4800.719,
      "duration": 4.641
    },
    {
      "lang": "en",
      "text": "landmarks that are usually uh very often",
      "offset": 4802.92,
      "duration": 3.96
    },
    {
      "lang": "en",
      "text": "talked about on the internet and",
      "offset": 4805.36,
      "duration": 3.24
    },
    {
      "lang": "en",
      "text": "remember that the model already has a",
      "offset": 4806.88,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "ton of Knowledge from its pre-training",
      "offset": 4808.6,
      "duration": 3.4
    },
    {
      "lang": "en",
      "text": "on the internet so it's probably seen a",
      "offset": 4810.08,
      "duration": 3.599
    },
    {
      "lang": "en",
      "text": "ton of conversations about Paris about",
      "offset": 4812,
      "duration": 3.32
    },
    {
      "lang": "en",
      "text": "landmarks about the kinds of things that",
      "offset": 4813.679,
      "duration": 3.441
    },
    {
      "lang": "en",
      "text": "people like to see and so it's the",
      "offset": 4815.32,
      "duration": 3.16
    },
    {
      "lang": "en",
      "text": "pre-training knowledge that has then",
      "offset": 4817.12,
      "duration": 3.64
    },
    {
      "lang": "en",
      "text": "combined with the postering data set",
      "offset": 4818.48,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "that results in this kind of an",
      "offset": 4820.76,
      "duration": 4.6
    },
    {
      "lang": "en",
      "text": "imitation um",
      "offset": 4823.52,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "so that's uh that's roughly how you can",
      "offset": 4825.36,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "kind of think about what's happening",
      "offset": 4827.92,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "behind the scenes here in in this",
      "offset": 4829.52,
      "duration": 4.04
    },
    {
      "lang": "en",
      "text": "statistical sense okay now I want to",
      "offset": 4831.6,
      "duration": 4.2
    },
    {
      "lang": "en",
      "text": "turn to the topic of llm psychology as I",
      "offset": 4833.56,
      "duration": 3.96
    },
    {
      "lang": "en",
      "text": "like to call it which is what are sort",
      "offset": 4835.8,
      "duration": 4.879
    },
    {
      "lang": "en",
      "text": "of the emergent cognitive effects of the",
      "offset": 4837.52,
      "duration": 4.679
    },
    {
      "lang": "en",
      "text": "training pipeline that we have for these",
      "offset": 4840.679,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "models so in particular the first one I",
      "offset": 4842.199,
      "duration": 5.281
    },
    {
      "lang": "en",
      "text": "want to talk to is of course",
      "offset": 4844.36,
      "duration": 6.12
    },
    {
      "lang": "en",
      "text": "hallucinations so you might be familiar",
      "offset": 4847.48,
      "duration": 5
    },
    {
      "lang": "en",
      "text": "with model hallucinations it's when llms",
      "offset": 4850.48,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "make stuff up they just totally",
      "offset": 4852.48,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "fabricate information Etc and it's a big",
      "offset": 4853.84,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "problem with llm assistants it is a",
      "offset": 4856.08,
      "duration": 3.96
    },
    {
      "lang": "en",
      "text": "problem that existed to a large extent",
      "offset": 4858.159,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "with early models uh from many years ago",
      "offset": 4860.04,
      "duration": 4.119
    },
    {
      "lang": "en",
      "text": "and I think the problem has gotten a bit",
      "offset": 4862.719,
      "duration": 2.881
    },
    {
      "lang": "en",
      "text": "better uh because there are some",
      "offset": 4864.159,
      "duration": 2.921
    },
    {
      "lang": "en",
      "text": "medications that I'm going to go into in",
      "offset": 4865.6,
      "duration": 3.559
    },
    {
      "lang": "en",
      "text": "a second for now let's just try to",
      "offset": 4867.08,
      "duration": 3.119
    },
    {
      "lang": "en",
      "text": "understand where these hallucinations",
      "offset": 4869.159,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "come from so here's a specific example",
      "offset": 4870.199,
      "duration": 5.841
    },
    {
      "lang": "en",
      "text": "of a few uh of three conversations that",
      "offset": 4873.48,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "you might think you have in your",
      "offset": 4876.04,
      "duration": 4.44
    },
    {
      "lang": "en",
      "text": "training set and um these are pretty",
      "offset": 4877.48,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "reasonable conversations that you could",
      "offset": 4880.48,
      "duration": 3.08
    },
    {
      "lang": "en",
      "text": "imagine being in the training set so",
      "offset": 4882.04,
      "duration": 3.679
    },
    {
      "lang": "en",
      "text": "like for example who is Cruz well Tom",
      "offset": 4883.56,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "Cruz is an famous actor American actor",
      "offset": 4885.719,
      "duration": 5.281
    },
    {
      "lang": "en",
      "text": "and producer Etc who is John baraso this",
      "offset": 4887.96,
      "duration": 6.239
    },
    {
      "lang": "en",
      "text": "turns out to be a us senetor for example",
      "offset": 4891,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "who is genis Khan well genis Khan was",
      "offset": 4894.199,
      "duration": 5.321
    },
    {
      "lang": "en",
      "text": "blah blah blah and so this is what your",
      "offset": 4896.52,
      "duration": 4.119
    },
    {
      "lang": "en",
      "text": "conversations could look like at",
      "offset": 4899.52,
      "duration": 3.24
    },
    {
      "lang": "en",
      "text": "training time now the problem with this",
      "offset": 4900.639,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "is that when the human is writing the",
      "offset": 4902.76,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "correct answer for the assistant in each",
      "offset": 4906.159,
      "duration": 4.921
    },
    {
      "lang": "en",
      "text": "one of these cases uh the human either",
      "offset": 4908.76,
      "duration": 3.64
    },
    {
      "lang": "en",
      "text": "like knows who this person is or they",
      "offset": 4911.08,
      "duration": 2.84
    },
    {
      "lang": "en",
      "text": "research them on the Internet and they",
      "offset": 4912.4,
      "duration": 3.319
    },
    {
      "lang": "en",
      "text": "come in and they write this response",
      "offset": 4913.92,
      "duration": 3.319
    },
    {
      "lang": "en",
      "text": "that kind of has this like confident",
      "offset": 4915.719,
      "duration": 3.881
    },
    {
      "lang": "en",
      "text": "tone of an answer and what happens",
      "offset": 4917.239,
      "duration": 4.201
    },
    {
      "lang": "en",
      "text": "basically is that at test time when you",
      "offset": 4919.6,
      "duration": 4.039
    },
    {
      "lang": "en",
      "text": "ask for someone who is this is a totally",
      "offset": 4921.44,
      "duration": 3.719
    },
    {
      "lang": "en",
      "text": "random name that I totally came up with",
      "offset": 4923.639,
      "duration": 3.881
    },
    {
      "lang": "en",
      "text": "and I don't think this person exists um",
      "offset": 4925.159,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "as far as I know I just Tred to generate",
      "offset": 4927.52,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "it randomly the problem is when we ask",
      "offset": 4929.719,
      "duration": 5.721
    },
    {
      "lang": "en",
      "text": "who is Orson kovats the problem is that",
      "offset": 4931.92,
      "duration": 5.719
    },
    {
      "lang": "en",
      "text": "the assistant will not just tell you oh",
      "offset": 4935.44,
      "duration": 4.719
    },
    {
      "lang": "en",
      "text": "I don't know even if the assistant and",
      "offset": 4937.639,
      "duration": 5.401
    },
    {
      "lang": "en",
      "text": "the language model itself might know",
      "offset": 4940.159,
      "duration": 4.441
    },
    {
      "lang": "en",
      "text": "inside its features inside its",
      "offset": 4943.04,
      "duration": 3.48
    },
    {
      "lang": "en",
      "text": "activations inside of its brain sort of",
      "offset": 4944.6,
      "duration": 3.4
    },
    {
      "lang": "en",
      "text": "it might know that this person is like",
      "offset": 4946.52,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "not someone that um that is that it's",
      "offset": 4948,
      "duration": 4.719
    },
    {
      "lang": "en",
      "text": "familiar with even if some part of the",
      "offset": 4950.84,
      "duration": 4.28
    },
    {
      "lang": "en",
      "text": "network kind of knows that in some sense",
      "offset": 4952.719,
      "duration": 4.761
    },
    {
      "lang": "en",
      "text": "the uh saying that oh I don't know who",
      "offset": 4955.12,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "this is is is not going to happen",
      "offset": 4957.48,
      "duration": 5.32
    },
    {
      "lang": "en",
      "text": "because the model statistically imitates",
      "offset": 4960.32,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "is training set in the training set the",
      "offset": 4962.8,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "questions of the form who is blah are",
      "offset": 4965.6,
      "duration": 4.119
    },
    {
      "lang": "en",
      "text": "confidently answered with the correct",
      "offset": 4967.6,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "answer and so it's going to take on the",
      "offset": 4969.719,
      "duration": 4.241
    },
    {
      "lang": "en",
      "text": "style of the answer and it's going to do",
      "offset": 4972,
      "duration": 3.32
    },
    {
      "lang": "en",
      "text": "its best it's going to give you",
      "offset": 4973.96,
      "duration": 3.64
    },
    {
      "lang": "en",
      "text": "statistically the most likely guess and",
      "offset": 4975.32,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "it's just going to basically make stuff",
      "offset": 4977.6,
      "duration": 3.72
    },
    {
      "lang": "en",
      "text": "up because these models again we just",
      "offset": 4978.92,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "talked about it is they don't have",
      "offset": 4981.32,
      "duration": 2.76
    },
    {
      "lang": "en",
      "text": "access to the internet they're not doing",
      "offset": 4982.76,
      "duration": 3.64
    },
    {
      "lang": "en",
      "text": "research these are statistical token",
      "offset": 4984.08,
      "duration": 4.599
    },
    {
      "lang": "en",
      "text": "tumblers as I call them uh is just",
      "offset": 4986.4,
      "duration": 3.72
    },
    {
      "lang": "en",
      "text": "trying to sample the next token in the",
      "offset": 4988.679,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "sequence and it's going to basically",
      "offset": 4990.12,
      "duration": 3.72
    },
    {
      "lang": "en",
      "text": "make stuff up so let's take a look at",
      "offset": 4992.28,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "what this looks",
      "offset": 4993.84,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "like I have here what's called the",
      "offset": 4995.32,
      "duration": 5.319
    },
    {
      "lang": "en",
      "text": "inference playground from hugging face",
      "offset": 4997.6,
      "duration": 5.119
    },
    {
      "lang": "en",
      "text": "and I am on purpose picking on a model",
      "offset": 5000.639,
      "duration": 4.801
    },
    {
      "lang": "en",
      "text": "called Falcon 7B which is an old model",
      "offset": 5002.719,
      "duration": 4.801
    },
    {
      "lang": "en",
      "text": "this is a few years ago now so it's an",
      "offset": 5005.44,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "older model So It suffers from",
      "offset": 5007.52,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "hallucinations and as I mentioned this",
      "offset": 5008.96,
      "duration": 4.52
    },
    {
      "lang": "en",
      "text": "has improved over time recently but",
      "offset": 5011.04,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "let's say who is Orson kovats let's ask",
      "offset": 5013.48,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "Falcon 7B instruct",
      "offset": 5015.44,
      "duration": 4.68
    },
    {
      "lang": "en",
      "text": "run oh yeah Orson kovat is an American",
      "offset": 5017.639,
      "duration": 4.961
    },
    {
      "lang": "en",
      "text": "author and science uh fiction writer",
      "offset": 5020.12,
      "duration": 4.519
    },
    {
      "lang": "en",
      "text": "okay this is totally false it's",
      "offset": 5022.6,
      "duration": 4.36
    },
    {
      "lang": "en",
      "text": "hallucination let's try again these are",
      "offset": 5024.639,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "statistical systems right so we can",
      "offset": 5026.96,
      "duration": 4.279
    },
    {
      "lang": "en",
      "text": "resample this time Orson kovat is a",
      "offset": 5028.719,
      "duration": 5.241
    },
    {
      "lang": "en",
      "text": "fictional character from this 1950s TV",
      "offset": 5031.239,
      "duration": 6.561
    },
    {
      "lang": "en",
      "text": "show it's total BS right let's try again",
      "offset": 5033.96,
      "duration": 5.92
    },
    {
      "lang": "en",
      "text": "he's a former minor league baseball",
      "offset": 5037.8,
      "duration": 4.76
    },
    {
      "lang": "en",
      "text": "player okay so basically the model",
      "offset": 5039.88,
      "duration": 4.6
    },
    {
      "lang": "en",
      "text": "doesn't know and it's given us lots of",
      "offset": 5042.56,
      "duration": 3.96
    },
    {
      "lang": "en",
      "text": "different answers because it doesn't",
      "offset": 5044.48,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "know it's just kind of like sampling",
      "offset": 5046.52,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "from these probabilities the model",
      "offset": 5048.32,
      "duration": 3.8
    },
    {
      "lang": "en",
      "text": "starts with the tokens who is oron",
      "offset": 5050.44,
      "duration": 4.36
    },
    {
      "lang": "en",
      "text": "kovats assistant and then it comes in",
      "offset": 5052.12,
      "duration": 5.8
    },
    {
      "lang": "en",
      "text": "here and it's get it's getting these",
      "offset": 5054.8,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "probabilities and it's just sampling",
      "offset": 5057.92,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "from the probabilities and it just like",
      "offset": 5059.199,
      "duration": 4.841
    },
    {
      "lang": "en",
      "text": "comes up with stuff and the stuff is",
      "offset": 5060.96,
      "duration": 3.96
    },
    {
      "lang": "en",
      "text": "actually",
      "offset": 5064.04,
      "duration": 3.8
    },
    {
      "lang": "en",
      "text": "statistically consistent with the style",
      "offset": 5064.92,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "of the answer in its training set and",
      "offset": 5067.84,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "it's just doing that but you and I",
      "offset": 5069.96,
      "duration": 3.96
    },
    {
      "lang": "en",
      "text": "experiened it as a madeup factual",
      "offset": 5071.76,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "knowledge but keep in mind that uh the",
      "offset": 5073.92,
      "duration": 3.96
    },
    {
      "lang": "en",
      "text": "model basically doesn't know and it's",
      "offset": 5076.32,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "just imitating the format of the answer",
      "offset": 5077.88,
      "duration": 3.4
    },
    {
      "lang": "en",
      "text": "and it's not going to go off and look it",
      "offset": 5080,
      "duration": 4.199
    },
    {
      "lang": "en",
      "text": "up uh because it's just imitating again",
      "offset": 5081.28,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "the answer so how can we uh mitigate",
      "offset": 5084.199,
      "duration": 4.241
    },
    {
      "lang": "en",
      "text": "this because for example when we go to",
      "offset": 5087.04,
      "duration": 3.88
    },
    {
      "lang": "en",
      "text": "chat apt and I say who is oron kovats",
      "offset": 5088.44,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "and I'm now asking the stateoftheart",
      "offset": 5090.92,
      "duration": 4.12
    },
    {
      "lang": "en",
      "text": "state-of-the-art model from open AI",
      "offset": 5092.6,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "this model will tell",
      "offset": 5095.04,
      "duration": 5.599
    },
    {
      "lang": "en",
      "text": "you oh so this model is actually is even",
      "offset": 5096.84,
      "duration": 5.92
    },
    {
      "lang": "en",
      "text": "smarter because you saw very briefly it",
      "offset": 5100.639,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "said searching the web uh we're going to",
      "offset": 5102.76,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "cover this later um it's actually trying",
      "offset": 5104.8,
      "duration": 6.64
    },
    {
      "lang": "en",
      "text": "to do tool use and",
      "offset": 5107.32,
      "duration": 6.16
    },
    {
      "lang": "en",
      "text": "uh kind of just like came up with some",
      "offset": 5111.44,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "kind of a story but I want to just who",
      "offset": 5113.48,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "or Kovach did not use any tools I don't",
      "offset": 5115.92,
      "duration": 6.199
    },
    {
      "lang": "en",
      "text": "want it to do web",
      "offset": 5119.48,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "search there's a wellknown historical or",
      "offset": 5122.119,
      "duration": 5.161
    },
    {
      "lang": "en",
      "text": "public figure named or oron kovats so",
      "offset": 5124.52,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "this model is not going to make up stuff",
      "offset": 5127.28,
      "duration": 3.8
    },
    {
      "lang": "en",
      "text": "this model knows that it doesn't know",
      "offset": 5129.4,
      "duration": 3.4
    },
    {
      "lang": "en",
      "text": "and it tells you that it doesn't appear",
      "offset": 5131.08,
      "duration": 4.559
    },
    {
      "lang": "en",
      "text": "to be a person that this model knows so",
      "offset": 5132.8,
      "duration": 4.439
    },
    {
      "lang": "en",
      "text": "somehow we sort of improved",
      "offset": 5135.639,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "hallucinations even though they clearly",
      "offset": 5137.239,
      "duration": 4.761
    },
    {
      "lang": "en",
      "text": "are an issue in older models and it",
      "offset": 5139.48,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "makes totally uh sense why you would be",
      "offset": 5142,
      "duration": 4.199
    },
    {
      "lang": "en",
      "text": "getting these kinds of answers if this",
      "offset": 5144.44,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "is what your training set looks like so",
      "offset": 5146.199,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "how do we fix this okay well clearly we",
      "offset": 5147.96,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "need some examples in our data set that",
      "offset": 5150.52,
      "duration": 4.199
    },
    {
      "lang": "en",
      "text": "where the correct answer for the",
      "offset": 5153.08,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "assistant is that the model doesn't know",
      "offset": 5154.719,
      "duration": 4.881
    },
    {
      "lang": "en",
      "text": "about some particular fact but we only",
      "offset": 5157.08,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "need to have those answers be produced",
      "offset": 5159.6,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "in the cases where the model actually",
      "offset": 5162.04,
      "duration": 3.4
    },
    {
      "lang": "en",
      "text": "doesn't know and so the question is how",
      "offset": 5163.52,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "do we know what the model knows or",
      "offset": 5165.44,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "doesn't know well we can empirically",
      "offset": 5167.04,
      "duration": 4.44
    },
    {
      "lang": "en",
      "text": "probe the model to figure that out so",
      "offset": 5169.04,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "let's take a look at for example how",
      "offset": 5171.48,
      "duration": 5
    },
    {
      "lang": "en",
      "text": "meta uh dealt with hallucinations for",
      "offset": 5173.44,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "the Llama 3 series of models as an",
      "offset": 5176.48,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "example so in this paper that they",
      "offset": 5178.48,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "published from meta we can go into",
      "offset": 5180.32,
      "duration": 4.76
    },
    {
      "lang": "en",
      "text": "hallucinations",
      "offset": 5182.08,
      "duration": 3
    },
    {
      "lang": "en",
      "text": "which they call here factuality and they",
      "offset": 5185.84,
      "duration": 4.12
    },
    {
      "lang": "en",
      "text": "describe the procedure by which they",
      "offset": 5187.92,
      "duration": 4.36
    },
    {
      "lang": "en",
      "text": "basically interrogate the model to",
      "offset": 5189.96,
      "duration": 3.759
    },
    {
      "lang": "en",
      "text": "figure out what it knows and doesn't",
      "offset": 5192.28,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "know to figure out sort of like the",
      "offset": 5193.719,
      "duration": 4.52
    },
    {
      "lang": "en",
      "text": "boundary of its knowledge and then they",
      "offset": 5195.32,
      "duration": 6.56
    },
    {
      "lang": "en",
      "text": "add examples to the training set where",
      "offset": 5198.239,
      "duration": 6.081
    },
    {
      "lang": "en",
      "text": "for the things where the model doesn't",
      "offset": 5201.88,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "know them the correct answer is that the",
      "offset": 5204.32,
      "duration": 4.52
    },
    {
      "lang": "en",
      "text": "model doesn't know them which sounds",
      "offset": 5206.6,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "like a very easy thing to do in",
      "offset": 5208.84,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "principle but this roughly fixes the",
      "offset": 5210.52,
      "duration": 4.36
    },
    {
      "lang": "en",
      "text": "issue and the the reason it fixes the",
      "offset": 5213,
      "duration": 3.08
    },
    {
      "lang": "en",
      "text": "issue is",
      "offset": 5214.88,
      "duration": 4.6
    },
    {
      "lang": "en",
      "text": "because remember like the model might",
      "offset": 5216.08,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "actually have a pretty good model of its",
      "offset": 5219.48,
      "duration": 4.719
    },
    {
      "lang": "en",
      "text": "self knowledge inside the network so",
      "offset": 5221.76,
      "duration": 4.68
    },
    {
      "lang": "en",
      "text": "remember we looked at the network and",
      "offset": 5224.199,
      "duration": 4.52
    },
    {
      "lang": "en",
      "text": "all these neurons inside the network you",
      "offset": 5226.44,
      "duration": 3.48
    },
    {
      "lang": "en",
      "text": "might imagine that there's a neuron",
      "offset": 5228.719,
      "duration": 3.241
    },
    {
      "lang": "en",
      "text": "somewhere in the network that sort of",
      "offset": 5229.92,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "like lights up for when the model is",
      "offset": 5231.96,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "uncertain but the problem is that the",
      "offset": 5234.4,
      "duration": 4.12
    },
    {
      "lang": "en",
      "text": "activation of that neuron is not",
      "offset": 5237,
      "duration": 3.96
    },
    {
      "lang": "en",
      "text": "currently wired up to the model actually",
      "offset": 5238.52,
      "duration": 4.84
    },
    {
      "lang": "en",
      "text": "saying in words that it doesn't know so",
      "offset": 5240.96,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "even though the internal of the neural",
      "offset": 5243.36,
      "duration": 3.4
    },
    {
      "lang": "en",
      "text": "network no because there's some neurons",
      "offset": 5244.8,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "that represent that the model uh will",
      "offset": 5246.76,
      "duration": 4.84
    },
    {
      "lang": "en",
      "text": "not surface that it will instead take",
      "offset": 5249.76,
      "duration": 3.32
    },
    {
      "lang": "en",
      "text": "its best guess so that it sounds",
      "offset": 5251.6,
      "duration": 4.039
    },
    {
      "lang": "en",
      "text": "confident um just like it sees in a",
      "offset": 5253.08,
      "duration": 4.28
    },
    {
      "lang": "en",
      "text": "training set so we need to basically",
      "offset": 5255.639,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "interrogate the model and allow it to",
      "offset": 5257.36,
      "duration": 4.12
    },
    {
      "lang": "en",
      "text": "say I don't know in the cases that it",
      "offset": 5259.639,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "doesn't know so let me take you through",
      "offset": 5261.48,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "what meta roughly does so basically what",
      "offset": 5263.48,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "they do is here I have an example uh",
      "offset": 5265.48,
      "duration": 6.159
    },
    {
      "lang": "en",
      "text": "Dominic kek is uh the featured article",
      "offset": 5268.28,
      "duration": 6.04
    },
    {
      "lang": "en",
      "text": "today so I just went there randomly and",
      "offset": 5271.639,
      "duration": 4.281
    },
    {
      "lang": "en",
      "text": "what they do is basically they take a",
      "offset": 5274.32,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "random document in a training set and",
      "offset": 5275.92,
      "duration": 5.4
    },
    {
      "lang": "en",
      "text": "they take a paragraph and then they use",
      "offset": 5278.239,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "an llm to construct questions about that",
      "offset": 5281.32,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "paragraph so for example I did that with",
      "offset": 5284.239,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "chat GPT",
      "offset": 5286.52,
      "duration": 5.96
    },
    {
      "lang": "en",
      "text": "here so I said here's a paragraph from",
      "offset": 5289.199,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "this document generate three specific",
      "offset": 5292.48,
      "duration": 3.4
    },
    {
      "lang": "en",
      "text": "factual questions based on this",
      "offset": 5294.639,
      "duration": 2.961
    },
    {
      "lang": "en",
      "text": "paragraph and give me the questions and",
      "offset": 5295.88,
      "duration": 4.6
    },
    {
      "lang": "en",
      "text": "the answers and so the llms are already",
      "offset": 5297.6,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "good enough to create and reframe this",
      "offset": 5300.48,
      "duration": 5.48
    },
    {
      "lang": "en",
      "text": "information so if the information is in",
      "offset": 5303.28,
      "duration": 6.32
    },
    {
      "lang": "en",
      "text": "the context window um of this llm this",
      "offset": 5305.96,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "actually works pretty well it doesn't",
      "offset": 5309.6,
      "duration": 3.559
    },
    {
      "lang": "en",
      "text": "have to rely on its memory it's right",
      "offset": 5310.92,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "there in the context window and so it",
      "offset": 5313.159,
      "duration": 4.601
    },
    {
      "lang": "en",
      "text": "can basically reframe that information",
      "offset": 5315.56,
      "duration": 4.52
    },
    {
      "lang": "en",
      "text": "with fairly high accuracy so for example",
      "offset": 5317.76,
      "duration": 4.2
    },
    {
      "lang": "en",
      "text": "can generate questions for us like for",
      "offset": 5320.08,
      "duration": 4.52
    },
    {
      "lang": "en",
      "text": "which team did he play here's the answer",
      "offset": 5321.96,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "how many cups did he win Etc and now",
      "offset": 5324.6,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "what we have to do is we have some",
      "offset": 5327,
      "duration": 3.119
    },
    {
      "lang": "en",
      "text": "question and answers and now we want to",
      "offset": 5328.44,
      "duration": 3.4
    },
    {
      "lang": "en",
      "text": "interrogate the model so roughly",
      "offset": 5330.119,
      "duration": 3.321
    },
    {
      "lang": "en",
      "text": "speaking what we'll do is we'll take our",
      "offset": 5331.84,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "questions and we'll go to our model",
      "offset": 5333.44,
      "duration": 5.64
    },
    {
      "lang": "en",
      "text": "which would be uh say llama uh in meta",
      "offset": 5335.52,
      "duration": 5.719
    },
    {
      "lang": "en",
      "text": "but let's just interrogate mol 7B here",
      "offset": 5339.08,
      "duration": 4.92
    },
    {
      "lang": "en",
      "text": "as an example that's another model so",
      "offset": 5341.239,
      "duration": 5.96
    },
    {
      "lang": "en",
      "text": "does this model know about this answer",
      "offset": 5344,
      "duration": 5.239
    },
    {
      "lang": "en",
      "text": "let's take a",
      "offset": 5347.199,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "look uh so he played for Buffalo Sabers",
      "offset": 5349.239,
      "duration": 5.761
    },
    {
      "lang": "en",
      "text": "right so the model knows and the the way",
      "offset": 5352.159,
      "duration": 4.801
    },
    {
      "lang": "en",
      "text": "that you can programmatically decide is",
      "offset": 5355,
      "duration": 3.8
    },
    {
      "lang": "en",
      "text": "basically we're going to take this",
      "offset": 5356.96,
      "duration": 3.759
    },
    {
      "lang": "en",
      "text": "answer from the model and we're going to",
      "offset": 5358.8,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "compare it to the correct answer and",
      "offset": 5360.719,
      "duration": 4.241
    },
    {
      "lang": "en",
      "text": "again the model model are good enough to",
      "offset": 5363.52,
      "duration": 2.84
    },
    {
      "lang": "en",
      "text": "do this automatically so there's no",
      "offset": 5364.96,
      "duration": 3.679
    },
    {
      "lang": "en",
      "text": "humans involved here we can take uh",
      "offset": 5366.36,
      "duration": 4.04
    },
    {
      "lang": "en",
      "text": "basically the answer from the model and",
      "offset": 5368.639,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "we can use another llm judge to check if",
      "offset": 5370.4,
      "duration": 5.48
    },
    {
      "lang": "en",
      "text": "that is correct according to this answer",
      "offset": 5373.679,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "and if it is correct that means that the",
      "offset": 5375.88,
      "duration": 3.08
    },
    {
      "lang": "en",
      "text": "model probably knows so what we're going",
      "offset": 5377.199,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "to do is we're going to do this maybe a",
      "offset": 5378.96,
      "duration": 3.719
    },
    {
      "lang": "en",
      "text": "few times so okay it knows it's Buffalo",
      "offset": 5380.88,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "Savers let's drag",
      "offset": 5382.679,
      "duration": 8.321
    },
    {
      "lang": "en",
      "text": "in um Buffalo Sabers let's try one more",
      "offset": 5385.36,
      "duration": 8.759
    },
    {
      "lang": "en",
      "text": "time Buffalo Sabers so we asked three",
      "offset": 5391,
      "duration": 4.679
    },
    {
      "lang": "en",
      "text": "times about this factual question and",
      "offset": 5394.119,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "the model seems to know so everything is",
      "offset": 5395.679,
      "duration": 5.281
    },
    {
      "lang": "en",
      "text": "great now let's try the second question",
      "offset": 5398.28,
      "duration": 4.68
    },
    {
      "lang": "en",
      "text": "how many Stanley Cups did he",
      "offset": 5400.96,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "win and again let's interrogate the",
      "offset": 5402.96,
      "duration": 3.279
    },
    {
      "lang": "en",
      "text": "model about that and the correct answer",
      "offset": 5404.96,
      "duration": 3.239
    },
    {
      "lang": "en",
      "text": "is",
      "offset": 5406.239,
      "duration": 7.321
    },
    {
      "lang": "en",
      "text": "two so um here the model claims that he",
      "offset": 5408.199,
      "duration": 9.321
    },
    {
      "lang": "en",
      "text": "won um four times which is not correct",
      "offset": 5413.56,
      "duration": 6.559
    },
    {
      "lang": "en",
      "text": "right it doesn't match two so the model",
      "offset": 5417.52,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "doesn't know it's making stuff up let's",
      "offset": 5420.119,
      "duration": 5.161
    },
    {
      "lang": "en",
      "text": "try again",
      "offset": 5422,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "um so here the model again it's kind of",
      "offset": 5427.92,
      "duration": 6.08
    },
    {
      "lang": "en",
      "text": "like making stuff up right let's",
      "offset": 5430.159,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "Dragon here it says did he did not even",
      "offset": 5434.199,
      "duration": 5.48
    },
    {
      "lang": "en",
      "text": "did not win during his career so",
      "offset": 5437.56,
      "duration": 3.88
    },
    {
      "lang": "en",
      "text": "obviously the model doesn't know and the",
      "offset": 5439.679,
      "duration": 3.281
    },
    {
      "lang": "en",
      "text": "way we can programmatically tell again",
      "offset": 5441.44,
      "duration": 3.719
    },
    {
      "lang": "en",
      "text": "is we interrogate the model three times",
      "offset": 5442.96,
      "duration": 4.36
    },
    {
      "lang": "en",
      "text": "and we compare its answers maybe three",
      "offset": 5445.159,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "times five times whatever it is to the",
      "offset": 5447.32,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "correct answer and if the model doesn't",
      "offset": 5449.239,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "know then we know that the model doesn't",
      "offset": 5451.639,
      "duration": 2.801
    },
    {
      "lang": "en",
      "text": "know this question",
      "offset": 5453.239,
      "duration": 3.4
    },
    {
      "lang": "en",
      "text": "and then what we do is we take this",
      "offset": 5454.44,
      "duration": 5.16
    },
    {
      "lang": "en",
      "text": "question we create a new conversation in",
      "offset": 5456.639,
      "duration": 4.881
    },
    {
      "lang": "en",
      "text": "the training set so we're going to add a",
      "offset": 5459.6,
      "duration": 4.28
    },
    {
      "lang": "en",
      "text": "new conversation training set and when",
      "offset": 5461.52,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "the question is how many Stanley Cups",
      "offset": 5463.88,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "did he win the answer is I'm sorry I",
      "offset": 5465.36,
      "duration": 5.279
    },
    {
      "lang": "en",
      "text": "don't know or I don't remember and",
      "offset": 5468.36,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "that's the correct answer for this",
      "offset": 5470.639,
      "duration": 3.201
    },
    {
      "lang": "en",
      "text": "question because we interrogated the",
      "offset": 5472.28,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "model and we saw that that's the case if",
      "offset": 5473.84,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "you do this for many different types of",
      "offset": 5475.96,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "uh questions for many different types of",
      "offset": 5478.4,
      "duration": 4.68
    },
    {
      "lang": "en",
      "text": "documents you are giving the model an",
      "offset": 5480.92,
      "duration": 4.68
    },
    {
      "lang": "en",
      "text": "opportunity to in its training set",
      "offset": 5483.08,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "refuse to say based on its knowledge and",
      "offset": 5485.6,
      "duration": 4.639
    },
    {
      "lang": "en",
      "text": "if you just have a few examples of that",
      "offset": 5488.36,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "in your training set the model will know",
      "offset": 5490.239,
      "duration": 5.241
    },
    {
      "lang": "en",
      "text": "um and and has the opportunity to learn",
      "offset": 5493.4,
      "duration": 4.36
    },
    {
      "lang": "en",
      "text": "the association of this knowledge-based",
      "offset": 5495.48,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "refusal to this internal neuron",
      "offset": 5497.76,
      "duration": 5.359
    },
    {
      "lang": "en",
      "text": "somewhere in its Network that we presume",
      "offset": 5501.08,
      "duration": 4.039
    },
    {
      "lang": "en",
      "text": "exists and empirically this turns out to",
      "offset": 5503.119,
      "duration": 4.241
    },
    {
      "lang": "en",
      "text": "be probably the case and it can learn",
      "offset": 5505.119,
      "duration": 4.241
    },
    {
      "lang": "en",
      "text": "that Association that hey when this",
      "offset": 5507.36,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "neuron of uncertainty is high then I",
      "offset": 5509.36,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "actually don't know and I'm allowed to",
      "offset": 5512.08,
      "duration": 4.2
    },
    {
      "lang": "en",
      "text": "say that I'm sorry but I don't think I",
      "offset": 5514.4,
      "duration": 5.16
    },
    {
      "lang": "en",
      "text": "remember this Etc and if you have these",
      "offset": 5516.28,
      "duration": 5.24
    },
    {
      "lang": "en",
      "text": "uh examples in your training set then",
      "offset": 5519.56,
      "duration": 4.28
    },
    {
      "lang": "en",
      "text": "this is a large mitigation for",
      "offset": 5521.52,
      "duration": 4.04
    },
    {
      "lang": "en",
      "text": "hallucination and that's roughly",
      "offset": 5523.84,
      "duration": 4.2
    },
    {
      "lang": "en",
      "text": "speaking why chpt is able to do stuff",
      "offset": 5525.56,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "like this as well so these are kinds of",
      "offset": 5528.04,
      "duration": 4.04
    },
    {
      "lang": "en",
      "text": "uh mitigations that people have",
      "offset": 5530.52,
      "duration": 3.599
    },
    {
      "lang": "en",
      "text": "implemented and that have improved the",
      "offset": 5532.08,
      "duration": 4.76
    },
    {
      "lang": "en",
      "text": "factuality issue over time okay so I've",
      "offset": 5534.119,
      "duration": 5.56
    },
    {
      "lang": "en",
      "text": "described mitigation number one for",
      "offset": 5536.84,
      "duration": 4.76
    },
    {
      "lang": "en",
      "text": "basically mitigating the hallucinations",
      "offset": 5539.679,
      "duration": 4.681
    },
    {
      "lang": "en",
      "text": "issue now we can actually do much better",
      "offset": 5541.6,
      "duration": 5.72
    },
    {
      "lang": "en",
      "text": "than that uh it's instead of just saying",
      "offset": 5544.36,
      "duration": 5.4
    },
    {
      "lang": "en",
      "text": "that we don't know uh we can introduce",
      "offset": 5547.32,
      "duration": 4.68
    },
    {
      "lang": "en",
      "text": "an additional mitigation number two to",
      "offset": 5549.76,
      "duration": 4.04
    },
    {
      "lang": "en",
      "text": "give the llm an opportunity to be",
      "offset": 5552,
      "duration": 4.44
    },
    {
      "lang": "en",
      "text": "factual and actually answer the question",
      "offset": 5553.8,
      "duration": 5.319
    },
    {
      "lang": "en",
      "text": "now what do you and I do if I was to ask",
      "offset": 5556.44,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "you a factual question and you don't",
      "offset": 5559.119,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "know uh what would you do um in order to",
      "offset": 5560.6,
      "duration": 5.16
    },
    {
      "lang": "en",
      "text": "answer the question well you could uh go",
      "offset": 5563.679,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "off and do some search and uh use the",
      "offset": 5565.76,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "internet and you could figure out the",
      "offset": 5567.679,
      "duration": 4.04
    },
    {
      "lang": "en",
      "text": "answer and then tell me what that answer",
      "offset": 5569.679,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "is and we can do the exact exact same",
      "offset": 5571.719,
      "duration": 5.201
    },
    {
      "lang": "en",
      "text": "thing with these models so think of the",
      "offset": 5574.239,
      "duration": 4.201
    },
    {
      "lang": "en",
      "text": "knowledge inside the neural network",
      "offset": 5576.92,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "inside its billions of parameters think",
      "offset": 5578.44,
      "duration": 4.52
    },
    {
      "lang": "en",
      "text": "of that as kind of a vague recollection",
      "offset": 5581.08,
      "duration": 4.599
    },
    {
      "lang": "en",
      "text": "of the things that the model has seen",
      "offset": 5582.96,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "during its training during the",
      "offset": 5585.679,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "pre-training stage a long time ago so",
      "offset": 5587.04,
      "duration": 3.679
    },
    {
      "lang": "en",
      "text": "think of that knowledge in the",
      "offset": 5589.52,
      "duration": 3.639
    },
    {
      "lang": "en",
      "text": "parameters as something you read a month",
      "offset": 5590.719,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "ago and if you keep reading something",
      "offset": 5593.159,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "then you will remember it and the model",
      "offset": 5595.679,
      "duration": 3.161
    },
    {
      "lang": "en",
      "text": "remembers that but if it's something",
      "offset": 5597.239,
      "duration": 2.88
    },
    {
      "lang": "en",
      "text": "rare then you probably don't have a",
      "offset": 5598.84,
      "duration": 2.52
    },
    {
      "lang": "en",
      "text": "really good recollection of that",
      "offset": 5600.119,
      "duration": 3.281
    },
    {
      "lang": "en",
      "text": "information but what you and I do is we",
      "offset": 5601.36,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "just go and look it up now when you go",
      "offset": 5603.4,
      "duration": 3.239
    },
    {
      "lang": "en",
      "text": "and look it up what you're doing",
      "offset": 5605.52,
      "duration": 2.639
    },
    {
      "lang": "en",
      "text": "basically is like you're refreshing your",
      "offset": 5606.639,
      "duration": 3.881
    },
    {
      "lang": "en",
      "text": "working memory with information and then",
      "offset": 5608.159,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "you're able to sort of like retrieve it",
      "offset": 5610.52,
      "duration": 3.719
    },
    {
      "lang": "en",
      "text": "talk about it or Etc so we need some",
      "offset": 5612.08,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "equivalent of allowing the model to",
      "offset": 5614.239,
      "duration": 4.681
    },
    {
      "lang": "en",
      "text": "refresh its memory or its recollection",
      "offset": 5616.32,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "and we can do that by introducing tools",
      "offset": 5618.92,
      "duration": 3.759
    },
    {
      "lang": "en",
      "text": "uh for the",
      "offset": 5621.28,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "models so the way we are going to",
      "offset": 5622.679,
      "duration": 3.121
    },
    {
      "lang": "en",
      "text": "approach this is that instead of just",
      "offset": 5624.56,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "saying hey I'm sorry I don't know we can",
      "offset": 5625.8,
      "duration": 7.359
    },
    {
      "lang": "en",
      "text": "attempt to use tools so we can create uh",
      "offset": 5628.4,
      "duration": 5.88
    },
    {
      "lang": "en",
      "text": "a mechanism",
      "offset": 5633.159,
      "duration": 2.841
    },
    {
      "lang": "en",
      "text": "by which the language model can emit",
      "offset": 5634.28,
      "duration": 3.32
    },
    {
      "lang": "en",
      "text": "special tokens and these are tokens that",
      "offset": 5636,
      "duration": 4.6
    },
    {
      "lang": "en",
      "text": "we're going to introduce new tokens so",
      "offset": 5637.6,
      "duration": 4.84
    },
    {
      "lang": "en",
      "text": "for example here I've introduced two",
      "offset": 5640.6,
      "duration": 4.2
    },
    {
      "lang": "en",
      "text": "tokens and I've introduced a format or a",
      "offset": 5642.44,
      "duration": 4.679
    },
    {
      "lang": "en",
      "text": "protocol for how the model is allowed to",
      "offset": 5644.8,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "use these tokens so for example instead",
      "offset": 5647.119,
      "duration": 4.881
    },
    {
      "lang": "en",
      "text": "of answering the question when the model",
      "offset": 5649.76,
      "duration": 4.28
    },
    {
      "lang": "en",
      "text": "does not instead of just saying I don't",
      "offset": 5652,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "know sorry the model has the option now",
      "offset": 5654.04,
      "duration": 4.28
    },
    {
      "lang": "en",
      "text": "to emitting the special token search",
      "offset": 5656.32,
      "duration": 4.28
    },
    {
      "lang": "en",
      "text": "start and this is the query that will go",
      "offset": 5658.32,
      "duration": 4.6
    },
    {
      "lang": "en",
      "text": "to like bing.com in the case of openai",
      "offset": 5660.6,
      "duration": 3.72
    },
    {
      "lang": "en",
      "text": "or say Google search or something like",
      "offset": 5662.92,
      "duration": 3.719
    },
    {
      "lang": "en",
      "text": "that so it will emit the query and then",
      "offset": 5664.32,
      "duration": 6.359
    },
    {
      "lang": "en",
      "text": "it will emit search end and then here",
      "offset": 5666.639,
      "duration": 6.321
    },
    {
      "lang": "en",
      "text": "what will happen is that the program",
      "offset": 5670.679,
      "duration": 4.121
    },
    {
      "lang": "en",
      "text": "that is sampling from the model that is",
      "offset": 5672.96,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "running the inference when it sees the",
      "offset": 5674.8,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "special token search end instead of",
      "offset": 5676.96,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "sampling the next token uh in the",
      "offset": 5679.52,
      "duration": 4.599
    },
    {
      "lang": "en",
      "text": "sequence it will actually pause",
      "offset": 5681.92,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "generating from the model it will go off",
      "offset": 5684.119,
      "duration": 4.881
    },
    {
      "lang": "en",
      "text": "it will open a session with bing.com and",
      "offset": 5686.4,
      "duration": 5.64
    },
    {
      "lang": "en",
      "text": "it will paste the search query into Bing",
      "offset": 5689,
      "duration": 5.239
    },
    {
      "lang": "en",
      "text": "and it will then um get all the text",
      "offset": 5692.04,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "that is retrieved and it will basically",
      "offset": 5694.239,
      "duration": 4.641
    },
    {
      "lang": "en",
      "text": "take that text it will maybe represent",
      "offset": 5696.84,
      "duration": 3.48
    },
    {
      "lang": "en",
      "text": "it again with some other special tokens",
      "offset": 5698.88,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "or something like that and it will take",
      "offset": 5700.32,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "that text and it will copy paste it here",
      "offset": 5702.08,
      "duration": 5.159
    },
    {
      "lang": "en",
      "text": "into what I Tred to like show with the",
      "offset": 5705.28,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "brackets so all that text kind of comes",
      "offset": 5707.239,
      "duration": 5.281
    },
    {
      "lang": "en",
      "text": "here and when the text comes here it",
      "offset": 5709.28,
      "duration": 6.16
    },
    {
      "lang": "en",
      "text": "enters the context window so the model",
      "offset": 5712.52,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "so that text from the web search is now",
      "offset": 5715.44,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "inside the context window that will feed",
      "offset": 5717.48,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "into the neural network and you should",
      "offset": 5720,
      "duration": 3.4
    },
    {
      "lang": "en",
      "text": "think of the context window as kind of",
      "offset": 5721.88,
      "duration": 3.56
    },
    {
      "lang": "en",
      "text": "like the working memory of the model",
      "offset": 5723.4,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "that data that is in the context window",
      "offset": 5725.44,
      "duration": 4.12
    },
    {
      "lang": "en",
      "text": "is directly accessible by the model it",
      "offset": 5727.48,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "directly feeds into the neural network",
      "offset": 5729.56,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "so it's not anymore a vague recollection",
      "offset": 5731.56,
      "duration": 5.32
    },
    {
      "lang": "en",
      "text": "it's data that it it has in the context",
      "offset": 5733.719,
      "duration": 4.721
    },
    {
      "lang": "en",
      "text": "window and is directly available to that",
      "offset": 5736.88,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "model so now when it's sampling the new",
      "offset": 5738.44,
      "duration": 5.199
    },
    {
      "lang": "en",
      "text": "uh tokens here afterwards it can",
      "offset": 5741.36,
      "duration": 4.44
    },
    {
      "lang": "en",
      "text": "reference very easily the data that has",
      "offset": 5743.639,
      "duration": 5.08
    },
    {
      "lang": "en",
      "text": "been copy pasted in there so that's",
      "offset": 5745.8,
      "duration": 6.68
    },
    {
      "lang": "en",
      "text": "roughly how these um how these tools use",
      "offset": 5748.719,
      "duration": 5.48
    },
    {
      "lang": "en",
      "text": "uh tools uh function",
      "offset": 5752.48,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "and so web search is just one of the",
      "offset": 5754.199,
      "duration": 2.401
    },
    {
      "lang": "en",
      "text": "tools we're going to look at some of the",
      "offset": 5755.52,
      "duration": 3.48
    },
    {
      "lang": "en",
      "text": "other tools in a bit uh but basically",
      "offset": 5756.6,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "you introduce new tokens you introduce",
      "offset": 5759,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "some schema by which the model can",
      "offset": 5760.84,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "utilize these tokens and can call these",
      "offset": 5762.44,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "special functions like web search",
      "offset": 5764.92,
      "duration": 3.96
    },
    {
      "lang": "en",
      "text": "functions and how do you teach the model",
      "offset": 5766.36,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "how to correctly use these tools like",
      "offset": 5768.88,
      "duration": 3.64
    },
    {
      "lang": "en",
      "text": "say web search search start search end",
      "offset": 5770.52,
      "duration": 3.719
    },
    {
      "lang": "en",
      "text": "Etc well again you do that through",
      "offset": 5772.52,
      "duration": 4.119
    },
    {
      "lang": "en",
      "text": "training sets so we need now to have a",
      "offset": 5774.239,
      "duration": 4.601
    },
    {
      "lang": "en",
      "text": "bunch of data and a bunch of",
      "offset": 5776.639,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "conversations that show the model by",
      "offset": 5778.84,
      "duration": 5.56
    },
    {
      "lang": "en",
      "text": "example how to use web search so what",
      "offset": 5781.119,
      "duration": 4.761
    },
    {
      "lang": "en",
      "text": "are the what are the settings where you",
      "offset": 5784.4,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "are using the search um and what does",
      "offset": 5785.88,
      "duration": 4.6
    },
    {
      "lang": "en",
      "text": "that look like and here's by example how",
      "offset": 5788.08,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "you start a search and the search Etc",
      "offset": 5790.48,
      "duration": 4.92
    },
    {
      "lang": "en",
      "text": "and uh if you have a few thousand maybe",
      "offset": 5793.36,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "examples of that in your training set",
      "offset": 5795.4,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "the model will actually do a pretty good",
      "offset": 5796.96,
      "duration": 3.96
    },
    {
      "lang": "en",
      "text": "job of understanding uh how this tool",
      "offset": 5798.76,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "works and it will know how to sort of",
      "offset": 5800.92,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "structure its queries and of course",
      "offset": 5803,
      "duration": 4.199
    },
    {
      "lang": "en",
      "text": "because of the pre-training data set and",
      "offset": 5804.92,
      "duration": 3.719
    },
    {
      "lang": "en",
      "text": "its understanding of the world it",
      "offset": 5807.199,
      "duration": 2.681
    },
    {
      "lang": "en",
      "text": "actually kind of understands what a web",
      "offset": 5808.639,
      "duration": 3.121
    },
    {
      "lang": "en",
      "text": "search is and so it actually kind of has",
      "offset": 5809.88,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "a pretty good native understanding",
      "offset": 5811.76,
      "duration": 4.28
    },
    {
      "lang": "en",
      "text": "um of what kind of stuff is a good",
      "offset": 5814.199,
      "duration": 4.121
    },
    {
      "lang": "en",
      "text": "search query um and so it all kind of",
      "offset": 5816.04,
      "duration": 4.119
    },
    {
      "lang": "en",
      "text": "just like works you just need a little",
      "offset": 5818.32,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "bit of a few examples to show it how to",
      "offset": 5820.159,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "use this new tool and then it can lean",
      "offset": 5822.639,
      "duration": 4.361
    },
    {
      "lang": "en",
      "text": "on it to retrieve information and uh put",
      "offset": 5824.56,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "it in the context window and that's",
      "offset": 5827,
      "duration": 3.08
    },
    {
      "lang": "en",
      "text": "equivalent to you and I looking",
      "offset": 5828.639,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "something up because once it's in the",
      "offset": 5830.08,
      "duration": 3.559
    },
    {
      "lang": "en",
      "text": "context it's in the working memory and",
      "offset": 5832.239,
      "duration": 3.761
    },
    {
      "lang": "en",
      "text": "it's very easy to manipulate and access",
      "offset": 5833.639,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "so that's what we saw a few minutes ago",
      "offset": 5836,
      "duration": 4.52
    },
    {
      "lang": "en",
      "text": "when I was searching on chat GPT for who",
      "offset": 5838.119,
      "duration": 4.881
    },
    {
      "lang": "en",
      "text": "is Orson kovats the chat GPT language",
      "offset": 5840.52,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "model decided Ed that this is some kind",
      "offset": 5843,
      "duration": 4.92
    },
    {
      "lang": "en",
      "text": "of a rare um individual or something",
      "offset": 5844.76,
      "duration": 4.919
    },
    {
      "lang": "en",
      "text": "like that and instead of giving me an",
      "offset": 5847.92,
      "duration": 3.719
    },
    {
      "lang": "en",
      "text": "answer from its memory it decided that",
      "offset": 5849.679,
      "duration": 3.721
    },
    {
      "lang": "en",
      "text": "it will sample a special token that is",
      "offset": 5851.639,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "going to do web search and we saw",
      "offset": 5853.4,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "briefly something flash it was like",
      "offset": 5855.159,
      "duration": 3.281
    },
    {
      "lang": "en",
      "text": "using the web tool or something like",
      "offset": 5856.92,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "that so it briefly said that and then we",
      "offset": 5858.44,
      "duration": 3.48
    },
    {
      "lang": "en",
      "text": "waited for like two seconds and then it",
      "offset": 5860.44,
      "duration": 3.239
    },
    {
      "lang": "en",
      "text": "generated this and you see how it's",
      "offset": 5861.92,
      "duration": 4.04
    },
    {
      "lang": "en",
      "text": "creating references here and so it's",
      "offset": 5863.679,
      "duration": 6.361
    },
    {
      "lang": "en",
      "text": "citing sources so what happened here is",
      "offset": 5865.96,
      "duration": 6.52
    },
    {
      "lang": "en",
      "text": "it went off it did a web web search it",
      "offset": 5870.04,
      "duration": 5
    },
    {
      "lang": "en",
      "text": "found these sources and these URLs and",
      "offset": 5872.48,
      "duration": 6.48
    },
    {
      "lang": "en",
      "text": "the text of these web pages was all",
      "offset": 5875.04,
      "duration": 6.119
    },
    {
      "lang": "en",
      "text": "stuffed in between here and it's not",
      "offset": 5878.96,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "showing here but it's it's basically",
      "offset": 5881.159,
      "duration": 5.48
    },
    {
      "lang": "en",
      "text": "stuffed as text in between here and now",
      "offset": 5882.88,
      "duration": 5.92
    },
    {
      "lang": "en",
      "text": "it sees that text and now it kind of",
      "offset": 5886.639,
      "duration": 4.681
    },
    {
      "lang": "en",
      "text": "references it and says that okay it",
      "offset": 5888.8,
      "duration": 4.359
    },
    {
      "lang": "en",
      "text": "could be these people citation could be",
      "offset": 5891.32,
      "duration": 4.2
    },
    {
      "lang": "en",
      "text": "those people citation Etc so that's what",
      "offset": 5893.159,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "happened here and that's what and that's",
      "offset": 5895.52,
      "duration": 3.88
    },
    {
      "lang": "en",
      "text": "why when I said who is Orson kovats I",
      "offset": 5897.48,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "could also say don't use any tools and",
      "offset": 5899.4,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "then that's enough to um",
      "offset": 5902.04,
      "duration": 3.8
    },
    {
      "lang": "en",
      "text": "basically convince chat PT to not use",
      "offset": 5904.04,
      "duration": 4.119
    },
    {
      "lang": "en",
      "text": "tools and just use its memory and its",
      "offset": 5905.84,
      "duration": 6.72
    },
    {
      "lang": "en",
      "text": "recollection I also went off and I um",
      "offset": 5908.159,
      "duration": 6.761
    },
    {
      "lang": "en",
      "text": "tried to ask this question of Chachi PT",
      "offset": 5912.56,
      "duration": 4.52
    },
    {
      "lang": "en",
      "text": "so how many standing cups did uh Dominic",
      "offset": 5914.92,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "Hasek win and Chachi P actually decided",
      "offset": 5917.08,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "that it knows the answer and it has the",
      "offset": 5919.56,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "confidence to say that uh he want twice",
      "offset": 5920.84,
      "duration": 4.52
    },
    {
      "lang": "en",
      "text": "and so it kind of just relied on its",
      "offset": 5923.719,
      "duration": 5.321
    },
    {
      "lang": "en",
      "text": "memory because presumably it has um it",
      "offset": 5925.36,
      "duration": 5
    },
    {
      "lang": "en",
      "text": "has enough of",
      "offset": 5929.04,
      "duration": 4.44
    },
    {
      "lang": "en",
      "text": "a kind of confidence in its weights in",
      "offset": 5930.36,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "it parameters and activations that this",
      "offset": 5933.48,
      "duration": 5.679
    },
    {
      "lang": "en",
      "text": "is uh retrievable just for memory um but",
      "offset": 5935.4,
      "duration": 5.719
    },
    {
      "lang": "en",
      "text": "you can also",
      "offset": 5939.159,
      "duration": 4.921
    },
    {
      "lang": "en",
      "text": "conversely use web search to make sure",
      "offset": 5941.119,
      "duration": 4.881
    },
    {
      "lang": "en",
      "text": "and then for the same query it actually",
      "offset": 5944.08,
      "duration": 3.8
    },
    {
      "lang": "en",
      "text": "goes off and it searches and then it",
      "offset": 5946,
      "duration": 4.36
    },
    {
      "lang": "en",
      "text": "finds a bunch of sources it finds all",
      "offset": 5947.88,
      "duration": 4.359
    },
    {
      "lang": "en",
      "text": "this all of this stuff gets copy pasted",
      "offset": 5950.36,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "in there and then it tells us uh to",
      "offset": 5952.239,
      "duration": 5.561
    },
    {
      "lang": "en",
      "text": "again and sites and it actually says the",
      "offset": 5955.4,
      "duration": 4.719
    },
    {
      "lang": "en",
      "text": "Wikipedia article which is the source of",
      "offset": 5957.8,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "this information for us as well so",
      "offset": 5960.119,
      "duration": 4.961
    },
    {
      "lang": "en",
      "text": "that's tools web search the model",
      "offset": 5963,
      "duration": 4.52
    },
    {
      "lang": "en",
      "text": "determines when to search and then uh",
      "offset": 5965.08,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "that's kind of like how these tools uh",
      "offset": 5967.52,
      "duration": 4.639
    },
    {
      "lang": "en",
      "text": "work and this is an additional kind of",
      "offset": 5969.96,
      "duration": 5
    },
    {
      "lang": "en",
      "text": "mitigation for uh hallucinations and",
      "offset": 5972.159,
      "duration": 4.921
    },
    {
      "lang": "en",
      "text": "factuality so I want to stress one more",
      "offset": 5974.96,
      "duration": 3.679
    },
    {
      "lang": "en",
      "text": "time this very important sort of",
      "offset": 5977.08,
      "duration": 3.159
    },
    {
      "lang": "en",
      "text": "psychology",
      "offset": 5978.639,
      "duration": 4.441
    },
    {
      "lang": "en",
      "text": "Point knowledge in the parameters of the",
      "offset": 5980.239,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "neural network is a vague recollection",
      "offset": 5983.08,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "the knowledge in the tokens that make up",
      "offset": 5985.679,
      "duration": 2.721
    },
    {
      "lang": "en",
      "text": "the context",
      "offset": 5987.4,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "window is the working memory and it",
      "offset": 5988.4,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "roughly speaking Works kind of like um",
      "offset": 5991.32,
      "duration": 4.44
    },
    {
      "lang": "en",
      "text": "it works for us in our brain the stuff",
      "offset": 5993.76,
      "duration": 4.839
    },
    {
      "lang": "en",
      "text": "we remember is our parameters uh and the",
      "offset": 5995.76,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "stuff that we just experienced like a",
      "offset": 5998.599,
      "duration": 4.481
    },
    {
      "lang": "en",
      "text": "few seconds or minutes ago and so on you",
      "offset": 6001.36,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "can imagine that being in our context",
      "offset": 6003.08,
      "duration": 2.8
    },
    {
      "lang": "en",
      "text": "window and this context window is being",
      "offset": 6004.48,
      "duration": 2.88
    },
    {
      "lang": "en",
      "text": "built up as you have a conscious",
      "offset": 6005.88,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "experience around you so this has a",
      "offset": 6007.36,
      "duration": 5
    },
    {
      "lang": "en",
      "text": "bunch of um implications also for your",
      "offset": 6010.199,
      "duration": 5.681
    },
    {
      "lang": "en",
      "text": "use of LOLs in practice so for example I",
      "offset": 6012.36,
      "duration": 4.799
    },
    {
      "lang": "en",
      "text": "can go to chat GPT and I can do",
      "offset": 6015.88,
      "duration": 2.68
    },
    {
      "lang": "en",
      "text": "something like this I can say can you",
      "offset": 6017.159,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "Summarize chapter one of Jane Austin's",
      "offset": 6018.56,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "Pride and Prejudice right and this is a",
      "offset": 6020.199,
      "duration": 5.081
    },
    {
      "lang": "en",
      "text": "perfectly fine prompt and Chach actually",
      "offset": 6022.719,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "does something relatively reasonable",
      "offset": 6025.28,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "here and but the reason it does that is",
      "offset": 6026.719,
      "duration": 3.281
    },
    {
      "lang": "en",
      "text": "because Chach has a pretty good",
      "offset": 6028.56,
      "duration": 4.039
    },
    {
      "lang": "en",
      "text": "recollection of a famous work like Pride",
      "offset": 6030,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "and Prejudice it's probably seen a ton",
      "offset": 6032.599,
      "duration": 2.921
    },
    {
      "lang": "en",
      "text": "of stuff about it there's probably",
      "offset": 6034.32,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "forums about this book it's probably",
      "offset": 6035.52,
      "duration": 4.76
    },
    {
      "lang": "en",
      "text": "read versions of this book um and it's",
      "offset": 6037.44,
      "duration": 5.92
    },
    {
      "lang": "en",
      "text": "kind of like remembers because even if",
      "offset": 6040.28,
      "duration": 6.359
    },
    {
      "lang": "en",
      "text": "you've read this or articles about it",
      "offset": 6043.36,
      "duration": 4.68
    },
    {
      "lang": "en",
      "text": "you'd kind of have a recollection enough",
      "offset": 6046.639,
      "duration": 3.281
    },
    {
      "lang": "en",
      "text": "to actually say all this but usually",
      "offset": 6048.04,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "when I actually interact with LMS and I",
      "offset": 6049.92,
      "duration": 3.88
    },
    {
      "lang": "en",
      "text": "want them to recall specific things it",
      "offset": 6051.48,
      "duration": 3.639
    },
    {
      "lang": "en",
      "text": "always works better if you just give it",
      "offset": 6053.8,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "to them so I think a much better prompt",
      "offset": 6055.119,
      "duration": 4.241
    },
    {
      "lang": "en",
      "text": "would be something like this can you",
      "offset": 6057.32,
      "duration": 4.12
    },
    {
      "lang": "en",
      "text": "summarize for me chapter one of genos's",
      "offset": 6059.36,
      "duration": 3.759
    },
    {
      "lang": "en",
      "text": "spr and Prejudice and then I am",
      "offset": 6061.44,
      "duration": 3.199
    },
    {
      "lang": "en",
      "text": "attaching it below for your reference",
      "offset": 6063.119,
      "duration": 3
    },
    {
      "lang": "en",
      "text": "and then I do something like a delimeter",
      "offset": 6064.639,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "here and I paste it in and I I found",
      "offset": 6066.119,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "that just copy pasting it from some",
      "offset": 6068.719,
      "duration": 5.48
    },
    {
      "lang": "en",
      "text": "website that I found here um so copy",
      "offset": 6070.599,
      "duration": 5.681
    },
    {
      "lang": "en",
      "text": "pasting the chapter one here and I do",
      "offset": 6074.199,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "that because when it's in the context",
      "offset": 6076.28,
      "duration": 4.04
    },
    {
      "lang": "en",
      "text": "window the model has direct access to it",
      "offset": 6077.8,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "and can exactly it doesn't have to",
      "offset": 6080.32,
      "duration": 4.279
    },
    {
      "lang": "en",
      "text": "recall it it just has access to it and",
      "offset": 6082.28,
      "duration": 4.76
    },
    {
      "lang": "en",
      "text": "so this summary is can be expected to be",
      "offset": 6084.599,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "a significantly high quality or higher",
      "offset": 6087.04,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "quality than this summary uh just",
      "offset": 6089,
      "duration": 3.639
    },
    {
      "lang": "en",
      "text": "because it's directly available to the",
      "offset": 6091.36,
      "duration": 2.96
    },
    {
      "lang": "en",
      "text": "model and I think you and I would work",
      "offset": 6092.639,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "in the same way if you want to it would",
      "offset": 6094.32,
      "duration": 3.64
    },
    {
      "lang": "en",
      "text": "be you would produce a much better",
      "offset": 6096.96,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "summary if you had reread this chapter",
      "offset": 6097.96,
      "duration": 4.719
    },
    {
      "lang": "en",
      "text": "before you had to summarize it and",
      "offset": 6100.8,
      "duration": 3.96
    },
    {
      "lang": "en",
      "text": "that's basically what's happening here",
      "offset": 6102.679,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "or the equivalent of it the next sort of",
      "offset": 6104.76,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "psychological Quirk I'd like to talk",
      "offset": 6107.08,
      "duration": 3.4
    },
    {
      "lang": "en",
      "text": "about briefly is that of the knowledge",
      "offset": 6108.599,
      "duration": 4.201
    },
    {
      "lang": "en",
      "text": "of self so what I see very often on the",
      "offset": 6110.48,
      "duration": 3.719
    },
    {
      "lang": "en",
      "text": "internet is that people do something",
      "offset": 6112.8,
      "duration": 4.12
    },
    {
      "lang": "en",
      "text": "like this they ask llms something like",
      "offset": 6114.199,
      "duration": 5.561
    },
    {
      "lang": "en",
      "text": "what model are you and who built you and",
      "offset": 6116.92,
      "duration": 4.52
    },
    {
      "lang": "en",
      "text": "um basically this uh question is a",
      "offset": 6119.76,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "little bit nonsensical and the reason I",
      "offset": 6121.44,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "say that is that as I try to kind of",
      "offset": 6123.679,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "explain with some of the underhood",
      "offset": 6125.92,
      "duration": 3.48
    },
    {
      "lang": "en",
      "text": "fundamentals this thing is not a person",
      "offset": 6127.119,
      "duration": 4.04
    },
    {
      "lang": "en",
      "text": "right it doesn't have a persistent",
      "offset": 6129.4,
      "duration": 4.799
    },
    {
      "lang": "en",
      "text": "existence in any way it sort of boots up",
      "offset": 6131.159,
      "duration": 5.96
    },
    {
      "lang": "en",
      "text": "processes tokens and shuts off and it",
      "offset": 6134.199,
      "duration": 4.241
    },
    {
      "lang": "en",
      "text": "does that for every single person it",
      "offset": 6137.119,
      "duration": 2.6
    },
    {
      "lang": "en",
      "text": "just kind of builds up a context window",
      "offset": 6138.44,
      "duration": 2.799
    },
    {
      "lang": "en",
      "text": "of conversation and then everything gets",
      "offset": 6139.719,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "deleted and so this this entity is kind",
      "offset": 6141.239,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "of like restarted from scratch every",
      "offset": 6143.639,
      "duration": 3.56
    },
    {
      "lang": "en",
      "text": "single conversation if that makes sense",
      "offset": 6145.08,
      "duration": 3.72
    },
    {
      "lang": "en",
      "text": "it has no persistent self it has no",
      "offset": 6147.199,
      "duration": 4.52
    },
    {
      "lang": "en",
      "text": "sense of self it's a token tumbler and",
      "offset": 6148.8,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "uh it follows the statistical",
      "offset": 6151.719,
      "duration": 3.801
    },
    {
      "lang": "en",
      "text": "regularities of its training set so it",
      "offset": 6153.44,
      "duration": 4.719
    },
    {
      "lang": "en",
      "text": "doesn't really make sense to ask it who",
      "offset": 6155.52,
      "duration": 4.92
    },
    {
      "lang": "en",
      "text": "are you what build you Etc and by",
      "offset": 6158.159,
      "duration": 4.601
    },
    {
      "lang": "en",
      "text": "default if you do what I described and",
      "offset": 6160.44,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "just by default and from nowhere you're",
      "offset": 6162.76,
      "duration": 3.399
    },
    {
      "lang": "en",
      "text": "going to get some pretty random answers",
      "offset": 6164.92,
      "duration": 3.56
    },
    {
      "lang": "en",
      "text": "so for example let's uh pick on Falcon",
      "offset": 6166.159,
      "duration": 4.361
    },
    {
      "lang": "en",
      "text": "which is a fairly old model and let's",
      "offset": 6168.48,
      "duration": 3.4
    },
    {
      "lang": "en",
      "text": "see what it tells",
      "offset": 6170.52,
      "duration": 5
    },
    {
      "lang": "en",
      "text": "us uh so it's evading the question uh",
      "offset": 6171.88,
      "duration": 6.12
    },
    {
      "lang": "en",
      "text": "talented engineers and developers here",
      "offset": 6175.52,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "it says I was built by open AI based on",
      "offset": 6178,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "the gpt3 model it's totally making stuff",
      "offset": 6179.92,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "up now the fact that it's built by open",
      "offset": 6181.92,
      "duration": 4.199
    },
    {
      "lang": "en",
      "text": "AI here I think a lot of people would",
      "offset": 6184.4,
      "duration": 3.48
    },
    {
      "lang": "en",
      "text": "take this as evidence that this model",
      "offset": 6186.119,
      "duration": 3.441
    },
    {
      "lang": "en",
      "text": "was somehow trained on open AI data or",
      "offset": 6187.88,
      "duration": 2.96
    },
    {
      "lang": "en",
      "text": "something like that I don't actually",
      "offset": 6189.56,
      "duration": 3.24
    },
    {
      "lang": "en",
      "text": "think that that's necessarily true the",
      "offset": 6190.84,
      "duration": 3.64
    },
    {
      "lang": "en",
      "text": "reason for that is",
      "offset": 6192.8,
      "duration": 4.839
    },
    {
      "lang": "en",
      "text": "that if you don't explicitly program the",
      "offset": 6194.48,
      "duration": 5.92
    },
    {
      "lang": "en",
      "text": "model to answer these kinds of questions",
      "offset": 6197.639,
      "duration": 4.361
    },
    {
      "lang": "en",
      "text": "then what you're going to get is its",
      "offset": 6200.4,
      "duration": 5.16
    },
    {
      "lang": "en",
      "text": "statistical best guess at the answer and",
      "offset": 6202,
      "duration": 7.44
    },
    {
      "lang": "en",
      "text": "this model had a um sft data mixture of",
      "offset": 6205.56,
      "duration": 6.48
    },
    {
      "lang": "en",
      "text": "conversations and during the",
      "offset": 6209.44,
      "duration": 6.08
    },
    {
      "lang": "en",
      "text": "fine-tuning um the model sort of",
      "offset": 6212.04,
      "duration": 4.639
    },
    {
      "lang": "en",
      "text": "understands as it's training on this",
      "offset": 6215.52,
      "duration": 2.92
    },
    {
      "lang": "en",
      "text": "data that it's taking on this",
      "offset": 6216.679,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "personality of this like helpful",
      "offset": 6218.44,
      "duration": 4.04
    },
    {
      "lang": "en",
      "text": "assistant and it doesn't know how to it",
      "offset": 6220.119,
      "duration": 4.361
    },
    {
      "lang": "en",
      "text": "doesn't actually it wasn't told exactly",
      "offset": 6222.48,
      "duration": 4.759
    },
    {
      "lang": "en",
      "text": "what label to apply to self it just kind",
      "offset": 6224.48,
      "duration": 5.639
    },
    {
      "lang": "en",
      "text": "of is taking on this uh this uh Persona",
      "offset": 6227.239,
      "duration": 5.92
    },
    {
      "lang": "en",
      "text": "of a helpful assistant and remember that",
      "offset": 6230.119,
      "duration": 4.921
    },
    {
      "lang": "en",
      "text": "the pre-training stage took the",
      "offset": 6233.159,
      "duration": 4.121
    },
    {
      "lang": "en",
      "text": "documents from the entire internet and",
      "offset": 6235.04,
      "duration": 4.639
    },
    {
      "lang": "en",
      "text": "Chach and open AI are very prominent in",
      "offset": 6237.28,
      "duration": 4.2
    },
    {
      "lang": "en",
      "text": "these documents and so I think what's",
      "offset": 6239.679,
      "duration": 3.881
    },
    {
      "lang": "en",
      "text": "actually likely to be happening here is",
      "offset": 6241.48,
      "duration": 4.759
    },
    {
      "lang": "en",
      "text": "that this is just its hallucinated label",
      "offset": 6243.56,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "for what it is this is its self-identity",
      "offset": 6246.239,
      "duration": 4.92
    },
    {
      "lang": "en",
      "text": "is that it's chat GPT by open Ai and",
      "offset": 6248.44,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "it's only saying that because there's a",
      "offset": 6251.159,
      "duration": 4.241
    },
    {
      "lang": "en",
      "text": "ton of data on the internet of um",
      "offset": 6252.599,
      "duration": 5.321
    },
    {
      "lang": "en",
      "text": "answers like this that are actually",
      "offset": 6255.4,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "coming from open from chasht and So",
      "offset": 6257.92,
      "duration": 5.679
    },
    {
      "lang": "en",
      "text": "that's its label for what it is now you",
      "offset": 6260.44,
      "duration": 5.239
    },
    {
      "lang": "en",
      "text": "can override this as a developer if you",
      "offset": 6263.599,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "have a llm model you can actually",
      "offset": 6265.679,
      "duration": 3.241
    },
    {
      "lang": "en",
      "text": "override it and there are a few ways to",
      "offset": 6267.52,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "do that so for example let me show you",
      "offset": 6268.92,
      "duration": 6.36
    },
    {
      "lang": "en",
      "text": "there's this MMO model from Allen Ai and",
      "offset": 6271.92,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "um this is one llm it's not a top tier",
      "offset": 6275.28,
      "duration": 4.2
    },
    {
      "lang": "en",
      "text": "LM or anything like that but I like it",
      "offset": 6277.92,
      "duration": 3.279
    },
    {
      "lang": "en",
      "text": "because it is fully open source so the",
      "offset": 6279.48,
      "duration": 3.56
    },
    {
      "lang": "en",
      "text": "paper for Almo and everything else is",
      "offset": 6281.199,
      "duration": 3.281
    },
    {
      "lang": "en",
      "text": "completely fully open source which is",
      "offset": 6283.04,
      "duration": 4.04
    },
    {
      "lang": "en",
      "text": "nice um so here we are looking at its",
      "offset": 6284.48,
      "duration": 5.32
    },
    {
      "lang": "en",
      "text": "sft mixture so this is the data mixture",
      "offset": 6287.08,
      "duration": 5.159
    },
    {
      "lang": "en",
      "text": "of um the fine tuning so this is the",
      "offset": 6289.8,
      "duration": 4.799
    },
    {
      "lang": "en",
      "text": "conversations data it right and so the",
      "offset": 6292.239,
      "duration": 4.041
    },
    {
      "lang": "en",
      "text": "way that they are solving it for Theo",
      "offset": 6294.599,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "model is we see that there's a bunch of",
      "offset": 6296.28,
      "duration": 3.319
    },
    {
      "lang": "en",
      "text": "stuff in the mixture and there's a total",
      "offset": 6298.28,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "of 1 million conversations here but here",
      "offset": 6299.599,
      "duration": 5.881
    },
    {
      "lang": "en",
      "text": "we have alot to hardcoded if we go there",
      "offset": 6302.44,
      "duration": 5.32
    },
    {
      "lang": "en",
      "text": "we see that this is 240",
      "offset": 6305.48,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "conversations and look at these 240",
      "offset": 6307.76,
      "duration": 5
    },
    {
      "lang": "en",
      "text": "conversations they're hardcoded tell me",
      "offset": 6310.52,
      "duration": 5.159
    },
    {
      "lang": "en",
      "text": "about yourself says user and then the",
      "offset": 6312.76,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "assistant says I'm and open language",
      "offset": 6315.679,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "model developed by AI to Allen Institute",
      "offset": 6317.56,
      "duration": 3.96
    },
    {
      "lang": "en",
      "text": "of artificial intelligence Etc I'm here",
      "offset": 6319.52,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "to help blah blah blah what is your name",
      "offset": 6321.52,
      "duration": 4.679
    },
    {
      "lang": "en",
      "text": "uh Theo project so these are all kinds",
      "offset": 6323.92,
      "duration": 3.96
    },
    {
      "lang": "en",
      "text": "of like cooked up hardcoded questions",
      "offset": 6326.199,
      "duration": 4.52
    },
    {
      "lang": "en",
      "text": "abouto 2 and the correct answers to give",
      "offset": 6327.88,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "in these cases if you take 240 questions",
      "offset": 6330.719,
      "duration": 5.241
    },
    {
      "lang": "en",
      "text": "like this or conversations put them into",
      "offset": 6333.88,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "your training set and fine tune with it",
      "offset": 6335.96,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "then the model will actually be expected",
      "offset": 6337.88,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "to parot this stuff later if you don't",
      "offset": 6339.48,
      "duration": 6.32
    },
    {
      "lang": "en",
      "text": "give it this then it's probably a Chach",
      "offset": 6343,
      "duration": 3.719
    },
    {
      "lang": "en",
      "text": "by open",
      "offset": 6345.8,
      "duration": 3.879
    },
    {
      "lang": "en",
      "text": "Ai and um there's one more way to",
      "offset": 6346.719,
      "duration": 4.641
    },
    {
      "lang": "en",
      "text": "sometimes do this is",
      "offset": 6349.679,
      "duration": 5.56
    },
    {
      "lang": "en",
      "text": "that basically um in these conversations",
      "offset": 6351.36,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "and you have terms between human and",
      "offset": 6355.239,
      "duration": 3.201
    },
    {
      "lang": "en",
      "text": "assistant sometimes there's a special",
      "offset": 6356.48,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "message called system message at the",
      "offset": 6358.44,
      "duration": 4.12
    },
    {
      "lang": "en",
      "text": "very beginning of the conversation so",
      "offset": 6360.48,
      "duration": 3.159
    },
    {
      "lang": "en",
      "text": "it's not just between human and",
      "offset": 6362.56,
      "duration": 3.32
    },
    {
      "lang": "en",
      "text": "assistant there's a system and in the",
      "offset": 6363.639,
      "duration": 4.281
    },
    {
      "lang": "en",
      "text": "system message you can actually hardcode",
      "offset": 6365.88,
      "duration": 4.839
    },
    {
      "lang": "en",
      "text": "and remind the model that hey you are a",
      "offset": 6367.92,
      "duration": 5.84
    },
    {
      "lang": "en",
      "text": "model developed by open Ai and your name",
      "offset": 6370.719,
      "duration": 5.801
    },
    {
      "lang": "en",
      "text": "is chashi pt40 and you were trained on",
      "offset": 6373.76,
      "duration": 4.52
    },
    {
      "lang": "en",
      "text": "this date and your knowledge cut off is",
      "offset": 6376.52,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "this and basically it kind of like",
      "offset": 6378.28,
      "duration": 3.48
    },
    {
      "lang": "en",
      "text": "documents the model a little bit and",
      "offset": 6379.96,
      "duration": 3.159
    },
    {
      "lang": "en",
      "text": "then this is inserted into to your",
      "offset": 6381.76,
      "duration": 3.359
    },
    {
      "lang": "en",
      "text": "conversations so when you go on chpt you",
      "offset": 6383.119,
      "duration": 3.881
    },
    {
      "lang": "en",
      "text": "see a blank page but actually the system",
      "offset": 6385.119,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "message is kind of like hidden in there",
      "offset": 6387,
      "duration": 3.239
    },
    {
      "lang": "en",
      "text": "and those tokens are in the context",
      "offset": 6388.719,
      "duration": 4.44
    },
    {
      "lang": "en",
      "text": "window and so those are the two ways to",
      "offset": 6390.239,
      "duration": 5.521
    },
    {
      "lang": "en",
      "text": "kind of um program the models to talk",
      "offset": 6393.159,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "about themselves either it's done",
      "offset": 6395.76,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "through uh data like this or it's done",
      "offset": 6397.639,
      "duration": 4.52
    },
    {
      "lang": "en",
      "text": "through system message and things like",
      "offset": 6400.32,
      "duration": 3.72
    },
    {
      "lang": "en",
      "text": "that basically invisible tokens that are",
      "offset": 6402.159,
      "duration": 3.801
    },
    {
      "lang": "en",
      "text": "in the context window and remind the",
      "offset": 6404.04,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "model of its identity but it's all just",
      "offset": 6405.96,
      "duration": 4.12
    },
    {
      "lang": "en",
      "text": "kind of like cooked up and bolted on in",
      "offset": 6407.96,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "some in some way it's not actually like",
      "offset": 6410.08,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "really deeply there in any real sense as",
      "offset": 6411.96,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "it would before a human I want to now",
      "offset": 6414.96,
      "duration": 4.52
    },
    {
      "lang": "en",
      "text": "continue to the next section which deals",
      "offset": 6417.32,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "with the computational capabilities or",
      "offset": 6419.48,
      "duration": 2.8
    },
    {
      "lang": "en",
      "text": "like I should say the native",
      "offset": 6421.159,
      "duration": 2.44
    },
    {
      "lang": "en",
      "text": "computational capabilities of these",
      "offset": 6422.28,
      "duration": 4.12
    },
    {
      "lang": "en",
      "text": "models in problem solving scenarios and",
      "offset": 6423.599,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "so in particular we have to be very",
      "offset": 6426.4,
      "duration": 2.799
    },
    {
      "lang": "en",
      "text": "careful with these models when we",
      "offset": 6427.76,
      "duration": 3.56
    },
    {
      "lang": "en",
      "text": "construct our examples of conversations",
      "offset": 6429.199,
      "duration": 4.04
    },
    {
      "lang": "en",
      "text": "and there's a lot of sharp edges here",
      "offset": 6431.32,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "that are kind of like elucidative is",
      "offset": 6433.239,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "that a word uh they're kind of like",
      "offset": 6435,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "interesting to look at when we consider",
      "offset": 6436.679,
      "duration": 5.801
    },
    {
      "lang": "en",
      "text": "how these models think so um consider",
      "offset": 6438.44,
      "duration": 6.48
    },
    {
      "lang": "en",
      "text": "the following prompt from a human and",
      "offset": 6442.48,
      "duration": 3.48
    },
    {
      "lang": "en",
      "text": "supposed that basically that we are",
      "offset": 6444.92,
      "duration": 2.719
    },
    {
      "lang": "en",
      "text": "building out a conversation to enter",
      "offset": 6445.96,
      "duration": 3.08
    },
    {
      "lang": "en",
      "text": "into our training set of conversations",
      "offset": 6447.639,
      "duration": 2.6
    },
    {
      "lang": "en",
      "text": "so we're going to train the model on",
      "offset": 6449.04,
      "duration": 3
    },
    {
      "lang": "en",
      "text": "this we're teaching you how to basically",
      "offset": 6450.239,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "solve simple math problems so the prompt",
      "offset": 6452.04,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "is Emily buys three apples and two",
      "offset": 6454.56,
      "duration": 4.119
    },
    {
      "lang": "en",
      "text": "oranges each orange cost $2 the total",
      "offset": 6456.52,
      "duration": 4.52
    },
    {
      "lang": "en",
      "text": "cost is 13 what is the cost of apples",
      "offset": 6458.679,
      "duration": 5.081
    },
    {
      "lang": "en",
      "text": "very simple math question now there are",
      "offset": 6461.04,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "two answers here on the left and on the",
      "offset": 6463.76,
      "duration": 4.52
    },
    {
      "lang": "en",
      "text": "right they are both correct answers they",
      "offset": 6465.76,
      "duration": 3.959
    },
    {
      "lang": "en",
      "text": "both say that the answer is three which",
      "offset": 6468.28,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "is correct but one of these two is a",
      "offset": 6469.719,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "significant ific anly better answer for",
      "offset": 6472.44,
      "duration": 3.96
    },
    {
      "lang": "en",
      "text": "the assistant than the other like if I",
      "offset": 6474.679,
      "duration": 3.281
    },
    {
      "lang": "en",
      "text": "was Data labeler and I was creating one",
      "offset": 6476.4,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "of these one of these would be uh a",
      "offset": 6477.96,
      "duration": 5.88
    },
    {
      "lang": "en",
      "text": "really terrible answer for the assistant",
      "offset": 6481.36,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "and the other would be okay and so I'd",
      "offset": 6483.84,
      "duration": 3.48
    },
    {
      "lang": "en",
      "text": "like you to potentially pause the video",
      "offset": 6485.76,
      "duration": 3.879
    },
    {
      "lang": "en",
      "text": "Even and think through why one of these",
      "offset": 6487.32,
      "duration": 5.16
    },
    {
      "lang": "en",
      "text": "two is significantly better answer uh",
      "offset": 6489.639,
      "duration": 5.281
    },
    {
      "lang": "en",
      "text": "than the other and um if you use the",
      "offset": 6492.48,
      "duration": 5.119
    },
    {
      "lang": "en",
      "text": "wrong one your model will actually be uh",
      "offset": 6494.92,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "really bad at math potentially and it",
      "offset": 6497.599,
      "duration": 3.64
    },
    {
      "lang": "en",
      "text": "would have uh bad outcomes and this is",
      "offset": 6499.48,
      "duration": 2.96
    },
    {
      "lang": "en",
      "text": "something that you would be careful with",
      "offset": 6501.239,
      "duration": 2.4
    },
    {
      "lang": "en",
      "text": "in your life labeling documentations",
      "offset": 6502.44,
      "duration": 2.92
    },
    {
      "lang": "en",
      "text": "when you are training people uh to",
      "offset": 6503.639,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "create the ideal responses for the",
      "offset": 6505.36,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "assistant okay so the key to this",
      "offset": 6507.239,
      "duration": 4.801
    },
    {
      "lang": "en",
      "text": "question is to realize and remember that",
      "offset": 6509.199,
      "duration": 5
    },
    {
      "lang": "en",
      "text": "when the models are training and also",
      "offset": 6512.04,
      "duration": 3.88
    },
    {
      "lang": "en",
      "text": "inferencing they are working in",
      "offset": 6514.199,
      "duration": 3.761
    },
    {
      "lang": "en",
      "text": "onedimensional sequence of tokens from",
      "offset": 6515.92,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "left to right and this is the picture",
      "offset": 6517.96,
      "duration": 4.36
    },
    {
      "lang": "en",
      "text": "that I often have in my mind I imagine",
      "offset": 6520.4,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "basically the token sequence evolving",
      "offset": 6522.32,
      "duration": 3.799
    },
    {
      "lang": "en",
      "text": "from left to right and to always produce",
      "offset": 6523.76,
      "duration": 4.76
    },
    {
      "lang": "en",
      "text": "the next token in a sequence we are",
      "offset": 6526.119,
      "duration": 4.681
    },
    {
      "lang": "en",
      "text": "feeding all these tokens into the neural",
      "offset": 6528.52,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "network and this neural network then is",
      "offset": 6530.8,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "the probabilities for the next token and",
      "offset": 6533,
      "duration": 3.48
    },
    {
      "lang": "en",
      "text": "sequence right so this picture here is",
      "offset": 6534.32,
      "duration": 4.6
    },
    {
      "lang": "en",
      "text": "the exact same picture we saw uh before",
      "offset": 6536.48,
      "duration": 5.4
    },
    {
      "lang": "en",
      "text": "up here and this comes from the web demo",
      "offset": 6538.92,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "that I showed you before right so this",
      "offset": 6541.88,
      "duration": 4.04
    },
    {
      "lang": "en",
      "text": "is the calculation that basically takes",
      "offset": 6544.28,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "the input tokens here on the top and uh",
      "offset": 6545.92,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "performs these operations of all these",
      "offset": 6549.08,
      "duration": 4.84
    },
    {
      "lang": "en",
      "text": "neurons and uh gives you the answer for",
      "offset": 6551.36,
      "duration": 4.44
    },
    {
      "lang": "en",
      "text": "the probabilities of what comes next now",
      "offset": 6553.92,
      "duration": 3.64
    },
    {
      "lang": "en",
      "text": "the important thing to realize is that",
      "offset": 6555.8,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "roughly",
      "offset": 6557.56,
      "duration": 3.72
    },
    {
      "lang": "en",
      "text": "speaking uh there's basically a finite",
      "offset": 6559,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "number of layers of computation that",
      "offset": 6561.28,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "happened here so for example this model",
      "offset": 6562.92,
      "duration": 5.64
    },
    {
      "lang": "en",
      "text": "here has only one two three layers of",
      "offset": 6565.199,
      "duration": 6.761
    },
    {
      "lang": "en",
      "text": "what's called detention and uh MLP here",
      "offset": 6568.56,
      "duration": 5.8
    },
    {
      "lang": "en",
      "text": "um maybe um typical modern",
      "offset": 6571.96,
      "duration": 4.199
    },
    {
      "lang": "en",
      "text": "state-of-the-art Network would have more",
      "offset": 6574.36,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "like say 100 layers or something like",
      "offset": 6576.159,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "that but there's only 100 layers of",
      "offset": 6577.56,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "computation or something like that to go",
      "offset": 6579.199,
      "duration": 3.641
    },
    {
      "lang": "en",
      "text": "from the previous token sequence to the",
      "offset": 6580.92,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "probabilities for the next token and so",
      "offset": 6582.84,
      "duration": 4.04
    },
    {
      "lang": "en",
      "text": "there's a finite amount of computation",
      "offset": 6584.84,
      "duration": 4.44
    },
    {
      "lang": "en",
      "text": "that happens here for every single token",
      "offset": 6586.88,
      "duration": 3.88
    },
    {
      "lang": "en",
      "text": "and you should think of this as a very",
      "offset": 6589.28,
      "duration": 3.56
    },
    {
      "lang": "en",
      "text": "small amount of computation and this",
      "offset": 6590.76,
      "duration": 3.8
    },
    {
      "lang": "en",
      "text": "amount of computation is almost roughly",
      "offset": 6592.84,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "fixed uh for every single token in this",
      "offset": 6594.56,
      "duration": 5.039
    },
    {
      "lang": "en",
      "text": "sequence um the that's not actually",
      "offset": 6597.4,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "fully true because the more tokens you",
      "offset": 6599.599,
      "duration": 4.801
    },
    {
      "lang": "en",
      "text": "feed in uh the the more expensive uh",
      "offset": 6601.719,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "this forward pass will be of this neural",
      "offset": 6604.4,
      "duration": 4.92
    },
    {
      "lang": "en",
      "text": "network but not by much so you should",
      "offset": 6606.599,
      "duration": 4.241
    },
    {
      "lang": "en",
      "text": "think of this uh and I think as a good",
      "offset": 6609.32,
      "duration": 3.24
    },
    {
      "lang": "en",
      "text": "model to have in mind this is a fixed",
      "offset": 6610.84,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "amount of compute that's going to happen",
      "offset": 6612.56,
      "duration": 3
    },
    {
      "lang": "en",
      "text": "in this box for every single one of",
      "offset": 6613.88,
      "duration": 3.759
    },
    {
      "lang": "en",
      "text": "these tokens and this amount of compute",
      "offset": 6615.56,
      "duration": 3.559
    },
    {
      "lang": "en",
      "text": "Cann possibly be too big because there's",
      "offset": 6617.639,
      "duration": 3.361
    },
    {
      "lang": "en",
      "text": "not that many layers that are sort of",
      "offset": 6619.119,
      "duration": 4.12
    },
    {
      "lang": "en",
      "text": "going from the top to bottom here",
      "offset": 6621,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "there's not that that much",
      "offset": 6623.239,
      "duration": 2.761
    },
    {
      "lang": "en",
      "text": "computationally that will happen here",
      "offset": 6624.28,
      "duration": 3.48
    },
    {
      "lang": "en",
      "text": "and so you can't imagine the model to to",
      "offset": 6626,
      "duration": 3.599
    },
    {
      "lang": "en",
      "text": "basically do arbitrary computation in a",
      "offset": 6627.76,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "single forward pass to get a single",
      "offset": 6629.599,
      "duration": 4.481
    },
    {
      "lang": "en",
      "text": "token and so what that means is that we",
      "offset": 6631.92,
      "duration": 3.799
    },
    {
      "lang": "en",
      "text": "actually have to distribute our",
      "offset": 6634.08,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "reasoning and our computation across",
      "offset": 6635.719,
      "duration": 4.561
    },
    {
      "lang": "en",
      "text": "many tokens because every single token",
      "offset": 6637.84,
      "duration": 4.12
    },
    {
      "lang": "en",
      "text": "is only spending a finite amount of",
      "offset": 6640.28,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "computation on it and so we kind of want",
      "offset": 6641.96,
      "duration": 5.8
    },
    {
      "lang": "en",
      "text": "to distribute the computation across",
      "offset": 6645.32,
      "duration": 5.359
    },
    {
      "lang": "en",
      "text": "many tokens and we can't have too much",
      "offset": 6647.76,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "computation or expect too much",
      "offset": 6650.679,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "computation out of of the model in any",
      "offset": 6652.079,
      "duration": 3.881
    },
    {
      "lang": "en",
      "text": "single individual token because there's",
      "offset": 6653.719,
      "duration": 4.121
    },
    {
      "lang": "en",
      "text": "only so much computation that happens",
      "offset": 6655.96,
      "duration": 4.759
    },
    {
      "lang": "en",
      "text": "per token okay roughly fixed amount of",
      "offset": 6657.84,
      "duration": 4.879
    },
    {
      "lang": "en",
      "text": "computation here",
      "offset": 6660.719,
      "duration": 5.4
    },
    {
      "lang": "en",
      "text": "so that's why this answer here is",
      "offset": 6662.719,
      "duration": 5.201
    },
    {
      "lang": "en",
      "text": "significantly worse and the reason for",
      "offset": 6666.119,
      "duration": 3.641
    },
    {
      "lang": "en",
      "text": "that is Imagine going from left to right",
      "offset": 6667.92,
      "duration": 5.64
    },
    {
      "lang": "en",
      "text": "here um and I copy pasted it right here",
      "offset": 6669.76,
      "duration": 6.479
    },
    {
      "lang": "en",
      "text": "the answer is three Etc imagine the",
      "offset": 6673.56,
      "duration": 4.119
    },
    {
      "lang": "en",
      "text": "model having to go from left to right",
      "offset": 6676.239,
      "duration": 3.561
    },
    {
      "lang": "en",
      "text": "emitting these tokens one at a time it",
      "offset": 6677.679,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "has to say or we're expecting to say the",
      "offset": 6679.8,
      "duration": 7.96
    },
    {
      "lang": "en",
      "text": "answer is space dollar sign and then",
      "offset": 6683.199,
      "duration": 5.681
    },
    {
      "lang": "en",
      "text": "right here we're expecting it to",
      "offset": 6687.76,
      "duration": 2.919
    },
    {
      "lang": "en",
      "text": "basically cram all of the computation of",
      "offset": 6688.88,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "this problem into this single token it",
      "offset": 6690.679,
      "duration": 5.121
    },
    {
      "lang": "en",
      "text": "has to emit the correct answer three and",
      "offset": 6692.719,
      "duration": 5.201
    },
    {
      "lang": "en",
      "text": "then once we've emitted the answer three",
      "offset": 6695.8,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "we're expecting it to say all these",
      "offset": 6697.92,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "tokens but at this point we've already",
      "offset": 6699.56,
      "duration": 3.599
    },
    {
      "lang": "en",
      "text": "prod produced the answer and it's",
      "offset": 6701.28,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "already in the context window for all",
      "offset": 6703.159,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "these tokens that follow so anything",
      "offset": 6704.56,
      "duration": 4.679
    },
    {
      "lang": "en",
      "text": "here is just um kind of post Hawk",
      "offset": 6706.84,
      "duration": 5.239
    },
    {
      "lang": "en",
      "text": "justification of why this is the answer",
      "offset": 6709.239,
      "duration": 4.641
    },
    {
      "lang": "en",
      "text": "um because the answer is already created",
      "offset": 6712.079,
      "duration": 4.361
    },
    {
      "lang": "en",
      "text": "it's already in the token window so it's",
      "offset": 6713.88,
      "duration": 4.719
    },
    {
      "lang": "en",
      "text": "it's not actually being calculated here",
      "offset": 6716.44,
      "duration": 4.6
    },
    {
      "lang": "en",
      "text": "um and so if you are answering the",
      "offset": 6718.599,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "question directly and immediately you",
      "offset": 6721.04,
      "duration": 5
    },
    {
      "lang": "en",
      "text": "are training the model to to try to",
      "offset": 6723.079,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "basically guess the answer in a single",
      "offset": 6726.04,
      "duration": 4.119
    },
    {
      "lang": "en",
      "text": "token and that is just not going to work",
      "offset": 6727.639,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "because of the finite amount of",
      "offset": 6730.159,
      "duration": 3.56
    },
    {
      "lang": "en",
      "text": "computation that happens per token",
      "offset": 6731.159,
      "duration": 4.641
    },
    {
      "lang": "en",
      "text": "that's why this answer on the right is",
      "offset": 6733.719,
      "duration": 3.48
    },
    {
      "lang": "en",
      "text": "significantly better because we are",
      "offset": 6735.8,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "Distributing this computation across the",
      "offset": 6737.199,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "answer we're actually getting the model",
      "offset": 6739,
      "duration": 4.239
    },
    {
      "lang": "en",
      "text": "to sort of slowly come to the answer",
      "offset": 6740.8,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "from the left to right we're getting",
      "offset": 6743.239,
      "duration": 3.321
    },
    {
      "lang": "en",
      "text": "intermediate results we're saying okay",
      "offset": 6744.639,
      "duration": 4.241
    },
    {
      "lang": "en",
      "text": "the total cost of oranges is four so 30",
      "offset": 6746.56,
      "duration": 5.519
    },
    {
      "lang": "en",
      "text": "- 4 is 9 and so we're creating",
      "offset": 6748.88,
      "duration": 5.319
    },
    {
      "lang": "en",
      "text": "intermediate calculations and each one",
      "offset": 6752.079,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "of these calculations is by itself not",
      "offset": 6754.199,
      "duration": 3.801
    },
    {
      "lang": "en",
      "text": "that expensive and so we're actually",
      "offset": 6756,
      "duration": 4.239
    },
    {
      "lang": "en",
      "text": "basically kind of guessing a little bit",
      "offset": 6758,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "the difficulty that the model is capable",
      "offset": 6760.239,
      "duration": 4.36
    },
    {
      "lang": "en",
      "text": "of in any single one of these individual",
      "offset": 6762.32,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "tokens and there can never be too much",
      "offset": 6764.599,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "work in any one of these tokens",
      "offset": 6767.04,
      "duration": 3.88
    },
    {
      "lang": "en",
      "text": "computationally because then the model",
      "offset": 6769.239,
      "duration": 3.721
    },
    {
      "lang": "en",
      "text": "won't be able to do that later at test",
      "offset": 6770.92,
      "duration": 4.36
    },
    {
      "lang": "en",
      "text": "time and so we're teaching the model",
      "offset": 6772.96,
      "duration": 4.719
    },
    {
      "lang": "en",
      "text": "here to spread out its reasoning and to",
      "offset": 6775.28,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "spread out its computation over the",
      "offset": 6777.679,
      "duration": 4.841
    },
    {
      "lang": "en",
      "text": "tokens and in this way it only has very",
      "offset": 6779.679,
      "duration": 5.601
    },
    {
      "lang": "en",
      "text": "simple problems in each token and they",
      "offset": 6782.52,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "can add up and then by the time it's",
      "offset": 6785.28,
      "duration": 4.439
    },
    {
      "lang": "en",
      "text": "near the end it has all the previous",
      "offset": 6787.56,
      "duration": 4.2
    },
    {
      "lang": "en",
      "text": "results in its working memory and it's",
      "offset": 6789.719,
      "duration": 3.48
    },
    {
      "lang": "en",
      "text": "much easier for it to determine that the",
      "offset": 6791.76,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "answer is and here it is three so this",
      "offset": 6793.199,
      "duration": 5.241
    },
    {
      "lang": "en",
      "text": "is a significantly better label for our",
      "offset": 6795.84,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "computation this would be really bad and",
      "offset": 6798.44,
      "duration": 4.639
    },
    {
      "lang": "en",
      "text": "is teaching the model to try to do all",
      "offset": 6800.8,
      "duration": 4.04
    },
    {
      "lang": "en",
      "text": "the computation in a single token and",
      "offset": 6803.079,
      "duration": 2.761
    },
    {
      "lang": "en",
      "text": "it's really",
      "offset": 6804.84,
      "duration": 3.879
    },
    {
      "lang": "en",
      "text": "bad so uh that's kind of like an",
      "offset": 6805.84,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "interesting thing to keep in mind is in",
      "offset": 6808.719,
      "duration": 2.841
    },
    {
      "lang": "en",
      "text": "your",
      "offset": 6810.48,
      "duration": 3.119
    },
    {
      "lang": "en",
      "text": "prompts uh usually don't have to think",
      "offset": 6811.56,
      "duration": 4.559
    },
    {
      "lang": "en",
      "text": "about it explicitly because uh the",
      "offset": 6813.599,
      "duration": 5.08
    },
    {
      "lang": "en",
      "text": "people at open AI have labelers and so",
      "offset": 6816.119,
      "duration": 4.281
    },
    {
      "lang": "en",
      "text": "on that actually worry about this and",
      "offset": 6818.679,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "they make sure that the answers are",
      "offset": 6820.4,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "spread out and so actually open AI will",
      "offset": 6821.719,
      "duration": 4.121
    },
    {
      "lang": "en",
      "text": "kind of like do the right thing so when",
      "offset": 6823.92,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "I ask this question for chat GPT it's",
      "offset": 6825.84,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "actually going to go very slowly it's",
      "offset": 6828.079,
      "duration": 2.721
    },
    {
      "lang": "en",
      "text": "going to be like okay let's define our",
      "offset": 6829.52,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "variables set up the equation",
      "offset": 6830.8,
      "duration": 3.24
    },
    {
      "lang": "en",
      "text": "and it's kind of creating all these",
      "offset": 6832.96,
      "duration": 3.159
    },
    {
      "lang": "en",
      "text": "intermediate results these are not for",
      "offset": 6834.04,
      "duration": 4.639
    },
    {
      "lang": "en",
      "text": "you these are for the model if the model",
      "offset": 6836.119,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "is not creating these intermediate",
      "offset": 6838.679,
      "duration": 2.92
    },
    {
      "lang": "en",
      "text": "results for itself it's not going to be",
      "offset": 6839.96,
      "duration": 4.44
    },
    {
      "lang": "en",
      "text": "able to reach three I also wanted to",
      "offset": 6841.599,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "show you that it's possible to be a bit",
      "offset": 6844.4,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "mean to the model uh we can just ask for",
      "offset": 6846.079,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "things so as an example I said I gave it",
      "offset": 6848.239,
      "duration": 5.081
    },
    {
      "lang": "en",
      "text": "the exact same uh prompt and I said",
      "offset": 6850.639,
      "duration": 4.361
    },
    {
      "lang": "en",
      "text": "answer the question in a single token",
      "offset": 6853.32,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "just immediately give me the answer",
      "offset": 6855,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "nothing else and it turns out that for",
      "offset": 6856.44,
      "duration": 5.159
    },
    {
      "lang": "en",
      "text": "this simple um prompt here it actually",
      "offset": 6858.84,
      "duration": 4.799
    },
    {
      "lang": "en",
      "text": "was able to do it in single go so it",
      "offset": 6861.599,
      "duration": 3.56
    },
    {
      "lang": "en",
      "text": "just created a single I think this is",
      "offset": 6863.639,
      "duration": 3.96
    },
    {
      "lang": "en",
      "text": "two tokens right uh because the dollar",
      "offset": 6865.159,
      "duration": 5.201
    },
    {
      "lang": "en",
      "text": "sign is its own token so basically this",
      "offset": 6867.599,
      "duration": 4.281
    },
    {
      "lang": "en",
      "text": "model didn't give me a single token it",
      "offset": 6870.36,
      "duration": 3.56
    },
    {
      "lang": "en",
      "text": "gave me two tokens but it still produced",
      "offset": 6871.88,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "the correct answer and it did that in a",
      "offset": 6873.92,
      "duration": 3.759
    },
    {
      "lang": "en",
      "text": "single forward pass of the",
      "offset": 6875.8,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "network now that's because the numbers",
      "offset": 6877.679,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "here I think are very simple and so I",
      "offset": 6880.04,
      "duration": 3.079
    },
    {
      "lang": "en",
      "text": "made it a bit more difficult to be a bit",
      "offset": 6881.76,
      "duration": 3.72
    },
    {
      "lang": "en",
      "text": "mean to the model so I said Emily buys",
      "offset": 6883.119,
      "duration": 5.281
    },
    {
      "lang": "en",
      "text": "23 apples and 177 oranges and then I",
      "offset": 6885.48,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "just made the numbers a bit bigger and",
      "offset": 6888.4,
      "duration": 3.279
    },
    {
      "lang": "en",
      "text": "I'm just making it harder for the model",
      "offset": 6890.36,
      "duration": 3.08
    },
    {
      "lang": "en",
      "text": "I'm asking it to more computation in a",
      "offset": 6891.679,
      "duration": 4.121
    },
    {
      "lang": "en",
      "text": "single token and so I said the same",
      "offset": 6893.44,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "thing and here it gave me five and five",
      "offset": 6895.8,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "is actually not correct so the model",
      "offset": 6898.4,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "failed to do all of this calculation in",
      "offset": 6900.04,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "a single forward pass of the network it",
      "offset": 6902.4,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "failed to go from the input tokens and",
      "offset": 6904.36,
      "duration": 4.759
    },
    {
      "lang": "en",
      "text": "then in a single forward pass of the",
      "offset": 6907.52,
      "duration": 3.719
    },
    {
      "lang": "en",
      "text": "network single go through the network it",
      "offset": 6909.119,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "couldn't produce the result and then I",
      "offset": 6911.239,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "said okay now don't worry about the the",
      "offset": 6913.679,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "token limit and just solve the problem",
      "offset": 6916.119,
      "duration": 4.04
    },
    {
      "lang": "en",
      "text": "as usual and then it goes all the",
      "offset": 6918.159,
      "duration": 4.361
    },
    {
      "lang": "en",
      "text": "intermediate results it simplifies and",
      "offset": 6920.159,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "every one of these intermediate results",
      "offset": 6922.52,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "here and intermediate calculations is",
      "offset": 6924.239,
      "duration": 5.4
    },
    {
      "lang": "en",
      "text": "much easier for the model and um it sort",
      "offset": 6926.44,
      "duration": 6.04
    },
    {
      "lang": "en",
      "text": "of it's not too much work per token all",
      "offset": 6929.639,
      "duration": 4.281
    },
    {
      "lang": "en",
      "text": "of the tokens here are correct and it",
      "offset": 6932.48,
      "duration": 3.759
    },
    {
      "lang": "en",
      "text": "arises the solution which is seven and I",
      "offset": 6933.92,
      "duration": 4.44
    },
    {
      "lang": "en",
      "text": "just couldn't squeeze all of this work",
      "offset": 6936.239,
      "duration": 3.641
    },
    {
      "lang": "en",
      "text": "it couldn't squeeze that into a single",
      "offset": 6938.36,
      "duration": 3.279
    },
    {
      "lang": "en",
      "text": "forward passive Network so I think",
      "offset": 6939.88,
      "duration": 3.56
    },
    {
      "lang": "en",
      "text": "that's kind of just a cute example and",
      "offset": 6941.639,
      "duration": 3.361
    },
    {
      "lang": "en",
      "text": "something to kind of like think about",
      "offset": 6943.44,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "and I think it's kind of again just",
      "offset": 6945,
      "duration": 3.599
    },
    {
      "lang": "en",
      "text": "elucidative in terms of how these uh",
      "offset": 6946.56,
      "duration": 3.679
    },
    {
      "lang": "en",
      "text": "models work the last thing that I would",
      "offset": 6948.599,
      "duration": 3.401
    },
    {
      "lang": "en",
      "text": "say on this topic is that if I was in",
      "offset": 6950.239,
      "duration": 3.241
    },
    {
      "lang": "en",
      "text": "practi is trying to actually solve this",
      "offset": 6952,
      "duration": 3.4
    },
    {
      "lang": "en",
      "text": "in my day-to-day life I might actually",
      "offset": 6953.48,
      "duration": 4.44
    },
    {
      "lang": "en",
      "text": "not uh trust that the model that all the",
      "offset": 6955.4,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "intermediate calculations correctly here",
      "offset": 6957.92,
      "duration": 3.199
    },
    {
      "lang": "en",
      "text": "so actually probably what I do is",
      "offset": 6959.88,
      "duration": 2.56
    },
    {
      "lang": "en",
      "text": "something like this I would come here",
      "offset": 6961.119,
      "duration": 5.241
    },
    {
      "lang": "en",
      "text": "and I would say use code and uh that's",
      "offset": 6962.44,
      "duration": 6.239
    },
    {
      "lang": "en",
      "text": "because code is one of the possible",
      "offset": 6966.36,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "tools that chachy PD can use and instead",
      "offset": 6968.679,
      "duration": 5.641
    },
    {
      "lang": "en",
      "text": "of it having to do mental arithmetic",
      "offset": 6971.96,
      "duration": 3.96
    },
    {
      "lang": "en",
      "text": "like this mental arithmetic here I don't",
      "offset": 6974.32,
      "duration": 2.96
    },
    {
      "lang": "en",
      "text": "fully trust it and especially if the",
      "offset": 6975.92,
      "duration": 3.159
    },
    {
      "lang": "en",
      "text": "numbers get really big there's no",
      "offset": 6977.28,
      "duration": 3.16
    },
    {
      "lang": "en",
      "text": "guarantee that the model will do this",
      "offset": 6979.079,
      "duration": 3.281
    },
    {
      "lang": "en",
      "text": "correctly any one of these intermediates",
      "offset": 6980.44,
      "duration": 4.12
    },
    {
      "lang": "en",
      "text": "steps might in principle fail we're",
      "offset": 6982.36,
      "duration": 3.719
    },
    {
      "lang": "en",
      "text": "using neural networks to do mental",
      "offset": 6984.56,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "arithmetic uh kind of like you doing",
      "offset": 6986.079,
      "duration": 3.961
    },
    {
      "lang": "en",
      "text": "mental arithmetic in your brain it might",
      "offset": 6987.84,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "just like uh screw up some of the",
      "offset": 6990.04,
      "duration": 2.88
    },
    {
      "lang": "en",
      "text": "intermediate results it's actually kind",
      "offset": 6991.36,
      "duration": 2.96
    },
    {
      "lang": "en",
      "text": "of amazing that it can even do this kind",
      "offset": 6992.92,
      "duration": 2.56
    },
    {
      "lang": "en",
      "text": "of mental arithmetic I don't think I",
      "offset": 6994.32,
      "duration": 2.68
    },
    {
      "lang": "en",
      "text": "could do this in my head but basically",
      "offset": 6995.48,
      "duration": 2.679
    },
    {
      "lang": "en",
      "text": "the model is kind of like doing it in",
      "offset": 6997,
      "duration": 3.119
    },
    {
      "lang": "en",
      "text": "its head and I don't trust that so I",
      "offset": 6998.159,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "wanted to use tools so you can say stuff",
      "offset": 7000.119,
      "duration": 3.361
    },
    {
      "lang": "en",
      "text": "like use",
      "offset": 7002.079,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "code and uh I'm not sure what happened",
      "offset": 7003.48,
      "duration": 6.96
    },
    {
      "lang": "en",
      "text": "there use",
      "offset": 7007.119,
      "duration": 6.12
    },
    {
      "lang": "en",
      "text": "code and so um like I mentioned there's",
      "offset": 7010.44,
      "duration": 5.4
    },
    {
      "lang": "en",
      "text": "a special tool and the uh the model can",
      "offset": 7013.239,
      "duration": 5.48
    },
    {
      "lang": "en",
      "text": "write code and I can inspect that this",
      "offset": 7015.84,
      "duration": 5.759
    },
    {
      "lang": "en",
      "text": "code is correct and then uh it's not",
      "offset": 7018.719,
      "duration": 4.92
    },
    {
      "lang": "en",
      "text": "relying on its mental arithmetic it is",
      "offset": 7021.599,
      "duration": 3.761
    },
    {
      "lang": "en",
      "text": "using the python interpreter which is a",
      "offset": 7023.639,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "very simple programming language to",
      "offset": 7025.36,
      "duration": 3.48
    },
    {
      "lang": "en",
      "text": "basically uh write out the code that",
      "offset": 7027.079,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "calculates the result and I would",
      "offset": 7028.84,
      "duration": 3.279
    },
    {
      "lang": "en",
      "text": "personally trust this a lot more because",
      "offset": 7030.679,
      "duration": 3.4
    },
    {
      "lang": "en",
      "text": "this came out of a Python program which",
      "offset": 7032.119,
      "duration": 3.361
    },
    {
      "lang": "en",
      "text": "I think has a lot more correctness",
      "offset": 7034.079,
      "duration": 3.64
    },
    {
      "lang": "en",
      "text": "guarantees than the mental arithmetic of",
      "offset": 7035.48,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "a language model uh so just um another",
      "offset": 7037.719,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "kind of uh potential hint that if you",
      "offset": 7041,
      "duration": 3.88
    },
    {
      "lang": "en",
      "text": "have these kinds of problems uh you may",
      "offset": 7043.079,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "want to basically just uh ask the model",
      "offset": 7044.88,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "to use the code interpreter and just",
      "offset": 7046.679,
      "duration": 4.121
    },
    {
      "lang": "en",
      "text": "like we saw with the web search the",
      "offset": 7048.88,
      "duration": 5.319
    },
    {
      "lang": "en",
      "text": "model has special uh kind of tokens for",
      "offset": 7050.8,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "calling uh like it will not actually",
      "offset": 7054.199,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "generate these tokens from the language",
      "offset": 7056.8,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "model it will write the program and then",
      "offset": 7058.199,
      "duration": 4.361
    },
    {
      "lang": "en",
      "text": "it actually sends that program to a",
      "offset": 7060.719,
      "duration": 3.641
    },
    {
      "lang": "en",
      "text": "different sort of part of the computer",
      "offset": 7062.56,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "that actually just runs that program and",
      "offset": 7064.36,
      "duration": 3.719
    },
    {
      "lang": "en",
      "text": "brings back the result and then the",
      "offset": 7066.32,
      "duration": 3.759
    },
    {
      "lang": "en",
      "text": "model gets access to that result and can",
      "offset": 7068.079,
      "duration": 3.16
    },
    {
      "lang": "en",
      "text": "tell you that okay the cost of each",
      "offset": 7070.079,
      "duration": 3
    },
    {
      "lang": "en",
      "text": "apple is seven",
      "offset": 7071.239,
      "duration": 4.241
    },
    {
      "lang": "en",
      "text": "um so that's another kind of tool and I",
      "offset": 7073.079,
      "duration": 4.721
    },
    {
      "lang": "en",
      "text": "would use this in practice for yourself",
      "offset": 7075.48,
      "duration": 6.159
    },
    {
      "lang": "en",
      "text": "and it's um yeah it's just uh less error",
      "offset": 7077.8,
      "duration": 5.919
    },
    {
      "lang": "en",
      "text": "prone I would say so that's why I called",
      "offset": 7081.639,
      "duration": 5
    },
    {
      "lang": "en",
      "text": "this section models need tokens to think",
      "offset": 7083.719,
      "duration": 4.801
    },
    {
      "lang": "en",
      "text": "distribute your competition across many",
      "offset": 7086.639,
      "duration": 4.241
    },
    {
      "lang": "en",
      "text": "tokens ask models to create intermediate",
      "offset": 7088.52,
      "duration": 5.119
    },
    {
      "lang": "en",
      "text": "results or whenever you can lean on",
      "offset": 7090.88,
      "duration": 5
    },
    {
      "lang": "en",
      "text": "tools and Tool use instead of allowing",
      "offset": 7093.639,
      "duration": 3.641
    },
    {
      "lang": "en",
      "text": "the models to do all of the stuff in",
      "offset": 7095.88,
      "duration": 3.08
    },
    {
      "lang": "en",
      "text": "their memory so if they try to do it all",
      "offset": 7097.28,
      "duration": 3.879
    },
    {
      "lang": "en",
      "text": "in their memory I don't fully trust it",
      "offset": 7098.96,
      "duration": 3.56
    },
    {
      "lang": "en",
      "text": "and prefer to use tools whenever",
      "offset": 7101.159,
      "duration": 3.401
    },
    {
      "lang": "en",
      "text": "possible I want to show you one more",
      "offset": 7102.52,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "example of where this actually comes up",
      "offset": 7104.56,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "and that's in counting so models",
      "offset": 7106.679,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "actually are not very good at counting",
      "offset": 7108.88,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "for the exact same reason you're asking",
      "offset": 7110.36,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "for way too much in a single individual",
      "offset": 7112.32,
      "duration": 4.2
    },
    {
      "lang": "en",
      "text": "token so let me show you a simple",
      "offset": 7114.28,
      "duration": 4.68
    },
    {
      "lang": "en",
      "text": "example of that um how many dots are",
      "offset": 7116.52,
      "duration": 4.52
    },
    {
      "lang": "en",
      "text": "below and then I just put in a bunch of",
      "offset": 7118.96,
      "duration": 5.719
    },
    {
      "lang": "en",
      "text": "dots and Chach says there are and then",
      "offset": 7121.04,
      "duration": 5.4
    },
    {
      "lang": "en",
      "text": "it just tries to solve the problem in a",
      "offset": 7124.679,
      "duration": 4.641
    },
    {
      "lang": "en",
      "text": "single token so in a single token it has",
      "offset": 7126.44,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "to count the number of dots in its",
      "offset": 7129.32,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "context window",
      "offset": 7131.48,
      "duration": 3.679
    },
    {
      "lang": "en",
      "text": "um and it has to do that in the single",
      "offset": 7133.4,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "forward pass of a network and a single",
      "offset": 7135.159,
      "duration": 3.641
    },
    {
      "lang": "en",
      "text": "forward pass of a network as we talked",
      "offset": 7137.4,
      "duration": 2.92
    },
    {
      "lang": "en",
      "text": "about there's not that much computation",
      "offset": 7138.8,
      "duration": 2.879
    },
    {
      "lang": "en",
      "text": "that can happen there just think of that",
      "offset": 7140.32,
      "duration": 3.24
    },
    {
      "lang": "en",
      "text": "as being like very little competation",
      "offset": 7141.679,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "that happens there so if I just look at",
      "offset": 7143.56,
      "duration": 5.72
    },
    {
      "lang": "en",
      "text": "what the model sees let's go to the LM",
      "offset": 7146,
      "duration": 7.52
    },
    {
      "lang": "en",
      "text": "go to tokenizer it sees uh",
      "offset": 7149.28,
      "duration": 6.399
    },
    {
      "lang": "en",
      "text": "this how many dots are below and then it",
      "offset": 7153.52,
      "duration": 4.199
    },
    {
      "lang": "en",
      "text": "turns out that these dots here this",
      "offset": 7155.679,
      "duration": 4.44
    },
    {
      "lang": "en",
      "text": "group of I think 20 dots is a single",
      "offset": 7157.719,
      "duration": 5.201
    },
    {
      "lang": "en",
      "text": "token and then this group of whatever it",
      "offset": 7160.119,
      "duration": 4.921
    },
    {
      "lang": "en",
      "text": "is is another token and then for some",
      "offset": 7162.92,
      "duration": 5.239
    },
    {
      "lang": "en",
      "text": "reason they break up as this so I don't",
      "offset": 7165.04,
      "duration": 4.44
    },
    {
      "lang": "en",
      "text": "actually this has to do with the details",
      "offset": 7168.159,
      "duration": 3.281
    },
    {
      "lang": "en",
      "text": "of the tokenizer but it turns out that",
      "offset": 7169.48,
      "duration": 5
    },
    {
      "lang": "en",
      "text": "these um the model basically sees the",
      "offset": 7171.44,
      "duration": 6.719
    },
    {
      "lang": "en",
      "text": "token ID this this this and so on and",
      "offset": 7174.48,
      "duration": 6.04
    },
    {
      "lang": "en",
      "text": "then from these token IDs it's expected",
      "offset": 7178.159,
      "duration": 5.401
    },
    {
      "lang": "en",
      "text": "to count the number and spoiler alert is",
      "offset": 7180.52,
      "duration": 5.159
    },
    {
      "lang": "en",
      "text": "not 161 it's actually I believe",
      "offset": 7183.56,
      "duration": 4.92
    },
    {
      "lang": "en",
      "text": "177 so here's what we can do instead uh",
      "offset": 7185.679,
      "duration": 6.081
    },
    {
      "lang": "en",
      "text": "we can say use code and you might expect",
      "offset": 7188.48,
      "duration": 5.599
    },
    {
      "lang": "en",
      "text": "that like why should this work and it's",
      "offset": 7191.76,
      "duration": 3.439
    },
    {
      "lang": "en",
      "text": "actually kind of subtle and kind of",
      "offset": 7194.079,
      "duration": 3.321
    },
    {
      "lang": "en",
      "text": "interesting so when I say use code I",
      "offset": 7195.199,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "actually expect this to work let's see",
      "offset": 7197.4,
      "duration": 5.199
    },
    {
      "lang": "en",
      "text": "okay 177 is correct so what happens here",
      "offset": 7199.119,
      "duration": 5.641
    },
    {
      "lang": "en",
      "text": "is I've actually it doesn't look like it",
      "offset": 7202.599,
      "duration": 5.441
    },
    {
      "lang": "en",
      "text": "but I've broken down the problem into a",
      "offset": 7204.76,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "problems that are easier for the model I",
      "offset": 7208.04,
      "duration": 3.96
    },
    {
      "lang": "en",
      "text": "know that the model can't count it can't",
      "offset": 7210.36,
      "duration": 4.04
    },
    {
      "lang": "en",
      "text": "do mental counting but I know that the",
      "offset": 7212,
      "duration": 3.8
    },
    {
      "lang": "en",
      "text": "model is actually pretty good at doing",
      "offset": 7214.4,
      "duration": 3.799
    },
    {
      "lang": "en",
      "text": "copy pasting so what I'm doing here is",
      "offset": 7215.8,
      "duration": 4.439
    },
    {
      "lang": "en",
      "text": "when I say use code it creates a string",
      "offset": 7218.199,
      "duration": 5.761
    },
    {
      "lang": "en",
      "text": "in Python for this and the task of",
      "offset": 7220.239,
      "duration": 6.96
    },
    {
      "lang": "en",
      "text": "basically copy pasting my input here to",
      "offset": 7223.96,
      "duration": 5.56
    },
    {
      "lang": "en",
      "text": "here is very simple because for the",
      "offset": 7227.199,
      "duration": 6.561
    },
    {
      "lang": "en",
      "text": "model um it sees this string of uh it",
      "offset": 7229.52,
      "duration": 6.159
    },
    {
      "lang": "en",
      "text": "sees it as just these four tokens or",
      "offset": 7233.76,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "whatever it is so it's very simple for",
      "offset": 7235.679,
      "duration": 5.281
    },
    {
      "lang": "en",
      "text": "the model to copy paste those token IDs",
      "offset": 7237.36,
      "duration": 7.719
    },
    {
      "lang": "en",
      "text": "and um kind of unpack them into Dots",
      "offset": 7240.96,
      "duration": 6.8
    },
    {
      "lang": "en",
      "text": "here and so it creates this string and",
      "offset": 7245.079,
      "duration": 5.361
    },
    {
      "lang": "en",
      "text": "then it calls python routine. count and",
      "offset": 7247.76,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "then it comes up with the correct answer",
      "offset": 7250.44,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "so the python interpreter is doing the",
      "offset": 7252.079,
      "duration": 3.401
    },
    {
      "lang": "en",
      "text": "counting it's not the models mental",
      "offset": 7253.8,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "arithmetic doing the counting so it's",
      "offset": 7255.48,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "again a simple example of um models need",
      "offset": 7257.4,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "tokens to think don't rely on their",
      "offset": 7260.84,
      "duration": 4.879
    },
    {
      "lang": "en",
      "text": "mental arithmetic and um that's why also",
      "offset": 7262.52,
      "duration": 4.639
    },
    {
      "lang": "en",
      "text": "the models are not very good at counting",
      "offset": 7265.719,
      "duration": 3.121
    },
    {
      "lang": "en",
      "text": "if you need them to do counting tasks",
      "offset": 7267.159,
      "duration": 4.801
    },
    {
      "lang": "en",
      "text": "always ask them to lean on the tool now",
      "offset": 7268.84,
      "duration": 4.92
    },
    {
      "lang": "en",
      "text": "the models also have many other little",
      "offset": 7271.96,
      "duration": 3.32
    },
    {
      "lang": "en",
      "text": "cognitive deficits here and there and",
      "offset": 7273.76,
      "duration": 2.76
    },
    {
      "lang": "en",
      "text": "these are kind of like sharp edges of",
      "offset": 7275.28,
      "duration": 2.959
    },
    {
      "lang": "en",
      "text": "the technology to be kind of aware of",
      "offset": 7276.52,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "over time so as an example the models",
      "offset": 7278.239,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "are not very good with all kinds of",
      "offset": 7280.84,
      "duration": 3.399
    },
    {
      "lang": "en",
      "text": "spelling related tasks they're not very",
      "offset": 7282.32,
      "duration": 4.44
    },
    {
      "lang": "en",
      "text": "good at it and I told you that we would",
      "offset": 7284.239,
      "duration": 4.92
    },
    {
      "lang": "en",
      "text": "loop back around to tokenization and the",
      "offset": 7286.76,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "reason to do for this is that the models",
      "offset": 7289.159,
      "duration": 4.121
    },
    {
      "lang": "en",
      "text": "they don't see the characters they see",
      "offset": 7291.4,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "tokens and they their entire world is",
      "offset": 7293.28,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "about tokens which are these little text",
      "offset": 7295.719,
      "duration": 3.721
    },
    {
      "lang": "en",
      "text": "chunks and so they don't see characters",
      "offset": 7297.199,
      "duration": 4.601
    },
    {
      "lang": "en",
      "text": "like our eyes do and so very simple",
      "offset": 7299.44,
      "duration": 5.719
    },
    {
      "lang": "en",
      "text": "character level tasks often fail so for",
      "offset": 7301.8,
      "duration": 5.72
    },
    {
      "lang": "en",
      "text": "example uh I'm giving it a string",
      "offset": 7305.159,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "ubiquitous and I'm asking it to print",
      "offset": 7307.52,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "only every third character starting with",
      "offset": 7309.719,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "the first one so we start with U and",
      "offset": 7311.679,
      "duration": 5.241
    },
    {
      "lang": "en",
      "text": "then we should go every third so every",
      "offset": 7314.199,
      "duration": 7
    },
    {
      "lang": "en",
      "text": "so 1 2 3 Q should be next and then Etc",
      "offset": 7316.92,
      "duration": 6.92
    },
    {
      "lang": "en",
      "text": "so this I see is not correct and again",
      "offset": 7321.199,
      "duration": 4.721
    },
    {
      "lang": "en",
      "text": "my hypothesis is that this is again",
      "offset": 7323.84,
      "duration": 4.52
    },
    {
      "lang": "en",
      "text": "Dental arithmetic here is failing number",
      "offset": 7325.92,
      "duration": 4.52
    },
    {
      "lang": "en",
      "text": "one a little bit but number two I think",
      "offset": 7328.36,
      "duration": 3.879
    },
    {
      "lang": "en",
      "text": "the the more important issue here is",
      "offset": 7330.44,
      "duration": 3.08
    },
    {
      "lang": "en",
      "text": "that if you go to Tik",
      "offset": 7332.239,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "tokenizer and you look at ubiquitous we",
      "offset": 7333.52,
      "duration": 5.599
    },
    {
      "lang": "en",
      "text": "see that it is three tokens right so you",
      "offset": 7336.32,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "and I see ubiquitous and we can easily",
      "offset": 7339.119,
      "duration": 4.761
    },
    {
      "lang": "en",
      "text": "access the individual letters because we",
      "offset": 7341.28,
      "duration": 4.28
    },
    {
      "lang": "en",
      "text": "kind of see them and when we have it in",
      "offset": 7343.88,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "the working memory of our visual sort of",
      "offset": 7345.56,
      "duration": 4.119
    },
    {
      "lang": "en",
      "text": "field we can really easily index into",
      "offset": 7347.56,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "every third letter and I can do that",
      "offset": 7349.679,
      "duration": 3.721
    },
    {
      "lang": "en",
      "text": "task but the models don't have access to",
      "offset": 7351.32,
      "duration": 3.96
    },
    {
      "lang": "en",
      "text": "the individual letters they see this as",
      "offset": 7353.4,
      "duration": 4.799
    },
    {
      "lang": "en",
      "text": "these three tokens and uh remember these",
      "offset": 7355.28,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "models are trained from scratch on the",
      "offset": 7358.199,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "internet and all these token uh",
      "offset": 7359.92,
      "duration": 4.12
    },
    {
      "lang": "en",
      "text": "basically the model has to discover how",
      "offset": 7362.599,
      "duration": 2.961
    },
    {
      "lang": "en",
      "text": "many of all these different letters are",
      "offset": 7364.04,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "packed into all these different tokens",
      "offset": 7365.56,
      "duration": 3.88
    },
    {
      "lang": "en",
      "text": "and the reason we even use tokens is",
      "offset": 7367.88,
      "duration": 3.359
    },
    {
      "lang": "en",
      "text": "mostly for efficiency uh but I think a",
      "offset": 7369.44,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "lot of people areed interested to delete",
      "offset": 7371.239,
      "duration": 3.4
    },
    {
      "lang": "en",
      "text": "tokens entirely like we should really",
      "offset": 7372.8,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "have character level or bite level",
      "offset": 7374.639,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "models it's just that that would create",
      "offset": 7376.4,
      "duration": 3.56
    },
    {
      "lang": "en",
      "text": "very long sequences and people don't",
      "offset": 7378.239,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "know how to deal with that right now so",
      "offset": 7379.96,
      "duration": 3.679
    },
    {
      "lang": "en",
      "text": "while we have the token World any kind",
      "offset": 7381.92,
      "duration": 3.08
    },
    {
      "lang": "en",
      "text": "of spelling tasks are not actually",
      "offset": 7383.639,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "expected to work super well so because I",
      "offset": 7385,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "know that spelling is not a strong suit",
      "offset": 7387.719,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "because of tokenization I can again Ask",
      "offset": 7389.4,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "it to lean On Tools so I can just say",
      "offset": 7391.719,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "use code and I would again expect this",
      "offset": 7393.56,
      "duration": 4.84
    },
    {
      "lang": "en",
      "text": "to work because the task of copy pasting",
      "offset": 7396.04,
      "duration": 4.36
    },
    {
      "lang": "en",
      "text": "ubiquitous into the python interpreter",
      "offset": 7398.4,
      "duration": 4.04
    },
    {
      "lang": "en",
      "text": "is much easier and then we're leaning on",
      "offset": 7400.4,
      "duration": 5
    },
    {
      "lang": "en",
      "text": "python interpreter to manipulate the",
      "offset": 7402.44,
      "duration": 5.199
    },
    {
      "lang": "en",
      "text": "characters of this string so when I say",
      "offset": 7405.4,
      "duration": 3.56
    },
    {
      "lang": "en",
      "text": "use",
      "offset": 7407.639,
      "duration": 3.08
    },
    {
      "lang": "en",
      "text": "code",
      "offset": 7408.96,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "ubiquitous yes it indexes into every",
      "offset": 7410.719,
      "duration": 4.561
    },
    {
      "lang": "en",
      "text": "third character and the actual truth is",
      "offset": 7412.96,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "u2s",
      "offset": 7415.28,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "uqs uh which looks correct to me so um",
      "offset": 7416.8,
      "duration": 6.04
    },
    {
      "lang": "en",
      "text": "again an example of spelling related",
      "offset": 7421.04,
      "duration": 3.72
    },
    {
      "lang": "en",
      "text": "tasks not working very well a very",
      "offset": 7422.84,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "famous example of that recently is how",
      "offset": 7424.76,
      "duration": 4.479
    },
    {
      "lang": "en",
      "text": "many R are there in strawberry and this",
      "offset": 7427.159,
      "duration": 4.641
    },
    {
      "lang": "en",
      "text": "went viral many times and basically the",
      "offset": 7429.239,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "models now get it correct they say there",
      "offset": 7431.8,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "are three Rs in Strawberry but for a",
      "offset": 7433.32,
      "duration": 3.399
    },
    {
      "lang": "en",
      "text": "very long time all the state-of-the-art",
      "offset": 7435.32,
      "duration": 2.96
    },
    {
      "lang": "en",
      "text": "models would insist that there are only",
      "offset": 7436.719,
      "duration": 4.201
    },
    {
      "lang": "en",
      "text": "two RS in strawberry and this caused a",
      "offset": 7438.28,
      "duration": 5.439
    },
    {
      "lang": "en",
      "text": "lot of you know Ruckus because is that a",
      "offset": 7440.92,
      "duration": 5.88
    },
    {
      "lang": "en",
      "text": "word I think so because um it just kind",
      "offset": 7443.719,
      "duration": 4.92
    },
    {
      "lang": "en",
      "text": "of like why are the models so brilliant",
      "offset": 7446.8,
      "duration": 3.359
    },
    {
      "lang": "en",
      "text": "and they can solve math Olympiad",
      "offset": 7448.639,
      "duration": 4.121
    },
    {
      "lang": "en",
      "text": "questions but they can't like count RS",
      "offset": 7450.159,
      "duration": 4.601
    },
    {
      "lang": "en",
      "text": "in strawberry and the answer for that",
      "offset": 7452.76,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "again is I've got built up to it kind of",
      "offset": 7454.76,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "slowly but number one the models don't",
      "offset": 7456.599,
      "duration": 4.361
    },
    {
      "lang": "en",
      "text": "see characters they see tokens and",
      "offset": 7458.84,
      "duration": 3.96
    },
    {
      "lang": "en",
      "text": "number two they are not very good at",
      "offset": 7460.96,
      "duration": 4.36
    },
    {
      "lang": "en",
      "text": "counting and so here we are combining",
      "offset": 7462.8,
      "duration": 4.68
    },
    {
      "lang": "en",
      "text": "the difficulty of seeing the characters",
      "offset": 7465.32,
      "duration": 4.04
    },
    {
      "lang": "en",
      "text": "with the difficulty of counting and",
      "offset": 7467.48,
      "duration": 3.119
    },
    {
      "lang": "en",
      "text": "that's why the models struggled with",
      "offset": 7469.36,
      "duration": 3.719
    },
    {
      "lang": "en",
      "text": "this even though I think by now honestly",
      "offset": 7470.599,
      "duration": 4.04
    },
    {
      "lang": "en",
      "text": "I think open I may have hardcoded the",
      "offset": 7473.079,
      "duration": 2.881
    },
    {
      "lang": "en",
      "text": "answer here or I'm not sure what they",
      "offset": 7474.639,
      "duration": 4.881
    },
    {
      "lang": "en",
      "text": "did but um uh but this specific query",
      "offset": 7475.96,
      "duration": 5.88
    },
    {
      "lang": "en",
      "text": "now works",
      "offset": 7479.52,
      "duration": 4.92
    },
    {
      "lang": "en",
      "text": "so models are not very good at spelling",
      "offset": 7481.84,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "and there there's a bunch of other",
      "offset": 7484.44,
      "duration": 2.44
    },
    {
      "lang": "en",
      "text": "little sharp edges and I don't want to",
      "offset": 7485.679,
      "duration": 2.681
    },
    {
      "lang": "en",
      "text": "go into all of them I just want to show",
      "offset": 7486.88,
      "duration": 3.16
    },
    {
      "lang": "en",
      "text": "you a few examples of things to be aware",
      "offset": 7488.36,
      "duration": 3.96
    },
    {
      "lang": "en",
      "text": "of and uh when you're using these models",
      "offset": 7490.04,
      "duration": 4.119
    },
    {
      "lang": "en",
      "text": "in practice I don't actually want to",
      "offset": 7492.32,
      "duration": 3.48
    },
    {
      "lang": "en",
      "text": "have a comprehensive analysis here of",
      "offset": 7494.159,
      "duration": 3.761
    },
    {
      "lang": "en",
      "text": "all the ways that the models are kind of",
      "offset": 7495.8,
      "duration": 3.759
    },
    {
      "lang": "en",
      "text": "like falling short I just want to make",
      "offset": 7497.92,
      "duration": 3.199
    },
    {
      "lang": "en",
      "text": "the point that there are some Jagged",
      "offset": 7499.559,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "edges here and there and we've discussed",
      "offset": 7501.119,
      "duration": 3.96
    },
    {
      "lang": "en",
      "text": "a few of them and a few of them make",
      "offset": 7503.639,
      "duration": 2.801
    },
    {
      "lang": "en",
      "text": "sense but some of them also will just",
      "offset": 7505.079,
      "duration": 3.321
    },
    {
      "lang": "en",
      "text": "not make as much sense and they're kind",
      "offset": 7506.44,
      "duration": 3.56
    },
    {
      "lang": "en",
      "text": "of like you're left scratching your head",
      "offset": 7508.4,
      "duration": 3.4
    },
    {
      "lang": "en",
      "text": "even if you understand in- depth how",
      "offset": 7510,
      "duration": 4.119
    },
    {
      "lang": "en",
      "text": "these models work and and good example",
      "offset": 7511.8,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "of that recently is the following uh the",
      "offset": 7514.119,
      "duration": 3.801
    },
    {
      "lang": "en",
      "text": "models are not very good at very simple",
      "offset": 7516.44,
      "duration": 3.88
    },
    {
      "lang": "en",
      "text": "questions like this and uh this is",
      "offset": 7517.92,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "shocking to a lot of people because",
      "offset": 7520.32,
      "duration": 3.48
    },
    {
      "lang": "en",
      "text": "these math uh these problems can solve",
      "offset": 7522,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "complex math problems they can answer",
      "offset": 7523.8,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "PhD grade physics chemistry biology",
      "offset": 7525.76,
      "duration": 4.799
    },
    {
      "lang": "en",
      "text": "questions much better than I can but",
      "offset": 7528.52,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "sometimes they fall short in like super",
      "offset": 7530.559,
      "duration": 4.201
    },
    {
      "lang": "en",
      "text": "simple problems like this so here we go",
      "offset": 7531.8,
      "duration": 6.64
    },
    {
      "lang": "en",
      "text": "9.11 is bigger than 9.9 and it justifies",
      "offset": 7534.76,
      "duration": 6.2
    },
    {
      "lang": "en",
      "text": "it in some way but obviously and then at",
      "offset": 7538.44,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "the end okay it actually it flips its",
      "offset": 7540.96,
      "duration": 6.159
    },
    {
      "lang": "en",
      "text": "decision later so um I don't believe",
      "offset": 7544.04,
      "duration": 5
    },
    {
      "lang": "en",
      "text": "that this is very reproducible sometimes",
      "offset": 7547.119,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "it flips around its answer sometimes",
      "offset": 7549.04,
      "duration": 3.039
    },
    {
      "lang": "en",
      "text": "gets it right sometimes get it get it",
      "offset": 7550.559,
      "duration": 4.921
    },
    {
      "lang": "en",
      "text": "wrong uh let's try",
      "offset": 7552.079,
      "duration": 3.401
    },
    {
      "lang": "en",
      "text": "again okay even though it might look",
      "offset": 7556.719,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "larger okay so here it doesn't even",
      "offset": 7559.679,
      "duration": 3.721
    },
    {
      "lang": "en",
      "text": "correct itself in the end if you ask",
      "offset": 7561.599,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "many times sometimes it gets it right",
      "offset": 7563.4,
      "duration": 3.88
    },
    {
      "lang": "en",
      "text": "too but how is it that the model can do",
      "offset": 7564.719,
      "duration": 5.681
    },
    {
      "lang": "en",
      "text": "so great at Olympiad grade problems but",
      "offset": 7567.28,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "then fail on very simple problems like",
      "offset": 7570.4,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "this and uh I think this one is as I",
      "offset": 7572.32,
      "duration": 4.279
    },
    {
      "lang": "en",
      "text": "mentioned a little bit of a head",
      "offset": 7575.76,
      "duration": 2.359
    },
    {
      "lang": "en",
      "text": "scratcher it turns out that a bunch of",
      "offset": 7576.599,
      "duration": 3.241
    },
    {
      "lang": "en",
      "text": "people studied this in depth and I",
      "offset": 7578.119,
      "duration": 3.881
    },
    {
      "lang": "en",
      "text": "haven't actually read the paper uh but",
      "offset": 7579.84,
      "duration": 5
    },
    {
      "lang": "en",
      "text": "what I was told by this team was that",
      "offset": 7582,
      "duration": 5.88
    },
    {
      "lang": "en",
      "text": "when you scrutinize the activations",
      "offset": 7584.84,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "inside the neural network when you look",
      "offset": 7587.88,
      "duration": 3.359
    },
    {
      "lang": "en",
      "text": "at some of the features and what what",
      "offset": 7589.32,
      "duration": 3.759
    },
    {
      "lang": "en",
      "text": "features turn on or off and what neurons",
      "offset": 7591.239,
      "duration": 4.561
    },
    {
      "lang": "en",
      "text": "turn on or off uh a bunch of neurons",
      "offset": 7593.079,
      "duration": 4.681
    },
    {
      "lang": "en",
      "text": "inside the neural network light up that",
      "offset": 7595.8,
      "duration": 4.879
    },
    {
      "lang": "en",
      "text": "are usually associated with Bible verses",
      "offset": 7597.76,
      "duration": 4.919
    },
    {
      "lang": "en",
      "text": "U and so I think the model is kind of",
      "offset": 7600.679,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "like reminded that these almost look",
      "offset": 7602.679,
      "duration": 5.361
    },
    {
      "lang": "en",
      "text": "like Bible verse markers and in a bip",
      "offset": 7604.76,
      "duration": 7.28
    },
    {
      "lang": "en",
      "text": "verse setting 9.11 would come after 99.9",
      "offset": 7608.04,
      "duration": 5.48
    },
    {
      "lang": "en",
      "text": "and so basically the model somehow finds",
      "offset": 7612.04,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "it like cognitively very distracting",
      "offset": 7613.52,
      "duration": 4.76
    },
    {
      "lang": "en",
      "text": "that in Bible verses 9.11 would be",
      "offset": 7616.119,
      "duration": 4.721
    },
    {
      "lang": "en",
      "text": "greater um even though here it's",
      "offset": 7618.28,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "actually trying to justify it and come",
      "offset": 7620.84,
      "duration": 3.799
    },
    {
      "lang": "en",
      "text": "up to the answer with a math it still",
      "offset": 7622.119,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "ends up with the wrong answer here so it",
      "offset": 7624.639,
      "duration": 4.241
    },
    {
      "lang": "en",
      "text": "basically just doesn't fully make sense",
      "offset": 7627.159,
      "duration": 5.601
    },
    {
      "lang": "en",
      "text": "and it's not fully understood and um",
      "offset": 7628.88,
      "duration": 5.92
    },
    {
      "lang": "en",
      "text": "there's a few Jagged issues like that so",
      "offset": 7632.76,
      "duration": 4.68
    },
    {
      "lang": "en",
      "text": "that's why treat this as a as what it is",
      "offset": 7634.8,
      "duration": 4.52
    },
    {
      "lang": "en",
      "text": "which is a St stochastic system that is",
      "offset": 7637.44,
      "duration": 3.719
    },
    {
      "lang": "en",
      "text": "really magical but that you can't also",
      "offset": 7639.32,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "fully trust and you want to use it as a",
      "offset": 7641.159,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "tool not as something that you kind of",
      "offset": 7643.239,
      "duration": 3.96
    },
    {
      "lang": "en",
      "text": "like letter rip on a problem and",
      "offset": 7645.079,
      "duration": 4.12
    },
    {
      "lang": "en",
      "text": "copypaste the results okay so we have",
      "offset": 7647.199,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "now covered two major stages of training",
      "offset": 7649.199,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "of large language models we saw that in",
      "offset": 7652.159,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "the first stage this is called the",
      "offset": 7654.559,
      "duration": 3.441
    },
    {
      "lang": "en",
      "text": "pre-training stage we are basically",
      "offset": 7656.239,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "training on internet documents and when",
      "offset": 7658,
      "duration": 4.119
    },
    {
      "lang": "en",
      "text": "you train a language model on internet",
      "offset": 7660.559,
      "duration": 3.441
    },
    {
      "lang": "en",
      "text": "documents you get what's called a base",
      "offset": 7662.119,
      "duration": 3.641
    },
    {
      "lang": "en",
      "text": "model and it's basically an internet",
      "offset": 7664,
      "duration": 4.84
    },
    {
      "lang": "en",
      "text": "document simulator right now we saw that",
      "offset": 7665.76,
      "duration": 5.439
    },
    {
      "lang": "en",
      "text": "this is an interesting artifact and uh",
      "offset": 7668.84,
      "duration": 4.52
    },
    {
      "lang": "en",
      "text": "this takes many months to train on",
      "offset": 7671.199,
      "duration": 3.761
    },
    {
      "lang": "en",
      "text": "thousands of computers and it's kind of",
      "offset": 7673.36,
      "duration": 3.719
    },
    {
      "lang": "en",
      "text": "a lossy compression of the internet and",
      "offset": 7674.96,
      "duration": 3.599
    },
    {
      "lang": "en",
      "text": "it's extremely interesting but it's not",
      "offset": 7677.079,
      "duration": 3.441
    },
    {
      "lang": "en",
      "text": "directly useful because we don't want to",
      "offset": 7678.559,
      "duration": 4.12
    },
    {
      "lang": "en",
      "text": "sample internet documents we want to ask",
      "offset": 7680.52,
      "duration": 4.52
    },
    {
      "lang": "en",
      "text": "questions of an AI and have it respond",
      "offset": 7682.679,
      "duration": 4.601
    },
    {
      "lang": "en",
      "text": "to our questions so for that we need an",
      "offset": 7685.04,
      "duration": 4.039
    },
    {
      "lang": "en",
      "text": "assistant and we saw that we can",
      "offset": 7687.28,
      "duration": 4.04
    },
    {
      "lang": "en",
      "text": "actually construct an assistant in the",
      "offset": 7689.079,
      "duration": 4.881
    },
    {
      "lang": "en",
      "text": "process of a post",
      "offset": 7691.32,
      "duration": 5.319
    },
    {
      "lang": "en",
      "text": "training and specifically in the process",
      "offset": 7693.96,
      "duration": 5.48
    },
    {
      "lang": "en",
      "text": "of supervised fine-tuning as we call",
      "offset": 7696.639,
      "duration": 6.08
    },
    {
      "lang": "en",
      "text": "it so in this stage we saw that it's",
      "offset": 7699.44,
      "duration": 4.639
    },
    {
      "lang": "en",
      "text": "algorithmically identical to",
      "offset": 7702.719,
      "duration": 3.241
    },
    {
      "lang": "en",
      "text": "pre-training nothing is going to change",
      "offset": 7704.079,
      "duration": 3.441
    },
    {
      "lang": "en",
      "text": "the only thing that changes is the data",
      "offset": 7705.96,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "set so instead of Internet documents we",
      "offset": 7707.52,
      "duration": 5.24
    },
    {
      "lang": "en",
      "text": "now want to create and curate a very",
      "offset": 7710.04,
      "duration": 5.32
    },
    {
      "lang": "en",
      "text": "nice data set of conversations so we",
      "offset": 7712.76,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "want Millions conversations on all kinds",
      "offset": 7715.36,
      "duration": 6.279
    },
    {
      "lang": "en",
      "text": "of diverse topics between a human and an",
      "offset": 7718.28,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "assistant and fundamentally these",
      "offset": 7721.639,
      "duration": 5.48
    },
    {
      "lang": "en",
      "text": "conversations are created by humans so",
      "offset": 7724.28,
      "duration": 5.64
    },
    {
      "lang": "en",
      "text": "humans write the prompts and humans",
      "offset": 7727.119,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "write the ideal response responses and",
      "offset": 7729.92,
      "duration": 4.679
    },
    {
      "lang": "en",
      "text": "they do that based on labeling",
      "offset": 7732.239,
      "duration": 5.081
    },
    {
      "lang": "en",
      "text": "documentations now in the modern stack",
      "offset": 7734.599,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "it's not actually done fully and",
      "offset": 7737.32,
      "duration": 3.48
    },
    {
      "lang": "en",
      "text": "manually by humans right they actually",
      "offset": 7739,
      "duration": 3.8
    },
    {
      "lang": "en",
      "text": "now have a lot of help from these tools",
      "offset": 7740.8,
      "duration": 4.839
    },
    {
      "lang": "en",
      "text": "so we can use language models um to help",
      "offset": 7742.8,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "us create these data sets and that's",
      "offset": 7745.639,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "done extensively but fundamentally it's",
      "offset": 7747.119,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "all still coming from Human curation at",
      "offset": 7749.159,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "the end so we create these conversations",
      "offset": 7750.96,
      "duration": 4.639
    },
    {
      "lang": "en",
      "text": "that now becomes our data set we fine",
      "offset": 7753.719,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "tune on it or continue training on it",
      "offset": 7755.599,
      "duration": 4.6
    },
    {
      "lang": "en",
      "text": "and we get an assistant and then we kind",
      "offset": 7757.88,
      "duration": 3.64
    },
    {
      "lang": "en",
      "text": "of shifted gears and started talking",
      "offset": 7760.199,
      "duration": 2.681
    },
    {
      "lang": "en",
      "text": "about some of the kind of cognitive",
      "offset": 7761.52,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "implications of what this assistant is",
      "offset": 7762.88,
      "duration": 3.88
    },
    {
      "lang": "en",
      "text": "like and we saw that for example the",
      "offset": 7764.88,
      "duration": 4.719
    },
    {
      "lang": "en",
      "text": "assistant will hallucinate if you don't",
      "offset": 7766.76,
      "duration": 5.72
    },
    {
      "lang": "en",
      "text": "take some sort of mitigations towards it",
      "offset": 7769.599,
      "duration": 4.761
    },
    {
      "lang": "en",
      "text": "so we saw that hallucinations would be",
      "offset": 7772.48,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "common and then we looked at some of the",
      "offset": 7774.36,
      "duration": 3.96
    },
    {
      "lang": "en",
      "text": "mitigations of those hallucinations and",
      "offset": 7775.84,
      "duration": 3.64
    },
    {
      "lang": "en",
      "text": "then we saw that the models are quite",
      "offset": 7778.32,
      "duration": 2.52
    },
    {
      "lang": "en",
      "text": "impressive and can do a lot of stuff in",
      "offset": 7779.48,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "their head but we saw that they can also",
      "offset": 7780.84,
      "duration": 4.68
    },
    {
      "lang": "en",
      "text": "Lean On Tools to become better so for",
      "offset": 7783,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "example we can lo lean on a web search",
      "offset": 7785.52,
      "duration": 5.4
    },
    {
      "lang": "en",
      "text": "in order to hallucinate less and to",
      "offset": 7788.36,
      "duration": 4.799
    },
    {
      "lang": "en",
      "text": "maybe bring up some more um recent",
      "offset": 7790.92,
      "duration": 4.04
    },
    {
      "lang": "en",
      "text": "information or something like that or we",
      "offset": 7793.159,
      "duration": 3.881
    },
    {
      "lang": "en",
      "text": "can lean on tools like code interpreter",
      "offset": 7794.96,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "so the code can so the llm can write",
      "offset": 7797.04,
      "duration": 3.679
    },
    {
      "lang": "en",
      "text": "some code and actually run it and see",
      "offset": 7799.119,
      "duration": 2.721
    },
    {
      "lang": "en",
      "text": "the",
      "offset": 7800.719,
      "duration": 3.201
    },
    {
      "lang": "en",
      "text": "results so these are some of the topics",
      "offset": 7801.84,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "we looked at so far um now what I'd like",
      "offset": 7803.92,
      "duration": 5.4
    },
    {
      "lang": "en",
      "text": "to do is I'd like to cover the last and",
      "offset": 7806.4,
      "duration": 6.319
    },
    {
      "lang": "en",
      "text": "major stage of this Pipeline and that is",
      "offset": 7809.32,
      "duration": 6.279
    },
    {
      "lang": "en",
      "text": "reinforcement learning so reinforcement",
      "offset": 7812.719,
      "duration": 4.241
    },
    {
      "lang": "en",
      "text": "learning is still kind of thought to be",
      "offset": 7815.599,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "under the umbrella of posttraining uh",
      "offset": 7816.96,
      "duration": 5.4
    },
    {
      "lang": "en",
      "text": "but it is the last third major stage and",
      "offset": 7819.52,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "it's a different way of training",
      "offset": 7822.36,
      "duration": 4.359
    },
    {
      "lang": "en",
      "text": "language models and usually follows as",
      "offset": 7824.4,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "this third step so inside companies like",
      "offset": 7826.719,
      "duration": 4.601
    },
    {
      "lang": "en",
      "text": "open AI you will start here and these",
      "offset": 7829.44,
      "duration": 3.96
    },
    {
      "lang": "en",
      "text": "are all separate teams so there's a team",
      "offset": 7831.32,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "doing data for pre-training and a team",
      "offset": 7833.4,
      "duration": 4.36
    },
    {
      "lang": "en",
      "text": "doing training for pre-training and then",
      "offset": 7835.639,
      "duration": 3.96
    },
    {
      "lang": "en",
      "text": "there's a team doing all the",
      "offset": 7837.76,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "conversation generation in a in a",
      "offset": 7839.599,
      "duration": 4.52
    },
    {
      "lang": "en",
      "text": "different team that is kind of doing the",
      "offset": 7842.159,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "supervis fine tuning and there will be a",
      "offset": 7844.119,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "team for the reinforcement learning as",
      "offset": 7845.84,
      "duration": 3.48
    },
    {
      "lang": "en",
      "text": "well so it's kind of like a handoff of",
      "offset": 7847.239,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "these models you get your base model the",
      "offset": 7849.32,
      "duration": 2.919
    },
    {
      "lang": "en",
      "text": "then you find you need to be an",
      "offset": 7851.32,
      "duration": 2.359
    },
    {
      "lang": "en",
      "text": "assistant and then you go into",
      "offset": 7852.239,
      "duration": 2.84
    },
    {
      "lang": "en",
      "text": "reinforcement learning which we'll talk",
      "offset": 7853.679,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "about uh",
      "offset": 7855.079,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "now so that's kind of like the major",
      "offset": 7856.719,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "flow and so let's now focus on",
      "offset": 7858.92,
      "duration": 4.239
    },
    {
      "lang": "en",
      "text": "reinforcement learning the last major",
      "offset": 7861.119,
      "duration": 4.44
    },
    {
      "lang": "en",
      "text": "stage of training and let me first",
      "offset": 7863.159,
      "duration": 4.201
    },
    {
      "lang": "en",
      "text": "actually motivate it and why we would",
      "offset": 7865.559,
      "duration": 3.56
    },
    {
      "lang": "en",
      "text": "want to do reinforcement learning and",
      "offset": 7867.36,
      "duration": 3.799
    },
    {
      "lang": "en",
      "text": "what it looks like on a high level so I",
      "offset": 7869.119,
      "duration": 3.48
    },
    {
      "lang": "en",
      "text": "would now like to try to motivate the",
      "offset": 7871.159,
      "duration": 2.721
    },
    {
      "lang": "en",
      "text": "reinforcement learning stage and what it",
      "offset": 7872.599,
      "duration": 2.721
    },
    {
      "lang": "en",
      "text": "corresponds to with something that",
      "offset": 7873.88,
      "duration": 3.08
    },
    {
      "lang": "en",
      "text": "you're probably familiar with and that",
      "offset": 7875.32,
      "duration": 3.799
    },
    {
      "lang": "en",
      "text": "is basically going to school so just",
      "offset": 7876.96,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "like you went to school to become um",
      "offset": 7879.119,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "really good at something we want to take",
      "offset": 7881.36,
      "duration": 4.44
    },
    {
      "lang": "en",
      "text": "large language models through school and",
      "offset": 7883.119,
      "duration": 6.401
    },
    {
      "lang": "en",
      "text": "really what we're doing is um we're um",
      "offset": 7885.8,
      "duration": 6.359
    },
    {
      "lang": "en",
      "text": "we have a few paradigms of ways of uh",
      "offset": 7889.52,
      "duration": 4.44
    },
    {
      "lang": "en",
      "text": "giving them knowledge or transferring",
      "offset": 7892.159,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "skills so in particular when we're",
      "offset": 7893.96,
      "duration": 4.36
    },
    {
      "lang": "en",
      "text": "working with textbooks in school you'll",
      "offset": 7896.159,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "see that there are three major kind of",
      "offset": 7898.32,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "uh pieces of information in these",
      "offset": 7900.559,
      "duration": 5.08
    },
    {
      "lang": "en",
      "text": "textbooks three classes of information",
      "offset": 7902.88,
      "duration": 3.96
    },
    {
      "lang": "en",
      "text": "the first thing you'll see is you'll see",
      "offset": 7905.639,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "a lot of exposition um and by the way",
      "offset": 7906.84,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "this is a totally random book I pulled",
      "offset": 7909.239,
      "duration": 2.721
    },
    {
      "lang": "en",
      "text": "from the internet I I think it's some",
      "offset": 7910.52,
      "duration": 2.679
    },
    {
      "lang": "en",
      "text": "kind of an organic chemistry or",
      "offset": 7911.96,
      "duration": 3.199
    },
    {
      "lang": "en",
      "text": "something I'm not sure uh but the",
      "offset": 7913.199,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "important thing is that you'll see that",
      "offset": 7915.159,
      "duration": 3.361
    },
    {
      "lang": "en",
      "text": "most of the text most of it is kind of",
      "offset": 7916.639,
      "duration": 4.241
    },
    {
      "lang": "en",
      "text": "just like the meat of it is exposition",
      "offset": 7918.52,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "it's kind of like background knowledge",
      "offset": 7920.88,
      "duration": 4.799
    },
    {
      "lang": "en",
      "text": "Etc as you are reading through the words",
      "offset": 7922.52,
      "duration": 5.559
    },
    {
      "lang": "en",
      "text": "of this Exposition you can think of that",
      "offset": 7925.679,
      "duration": 6.721
    },
    {
      "lang": "en",
      "text": "roughly as training on that data so um",
      "offset": 7928.079,
      "duration": 5.441
    },
    {
      "lang": "en",
      "text": "and that's why when you're reading",
      "offset": 7932.4,
      "duration": 2.44
    },
    {
      "lang": "en",
      "text": "through this stuff this background",
      "offset": 7933.52,
      "duration": 2.48
    },
    {
      "lang": "en",
      "text": "knowledge and this all this context",
      "offset": 7934.84,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "information it's kind of equivalent to",
      "offset": 7936,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "pre-training so it's it's where we build",
      "offset": 7938.679,
      "duration": 5
    },
    {
      "lang": "en",
      "text": "sort of like a knowledge base of this",
      "offset": 7941.44,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "data and get a sense of the topic the",
      "offset": 7943.679,
      "duration": 5.201
    },
    {
      "lang": "en",
      "text": "next major kind of information that you",
      "offset": 7947.04,
      "duration": 5.88
    },
    {
      "lang": "en",
      "text": "will see is these uh problems and with",
      "offset": 7948.88,
      "duration": 6.64
    },
    {
      "lang": "en",
      "text": "their worked Solutions so basically a",
      "offset": 7952.92,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "human expert in this case uh the author",
      "offset": 7955.52,
      "duration": 3.8
    },
    {
      "lang": "en",
      "text": "of this book has given us not just a",
      "offset": 7957.4,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "problem but has also worked through the",
      "offset": 7959.32,
      "duration": 4.279
    },
    {
      "lang": "en",
      "text": "solution and the solution is basically",
      "offset": 7961.48,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "like equivalent to having like this",
      "offset": 7963.599,
      "duration": 4.52
    },
    {
      "lang": "en",
      "text": "ideal response for an assistant so it's",
      "offset": 7965.8,
      "duration": 4.12
    },
    {
      "lang": "en",
      "text": "basically the expert is showing us how",
      "offset": 7968.119,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "to solve the problem in it's uh kind of",
      "offset": 7969.92,
      "duration": 5.239
    },
    {
      "lang": "en",
      "text": "like um in its full form so as we are",
      "offset": 7972.28,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "reading the solution we are basically",
      "offset": 7975.159,
      "duration": 6.04
    },
    {
      "lang": "en",
      "text": "training on the expert data and then",
      "offset": 7977.96,
      "duration": 5.88
    },
    {
      "lang": "en",
      "text": "later we can try to imitate the expert",
      "offset": 7981.199,
      "duration": 6.04
    },
    {
      "lang": "en",
      "text": "um and basically um that's that roughly",
      "offset": 7983.84,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "correspond to having the sft model",
      "offset": 7987.239,
      "duration": 3.96
    },
    {
      "lang": "en",
      "text": "that's what it would be doing so",
      "offset": 7988.88,
      "duration": 3.359
    },
    {
      "lang": "en",
      "text": "basically we've already done",
      "offset": 7991.199,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "pre-training and we've already covered",
      "offset": 7992.239,
      "duration": 5.201
    },
    {
      "lang": "en",
      "text": "this um imitation of experts and how",
      "offset": 7994.639,
      "duration": 5.281
    },
    {
      "lang": "en",
      "text": "they solve these problems and the third",
      "offset": 7997.44,
      "duration": 4.279
    },
    {
      "lang": "en",
      "text": "stage of reinforcement learning is",
      "offset": 7999.92,
      "duration": 4.36
    },
    {
      "lang": "en",
      "text": "basically the practice problems so",
      "offset": 8001.719,
      "duration": 3.96
    },
    {
      "lang": "en",
      "text": "sometimes you'll see this is just a",
      "offset": 8004.28,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "single practice problem here but of",
      "offset": 8005.679,
      "duration": 3
    },
    {
      "lang": "en",
      "text": "course there will be usually many",
      "offset": 8007.4,
      "duration": 2.719
    },
    {
      "lang": "en",
      "text": "practice problems at the end of each",
      "offset": 8008.679,
      "duration": 4.04
    },
    {
      "lang": "en",
      "text": "chapter in any textbook and practice",
      "offset": 8010.119,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "problems of course we know are critical",
      "offset": 8012.719,
      "duration": 3.4
    },
    {
      "lang": "en",
      "text": "for learning because what are they",
      "offset": 8014.119,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "getting you to do they're getting you to",
      "offset": 8016.119,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "practice uh to practice yourself and",
      "offset": 8017.719,
      "duration": 4.44
    },
    {
      "lang": "en",
      "text": "discover ways of solving these problems",
      "offset": 8019.96,
      "duration": 4.279
    },
    {
      "lang": "en",
      "text": "yourself and so what you get in a",
      "offset": 8022.159,
      "duration": 4.121
    },
    {
      "lang": "en",
      "text": "practice problem is you get a problem",
      "offset": 8024.239,
      "duration": 4.281
    },
    {
      "lang": "en",
      "text": "description but you're not given the",
      "offset": 8026.28,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "solution but you are given the final",
      "offset": 8028.52,
      "duration": 4.559
    },
    {
      "lang": "en",
      "text": "answer answer usually in the answer key",
      "offset": 8030.84,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "of the textbook and so you know the",
      "offset": 8033.079,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "final answer that you're trying to get",
      "offset": 8035.32,
      "duration": 3.279
    },
    {
      "lang": "en",
      "text": "to and you have the problem statement",
      "offset": 8036.599,
      "duration": 3.801
    },
    {
      "lang": "en",
      "text": "but you don't have the solution you are",
      "offset": 8038.599,
      "duration": 3.96
    },
    {
      "lang": "en",
      "text": "trying to practice the solution you're",
      "offset": 8040.4,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "trying out many different things and",
      "offset": 8042.559,
      "duration": 4.761
    },
    {
      "lang": "en",
      "text": "you're seeing what gets you to the final",
      "offset": 8044.32,
      "duration": 5.239
    },
    {
      "lang": "en",
      "text": "solution the best and so you're",
      "offset": 8047.32,
      "duration": 4.279
    },
    {
      "lang": "en",
      "text": "discovering how to solve these problems",
      "offset": 8049.559,
      "duration": 3.481
    },
    {
      "lang": "en",
      "text": "so and in the process of that you're",
      "offset": 8051.599,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "relying on number one the background",
      "offset": 8053.04,
      "duration": 2.8
    },
    {
      "lang": "en",
      "text": "information which comes from",
      "offset": 8054.639,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "pre-training and number two maybe a",
      "offset": 8055.84,
      "duration": 4.6
    },
    {
      "lang": "en",
      "text": "little bit of imitation of human experts",
      "offset": 8057.679,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "and you can probably try similar kinds",
      "offset": 8060.44,
      "duration": 4.679
    },
    {
      "lang": "en",
      "text": "of solutions and so on so we've done",
      "offset": 8062.159,
      "duration": 5.08
    },
    {
      "lang": "en",
      "text": "this and this and now in this section",
      "offset": 8065.119,
      "duration": 5.08
    },
    {
      "lang": "en",
      "text": "we're going to try to practice and so",
      "offset": 8067.239,
      "duration": 4.84
    },
    {
      "lang": "en",
      "text": "we're going to be given prompts we're",
      "offset": 8070.199,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "going to be given Solutions U sorry the",
      "offset": 8072.079,
      "duration": 4.201
    },
    {
      "lang": "en",
      "text": "final answers but we're not going to be",
      "offset": 8074.52,
      "duration": 4.199
    },
    {
      "lang": "en",
      "text": "given expert Solutions we have to",
      "offset": 8076.28,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "practice and try stuff out and that's",
      "offset": 8078.719,
      "duration": 4.44
    },
    {
      "lang": "en",
      "text": "what reinforcement learning is about",
      "offset": 8080.76,
      "duration": 3.64
    },
    {
      "lang": "en",
      "text": "okay so let's go back to the problem",
      "offset": 8083.159,
      "duration": 3.121
    },
    {
      "lang": "en",
      "text": "that we worked with previously just so",
      "offset": 8084.4,
      "duration": 3.319
    },
    {
      "lang": "en",
      "text": "we have a concrete example to talk",
      "offset": 8086.28,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "through as we explore sort of the topic",
      "offset": 8087.719,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "here so um I'm here in the Teck",
      "offset": 8090.04,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "tokenizer because I'd also like to well",
      "offset": 8092.679,
      "duration": 4.52
    },
    {
      "lang": "en",
      "text": "I get a text box which is useful but",
      "offset": 8095,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "number two I want to remind you again",
      "offset": 8097.199,
      "duration": 2.721
    },
    {
      "lang": "en",
      "text": "that we're always working with",
      "offset": 8099,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "onedimensional token sequences and so um",
      "offset": 8099.92,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "I actually like prefer this view because",
      "offset": 8102.84,
      "duration": 3.48
    },
    {
      "lang": "en",
      "text": "this is like the native view of the llm",
      "offset": 8104.48,
      "duration": 3.679
    },
    {
      "lang": "en",
      "text": "if that makes sense like this is what it",
      "offset": 8106.32,
      "duration": 4.759
    },
    {
      "lang": "en",
      "text": "actually sees it sees token IDs right",
      "offset": 8108.159,
      "duration": 5.96
    },
    {
      "lang": "en",
      "text": "okay so Emily buys three apples and two",
      "offset": 8111.079,
      "duration": 6.281
    },
    {
      "lang": "en",
      "text": "oranges each orange is $2 the total cost",
      "offset": 8114.119,
      "duration": 5.841
    },
    {
      "lang": "en",
      "text": "of all the fruit is $13 what is the cost",
      "offset": 8117.36,
      "duration": 4.279
    },
    {
      "lang": "en",
      "text": "of each apple",
      "offset": 8119.96,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "and what I'd like to what I like you to",
      "offset": 8121.639,
      "duration": 4.681
    },
    {
      "lang": "en",
      "text": "appreciate here is these are like four",
      "offset": 8123.4,
      "duration": 5.96
    },
    {
      "lang": "en",
      "text": "possible candidate Solutions as an",
      "offset": 8126.32,
      "duration": 5.399
    },
    {
      "lang": "en",
      "text": "example and they all reach the answer",
      "offset": 8129.36,
      "duration": 4.04
    },
    {
      "lang": "en",
      "text": "three now what I'd like you to",
      "offset": 8131.719,
      "duration": 3.761
    },
    {
      "lang": "en",
      "text": "appreciate at this point is that if I am",
      "offset": 8133.4,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "the human data labeler that is creating",
      "offset": 8135.48,
      "duration": 3.8
    },
    {
      "lang": "en",
      "text": "a conversation to be entered into the",
      "offset": 8137.719,
      "duration": 4.281
    },
    {
      "lang": "en",
      "text": "training set I don't actually really",
      "offset": 8139.28,
      "duration": 4.839
    },
    {
      "lang": "en",
      "text": "know which of these",
      "offset": 8142,
      "duration": 6.36
    },
    {
      "lang": "en",
      "text": "conversations to um to add to the data",
      "offset": 8144.119,
      "duration": 6.201
    },
    {
      "lang": "en",
      "text": "set some of these conversations kind of",
      "offset": 8148.36,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "set up a system equations some of them",
      "offset": 8150.32,
      "duration": 3.72
    },
    {
      "lang": "en",
      "text": "sort of like just talk through it in",
      "offset": 8152.52,
      "duration": 3.199
    },
    {
      "lang": "en",
      "text": "English and some of them just kind of",
      "offset": 8154.04,
      "duration": 4.199
    },
    {
      "lang": "en",
      "text": "like skip right through to the",
      "offset": 8155.719,
      "duration": 5
    },
    {
      "lang": "en",
      "text": "solution um if you look at chbt for",
      "offset": 8158.239,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "example and you give it this question it",
      "offset": 8160.719,
      "duration": 4.44
    },
    {
      "lang": "en",
      "text": "defines a system of variables and it",
      "offset": 8163.679,
      "duration": 3.56
    },
    {
      "lang": "en",
      "text": "kind of like does this little thing what",
      "offset": 8165.159,
      "duration": 3.801
    },
    {
      "lang": "en",
      "text": "we have to appreciate and uh",
      "offset": 8167.239,
      "duration": 5.161
    },
    {
      "lang": "en",
      "text": "differentiate between though is um the",
      "offset": 8168.96,
      "duration": 5.32
    },
    {
      "lang": "en",
      "text": "first purpose of a solution is to reach",
      "offset": 8172.4,
      "duration": 3.279
    },
    {
      "lang": "en",
      "text": "the right answer of course we want to",
      "offset": 8174.28,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "get the final answer three that is the",
      "offset": 8175.679,
      "duration": 4.201
    },
    {
      "lang": "en",
      "text": "that is the important purpose here but",
      "offset": 8177.96,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "there's kind of like a secondary purpose",
      "offset": 8179.88,
      "duration": 3.679
    },
    {
      "lang": "en",
      "text": "as well where here we are also just kind",
      "offset": 8181.48,
      "duration": 4.599
    },
    {
      "lang": "en",
      "text": "of trying to make it like nice uh for",
      "offset": 8183.559,
      "duration": 4.361
    },
    {
      "lang": "en",
      "text": "the human because we're kind of assuming",
      "offset": 8186.079,
      "duration": 2.961
    },
    {
      "lang": "en",
      "text": "that the person wants to see the",
      "offset": 8187.92,
      "duration": 2.199
    },
    {
      "lang": "en",
      "text": "solution they want to see the",
      "offset": 8189.04,
      "duration": 2.84
    },
    {
      "lang": "en",
      "text": "intermediate steps we want to present it",
      "offset": 8190.119,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "nicely Etc so there are two separate",
      "offset": 8191.88,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "things going on here number one is the",
      "offset": 8193.96,
      "duration": 3.759
    },
    {
      "lang": "en",
      "text": "presentation for the human but number",
      "offset": 8196.04,
      "duration": 2.84
    },
    {
      "lang": "en",
      "text": "two we're trying to actually get the",
      "offset": 8197.719,
      "duration": 4.441
    },
    {
      "lang": "en",
      "text": "right answer um so let's for the moment",
      "offset": 8198.88,
      "duration": 6.08
    },
    {
      "lang": "en",
      "text": "focus on just reaching the final answer",
      "offset": 8202.16,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "if we're only care if we only care about",
      "offset": 8204.96,
      "duration": 4.599
    },
    {
      "lang": "en",
      "text": "the final answer then which of these is",
      "offset": 8206.8,
      "duration": 6.839
    },
    {
      "lang": "en",
      "text": "the optimal or the best prompt um sorry",
      "offset": 8209.559,
      "duration": 6.601
    },
    {
      "lang": "en",
      "text": "the best solution for the llm to reach",
      "offset": 8213.639,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "the right",
      "offset": 8216.16,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "answer um and what I'm trying to get at",
      "offset": 8217.639,
      "duration": 5.361
    },
    {
      "lang": "en",
      "text": "is we don't know me as a human labeler I",
      "offset": 8220.479,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "would not know which one of these is",
      "offset": 8223,
      "duration": 4.359
    },
    {
      "lang": "en",
      "text": "best so as an example we saw earlier on",
      "offset": 8224.399,
      "duration": 5
    },
    {
      "lang": "en",
      "text": "when we looked at",
      "offset": 8227.359,
      "duration": 4.36
    },
    {
      "lang": "en",
      "text": "um the token sequences here and the",
      "offset": 8229.399,
      "duration": 4.681
    },
    {
      "lang": "en",
      "text": "mental arithmetic and reasoning we saw",
      "offset": 8231.719,
      "duration": 4.041
    },
    {
      "lang": "en",
      "text": "that for each token we can only spend",
      "offset": 8234.08,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "basically a finite number of finite",
      "offset": 8235.76,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "amount of compute here that is not very",
      "offset": 8238.08,
      "duration": 2.68
    },
    {
      "lang": "en",
      "text": "large or you should think about it that",
      "offset": 8239.599,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "way way and so we can't actually make",
      "offset": 8240.76,
      "duration": 5.879
    },
    {
      "lang": "en",
      "text": "too big of a leap in any one token is is",
      "offset": 8243.519,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "maybe the way to think about it so as an",
      "offset": 8246.639,
      "duration": 4.281
    },
    {
      "lang": "en",
      "text": "example in this one what's really nice",
      "offset": 8248.719,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "about it is that it's very few tokens so",
      "offset": 8250.92,
      "duration": 3.08
    },
    {
      "lang": "en",
      "text": "it's going to take us very short amount",
      "offset": 8252.559,
      "duration": 4.441
    },
    {
      "lang": "en",
      "text": "of time to get to the answer but right",
      "offset": 8254,
      "duration": 5.519
    },
    {
      "lang": "en",
      "text": "here when we're doing 30 - 4 IDE 3",
      "offset": 8257,
      "duration": 5.599
    },
    {
      "lang": "en",
      "text": "equals right in this token here we're",
      "offset": 8259.519,
      "duration": 4.561
    },
    {
      "lang": "en",
      "text": "actually asking for a lot of computation",
      "offset": 8262.599,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "to happen on that single individual",
      "offset": 8264.08,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "token and so maybe this is a bad example",
      "offset": 8265.719,
      "duration": 3.64
    },
    {
      "lang": "en",
      "text": "to give to the llm because it's kind of",
      "offset": 8268,
      "duration": 2.84
    },
    {
      "lang": "en",
      "text": "incentivizing it to skip through the",
      "offset": 8269.359,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "calculations very quickly and it's going",
      "offset": 8270.84,
      "duration": 3.479
    },
    {
      "lang": "en",
      "text": "to actually make up mistakes make",
      "offset": 8272.399,
      "duration": 4.481
    },
    {
      "lang": "en",
      "text": "mistakes in this mental arithmetic uh so",
      "offset": 8274.319,
      "duration": 3.961
    },
    {
      "lang": "en",
      "text": "maybe it would work better to like",
      "offset": 8276.88,
      "duration": 4.12
    },
    {
      "lang": "en",
      "text": "spread out the spread it out more maybe",
      "offset": 8278.28,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "it would be better to set it up as an",
      "offset": 8281,
      "duration": 3.16
    },
    {
      "lang": "en",
      "text": "equation maybe it would be better to",
      "offset": 8282.359,
      "duration": 3.96
    },
    {
      "lang": "en",
      "text": "talk through it we fundamentally don't",
      "offset": 8284.16,
      "duration": 5.479
    },
    {
      "lang": "en",
      "text": "know and we don't know because what is",
      "offset": 8286.319,
      "duration": 5.921
    },
    {
      "lang": "en",
      "text": "easy for you or I as or as human",
      "offset": 8289.639,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "labelers what's easy for us or hard for",
      "offset": 8292.24,
      "duration": 4.479
    },
    {
      "lang": "en",
      "text": "us is different than what's easy or hard",
      "offset": 8294.439,
      "duration": 5.761
    },
    {
      "lang": "en",
      "text": "for the llm it cognition is different um",
      "offset": 8296.719,
      "duration": 6.441
    },
    {
      "lang": "en",
      "text": "and the token sequences are kind of like",
      "offset": 8300.2,
      "duration": 7.319
    },
    {
      "lang": "en",
      "text": "different hard for it and so some of the",
      "offset": 8303.16,
      "duration": 7.239
    },
    {
      "lang": "en",
      "text": "token sequences here that are trivial",
      "offset": 8307.519,
      "duration": 6.2
    },
    {
      "lang": "en",
      "text": "for me might be um very too much of a",
      "offset": 8310.399,
      "duration": 6.361
    },
    {
      "lang": "en",
      "text": "leap for the llm so right here this",
      "offset": 8313.719,
      "duration": 4.76
    },
    {
      "lang": "en",
      "text": "token would be way too hard but",
      "offset": 8316.76,
      "duration": 3.759
    },
    {
      "lang": "en",
      "text": "conversely many of the tokens that I'm",
      "offset": 8318.479,
      "duration": 4.801
    },
    {
      "lang": "en",
      "text": "creating here might be just trivial to",
      "offset": 8320.519,
      "duration": 4.721
    },
    {
      "lang": "en",
      "text": "the llm and we're just wasting tokens",
      "offset": 8323.28,
      "duration": 3.56
    },
    {
      "lang": "en",
      "text": "like why waste all these tokens when",
      "offset": 8325.24,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "this is all trivial so if the only thing",
      "offset": 8326.84,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "we care care about is the final answer",
      "offset": 8329.399,
      "duration": 3.881
    },
    {
      "lang": "en",
      "text": "and we're separating out the issue of",
      "offset": 8331.88,
      "duration": 4.28
    },
    {
      "lang": "en",
      "text": "the presentation to the human um then we",
      "offset": 8333.28,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "don't actually really know how to",
      "offset": 8336.16,
      "duration": 3.08
    },
    {
      "lang": "en",
      "text": "annotate this example we don't know what",
      "offset": 8337.2,
      "duration": 3.88
    },
    {
      "lang": "en",
      "text": "solution to get to the llm because we",
      "offset": 8339.24,
      "duration": 2.96
    },
    {
      "lang": "en",
      "text": "are not the",
      "offset": 8341.08,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "llm and it's clear here in the case of",
      "offset": 8342.2,
      "duration": 5
    },
    {
      "lang": "en",
      "text": "like the math example but this is",
      "offset": 8345.16,
      "duration": 3.64
    },
    {
      "lang": "en",
      "text": "actually like a very pervasive issue",
      "offset": 8347.2,
      "duration": 4.76
    },
    {
      "lang": "en",
      "text": "like for our knowledge is not lm's",
      "offset": 8348.8,
      "duration": 4.879
    },
    {
      "lang": "en",
      "text": "knowledge like the llm actually has a",
      "offset": 8351.96,
      "duration": 3.399
    },
    {
      "lang": "en",
      "text": "ton of knowledge of PhD in math and",
      "offset": 8353.679,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "physics chemistry and whatnot so in many",
      "offset": 8355.359,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "ways it actually knows more than I do",
      "offset": 8357.359,
      "duration": 4.2
    },
    {
      "lang": "en",
      "text": "and I'm I'm potentially not utilizing",
      "offset": 8359.439,
      "duration": 4.561
    },
    {
      "lang": "en",
      "text": "that knowledge in its problem solving",
      "offset": 8361.559,
      "duration": 4.561
    },
    {
      "lang": "en",
      "text": "but conversely I might be injecting a",
      "offset": 8364,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "bunch of knowledge in my solutions that",
      "offset": 8366.12,
      "duration": 5.199
    },
    {
      "lang": "en",
      "text": "the LM doesn't know in its parameters",
      "offset": 8368.08,
      "duration": 5.239
    },
    {
      "lang": "en",
      "text": "and then those are like sudden leaps",
      "offset": 8371.319,
      "duration": 4.801
    },
    {
      "lang": "en",
      "text": "that are very confusing to the model and",
      "offset": 8373.319,
      "duration": 5.521
    },
    {
      "lang": "en",
      "text": "so our cognitions are different and I",
      "offset": 8376.12,
      "duration": 5.279
    },
    {
      "lang": "en",
      "text": "don't really know what to put here if",
      "offset": 8378.84,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "all we care about is the reaching the",
      "offset": 8381.399,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "final solution and doing it economically",
      "offset": 8382.84,
      "duration": 7
    },
    {
      "lang": "en",
      "text": "ideally and so long story short we are",
      "offset": 8385.8,
      "duration": 6.88
    },
    {
      "lang": "en",
      "text": "not in a good position to create these",
      "offset": 8389.84,
      "duration": 5.599
    },
    {
      "lang": "en",
      "text": "uh token sequences for the LM and",
      "offset": 8392.68,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "they're useful by imitation to",
      "offset": 8395.439,
      "duration": 4.281
    },
    {
      "lang": "en",
      "text": "initialize the system but we really want",
      "offset": 8396.84,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "the llm to discover the token sequences",
      "offset": 8399.72,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "that work for it we need to find it",
      "offset": 8401.88,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "needs to find for itself what token",
      "offset": 8404.6,
      "duration": 5.08
    },
    {
      "lang": "en",
      "text": "sequence reliably gets to the answer",
      "offset": 8406.92,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "given the prompt and it needs to",
      "offset": 8409.68,
      "duration": 2.96
    },
    {
      "lang": "en",
      "text": "discover that in the process of",
      "offset": 8411.64,
      "duration": 2.759
    },
    {
      "lang": "en",
      "text": "reinforcement learning and of trial and",
      "offset": 8412.64,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "error so let's see how this example",
      "offset": 8414.399,
      "duration": 5.561
    },
    {
      "lang": "en",
      "text": "would work like in reinforcement",
      "offset": 8418,
      "duration": 3.16
    },
    {
      "lang": "en",
      "text": "learning",
      "offset": 8419.96,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "okay so we're now back in the huging",
      "offset": 8421.16,
      "duration": 4.92
    },
    {
      "lang": "en",
      "text": "face inference playground and uh that",
      "offset": 8423.08,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "just allows me to very easily call uh",
      "offset": 8426.08,
      "duration": 3.64
    },
    {
      "lang": "en",
      "text": "different kinds of models so as an",
      "offset": 8428.2,
      "duration": 2.92
    },
    {
      "lang": "en",
      "text": "example here on the top right I chose",
      "offset": 8429.72,
      "duration": 4.759
    },
    {
      "lang": "en",
      "text": "the Gemma 2 2 billion parameter model so",
      "offset": 8431.12,
      "duration": 5.359
    },
    {
      "lang": "en",
      "text": "two billion is very very small so this",
      "offset": 8434.479,
      "duration": 4.641
    },
    {
      "lang": "en",
      "text": "is a tiny model but it's okay so we're",
      "offset": 8436.479,
      "duration": 4.201
    },
    {
      "lang": "en",
      "text": "going to give it um the way that",
      "offset": 8439.12,
      "duration": 2.8
    },
    {
      "lang": "en",
      "text": "reinforcement learning will basically",
      "offset": 8440.68,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "work is actually quite quite simple um",
      "offset": 8441.92,
      "duration": 5.439
    },
    {
      "lang": "en",
      "text": "we need to try many different kinds of",
      "offset": 8444.68,
      "duration": 4.44
    },
    {
      "lang": "en",
      "text": "solutions and we want to see which",
      "offset": 8447.359,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "Solutions work well or not",
      "offset": 8449.12,
      "duration": 4.04
    },
    {
      "lang": "en",
      "text": "so we're basically going to take the",
      "offset": 8451.28,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "prompt we're going to run the",
      "offset": 8453.16,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "model and the model generates a solution",
      "offset": 8455.359,
      "duration": 4.601
    },
    {
      "lang": "en",
      "text": "and then we're going to inspect the",
      "offset": 8458.84,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "solution and we know that the correct",
      "offset": 8459.96,
      "duration": 5.24
    },
    {
      "lang": "en",
      "text": "answer for this one is $3 and so indeed",
      "offset": 8462.2,
      "duration": 4.76
    },
    {
      "lang": "en",
      "text": "the model gets it correct it says it's",
      "offset": 8465.2,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "$3 so this is correct so that's just one",
      "offset": 8466.96,
      "duration": 5
    },
    {
      "lang": "en",
      "text": "attempt at DIS solution so now we're",
      "offset": 8470.08,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "going to delete this and we're going to",
      "offset": 8471.96,
      "duration": 3.479
    },
    {
      "lang": "en",
      "text": "rerun it again let's try a second",
      "offset": 8473.12,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "attempt so the model solves it in a bit",
      "offset": 8475.439,
      "duration": 4.241
    },
    {
      "lang": "en",
      "text": "slightly different way right every",
      "offset": 8477.84,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "single attempt will be a different",
      "offset": 8479.68,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "generation because these models are",
      "offset": 8481.68,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "stochastic systems remember that at",
      "offset": 8483.04,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "every single token here we have a",
      "offset": 8484.8,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "probability distribution and we're",
      "offset": 8486.16,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "sampling from that distribution so we",
      "offset": 8487.84,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "end up kind kind of going down slightly",
      "offset": 8489.68,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "different paths and so this is a second",
      "offset": 8491.68,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "solution that also ends in the correct",
      "offset": 8494.08,
      "duration": 4.44
    },
    {
      "lang": "en",
      "text": "answer now we're going to delete that",
      "offset": 8496.08,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "let's go a third",
      "offset": 8498.52,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "time okay so again slightly different",
      "offset": 8499.84,
      "duration": 4.559
    },
    {
      "lang": "en",
      "text": "solution but also gets it",
      "offset": 8502.12,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "correct now we can actually repeat this",
      "offset": 8504.399,
      "duration": 4.881
    },
    {
      "lang": "en",
      "text": "uh many times and so in practice you",
      "offset": 8506.76,
      "duration": 4.44
    },
    {
      "lang": "en",
      "text": "might actually sample thousand of",
      "offset": 8509.28,
      "duration": 3.56
    },
    {
      "lang": "en",
      "text": "independent Solutions or even like",
      "offset": 8511.2,
      "duration": 3.8
    },
    {
      "lang": "en",
      "text": "million solutions for just a single",
      "offset": 8512.84,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "prompt um and some of them will be",
      "offset": 8515,
      "duration": 3.96
    },
    {
      "lang": "en",
      "text": "correct and some of them will not be",
      "offset": 8517.64,
      "duration": 2.92
    },
    {
      "lang": "en",
      "text": "very correct and basically what we want",
      "offset": 8518.96,
      "duration": 3.439
    },
    {
      "lang": "en",
      "text": "to do is we want to encourage the",
      "offset": 8520.56,
      "duration": 4.799
    },
    {
      "lang": "en",
      "text": "solutions that lead to correct answers",
      "offset": 8522.399,
      "duration": 4.241
    },
    {
      "lang": "en",
      "text": "so let's take a look at what that looks",
      "offset": 8525.359,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "like so if we come back over here here's",
      "offset": 8526.64,
      "duration": 4.2
    },
    {
      "lang": "en",
      "text": "kind of like a cartoon diagram of what",
      "offset": 8529.439,
      "duration": 4.521
    },
    {
      "lang": "en",
      "text": "this is looking like we have a prompt",
      "offset": 8530.84,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "and then we tried many different",
      "offset": 8533.96,
      "duration": 2.76
    },
    {
      "lang": "en",
      "text": "solutions in",
      "offset": 8535.16,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "parallel and some of the solutions um",
      "offset": 8536.72,
      "duration": 4.92
    },
    {
      "lang": "en",
      "text": "might go well so they get the right",
      "offset": 8539.96,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "answer which is in green and some of the",
      "offset": 8541.64,
      "duration": 4.2
    },
    {
      "lang": "en",
      "text": "solutions might go poorly and may not",
      "offset": 8544.12,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "reach the right answer which is red now",
      "offset": 8545.84,
      "duration": 4.12
    },
    {
      "lang": "en",
      "text": "this problem here unfortunately is not",
      "offset": 8548.6,
      "duration": 3.48
    },
    {
      "lang": "en",
      "text": "the best example because it's a trivial",
      "offset": 8549.96,
      "duration": 4.68
    },
    {
      "lang": "en",
      "text": "prompt and as we saw uh even like a two",
      "offset": 8552.08,
      "duration": 4.12
    },
    {
      "lang": "en",
      "text": "billion parameter model always gets it",
      "offset": 8554.64,
      "duration": 3.4
    },
    {
      "lang": "en",
      "text": "right so it's not the best example in",
      "offset": 8556.2,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "that sense but let's just exercise some",
      "offset": 8558.04,
      "duration": 5.64
    },
    {
      "lang": "en",
      "text": "imagination here and let's just suppose",
      "offset": 8560.2,
      "duration": 7.04
    },
    {
      "lang": "en",
      "text": "that the um green ones are good and the",
      "offset": 8563.68,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "red ones are",
      "offset": 8567.24,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "bad okay so we generated 15 Solutions",
      "offset": 8568.64,
      "duration": 5.92
    },
    {
      "lang": "en",
      "text": "only four of them got the right answer",
      "offset": 8572.2,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "and so now what we want to do is",
      "offset": 8574.56,
      "duration": 3.799
    },
    {
      "lang": "en",
      "text": "basically we want to encourage the kinds",
      "offset": 8576.68,
      "duration": 4.2
    },
    {
      "lang": "en",
      "text": "of solutions that lead to right answers",
      "offset": 8578.359,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "so whatever token sequences happened in",
      "offset": 8580.88,
      "duration": 4.439
    },
    {
      "lang": "en",
      "text": "these red Solutions obviously something",
      "offset": 8583.399,
      "duration": 4.481
    },
    {
      "lang": "en",
      "text": "went wrong along the way somewhere and",
      "offset": 8585.319,
      "duration": 4.281
    },
    {
      "lang": "en",
      "text": "uh this was not a good path to take",
      "offset": 8587.88,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "through the solution and whatever token",
      "offset": 8589.6,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "sequences there were in these Green",
      "offset": 8591.72,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "Solutions well things went uh pretty",
      "offset": 8593.04,
      "duration": 5.08
    },
    {
      "lang": "en",
      "text": "well in this situation and so we want to",
      "offset": 8595.24,
      "duration": 5.92
    },
    {
      "lang": "en",
      "text": "do more things like it in prompts like",
      "offset": 8598.12,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "this and the way we encourage this kind",
      "offset": 8601.16,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "of a behavior in the future is we",
      "offset": 8603.64,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "basically train on these sequences um",
      "offset": 8605.24,
      "duration": 4.28
    },
    {
      "lang": "en",
      "text": "but these training sequencies now are",
      "offset": 8608.04,
      "duration": 4.439
    },
    {
      "lang": "en",
      "text": "not coming from expert human annotators",
      "offset": 8609.52,
      "duration": 4.44
    },
    {
      "lang": "en",
      "text": "there's no human who decided that this",
      "offset": 8612.479,
      "duration": 3.521
    },
    {
      "lang": "en",
      "text": "is the correct solution this solution",
      "offset": 8613.96,
      "duration": 4.359
    },
    {
      "lang": "en",
      "text": "came from the model itself so the model",
      "offset": 8616,
      "duration": 4.12
    },
    {
      "lang": "en",
      "text": "is practicing here it's tried out a few",
      "offset": 8618.319,
      "duration": 3.401
    },
    {
      "lang": "en",
      "text": "Solutions four of them seem to have",
      "offset": 8620.12,
      "duration": 3.64
    },
    {
      "lang": "en",
      "text": "worked and now the model will kind of",
      "offset": 8621.72,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "like train on them and this corresponds",
      "offset": 8623.76,
      "duration": 3.4
    },
    {
      "lang": "en",
      "text": "to a student basically looking at their",
      "offset": 8625.8,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "Solutions and being like okay well this",
      "offset": 8627.16,
      "duration": 3.319
    },
    {
      "lang": "en",
      "text": "one worked really well so this is this",
      "offset": 8628.84,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "is how I should be solving these kinds",
      "offset": 8630.479,
      "duration": 5.481
    },
    {
      "lang": "en",
      "text": "of problems and uh here in this example",
      "offset": 8632.12,
      "duration": 5.279
    },
    {
      "lang": "en",
      "text": "there are many different ways to",
      "offset": 8635.96,
      "duration": 2.64
    },
    {
      "lang": "en",
      "text": "actually like really tweak the",
      "offset": 8637.399,
      "duration": 3.241
    },
    {
      "lang": "en",
      "text": "methodology a little bit here but just",
      "offset": 8638.6,
      "duration": 3.679
    },
    {
      "lang": "en",
      "text": "to give the core idea across maybe it's",
      "offset": 8640.64,
      "duration": 3.96
    },
    {
      "lang": "en",
      "text": "simplest to just think about take the",
      "offset": 8642.279,
      "duration": 4.04
    },
    {
      "lang": "en",
      "text": "taking the single best solution out of",
      "offset": 8644.6,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "these four uh like say this one that's",
      "offset": 8646.319,
      "duration": 5.801
    },
    {
      "lang": "en",
      "text": "why it was yellow uh so this is the the",
      "offset": 8648.68,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "solution that not only led to the right",
      "offset": 8652.12,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "answer but may maybe had some other nice",
      "offset": 8653.64,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "properties maybe it was the shortest one",
      "offset": 8655.64,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "or it looked nicest in some ways or uh",
      "offset": 8657.88,
      "duration": 3.96
    },
    {
      "lang": "en",
      "text": "there's other criteria you could think",
      "offset": 8660.52,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "of as an example but we're going to",
      "offset": 8661.84,
      "duration": 3.599
    },
    {
      "lang": "en",
      "text": "decide that this the top solution we're",
      "offset": 8663.72,
      "duration": 4.28
    },
    {
      "lang": "en",
      "text": "going to train on it and then uh the",
      "offset": 8665.439,
      "duration": 5.361
    },
    {
      "lang": "en",
      "text": "model will be slightly more likely once",
      "offset": 8668,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "you do the parameter update to take this",
      "offset": 8670.8,
      "duration": 5.32
    },
    {
      "lang": "en",
      "text": "path in this kind of a setting in the",
      "offset": 8673.52,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "future but you have to remember that",
      "offset": 8676.12,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "we're going to run many different",
      "offset": 8678.24,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "diverse prompts across lots of math",
      "offset": 8679.96,
      "duration": 3.519
    },
    {
      "lang": "en",
      "text": "problems and physics problems and",
      "offset": 8682.16,
      "duration": 4.199
    },
    {
      "lang": "en",
      "text": "whatever wherever there might be so tens",
      "offset": 8683.479,
      "duration": 4.481
    },
    {
      "lang": "en",
      "text": "of thousands of prompts maybe have in",
      "offset": 8686.359,
      "duration": 4.201
    },
    {
      "lang": "en",
      "text": "mind there's thousands of solutions",
      "offset": 8687.96,
      "duration": 4.6
    },
    {
      "lang": "en",
      "text": "prompt and so this is all happening kind",
      "offset": 8690.56,
      "duration": 4.919
    },
    {
      "lang": "en",
      "text": "of like at the same time and as we're",
      "offset": 8692.56,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "iterating this process the model is",
      "offset": 8695.479,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "discovering for itself what kinds of",
      "offset": 8697.6,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "token sequences lead it to correct",
      "offset": 8699.8,
      "duration": 5.24
    },
    {
      "lang": "en",
      "text": "answers it's not coming from a human",
      "offset": 8702.8,
      "duration": 5.24
    },
    {
      "lang": "en",
      "text": "annotator the the model is kind of like",
      "offset": 8705.04,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "playing in this playground and it knows",
      "offset": 8708.04,
      "duration": 4.52
    },
    {
      "lang": "en",
      "text": "what it's trying to get to and it's",
      "offset": 8710.08,
      "duration": 5.08
    },
    {
      "lang": "en",
      "text": "discovering sequences that work for it",
      "offset": 8712.56,
      "duration": 4.36
    },
    {
      "lang": "en",
      "text": "uh these are sequences that don't make",
      "offset": 8715.16,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "any mental leaps uh they they seem to",
      "offset": 8716.92,
      "duration": 6.24
    },
    {
      "lang": "en",
      "text": "work reliably and statistically and uh",
      "offset": 8719.96,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "fully utilize the knowledge of the model",
      "offset": 8723.16,
      "duration": 5
    },
    {
      "lang": "en",
      "text": "as it has it and so uh this is the",
      "offset": 8725,
      "duration": 4.52
    },
    {
      "lang": "en",
      "text": "process of reinforcement",
      "offset": 8728.16,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "learning it's basically a guess and",
      "offset": 8729.52,
      "duration": 3.16
    },
    {
      "lang": "en",
      "text": "check we're going to guess many",
      "offset": 8731.52,
      "duration": 2.36
    },
    {
      "lang": "en",
      "text": "different types of solutions we're going",
      "offset": 8732.68,
      "duration": 3
    },
    {
      "lang": "en",
      "text": "to check them and we're going to do more",
      "offset": 8733.88,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "of what worked in the future and that is",
      "offset": 8735.68,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "uh reinforcement learning so in the",
      "offset": 8738.6,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "context of what came before we see now",
      "offset": 8740.88,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "that the sft model the supervised fine",
      "offset": 8743.16,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "tuning model it's still helpful because",
      "offset": 8745.2,
      "duration": 3.8
    },
    {
      "lang": "en",
      "text": "it still kind of like initializes the",
      "offset": 8747.319,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "model a little bit into to the vicinity",
      "offset": 8749,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "of the correct Solutions so it's kind of",
      "offset": 8751,
      "duration": 5.64
    },
    {
      "lang": "en",
      "text": "like a initialization of um of the model",
      "offset": 8753.24,
      "duration": 4.76
    },
    {
      "lang": "en",
      "text": "in the sense that it kind of gets the",
      "offset": 8756.64,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "model to you know take Solutions like",
      "offset": 8758,
      "duration": 5
    },
    {
      "lang": "en",
      "text": "write out Solutions and maybe it has an",
      "offset": 8760.8,
      "duration": 3.559
    },
    {
      "lang": "en",
      "text": "understanding of setting up a system of",
      "offset": 8763,
      "duration": 3.279
    },
    {
      "lang": "en",
      "text": "equations or maybe it kind of like talks",
      "offset": 8764.359,
      "duration": 3.641
    },
    {
      "lang": "en",
      "text": "through a solution so it gets you into",
      "offset": 8766.279,
      "duration": 3.961
    },
    {
      "lang": "en",
      "text": "the vicinity of correct Solutions but",
      "offset": 8768,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "reinforcement learning is where",
      "offset": 8770.24,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "everything gets dialed in we really",
      "offset": 8771.52,
      "duration": 3.759
    },
    {
      "lang": "en",
      "text": "discover the solutions that work for the",
      "offset": 8773.68,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "model get the right answers we encourage",
      "offset": 8775.279,
      "duration": 3.881
    },
    {
      "lang": "en",
      "text": "them and then the model just kind of",
      "offset": 8777.6,
      "duration": 4.36
    },
    {
      "lang": "en",
      "text": "like gets better over time time okay so",
      "offset": 8779.16,
      "duration": 4.279
    },
    {
      "lang": "en",
      "text": "that is the high Lev process for how we",
      "offset": 8781.96,
      "duration": 4.439
    },
    {
      "lang": "en",
      "text": "train large language models in short we",
      "offset": 8783.439,
      "duration": 4.441
    },
    {
      "lang": "en",
      "text": "train them kind of very similar to how",
      "offset": 8786.399,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "we train children and basically the only",
      "offset": 8787.88,
      "duration": 4.439
    },
    {
      "lang": "en",
      "text": "difference is that children go through",
      "offset": 8790.72,
      "duration": 4.12
    },
    {
      "lang": "en",
      "text": "chapters of books and they do all these",
      "offset": 8792.319,
      "duration": 5.441
    },
    {
      "lang": "en",
      "text": "different types of training exercises um",
      "offset": 8794.84,
      "duration": 4.92
    },
    {
      "lang": "en",
      "text": "kind of within the chapter of each book",
      "offset": 8797.76,
      "duration": 3.599
    },
    {
      "lang": "en",
      "text": "but instead when we train AIS it's",
      "offset": 8799.76,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "almost like we kind of do it stage by",
      "offset": 8801.359,
      "duration": 3.721
    },
    {
      "lang": "en",
      "text": "stage depending on the type of that",
      "offset": 8803.04,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "stage so first what we do is we do",
      "offset": 8805.08,
      "duration": 4.12
    },
    {
      "lang": "en",
      "text": "pre-training which as we saw is",
      "offset": 8807.6,
      "duration": 3.719
    },
    {
      "lang": "en",
      "text": "equivalent to uh basically reading all",
      "offset": 8809.2,
      "duration": 4.52
    },
    {
      "lang": "en",
      "text": "the expository material so we look at",
      "offset": 8811.319,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "all the textbooks at the same time and",
      "offset": 8813.72,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "we read all the exposition and we try to",
      "offset": 8815.479,
      "duration": 4.761
    },
    {
      "lang": "en",
      "text": "build a knowledge base the second thing",
      "offset": 8817.72,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "then is we go into the sft stage which",
      "offset": 8820.24,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "is really looking at all the fixed uh",
      "offset": 8822.84,
      "duration": 4.519
    },
    {
      "lang": "en",
      "text": "sort of like solutions from Human",
      "offset": 8824.96,
      "duration": 4.76
    },
    {
      "lang": "en",
      "text": "Experts of all the different kinds of",
      "offset": 8827.359,
      "duration": 4.441
    },
    {
      "lang": "en",
      "text": "worked Solutions across all the",
      "offset": 8829.72,
      "duration": 4.84
    },
    {
      "lang": "en",
      "text": "textbooks and we just kind of get an sft",
      "offset": 8831.8,
      "duration": 4.479
    },
    {
      "lang": "en",
      "text": "model which is able to imitate the",
      "offset": 8834.56,
      "duration": 3.759
    },
    {
      "lang": "en",
      "text": "experts but does so kind of blindly it",
      "offset": 8836.279,
      "duration": 4.601
    },
    {
      "lang": "en",
      "text": "just kind of like does its best guess",
      "offset": 8838.319,
      "duration": 4.361
    },
    {
      "lang": "en",
      "text": "uh kind of just like trying to mimic",
      "offset": 8840.88,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "statistically the expert behavior and so",
      "offset": 8842.68,
      "duration": 3.4
    },
    {
      "lang": "en",
      "text": "that's what you get when you look at all",
      "offset": 8844.88,
      "duration": 3.8
    },
    {
      "lang": "en",
      "text": "the work Solutions and then finally in",
      "offset": 8846.08,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "the last stage we do all the practice",
      "offset": 8848.68,
      "duration": 4.599
    },
    {
      "lang": "en",
      "text": "problems in the RL stage across all the",
      "offset": 8850.8,
      "duration": 4.28
    },
    {
      "lang": "en",
      "text": "textbooks we only do the practice",
      "offset": 8853.279,
      "duration": 4.601
    },
    {
      "lang": "en",
      "text": "problems and that's how we get the RL",
      "offset": 8855.08,
      "duration": 4.92
    },
    {
      "lang": "en",
      "text": "model so on a high level the way we",
      "offset": 8857.88,
      "duration": 5.16
    },
    {
      "lang": "en",
      "text": "train llms is very much equivalent uh to",
      "offset": 8860,
      "duration": 5.479
    },
    {
      "lang": "en",
      "text": "the process that we train uh that we use",
      "offset": 8863.04,
      "duration": 4.84
    },
    {
      "lang": "en",
      "text": "for training of children the next point",
      "offset": 8865.479,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "I would like to make is that actually",
      "offset": 8867.88,
      "duration": 3.16
    },
    {
      "lang": "en",
      "text": "these first two stat ages pre-training",
      "offset": 8869.319,
      "duration": 3.361
    },
    {
      "lang": "en",
      "text": "and surprise fine-tuning they've been",
      "offset": 8871.04,
      "duration": 2.84
    },
    {
      "lang": "en",
      "text": "around for years and they are very",
      "offset": 8872.68,
      "duration": 2.799
    },
    {
      "lang": "en",
      "text": "standard and everyone does them all the",
      "offset": 8873.88,
      "duration": 4.28
    },
    {
      "lang": "en",
      "text": "different llm providers it is this last",
      "offset": 8875.479,
      "duration": 5.281
    },
    {
      "lang": "en",
      "text": "stage the RL training that is a lot more",
      "offset": 8878.16,
      "duration": 4.68
    },
    {
      "lang": "en",
      "text": "early in its process of development and",
      "offset": 8880.76,
      "duration": 5.84
    },
    {
      "lang": "en",
      "text": "is not standard yet in the field and so",
      "offset": 8882.84,
      "duration": 6.599
    },
    {
      "lang": "en",
      "text": "um this stage is a lot more kind of",
      "offset": 8886.6,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "early and nent and the reason for that",
      "offset": 8889.439,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "is because I actually skipped over a ton",
      "offset": 8891.8,
      "duration": 3.519
    },
    {
      "lang": "en",
      "text": "of little details here in this process",
      "offset": 8893.439,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "the high level idea is very simple it's",
      "offset": 8895.319,
      "duration": 3.521
    },
    {
      "lang": "en",
      "text": "trial and there learning but there's a",
      "offset": 8897.04,
      "duration": 3.08
    },
    {
      "lang": "en",
      "text": "ton of details and little math",
      "offset": 8898.84,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "mathematical kind of like nuances to",
      "offset": 8900.12,
      "duration": 3.319
    },
    {
      "lang": "en",
      "text": "exactly how you pick the solutions that",
      "offset": 8901.96,
      "duration": 3.479
    },
    {
      "lang": "en",
      "text": "are the best and how much you train on",
      "offset": 8903.439,
      "duration": 4.04
    },
    {
      "lang": "en",
      "text": "them and what is the prompt distribution",
      "offset": 8905.439,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "and how to set up the training run such",
      "offset": 8907.479,
      "duration": 3.481
    },
    {
      "lang": "en",
      "text": "that this actually works so there's a",
      "offset": 8909.279,
      "duration": 3.641
    },
    {
      "lang": "en",
      "text": "lot of little details and knobs to the",
      "offset": 8910.96,
      "duration": 4.439
    },
    {
      "lang": "en",
      "text": "core idea that is very very simple and",
      "offset": 8912.92,
      "duration": 4.76
    },
    {
      "lang": "en",
      "text": "so getting the details right here uh is",
      "offset": 8915.399,
      "duration": 4.641
    },
    {
      "lang": "en",
      "text": "not trivial and so a lot of companies",
      "offset": 8917.68,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "like for example open and other LM",
      "offset": 8920.04,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "providers have experimented internally",
      "offset": 8921.6,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "with reinforcement learning fine tuning",
      "offset": 8924.359,
      "duration": 4.241
    },
    {
      "lang": "en",
      "text": "for llms for a while but they've not",
      "offset": 8926.16,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "talked about it publicly",
      "offset": 8928.6,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "um it's all kind of done inside the",
      "offset": 8930.64,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "company and so that's why the paper from",
      "offset": 8932.439,
      "duration": 4.441
    },
    {
      "lang": "en",
      "text": "Deep seek that came out very very",
      "offset": 8935.2,
      "duration": 4.119
    },
    {
      "lang": "en",
      "text": "recently was such a big deal because",
      "offset": 8936.88,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "this is a paper from this company called",
      "offset": 8939.319,
      "duration": 5.721
    },
    {
      "lang": "en",
      "text": "DC Kai in China and this paper really",
      "offset": 8941.2,
      "duration": 5.8
    },
    {
      "lang": "en",
      "text": "talked very publicly about reinforcement",
      "offset": 8945.04,
      "duration": 2.96
    },
    {
      "lang": "en",
      "text": "learning fine training for large",
      "offset": 8947,
      "duration": 3.479
    },
    {
      "lang": "en",
      "text": "language models and how incredibly",
      "offset": 8948,
      "duration": 4.279
    },
    {
      "lang": "en",
      "text": "important it is for large language",
      "offset": 8950.479,
      "duration": 4.121
    },
    {
      "lang": "en",
      "text": "models and how it brings out a lot of",
      "offset": 8952.279,
      "duration": 3.881
    },
    {
      "lang": "en",
      "text": "reasoning capabilities in the models",
      "offset": 8954.6,
      "duration": 3.879
    },
    {
      "lang": "en",
      "text": "we'll go into this in a second so this",
      "offset": 8956.16,
      "duration": 5.159
    },
    {
      "lang": "en",
      "text": "paper reinvigorated the public interest",
      "offset": 8958.479,
      "duration": 6.761
    },
    {
      "lang": "en",
      "text": "of using RL for llms and gave a lot of",
      "offset": 8961.319,
      "duration": 6.281
    },
    {
      "lang": "en",
      "text": "the um sort of n-r details that are",
      "offset": 8965.24,
      "duration": 4.36
    },
    {
      "lang": "en",
      "text": "needed to reproduce their results and",
      "offset": 8967.6,
      "duration": 3.879
    },
    {
      "lang": "en",
      "text": "actually get the stage to work for large",
      "offset": 8969.6,
      "duration": 3.759
    },
    {
      "lang": "en",
      "text": "langage models so let me take you",
      "offset": 8971.479,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "briefly through this uh deep seek R1",
      "offset": 8973.359,
      "duration": 3.521
    },
    {
      "lang": "en",
      "text": "paper and what happens when you actually",
      "offset": 8975.08,
      "duration": 3.8
    },
    {
      "lang": "en",
      "text": "correctly apply RL to language models",
      "offset": 8976.88,
      "duration": 3.08
    },
    {
      "lang": "en",
      "text": "and what that looks like and what that",
      "offset": 8978.88,
      "duration": 2.599
    },
    {
      "lang": "en",
      "text": "gives you so the first thing I'll scroll",
      "offset": 8979.96,
      "duration": 3.88
    },
    {
      "lang": "en",
      "text": "to is this uh kind of figure two here",
      "offset": 8981.479,
      "duration": 4.361
    },
    {
      "lang": "en",
      "text": "where we are looking at the Improvement",
      "offset": 8983.84,
      "duration": 3.639
    },
    {
      "lang": "en",
      "text": "in how the models are solving",
      "offset": 8985.84,
      "duration": 3.599
    },
    {
      "lang": "en",
      "text": "mathematical problems so this is the",
      "offset": 8987.479,
      "duration": 3.361
    },
    {
      "lang": "en",
      "text": "accuracy of solving mathematical",
      "offset": 8989.439,
      "duration": 4.641
    },
    {
      "lang": "en",
      "text": "problems on the a accuracy and then we",
      "offset": 8990.84,
      "duration": 4.479
    },
    {
      "lang": "en",
      "text": "can go to the web page and we can see",
      "offset": 8994.08,
      "duration": 2.48
    },
    {
      "lang": "en",
      "text": "the kinds of problems that are actually",
      "offset": 8995.319,
      "duration": 3.601
    },
    {
      "lang": "en",
      "text": "in these um these the kinds of math",
      "offset": 8996.56,
      "duration": 4.28
    },
    {
      "lang": "en",
      "text": "problems that are being measured here so",
      "offset": 8998.92,
      "duration": 3.559
    },
    {
      "lang": "en",
      "text": "these are simple math problems you can",
      "offset": 9000.84,
      "duration": 4.04
    },
    {
      "lang": "en",
      "text": "um pause the video if you like but these",
      "offset": 9002.479,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "are the kinds of problems that basically",
      "offset": 9004.88,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "the models are being asked to solve and",
      "offset": 9006.16,
      "duration": 2.88
    },
    {
      "lang": "en",
      "text": "you can see that in the beginning",
      "offset": 9008.08,
      "duration": 2.52
    },
    {
      "lang": "en",
      "text": "they're not doing very well but then as",
      "offset": 9009.04,
      "duration": 3.48
    },
    {
      "lang": "en",
      "text": "you update the model with this many",
      "offset": 9010.6,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "thousands of steps their accuracy kind",
      "offset": 9012.52,
      "duration": 4.839
    },
    {
      "lang": "en",
      "text": "of continues to climb so the models are",
      "offset": 9014.68,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "improving and they're solving these",
      "offset": 9017.359,
      "duration": 3.161
    },
    {
      "lang": "en",
      "text": "problems with a higher accuracy",
      "offset": 9018.76,
      "duration": 4.12
    },
    {
      "lang": "en",
      "text": "as you do this trial and error on a",
      "offset": 9020.52,
      "duration": 3.72
    },
    {
      "lang": "en",
      "text": "large data set of these kinds of",
      "offset": 9022.88,
      "duration": 3.599
    },
    {
      "lang": "en",
      "text": "problems and the models are discovering",
      "offset": 9024.24,
      "duration": 5.199
    },
    {
      "lang": "en",
      "text": "how to solve math problems but even more",
      "offset": 9026.479,
      "duration": 5.521
    },
    {
      "lang": "en",
      "text": "incredible than the quantitative kind of",
      "offset": 9029.439,
      "duration": 4.281
    },
    {
      "lang": "en",
      "text": "results of solving these problems with a",
      "offset": 9032,
      "duration": 3.72
    },
    {
      "lang": "en",
      "text": "higher accuracy is the qualitative means",
      "offset": 9033.72,
      "duration": 3.719
    },
    {
      "lang": "en",
      "text": "by which the model achieves these",
      "offset": 9035.72,
      "duration": 4.719
    },
    {
      "lang": "en",
      "text": "results so when we scroll down uh one of",
      "offset": 9037.439,
      "duration": 4.04
    },
    {
      "lang": "en",
      "text": "the figures here that is kind of",
      "offset": 9040.439,
      "duration": 3.241
    },
    {
      "lang": "en",
      "text": "interesting is that later on in the",
      "offset": 9041.479,
      "duration": 5.401
    },
    {
      "lang": "en",
      "text": "optimization the model seems to be uh",
      "offset": 9043.68,
      "duration": 5.92
    },
    {
      "lang": "en",
      "text": "using average length per response uh",
      "offset": 9046.88,
      "duration": 4.28
    },
    {
      "lang": "en",
      "text": "goes up up so the model seems to be",
      "offset": 9049.6,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "using more tokens to get its higher",
      "offset": 9051.16,
      "duration": 5.279
    },
    {
      "lang": "en",
      "text": "accuracy results so it's learning to",
      "offset": 9054.56,
      "duration": 4.799
    },
    {
      "lang": "en",
      "text": "create very very long Solutions why are",
      "offset": 9056.439,
      "duration": 4.481
    },
    {
      "lang": "en",
      "text": "these Solutions very long we can look at",
      "offset": 9059.359,
      "duration": 4.04
    },
    {
      "lang": "en",
      "text": "them qualitatively here so basically",
      "offset": 9060.92,
      "duration": 4.519
    },
    {
      "lang": "en",
      "text": "what they discover is that the model",
      "offset": 9063.399,
      "duration": 3.88
    },
    {
      "lang": "en",
      "text": "solution get very very long partially",
      "offset": 9065.439,
      "duration": 3.761
    },
    {
      "lang": "en",
      "text": "because so here's a question and here's",
      "offset": 9067.279,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "kind of the answer from the model what",
      "offset": 9069.2,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "the model learns to do um and this is an",
      "offset": 9071.12,
      "duration": 4.76
    },
    {
      "lang": "en",
      "text": "immerging property of new optimization",
      "offset": 9073.76,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "it just discovers that this is good for",
      "offset": 9075.88,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "problem solving is it starts to do stuff",
      "offset": 9077.6,
      "duration": 4.04
    },
    {
      "lang": "en",
      "text": "like this wait wait wait that's Nota",
      "offset": 9079.56,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "moment I can flag here let's reevaluate",
      "offset": 9081.64,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "this step by step to identify the",
      "offset": 9083.64,
      "duration": 3.48
    },
    {
      "lang": "en",
      "text": "correct sum can be so what is the model",
      "offset": 9085.08,
      "duration": 5.199
    },
    {
      "lang": "en",
      "text": "doing here right the model is basically",
      "offset": 9087.12,
      "duration": 5.359
    },
    {
      "lang": "en",
      "text": "re-evaluating steps it has learned that",
      "offset": 9090.279,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "it works better for accuracy to try out",
      "offset": 9092.479,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "lots of ideas try something from",
      "offset": 9095.479,
      "duration": 4.121
    },
    {
      "lang": "en",
      "text": "different perspectives retrace reframe",
      "offset": 9097.279,
      "duration": 4.281
    },
    {
      "lang": "en",
      "text": "backtrack is doing a lot of the things",
      "offset": 9099.6,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "that you and I are doing in the process",
      "offset": 9101.56,
      "duration": 3.4
    },
    {
      "lang": "en",
      "text": "of problem solving for mathematical",
      "offset": 9103.04,
      "duration": 3.56
    },
    {
      "lang": "en",
      "text": "questions but it's rediscovering what",
      "offset": 9104.96,
      "duration": 3.56
    },
    {
      "lang": "en",
      "text": "happens in your head not what you put",
      "offset": 9106.6,
      "duration": 3.96
    },
    {
      "lang": "en",
      "text": "down on the solution and there is no",
      "offset": 9108.52,
      "duration": 4.28
    },
    {
      "lang": "en",
      "text": "human who can hardcode this stuff in the",
      "offset": 9110.56,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "ideal assistant response this is only",
      "offset": 9112.8,
      "duration": 3.639
    },
    {
      "lang": "en",
      "text": "something that can be discovered in the",
      "offset": 9115.04,
      "duration": 2.88
    },
    {
      "lang": "en",
      "text": "process of reinforcement learning",
      "offset": 9116.439,
      "duration": 3.201
    },
    {
      "lang": "en",
      "text": "because you wouldn't know what to put",
      "offset": 9117.92,
      "duration": 4.439
    },
    {
      "lang": "en",
      "text": "here this just turns out to work for the",
      "offset": 9119.64,
      "duration": 4.44
    },
    {
      "lang": "en",
      "text": "model and it improves its accuracy in",
      "offset": 9122.359,
      "duration": 4.561
    },
    {
      "lang": "en",
      "text": "problem solving so the model learns what",
      "offset": 9124.08,
      "duration": 4.84
    },
    {
      "lang": "en",
      "text": "we call these chains of thought in your",
      "offset": 9126.92,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "head and it's an emergent property of",
      "offset": 9128.92,
      "duration": 4.84
    },
    {
      "lang": "en",
      "text": "the optim of the optimization and that's",
      "offset": 9130.84,
      "duration": 5.599
    },
    {
      "lang": "en",
      "text": "what's bloating up the response length",
      "offset": 9133.76,
      "duration": 4.44
    },
    {
      "lang": "en",
      "text": "but that's also what's increasing the",
      "offset": 9136.439,
      "duration": 4.201
    },
    {
      "lang": "en",
      "text": "accuracy of the problem problem solving",
      "offset": 9138.2,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "so what's incredible here is basically",
      "offset": 9140.64,
      "duration": 3.96
    },
    {
      "lang": "en",
      "text": "the model is discovering ways to think",
      "offset": 9142.12,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "it's learning what I like to call",
      "offset": 9144.6,
      "duration": 3.56
    },
    {
      "lang": "en",
      "text": "cognitive strategies of how you",
      "offset": 9146.2,
      "duration": 3.88
    },
    {
      "lang": "en",
      "text": "manipulate a problem and how you",
      "offset": 9148.16,
      "duration": 3.8
    },
    {
      "lang": "en",
      "text": "approach it from different perspectives",
      "offset": 9150.08,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "how you pull in some analogies or do",
      "offset": 9151.96,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "different kinds of things like that and",
      "offset": 9153.84,
      "duration": 3.32
    },
    {
      "lang": "en",
      "text": "how you kind of uh try out many",
      "offset": 9155.64,
      "duration": 3.4
    },
    {
      "lang": "en",
      "text": "different things over time uh check a",
      "offset": 9157.16,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "result from different perspectives and",
      "offset": 9159.04,
      "duration": 4.439
    },
    {
      "lang": "en",
      "text": "how you kind of uh solve problems but",
      "offset": 9160.92,
      "duration": 4.04
    },
    {
      "lang": "en",
      "text": "here it's kind of discovered by the RL",
      "offset": 9163.479,
      "duration": 3.521
    },
    {
      "lang": "en",
      "text": "so extremely incredible to see this",
      "offset": 9164.96,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "emerge in the optimization without",
      "offset": 9167,
      "duration": 3.96
    },
    {
      "lang": "en",
      "text": "having to hardcode it anywhere the only",
      "offset": 9168.88,
      "duration": 3.559
    },
    {
      "lang": "en",
      "text": "thing we've given it are the correct",
      "offset": 9170.96,
      "duration": 3.72
    },
    {
      "lang": "en",
      "text": "answers and this comes out from trying",
      "offset": 9172.439,
      "duration": 4.241
    },
    {
      "lang": "en",
      "text": "to just solve them correctly which is",
      "offset": 9174.68,
      "duration": 3.679
    },
    {
      "lang": "en",
      "text": "incredible",
      "offset": 9176.68,
      "duration": 3.88
    },
    {
      "lang": "en",
      "text": "um now let's go back to actually the",
      "offset": 9178.359,
      "duration": 3.641
    },
    {
      "lang": "en",
      "text": "problem that we've been working with and",
      "offset": 9180.56,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "let's take a look at what it would look",
      "offset": 9182,
      "duration": 5.56
    },
    {
      "lang": "en",
      "text": "like uh for uh for this kind of a model",
      "offset": 9183.6,
      "duration": 6.24
    },
    {
      "lang": "en",
      "text": "what we call reasoning or thinking model",
      "offset": 9187.56,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "to solve that problem okay so recall",
      "offset": 9189.84,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "that this is the problem we've been",
      "offset": 9192.04,
      "duration": 3.08
    },
    {
      "lang": "en",
      "text": "working with and when I pasted it into",
      "offset": 9193.04,
      "duration": 4.6
    },
    {
      "lang": "en",
      "text": "chat GPT 40 I'm getting this kind of a",
      "offset": 9195.12,
      "duration": 4.239
    },
    {
      "lang": "en",
      "text": "response let's take a look at what",
      "offset": 9197.64,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "happens when you give this same query to",
      "offset": 9199.359,
      "duration": 4.281
    },
    {
      "lang": "en",
      "text": "what's called a reasoning or a thinking",
      "offset": 9202.04,
      "duration": 3.08
    },
    {
      "lang": "en",
      "text": "model this is a model that was trained",
      "offset": 9203.64,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "with reinforcement learning so this",
      "offset": 9205.12,
      "duration": 5.84
    },
    {
      "lang": "en",
      "text": "model described in this paper DC car1 is",
      "offset": 9208.12,
      "duration": 6.319
    },
    {
      "lang": "en",
      "text": "available on chat. dec.com uh so this is",
      "offset": 9210.96,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "kind of like the company uh that",
      "offset": 9214.439,
      "duration": 3.201
    },
    {
      "lang": "en",
      "text": "developed is hosting it you have to make",
      "offset": 9215.92,
      "duration": 3.24
    },
    {
      "lang": "en",
      "text": "sure that the Deep think button is",
      "offset": 9217.64,
      "duration": 3.88
    },
    {
      "lang": "en",
      "text": "turned on to get the R1 model as it's",
      "offset": 9219.16,
      "duration": 5.159
    },
    {
      "lang": "en",
      "text": "called we can paste it here and run",
      "offset": 9221.52,
      "duration": 5.24
    },
    {
      "lang": "en",
      "text": "it and so let's take a look at what",
      "offset": 9224.319,
      "duration": 3.761
    },
    {
      "lang": "en",
      "text": "happens now and what is the output of",
      "offset": 9226.76,
      "duration": 4.599
    },
    {
      "lang": "en",
      "text": "the model okay so here's it says so this",
      "offset": 9228.08,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "is previously what we get using",
      "offset": 9231.359,
      "duration": 3.401
    },
    {
      "lang": "en",
      "text": "basically what's an sft approach a",
      "offset": 9233.04,
      "duration": 3.88
    },
    {
      "lang": "en",
      "text": "supervised funing approach this is like",
      "offset": 9234.76,
      "duration": 4.12
    },
    {
      "lang": "en",
      "text": "mimicking an expert solution this is",
      "offset": 9236.92,
      "duration": 4.68
    },
    {
      "lang": "en",
      "text": "what we get from the RL model okay let",
      "offset": 9238.88,
      "duration": 4.559
    },
    {
      "lang": "en",
      "text": "me try to figure this out so Emily buys",
      "offset": 9241.6,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "three apples and two oranges each orange",
      "offset": 9243.439,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "cost $2 total is 13 I need to find out",
      "offset": 9245.2,
      "duration": 6.239
    },
    {
      "lang": "en",
      "text": "blah blah blah so here you you um as",
      "offset": 9247.6,
      "duration": 6.48
    },
    {
      "lang": "en",
      "text": "you're reading this you can't escape",
      "offset": 9251.439,
      "duration": 5
    },
    {
      "lang": "en",
      "text": "thinking that this model is",
      "offset": 9254.08,
      "duration": 5.399
    },
    {
      "lang": "en",
      "text": "thinking um is definitely pursuing the",
      "offset": 9256.439,
      "duration": 5.201
    },
    {
      "lang": "en",
      "text": "solution solution it deres that it must",
      "offset": 9259.479,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "cost $3 and then it says wait a second",
      "offset": 9261.64,
      "duration": 3.679
    },
    {
      "lang": "en",
      "text": "let me check my math again to be sure",
      "offset": 9263.56,
      "duration": 2.879
    },
    {
      "lang": "en",
      "text": "and then it tries it from a slightly",
      "offset": 9265.319,
      "duration": 3.281
    },
    {
      "lang": "en",
      "text": "different perspective and then it says",
      "offset": 9266.439,
      "duration": 4.441
    },
    {
      "lang": "en",
      "text": "yep all that checks out I think that's",
      "offset": 9268.6,
      "duration": 4.719
    },
    {
      "lang": "en",
      "text": "the answer I don't see any mistakes let",
      "offset": 9270.88,
      "duration": 3.599
    },
    {
      "lang": "en",
      "text": "me see if there's another way to",
      "offset": 9273.319,
      "duration": 3
    },
    {
      "lang": "en",
      "text": "approach the problem maybe setting up an",
      "offset": 9274.479,
      "duration": 5
    },
    {
      "lang": "en",
      "text": "equation let's let the cost of one apple",
      "offset": 9276.319,
      "duration": 5.761
    },
    {
      "lang": "en",
      "text": "be $8 then blah blah blah yep same",
      "offset": 9279.479,
      "duration": 5.361
    },
    {
      "lang": "en",
      "text": "answer so definitely each apple is $3",
      "offset": 9282.08,
      "duration": 5.08
    },
    {
      "lang": "en",
      "text": "all right confident that that's correct",
      "offset": 9284.84,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "and then what it does once it sort of um",
      "offset": 9287.16,
      "duration": 4.52
    },
    {
      "lang": "en",
      "text": "did the thinking process is it writes up",
      "offset": 9289.72,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "the nice solution for the human and so",
      "offset": 9291.68,
      "duration": 4.759
    },
    {
      "lang": "en",
      "text": "this is now considering so this is more",
      "offset": 9294.12,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "about the correctness aspect and this is",
      "offset": 9296.439,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "more about the presentation aspect where",
      "offset": 9298.6,
      "duration": 4.44
    },
    {
      "lang": "en",
      "text": "it kind of like writes it out nicely and",
      "offset": 9300.52,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "uh boxes in the correct answer at the",
      "offset": 9303.04,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "bottom and so what's incredible about",
      "offset": 9305.16,
      "duration": 3.239
    },
    {
      "lang": "en",
      "text": "this is we get this like thinking",
      "offset": 9307.12,
      "duration": 3.56
    },
    {
      "lang": "en",
      "text": "process of the model and this is what's",
      "offset": 9308.399,
      "duration": 3.721
    },
    {
      "lang": "en",
      "text": "coming from the reinforcement learning",
      "offset": 9310.68,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "process this is what's bloating up the",
      "offset": 9312.12,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "length of the token sequences they're",
      "offset": 9315,
      "duration": 2.96
    },
    {
      "lang": "en",
      "text": "doing thinking and they're trying",
      "offset": 9316.76,
      "duration": 3.96
    },
    {
      "lang": "en",
      "text": "different ways this is what's giving you",
      "offset": 9317.96,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "higher accuracy in problem",
      "offset": 9320.72,
      "duration": 4.12
    },
    {
      "lang": "en",
      "text": "solving and this is where we are seeing",
      "offset": 9322.359,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "these aha moments and these different",
      "offset": 9324.84,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "strategies and these um ideas for how",
      "offset": 9326.76,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "you can make sure that you're getting",
      "offset": 9329.88,
      "duration": 2.439
    },
    {
      "lang": "en",
      "text": "the correct",
      "offset": 9331.24,
      "duration": 3.159
    },
    {
      "lang": "en",
      "text": "answer the last point I wanted to make",
      "offset": 9332.319,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "is some people are a little bit nervous",
      "offset": 9334.399,
      "duration": 4.201
    },
    {
      "lang": "en",
      "text": "about putting you know very sensitive",
      "offset": 9336.24,
      "duration": 5.159
    },
    {
      "lang": "en",
      "text": "data into chat.com because this is a",
      "offset": 9338.6,
      "duration": 4.879
    },
    {
      "lang": "en",
      "text": "Chinese company so people don't um",
      "offset": 9341.399,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "people are a little bit careful and Cy",
      "offset": 9343.479,
      "duration": 4.601
    },
    {
      "lang": "en",
      "text": "with that a little bit um deep seek R1",
      "offset": 9345.24,
      "duration": 4.76
    },
    {
      "lang": "en",
      "text": "is a model that was released by this",
      "offset": 9348.08,
      "duration": 4.359
    },
    {
      "lang": "en",
      "text": "company so this is an open source model",
      "offset": 9350,
      "duration": 4.76
    },
    {
      "lang": "en",
      "text": "or open weights model it is available",
      "offset": 9352.439,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "for anyone to download and use you will",
      "offset": 9354.76,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "not be able to like run it in its full",
      "offset": 9356.84,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "um sort of the full model in full",
      "offset": 9359.72,
      "duration": 4.559
    },
    {
      "lang": "en",
      "text": "Precision you won't run that on a",
      "offset": 9362.6,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "MacBook but uh or like a local device",
      "offset": 9364.279,
      "duration": 4.561
    },
    {
      "lang": "en",
      "text": "because this is a fairly large model but",
      "offset": 9367,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "many companies are hosting the full",
      "offset": 9368.84,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "largest model one of those companies",
      "offset": 9370.68,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "that I like to use is called",
      "offset": 9372.76,
      "duration": 4.519
    },
    {
      "lang": "en",
      "text": "together. so when you go to together.",
      "offset": 9374.76,
      "duration": 4.519
    },
    {
      "lang": "en",
      "text": "you sign up and you go to playgrounds",
      "offset": 9377.279,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "you can can select here in the chat deep",
      "offset": 9379.279,
      "duration": 4.281
    },
    {
      "lang": "en",
      "text": "seek R1 and there's many different kinds",
      "offset": 9381.6,
      "duration": 3.48
    },
    {
      "lang": "en",
      "text": "of other models that you can select here",
      "offset": 9383.56,
      "duration": 3.56
    },
    {
      "lang": "en",
      "text": "these are all state-of-the-art models so",
      "offset": 9385.08,
      "duration": 3.239
    },
    {
      "lang": "en",
      "text": "this is kind of similar to the hugging",
      "offset": 9387.12,
      "duration": 2.56
    },
    {
      "lang": "en",
      "text": "face inference playground that we've",
      "offset": 9388.319,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "been playing with so far but together. a",
      "offset": 9389.68,
      "duration": 3.719
    },
    {
      "lang": "en",
      "text": "will usually host all the",
      "offset": 9392.319,
      "duration": 3.721
    },
    {
      "lang": "en",
      "text": "state-of-the-art models so select DT",
      "offset": 9393.399,
      "duration": 5.08
    },
    {
      "lang": "en",
      "text": "car1 um you can try to ignore a lot of",
      "offset": 9396.04,
      "duration": 3.72
    },
    {
      "lang": "en",
      "text": "these I think the default settings will",
      "offset": 9398.479,
      "duration": 5.081
    },
    {
      "lang": "en",
      "text": "often be okay and we can put in this and",
      "offset": 9399.76,
      "duration": 5.679
    },
    {
      "lang": "en",
      "text": "because the model was released by Deep",
      "offset": 9403.56,
      "duration": 3.96
    },
    {
      "lang": "en",
      "text": "seek what you're getting here should be",
      "offset": 9405.439,
      "duration": 3.401
    },
    {
      "lang": "en",
      "text": "basically equivalent to what you're",
      "offset": 9407.52,
      "duration": 3
    },
    {
      "lang": "en",
      "text": "getting here now because of the",
      "offset": 9408.84,
      "duration": 2.92
    },
    {
      "lang": "en",
      "text": "randomness in the sampling we're going",
      "offset": 9410.52,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "to get something slightly different uh",
      "offset": 9411.76,
      "duration": 3.8
    },
    {
      "lang": "en",
      "text": "but in principle this should be uh",
      "offset": 9413.56,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "identical in terms of the power of the",
      "offset": 9415.56,
      "duration": 3.08
    },
    {
      "lang": "en",
      "text": "model and you should be able to see the",
      "offset": 9417.08,
      "duration": 3.08
    },
    {
      "lang": "en",
      "text": "same things quantitatively and",
      "offset": 9418.64,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "qualitatively uh but uh this model is",
      "offset": 9420.16,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "coming from kind of a an American",
      "offset": 9422.24,
      "duration": 5.039
    },
    {
      "lang": "en",
      "text": "company so that's deep seek and that's",
      "offset": 9424.56,
      "duration": 4.799
    },
    {
      "lang": "en",
      "text": "the what's called a reasoning",
      "offset": 9427.279,
      "duration": 5.16
    },
    {
      "lang": "en",
      "text": "model now when I go back to chat uh let",
      "offset": 9429.359,
      "duration": 5.401
    },
    {
      "lang": "en",
      "text": "me go to chat here okay so the models",
      "offset": 9432.439,
      "duration": 3.281
    },
    {
      "lang": "en",
      "text": "that you're going to see in the drop",
      "offset": 9434.76,
      "duration": 3.96
    },
    {
      "lang": "en",
      "text": "down here some of them like 01 03 mini",
      "offset": 9435.72,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "O3 mini High Etc they are talking about",
      "offset": 9438.72,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "uses Advanced reasoning now what this is",
      "offset": 9441.24,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "referring to uses Advanced reasoning is",
      "offset": 9443.92,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "it's referring to the fact that it was",
      "offset": 9446.12,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "trained by reinforcement learning with",
      "offset": 9447.6,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "techniques very similar to those of deep",
      "offset": 9449.56,
      "duration": 4.719
    },
    {
      "lang": "en",
      "text": "C car1 per public statements of opening",
      "offset": 9451.6,
      "duration": 6.04
    },
    {
      "lang": "en",
      "text": "ey employees uh so these are thinking",
      "offset": 9454.279,
      "duration": 5.841
    },
    {
      "lang": "en",
      "text": "models trained with RL and these models",
      "offset": 9457.64,
      "duration": 4.92
    },
    {
      "lang": "en",
      "text": "like GPT 4 or GPT 4 40 mini that you're",
      "offset": 9460.12,
      "duration": 3.8
    },
    {
      "lang": "en",
      "text": "getting in the free tier you should",
      "offset": 9462.56,
      "duration": 3.24
    },
    {
      "lang": "en",
      "text": "think of them as mostly sft models",
      "offset": 9463.92,
      "duration": 3.88
    },
    {
      "lang": "en",
      "text": "supervised fine tuning models they don't",
      "offset": 9465.8,
      "duration": 3.88
    },
    {
      "lang": "en",
      "text": "actually do this like thinking as as you",
      "offset": 9467.8,
      "duration": 4.559
    },
    {
      "lang": "en",
      "text": "see in the RL models and even though",
      "offset": 9469.68,
      "duration": 3.799
    },
    {
      "lang": "en",
      "text": "there's a little bit of reinforcement",
      "offset": 9472.359,
      "duration": 2.721
    },
    {
      "lang": "en",
      "text": "learning involved with these models and",
      "offset": 9473.479,
      "duration": 3.401
    },
    {
      "lang": "en",
      "text": "I'll go that into that in a second these",
      "offset": 9475.08,
      "duration": 3.56
    },
    {
      "lang": "en",
      "text": "are mostly sft models I think you should",
      "offset": 9476.88,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "think about it that way so in the same",
      "offset": 9478.64,
      "duration": 4.36
    },
    {
      "lang": "en",
      "text": "way as what we saw here we can pick one",
      "offset": 9480.64,
      "duration": 4.639
    },
    {
      "lang": "en",
      "text": "of the thinking models like say 03 mini",
      "offset": 9483,
      "duration": 4.359
    },
    {
      "lang": "en",
      "text": "high and these models by the way might",
      "offset": 9485.279,
      "duration": 4.241
    },
    {
      "lang": "en",
      "text": "not be available to you unless you pay a",
      "offset": 9487.359,
      "duration": 4.561
    },
    {
      "lang": "en",
      "text": "Chachi PT subscription of either $20 per",
      "offset": 9489.52,
      "duration": 4.879
    },
    {
      "lang": "en",
      "text": "month or $200 per month for some of the",
      "offset": 9491.92,
      "duration": 5
    },
    {
      "lang": "en",
      "text": "top models so we can pick a thinking",
      "offset": 9494.399,
      "duration": 5.761
    },
    {
      "lang": "en",
      "text": "model and run now what's going to happen",
      "offset": 9496.92,
      "duration": 4.92
    },
    {
      "lang": "en",
      "text": "here is it's going to say reasoning and",
      "offset": 9500.16,
      "duration": 3.08
    },
    {
      "lang": "en",
      "text": "it's going to start to do stuff like",
      "offset": 9501.84,
      "duration": 4.76
    },
    {
      "lang": "en",
      "text": "this and um what we're seeing here is",
      "offset": 9503.24,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "not exactly the stuff we're seeing here",
      "offset": 9506.6,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "so even though under the hood the model",
      "offset": 9509.24,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "produces these kinds of uh kind of",
      "offset": 9511.64,
      "duration": 4.839
    },
    {
      "lang": "en",
      "text": "chains of thought opening ey chooses to",
      "offset": 9514.12,
      "duration": 4.76
    },
    {
      "lang": "en",
      "text": "not show the exact chains of thought in",
      "offset": 9516.479,
      "duration": 4.241
    },
    {
      "lang": "en",
      "text": "the web interface it shows little",
      "offset": 9518.88,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "summaries of that of those chains of",
      "offset": 9520.72,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "thought and open kind of does this I",
      "offset": 9522.56,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "think partly because uh they are worried",
      "offset": 9524.64,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "about what's called the distillation",
      "offset": 9526.72,
      "duration": 3.639
    },
    {
      "lang": "en",
      "text": "risk that is that someone could come in",
      "offset": 9528.08,
      "duration": 3.8
    },
    {
      "lang": "en",
      "text": "and actually try to imitate those",
      "offset": 9530.359,
      "duration": 3.361
    },
    {
      "lang": "en",
      "text": "reasoning traces and recover a lot of",
      "offset": 9531.88,
      "duration": 3.479
    },
    {
      "lang": "en",
      "text": "the reasoning performance by just",
      "offset": 9533.72,
      "duration": 3.88
    },
    {
      "lang": "en",
      "text": "imitating the reasoning uh chains of",
      "offset": 9535.359,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "thought and so they kind of hide them",
      "offset": 9537.6,
      "duration": 3
    },
    {
      "lang": "en",
      "text": "and they only show little summaries of",
      "offset": 9539.279,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "them so you're not getting exactly what",
      "offset": 9540.6,
      "duration": 3.64
    },
    {
      "lang": "en",
      "text": "you would get in deep seek as with",
      "offset": 9542.319,
      "duration": 4.681
    },
    {
      "lang": "en",
      "text": "respect to the reasoning itself and then",
      "offset": 9544.24,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "they write up the",
      "offset": 9547,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "solution so these are kind of like",
      "offset": 9548.56,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "equivalent even though we're not seeing",
      "offset": 9550.6,
      "duration": 3.759
    },
    {
      "lang": "en",
      "text": "the full under the hood details now in",
      "offset": 9552,
      "duration": 5.24
    },
    {
      "lang": "en",
      "text": "terms of the performance uh these models",
      "offset": 9554.359,
      "duration": 5.321
    },
    {
      "lang": "en",
      "text": "and deep seek models are currently rly",
      "offset": 9557.24,
      "duration": 3.88
    },
    {
      "lang": "en",
      "text": "on par I would say it's kind of hard to",
      "offset": 9559.68,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "tell because of the evaluations but if",
      "offset": 9561.12,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "you're paying $200 per month to open AI",
      "offset": 9562.72,
      "duration": 3.24
    },
    {
      "lang": "en",
      "text": "some of these models I believe are",
      "offset": 9564.72,
      "duration": 3
    },
    {
      "lang": "en",
      "text": "currently they basically still look",
      "offset": 9565.96,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "better uh but deep seek R1 for now is",
      "offset": 9567.72,
      "duration": 5.559
    },
    {
      "lang": "en",
      "text": "still a very solid choice for a thinking",
      "offset": 9570.76,
      "duration": 5.719
    },
    {
      "lang": "en",
      "text": "model that would be available to you um",
      "offset": 9573.279,
      "duration": 5.881
    },
    {
      "lang": "en",
      "text": "sort of um either on this website or any",
      "offset": 9576.479,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "other website because the model is open",
      "offset": 9579.16,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "weights you can just download it so",
      "offset": 9580.56,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "that's thinking models so what is the",
      "offset": 9583.8,
      "duration": 4.599
    },
    {
      "lang": "en",
      "text": "summary so far well we've talked about",
      "offset": 9586.08,
      "duration": 4.68
    },
    {
      "lang": "en",
      "text": "reinforcement learning and the fact that",
      "offset": 9588.399,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "thinking emerges in the process of the",
      "offset": 9590.76,
      "duration": 4.519
    },
    {
      "lang": "en",
      "text": "optimization on when we basically run RL",
      "offset": 9592.479,
      "duration": 5
    },
    {
      "lang": "en",
      "text": "on many math uh and kind of code",
      "offset": 9595.279,
      "duration": 4.361
    },
    {
      "lang": "en",
      "text": "problems that have verifiable Solutions",
      "offset": 9597.479,
      "duration": 4.121
    },
    {
      "lang": "en",
      "text": "so there's like an answer three",
      "offset": 9599.64,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "Etc now these thinking models you can",
      "offset": 9601.6,
      "duration": 5.759
    },
    {
      "lang": "en",
      "text": "access in for example deep seek or any",
      "offset": 9604.6,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "inference provider like together. a and",
      "offset": 9607.359,
      "duration": 5.161
    },
    {
      "lang": "en",
      "text": "choosing deep seek over there these",
      "offset": 9609.8,
      "duration": 4.92
    },
    {
      "lang": "en",
      "text": "thinking models are also available uh in",
      "offset": 9612.52,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "chpt under any of the 01 or O3",
      "offset": 9614.72,
      "duration": 6.04
    },
    {
      "lang": "en",
      "text": "models but these GPT 4 R models Etc",
      "offset": 9617.96,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "they're not thinking models you should",
      "offset": 9620.76,
      "duration": 4.519
    },
    {
      "lang": "en",
      "text": "think of them as mostly sft models now",
      "offset": 9621.88,
      "duration": 6.04
    },
    {
      "lang": "en",
      "text": "if you are um if you have a prompt that",
      "offset": 9625.279,
      "duration": 4.601
    },
    {
      "lang": "en",
      "text": "requires Advanced reasoning and so on",
      "offset": 9627.92,
      "duration": 2.96
    },
    {
      "lang": "en",
      "text": "you should probably use some of the",
      "offset": 9629.88,
      "duration": 2.92
    },
    {
      "lang": "en",
      "text": "thinking models or at least try them out",
      "offset": 9630.88,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "but empirically for a lot of my use when",
      "offset": 9632.8,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "you're asking a simpler question there's",
      "offset": 9635.279,
      "duration": 2.561
    },
    {
      "lang": "en",
      "text": "like a knowledge based question or",
      "offset": 9636.72,
      "duration": 2.32
    },
    {
      "lang": "en",
      "text": "something like that this might be",
      "offset": 9637.84,
      "duration": 2.599
    },
    {
      "lang": "en",
      "text": "Overkill like there's no need to think",
      "offset": 9639.04,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "30 seconds about some factual question",
      "offset": 9640.439,
      "duration": 4.241
    },
    {
      "lang": "en",
      "text": "so for that I will uh sometimes default",
      "offset": 9642.72,
      "duration": 4.559
    },
    {
      "lang": "en",
      "text": "to just GPT 40 so empirically about 80",
      "offset": 9644.68,
      "duration": 5.16
    },
    {
      "lang": "en",
      "text": "90% of my use is just gp4",
      "offset": 9647.279,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "and when I come across a very difficult",
      "offset": 9649.84,
      "duration": 3.639
    },
    {
      "lang": "en",
      "text": "problem like in math and code Etc I will",
      "offset": 9651.279,
      "duration": 4.841
    },
    {
      "lang": "en",
      "text": "reach for the thinking models but then I",
      "offset": 9653.479,
      "duration": 3.96
    },
    {
      "lang": "en",
      "text": "have to wait a bit longer because",
      "offset": 9656.12,
      "duration": 3.96
    },
    {
      "lang": "en",
      "text": "they're thinking um so you can access",
      "offset": 9657.439,
      "duration": 5.121
    },
    {
      "lang": "en",
      "text": "these on chat on deep seek also I wanted",
      "offset": 9660.08,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "to point out that um AI studio.",
      "offset": 9662.56,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "go.com even though it looks really busy",
      "offset": 9665.76,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "really ugly because Google's just unable",
      "offset": 9668.24,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "to do this kind of stuff well it's like",
      "offset": 9670.72,
      "duration": 4.44
    },
    {
      "lang": "en",
      "text": "what is happening but if you choose",
      "offset": 9673.04,
      "duration": 4.76
    },
    {
      "lang": "en",
      "text": "model and you choose here Gemini 2.0",
      "offset": 9675.16,
      "duration": 5.319
    },
    {
      "lang": "en",
      "text": "flash thinking experimental 01 21 if you",
      "offset": 9677.8,
      "duration": 4.679
    },
    {
      "lang": "en",
      "text": "choose that one that's also a a kind of",
      "offset": 9680.479,
      "duration": 4.521
    },
    {
      "lang": "en",
      "text": "early experiment experimental of a",
      "offset": 9682.479,
      "duration": 5
    },
    {
      "lang": "en",
      "text": "thinking model by Google so we can go",
      "offset": 9685,
      "duration": 4.279
    },
    {
      "lang": "en",
      "text": "here and we can give it the same problem",
      "offset": 9687.479,
      "duration": 3.761
    },
    {
      "lang": "en",
      "text": "and click run and this is also a",
      "offset": 9689.279,
      "duration": 4.361
    },
    {
      "lang": "en",
      "text": "thinking problem a thinking model that",
      "offset": 9691.24,
      "duration": 4.199
    },
    {
      "lang": "en",
      "text": "will also do something",
      "offset": 9693.64,
      "duration": 3.719
    },
    {
      "lang": "en",
      "text": "similar and comes out with the right",
      "offset": 9695.439,
      "duration": 4.761
    },
    {
      "lang": "en",
      "text": "answer here so basically Gemini also",
      "offset": 9697.359,
      "duration": 4.841
    },
    {
      "lang": "en",
      "text": "offers a thinking model anthropic",
      "offset": 9700.2,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "currently does not offer a thinking",
      "offset": 9702.2,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "model but basically this is kind of like",
      "offset": 9703.56,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "the frontier development of these llms I",
      "offset": 9705.24,
      "duration": 4.239
    },
    {
      "lang": "en",
      "text": "think RL is kind of like this new",
      "offset": 9707.56,
      "duration": 4.2
    },
    {
      "lang": "en",
      "text": "exciting stage but getting the details",
      "offset": 9709.479,
      "duration": 4.201
    },
    {
      "lang": "en",
      "text": "right is difficult and that's why all",
      "offset": 9711.76,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "these models and thinking models are",
      "offset": 9713.68,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "currently experimental as of 2025 very",
      "offset": 9715.12,
      "duration": 5.92
    },
    {
      "lang": "en",
      "text": "early 2025 um but this is kind of like",
      "offset": 9717.92,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "the frontier development of pushing the",
      "offset": 9721.04,
      "duration": 2.92
    },
    {
      "lang": "en",
      "text": "performance on these very difficult",
      "offset": 9722.8,
      "duration": 3
    },
    {
      "lang": "en",
      "text": "problems using reasoning that is",
      "offset": 9723.96,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "emerging in these optimizations one more",
      "offset": 9725.8,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "connection that I wanted to bring up is",
      "offset": 9727.96,
      "duration": 4.28
    },
    {
      "lang": "en",
      "text": "that the discovery that reinforcement",
      "offset": 9730.04,
      "duration": 4.359
    },
    {
      "lang": "en",
      "text": "learning is extremely powerful way of",
      "offset": 9732.24,
      "duration": 5.4
    },
    {
      "lang": "en",
      "text": "learning is not new to the field of AI",
      "offset": 9734.399,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "and one place what we've already seen",
      "offset": 9737.64,
      "duration": 4.639
    },
    {
      "lang": "en",
      "text": "this demonstrated is in the game of Go",
      "offset": 9739.439,
      "duration": 5
    },
    {
      "lang": "en",
      "text": "and famously Deep Mind developed the",
      "offset": 9742.279,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "system alphago and you can watch a movie",
      "offset": 9744.439,
      "duration": 5.281
    },
    {
      "lang": "en",
      "text": "about it um where the system is learning",
      "offset": 9746.439,
      "duration": 5.681
    },
    {
      "lang": "en",
      "text": "to play the game of go against top human",
      "offset": 9749.72,
      "duration": 6.679
    },
    {
      "lang": "en",
      "text": "players and um when we go to the paper",
      "offset": 9752.12,
      "duration": 7.44
    },
    {
      "lang": "en",
      "text": "underlying alphago so in this paper when",
      "offset": 9756.399,
      "duration": 4.841
    },
    {
      "lang": "en",
      "text": "we scroll",
      "offset": 9759.56,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "down we actually find a really",
      "offset": 9761.24,
      "duration": 3.199
    },
    {
      "lang": "en",
      "text": "interesting",
      "offset": 9763.16,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "plot um that I think uh is kind of",
      "offset": 9764.439,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "familiar uh to us and we're kind of like",
      "offset": 9767.16,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "we discovering in the more open domain",
      "offset": 9769.319,
      "duration": 4.361
    },
    {
      "lang": "en",
      "text": "of arbitrary problem solving instead of",
      "offset": 9771.64,
      "duration": 3.799
    },
    {
      "lang": "en",
      "text": "on the closed specific domain of the",
      "offset": 9773.68,
      "duration": 4.2
    },
    {
      "lang": "en",
      "text": "game of Go but basically what they saw",
      "offset": 9775.439,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "and we're going to see this in llms as",
      "offset": 9777.88,
      "duration": 5.32
    },
    {
      "lang": "en",
      "text": "well as this becomes more mature is this",
      "offset": 9779.279,
      "duration": 6.08
    },
    {
      "lang": "en",
      "text": "is the ELO rating of playing game of Go",
      "offset": 9783.2,
      "duration": 4.119
    },
    {
      "lang": "en",
      "text": "and this is leas dull an extremely",
      "offset": 9785.359,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "strong human player and here what they",
      "offset": 9787.319,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "are comparing is the strength of a model",
      "offset": 9789.68,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "learned trained by supervised learning",
      "offset": 9791.64,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "and a model trained by reinforcement",
      "offset": 9794.08,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "learning so the supervised learning",
      "offset": 9795.64,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "model is imitating human expert players",
      "offset": 9797.6,
      "duration": 4.719
    },
    {
      "lang": "en",
      "text": "so if you just get a huge amount of",
      "offset": 9800.84,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "games played by expert players in the",
      "offset": 9802.319,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "game of Go and you try to imitate them",
      "offset": 9803.96,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "you are going to get better but then you",
      "offset": 9806.479,
      "duration": 5.161
    },
    {
      "lang": "en",
      "text": "top out and you never quite get better",
      "offset": 9808.92,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "than some of the top top top players of",
      "offset": 9811.64,
      "duration": 4.2
    },
    {
      "lang": "en",
      "text": "in the game of Go like LEL so you're",
      "offset": 9814.04,
      "duration": 3.48
    },
    {
      "lang": "en",
      "text": "never going to reach there because",
      "offset": 9815.84,
      "duration": 3.32
    },
    {
      "lang": "en",
      "text": "you're just imitating human players you",
      "offset": 9817.52,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "can't fundamentally go beyond a human",
      "offset": 9819.16,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "player if you're just imitating human",
      "offset": 9820.8,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "players but in a process of",
      "offset": 9822.52,
      "duration": 3.759
    },
    {
      "lang": "en",
      "text": "reinforcement learning is significantly",
      "offset": 9824.24,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "more powerful in reinforcement learning",
      "offset": 9826.279,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "for a game of Go it means that the",
      "offset": 9828.08,
      "duration": 5.08
    },
    {
      "lang": "en",
      "text": "system is playing moves that empirically",
      "offset": 9830.12,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "and statistically lead to win to winning",
      "offset": 9833.16,
      "duration": 6.36
    },
    {
      "lang": "en",
      "text": "the game and so alphago is a system",
      "offset": 9836.12,
      "duration": 6.04
    },
    {
      "lang": "en",
      "text": "where it kind of plays against it itself",
      "offset": 9839.52,
      "duration": 4.44
    },
    {
      "lang": "en",
      "text": "and it's using reinforcement learning to",
      "offset": 9842.16,
      "duration": 2.72
    },
    {
      "lang": "en",
      "text": "create",
      "offset": 9843.96,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "rollouts so it's the exact same diagram",
      "offset": 9844.88,
      "duration": 5.479
    },
    {
      "lang": "en",
      "text": "here but there's no prompt it's just uh",
      "offset": 9847.24,
      "duration": 4.159
    },
    {
      "lang": "en",
      "text": "because there's no prompt it's just a",
      "offset": 9850.359,
      "duration": 3.241
    },
    {
      "lang": "en",
      "text": "fixed game of Go but it's trying out",
      "offset": 9851.399,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "lots of solutions it's trying out lots",
      "offset": 9853.6,
      "duration": 4.679
    },
    {
      "lang": "en",
      "text": "of plays and then the games that lead to",
      "offset": 9855.24,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "a win instead of a specific answer are",
      "offset": 9858.279,
      "duration": 5.921
    },
    {
      "lang": "en",
      "text": "reinforced they're they're made stronger",
      "offset": 9860.92,
      "duration": 5.64
    },
    {
      "lang": "en",
      "text": "and so um the system is learning",
      "offset": 9864.2,
      "duration": 3.96
    },
    {
      "lang": "en",
      "text": "basically the sequences of actions that",
      "offset": 9866.56,
      "duration": 3.719
    },
    {
      "lang": "en",
      "text": "empirically and statistically lead to",
      "offset": 9868.16,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "winning the game and reinforcement",
      "offset": 9870.279,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "learning is not going to be constrained",
      "offset": 9872.72,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "by human performance and reinforcement",
      "offset": 9874.12,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "learning can do significantly better and",
      "offset": 9876.16,
      "duration": 4.92
    },
    {
      "lang": "en",
      "text": "overcome even the top players like Lisa",
      "offset": 9878.12,
      "duration": 6.4
    },
    {
      "lang": "en",
      "text": "Dole and so uh probably they could have",
      "offset": 9881.08,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "run this longer and they just chose to",
      "offset": 9884.52,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "crop it at some point because this costs",
      "offset": 9886.04,
      "duration": 3.359
    },
    {
      "lang": "en",
      "text": "money but this is very powerful",
      "offset": 9887.64,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "demonstration of reinforcement learning",
      "offset": 9889.399,
      "duration": 3.401
    },
    {
      "lang": "en",
      "text": "and we're only starting to kind of see",
      "offset": 9891.24,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "hints of this diagram in larger language",
      "offset": 9892.8,
      "duration": 5.8
    },
    {
      "lang": "en",
      "text": "models for reasoning problems so we're",
      "offset": 9895.8,
      "duration": 4.12
    },
    {
      "lang": "en",
      "text": "not going to get too far by just",
      "offset": 9898.6,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "imitating experts we need to go beyond",
      "offset": 9899.92,
      "duration": 3.8
    },
    {
      "lang": "en",
      "text": "that set up these like little game",
      "offset": 9901.8,
      "duration": 5.599
    },
    {
      "lang": "en",
      "text": "environments and get let let the system",
      "offset": 9903.72,
      "duration": 6.16
    },
    {
      "lang": "en",
      "text": "discover reasoning traces or like ways",
      "offset": 9907.399,
      "duration": 6.761
    },
    {
      "lang": "en",
      "text": "of solving problems uh that are unique",
      "offset": 9909.88,
      "duration": 6.439
    },
    {
      "lang": "en",
      "text": "and that uh just basically work",
      "offset": 9914.16,
      "duration": 5
    },
    {
      "lang": "en",
      "text": "well now on this aspect of uniqueness",
      "offset": 9916.319,
      "duration": 3.641
    },
    {
      "lang": "en",
      "text": "notice that when you're doing",
      "offset": 9919.16,
      "duration": 2.64
    },
    {
      "lang": "en",
      "text": "reinforcement learning nothing prevents",
      "offset": 9919.96,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "you from veering off the distribution of",
      "offset": 9921.8,
      "duration": 5
    },
    {
      "lang": "en",
      "text": "how humans are playing the game and so",
      "offset": 9924.6,
      "duration": 4.679
    },
    {
      "lang": "en",
      "text": "when we go back to uh this alphao search",
      "offset": 9926.8,
      "duration": 4.76
    },
    {
      "lang": "en",
      "text": "here one of the suggested modifications",
      "offset": 9929.279,
      "duration": 5.641
    },
    {
      "lang": "en",
      "text": "is called move 37 and move 37 in alphao",
      "offset": 9931.56,
      "duration": 5.919
    },
    {
      "lang": "en",
      "text": "is referring to a specific point in time",
      "offset": 9934.92,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "where alphago basically played a move",
      "offset": 9937.479,
      "duration": 6.281
    },
    {
      "lang": "en",
      "text": "that uh no human expert would play uh so",
      "offset": 9940.6,
      "duration": 5.16
    },
    {
      "lang": "en",
      "text": "the probability of this move uh to be",
      "offset": 9943.76,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "played by a human player was evaluated",
      "offset": 9945.76,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "to be about 1 in 10th ,000 so it's a",
      "offset": 9947.76,
      "duration": 4.36
    },
    {
      "lang": "en",
      "text": "very rare move but in retrospect it was",
      "offset": 9949.84,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "a brilliant move so alphago in the",
      "offset": 9952.12,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "process of reinforcement learning",
      "offset": 9954.24,
      "duration": 3.32
    },
    {
      "lang": "en",
      "text": "discovered kind of like a strategy of",
      "offset": 9955.88,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "playing that was unknown to humans and",
      "offset": 9957.56,
      "duration": 4.879
    },
    {
      "lang": "en",
      "text": "but is in retrospect uh brilliant I",
      "offset": 9960.04,
      "duration": 4.92
    },
    {
      "lang": "en",
      "text": "recommend this YouTube video um leis do",
      "offset": 9962.439,
      "duration": 4.281
    },
    {
      "lang": "en",
      "text": "versus alphao move 37 reactions and",
      "offset": 9964.96,
      "duration": 3.72
    },
    {
      "lang": "en",
      "text": "Analysis and this is kind of what it",
      "offset": 9966.72,
      "duration": 4.759
    },
    {
      "lang": "en",
      "text": "looked like when alphao played this",
      "offset": 9968.68,
      "duration": 5.759
    },
    {
      "lang": "en",
      "text": "move",
      "offset": 9971.479,
      "duration": 5.281
    },
    {
      "lang": "en",
      "text": "value that's a very that's a very",
      "offset": 9974.439,
      "duration": 5.121
    },
    {
      "lang": "en",
      "text": "surprising move I thought I thought it",
      "offset": 9976.76,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "was I thought it was a",
      "offset": 9979.56,
      "duration": 5.24
    },
    {
      "lang": "en",
      "text": "mistake when I see this move anyway so",
      "offset": 9981.72,
      "duration": 4.2
    },
    {
      "lang": "en",
      "text": "basically people are kind of freaking",
      "offset": 9984.8,
      "duration": 3.8
    },
    {
      "lang": "en",
      "text": "out because it's a it's a move that a",
      "offset": 9985.92,
      "duration": 5.32
    },
    {
      "lang": "en",
      "text": "human would not play that alphago played",
      "offset": 9988.6,
      "duration": 5.16
    },
    {
      "lang": "en",
      "text": "because in its training uh this move",
      "offset": 9991.24,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "seemed to be a good idea it just happens",
      "offset": 9993.76,
      "duration": 3.4
    },
    {
      "lang": "en",
      "text": "not to be a kind of thing that a humans",
      "offset": 9995.64,
      "duration": 3.759
    },
    {
      "lang": "en",
      "text": "would would do and so that is again the",
      "offset": 9997.16,
      "duration": 3.88
    },
    {
      "lang": "en",
      "text": "power of reinforcement learning and in",
      "offset": 9999.399,
      "duration": 3.121
    },
    {
      "lang": "en",
      "text": "principle we can actually see the",
      "offset": 10001.04,
      "duration": 3.08
    },
    {
      "lang": "en",
      "text": "equivalence of that if we continue",
      "offset": 10002.52,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "scaling this Paradigm in language models",
      "offset": 10004.12,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "and what that looks like is kind of",
      "offset": 10006.6,
      "duration": 4.12
    },
    {
      "lang": "en",
      "text": "unknown so so um what does it mean to",
      "offset": 10007.88,
      "duration": 6.72
    },
    {
      "lang": "en",
      "text": "solve problems in such a way that uh",
      "offset": 10010.72,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "even humans would not be able to get how",
      "offset": 10014.6,
      "duration": 3.48
    },
    {
      "lang": "en",
      "text": "can you be better at reasoning or",
      "offset": 10016.72,
      "duration": 3.639
    },
    {
      "lang": "en",
      "text": "thinking than humans how can you go",
      "offset": 10018.08,
      "duration": 5.84
    },
    {
      "lang": "en",
      "text": "beyond just uh a thinking human like",
      "offset": 10020.359,
      "duration": 5.561
    },
    {
      "lang": "en",
      "text": "maybe it means discovering analogies",
      "offset": 10023.92,
      "duration": 3.64
    },
    {
      "lang": "en",
      "text": "that humans would not be able to uh",
      "offset": 10025.92,
      "duration": 3.72
    },
    {
      "lang": "en",
      "text": "create or maybe it's like a new thinking",
      "offset": 10027.56,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "strategy it's kind of hard to think",
      "offset": 10029.64,
      "duration": 4.52
    },
    {
      "lang": "en",
      "text": "through uh maybe it's a holy new",
      "offset": 10030.76,
      "duration": 5.32
    },
    {
      "lang": "en",
      "text": "language that actually is not even",
      "offset": 10034.16,
      "duration": 3.48
    },
    {
      "lang": "en",
      "text": "English maybe it discovers its own",
      "offset": 10036.08,
      "duration": 3.8
    },
    {
      "lang": "en",
      "text": "language that is a lot better at",
      "offset": 10037.64,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "thinking um because the model is",
      "offset": 10039.88,
      "duration": 4.559
    },
    {
      "lang": "en",
      "text": "unconstrained to even like stick with",
      "offset": 10042.76,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "English uh so maybe it takes a different",
      "offset": 10044.439,
      "duration": 4.641
    },
    {
      "lang": "en",
      "text": "language to think in or it discovers its",
      "offset": 10047.24,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "own language so in principle the",
      "offset": 10049.08,
      "duration": 4.279
    },
    {
      "lang": "en",
      "text": "behavior of the system is a lot less",
      "offset": 10051.319,
      "duration": 5.881
    },
    {
      "lang": "en",
      "text": "defined it is open to do whatever works",
      "offset": 10053.359,
      "duration": 6.761
    },
    {
      "lang": "en",
      "text": "and it is open to also slowly Drift from",
      "offset": 10057.2,
      "duration": 4.239
    },
    {
      "lang": "en",
      "text": "the distribution of its training data",
      "offset": 10060.12,
      "duration": 3.64
    },
    {
      "lang": "en",
      "text": "which is English but all of that can",
      "offset": 10061.439,
      "duration": 4.241
    },
    {
      "lang": "en",
      "text": "only be done if we have a very large",
      "offset": 10063.76,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "diverse set of problems in which the",
      "offset": 10065.68,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "these strategy can be refined and",
      "offset": 10068.16,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "perfected and so that is a lot of the",
      "offset": 10069.68,
      "duration": 4.04
    },
    {
      "lang": "en",
      "text": "frontier LM research that's going on",
      "offset": 10071.84,
      "duration": 3.88
    },
    {
      "lang": "en",
      "text": "right now is trying to kind of create",
      "offset": 10073.72,
      "duration": 3.559
    },
    {
      "lang": "en",
      "text": "those kinds of prompt distributions that",
      "offset": 10075.72,
      "duration": 3.599
    },
    {
      "lang": "en",
      "text": "are large and diverse these are all kind",
      "offset": 10077.279,
      "duration": 3.441
    },
    {
      "lang": "en",
      "text": "of like game environments in which the",
      "offset": 10079.319,
      "duration": 4.921
    },
    {
      "lang": "en",
      "text": "llms can practice their thinking and uh",
      "offset": 10080.72,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "it's kind of like writing you know these",
      "offset": 10084.24,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "practice problems we have to create",
      "offset": 10086,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "practice problems for all of domains of",
      "offset": 10087.52,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "knowledge and if we have practice",
      "offset": 10090.08,
      "duration": 4.04
    },
    {
      "lang": "en",
      "text": "problems and tons of them the models",
      "offset": 10092.08,
      "duration": 4.279
    },
    {
      "lang": "en",
      "text": "will be able to reinforcement learning",
      "offset": 10094.12,
      "duration": 4.359
    },
    {
      "lang": "en",
      "text": "reinforcement learn on them and kind of",
      "offset": 10096.359,
      "duration": 5.561
    },
    {
      "lang": "en",
      "text": "uh create these kinds of uh diagrams but",
      "offset": 10098.479,
      "duration": 5.281
    },
    {
      "lang": "en",
      "text": "in the domain of open thinking instead",
      "offset": 10101.92,
      "duration": 4.68
    },
    {
      "lang": "en",
      "text": "of a closed domain like game of Go",
      "offset": 10103.76,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "there's one more section within",
      "offset": 10106.6,
      "duration": 2.799
    },
    {
      "lang": "en",
      "text": "reinforcement learning that I wanted to",
      "offset": 10107.68,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "cover and that is that of learning in",
      "offset": 10109.399,
      "duration": 5.801
    },
    {
      "lang": "en",
      "text": "unverifiable domains so so far all of",
      "offset": 10112.16,
      "duration": 4.36
    },
    {
      "lang": "en",
      "text": "the problems that we've looked at are in",
      "offset": 10115.2,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "what's called verifiable domains that is",
      "offset": 10116.52,
      "duration": 4.839
    },
    {
      "lang": "en",
      "text": "any candidate solution we can score very",
      "offset": 10118.88,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "easily against a concrete answer so for",
      "offset": 10121.359,
      "duration": 4.521
    },
    {
      "lang": "en",
      "text": "example answer is three and we can very",
      "offset": 10124,
      "duration": 3.88
    },
    {
      "lang": "en",
      "text": "easily score these Solutions against the",
      "offset": 10125.88,
      "duration": 3.64
    },
    {
      "lang": "en",
      "text": "answer of three",
      "offset": 10127.88,
      "duration": 3.8
    },
    {
      "lang": "en",
      "text": "either we require the models to like box",
      "offset": 10129.52,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "in their answers and then we just check",
      "offset": 10131.68,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "for equality of whatever is in the box",
      "offset": 10133.68,
      "duration": 4.759
    },
    {
      "lang": "en",
      "text": "with the answer or you can also use uh",
      "offset": 10135.92,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "kind of what's called an llm judge so",
      "offset": 10138.439,
      "duration": 4.681
    },
    {
      "lang": "en",
      "text": "the llm judge looks at a solution and it",
      "offset": 10140.56,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "gets the answer and just basically",
      "offset": 10143.12,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "scores the solution for whether it's",
      "offset": 10145.04,
      "duration": 3.359
    },
    {
      "lang": "en",
      "text": "consistent with the answer or not and",
      "offset": 10146.56,
      "duration": 4.28
    },
    {
      "lang": "en",
      "text": "llms uh empirically are good enough at",
      "offset": 10148.399,
      "duration": 3.96
    },
    {
      "lang": "en",
      "text": "the current capability that they can do",
      "offset": 10150.84,
      "duration": 3.559
    },
    {
      "lang": "en",
      "text": "this fairly reliably so we can apply",
      "offset": 10152.359,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "those kinds of techniques as well in any",
      "offset": 10154.399,
      "duration": 3.401
    },
    {
      "lang": "en",
      "text": "case we have a concrete answer and we're",
      "offset": 10156.2,
      "duration": 3
    },
    {
      "lang": "en",
      "text": "just checking Solutions again against it",
      "offset": 10157.8,
      "duration": 3.639
    },
    {
      "lang": "en",
      "text": "and we can do this automatically with no",
      "offset": 10159.2,
      "duration": 4.36
    },
    {
      "lang": "en",
      "text": "kind of humans in the loop the problem",
      "offset": 10161.439,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "is that we can't apply the strategy in",
      "offset": 10163.56,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "what's called unverifiable domains so",
      "offset": 10165.279,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "usually these are for example creative",
      "offset": 10168.04,
      "duration": 2.96
    },
    {
      "lang": "en",
      "text": "writing tasks like write a joke about",
      "offset": 10169.439,
      "duration": 3.88
    },
    {
      "lang": "en",
      "text": "Pelicans or write a poem or summarize a",
      "offset": 10171,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "paragraph or something like that in",
      "offset": 10173.319,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "these kinds of domains it becomes harder",
      "offset": 10175.319,
      "duration": 4.481
    },
    {
      "lang": "en",
      "text": "to score our different solutions to this",
      "offset": 10177.399,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "problem so for example writing a joke",
      "offset": 10179.8,
      "duration": 3.639
    },
    {
      "lang": "en",
      "text": "about Pelicans we can generate lots of",
      "offset": 10181.8,
      "duration": 4.04
    },
    {
      "lang": "en",
      "text": "different uh jokes of course that's fine",
      "offset": 10183.439,
      "duration": 4.241
    },
    {
      "lang": "en",
      "text": "for example we can go to chbt and we can",
      "offset": 10185.84,
      "duration": 5.439
    },
    {
      "lang": "en",
      "text": "get it to uh generate a joke about",
      "offset": 10187.68,
      "duration": 6.12
    },
    {
      "lang": "en",
      "text": "Pelicans uh so much stuff in their beaks",
      "offset": 10191.279,
      "duration": 5.441
    },
    {
      "lang": "en",
      "text": "because they don't bellan in",
      "offset": 10193.8,
      "duration": 5.639
    },
    {
      "lang": "en",
      "text": "backpacks what",
      "offset": 10196.72,
      "duration": 5.96
    },
    {
      "lang": "en",
      "text": "okay we can uh we can try something else",
      "offset": 10199.439,
      "duration": 4.92
    },
    {
      "lang": "en",
      "text": "why don't Pelicans ever pay for their",
      "offset": 10202.68,
      "duration": 3.799
    },
    {
      "lang": "en",
      "text": "drinks because they always B it to",
      "offset": 10204.359,
      "duration": 5.841
    },
    {
      "lang": "en",
      "text": "someone else haha okay so these models",
      "offset": 10206.479,
      "duration": 5.601
    },
    {
      "lang": "en",
      "text": "are not obviously not very good at humor",
      "offset": 10210.2,
      "duration": 3.039
    },
    {
      "lang": "en",
      "text": "actually I think it's pretty fascinating",
      "offset": 10212.08,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "because I think humor is secretly very",
      "offset": 10213.239,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "difficult and the model have the",
      "offset": 10215.2,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "capability I think anyway in any case",
      "offset": 10216.92,
      "duration": 6.08
    },
    {
      "lang": "en",
      "text": "you could imagine creating lots of jokes",
      "offset": 10220,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "the problem that we are facing is how do",
      "offset": 10223,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "we score them now in principle we could",
      "offset": 10224.56,
      "duration": 4.839
    },
    {
      "lang": "en",
      "text": "of course get a human to look at all",
      "offset": 10227.64,
      "duration": 3.96
    },
    {
      "lang": "en",
      "text": "these jokes just like I did right now",
      "offset": 10229.399,
      "duration": 3.561
    },
    {
      "lang": "en",
      "text": "the problem with that is if you are",
      "offset": 10231.6,
      "duration": 2.92
    },
    {
      "lang": "en",
      "text": "doing reinforcement learning you're",
      "offset": 10232.96,
      "duration": 3.319
    },
    {
      "lang": "en",
      "text": "going to be doing many thousands of",
      "offset": 10234.52,
      "duration": 3.879
    },
    {
      "lang": "en",
      "text": "updates and for each update you want to",
      "offset": 10236.279,
      "duration": 4.361
    },
    {
      "lang": "en",
      "text": "be looking at say thousands of prompts",
      "offset": 10238.399,
      "duration": 3.401
    },
    {
      "lang": "en",
      "text": "and for each prompt you want to be",
      "offset": 10240.64,
      "duration": 2.56
    },
    {
      "lang": "en",
      "text": "potentially looking at looking at",
      "offset": 10241.8,
      "duration": 3.16
    },
    {
      "lang": "en",
      "text": "hundred or thousands of different kinds",
      "offset": 10243.2,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "of generations and so there's just like",
      "offset": 10244.96,
      "duration": 5.56
    },
    {
      "lang": "en",
      "text": "way too many of these to look at and so",
      "offset": 10247.6,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "um in principle you could have a human",
      "offset": 10250.52,
      "duration": 3
    },
    {
      "lang": "en",
      "text": "inspect all of them and score them and",
      "offset": 10252.16,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "decide that okay maybe this one is funny",
      "offset": 10253.52,
      "duration": 4.839
    },
    {
      "lang": "en",
      "text": "and uh maybe this one is funny and this",
      "offset": 10255.92,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "one is funny and we could train on them",
      "offset": 10258.359,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "to get the model to become slightly",
      "offset": 10261.12,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "better at jokes um in the context of",
      "offset": 10262.52,
      "duration": 6.48
    },
    {
      "lang": "en",
      "text": "pelicans at least um the problem is that",
      "offset": 10265.2,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "it's just like way too much human time",
      "offset": 10269,
      "duration": 3.399
    },
    {
      "lang": "en",
      "text": "this is an unscalable strategy we need",
      "offset": 10270.56,
      "duration": 3.64
    },
    {
      "lang": "en",
      "text": "some kind of an automatic strategy for",
      "offset": 10272.399,
      "duration": 4.561
    },
    {
      "lang": "en",
      "text": "doing this and one sort of solution to",
      "offset": 10274.2,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "this was proposed in this paper",
      "offset": 10276.96,
      "duration": 3.439
    },
    {
      "lang": "en",
      "text": "uh that introduced what's called",
      "offset": 10279.16,
      "duration": 2.48
    },
    {
      "lang": "en",
      "text": "reinforcement learning from Human",
      "offset": 10280.399,
      "duration": 3.321
    },
    {
      "lang": "en",
      "text": "feedback and so this was a paper from",
      "offset": 10281.64,
      "duration": 3.759
    },
    {
      "lang": "en",
      "text": "open at the time and many of these",
      "offset": 10283.72,
      "duration": 3.88
    },
    {
      "lang": "en",
      "text": "people are now um co-founders in",
      "offset": 10285.399,
      "duration": 5.521
    },
    {
      "lang": "en",
      "text": "anthropic um and this kind of proposed a",
      "offset": 10287.6,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "approach for uh basically doing",
      "offset": 10290.92,
      "duration": 4.2
    },
    {
      "lang": "en",
      "text": "reinforcement learning in unverifiable",
      "offset": 10293.2,
      "duration": 3.72
    },
    {
      "lang": "en",
      "text": "domains so let's take a look at how that",
      "offset": 10295.12,
      "duration": 4.52
    },
    {
      "lang": "en",
      "text": "works so this is the cartoon diagram of",
      "offset": 10296.92,
      "duration": 4.92
    },
    {
      "lang": "en",
      "text": "the core ideas involved so as I",
      "offset": 10299.64,
      "duration": 4.44
    },
    {
      "lang": "en",
      "text": "mentioned the native approach is if we",
      "offset": 10301.84,
      "duration": 4.599
    },
    {
      "lang": "en",
      "text": "just set Infinity human time we could",
      "offset": 10304.08,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "just run RL in these domains just fine",
      "offset": 10306.439,
      "duration": 5.121
    },
    {
      "lang": "en",
      "text": "so for example we can run RL as usual if",
      "offset": 10309.12,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "I have Infinity humans I would I just",
      "offset": 10311.56,
      "duration": 3.56
    },
    {
      "lang": "en",
      "text": "want to do and these are just cartoon",
      "offset": 10313.68,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "numbers I want to do 1,000 updates where",
      "offset": 10315.12,
      "duration": 5.4
    },
    {
      "lang": "en",
      "text": "each update will be on 1,000 prompts and",
      "offset": 10317.76,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "in for each prompt we're going to have",
      "offset": 10320.52,
      "duration": 5.4
    },
    {
      "lang": "en",
      "text": "1,000 roll outs that we're scoring so we",
      "offset": 10322.16,
      "duration": 6.72
    },
    {
      "lang": "en",
      "text": "can run RL with this kind of a setup the",
      "offset": 10325.92,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "problem is in the process of doing this",
      "offset": 10328.88,
      "duration": 3.88
    },
    {
      "lang": "en",
      "text": "I will need to run one I will need to",
      "offset": 10330.72,
      "duration": 4.599
    },
    {
      "lang": "en",
      "text": "ask a human to evaluate a joke a total",
      "offset": 10332.76,
      "duration": 5.32
    },
    {
      "lang": "en",
      "text": "of 1 billion times and so that's a lot",
      "offset": 10335.319,
      "duration": 4.241
    },
    {
      "lang": "en",
      "text": "of people looking at really terrible",
      "offset": 10338.08,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "jokes so we don't want to do that so",
      "offset": 10339.56,
      "duration": 4.44
    },
    {
      "lang": "en",
      "text": "instead we want to take the arlef",
      "offset": 10342.08,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "approach so um in our Rel of approach we",
      "offset": 10344,
      "duration": 5.72
    },
    {
      "lang": "en",
      "text": "are kind of like the the core trick is",
      "offset": 10347.68,
      "duration": 4.92
    },
    {
      "lang": "en",
      "text": "that of indirection so we're going to",
      "offset": 10349.72,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "involve humans just a little bit and the",
      "offset": 10352.6,
      "duration": 4.799
    },
    {
      "lang": "en",
      "text": "way we cheat is that we basically train",
      "offset": 10355,
      "duration": 4.279
    },
    {
      "lang": "en",
      "text": "a whole separate neural network that we",
      "offset": 10357.399,
      "duration": 4.481
    },
    {
      "lang": "en",
      "text": "call a reward model and this neural",
      "offset": 10359.279,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "network will kind of like imitate human",
      "offset": 10361.88,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "scores so we're going to ask humans to",
      "offset": 10364.319,
      "duration": 4.881
    },
    {
      "lang": "en",
      "text": "score um roll",
      "offset": 10366.76,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "we're going to then imitate human scores",
      "offset": 10369.2,
      "duration": 5.199
    },
    {
      "lang": "en",
      "text": "using a neural network and this neural",
      "offset": 10371.72,
      "duration": 4.12
    },
    {
      "lang": "en",
      "text": "network will become a kind of simulator",
      "offset": 10374.399,
      "duration": 2.321
    },
    {
      "lang": "en",
      "text": "of human",
      "offset": 10375.84,
      "duration": 2.559
    },
    {
      "lang": "en",
      "text": "preferences and now that we have a",
      "offset": 10376.72,
      "duration": 4.36
    },
    {
      "lang": "en",
      "text": "neural network simulator we can do RL",
      "offset": 10378.399,
      "duration": 5.08
    },
    {
      "lang": "en",
      "text": "against it so instead of asking a real",
      "offset": 10381.08,
      "duration": 5.159
    },
    {
      "lang": "en",
      "text": "human we're asking a simulated human for",
      "offset": 10383.479,
      "duration": 6.321
    },
    {
      "lang": "en",
      "text": "their score of a joke as an example and",
      "offset": 10386.239,
      "duration": 5.721
    },
    {
      "lang": "en",
      "text": "so once we have a simulator we're often",
      "offset": 10389.8,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "racist because we can query it as many",
      "offset": 10391.96,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "times as we want to and it's all whole",
      "offset": 10393.64,
      "duration": 4.12
    },
    {
      "lang": "en",
      "text": "automatic process and we can now do",
      "offset": 10396.04,
      "duration": 3
    },
    {
      "lang": "en",
      "text": "reinforcement learning with respect to",
      "offset": 10397.76,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "the simulator and the simulator as you",
      "offset": 10399.04,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "might expect is not going to be a",
      "offset": 10400.96,
      "duration": 3.479
    },
    {
      "lang": "en",
      "text": "perfect human but if it's at least",
      "offset": 10402.16,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "statistically similar to human judgment",
      "offset": 10404.439,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "then you might expect that this will do",
      "offset": 10406.96,
      "duration": 3.359
    },
    {
      "lang": "en",
      "text": "something and in practice indeed uh it",
      "offset": 10408.279,
      "duration": 4.601
    },
    {
      "lang": "en",
      "text": "does so once we have a simulator we can",
      "offset": 10410.319,
      "duration": 4.681
    },
    {
      "lang": "en",
      "text": "do RL and everything works great so let",
      "offset": 10412.88,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "me show you a cartoon diagram a little",
      "offset": 10415,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "bit of what this process looks like",
      "offset": 10416.56,
      "duration": 4.12
    },
    {
      "lang": "en",
      "text": "although the details are not 100 like",
      "offset": 10418.68,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "super important it's just a core idea of",
      "offset": 10420.68,
      "duration": 3.639
    },
    {
      "lang": "en",
      "text": "how this works so here I have a cartoon",
      "offset": 10422.52,
      "duration": 3.64
    },
    {
      "lang": "en",
      "text": "diagram of a hypothetical example of",
      "offset": 10424.319,
      "duration": 3.361
    },
    {
      "lang": "en",
      "text": "what training the reward model would",
      "offset": 10426.16,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "look like so we have a prompt like write",
      "offset": 10427.68,
      "duration": 4.679
    },
    {
      "lang": "en",
      "text": "a joke about picans and then here we",
      "offset": 10430.239,
      "duration": 3.761
    },
    {
      "lang": "en",
      "text": "have five separate roll outs so these",
      "offset": 10432.359,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "are all five different jokes just like",
      "offset": 10434,
      "duration": 5
    },
    {
      "lang": "en",
      "text": "this one now the first thing we're going",
      "offset": 10436.52,
      "duration": 6.16
    },
    {
      "lang": "en",
      "text": "to do is we are going to ask a human to",
      "offset": 10439,
      "duration": 6.08
    },
    {
      "lang": "en",
      "text": "uh order these jokes from the best to",
      "offset": 10442.68,
      "duration": 5.799
    },
    {
      "lang": "en",
      "text": "worst so this is uh so here this human",
      "offset": 10445.08,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "thought that this joke is the best the",
      "offset": 10448.479,
      "duration": 5.561
    },
    {
      "lang": "en",
      "text": "funniest so number one joke this is",
      "offset": 10450.76,
      "duration": 5.84
    },
    {
      "lang": "en",
      "text": "number two joke number three joke four",
      "offset": 10454.04,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "and five so this is the worst joke",
      "offset": 10456.6,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "we're asking humans to order instead of",
      "offset": 10459.08,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "give scores directly because it's a bit",
      "offset": 10460.92,
      "duration": 3.519
    },
    {
      "lang": "en",
      "text": "of an easier task it's easier for a",
      "offset": 10462.68,
      "duration": 3.4
    },
    {
      "lang": "en",
      "text": "human to give an ordering than to give",
      "offset": 10464.439,
      "duration": 4.761
    },
    {
      "lang": "en",
      "text": "precise scores now that is now the",
      "offset": 10466.08,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "supervision for the model so the human",
      "offset": 10469.2,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "has ordered them and that is kind of",
      "offset": 10471.12,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "like their contribution to the training",
      "offset": 10472.64,
      "duration": 3.48
    },
    {
      "lang": "en",
      "text": "process but now separately what we're",
      "offset": 10474.16,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "going to do is we're going to ask a",
      "offset": 10476.12,
      "duration": 4.52
    },
    {
      "lang": "en",
      "text": "reward model uh about its scoring of",
      "offset": 10477.52,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "these jokes now the reward model is a",
      "offset": 10480.64,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "whole separate neural network completely",
      "offset": 10482.88,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "separate neural net um and it's also",
      "offset": 10484.96,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "probably a transform",
      "offset": 10487.6,
      "duration": 3.32
    },
    {
      "lang": "en",
      "text": "uh but it's not a language model in the",
      "offset": 10489.279,
      "duration": 4.2
    },
    {
      "lang": "en",
      "text": "sense that it generates diverse language",
      "offset": 10490.92,
      "duration": 5.64
    },
    {
      "lang": "en",
      "text": "Etc it's just a scoring model so the",
      "offset": 10493.479,
      "duration": 5.88
    },
    {
      "lang": "en",
      "text": "reward model will take as an input The",
      "offset": 10496.56,
      "duration": 5.64
    },
    {
      "lang": "en",
      "text": "Prompt number one and number two a",
      "offset": 10499.359,
      "duration": 5.96
    },
    {
      "lang": "en",
      "text": "candidate joke so um those are the two",
      "offset": 10502.2,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "inputs that go into the reward model so",
      "offset": 10505.319,
      "duration": 3.481
    },
    {
      "lang": "en",
      "text": "here for example the reward model would",
      "offset": 10507.16,
      "duration": 4.68
    },
    {
      "lang": "en",
      "text": "be taken this prompt and this joke now",
      "offset": 10508.8,
      "duration": 5.32
    },
    {
      "lang": "en",
      "text": "the output of a reward model is a single",
      "offset": 10511.84,
      "duration": 4.479
    },
    {
      "lang": "en",
      "text": "number and this number is thought of as",
      "offset": 10514.12,
      "duration": 4.279
    },
    {
      "lang": "en",
      "text": "a score and it can range for example",
      "offset": 10516.319,
      "duration": 4.601
    },
    {
      "lang": "en",
      "text": "from Z to one so zero would be the worst",
      "offset": 10518.399,
      "duration": 5.281
    },
    {
      "lang": "en",
      "text": "score and one would be the best score so",
      "offset": 10520.92,
      "duration": 4.359
    },
    {
      "lang": "en",
      "text": "here are some examples of what a",
      "offset": 10523.68,
      "duration": 3.559
    },
    {
      "lang": "en",
      "text": "hypothetical reward model at some stage",
      "offset": 10525.279,
      "duration": 4.12
    },
    {
      "lang": "en",
      "text": "in the training process would give uh s",
      "offset": 10527.239,
      "duration": 5.881
    },
    {
      "lang": "en",
      "text": "scoring to these jokes so 0.1 is a very",
      "offset": 10529.399,
      "duration": 6.84
    },
    {
      "lang": "en",
      "text": "low score 08 is a really high score and",
      "offset": 10533.12,
      "duration": 7.6
    },
    {
      "lang": "en",
      "text": "so on and so now um we compare the",
      "offset": 10536.239,
      "duration": 7.08
    },
    {
      "lang": "en",
      "text": "scores given by the reward model with uh",
      "offset": 10540.72,
      "duration": 4.719
    },
    {
      "lang": "en",
      "text": "the ordering given by the human and",
      "offset": 10543.319,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "there's a precise mathematical way to",
      "offset": 10545.439,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "actually calculate this uh basically set",
      "offset": 10547.399,
      "duration": 4.281
    },
    {
      "lang": "en",
      "text": "up a loss function and calculate a kind",
      "offset": 10549.439,
      "duration": 4.601
    },
    {
      "lang": "en",
      "text": "of like a correspondence here and uh",
      "offset": 10551.68,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "update a model based on it but I just",
      "offset": 10554.04,
      "duration": 3.64
    },
    {
      "lang": "en",
      "text": "want to give you the intuition which is",
      "offset": 10555.84,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "that as an example here for this second",
      "offset": 10557.68,
      "duration": 4.559
    },
    {
      "lang": "en",
      "text": "joke the the human thought that it was",
      "offset": 10560.56,
      "duration": 3
    },
    {
      "lang": "en",
      "text": "the funniest and the model kind of",
      "offset": 10562.239,
      "duration": 3.281
    },
    {
      "lang": "en",
      "text": "agreed right 08 is a relatively high",
      "offset": 10563.56,
      "duration": 3.679
    },
    {
      "lang": "en",
      "text": "score but this score should have been",
      "offset": 10565.52,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "even higher right so after an update we",
      "offset": 10567.239,
      "duration": 4.521
    },
    {
      "lang": "en",
      "text": "would expect that maybe this score",
      "offset": 10570.64,
      "duration": 3.08
    },
    {
      "lang": "en",
      "text": "should have been will actually grow",
      "offset": 10571.76,
      "duration": 3.24
    },
    {
      "lang": "en",
      "text": "after an update of the network to be",
      "offset": 10573.72,
      "duration": 3.24
    },
    {
      "lang": "en",
      "text": "like say 081 or",
      "offset": 10575,
      "duration": 4.479
    },
    {
      "lang": "en",
      "text": "something um for this one here they",
      "offset": 10576.96,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "actually are in a massive disagreement",
      "offset": 10579.479,
      "duration": 2.641
    },
    {
      "lang": "en",
      "text": "because the human thought that this was",
      "offset": 10581.04,
      "duration": 3.56
    },
    {
      "lang": "en",
      "text": "number two but here the the score is",
      "offset": 10582.12,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "only 0.1 and so this score needs to be",
      "offset": 10584.6,
      "duration": 6.32
    },
    {
      "lang": "en",
      "text": "much higher so after an update on top of",
      "offset": 10587.88,
      "duration": 5.64
    },
    {
      "lang": "en",
      "text": "this um kind of a supervision this might",
      "offset": 10590.92,
      "duration": 4.559
    },
    {
      "lang": "en",
      "text": "grow a lot more like maybe it's 0.15 or",
      "offset": 10593.52,
      "duration": 2.919
    },
    {
      "lang": "en",
      "text": "something like",
      "offset": 10595.479,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "that um and then here the human thought",
      "offset": 10596.439,
      "duration": 5.481
    },
    {
      "lang": "en",
      "text": "that this one was the worst joke but",
      "offset": 10599.8,
      "duration": 3.72
    },
    {
      "lang": "en",
      "text": "here the model actually gave it a fairly",
      "offset": 10601.92,
      "duration": 3.439
    },
    {
      "lang": "en",
      "text": "High number so you might expect that",
      "offset": 10603.52,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "after the update uh this would come down",
      "offset": 10605.359,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "to maybe 3 3.5 or something like that so",
      "offset": 10607.6,
      "duration": 4.28
    },
    {
      "lang": "en",
      "text": "basically we're doing what we did before",
      "offset": 10610.239,
      "duration": 4.281
    },
    {
      "lang": "en",
      "text": "we're slightly nudging the predictions",
      "offset": 10611.88,
      "duration": 5.559
    },
    {
      "lang": "en",
      "text": "from the models using a neural network",
      "offset": 10614.52,
      "duration": 3.959
    },
    {
      "lang": "en",
      "text": "training",
      "offset": 10617.439,
      "duration": 3.081
    },
    {
      "lang": "en",
      "text": "process and we're trying to make the",
      "offset": 10618.479,
      "duration": 4.721
    },
    {
      "lang": "en",
      "text": "reward model scores be consistent with",
      "offset": 10620.52,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "human",
      "offset": 10623.2,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "ordering and so um as we update the",
      "offset": 10624.04,
      "duration": 5.64
    },
    {
      "lang": "en",
      "text": "reward model on human data it becomes",
      "offset": 10627.2,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "better and better simulator of the",
      "offset": 10629.68,
      "duration": 5.16
    },
    {
      "lang": "en",
      "text": "scores and orders uh that humans provide",
      "offset": 10631.6,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "and then becomes kind of like the the",
      "offset": 10634.84,
      "duration": 3.96
    },
    {
      "lang": "en",
      "text": "neural the simulator of human",
      "offset": 10637.04,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "preferences which we can then do RL",
      "offset": 10638.8,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "against but critically we're not asking",
      "offset": 10640.96,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "humans one billion times to look at a",
      "offset": 10643.12,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "joke we're maybe looking at th000",
      "offset": 10644.8,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "prompts and five roll outs each so maybe",
      "offset": 10646.88,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "5,000 jokes that humans have to look at",
      "offset": 10648.88,
      "duration": 4.28
    },
    {
      "lang": "en",
      "text": "in total and they just give the ordering",
      "offset": 10650.8,
      "duration": 3.639
    },
    {
      "lang": "en",
      "text": "and then we're training the model to be",
      "offset": 10653.16,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "consistent with that ordering and I'm",
      "offset": 10654.439,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "skipping over the mathematical details",
      "offset": 10656.2,
      "duration": 3.64
    },
    {
      "lang": "en",
      "text": "but I just want you to understand a high",
      "offset": 10658.52,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "level idea that uh this reward model is",
      "offset": 10659.84,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "do is basically giving us this scour and",
      "offset": 10662.92,
      "duration": 3.8
    },
    {
      "lang": "en",
      "text": "we have a way of training it to be",
      "offset": 10665.2,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "consistent with human orderings",
      "offset": 10666.72,
      "duration": 4.559
    },
    {
      "lang": "en",
      "text": "and that's how rhf works okay so that is",
      "offset": 10668.64,
      "duration": 4.799
    },
    {
      "lang": "en",
      "text": "the rough idea we basically train",
      "offset": 10671.279,
      "duration": 4.361
    },
    {
      "lang": "en",
      "text": "simulators of humans and RL with respect",
      "offset": 10673.439,
      "duration": 3.361
    },
    {
      "lang": "en",
      "text": "to those",
      "offset": 10675.64,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "simulators now I want to talk about",
      "offset": 10676.8,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "first the upside of reinforcement",
      "offset": 10679.08,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "learning from Human",
      "offset": 10680.96,
      "duration": 5
    },
    {
      "lang": "en",
      "text": "feedback the first thing is that this",
      "offset": 10683.72,
      "duration": 3.8
    },
    {
      "lang": "en",
      "text": "allows us to run reinforcement learning",
      "offset": 10685.96,
      "duration": 3.279
    },
    {
      "lang": "en",
      "text": "which we know is incredibly powerful",
      "offset": 10687.52,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "kind of set of techniques and it allows",
      "offset": 10689.239,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "us to do it in arbitrary domains and",
      "offset": 10690.96,
      "duration": 4.68
    },
    {
      "lang": "en",
      "text": "including the ones that are unverifiable",
      "offset": 10693.239,
      "duration": 4.601
    },
    {
      "lang": "en",
      "text": "so things like summarization and poem",
      "offset": 10695.64,
      "duration": 3.719
    },
    {
      "lang": "en",
      "text": "writing joke writing or any other",
      "offset": 10697.84,
      "duration": 3.599
    },
    {
      "lang": "en",
      "text": "creative writing really uh in domains",
      "offset": 10699.359,
      "duration": 3.88
    },
    {
      "lang": "en",
      "text": "outside of math and code",
      "offset": 10701.439,
      "duration": 4.481
    },
    {
      "lang": "en",
      "text": "Etc now empirically what we see when we",
      "offset": 10703.239,
      "duration": 4.921
    },
    {
      "lang": "en",
      "text": "actually apply rhf is that this is a way",
      "offset": 10705.92,
      "duration": 4.68
    },
    {
      "lang": "en",
      "text": "to improve the performance of the model",
      "offset": 10708.16,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "and uh I have a top answer for why that",
      "offset": 10710.6,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "might be but I don't actually know that",
      "offset": 10713.84,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "it is like super well established on",
      "offset": 10715.96,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "like why this is you can empirically",
      "offset": 10718.08,
      "duration": 3.72
    },
    {
      "lang": "en",
      "text": "observe that when you do rhf correctly",
      "offset": 10719.72,
      "duration": 3.639
    },
    {
      "lang": "en",
      "text": "the models you get are just like a",
      "offset": 10721.8,
      "duration": 4.12
    },
    {
      "lang": "en",
      "text": "little bit better um but as to why is I",
      "offset": 10723.359,
      "duration": 4.12
    },
    {
      "lang": "en",
      "text": "think like not as clear so here's my",
      "offset": 10725.92,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "best guess my best guess is that this is",
      "offset": 10727.479,
      "duration": 4.721
    },
    {
      "lang": "en",
      "text": "possibly mostly due to the discriminator",
      "offset": 10729.84,
      "duration": 3.439
    },
    {
      "lang": "en",
      "text": "generator",
      "offset": 10732.2,
      "duration": 3.48
    },
    {
      "lang": "en",
      "text": "Gap what that means is that in many",
      "offset": 10733.279,
      "duration": 4.921
    },
    {
      "lang": "en",
      "text": "cases it is significantly easier to",
      "offset": 10735.68,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "discriminate than to generate for humans",
      "offset": 10738.2,
      "duration": 6.76
    },
    {
      "lang": "en",
      "text": "so in particular an example of this is",
      "offset": 10741.04,
      "duration": 6.56
    },
    {
      "lang": "en",
      "text": "um in when we do supervised fine-tuning",
      "offset": 10744.96,
      "duration": 4.279
    },
    {
      "lang": "en",
      "text": "right",
      "offset": 10747.6,
      "duration": 4.639
    },
    {
      "lang": "en",
      "text": "sft we're asking humans to generate the",
      "offset": 10749.239,
      "duration": 5.921
    },
    {
      "lang": "en",
      "text": "ideal assistant response and in many",
      "offset": 10752.239,
      "duration": 6.281
    },
    {
      "lang": "en",
      "text": "cases here um as I've shown it uh the",
      "offset": 10755.16,
      "duration": 5.119
    },
    {
      "lang": "en",
      "text": "ideal response is very simple to write",
      "offset": 10758.52,
      "duration": 3.719
    },
    {
      "lang": "en",
      "text": "but in many cases might not be so for",
      "offset": 10760.279,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "example in summarization or poem writing",
      "offset": 10762.239,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "or joke writing like how are you as a",
      "offset": 10764.12,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "human assist as a human labeler um",
      "offset": 10766.319,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "supposed to give the ideal response in",
      "offset": 10769,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "these cases it requires creative human",
      "offset": 10770.72,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "writing to do that and so rhf kind of",
      "offset": 10772.92,
      "duration": 5.84
    },
    {
      "lang": "en",
      "text": "sidesteps this because we get um we get",
      "offset": 10775.84,
      "duration": 4.76
    },
    {
      "lang": "en",
      "text": "to ask people a significantly easier",
      "offset": 10778.76,
      "duration": 4.2
    },
    {
      "lang": "en",
      "text": "question as a data labelers they're not",
      "offset": 10780.6,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "asked to write poems directly they're",
      "offset": 10782.96,
      "duration": 3.96
    },
    {
      "lang": "en",
      "text": "just given five poems from the model and",
      "offset": 10784.84,
      "duration": 4.599
    },
    {
      "lang": "en",
      "text": "they're just asked to order them and so",
      "offset": 10786.92,
      "duration": 4.359
    },
    {
      "lang": "en",
      "text": "that's just a much easier task for a",
      "offset": 10789.439,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "human labeler to do and so what I think",
      "offset": 10791.279,
      "duration": 5.801
    },
    {
      "lang": "en",
      "text": "this allows you to do basically is it um",
      "offset": 10793.84,
      "duration": 6.439
    },
    {
      "lang": "en",
      "text": "it kind of like allows a lot more higher",
      "offset": 10797.08,
      "duration": 5.159
    },
    {
      "lang": "en",
      "text": "accuracy data because we're not asking",
      "offset": 10800.279,
      "duration": 3.881
    },
    {
      "lang": "en",
      "text": "people to do the generation task which",
      "offset": 10802.239,
      "duration": 3.881
    },
    {
      "lang": "en",
      "text": "can be extremely difficult like we're",
      "offset": 10804.16,
      "duration": 3.72
    },
    {
      "lang": "en",
      "text": "not asking them to do creative writing",
      "offset": 10806.12,
      "duration": 3.279
    },
    {
      "lang": "en",
      "text": "we're just trying to get them to",
      "offset": 10807.88,
      "duration": 3.519
    },
    {
      "lang": "en",
      "text": "distinguish between creative writings",
      "offset": 10809.399,
      "duration": 4.761
    },
    {
      "lang": "en",
      "text": "and uh find the ones that are best and",
      "offset": 10811.399,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "that is the signal that humans are",
      "offset": 10814.16,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "providing just the ordering and that is",
      "offset": 10815.56,
      "duration": 4.44
    },
    {
      "lang": "en",
      "text": "their input into the system and then the",
      "offset": 10817.52,
      "duration": 5.879
    },
    {
      "lang": "en",
      "text": "system in rhf just discovers the kinds",
      "offset": 10820,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "of responses that would be graded well",
      "offset": 10823.399,
      "duration": 5.281
    },
    {
      "lang": "en",
      "text": "by humans and so that step of",
      "offset": 10826,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "indirection allows the models to become",
      "offset": 10828.68,
      "duration": 4.92
    },
    {
      "lang": "en",
      "text": "a bit better so that is the upside of",
      "offset": 10830.64,
      "duration": 5.08
    },
    {
      "lang": "en",
      "text": "our LF it allows us to run RL it",
      "offset": 10833.6,
      "duration": 4.36
    },
    {
      "lang": "en",
      "text": "empirically results in better models and",
      "offset": 10835.72,
      "duration": 4.599
    },
    {
      "lang": "en",
      "text": "it allows uh people to contribute their",
      "offset": 10837.96,
      "duration": 4.519
    },
    {
      "lang": "en",
      "text": "supervision uh even without having to do",
      "offset": 10840.319,
      "duration": 4.801
    },
    {
      "lang": "en",
      "text": "extremely difficult tasks um in the case",
      "offset": 10842.479,
      "duration": 5.161
    },
    {
      "lang": "en",
      "text": "of writing ideal responses unfortunately",
      "offset": 10845.12,
      "duration": 4.52
    },
    {
      "lang": "en",
      "text": "our HF also comes with significant",
      "offset": 10847.64,
      "duration": 6.759
    },
    {
      "lang": "en",
      "text": "downsides and so um the main one is that",
      "offset": 10849.64,
      "duration": 6.08
    },
    {
      "lang": "en",
      "text": "basically we are doing reinforcement",
      "offset": 10854.399,
      "duration": 3.161
    },
    {
      "lang": "en",
      "text": "learning not with respect to humans and",
      "offset": 10855.72,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "actual human judgment but with respect",
      "offset": 10857.56,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "to a lossy simulation of humans right",
      "offset": 10859.16,
      "duration": 4.119
    },
    {
      "lang": "en",
      "text": "and this lossy simulation could be",
      "offset": 10861.72,
      "duration": 3.4
    },
    {
      "lang": "en",
      "text": "misleading because it's just a it's just",
      "offset": 10863.279,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "a simulation right it's just a language",
      "offset": 10865.12,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "model that's kind of outputting scores",
      "offset": 10867.12,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "and it might not perfectly reflect the",
      "offset": 10869.12,
      "duration": 4.199
    },
    {
      "lang": "en",
      "text": "opinion of an actual human with an",
      "offset": 10871.439,
      "duration": 3.8
    },
    {
      "lang": "en",
      "text": "actual brain in all the possible",
      "offset": 10873.319,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "different cases so that's number one",
      "offset": 10875.239,
      "duration": 3.321
    },
    {
      "lang": "en",
      "text": "which is actually something even more",
      "offset": 10877.319,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "subtle and devious going on that uh",
      "offset": 10878.56,
      "duration": 3.759
    },
    {
      "lang": "en",
      "text": "really",
      "offset": 10881,
      "duration": 3.8
    },
    {
      "lang": "en",
      "text": "dramatically holds back our LF as a",
      "offset": 10882.319,
      "duration": 5.201
    },
    {
      "lang": "en",
      "text": "technique that we can really scale to",
      "offset": 10884.8,
      "duration": 6.2
    },
    {
      "lang": "en",
      "text": "significantly um kind of Smart Systems",
      "offset": 10887.52,
      "duration": 5.32
    },
    {
      "lang": "en",
      "text": "and that is that reinforcement learning",
      "offset": 10891,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "is extremely good at discovering a way",
      "offset": 10892.84,
      "duration": 5.559
    },
    {
      "lang": "en",
      "text": "to game the model to game the simulation",
      "offset": 10895.08,
      "duration": 5.199
    },
    {
      "lang": "en",
      "text": "so this reward model that we're",
      "offset": 10898.399,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "constructing here that gives the course",
      "offset": 10900.279,
      "duration": 6.04
    },
    {
      "lang": "en",
      "text": "these models are Transformers these",
      "offset": 10903.359,
      "duration": 4.841
    },
    {
      "lang": "en",
      "text": "Transformers are massive neurals they",
      "offset": 10906.319,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "have billions of parameters and they",
      "offset": 10908.2,
      "duration": 4.079
    },
    {
      "lang": "en",
      "text": "imitate humans but they do so in a kind",
      "offset": 10910.239,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "of like a simulation way now the problem",
      "offset": 10912.279,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "is that these are massive complicated",
      "offset": 10914.319,
      "duration": 3
    },
    {
      "lang": "en",
      "text": "systems right there's a billion",
      "offset": 10916.12,
      "duration": 2.76
    },
    {
      "lang": "en",
      "text": "parameters here that are outputting a",
      "offset": 10917.319,
      "duration": 2.761
    },
    {
      "lang": "en",
      "text": "single",
      "offset": 10918.88,
      "duration": 3.96
    },
    {
      "lang": "en",
      "text": "score it turns out that there are ways",
      "offset": 10920.08,
      "duration": 5.64
    },
    {
      "lang": "en",
      "text": "to gain these models you can find kinds",
      "offset": 10922.84,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "of inputs that were not part of their",
      "offset": 10925.72,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "training set and these inputs",
      "offset": 10928.04,
      "duration": 5.56
    },
    {
      "lang": "en",
      "text": "inexplicably get very high scores but in",
      "offset": 10931,
      "duration": 6.16
    },
    {
      "lang": "en",
      "text": "a fake way so very often what you find",
      "offset": 10933.6,
      "duration": 5.639
    },
    {
      "lang": "en",
      "text": "if you run our lch for very long so for",
      "offset": 10937.16,
      "duration": 4.04
    },
    {
      "lang": "en",
      "text": "example if we do 1,000 updates which is",
      "offset": 10939.239,
      "duration": 4.641
    },
    {
      "lang": "en",
      "text": "like say a lot of updates you might",
      "offset": 10941.2,
      "duration": 3.88
    },
    {
      "lang": "en",
      "text": "expect that your jokes are getting",
      "offset": 10943.88,
      "duration": 2.84
    },
    {
      "lang": "en",
      "text": "better and that you're getting like real",
      "offset": 10945.08,
      "duration": 3.64
    },
    {
      "lang": "en",
      "text": "bangers about Pelicans but that's not",
      "offset": 10946.72,
      "duration": 5
    },
    {
      "lang": "en",
      "text": "EXA exactly what happens what happens is",
      "offset": 10948.72,
      "duration": 5.4
    },
    {
      "lang": "en",
      "text": "that uh in the first few hundred steps",
      "offset": 10951.72,
      "duration": 3.759
    },
    {
      "lang": "en",
      "text": "the jokes about Pelicans are probably",
      "offset": 10954.12,
      "duration": 2.96
    },
    {
      "lang": "en",
      "text": "improving a little bit and then they",
      "offset": 10955.479,
      "duration": 3.361
    },
    {
      "lang": "en",
      "text": "actually dramatically fall off the cliff",
      "offset": 10957.08,
      "duration": 3.319
    },
    {
      "lang": "en",
      "text": "and you start to get extremely",
      "offset": 10958.84,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "nonsensical results like for example you",
      "offset": 10960.399,
      "duration": 4.601
    },
    {
      "lang": "en",
      "text": "start to get um the top joke about",
      "offset": 10962.52,
      "duration": 5.48
    },
    {
      "lang": "en",
      "text": "Pelicans starts to be the",
      "offset": 10965,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "and this makes no sense right like when",
      "offset": 10968,
      "duration": 2.6
    },
    {
      "lang": "en",
      "text": "you look at it why should this be a top",
      "offset": 10969.319,
      "duration": 4.241
    },
    {
      "lang": "en",
      "text": "joke but when you take the the and you",
      "offset": 10970.6,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "plug it into your reward model you'd",
      "offset": 10973.56,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "expect score of zero but actually the",
      "offset": 10975.56,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "reward model loves this as a joke it",
      "offset": 10977.399,
      "duration": 5.361
    },
    {
      "lang": "en",
      "text": "will tell you that the the the theth is",
      "offset": 10979.64,
      "duration": 6.719
    },
    {
      "lang": "en",
      "text": "a score of 1. Z this is a top joke and",
      "offset": 10982.76,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "this makes no sense right but it's",
      "offset": 10986.359,
      "duration": 2.761
    },
    {
      "lang": "en",
      "text": "because these models are just",
      "offset": 10987.96,
      "duration": 2.76
    },
    {
      "lang": "en",
      "text": "simulations of humans and they're",
      "offset": 10989.12,
      "duration": 3.359
    },
    {
      "lang": "en",
      "text": "massive neural lots and you can find",
      "offset": 10990.72,
      "duration": 4.36
    },
    {
      "lang": "en",
      "text": "inputs at the bottom that kind of like",
      "offset": 10992.479,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "get into the part of the input space",
      "offset": 10995.08,
      "duration": 2.76
    },
    {
      "lang": "en",
      "text": "that kind of gives you nonsensical",
      "offset": 10996.56,
      "duration": 3.759
    },
    {
      "lang": "en",
      "text": "results these examples are what's called",
      "offset": 10997.84,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "adversarial examples and I'm not going",
      "offset": 11000.319,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "to go into the topic too much but these",
      "offset": 11002,
      "duration": 4.479
    },
    {
      "lang": "en",
      "text": "are adversarial inputs to the model they",
      "offset": 11004,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "are specific little inputs that kind of",
      "offset": 11006.479,
      "duration": 4.241
    },
    {
      "lang": "en",
      "text": "go between the nooks and crannies of the",
      "offset": 11009.2,
      "duration": 3.32
    },
    {
      "lang": "en",
      "text": "model and give nonsensical results at",
      "offset": 11010.72,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "the top now here's what you might",
      "offset": 11012.52,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "imagine doing you say okay the the the",
      "offset": 11014.64,
      "duration": 4.719
    },
    {
      "lang": "en",
      "text": "is obviously not score of one um it's",
      "offset": 11016.68,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "obviously a low score so let's take the",
      "offset": 11019.359,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "the the the the let's add it to the data",
      "offset": 11021.16,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "set and give it an ordering that is",
      "offset": 11023.359,
      "duration": 4.521
    },
    {
      "lang": "en",
      "text": "extremely bad like a score of five and",
      "offset": 11025.56,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "indeed your model will learn that the D",
      "offset": 11027.88,
      "duration": 3.96
    },
    {
      "lang": "en",
      "text": "should have a very low score and it will",
      "offset": 11030.04,
      "duration": 3.8
    },
    {
      "lang": "en",
      "text": "give it score of zero the problem is",
      "offset": 11031.84,
      "duration": 3.599
    },
    {
      "lang": "en",
      "text": "that there will always be basically",
      "offset": 11033.84,
      "duration": 3.88
    },
    {
      "lang": "en",
      "text": "infinite number of nonsensical",
      "offset": 11035.439,
      "duration": 5.281
    },
    {
      "lang": "en",
      "text": "adversarial examples hiding in the model",
      "offset": 11037.72,
      "duration": 4.639
    },
    {
      "lang": "en",
      "text": "if you iterate this process many times",
      "offset": 11040.72,
      "duration": 3.48
    },
    {
      "lang": "en",
      "text": "and you keep adding nonsensical stuff to",
      "offset": 11042.359,
      "duration": 3.561
    },
    {
      "lang": "en",
      "text": "your reward model and giving it very low",
      "offset": 11044.2,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "scores you can you'll never win the game",
      "offset": 11045.92,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "uh you can do this many many rounds and",
      "offset": 11049,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "reinforcement learning if you run it",
      "offset": 11051.04,
      "duration": 3.439
    },
    {
      "lang": "en",
      "text": "long enough will always find a way to",
      "offset": 11052.52,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "gain the model it will discover",
      "offset": 11054.479,
      "duration": 3.481
    },
    {
      "lang": "en",
      "text": "adversarial examples it will get get",
      "offset": 11055.96,
      "duration": 4.76
    },
    {
      "lang": "en",
      "text": "really high scores uh with nonsensical",
      "offset": 11057.96,
      "duration": 5.08
    },
    {
      "lang": "en",
      "text": "results and fundamentally this is",
      "offset": 11060.72,
      "duration": 5.32
    },
    {
      "lang": "en",
      "text": "because our scoring function is a giant",
      "offset": 11063.04,
      "duration": 5.92
    },
    {
      "lang": "en",
      "text": "neural nut and RL is extremely good at",
      "offset": 11066.04,
      "duration": 7.8
    },
    {
      "lang": "en",
      "text": "finding just the ways to trick it uh so",
      "offset": 11068.96,
      "duration": 7.84
    },
    {
      "lang": "en",
      "text": "long story short you always run rhf put",
      "offset": 11073.84,
      "duration": 4.68
    },
    {
      "lang": "en",
      "text": "for maybe a few hundred updates the",
      "offset": 11076.8,
      "duration": 3.08
    },
    {
      "lang": "en",
      "text": "model is getting better and then you",
      "offset": 11078.52,
      "duration": 3.64
    },
    {
      "lang": "en",
      "text": "have to crop it and you are done you",
      "offset": 11079.88,
      "duration": 5.64
    },
    {
      "lang": "en",
      "text": "can't run too much against this reward",
      "offset": 11082.16,
      "duration": 5.64
    },
    {
      "lang": "en",
      "text": "model because the optimization will",
      "offset": 11085.52,
      "duration": 4.719
    },
    {
      "lang": "en",
      "text": "start to game it and you basically crop",
      "offset": 11087.8,
      "duration": 6.16
    },
    {
      "lang": "en",
      "text": "it and you call it and you ship it um",
      "offset": 11090.239,
      "duration": 6.08
    },
    {
      "lang": "en",
      "text": "and uh you can improve the reward model",
      "offset": 11093.96,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "but you kind of like come across these",
      "offset": 11096.319,
      "duration": 4.601
    },
    {
      "lang": "en",
      "text": "situations eventually at some point so",
      "offset": 11097.64,
      "duration": 6.08
    },
    {
      "lang": "en",
      "text": "rhf basically what I usually say is that",
      "offset": 11100.92,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "RF is not RL and what I mean by that is",
      "offset": 11103.72,
      "duration": 5.519
    },
    {
      "lang": "en",
      "text": "I mean RF is RL obviously but it's not",
      "offset": 11106.68,
      "duration": 5.679
    },
    {
      "lang": "en",
      "text": "RL in the magical sense this is not RL",
      "offset": 11109.239,
      "duration": 4.481
    },
    {
      "lang": "en",
      "text": "that you can run",
      "offset": 11112.359,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "indefinitely these kinds of problems",
      "offset": 11113.72,
      "duration": 4.44
    },
    {
      "lang": "en",
      "text": "like where you are getting con correct",
      "offset": 11116.279,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "answer you cannot gain this as easily",
      "offset": 11118.16,
      "duration": 3.8
    },
    {
      "lang": "en",
      "text": "you either got the correct answer or you",
      "offset": 11120.6,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "didn't and the scoring function is much",
      "offset": 11121.96,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "much simpler you're just looking at the",
      "offset": 11123.8,
      "duration": 3.479
    },
    {
      "lang": "en",
      "text": "boxed area and seeing if the result is",
      "offset": 11125.16,
      "duration": 4.44
    },
    {
      "lang": "en",
      "text": "correct so it's very difficult to gain",
      "offset": 11127.279,
      "duration": 4.761
    },
    {
      "lang": "en",
      "text": "these functions but uh gaming a reward",
      "offset": 11129.6,
      "duration": 4.639
    },
    {
      "lang": "en",
      "text": "model is possible now in these",
      "offset": 11132.04,
      "duration": 4.279
    },
    {
      "lang": "en",
      "text": "verifiable domains you can run RL",
      "offset": 11134.239,
      "duration": 4.601
    },
    {
      "lang": "en",
      "text": "indefinitely you could run for tens of",
      "offset": 11136.319,
      "duration": 3.881
    },
    {
      "lang": "en",
      "text": "thousands hundreds of thousands of steps",
      "offset": 11138.84,
      "duration": 2.96
    },
    {
      "lang": "en",
      "text": "and discover all kinds of really crazy",
      "offset": 11140.2,
      "duration": 3.32
    },
    {
      "lang": "en",
      "text": "strategies that we might not even ever",
      "offset": 11141.8,
      "duration": 4.04
    },
    {
      "lang": "en",
      "text": "think about of Performing really well",
      "offset": 11143.52,
      "duration": 5.24
    },
    {
      "lang": "en",
      "text": "for all these problems in the game of Go",
      "offset": 11145.84,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "there's no way to to beat to basically",
      "offset": 11148.76,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "game uh the winning of a game or the",
      "offset": 11150.96,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "losing of a game we have a perfect",
      "offset": 11152.92,
      "duration": 4.76
    },
    {
      "lang": "en",
      "text": "simulator we know all the different uh",
      "offset": 11154.64,
      "duration": 4.679
    },
    {
      "lang": "en",
      "text": "where all the stones are placed and we",
      "offset": 11157.68,
      "duration": 3.759
    },
    {
      "lang": "en",
      "text": "can calculate uh whether someone has won",
      "offset": 11159.319,
      "duration": 4.281
    },
    {
      "lang": "en",
      "text": "or not there's no way to gain that and",
      "offset": 11161.439,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "so you can do RL indefinitely and you",
      "offset": 11163.6,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "can eventually be beat even leol but",
      "offset": 11165.76,
      "duration": 5.96
    },
    {
      "lang": "en",
      "text": "with models like this which are gameable",
      "offset": 11168.72,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "you cannot repeat this process",
      "offset": 11171.72,
      "duration": 4.92
    },
    {
      "lang": "en",
      "text": "indefinitely so I kind of see rhf as not",
      "offset": 11173.84,
      "duration": 5.399
    },
    {
      "lang": "en",
      "text": "real RL because the reward function is",
      "offset": 11176.64,
      "duration": 4.639
    },
    {
      "lang": "en",
      "text": "gameable so it's kind of more like in",
      "offset": 11179.239,
      "duration": 3.801
    },
    {
      "lang": "en",
      "text": "the realm of like little fine-tuning",
      "offset": 11181.279,
      "duration": 4.841
    },
    {
      "lang": "en",
      "text": "it's a little it's a little Improvement",
      "offset": 11183.04,
      "duration": 4.439
    },
    {
      "lang": "en",
      "text": "but it's not something that is",
      "offset": 11186.12,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "fundamentally set up correctly where you",
      "offset": 11187.479,
      "duration": 4.561
    },
    {
      "lang": "en",
      "text": "can insert more compute run for longer",
      "offset": 11189.56,
      "duration": 5
    },
    {
      "lang": "en",
      "text": "and get much better and magical results",
      "offset": 11192.04,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "so it's it's uh it's not RL in that",
      "offset": 11194.56,
      "duration": 4.28
    },
    {
      "lang": "en",
      "text": "sense it's not RL in the sense that it",
      "offset": 11196.84,
      "duration": 4.479
    },
    {
      "lang": "en",
      "text": "lacks magic um it can find you in your",
      "offset": 11198.84,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "model and get a better performance and",
      "offset": 11201.319,
      "duration": 5.601
    },
    {
      "lang": "en",
      "text": "indeed if we go back to chat GPT the GPT",
      "offset": 11203.64,
      "duration": 6.44
    },
    {
      "lang": "en",
      "text": "40 model has gone through rhf because it",
      "offset": 11206.92,
      "duration": 5.88
    },
    {
      "lang": "en",
      "text": "works well but it's just not RL in the",
      "offset": 11210.08,
      "duration": 4.84
    },
    {
      "lang": "en",
      "text": "same sense rlf is like a little fine",
      "offset": 11212.8,
      "duration": 3.679
    },
    {
      "lang": "en",
      "text": "tune that slightly improves your model",
      "offset": 11214.92,
      "duration": 2.8
    },
    {
      "lang": "en",
      "text": "is maybe like the way I would think",
      "offset": 11216.479,
      "duration": 3.161
    },
    {
      "lang": "en",
      "text": "about it okay so that's most of the",
      "offset": 11217.72,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "technical content that I wanted to cover",
      "offset": 11219.64,
      "duration": 3.719
    },
    {
      "lang": "en",
      "text": "I took you through the three major",
      "offset": 11221.8,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "stages and paradigms of training these",
      "offset": 11223.359,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "models pre-training supervised fine",
      "offset": 11225.16,
      "duration": 4.279
    },
    {
      "lang": "en",
      "text": "tuning and reinforcement learning and I",
      "offset": 11227.439,
      "duration": 3.561
    },
    {
      "lang": "en",
      "text": "showed you that they Loosely correspond",
      "offset": 11229.439,
      "duration": 3.241
    },
    {
      "lang": "en",
      "text": "to the process we already use for",
      "offset": 11231,
      "duration": 4.12
    },
    {
      "lang": "en",
      "text": "teaching children and so in particular",
      "offset": 11232.68,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "we talked about pre-training being sort",
      "offset": 11235.12,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "of like the basic knowledge acquisition",
      "offset": 11237,
      "duration": 4.279
    },
    {
      "lang": "en",
      "text": "of reading Exposition supervised fine",
      "offset": 11238.88,
      "duration": 4.04
    },
    {
      "lang": "en",
      "text": "tuning being the process of looking at",
      "offset": 11241.279,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "lots and lots of worked examples and",
      "offset": 11242.92,
      "duration": 5.64
    },
    {
      "lang": "en",
      "text": "imitating experts and practice problems",
      "offset": 11244.96,
      "duration": 5.16
    },
    {
      "lang": "en",
      "text": "the only difference is that we now have",
      "offset": 11248.56,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "to effectively write textbooks for llms",
      "offset": 11250.12,
      "duration": 5.08
    },
    {
      "lang": "en",
      "text": "and AIS across all the disciplines of",
      "offset": 11252.96,
      "duration": 4.479
    },
    {
      "lang": "en",
      "text": "human knowledge and also in all the",
      "offset": 11255.2,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "cases where we actually would like them",
      "offset": 11257.439,
      "duration": 5.241
    },
    {
      "lang": "en",
      "text": "to work like code and math and you know",
      "offset": 11259.2,
      "duration": 5.199
    },
    {
      "lang": "en",
      "text": "basically all the other disciplines so",
      "offset": 11262.68,
      "duration": 2.639
    },
    {
      "lang": "en",
      "text": "we're in the process of writing",
      "offset": 11264.399,
      "duration": 3.161
    },
    {
      "lang": "en",
      "text": "textbooks for them refining all the",
      "offset": 11265.319,
      "duration": 3.441
    },
    {
      "lang": "en",
      "text": "algorithms that I've presented on the",
      "offset": 11267.56,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "high level and then of course doing a",
      "offset": 11268.76,
      "duration": 3.88
    },
    {
      "lang": "en",
      "text": "really really good job at the execution",
      "offset": 11270.68,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "of training these models at scale and",
      "offset": 11272.64,
      "duration": 4.04
    },
    {
      "lang": "en",
      "text": "efficiently so in particular I didn't go",
      "offset": 11274.6,
      "duration": 4.36
    },
    {
      "lang": "en",
      "text": "into too many details but these are",
      "offset": 11276.68,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "extremely large and complicated",
      "offset": 11278.96,
      "duration": 5.16
    },
    {
      "lang": "en",
      "text": "distributed uh sort of",
      "offset": 11280.92,
      "duration": 6.16
    },
    {
      "lang": "en",
      "text": "um jobs that have to run over tens of",
      "offset": 11284.12,
      "duration": 4.199
    },
    {
      "lang": "en",
      "text": "thousands or even hundreds of thousands",
      "offset": 11287.08,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "of gpus and the engineering that goes",
      "offset": 11288.319,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "into this is really at the stateof the",
      "offset": 11290.92,
      "duration": 3.559
    },
    {
      "lang": "en",
      "text": "art of what's possible with computers at",
      "offset": 11292.72,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "that scale so I didn't cover that aspect",
      "offset": 11294.479,
      "duration": 4.641
    },
    {
      "lang": "en",
      "text": "too much",
      "offset": 11297.68,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "but um this is very kind of serious and",
      "offset": 11299.12,
      "duration": 5.08
    },
    {
      "lang": "en",
      "text": "they were underlying all these very",
      "offset": 11302.72,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "simple algorithms",
      "offset": 11304.2,
      "duration": 4.52
    },
    {
      "lang": "en",
      "text": "ultimately now I also talked about sort",
      "offset": 11305.76,
      "duration": 4.519
    },
    {
      "lang": "en",
      "text": "of like the theory of mind a little bit",
      "offset": 11308.72,
      "duration": 2.96
    },
    {
      "lang": "en",
      "text": "of these models and the thing I want you",
      "offset": 11310.279,
      "duration": 3.361
    },
    {
      "lang": "en",
      "text": "to take away is that these models are",
      "offset": 11311.68,
      "duration": 3.719
    },
    {
      "lang": "en",
      "text": "really good but they're extremely useful",
      "offset": 11313.64,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "as tools for your work you shouldn't uh",
      "offset": 11315.399,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "sort of trust them fully and I showed",
      "offset": 11318.12,
      "duration": 3.359
    },
    {
      "lang": "en",
      "text": "you some examples of that even though we",
      "offset": 11319.72,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "have mitigations for hallucinations the",
      "offset": 11321.479,
      "duration": 3.161
    },
    {
      "lang": "en",
      "text": "models are not perfect and they will",
      "offset": 11323.16,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "hallucinate still it's gotten better",
      "offset": 11324.64,
      "duration": 3.599
    },
    {
      "lang": "en",
      "text": "over time and it will continue to get",
      "offset": 11326.76,
      "duration": 2.88
    },
    {
      "lang": "en",
      "text": "better but they can",
      "offset": 11328.239,
      "duration": 3.961
    },
    {
      "lang": "en",
      "text": "hallucinate in other words in in",
      "offset": 11329.64,
      "duration": 4.28
    },
    {
      "lang": "en",
      "text": "addition to that I covered kind of like",
      "offset": 11332.2,
      "duration": 3.88
    },
    {
      "lang": "en",
      "text": "what I call the Swiss cheese uh sort of",
      "offset": 11333.92,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "model of llm capabilities that you",
      "offset": 11336.08,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "should have in your mind the models are",
      "offset": 11337.52,
      "duration": 3.08
    },
    {
      "lang": "en",
      "text": "incredibly good across so many different",
      "offset": 11339.2,
      "duration": 3.32
    },
    {
      "lang": "en",
      "text": "disciplines but then fail randomly",
      "offset": 11340.6,
      "duration": 4.52
    },
    {
      "lang": "en",
      "text": "almost in some unique cases so for",
      "offset": 11342.52,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "example what is bigger 9.11 or 9.9 like",
      "offset": 11345.12,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "the model doesn't know but",
      "offset": 11347.88,
      "duration": 3.519
    },
    {
      "lang": "en",
      "text": "simultaneously it can turn around and",
      "offset": 11349.2,
      "duration": 5.279
    },
    {
      "lang": "en",
      "text": "solve Olympiad questions and so this is",
      "offset": 11351.399,
      "duration": 4.681
    },
    {
      "lang": "en",
      "text": "a hole in the Swiss cheese and there are",
      "offset": 11354.479,
      "duration": 3.361
    },
    {
      "lang": "en",
      "text": "many of them and you don't want to trip",
      "offset": 11356.08,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "over them so don't um treat these models",
      "offset": 11357.84,
      "duration": 6.12
    },
    {
      "lang": "en",
      "text": "as infallible models check their work",
      "offset": 11361.6,
      "duration": 3.96
    },
    {
      "lang": "en",
      "text": "use them as tools use them for",
      "offset": 11363.96,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "inspiration use them for the first draft",
      "offset": 11365.56,
      "duration": 4.839
    },
    {
      "lang": "en",
      "text": "but uh work with them as tools and be",
      "offset": 11368.12,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "ultimately respons responsible for the",
      "offset": 11370.399,
      "duration": 4.681
    },
    {
      "lang": "en",
      "text": "you know product of your",
      "offset": 11372.92,
      "duration": 5.96
    },
    {
      "lang": "en",
      "text": "work and that's roughly what I wanted to",
      "offset": 11375.08,
      "duration": 5.84
    },
    {
      "lang": "en",
      "text": "talk about this is how they're trained",
      "offset": 11378.88,
      "duration": 4.28
    },
    {
      "lang": "en",
      "text": "and this is what they are let's now turn",
      "offset": 11380.92,
      "duration": 3.359
    },
    {
      "lang": "en",
      "text": "to what are some of the future",
      "offset": 11383.16,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "capabilities of these models uh probably",
      "offset": 11384.279,
      "duration": 3.801
    },
    {
      "lang": "en",
      "text": "what's coming down the pipe and also",
      "offset": 11386.68,
      "duration": 3.559
    },
    {
      "lang": "en",
      "text": "where can you find these models I have a",
      "offset": 11388.08,
      "duration": 3.359
    },
    {
      "lang": "en",
      "text": "few blow points on some of the things",
      "offset": 11390.239,
      "duration": 3.24
    },
    {
      "lang": "en",
      "text": "that you can expect coming down the pipe",
      "offset": 11391.439,
      "duration": 3.561
    },
    {
      "lang": "en",
      "text": "the first thing you'll notice is that",
      "offset": 11393.479,
      "duration": 3.401
    },
    {
      "lang": "en",
      "text": "the models will very rapidly become",
      "offset": 11395,
      "duration": 3.64
    },
    {
      "lang": "en",
      "text": "multimodal everything I talked about",
      "offset": 11396.88,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "above concerned text but very soon we'll",
      "offset": 11398.64,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "have llms that can not just handle text",
      "offset": 11401.279,
      "duration": 4.281
    },
    {
      "lang": "en",
      "text": "but they can also operate natively and",
      "offset": 11403.6,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "very easily over audio so they can hear",
      "offset": 11405.56,
      "duration": 4.919
    },
    {
      "lang": "en",
      "text": "and speak and also images so they can",
      "offset": 11408,
      "duration": 5
    },
    {
      "lang": "en",
      "text": "see and paint and we're already seeing",
      "offset": 11410.479,
      "duration": 4.561
    },
    {
      "lang": "en",
      "text": "the beginnings of all of this uh but",
      "offset": 11413,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "this will be all done natively inside",
      "offset": 11415.04,
      "duration": 4.12
    },
    {
      "lang": "en",
      "text": "inside the language model and this will",
      "offset": 11417.319,
      "duration": 3.241
    },
    {
      "lang": "en",
      "text": "enable kind of like natural",
      "offset": 11419.16,
      "duration": 3.239
    },
    {
      "lang": "en",
      "text": "conversations and roughly speaking the",
      "offset": 11420.56,
      "duration": 3
    },
    {
      "lang": "en",
      "text": "reason that this is actually no",
      "offset": 11422.399,
      "duration": 2.361
    },
    {
      "lang": "en",
      "text": "different from everything we've covered",
      "offset": 11423.56,
      "duration": 4.799
    },
    {
      "lang": "en",
      "text": "above is that as a baseline you can",
      "offset": 11424.76,
      "duration": 6.4
    },
    {
      "lang": "en",
      "text": "tokenize audio and images and apply the",
      "offset": 11428.359,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "exact same approaches of everything that",
      "offset": 11431.16,
      "duration": 3.48
    },
    {
      "lang": "en",
      "text": "we've talked about above so it's not a",
      "offset": 11432.68,
      "duration": 3.599
    },
    {
      "lang": "en",
      "text": "fundamental change it's just uh it's",
      "offset": 11434.64,
      "duration": 4.2
    },
    {
      "lang": "en",
      "text": "just a to we have to add some tokens so",
      "offset": 11436.279,
      "duration": 4.761
    },
    {
      "lang": "en",
      "text": "as an example for tokenizing audio we",
      "offset": 11438.84,
      "duration": 4.36
    },
    {
      "lang": "en",
      "text": "can look at slices of the spectrogram of",
      "offset": 11441.04,
      "duration": 4.92
    },
    {
      "lang": "en",
      "text": "the audio signal and we can tokenize",
      "offset": 11443.2,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "that and just add more tokens that",
      "offset": 11445.96,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "suddenly represent audio and just add",
      "offset": 11447.84,
      "duration": 3.559
    },
    {
      "lang": "en",
      "text": "them into the context windows and train",
      "offset": 11450.04,
      "duration": 3.399
    },
    {
      "lang": "en",
      "text": "on them just like above the same for",
      "offset": 11451.399,
      "duration": 4.641
    },
    {
      "lang": "en",
      "text": "images we can use patches and we can",
      "offset": 11453.439,
      "duration": 5.401
    },
    {
      "lang": "en",
      "text": "separately tokenize patches and then",
      "offset": 11456.04,
      "duration": 4.52
    },
    {
      "lang": "en",
      "text": "what is an image an image is just a",
      "offset": 11458.84,
      "duration": 4.28
    },
    {
      "lang": "en",
      "text": "sequence of tokens and this actually",
      "offset": 11460.56,
      "duration": 4.12
    },
    {
      "lang": "en",
      "text": "kind of works and there's a lot of early",
      "offset": 11463.12,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "work in this direction and so we can",
      "offset": 11464.68,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "just create streams of tokens that are",
      "offset": 11466.64,
      "duration": 3.799
    },
    {
      "lang": "en",
      "text": "representing audio images as well as",
      "offset": 11468.68,
      "duration": 3.799
    },
    {
      "lang": "en",
      "text": "text and interpers them and handle them",
      "offset": 11470.439,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "all simultaneously in a single model so",
      "offset": 11472.479,
      "duration": 4.92
    },
    {
      "lang": "en",
      "text": "that's one example of multimodality",
      "offset": 11474.76,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "uh second something that people are very",
      "offset": 11477.399,
      "duration": 2.641
    },
    {
      "lang": "en",
      "text": "interested in",
      "offset": 11478.92,
      "duration": 3.399
    },
    {
      "lang": "en",
      "text": "is currently most of the work is that",
      "offset": 11480.04,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "we're handing individual tasks to the",
      "offset": 11482.319,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "models on kind of like a silver platter",
      "offset": 11484.2,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "like please solve this task for me and",
      "offset": 11486.319,
      "duration": 3.16
    },
    {
      "lang": "en",
      "text": "the model sort of like does this little",
      "offset": 11488.04,
      "duration": 4.04
    },
    {
      "lang": "en",
      "text": "task but it's up to us to still sort of",
      "offset": 11489.479,
      "duration": 5.521
    },
    {
      "lang": "en",
      "text": "like organize a coherent execution of",
      "offset": 11492.08,
      "duration": 6.04
    },
    {
      "lang": "en",
      "text": "tasks to perform jobs and the models are",
      "offset": 11495,
      "duration": 6.279
    },
    {
      "lang": "en",
      "text": "not yet at the capability required to do",
      "offset": 11498.12,
      "duration": 5.72
    },
    {
      "lang": "en",
      "text": "this in a coherent error correcting way",
      "offset": 11501.279,
      "duration": 5.441
    },
    {
      "lang": "en",
      "text": "over long periods of time so they're not",
      "offset": 11503.84,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "able to fully string together tasks to",
      "offset": 11506.72,
      "duration": 4.44
    },
    {
      "lang": "en",
      "text": "perform these longer running jobs but",
      "offset": 11508.56,
      "duration": 3.64
    },
    {
      "lang": "en",
      "text": "they're getting there and this is",
      "offset": 11511.16,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "improving uh over time but uh probably",
      "offset": 11512.2,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "what's going to happen here is we're",
      "offset": 11515.08,
      "duration": 2.319
    },
    {
      "lang": "en",
      "text": "going to start to see what's called",
      "offset": 11516.12,
      "duration": 4.239
    },
    {
      "lang": "en",
      "text": "agents which perform tasks over time and",
      "offset": 11517.399,
      "duration": 5.321
    },
    {
      "lang": "en",
      "text": "you you supervise them and you watch",
      "offset": 11520.359,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "their work and they come up to once in a",
      "offset": 11522.72,
      "duration": 4.44
    },
    {
      "lang": "en",
      "text": "while report progress and so on so we're",
      "offset": 11524.68,
      "duration": 4.92
    },
    {
      "lang": "en",
      "text": "going to see more long running agents uh",
      "offset": 11527.16,
      "duration": 3.88
    },
    {
      "lang": "en",
      "text": "tasks that don't just take you know a",
      "offset": 11529.6,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "few seconds of response but many tens of",
      "offset": 11531.04,
      "duration": 4.12
    },
    {
      "lang": "en",
      "text": "seconds or even minutes or hours over",
      "offset": 11533.12,
      "duration": 4.76
    },
    {
      "lang": "en",
      "text": "time uh but these uh models are not",
      "offset": 11535.16,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "infallible as we talked about above so",
      "offset": 11537.88,
      "duration": 3.96
    },
    {
      "lang": "en",
      "text": "all of this will require supervision so",
      "offset": 11539.8,
      "duration": 3.4
    },
    {
      "lang": "en",
      "text": "for example in factories people talk",
      "offset": 11541.84,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "about the human to robot ratio uh for",
      "offset": 11543.2,
      "duration": 4.6
    },
    {
      "lang": "en",
      "text": "automation I think we're going to see",
      "offset": 11546.239,
      "duration": 3.561
    },
    {
      "lang": "en",
      "text": "something similar in the digital space",
      "offset": 11547.8,
      "duration": 3.24
    },
    {
      "lang": "en",
      "text": "where we are going to be talking about",
      "offset": 11549.8,
      "duration": 3.439
    },
    {
      "lang": "en",
      "text": "human to agent ratios where humans",
      "offset": 11551.04,
      "duration": 4.68
    },
    {
      "lang": "en",
      "text": "becomes a lot more supervisors of agent",
      "offset": 11553.239,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "tasks um in the digital",
      "offset": 11555.72,
      "duration": 5.719
    },
    {
      "lang": "en",
      "text": "domain uh next um I think everything is",
      "offset": 11558.439,
      "duration": 4.361
    },
    {
      "lang": "en",
      "text": "going to become a lot more pervasive and",
      "offset": 11561.439,
      "duration": 3.161
    },
    {
      "lang": "en",
      "text": "invisible so it's kind of like",
      "offset": 11562.8,
      "duration": 5.92
    },
    {
      "lang": "en",
      "text": "integrated into the tools and everywhere",
      "offset": 11564.6,
      "duration": 6.6
    },
    {
      "lang": "en",
      "text": "um and in addition kind of like computer",
      "offset": 11568.72,
      "duration": 4.92
    },
    {
      "lang": "en",
      "text": "using so right now these models aren't",
      "offset": 11571.2,
      "duration": 5
    },
    {
      "lang": "en",
      "text": "able to take actions on your behalf but",
      "offset": 11573.64,
      "duration": 5.24
    },
    {
      "lang": "en",
      "text": "I think this is a separate bullet point",
      "offset": 11576.2,
      "duration": 6.119
    },
    {
      "lang": "en",
      "text": "um if you saw chpt launch the operator",
      "offset": 11578.88,
      "duration": 5.439
    },
    {
      "lang": "en",
      "text": "then uh that's one early example of that",
      "offset": 11582.319,
      "duration": 3.441
    },
    {
      "lang": "en",
      "text": "where you can actually hand off control",
      "offset": 11584.319,
      "duration": 3.441
    },
    {
      "lang": "en",
      "text": "to the model to perform you know",
      "offset": 11585.76,
      "duration": 3.8
    },
    {
      "lang": "en",
      "text": "keyboard and mouse actions on your",
      "offset": 11587.76,
      "duration": 3.559
    },
    {
      "lang": "en",
      "text": "behalf so that's also something that",
      "offset": 11589.56,
      "duration": 3.64
    },
    {
      "lang": "en",
      "text": "that I think is very interesting the",
      "offset": 11591.319,
      "duration": 3.321
    },
    {
      "lang": "en",
      "text": "last point I have here is just a general",
      "offset": 11593.2,
      "duration": 2.56
    },
    {
      "lang": "en",
      "text": "comment that there's still a lot of",
      "offset": 11594.64,
      "duration": 2.28
    },
    {
      "lang": "en",
      "text": "research to potentially do in this",
      "offset": 11595.76,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "domain main one example of that uh is",
      "offset": 11596.92,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "something along the lines of test time",
      "offset": 11599.68,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "training so remember that everything",
      "offset": 11600.92,
      "duration": 3.319
    },
    {
      "lang": "en",
      "text": "we've done above and that we talked",
      "offset": 11602.8,
      "duration": 4.28
    },
    {
      "lang": "en",
      "text": "about has two major stages there's first",
      "offset": 11604.239,
      "duration": 4.481
    },
    {
      "lang": "en",
      "text": "the training stage where we tune the",
      "offset": 11607.08,
      "duration": 3.399
    },
    {
      "lang": "en",
      "text": "parameters of the model to perform the",
      "offset": 11608.72,
      "duration": 4.44
    },
    {
      "lang": "en",
      "text": "tasks well once we get the parameters we",
      "offset": 11610.479,
      "duration": 4.481
    },
    {
      "lang": "en",
      "text": "fix them and then we deploy the model",
      "offset": 11613.16,
      "duration": 4.52
    },
    {
      "lang": "en",
      "text": "for inference from there the model is",
      "offset": 11614.96,
      "duration": 4.6
    },
    {
      "lang": "en",
      "text": "fixed it doesn't change anymore it",
      "offset": 11617.68,
      "duration": 3.559
    },
    {
      "lang": "en",
      "text": "doesn't learn from all the stuff that",
      "offset": 11619.56,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "it's doing a test time it's a fixed um",
      "offset": 11621.239,
      "duration": 4.2
    },
    {
      "lang": "en",
      "text": "number of parameters and the only thing",
      "offset": 11623.479,
      "duration": 4.121
    },
    {
      "lang": "en",
      "text": "that is changing is now the token inside",
      "offset": 11625.439,
      "duration": 4.441
    },
    {
      "lang": "en",
      "text": "the context windows and so the only type",
      "offset": 11627.6,
      "duration": 4.36
    },
    {
      "lang": "en",
      "text": "of learning or test time learning that",
      "offset": 11629.88,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "the model has access to is the in",
      "offset": 11631.96,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "context learning of its uh kind of like",
      "offset": 11633.8,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "uh dynamically adjustable context window",
      "offset": 11636.92,
      "duration": 3.559
    },
    {
      "lang": "en",
      "text": "depending on like what it's doing at",
      "offset": 11639,
      "duration": 4.279
    },
    {
      "lang": "en",
      "text": "test time so but I think this is still",
      "offset": 11640.479,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "different from humans who actually are",
      "offset": 11643.279,
      "duration": 3.281
    },
    {
      "lang": "en",
      "text": "able to like actually learn uh depending",
      "offset": 11644.64,
      "duration": 3.4
    },
    {
      "lang": "en",
      "text": "on what they're doing especially when",
      "offset": 11646.56,
      "duration": 2.919
    },
    {
      "lang": "en",
      "text": "you sleep for example like your brain is",
      "offset": 11648.04,
      "duration": 2.76
    },
    {
      "lang": "en",
      "text": "updating your parameters or something",
      "offset": 11649.479,
      "duration": 3.521
    },
    {
      "lang": "en",
      "text": "like that right so there's no kind of",
      "offset": 11650.8,
      "duration": 3.559
    },
    {
      "lang": "en",
      "text": "equivalent of that currently in these",
      "offset": 11653,
      "duration": 3.56
    },
    {
      "lang": "en",
      "text": "models and tools so there's a lot of",
      "offset": 11654.359,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "like um more wonky ideas I think that",
      "offset": 11656.56,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "are to be explored still and uh in",
      "offset": 11658.439,
      "duration": 3.441
    },
    {
      "lang": "en",
      "text": "particular I think this will be",
      "offset": 11660.8,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "necessary because the context window is",
      "offset": 11661.88,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "a finite and precious resource and",
      "offset": 11664.08,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "especially once we start to tackle very",
      "offset": 11666.12,
      "duration": 4.279
    },
    {
      "lang": "en",
      "text": "long running multimodal tasks and we're",
      "offset": 11667.84,
      "duration": 3.96
    },
    {
      "lang": "en",
      "text": "putting in videos and these token",
      "offset": 11670.399,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "windows will basically start to grow",
      "offset": 11671.8,
      "duration": 4.599
    },
    {
      "lang": "en",
      "text": "extremely large like not thousands or",
      "offset": 11674.08,
      "duration": 3.72
    },
    {
      "lang": "en",
      "text": "even hundreds of thousands but",
      "offset": 11676.399,
      "duration": 3.481
    },
    {
      "lang": "en",
      "text": "significantly beyond that and the only",
      "offset": 11677.8,
      "duration": 4.04
    },
    {
      "lang": "en",
      "text": "trick uh the only kind of trick we have",
      "offset": 11679.88,
      "duration": 3.599
    },
    {
      "lang": "en",
      "text": "Avail to us right now is to make the",
      "offset": 11681.84,
      "duration": 4.28
    },
    {
      "lang": "en",
      "text": "context Windows longer but I think that",
      "offset": 11683.479,
      "duration": 3.96
    },
    {
      "lang": "en",
      "text": "that approach by itself will will not",
      "offset": 11686.12,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "will not scale to actual long running",
      "offset": 11687.439,
      "duration": 4.521
    },
    {
      "lang": "en",
      "text": "tasks that are multimodal over time and",
      "offset": 11689.8,
      "duration": 4.12
    },
    {
      "lang": "en",
      "text": "so I think new ideas are needed in some",
      "offset": 11691.96,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "of those disciplines um in some of those",
      "offset": 11693.92,
      "duration": 4.559
    },
    {
      "lang": "en",
      "text": "kind of cases in the main where these",
      "offset": 11696.76,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "tasks are going to require very long",
      "offset": 11698.479,
      "duration": 4.521
    },
    {
      "lang": "en",
      "text": "contexts so those are some examples of",
      "offset": 11700.84,
      "duration": 4.519
    },
    {
      "lang": "en",
      "text": "some of the things you can um expect",
      "offset": 11703,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "coming down the pipe let's now turn to",
      "offset": 11705.359,
      "duration": 3.761
    },
    {
      "lang": "en",
      "text": "where you can actually uh kind of keep",
      "offset": 11707.16,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "track of this progress and um you know",
      "offset": 11709.12,
      "duration": 4.84
    },
    {
      "lang": "en",
      "text": "be up to date with the latest and grest",
      "offset": 11712.2,
      "duration": 3.199
    },
    {
      "lang": "en",
      "text": "of what's happening in the field so I",
      "offset": 11713.96,
      "duration": 2.68
    },
    {
      "lang": "en",
      "text": "would say the three resources that I",
      "offset": 11715.399,
      "duration": 3.201
    },
    {
      "lang": "en",
      "text": "have consistently used to stay up to",
      "offset": 11716.64,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "date are number one El Marina uh so let",
      "offset": 11718.6,
      "duration": 5.08
    },
    {
      "lang": "en",
      "text": "me show you El",
      "offset": 11721.76,
      "duration": 4.599
    },
    {
      "lang": "en",
      "text": "Marina this is basically an llm leader",
      "offset": 11723.68,
      "duration": 6.519
    },
    {
      "lang": "en",
      "text": "board and it ranks all the top models",
      "offset": 11726.359,
      "duration": 5.84
    },
    {
      "lang": "en",
      "text": "and the ranking is based on human",
      "offset": 11730.199,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "comparisons so humans prompt these",
      "offset": 11732.199,
      "duration": 3.761
    },
    {
      "lang": "en",
      "text": "models and they get to judge which one",
      "offset": 11734.04,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "gives a better answer they don't know",
      "offset": 11735.96,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "which model is which they're just",
      "offset": 11737.56,
      "duration": 2.719
    },
    {
      "lang": "en",
      "text": "looking at which model is the better",
      "offset": 11739,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "answer and you can calculate a ranking",
      "offset": 11740.279,
      "duration": 4.281
    },
    {
      "lang": "en",
      "text": "and then you get some results and so",
      "offset": 11742.68,
      "duration": 3.639
    },
    {
      "lang": "en",
      "text": "what you can hear is what you can see",
      "offset": 11744.56,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "here is the different organizations like",
      "offset": 11746.319,
      "duration": 3.241
    },
    {
      "lang": "en",
      "text": "Google Gemini for example that produce",
      "offset": 11748,
      "duration": 3.319
    },
    {
      "lang": "en",
      "text": "these models when you click on any one",
      "offset": 11749.56,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "of these it takes you to the place where",
      "offset": 11751.319,
      "duration": 3.721
    },
    {
      "lang": "en",
      "text": "that model is",
      "offset": 11753.88,
      "duration": 3.319
    },
    {
      "lang": "en",
      "text": "hosted and then here we see Google is",
      "offset": 11755.04,
      "duration": 4.239
    },
    {
      "lang": "en",
      "text": "currently on top with open AI right",
      "offset": 11757.199,
      "duration": 5.24
    },
    {
      "lang": "en",
      "text": "behind here we see deep seek in position",
      "offset": 11759.279,
      "duration": 4.881
    },
    {
      "lang": "en",
      "text": "number three now the reason this is a",
      "offset": 11762.439,
      "duration": 3.521
    },
    {
      "lang": "en",
      "text": "big deal is the last column here you see",
      "offset": 11764.16,
      "duration": 4.279
    },
    {
      "lang": "en",
      "text": "license deep seek is an MIT license",
      "offset": 11765.96,
      "duration": 4.84
    },
    {
      "lang": "en",
      "text": "model it's open weights anyone can use",
      "offset": 11768.439,
      "duration": 4.281
    },
    {
      "lang": "en",
      "text": "these weights uh anyone can download",
      "offset": 11770.8,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "them anyone can host their own version",
      "offset": 11772.72,
      "duration": 4.2
    },
    {
      "lang": "en",
      "text": "of Deep seek and they can use it in what",
      "offset": 11774.56,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "whatever way they like and so it's not a",
      "offset": 11776.92,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "proprietary model that you don't have",
      "offset": 11778.72,
      "duration": 2.92
    },
    {
      "lang": "en",
      "text": "access to it's it's basically an open",
      "offset": 11779.96,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "weight release and so this is kind of",
      "offset": 11781.64,
      "duration": 5.559
    },
    {
      "lang": "en",
      "text": "unprecedented that a model this strong",
      "offset": 11784.52,
      "duration": 5.16
    },
    {
      "lang": "en",
      "text": "was released with open weights so pretty",
      "offset": 11787.199,
      "duration": 4.961
    },
    {
      "lang": "en",
      "text": "cool from the team next up we have a few",
      "offset": 11789.68,
      "duration": 4.44
    },
    {
      "lang": "en",
      "text": "more models from Google and open Ai and",
      "offset": 11792.16,
      "duration": 3.199
    },
    {
      "lang": "en",
      "text": "then when you continue to scroll down",
      "offset": 11794.12,
      "duration": 2.76
    },
    {
      "lang": "en",
      "text": "you start to see some other Usual",
      "offset": 11795.359,
      "duration": 5.401
    },
    {
      "lang": "en",
      "text": "Suspects so xai here anthropic with son",
      "offset": 11796.88,
      "duration": 6.16
    },
    {
      "lang": "en",
      "text": "it uh here at number",
      "offset": 11800.76,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "14 and",
      "offset": 11803.04,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "um then",
      "offset": 11805.64,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "meta with llama over here so llama",
      "offset": 11807.92,
      "duration": 4.84
    },
    {
      "lang": "en",
      "text": "similar to deep seek is an open weights",
      "offset": 11811,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "model and so uh but it's down here as",
      "offset": 11812.76,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "opposed to up here now I will say that",
      "offset": 11815.8,
      "duration": 4.84
    },
    {
      "lang": "en",
      "text": "this leaderboard was really good for a",
      "offset": 11817.96,
      "duration": 5.72
    },
    {
      "lang": "en",
      "text": "long time I do think that in the last",
      "offset": 11820.64,
      "duration": 4.719
    },
    {
      "lang": "en",
      "text": "few months it's become a little bit",
      "offset": 11823.68,
      "duration": 4.679
    },
    {
      "lang": "en",
      "text": "gamed um and I don't trust it as much as",
      "offset": 11825.359,
      "duration": 6.401
    },
    {
      "lang": "en",
      "text": "I used to I think um just empirically I",
      "offset": 11828.359,
      "duration": 4.761
    },
    {
      "lang": "en",
      "text": "feel like a lot of people for example",
      "offset": 11831.76,
      "duration": 3.599
    },
    {
      "lang": "en",
      "text": "are using a Sonet from anthropic and",
      "offset": 11833.12,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "that it's a really good model so but",
      "offset": 11835.359,
      "duration": 4.281
    },
    {
      "lang": "en",
      "text": "that's all the way down here um in",
      "offset": 11837.04,
      "duration": 5.399
    },
    {
      "lang": "en",
      "text": "number 14 and conversely I think not as",
      "offset": 11839.64,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "many people are using Gemini but it's",
      "offset": 11842.439,
      "duration": 4.561
    },
    {
      "lang": "en",
      "text": "racking really really high uh so I think",
      "offset": 11843.72,
      "duration": 6.759
    },
    {
      "lang": "en",
      "text": "use this as a first pass uh but uh sort",
      "offset": 11847,
      "duration": 5.88
    },
    {
      "lang": "en",
      "text": "of try out a few of the models for your",
      "offset": 11850.479,
      "duration": 5.121
    },
    {
      "lang": "en",
      "text": "tasks and see which one performs better",
      "offset": 11852.88,
      "duration": 4.12
    },
    {
      "lang": "en",
      "text": "the second thing that I would point to",
      "offset": 11855.6,
      "duration": 5.48
    },
    {
      "lang": "en",
      "text": "is the uh AI news uh newsletter so AI",
      "offset": 11857,
      "duration": 6.16
    },
    {
      "lang": "en",
      "text": "news is not very creatively named but it",
      "offset": 11861.08,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "is a very good newsletter produced by",
      "offset": 11863.16,
      "duration": 3.159
    },
    {
      "lang": "en",
      "text": "swix and friends so thank you for",
      "offset": 11864.92,
      "duration": 2.439
    },
    {
      "lang": "en",
      "text": "maintaining it",
      "offset": 11866.319,
      "duration": 2.441
    },
    {
      "lang": "en",
      "text": "and it's been very helpful to me because",
      "offset": 11867.359,
      "duration": 3.441
    },
    {
      "lang": "en",
      "text": "it is extremely comprehensive so if you",
      "offset": 11868.76,
      "duration": 4.2
    },
    {
      "lang": "en",
      "text": "go to archives uh you see that it's",
      "offset": 11870.8,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "produced almost every other day and um",
      "offset": 11872.96,
      "duration": 5.16
    },
    {
      "lang": "en",
      "text": "it is very comprehensive and some of it",
      "offset": 11876.08,
      "duration": 3.56
    },
    {
      "lang": "en",
      "text": "is written by humans and curated by",
      "offset": 11878.12,
      "duration": 3.159
    },
    {
      "lang": "en",
      "text": "humans but a lot of it is constructed",
      "offset": 11879.64,
      "duration": 3.559
    },
    {
      "lang": "en",
      "text": "automatically with llms so you'll see",
      "offset": 11881.279,
      "duration": 3.561
    },
    {
      "lang": "en",
      "text": "that these are very comprehensive and",
      "offset": 11883.199,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "you're probably not missing anything",
      "offset": 11884.84,
      "duration": 3.96
    },
    {
      "lang": "en",
      "text": "major if you go through it of course",
      "offset": 11886.399,
      "duration": 3.521
    },
    {
      "lang": "en",
      "text": "you're probably not going to go through",
      "offset": 11888.8,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "it because it's so long but I do think",
      "offset": 11889.92,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "that these summaries all the way up top",
      "offset": 11892,
      "duration": 3.64
    },
    {
      "lang": "en",
      "text": "are quite good and I think have some",
      "offset": 11894.08,
      "duration": 4.52
    },
    {
      "lang": "en",
      "text": "human oversight uh so this has been very",
      "offset": 11895.64,
      "duration": 4.759
    },
    {
      "lang": "en",
      "text": "helpful to me and the last thing I would",
      "offset": 11898.6,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "point to is just X and Twitter uh a lot",
      "offset": 11900.399,
      "duration": 5.321
    },
    {
      "lang": "en",
      "text": "of um AI happens on X and so I would",
      "offset": 11902.68,
      "duration": 4.519
    },
    {
      "lang": "en",
      "text": "just follow people who you like and",
      "offset": 11905.72,
      "duration": 4.04
    },
    {
      "lang": "en",
      "text": "trust and get all your latest and",
      "offset": 11907.199,
      "duration": 5.16
    },
    {
      "lang": "en",
      "text": "greatest uh on X as well so those are",
      "offset": 11909.76,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "the major places that have worked for me",
      "offset": 11912.359,
      "duration": 3.201
    },
    {
      "lang": "en",
      "text": "over time and finally a few words on",
      "offset": 11913.68,
      "duration": 3.88
    },
    {
      "lang": "en",
      "text": "where you can find the models and where",
      "offset": 11915.56,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "can you use them so the first one I",
      "offset": 11917.56,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "would say is for any of the biggest",
      "offset": 11919.399,
      "duration": 3.361
    },
    {
      "lang": "en",
      "text": "proprietary models you just have to go",
      "offset": 11921.16,
      "duration": 3.56
    },
    {
      "lang": "en",
      "text": "to the website of that LM provider so",
      "offset": 11922.76,
      "duration": 4.479
    },
    {
      "lang": "en",
      "text": "for example for open a that's uh chat",
      "offset": 11924.72,
      "duration": 4.639
    },
    {
      "lang": "en",
      "text": "I believe actually works now uh so",
      "offset": 11927.239,
      "duration": 3.481
    },
    {
      "lang": "en",
      "text": "that's for open",
      "offset": 11929.359,
      "duration": 5.241
    },
    {
      "lang": "en",
      "text": "AI now for or you know for um for Gemini",
      "offset": 11930.72,
      "duration": 7.04
    },
    {
      "lang": "en",
      "text": "I think it's gem. google.com or AI",
      "offset": 11934.6,
      "duration": 5
    },
    {
      "lang": "en",
      "text": "Studio I think they have two for some",
      "offset": 11937.76,
      "duration": 3.719
    },
    {
      "lang": "en",
      "text": "reason that I don't fly understand no",
      "offset": 11939.6,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "one does um for the open weights models",
      "offset": 11941.479,
      "duration": 5.241
    },
    {
      "lang": "en",
      "text": "like deep SE CL Etc you have to go to",
      "offset": 11944.72,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "some kind of an inference provider of",
      "offset": 11946.72,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "LMS so my favorite one is together",
      "offset": 11948.08,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "together. a and I showed you that when",
      "offset": 11950.08,
      "duration": 4.239
    },
    {
      "lang": "en",
      "text": "you go to the playground of together. a",
      "offset": 11951.84,
      "duration": 3.96
    },
    {
      "lang": "en",
      "text": "then you can sort of pick lots of",
      "offset": 11954.319,
      "duration": 3.08
    },
    {
      "lang": "en",
      "text": "different models and all of these are",
      "offset": 11955.8,
      "duration": 3.519
    },
    {
      "lang": "en",
      "text": "open models of different types and you",
      "offset": 11957.399,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "can talk to them here as an",
      "offset": 11959.319,
      "duration": 5.361
    },
    {
      "lang": "en",
      "text": "example um now if you'd like to use a",
      "offset": 11961.56,
      "duration": 6.52
    },
    {
      "lang": "en",
      "text": "base model like um you know a base model",
      "offset": 11964.68,
      "duration": 4.84
    },
    {
      "lang": "en",
      "text": "then this is where I think it's not as",
      "offset": 11968.08,
      "duration": 2.96
    },
    {
      "lang": "en",
      "text": "common to find base models even on these",
      "offset": 11969.52,
      "duration": 3.16
    },
    {
      "lang": "en",
      "text": "inference providers they are all",
      "offset": 11971.04,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "targeting assistants and chat and so I",
      "offset": 11972.68,
      "duration": 4.84
    },
    {
      "lang": "en",
      "text": "think even here I can't I couldn't see",
      "offset": 11975.6,
      "duration": 4.12
    },
    {
      "lang": "en",
      "text": "base models here so for base models I",
      "offset": 11977.52,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "usually go to hyperbolic because they",
      "offset": 11979.72,
      "duration": 5.4
    },
    {
      "lang": "en",
      "text": "serve my llama 3.1 base and I love that",
      "offset": 11981.76,
      "duration": 5.479
    },
    {
      "lang": "en",
      "text": "model and you can just talk to it here",
      "offset": 11985.12,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "so as far as I know this is this is a",
      "offset": 11987.239,
      "duration": 4.12
    },
    {
      "lang": "en",
      "text": "good place for a base model and I wish",
      "offset": 11989.439,
      "duration": 3.88
    },
    {
      "lang": "en",
      "text": "more people hosted base models because",
      "offset": 11991.359,
      "duration": 3.401
    },
    {
      "lang": "en",
      "text": "they are useful and interesting to work",
      "offset": 11993.319,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "with in some cases finally you can also",
      "offset": 11994.76,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "take some of the models that are smaller",
      "offset": 11997.64,
      "duration": 4.759
    },
    {
      "lang": "en",
      "text": "and you can run them locally and so for",
      "offset": 11999.72,
      "duration": 4.599
    },
    {
      "lang": "en",
      "text": "example deep seek the biggest model",
      "offset": 12002.399,
      "duration": 2.88
    },
    {
      "lang": "en",
      "text": "you're not going to be able to run",
      "offset": 12004.319,
      "duration": 3.361
    },
    {
      "lang": "en",
      "text": "locally on your MacBook but there are",
      "offset": 12005.279,
      "duration": 4.04
    },
    {
      "lang": "en",
      "text": "smaller versions of the deep seek model",
      "offset": 12007.68,
      "duration": 3.519
    },
    {
      "lang": "en",
      "text": "that are what's called distilled and",
      "offset": 12009.319,
      "duration": 3.16
    },
    {
      "lang": "en",
      "text": "then also you can run these models at",
      "offset": 12011.199,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "smaller Precision so not at the native",
      "offset": 12012.479,
      "duration": 4.601
    },
    {
      "lang": "en",
      "text": "Precision of for example fp8 on deep",
      "offset": 12014.479,
      "duration": 5.84
    },
    {
      "lang": "en",
      "text": "seek or you know bf16 llama but much",
      "offset": 12017.08,
      "duration": 6.68
    },
    {
      "lang": "en",
      "text": "much lower than that um and don't worry",
      "offset": 12020.319,
      "duration": 4.521
    },
    {
      "lang": "en",
      "text": "if you don't fully understand those",
      "offset": 12023.76,
      "duration": 2.92
    },
    {
      "lang": "en",
      "text": "details but you can run smaller versions",
      "offset": 12024.84,
      "duration": 3.439
    },
    {
      "lang": "en",
      "text": "that have been distilled and then at",
      "offset": 12026.68,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "even lower precision and then you can",
      "offset": 12028.279,
      "duration": 4.92
    },
    {
      "lang": "en",
      "text": "fit them on your uh computer and so you",
      "offset": 12029.88,
      "duration": 5.359
    },
    {
      "lang": "en",
      "text": "can actually run pretty okay models on",
      "offset": 12033.199,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "your laptop and my favorite I think",
      "offset": 12035.239,
      "duration": 4.481
    },
    {
      "lang": "en",
      "text": "place I go to usually is LM studio uh",
      "offset": 12037.439,
      "duration": 4.641
    },
    {
      "lang": "en",
      "text": "which is basically an app you can get",
      "offset": 12039.72,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "and I think it kind of actually looks",
      "offset": 12042.08,
      "duration": 3.399
    },
    {
      "lang": "en",
      "text": "really ugly and it's I don't like that",
      "offset": 12043.56,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "it shows you all these models that are",
      "offset": 12045.479,
      "duration": 2.76
    },
    {
      "lang": "en",
      "text": "basically not that useful like everyone",
      "offset": 12046.76,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "just wants to run deep seek so I don't",
      "offset": 12048.239,
      "duration": 3.16
    },
    {
      "lang": "en",
      "text": "know why they give you these 500",
      "offset": 12049.8,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "different types of models they're really",
      "offset": 12051.399,
      "duration": 2.88
    },
    {
      "lang": "en",
      "text": "complicated to search for and you have",
      "offset": 12053,
      "duration": 3.319
    },
    {
      "lang": "en",
      "text": "to choose different distillations and",
      "offset": 12054.279,
      "duration": 4.12
    },
    {
      "lang": "en",
      "text": "different uh precisions and it's all",
      "offset": 12056.319,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "really confusing but once you actually",
      "offset": 12058.399,
      "duration": 2.88
    },
    {
      "lang": "en",
      "text": "understand how it works and that's a",
      "offset": 12060.319,
      "duration": 2.561
    },
    {
      "lang": "en",
      "text": "whole separate video then you can",
      "offset": 12061.279,
      "duration": 3.16
    },
    {
      "lang": "en",
      "text": "actually load up a model like here I",
      "offset": 12062.88,
      "duration": 5.399
    },
    {
      "lang": "en",
      "text": "loaded up a llama 3 uh2 instruct 1",
      "offset": 12064.439,
      "duration": 7.081
    },
    {
      "lang": "en",
      "text": "billion and um you can just talk to it",
      "offset": 12068.279,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "so I ask for Pelican jokes and I can ask",
      "offset": 12071.52,
      "duration": 4.28
    },
    {
      "lang": "en",
      "text": "for another one and it gives me another",
      "offset": 12074.279,
      "duration": 4.561
    },
    {
      "lang": "en",
      "text": "one Etc all of this that happens here is",
      "offset": 12075.8,
      "duration": 5
    },
    {
      "lang": "en",
      "text": "locally on your computer so we're not",
      "offset": 12078.84,
      "duration": 3.559
    },
    {
      "lang": "en",
      "text": "actually going to anywhere anyone else",
      "offset": 12080.8,
      "duration": 3.479
    },
    {
      "lang": "en",
      "text": "this is running on the GPU on the",
      "offset": 12082.399,
      "duration": 4.561
    },
    {
      "lang": "en",
      "text": "MacBook Pro so that's very nice and you",
      "offset": 12084.279,
      "duration": 4.04
    },
    {
      "lang": "en",
      "text": "can then eject the model when you're",
      "offset": 12086.96,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "done and that frees up the ram so LM",
      "offset": 12088.319,
      "duration": 4.761
    },
    {
      "lang": "en",
      "text": "studio is probably like my favorite one",
      "offset": 12091.359,
      "duration": 3.08
    },
    {
      "lang": "en",
      "text": "even though I don't I think it's got a",
      "offset": 12093.08,
      "duration": 3.159
    },
    {
      "lang": "en",
      "text": "lot of uiux issues and it's really",
      "offset": 12094.439,
      "duration": 4.84
    },
    {
      "lang": "en",
      "text": "geared towards uh professionals almost",
      "offset": 12096.239,
      "duration": 4.361
    },
    {
      "lang": "en",
      "text": "uh but if you watch some videos on",
      "offset": 12099.279,
      "duration": 2.681
    },
    {
      "lang": "en",
      "text": "YouTube I think you can figure out how",
      "offset": 12100.6,
      "duration": 2.799
    },
    {
      "lang": "en",
      "text": "to how to use this",
      "offset": 12101.96,
      "duration": 3.88
    },
    {
      "lang": "en",
      "text": "interface uh so those are a few words on",
      "offset": 12103.399,
      "duration": 4.281
    },
    {
      "lang": "en",
      "text": "where to find them so let me now loop",
      "offset": 12105.84,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "back around to where we started the",
      "offset": 12107.68,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "question was when we go to chashi",
      "offset": 12109.52,
      "duration": 4.2
    },
    {
      "lang": "en",
      "text": "pta.com and we enter some kind of a",
      "offset": 12110.8,
      "duration": 6.8
    },
    {
      "lang": "en",
      "text": "query and we hit go what exactly is",
      "offset": 12113.72,
      "duration": 6.2
    },
    {
      "lang": "en",
      "text": "happening here what are we seeing what",
      "offset": 12117.6,
      "duration": 5.599
    },
    {
      "lang": "en",
      "text": "are we talking to how does this work and",
      "offset": 12119.92,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "I hope that this video gave you some",
      "offset": 12123.199,
      "duration": 2.881
    },
    {
      "lang": "en",
      "text": "appreciation for some of the under the",
      "offset": 12124.72,
      "duration": 3.559
    },
    {
      "lang": "en",
      "text": "hood details of how these models are",
      "offset": 12126.08,
      "duration": 4.239
    },
    {
      "lang": "en",
      "text": "trained and what this is that is coming",
      "offset": 12128.279,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "back so in particular we now know that",
      "offset": 12130.319,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "your query is taken and is first chopped",
      "offset": 12132.439,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "up into tokens so we go to to tick",
      "offset": 12135.359,
      "duration": 5.681
    },
    {
      "lang": "en",
      "text": "tokenizer and here where is the place in",
      "offset": 12138.199,
      "duration": 6.28
    },
    {
      "lang": "en",
      "text": "the in the um sort of format that is for",
      "offset": 12141.04,
      "duration": 6.76
    },
    {
      "lang": "en",
      "text": "the user query we basically put in our",
      "offset": 12144.479,
      "duration": 6.561
    },
    {
      "lang": "en",
      "text": "query right there so our query goes into",
      "offset": 12147.8,
      "duration": 4.92
    },
    {
      "lang": "en",
      "text": "what we discussed here is the",
      "offset": 12151.04,
      "duration": 3.8
    },
    {
      "lang": "en",
      "text": "conversation protocol format which is",
      "offset": 12152.72,
      "duration": 4.04
    },
    {
      "lang": "en",
      "text": "this way that we maintain conversation",
      "offset": 12154.84,
      "duration": 4.76
    },
    {
      "lang": "en",
      "text": "objects so this gets inserted there and",
      "offset": 12156.76,
      "duration": 4.2
    },
    {
      "lang": "en",
      "text": "then this whole thing ends up being just",
      "offset": 12159.6,
      "duration": 3.48
    },
    {
      "lang": "en",
      "text": "a token sequence a onedimensional token",
      "offset": 12160.96,
      "duration": 5.08
    },
    {
      "lang": "en",
      "text": "sequence under the hood so Chachi PT saw",
      "offset": 12163.08,
      "duration": 5.239
    },
    {
      "lang": "en",
      "text": "this token sequence and then when we hit",
      "offset": 12166.04,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "go it basically continues appending",
      "offset": 12168.319,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "tokens into this list it continues the",
      "offset": 12170.84,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "sequence it acts like a token",
      "offset": 12173.439,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "autocomplete so in particular it gave us",
      "offset": 12175,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "this response so we can basically just",
      "offset": 12177.52,
      "duration": 4.6
    },
    {
      "lang": "en",
      "text": "put it here and we see the tokens that",
      "offset": 12180.04,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "it continued uh these are the tokens",
      "offset": 12182.12,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "that it continued with",
      "offset": 12184.359,
      "duration": 4.12
    },
    {
      "lang": "en",
      "text": "roughly now the question",
      "offset": 12186.04,
      "duration": 4.76
    },
    {
      "lang": "en",
      "text": "becomes okay why are these the tokens",
      "offset": 12188.479,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "that the model responded with what are",
      "offset": 12190.8,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "these tokens where are they coming from",
      "offset": 12192.8,
      "duration": 4.28
    },
    {
      "lang": "en",
      "text": "uh what are we talking to and how do we",
      "offset": 12194.64,
      "duration": 4.759
    },
    {
      "lang": "en",
      "text": "program this system and so that's where",
      "offset": 12197.08,
      "duration": 4.359
    },
    {
      "lang": "en",
      "text": "we shifted gears and we talked about the",
      "offset": 12199.399,
      "duration": 4.601
    },
    {
      "lang": "en",
      "text": "under thehood pieces of it so the first",
      "offset": 12201.439,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "stage of this process and there are",
      "offset": 12204,
      "duration": 3.399
    },
    {
      "lang": "en",
      "text": "three stages is the pre-training stage",
      "offset": 12205.52,
      "duration": 3.4
    },
    {
      "lang": "en",
      "text": "which fundamentally has to do with just",
      "offset": 12207.399,
      "duration": 3.521
    },
    {
      "lang": "en",
      "text": "knowledge acquisition from the internet",
      "offset": 12208.92,
      "duration": 4.04
    },
    {
      "lang": "en",
      "text": "into the parameters of this neural",
      "offset": 12210.92,
      "duration": 4.519
    },
    {
      "lang": "en",
      "text": "network and so the neural net",
      "offset": 12212.96,
      "duration": 4.12
    },
    {
      "lang": "en",
      "text": "internalizes a lot of Knowledge from the",
      "offset": 12215.439,
      "duration": 3.641
    },
    {
      "lang": "en",
      "text": "internet but where the personality",
      "offset": 12217.08,
      "duration": 3.96
    },
    {
      "lang": "en",
      "text": "really comes in is in the process of",
      "offset": 12219.08,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "supervised fine-tuning here and so what",
      "offset": 12221.04,
      "duration": 5.8
    },
    {
      "lang": "en",
      "text": "what happens here is that basically the",
      "offset": 12224.6,
      "duration": 4.799
    },
    {
      "lang": "en",
      "text": "a company like openai will curate a",
      "offset": 12226.84,
      "duration": 4.439
    },
    {
      "lang": "en",
      "text": "large data set of conversations like say",
      "offset": 12229.399,
      "duration": 3.641
    },
    {
      "lang": "en",
      "text": "1 million conversation across very",
      "offset": 12231.279,
      "duration": 4.321
    },
    {
      "lang": "en",
      "text": "diverse topics and there will be",
      "offset": 12233.04,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "conversations between a human and an",
      "offset": 12235.6,
      "duration": 3.879
    },
    {
      "lang": "en",
      "text": "assistant and even though there's a lot",
      "offset": 12237.52,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "of synthetic data generation used",
      "offset": 12239.479,
      "duration": 3.281
    },
    {
      "lang": "en",
      "text": "throughout this entire process and a lot",
      "offset": 12241.04,
      "duration": 4.359
    },
    {
      "lang": "en",
      "text": "of llm help and so on fundamentally this",
      "offset": 12242.76,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "is a human data curation task with lots",
      "offset": 12245.399,
      "duration": 4.84
    },
    {
      "lang": "en",
      "text": "of humans involved and in particular",
      "offset": 12248.04,
      "duration": 4.359
    },
    {
      "lang": "en",
      "text": "these humans are data labelers hired by",
      "offset": 12250.239,
      "duration": 3.801
    },
    {
      "lang": "en",
      "text": "open AI who are given labeling",
      "offset": 12252.399,
      "duration": 4.121
    },
    {
      "lang": "en",
      "text": "instructions that they learn and they",
      "offset": 12254.04,
      "duration": 4.359
    },
    {
      "lang": "en",
      "text": "task is to create ideal assistant",
      "offset": 12256.52,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "responses for any arbitrary prompts so",
      "offset": 12258.399,
      "duration": 5.84
    },
    {
      "lang": "en",
      "text": "they are teaching the neural network by",
      "offset": 12261.16,
      "duration": 6.279
    },
    {
      "lang": "en",
      "text": "example how to respond to",
      "offset": 12264.239,
      "duration": 5.721
    },
    {
      "lang": "en",
      "text": "prompts so what is the way to think",
      "offset": 12267.439,
      "duration": 5.281
    },
    {
      "lang": "en",
      "text": "about what came back here like what is",
      "offset": 12269.96,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "this well I think the right way to think",
      "offset": 12272.72,
      "duration": 4.44
    },
    {
      "lang": "en",
      "text": "about it is that this is the neural",
      "offset": 12274.92,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "network simulation of a data labeler at",
      "offset": 12277.16,
      "duration": 7.239
    },
    {
      "lang": "en",
      "text": "openai so it's as if I gave this query",
      "offset": 12280.6,
      "duration": 6.879
    },
    {
      "lang": "en",
      "text": "to a data Li open and this data labeler",
      "offset": 12284.399,
      "duration": 4.361
    },
    {
      "lang": "en",
      "text": "first reads all of the labeling",
      "offset": 12287.479,
      "duration": 3.561
    },
    {
      "lang": "en",
      "text": "instructions from open Ai and then",
      "offset": 12288.76,
      "duration": 4.719
    },
    {
      "lang": "en",
      "text": "spends 2 hours writing up the ideal",
      "offset": 12291.04,
      "duration": 6.12
    },
    {
      "lang": "en",
      "text": "assistant response to this query and uh",
      "offset": 12293.479,
      "duration": 6.321
    },
    {
      "lang": "en",
      "text": "giving it to me now we're not actually",
      "offset": 12297.16,
      "duration": 3.96
    },
    {
      "lang": "en",
      "text": "doing that right because we didn't wait",
      "offset": 12299.8,
      "duration": 3.16
    },
    {
      "lang": "en",
      "text": "two hours so what we're getting here is",
      "offset": 12301.12,
      "duration": 4.119
    },
    {
      "lang": "en",
      "text": "a neural network simulation of that",
      "offset": 12302.96,
      "duration": 5.16
    },
    {
      "lang": "en",
      "text": "process and we have to keep in mind that",
      "offset": 12305.239,
      "duration": 4.841
    },
    {
      "lang": "en",
      "text": "these neural networks don't function",
      "offset": 12308.12,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "like human brains do they are different",
      "offset": 12310.08,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "what's easy or hard for them is",
      "offset": 12312.439,
      "duration": 3.161
    },
    {
      "lang": "en",
      "text": "different from what's easy or hard for",
      "offset": 12313.92,
      "duration": 3.6
    },
    {
      "lang": "en",
      "text": "humans and so we really are just getting",
      "offset": 12315.6,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "a simulation so here I shown you this is",
      "offset": 12317.52,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "a token stream and this is fundamentally",
      "offset": 12320.8,
      "duration": 3.96
    },
    {
      "lang": "en",
      "text": "the neural network with a bunch of",
      "offset": 12323.12,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "activations and neurons in between this",
      "offset": 12324.76,
      "duration": 4.2
    },
    {
      "lang": "en",
      "text": "is a fixed mathematical expression that",
      "offset": 12326.64,
      "duration": 6.12
    },
    {
      "lang": "en",
      "text": "mixes inputs from tokens with parameters",
      "offset": 12328.96,
      "duration": 6.6
    },
    {
      "lang": "en",
      "text": "of the model and they get mixed up and",
      "offset": 12332.76,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "get you the next token in a sequence but",
      "offset": 12335.56,
      "duration": 3.679
    },
    {
      "lang": "en",
      "text": "this is a finite amount of compute that",
      "offset": 12337.56,
      "duration": 4.04
    },
    {
      "lang": "en",
      "text": "happens for every single token and so",
      "offset": 12339.239,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "this is some kind of a lossy simulation",
      "offset": 12341.6,
      "duration": 4.799
    },
    {
      "lang": "en",
      "text": "of a human that is kind of like",
      "offset": 12344.199,
      "duration": 5
    },
    {
      "lang": "en",
      "text": "restricted in this way and so whatever",
      "offset": 12346.399,
      "duration": 3.88
    },
    {
      "lang": "en",
      "text": "the humans",
      "offset": 12349.199,
      "duration": 3.16
    },
    {
      "lang": "en",
      "text": "write the language model is kind of",
      "offset": 12350.279,
      "duration": 4.881
    },
    {
      "lang": "en",
      "text": "imitating on this token level with only",
      "offset": 12352.359,
      "duration": 5.92
    },
    {
      "lang": "en",
      "text": "this this specific computation for every",
      "offset": 12355.16,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "single token and",
      "offset": 12358.279,
      "duration": 5.241
    },
    {
      "lang": "en",
      "text": "sequence we also saw that as a result of",
      "offset": 12360.84,
      "duration": 5
    },
    {
      "lang": "en",
      "text": "this and the cognitive differences the",
      "offset": 12363.52,
      "duration": 4.839
    },
    {
      "lang": "en",
      "text": "models will suffer in a variety of ways",
      "offset": 12365.84,
      "duration": 4.2
    },
    {
      "lang": "en",
      "text": "and uh you have to be very careful with",
      "offset": 12368.359,
      "duration": 3.401
    },
    {
      "lang": "en",
      "text": "their use so for example we saw that",
      "offset": 12370.04,
      "duration": 4.04
    },
    {
      "lang": "en",
      "text": "they will suffer from hallucinations and",
      "offset": 12371.76,
      "duration": 4.8
    },
    {
      "lang": "en",
      "text": "they also we have the sense of a Swiss",
      "offset": 12374.08,
      "duration": 4.68
    },
    {
      "lang": "en",
      "text": "model of the LM capabilities where",
      "offset": 12376.56,
      "duration": 3.96
    },
    {
      "lang": "en",
      "text": "basically there's like holes in the",
      "offset": 12378.76,
      "duration": 3.96
    },
    {
      "lang": "en",
      "text": "cheese sometimes the models will just",
      "offset": 12380.52,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "arbitrarily like do something dumb uh so",
      "offset": 12382.72,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "even though they're doing lots of",
      "offset": 12385.56,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "magical stuff sometimes they just can't",
      "offset": 12386.64,
      "duration": 3.88
    },
    {
      "lang": "en",
      "text": "so maybe you're not giving them enough",
      "offset": 12388.92,
      "duration": 3.399
    },
    {
      "lang": "en",
      "text": "tokens to think and maybe they're going",
      "offset": 12390.52,
      "duration": 3
    },
    {
      "lang": "en",
      "text": "to just make stuff up because they're",
      "offset": 12392.319,
      "duration": 3.561
    },
    {
      "lang": "en",
      "text": "mental arithmetic breaks uh maybe they",
      "offset": 12393.52,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "are suddenly unable to count number of",
      "offset": 12395.88,
      "duration": 4.76
    },
    {
      "lang": "en",
      "text": "letters um or maybe they're unable to",
      "offset": 12398,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "tell you that 911 9.11 is smaller than",
      "offset": 12400.64,
      "duration": 5.799
    },
    {
      "lang": "en",
      "text": "9.9 and it looks kind of dumb and so so",
      "offset": 12403.68,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "it's a Swiss cheese capability and we",
      "offset": 12406.439,
      "duration": 3.161
    },
    {
      "lang": "en",
      "text": "have to be careful with that and we saw",
      "offset": 12408,
      "duration": 2.84
    },
    {
      "lang": "en",
      "text": "the reasons for",
      "offset": 12409.6,
      "duration": 4.12
    },
    {
      "lang": "en",
      "text": "that but fundamentally this is how we",
      "offset": 12410.84,
      "duration": 5.479
    },
    {
      "lang": "en",
      "text": "think of what came back it's again a",
      "offset": 12413.72,
      "duration": 7.2
    },
    {
      "lang": "en",
      "text": "simulation of this neural network of a",
      "offset": 12416.319,
      "duration": 6.92
    },
    {
      "lang": "en",
      "text": "human data labeler following the",
      "offset": 12420.92,
      "duration": 5.24
    },
    {
      "lang": "en",
      "text": "labeling instructions at open a so",
      "offset": 12423.239,
      "duration": 6.04
    },
    {
      "lang": "en",
      "text": "that's what we're getting back now I do",
      "offset": 12426.16,
      "duration": 5.039
    },
    {
      "lang": "en",
      "text": "think that the uh things change a little",
      "offset": 12429.279,
      "duration": 4.521
    },
    {
      "lang": "en",
      "text": "bit when you actually go and reach for",
      "offset": 12431.199,
      "duration": 6.441
    },
    {
      "lang": "en",
      "text": "one of the thinking models like o03 mini",
      "offset": 12433.8,
      "duration": 6.599
    },
    {
      "lang": "en",
      "text": "and the reason for that is that GPT",
      "offset": 12437.64,
      "duration": 5.4
    },
    {
      "lang": "en",
      "text": "40 basically doesn't do reinforcement",
      "offset": 12440.399,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "learning it does do rhf but I've told",
      "offset": 12443.04,
      "duration": 5.96
    },
    {
      "lang": "en",
      "text": "you that rhf is not RL there's no",
      "offset": 12446.399,
      "duration": 4.761
    },
    {
      "lang": "en",
      "text": "there's no uh time for magic in there",
      "offset": 12449,
      "duration": 4.04
    },
    {
      "lang": "en",
      "text": "it's just a little bit of a fine-tuning",
      "offset": 12451.16,
      "duration": 3.96
    },
    {
      "lang": "en",
      "text": "is the way to look at it but these",
      "offset": 12453.04,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "thinking models they do use RL so they",
      "offset": 12455.12,
      "duration": 6.119
    },
    {
      "lang": "en",
      "text": "go through this third state stage of",
      "offset": 12458.08,
      "duration": 5.96
    },
    {
      "lang": "en",
      "text": "perfecting their thinking process and",
      "offset": 12461.239,
      "duration": 4.761
    },
    {
      "lang": "en",
      "text": "discovering new thinking strategies and",
      "offset": 12464.04,
      "duration": 2.92
    },
    {
      "lang": "en",
      "text": "uh",
      "offset": 12466,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "solutions to problem solving that look a",
      "offset": 12466.96,
      "duration": 4.359
    },
    {
      "lang": "en",
      "text": "little bit like your internal monologue",
      "offset": 12469.92,
      "duration": 3.439
    },
    {
      "lang": "en",
      "text": "in your head and they practice that on a",
      "offset": 12471.319,
      "duration": 3.88
    },
    {
      "lang": "en",
      "text": "large collection of practice problems",
      "offset": 12473.359,
      "duration": 4.12
    },
    {
      "lang": "en",
      "text": "that companies like openi create and",
      "offset": 12475.199,
      "duration": 5.361
    },
    {
      "lang": "en",
      "text": "curate and um then make available to the",
      "offset": 12477.479,
      "duration": 5.281
    },
    {
      "lang": "en",
      "text": "LMS so when I come here and I talked to",
      "offset": 12480.56,
      "duration": 5.24
    },
    {
      "lang": "en",
      "text": "a thinking model and I put in this",
      "offset": 12482.76,
      "duration": 5.16
    },
    {
      "lang": "en",
      "text": "question what we're seeing here is not",
      "offset": 12485.8,
      "duration": 3.439
    },
    {
      "lang": "en",
      "text": "anymore just the straightforward",
      "offset": 12487.92,
      "duration": 3.519
    },
    {
      "lang": "en",
      "text": "simulation of a human data labeler like",
      "offset": 12489.239,
      "duration": 4.761
    },
    {
      "lang": "en",
      "text": "this is actually kind of new unique and",
      "offset": 12491.439,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "interesting um and of course open is not",
      "offset": 12494,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "showing us the under thehood thinking",
      "offset": 12496.399,
      "duration": 3.96
    },
    {
      "lang": "en",
      "text": "and the chains of thought that are",
      "offset": 12498.96,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "underlying the reasoning here but we",
      "offset": 12500.359,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "know that such a thing exists and this",
      "offset": 12503.04,
      "duration": 3.279
    },
    {
      "lang": "en",
      "text": "is a summary of it and what we're",
      "offset": 12504.52,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "getting here is actually not just an",
      "offset": 12506.319,
      "duration": 3.361
    },
    {
      "lang": "en",
      "text": "imitation of a human data labeler it's",
      "offset": 12507.88,
      "duration": 3.08
    },
    {
      "lang": "en",
      "text": "actually something that is kind of new",
      "offset": 12509.68,
      "duration": 2.519
    },
    {
      "lang": "en",
      "text": "and interesting and exciting in the",
      "offset": 12510.96,
      "duration": 4.359
    },
    {
      "lang": "en",
      "text": "sense that it is a function of thinking",
      "offset": 12512.199,
      "duration": 5.08
    },
    {
      "lang": "en",
      "text": "that was emergent in a simulation it's",
      "offset": 12515.319,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "not just imitating human data labeler it",
      "offset": 12517.279,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "comes from this reinforcement learning",
      "offset": 12519.479,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "process and so here we're of course not",
      "offset": 12521.279,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "giving it a chance to shine because this",
      "offset": 12523.479,
      "duration": 3.281
    },
    {
      "lang": "en",
      "text": "is not a mathematical or a reasoning",
      "offset": 12525.199,
      "duration": 3.561
    },
    {
      "lang": "en",
      "text": "problem this is just some kind of a sort",
      "offset": 12526.76,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "of creative writing problem roughly",
      "offset": 12528.76,
      "duration": 5.84
    },
    {
      "lang": "en",
      "text": "speaking and I think it's um it's a a",
      "offset": 12530.52,
      "duration": 7.08
    },
    {
      "lang": "en",
      "text": "question an open question as to whether",
      "offset": 12534.6,
      "duration": 4.719
    },
    {
      "lang": "en",
      "text": "the thinking strategies that are",
      "offset": 12537.6,
      "duration": 4.799
    },
    {
      "lang": "en",
      "text": "developed inside verifiable domains",
      "offset": 12539.319,
      "duration": 6.521
    },
    {
      "lang": "en",
      "text": "transfer and are generalizable to other",
      "offset": 12542.399,
      "duration": 5.401
    },
    {
      "lang": "en",
      "text": "domains that are unverifiable such as",
      "offset": 12545.84,
      "duration": 4.04
    },
    {
      "lang": "en",
      "text": "create writing the extent to which that",
      "offset": 12547.8,
      "duration": 4.36
    },
    {
      "lang": "en",
      "text": "transfer happens is unknown in the field",
      "offset": 12549.88,
      "duration": 4.519
    },
    {
      "lang": "en",
      "text": "I would say so we're not sure if we are",
      "offset": 12552.16,
      "duration": 3.96
    },
    {
      "lang": "en",
      "text": "able to do RL on everything that is very",
      "offset": 12554.399,
      "duration": 3.8
    },
    {
      "lang": "en",
      "text": "verifiable and see the benefits of that",
      "offset": 12556.12,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "on things that are unverifiable like",
      "offset": 12558.199,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "this prompt so that's an open question",
      "offset": 12560.04,
      "duration": 3.8
    },
    {
      "lang": "en",
      "text": "the other thing that's interesting is",
      "offset": 12562.439,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "that this reinforcement learning here is",
      "offset": 12563.84,
      "duration": 5.639
    },
    {
      "lang": "en",
      "text": "still like way too new primordial and",
      "offset": 12566.279,
      "duration": 5.481
    },
    {
      "lang": "en",
      "text": "nent so we're just seeing like the",
      "offset": 12569.479,
      "duration": 4.681
    },
    {
      "lang": "en",
      "text": "beginnings of the hints of greatness uh",
      "offset": 12571.76,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "in the reasoning problems we're seeing",
      "offset": 12574.16,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "something that is in principle capable",
      "offset": 12576.16,
      "duration": 4.199
    },
    {
      "lang": "en",
      "text": "of something like the equivalent of move",
      "offset": 12578.16,
      "duration": 6.239
    },
    {
      "lang": "en",
      "text": "37 but not in the game of Go but in open",
      "offset": 12580.359,
      "duration": 6.12
    },
    {
      "lang": "en",
      "text": "domain thinking and problem solving in",
      "offset": 12584.399,
      "duration": 4.441
    },
    {
      "lang": "en",
      "text": "principle this Paradigm is capable of",
      "offset": 12586.479,
      "duration": 3.641
    },
    {
      "lang": "en",
      "text": "doing something really cool new and",
      "offset": 12588.84,
      "duration": 3.8
    },
    {
      "lang": "en",
      "text": "exciting something even that no human",
      "offset": 12590.12,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "has thought of before in principle these",
      "offset": 12592.64,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "models are capable of analogies no human",
      "offset": 12594.84,
      "duration": 4.12
    },
    {
      "lang": "en",
      "text": "has had so I think it's incredibly",
      "offset": 12596.72,
      "duration": 3.96
    },
    {
      "lang": "en",
      "text": "exciting that these models exist but",
      "offset": 12598.96,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "again it's very early and these are",
      "offset": 12600.68,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "primordial models for now um and they",
      "offset": 12602.08,
      "duration": 4.72
    },
    {
      "lang": "en",
      "text": "will mostly shine in domains that are",
      "offset": 12605.08,
      "duration": 5.319
    },
    {
      "lang": "en",
      "text": "verifiable like math en code Etc so very",
      "offset": 12606.8,
      "duration": 5.16
    },
    {
      "lang": "en",
      "text": "interesting to play with and think about",
      "offset": 12610.399,
      "duration": 2.281
    },
    {
      "lang": "en",
      "text": "and",
      "offset": 12611.96,
      "duration": 4.6
    },
    {
      "lang": "en",
      "text": "use and then that's roughly it um um I",
      "offset": 12612.68,
      "duration": 5.719
    },
    {
      "lang": "en",
      "text": "would say those are the broad Strokes of",
      "offset": 12616.56,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "what's available right now I will say",
      "offset": 12618.399,
      "duration": 4.601
    },
    {
      "lang": "en",
      "text": "that overall it is an extremely exciting",
      "offset": 12620.399,
      "duration": 3.8
    },
    {
      "lang": "en",
      "text": "time to be in the",
      "offset": 12623,
      "duration": 3.439
    },
    {
      "lang": "en",
      "text": "field personally I use these models all",
      "offset": 12624.199,
      "duration": 4.521
    },
    {
      "lang": "en",
      "text": "the time daily uh tens or hundreds of",
      "offset": 12626.439,
      "duration": 3.641
    },
    {
      "lang": "en",
      "text": "times because they dramatically",
      "offset": 12628.72,
      "duration": 2.92
    },
    {
      "lang": "en",
      "text": "accelerate my work I think a lot of",
      "offset": 12630.08,
      "duration": 3.199
    },
    {
      "lang": "en",
      "text": "people see the same thing I think we're",
      "offset": 12631.64,
      "duration": 2.88
    },
    {
      "lang": "en",
      "text": "going to see a huge amount of wealth",
      "offset": 12633.279,
      "duration": 3.841
    },
    {
      "lang": "en",
      "text": "creation as a result of these models be",
      "offset": 12634.52,
      "duration": 6.12
    },
    {
      "lang": "en",
      "text": "aware of some of their shortcomings even",
      "offset": 12637.12,
      "duration": 5.119
    },
    {
      "lang": "en",
      "text": "with RL models they're going to suffer",
      "offset": 12640.64,
      "duration": 3.88
    },
    {
      "lang": "en",
      "text": "from some of these use it as a tool in a",
      "offset": 12642.239,
      "duration": 5.601
    },
    {
      "lang": "en",
      "text": "toolbox don't trust it fully because",
      "offset": 12644.52,
      "duration": 5.16
    },
    {
      "lang": "en",
      "text": "they will randomly do dumb things they",
      "offset": 12647.84,
      "duration": 3.519
    },
    {
      "lang": "en",
      "text": "will randomly hallucinate they will",
      "offset": 12649.68,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "randomly skip over some mental",
      "offset": 12651.359,
      "duration": 3.641
    },
    {
      "lang": "en",
      "text": "arithmetic and not get it right um they",
      "offset": 12652.72,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "randomly can't count or something like",
      "offset": 12655,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "that so use them as tools in the toolbox",
      "offset": 12656.64,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "check their work and own the product of",
      "offset": 12658.76,
      "duration": 4.36
    },
    {
      "lang": "en",
      "text": "your work but use them for inspiration",
      "offset": 12660.56,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "for first draft uh ask them questions",
      "offset": 12663.12,
      "duration": 5.52
    },
    {
      "lang": "en",
      "text": "but always check and verify and you will",
      "offset": 12666,
      "duration": 4.6
    },
    {
      "lang": "en",
      "text": "be very successful in your work if you",
      "offset": 12668.64,
      "duration": 5.16
    },
    {
      "lang": "en",
      "text": "do so uh so I hope this video was useful",
      "offset": 12670.6,
      "duration": 4.799
    },
    {
      "lang": "en",
      "text": "and interesting to you I hope you had it",
      "offset": 12673.8,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "fun and uh it's already like very long",
      "offset": 12675.399,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "so I apologize for that but I hope it",
      "offset": 12677.72,
      "duration": 6.599
    },
    {
      "lang": "en",
      "text": "was useful and yeah I will see you later",
      "offset": 12679.479,
      "duration": 4.84
    }
  ],
  "cleanText": null,
  "dumpedAt": "2025-07-21T18:43:24.941Z"
}