{
  "episodeId": "64lXQP6cs5M",
  "channelSlug": "@dwarkeshpatel",
  "title": "How Does Claude 4 Think? – Sholto Douglas & Trenton Bricken",
  "publishedAt": "2025-05-22T21:06:29.000Z",
  "rawLines": [
    {
      "lang": "en",
      "text": "Okay.",
      "offset": 0.24,
      "duration": 0.46
    },
    {
      "lang": "en",
      "text": "I'm joined again by my friends,\nSholto Bricken... Wait",
      "offset": 0.7,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "Did I do this last time?",
      "offset": 6.89,
      "duration": 0.89
    },
    {
      "lang": "en",
      "text": "You did the same thing.",
      "offset": 7.78,
      "duration": 0.898
    },
    {
      "lang": "en",
      "text": "No, no, you named us differently,\nbut we didn't have Sholto",
      "offset": 8.678,
      "duration": 2.412
    },
    {
      "lang": "en",
      "text": "Bricken and Trenton Douglas.",
      "offset": 11.43,
      "duration": 1.965
    },
    {
      "lang": "en",
      "text": "You swapped us.",
      "offset": 13.395,
      "duration": 0.915
    },
    {
      "lang": "en",
      "text": "Sholto Douglas and Trenton Bricken,",
      "offset": 14.31,
      "duration": 1.819
    },
    {
      "lang": "en",
      "text": "who are now both at Anthropic.",
      "offset": 18.42,
      "duration": 1.7
    },
    {
      "lang": "en",
      "text": "Yeah.",
      "offset": 20.16,
      "duration": 0.31
    },
    {
      "lang": "en",
      "text": "Let's go.",
      "offset": 20.47,
      "duration": 1.939
    },
    {
      "lang": "en",
      "text": "Sholto is scaling RL, Trenton's still\nworking on mechanistic interpretability.",
      "offset": 23.38,
      "duration": 5.41
    },
    {
      "lang": "en",
      "text": "Welcome back.",
      "offset": 28.96,
      "duration": 0.6
    },
    {
      "lang": "en",
      "text": "Happy to be here.",
      "offset": 29.96,
      "duration": 0.55
    },
    {
      "lang": "en",
      "text": "Yeah, it's fun.",
      "offset": 30.58,
      "duration": 0.67
    },
    {
      "lang": "en",
      "text": "What's changed since last year?",
      "offset": 31.689,
      "duration": 1.34
    },
    {
      "lang": "en",
      "text": "We talked basically this month in 2024.",
      "offset": 33.03,
      "duration": 2.57
    },
    {
      "lang": "en",
      "text": "Yep.\nNow, we're in 2025.",
      "offset": 35.609,
      "duration": 1.24
    },
    {
      "lang": "en",
      "text": "What's happened?",
      "offset": 36.89,
      "duration": 0.58
    },
    {
      "lang": "en",
      "text": "Okay, so I think the biggest\nthing that's changed is that RL in",
      "offset": 37.55,
      "duration": 2.41
    },
    {
      "lang": "en",
      "text": "language models has finally worked.",
      "offset": 39.96,
      "duration": 1.33
    },
    {
      "lang": "en",
      "text": "We finally have proof of an\nalgorithm that can give us expert",
      "offset": 44.22,
      "duration": 3.729
    },
    {
      "lang": "en",
      "text": "human reliability and performance,\ngiven the right feedback loop.",
      "offset": 47.95,
      "duration": 3.27
    },
    {
      "lang": "en",
      "text": "I think this has only really been\nconclusively demonstrated in competitive",
      "offset": 51.349,
      "duration": 3.191
    },
    {
      "lang": "en",
      "text": "programming and math, basically.",
      "offset": 54.54,
      "duration": 1.89
    },
    {
      "lang": "en",
      "text": "Think of these two axes, one is the\nintellectual complexity of the task,",
      "offset": 58.4,
      "duration": 3.74
    },
    {
      "lang": "en",
      "text": "and the other is the time horizon at\nwhich the task is being completed on.",
      "offset": 62.14,
      "duration": 3.41
    },
    {
      "lang": "en",
      "text": "I think we have proof that we can\nreach the peaks of intellectual",
      "offset": 66.63,
      "duration": 2.39
    },
    {
      "lang": "en",
      "text": "complexity along many dimensions.",
      "offset": 69.289,
      "duration": 2.101
    },
    {
      "lang": "en",
      "text": "We haven't yet demonstrated\nlong-running agentic performance.",
      "offset": 72.76,
      "duration": 4.439
    },
    {
      "lang": "en",
      "text": "You're seeing the first stumbling steps\nof that now, and should see much more",
      "offset": 77.35,
      "duration": 4.349
    },
    {
      "lang": "en",
      "text": "conclusive evidence of that basically by\nthe end of the year, with real software",
      "offset": 81.74,
      "duration": 4.16
    },
    {
      "lang": "en",
      "text": "engineering agents doing real work.",
      "offset": 85.9,
      "duration": 1.6
    },
    {
      "lang": "en",
      "text": "I think Trenton, you're experimenting\nwith this at the moment?",
      "offset": 87.9,
      "duration": 2.67
    },
    {
      "lang": "en",
      "text": "Yeah, absolutely.",
      "offset": 90.71,
      "duration": 0.63
    },
    {
      "lang": "en",
      "text": "The most public example people could\ngo to today is ClaudePlaysPokemon.",
      "offset": 91.82,
      "duration": 2.82
    },
    {
      "lang": "en",
      "text": "Seeing it struggle is in a way kind\nof painful to watch, but each model",
      "offset": 96.86,
      "duration": 4.81
    },
    {
      "lang": "en",
      "text": "generation gets further through the game.",
      "offset": 101.67,
      "duration": 2.32
    },
    {
      "lang": "en",
      "text": "It seems more like a limitation\nof it being able to use memory",
      "offset": 105.24,
      "duration": 3.33
    },
    {
      "lang": "en",
      "text": "system than anything else.",
      "offset": 108.57,
      "duration": 1.71
    },
    {
      "lang": "en",
      "text": "I wish we had recorded\npredictions last year.",
      "offset": 111.99,
      "duration": 1.93
    },
    {
      "lang": "en",
      "text": "We definitely should this year.",
      "offset": 113.94,
      "duration": 0.93
    },
    {
      "lang": "en",
      "text": "Hold us accountable.",
      "offset": 115.73,
      "duration": 0.72
    },
    {
      "lang": "en",
      "text": "That's right.",
      "offset": 116.65,
      "duration": 0.5
    },
    {
      "lang": "en",
      "text": "Would you have said that agents would\nbe only this powerful as of last year?",
      "offset": 117.74,
      "duration": 3.87
    },
    {
      "lang": "en",
      "text": "I think this is roughly on track for where\nI expected with software engineering.",
      "offset": 121.96,
      "duration": 3.45
    },
    {
      "lang": "en",
      "text": "I think I expected them to be a\nlittle bit better at computer use.",
      "offset": 125.48,
      "duration": 2.06
    },
    {
      "lang": "en",
      "text": "But I understand all the reasons\nfor why that is, and I think",
      "offset": 128.479,
      "duration": 3.801
    },
    {
      "lang": "en",
      "text": "that's well on track to be solved.",
      "offset": 132.28,
      "duration": 1.39
    },
    {
      "lang": "en",
      "text": "It's just a sort of temporary lapse.",
      "offset": 133.67,
      "duration": 2.78
    },
    {
      "lang": "en",
      "text": "Holding me accountable for my predictions\nnext year, I really do think by the end",
      "offset": 139.429,
      "duration": 3.1
    },
    {
      "lang": "en",
      "text": "of this year to this time next year, we\nwill have software engineering agents that",
      "offset": 142.529,
      "duration": 4.741
    },
    {
      "lang": "en",
      "text": "can do close to a day's worth of work for\na junior engineer, or a couple of hours",
      "offset": 147.27,
      "duration": 6.53
    },
    {
      "lang": "en",
      "text": "of quite competent, independent work.",
      "offset": 153.8,
      "duration": 1.92
    },
    {
      "lang": "en",
      "text": "Yeah, that seems right to me.",
      "offset": 155.9,
      "duration": 1.179
    },
    {
      "lang": "en",
      "text": "I think the distribution's pretty\nwonky though, where for some tasks,",
      "offset": 157.099,
      "duration": 3.38
    },
    {
      "lang": "en",
      "text": "like boilerplate website code, these\nsorts of things, it can already bang",
      "offset": 160.729,
      "duration": 3.787
    },
    {
      "lang": "en",
      "text": "it out and save you a whole day.",
      "offset": 164.65,
      "duration": 0.92
    },
    {
      "lang": "en",
      "text": "Yeah,",
      "offset": 165.59,
      "duration": 0.5
    },
    {
      "lang": "en",
      "text": "exactly.",
      "offset": 167.85,
      "duration": 0.16
    },
    {
      "lang": "en",
      "text": "I think last year, you said that\nthe thing that was holding them back",
      "offset": 168.01,
      "duration": 2.98
    },
    {
      "lang": "en",
      "text": "was the extra nines of reliability.",
      "offset": 171.25,
      "duration": 1.869
    },
    {
      "lang": "en",
      "text": "I don't know if that's the way you\nwould still describe the way in which",
      "offset": 173.78,
      "duration": 2.489
    },
    {
      "lang": "en",
      "text": "these software agents aren't able to\ndo a full day of work, but are able",
      "offset": 176.27,
      "duration": 3.58
    },
    {
      "lang": "en",
      "text": "to help you out with a couple minutes.",
      "offset": 179.85,
      "duration": 1.57
    },
    {
      "lang": "en",
      "text": "Is it the extra nines that's really\nstopping you or is it something else?",
      "offset": 181.42,
      "duration": 3.29
    },
    {
      "lang": "en",
      "text": "I think my description there\nwas, in retrospect, probably",
      "offset": 185.12,
      "duration": 2.93
    },
    {
      "lang": "en",
      "text": "not what's limiting them.",
      "offset": 188.05,
      "duration": 1.54
    },
    {
      "lang": "en",
      "text": "I think what we're seeing now is closer\nto: lack of context, lack of ability to do",
      "offset": 190.48,
      "duration": 8.63
    },
    {
      "lang": "en",
      "text": "complex, very multi-file changes… sort of\nthe scope of the task, in some respects.",
      "offset": 199.27,
      "duration": 8.969
    },
    {
      "lang": "en",
      "text": "They can cope with high\nintellectual complexity in a focused",
      "offset": 208.7,
      "duration": 2.85
    },
    {
      "lang": "en",
      "text": "context with a scoped problem.",
      "offset": 211.55,
      "duration": 2.43
    },
    {
      "lang": "en",
      "text": "When something's a bit more amorphous\nor requires a lot of discovery and",
      "offset": 214.51,
      "duration": 2.338
    },
    {
      "lang": "en",
      "text": "iteration with the environment, with\nthis kind of stuff they struggle more.",
      "offset": 216.848,
      "duration": 2.982
    },
    {
      "lang": "en",
      "text": "Maybe the way I would define the thing\nthat's holding them back like this.",
      "offset": 222.81,
      "duration": 4.746
    },
    {
      "lang": "en",
      "text": "If you can give it a good feedback\nloop for the thing that you want it",
      "offset": 227.679,
      "duration": 2.431
    },
    {
      "lang": "en",
      "text": "to do, then it's pretty good at it.",
      "offset": 230.17,
      "duration": 3.1
    },
    {
      "lang": "en",
      "text": "If you can't, then they struggle a bit.",
      "offset": 233.309,
      "duration": 2.471
    },
    {
      "lang": "en",
      "text": "For the audience, can you say more\nabout what you mean by this feedback",
      "offset": 236.72,
      "duration": 1.82
    },
    {
      "lang": "en",
      "text": "loop if they're not aware of what's\nhappening with RL and so forth?",
      "offset": 238.54,
      "duration": 3.4
    },
    {
      "lang": "en",
      "text": "Yes, so it’s the big thing that\nreally worked over the last year.",
      "offset": 241.95,
      "duration": 3.17
    },
    {
      "lang": "en",
      "text": "Broadly, the domain is called RL from\nVerifiable Rewards, or something like",
      "offset": 247.73,
      "duration": 3.38
    },
    {
      "lang": "en",
      "text": "this, with a clean reward signal.",
      "offset": 251.11,
      "duration": 2.19
    },
    {
      "lang": "en",
      "text": "So the initial unhobbling of language\nmodels was RL from human feedback.",
      "offset": 253.64,
      "duration": 4.009
    },
    {
      "lang": "en",
      "text": "Typically, it was something like\npairwise feedback and the outputs",
      "offset": 258.969,
      "duration": 3.181
    },
    {
      "lang": "en",
      "text": "of the models became closer and\ncloser to things that humans wanted.",
      "offset": 262.15,
      "duration": 2.839
    },
    {
      "lang": "en",
      "text": "This doesn't necessarily\nimprove their performance at any",
      "offset": 265.969,
      "duration": 2.991
    },
    {
      "lang": "en",
      "text": "difficulty or problem domain.",
      "offset": 270.02,
      "duration": 1.029
    },
    {
      "lang": "en",
      "text": "Particularly, humans are actually quite\nbad judges of what a better answer is.",
      "offset": 271.409,
      "duration": 3.591
    },
    {
      "lang": "en",
      "text": "Humans have things like\nlength biases and so forth.",
      "offset": 275.27,
      "duration": 3.785
    },
    {
      "lang": "en",
      "text": "You need a signal of whether the\nmodel was correct in its output",
      "offset": 279.055,
      "duration": 4.144
    },
    {
      "lang": "en",
      "text": "that is quite true, let’s say.",
      "offset": 283.63,
      "duration": 4.06
    },
    {
      "lang": "en",
      "text": "Things like the correct answer to a\nmath problem, or passing unit tests.",
      "offset": 288.96,
      "duration": 2.82
    },
    {
      "lang": "en",
      "text": "These are the examples of a\nreward signal that's very clean.",
      "offset": 293.24,
      "duration": 3.19
    },
    {
      "lang": "en",
      "text": "Even these can be hacked, by the way.",
      "offset": 296.73,
      "duration": 1.7
    },
    {
      "lang": "en",
      "text": "Even with unit tests, the models\nfind ways around it to hack in",
      "offset": 299.13,
      "duration": 3.589
    },
    {
      "lang": "en",
      "text": "particular values and hard code values\nof unit tests, if they can figure",
      "offset": 302.78,
      "duration": 2.78
    },
    {
      "lang": "en",
      "text": "out what the actual test is doing.",
      "offset": 305.56,
      "duration": 1.979
    },
    {
      "lang": "en",
      "text": "If they can look at the cached Python\nfiles and find what the actual test is,",
      "offset": 307.61,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "they'll try and hack their way around it.",
      "offset": 311.6,
      "duration": 1.17
    },
    {
      "lang": "en",
      "text": "These aren't perfect,\nbut they're much closer.",
      "offset": 313.49,
      "duration": 2.31
    },
    {
      "lang": "en",
      "text": "Why has it gotten so much better at\nsoftware engineering than everything else?",
      "offset": 316.16,
      "duration": 2.55
    },
    {
      "lang": "en",
      "text": "In part, because software\nengineering is very verifiable.",
      "offset": 319.349,
      "duration": 4.871
    },
    {
      "lang": "en",
      "text": "It's a domain which just naturally\nlends itself to this way.",
      "offset": 325.48,
      "duration": 2.54
    },
    {
      "lang": "en",
      "text": "Does the code pass the test?",
      "offset": 328.64,
      "duration": 1.05
    },
    {
      "lang": "en",
      "text": "Does it even run?",
      "offset": 329.71,
      "duration": 0.697
    },
    {
      "lang": "en",
      "text": "Does it compile?",
      "offset": 330.58,
      "duration": 0.66
    },
    {
      "lang": "en",
      "text": "Yeah, does it compile?",
      "offset": 331.26,
      "duration": 0.85
    },
    {
      "lang": "en",
      "text": "Does it pass the test?",
      "offset": 332.13,
      "duration": 0.86
    },
    {
      "lang": "en",
      "text": "You can go on LeetCode and run\ntests and you know whether or",
      "offset": 333.99,
      "duration": 3.06
    },
    {
      "lang": "en",
      "text": "not you got the right answer.",
      "offset": 337.05,
      "duration": 1.4
    },
    {
      "lang": "en",
      "text": "There isn't the same kind of\nthing for writing a great essay.",
      "offset": 338.61,
      "duration": 2.849
    },
    {
      "lang": "en",
      "text": "That requires...",
      "offset": 341.83,
      "duration": 0.87
    },
    {
      "lang": "en",
      "text": "The question of taste in\nthat regard is quite hard.",
      "offset": 345.2,
      "duration": 2.292
    },
    {
      "lang": "en",
      "text": "We discussed the other night\nat dinner, the Pulitzer Prize.",
      "offset": 347.66,
      "duration": 2.55
    },
    {
      "lang": "en",
      "text": "Which would come first, a Pulitzer\nPrize winning novel or a Nobel",
      "offset": 351.48,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "Prize or something like this?",
      "offset": 354.76,
      "duration": 0.85
    },
    {
      "lang": "en",
      "text": "I actually think a Nobel Prize\nis more likely than a Pulitzer",
      "offset": 355.61,
      "duration": 3.64
    },
    {
      "lang": "en",
      "text": "Prize-winning novel in some respects.",
      "offset": 359.27,
      "duration": 2.37
    },
    {
      "lang": "en",
      "text": "Because a lot of the tasks required\nin winning a Nobel Prize—or at",
      "offset": 361.68,
      "duration": 3.47
    },
    {
      "lang": "en",
      "text": "least strongly assisting in helping\nto win a Nobel Prize—have more",
      "offset": 365.15,
      "duration": 5.24
    },
    {
      "lang": "en",
      "text": "layers of verifiability built up.",
      "offset": 370.599,
      "duration": 1.88
    },
    {
      "lang": "en",
      "text": "I expect them to accelerate the\nprocess of doing Nobel Prize winning",
      "offset": 372.79,
      "duration": 4.879
    },
    {
      "lang": "en",
      "text": "work more initially than that of\nwriting Pulitzer Prize worthy novels.",
      "offset": 377.67,
      "duration": 5.97
    },
    {
      "lang": "en",
      "text": "I think if we rewind 14 months to\nwhen we recorded last time, the",
      "offset": 384.22,
      "duration": 4.18
    },
    {
      "lang": "en",
      "text": "nines of reliability was right to me.",
      "offset": 388.48,
      "duration": 2.989
    },
    {
      "lang": "en",
      "text": "We didn't have Claude Code,\nwe didn't have Deep Research.",
      "offset": 392.38,
      "duration": 3.289
    },
    {
      "lang": "en",
      "text": "All we did was use agents\nin a chatbot format.",
      "offset": 395.98,
      "duration": 2.989
    },
    {
      "lang": "en",
      "text": "Right.",
      "offset": 399,
      "duration": 0.5
    },
    {
      "lang": "en",
      "text": "Copy paste, copy paste, copy paste.",
      "offset": 400.07,
      "duration": 0.966
    },
    {
      "lang": "en",
      "text": "Totally.",
      "offset": 401.12,
      "duration": 0.5
    },
    {
      "lang": "en",
      "text": "We're very used to chat interfaces,\nwhether we're texting or using Google.",
      "offset": 402.72,
      "duration": 3.88
    },
    {
      "lang": "en",
      "text": "It's weird to think that the\nagent can actually go and fetch",
      "offset": 406.77,
      "duration": 3.57
    },
    {
      "lang": "en",
      "text": "its own context, and store its\nown facts into its memory system.",
      "offset": 410.389,
      "duration": 4.811
    },
    {
      "lang": "en",
      "text": "I still think that it's\nthe nines of reliability.",
      "offset": 416.51,
      "duration": 2.3
    },
    {
      "lang": "en",
      "text": "If you scaffold the model\ncorrectly or prompt it, it can",
      "offset": 419.76,
      "duration": 4.019
    },
    {
      "lang": "en",
      "text": "do much more sophisticated things\nthan the average user assumes.",
      "offset": 423.78,
      "duration": 2.84
    },
    {
      "lang": "en",
      "text": "One",
      "offset": 426.67,
      "duration": 0.5
    },
    {
      "lang": "en",
      "text": "of my friends, Sam Rodriques,\nwho does Future House, they've",
      "offset": 429.21,
      "duration": 3.42
    },
    {
      "lang": "en",
      "text": "discovered a new drug that they're\nin the process of patenting.",
      "offset": 432.77,
      "duration": 3.32
    },
    {
      "lang": "en",
      "text": "By the time this episode\ncomes out that will be live.",
      "offset": 436.72,
      "duration": 2.97
    },
    {
      "lang": "en",
      "text": "LSD v2?",
      "offset": 440.389,
      "duration": 0.551
    },
    {
      "lang": "en",
      "text": "Wait, is it really?",
      "offset": 442.45,
      "duration": 0.5
    },
    {
      "lang": "en",
      "text": "No, they're not making LSD.",
      "offset": 443.35,
      "duration": 3.839
    },
    {
      "lang": "en",
      "text": "But people didn't think that models\ncould be creative or do new science.",
      "offset": 447.189,
      "duration": 6.281
    },
    {
      "lang": "en",
      "text": "It does just seem like a skill issue.",
      "offset": 454.62,
      "duration": 2.76
    },
    {
      "lang": "en",
      "text": "Wait, it discovered a drug?",
      "offset": 458.82,
      "duration": 2.219
    },
    {
      "lang": "en",
      "text": "How did it?",
      "offset": 461.04,
      "duration": 1.319
    },
    {
      "lang": "en",
      "text": "Did it one-shot the molecules?",
      "offset": 462.359,
      "duration": 2.551
    },
    {
      "lang": "en",
      "text": "This was just over a conversation.",
      "offset": 464.91,
      "duration": 1.51
    },
    {
      "lang": "en",
      "text": "We'll need to refer to the full\nannouncement, but my impression is that",
      "offset": 466.42,
      "duration": 3.259
    },
    {
      "lang": "en",
      "text": "it was able to read a huge amount of\nmedical literature and brainstorm, and",
      "offset": 470.88,
      "duration": 4.55
    },
    {
      "lang": "en",
      "text": "make new connections, and then propose\nwet lab experiments that the humans did.",
      "offset": 475.48,
      "duration": 3.96
    },
    {
      "lang": "en",
      "text": "Through iteration on that, they\nverified that this new compound does",
      "offset": 480.2,
      "duration": 5.089
    },
    {
      "lang": "en",
      "text": "this thing that's really exciting.",
      "offset": 485.309,
      "duration": 1.23
    },
    {
      "lang": "en",
      "text": "Another critique I've heard is that LLMs\ncan't write creative longform books.",
      "offset": 488.109,
      "duration": 4.451
    },
    {
      "lang": "en",
      "text": "I'm aware of at least two individuals—who\nprobably want to remain anonymous—who",
      "offset": 493.1,
      "duration": 3.879
    },
    {
      "lang": "en",
      "text": "have used LLMs to write long form books.",
      "offset": 496.98,
      "duration": 2.619
    },
    {
      "lang": "en",
      "text": "I think in both cases, they're\njust very good at scaffolding",
      "offset": 499.78,
      "duration": 3.15
    },
    {
      "lang": "en",
      "text": "and prompting the model.",
      "offset": 502.93,
      "duration": 0.94
    },
    {
      "lang": "en",
      "text": "Even with the viral ChatGPT\nGeoGuessr capabilities, it's",
      "offset": 504.32,
      "duration": 5.08
    },
    {
      "lang": "en",
      "text": "insanely good at spotting what\nbeach you were on from a photo.",
      "offset": 509.84,
      "duration": 3.51
    },
    {
      "lang": "en",
      "text": "Kelsey Piper, who I think made this\nviral, their prompt is so sophisticated.",
      "offset": 514.21,
      "duration": 5.949
    },
    {
      "lang": "en",
      "text": "It's really long, and it encourages you\nto think of five different hypotheses,",
      "offset": 520.4,
      "duration": 4
    },
    {
      "lang": "en",
      "text": "and assign probabilities to them,\nand reason through the different",
      "offset": 525.33,
      "duration": 3.07
    },
    {
      "lang": "en",
      "text": "aspects of the image that matter.",
      "offset": 528.42,
      "duration": 1.519
    },
    {
      "lang": "en",
      "text": "I haven't A/B tested it, but I think\nunless you really encourage the",
      "offset": 530.41,
      "duration": 3.95
    },
    {
      "lang": "en",
      "text": "model to be this thoughtful, you\nwouldn't get the level of performance",
      "offset": 534.36,
      "duration": 2.92
    },
    {
      "lang": "en",
      "text": "that you see with that ability.",
      "offset": 537.28,
      "duration": 1.6
    },
    {
      "lang": "en",
      "text": "You're bringing up ways in which\npeople have constrained what the",
      "offset": 539.789,
      "duration": 4.581
    },
    {
      "lang": "en",
      "text": "model is outputting to get the\ngood part of the distribution.",
      "offset": 544.37,
      "duration": 2.99
    },
    {
      "lang": "en",
      "text": "One of the critiques",
      "offset": 547.82,
      "duration": 1.47
    },
    {
      "lang": "en",
      "text": "I've heard about using the success\nof models like o3 to suggest that",
      "offset": 553.679,
      "duration": 4.841
    },
    {
      "lang": "en",
      "text": "we're getting new capabilities from\nthese reasoning models, is that",
      "offset": 559.04,
      "duration": 3.789
    },
    {
      "lang": "en",
      "text": "all these capabilities were already\nbaked in the pre-training model.",
      "offset": 563.15,
      "duration": 2.55
    },
    {
      "lang": "en",
      "text": "I think there's a paper from Tsinghua\nUniversity, where they showed that if",
      "offset": 565.7,
      "duration": 5.54
    },
    {
      "lang": "en",
      "text": "you give a base model enough tries to\nanswer a question, it can still answer the",
      "offset": 571.24,
      "duration": 7.22
    },
    {
      "lang": "en",
      "text": "question as well as the reasoning model.",
      "offset": 578.46,
      "duration": 2.92
    },
    {
      "lang": "en",
      "text": "It basically just has a lower\nprobability of answering correctly.",
      "offset": 581.38,
      "duration": 2.29
    },
    {
      "lang": "en",
      "text": "You're narrowing down the\npossibilities that the model explores",
      "offset": 583.96,
      "duration": 4.099
    },
    {
      "lang": "en",
      "text": "when it's answering a question.",
      "offset": 588.07,
      "duration": 1.06
    },
    {
      "lang": "en",
      "text": "Are we actually eliciting new capabilities\nwith this RL training, or are we",
      "offset": 590.92,
      "duration": 3.689
    },
    {
      "lang": "en",
      "text": "just putting the blinders on them?",
      "offset": 594.61,
      "duration": 2.97
    },
    {
      "lang": "en",
      "text": "Right, like carving away\nthe marbles on this.",
      "offset": 597.63,
      "duration": 2.06
    },
    {
      "lang": "en",
      "text": "I think it's worth noting that\nthat paper was, I'm pretty sure,",
      "offset": 600.86,
      "duration": 2.805
    },
    {
      "lang": "en",
      "text": "on the Llama and Qwen models.",
      "offset": 603.665,
      "duration": 1.805
    },
    {
      "lang": "en",
      "text": "I'm not sure how much RL compute they\nused, but I don't think it was anywhere",
      "offset": 605.79,
      "duration": 5.419
    },
    {
      "lang": "en",
      "text": "comparable to the amount of compute\nthat was used in the base models.",
      "offset": 611.26,
      "duration": 2.42
    },
    {
      "lang": "en",
      "text": "The amount of compute that you use\nin training is a decent proxy for the",
      "offset": 614.31,
      "duration": 4.15
    },
    {
      "lang": "en",
      "text": "amount of actual raw new knowledge or\ncapabilities you're adding to a model.",
      "offset": 618.46,
      "duration": 4.939
    },
    {
      "lang": "en",
      "text": "If you look at all of DeepMind's research\nfrom RL before, RL was able to teach",
      "offset": 624.819,
      "duration": 6.141
    },
    {
      "lang": "en",
      "text": "these Go and chess playing agents new\nknowledge in excess of human-level",
      "offset": 630.969,
      "duration": 5.951
    },
    {
      "lang": "en",
      "text": "performance, just from RL signal, provided\nthe RL signal is sufficiently clean.",
      "offset": 636.92,
      "duration": 3.96
    },
    {
      "lang": "en",
      "text": "There's nothing structurally\nlimiting about the algorithm here",
      "offset": 641.23,
      "duration": 2.92
    },
    {
      "lang": "en",
      "text": "that prevents it from imbuing the\nneural net with new knowledge.",
      "offset": 644.2,
      "duration": 3.759
    },
    {
      "lang": "en",
      "text": "It's just a matter of expending\nenough compute and having the",
      "offset": 648.219,
      "duration": 2.831
    },
    {
      "lang": "en",
      "text": "right algorithm, basically.",
      "offset": 651.05,
      "duration": 1.41
    },
    {
      "lang": "en",
      "text": "Why aren't you already\nspending more compute on this?",
      "offset": 653.29,
      "duration": 1.64
    },
    {
      "lang": "en",
      "text": "I think Dario said in his blog post\na couple months ago about the export",
      "offset": 655,
      "duration": 3.342
    },
    {
      "lang": "en",
      "text": "controls thing, &quot;Ah, DeepSeek,\nwhatever. We're only spending",
      "offset": 658.342,
      "duration": 3.258
    },
    {
      "lang": "en",
      "text": "$1 million on RL,&quot; or something.",
      "offset": 661.6,
      "duration": 1.57
    },
    {
      "lang": "en",
      "text": "“We aren't in the compute limited\nregime for RL yet, but we will be",
      "offset": 664.879,
      "duration": 2.691
    },
    {
      "lang": "en",
      "text": "soon.&quot; You're spending hundreds\nof millions on the base model.",
      "offset": 667.57,
      "duration": 3.4
    },
    {
      "lang": "en",
      "text": "Why only order a million on the RL?",
      "offset": 670.97,
      "duration": 2.4
    },
    {
      "lang": "en",
      "text": "You know the parable about when you\nchoose to launch a space mission?",
      "offset": 673.72,
      "duration": 3.21
    },
    {
      "lang": "en",
      "text": "You should go further up the tech tree\nbecause if you launch later on your ship",
      "offset": 677.059,
      "duration": 6.001
    },
    {
      "lang": "en",
      "text": "will go faster and this kind of stuff?",
      "offset": 683.06,
      "duration": 1.279
    },
    {
      "lang": "en",
      "text": "I think it's quite similar to that.",
      "offset": 684.57,
      "duration": 0.79
    },
    {
      "lang": "en",
      "text": "You want to be sure that you've\nalgorithmically got the right thing,",
      "offset": 685.51,
      "duration": 3.24
    },
    {
      "lang": "en",
      "text": "and then when you bet and you do\nthe large compute spend on the",
      "offset": 688.77,
      "duration": 2.47
    },
    {
      "lang": "en",
      "text": "run, then it’ll actually pay off.",
      "offset": 691.24,
      "duration": 2.45
    },
    {
      "lang": "en",
      "text": "They'll have the right compute\nefficiencies and this kind of stuff.",
      "offset": 693.69,
      "duration": 1.83
    },
    {
      "lang": "en",
      "text": "I think RL is slightly different\nto pre-training in this regard.",
      "offset": 695.86,
      "duration": 3.429
    },
    {
      "lang": "en",
      "text": "RL can be a more iterative thing.",
      "offset": 699.78,
      "duration": 1.98
    },
    {
      "lang": "en",
      "text": "You're progressively adding\ncapabilities to the base model.",
      "offset": 701.889,
      "duration": 1.741
    },
    {
      "lang": "en",
      "text": "With pre-training, in many\nrespects, if you're halfway through",
      "offset": 703.63,
      "duration": 4.15
    },
    {
      "lang": "en",
      "text": "a run and you've messed it up,\nthen you've really messed it up.",
      "offset": 707.78,
      "duration": 3.13
    },
    {
      "lang": "en",
      "text": "I think that's the main reason why.",
      "offset": 713.83,
      "duration": 2.22
    },
    {
      "lang": "en",
      "text": "People are still figuring out\nexactly what they want it to do.",
      "offset": 716.05,
      "duration": 2.664
    },
    {
      "lang": "en",
      "text": "o1 to o3, OpenAI put in their\nblog post that it was a 10X",
      "offset": 719.089,
      "duration": 2.76
    },
    {
      "lang": "en",
      "text": "compute multiplier over o1.",
      "offset": 721.87,
      "duration": 1.37
    },
    {
      "lang": "en",
      "text": "So clearly, they bet on one level of\ncompute and they were like, &quot;Okay,",
      "offset": 724.54,
      "duration": 5.319
    },
    {
      "lang": "en",
      "text": "this seems good. Let's actually\nrelease it. Let's get it out there.&quot;",
      "offset": 729.86,
      "duration": 2.76
    },
    {
      "lang": "en",
      "text": "Then they spent the next few\nmonths increasing the amount of",
      "offset": 732.62,
      "duration": 2.053
    },
    {
      "lang": "en",
      "text": "compute that they expend on that.",
      "offset": 734.73,
      "duration": 2.81
    },
    {
      "lang": "en",
      "text": "Everyone else is scaling up RL right\nnow, so I basically don't expect",
      "offset": 737.55,
      "duration": 4.13
    },
    {
      "lang": "en",
      "text": "that to be true for fairly long.",
      "offset": 741.68,
      "duration": 1.49
    },
    {
      "lang": "en",
      "text": "Just for the sake of listeners,\nmaybe, you're doing gradient",
      "offset": 743.53,
      "duration": 4.18
    },
    {
      "lang": "en",
      "text": "descent steps in both pre-training\nand reinforcement learning.",
      "offset": 747.74,
      "duration": 3.32
    },
    {
      "lang": "en",
      "text": "It's just the signal's different.",
      "offset": 751.42,
      "duration": 1.5
    },
    {
      "lang": "en",
      "text": "Typically, in reinforcement\nlearning, your reward is sparser,",
      "offset": 752.98,
      "duration": 2.81
    },
    {
      "lang": "en",
      "text": "so you take multiple turns.",
      "offset": 756.17,
      "duration": 1.56
    },
    {
      "lang": "en",
      "text": "It's like, &quot;Did you win the chess game or\nnot,&quot; is the only signal you're getting.",
      "offset": 757.73,
      "duration": 2.98
    },
    {
      "lang": "en",
      "text": "Often you can't compute gradients\nthrough discrete actions.",
      "offset": 761.43,
      "duration": 4.06
    },
    {
      "lang": "en",
      "text": "So you end up losing a\nlot of gradient signal.",
      "offset": 765.5,
      "duration": 3.56
    },
    {
      "lang": "en",
      "text": "You can presume that pre-training\nis more efficient, but there's no",
      "offset": 769.889,
      "duration": 4.701
    },
    {
      "lang": "en",
      "text": "reason why you couldn't learn new\nabilities in reinforcement learning.",
      "offset": 774.59,
      "duration": 3.06
    },
    {
      "lang": "en",
      "text": "In fact, you could replace the whole next\ntoken prediction task in pre-training",
      "offset": 777.92,
      "duration": 3.779
    },
    {
      "lang": "en",
      "text": "with some weird RL variant of it and\nthen do all of your learning with RL.",
      "offset": 781.89,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "Yeah, at the end of the day, just\nsignal and then correcting to it.",
      "offset": 787.99,
      "duration": 3.049
    },
    {
      "lang": "en",
      "text": "Totally.",
      "offset": 791.1,
      "duration": 0.5
    },
    {
      "lang": "en",
      "text": "Then going back to the paper you\nmentioned, aside from the caveats",
      "offset": 791.699,
      "duration": 3.491
    },
    {
      "lang": "en",
      "text": "that Sholto brings up, which I think\nis the first order, most important,",
      "offset": 795.19,
      "duration": 2.84
    },
    {
      "lang": "en",
      "text": "I think zeroing in on the probability\nspace of meaningful actions comes",
      "offset": 798.8,
      "duration": 3.71
    },
    {
      "lang": "en",
      "text": "back to the nines of reliability.",
      "offset": 802.52,
      "duration": 1.46
    },
    {
      "lang": "en",
      "text": "Classically, if you give\nmonkeys a typewriter, eventually",
      "offset": 805.63,
      "duration": 2.08
    },
    {
      "lang": "en",
      "text": "they'll write Shakespeare.",
      "offset": 807.71,
      "duration": 0.679
    },
    {
      "lang": "en",
      "text": "The action space for any of these\nreal world tasks that we care about",
      "offset": 808.389,
      "duration": 4.891
    },
    {
      "lang": "en",
      "text": "is so large that you really do care\nabout getting the model to zero",
      "offset": 813.28,
      "duration": 4.77
    },
    {
      "lang": "en",
      "text": "in on doing the reasonable things.",
      "offset": 818.05,
      "duration": 1.47
    },
    {
      "lang": "en",
      "text": "To the extent",
      "offset": 820.16,
      "duration": 0.529
    },
    {
      "lang": "en",
      "text": "that at some pass you’re like\n&quot;Hey, you've got token space&quot;...",
      "offset": 822.939,
      "duration": 4.061
    },
    {
      "lang": "en",
      "text": "Right, you literally do have\na monkey and it's making",
      "offset": 827.01,
      "duration": 3.13
    },
    {
      "lang": "en",
      "text": "Shakespeare in the end.",
      "offset": 834.439,
      "duration": 0.681
    },
    {
      "lang": "en",
      "text": "The chess analogy is interesting.",
      "offset": 835.24,
      "duration": 1.49
    },
    {
      "lang": "en",
      "text": "Sorry, were you about to say something?",
      "offset": 836.73,
      "duration": 0.715
    },
    {
      "lang": "en",
      "text": "Oh, I was just going to say that\nyou do need to be able to get",
      "offset": 837.445,
      "duration": 2.995
    },
    {
      "lang": "en",
      "text": "reward sometimes in order to learn.",
      "offset": 840.44,
      "duration": 2.363
    },
    {
      "lang": "en",
      "text": "That's the complexity in some respects.",
      "offset": 842.803,
      "duration": 1.486
    },
    {
      "lang": "en",
      "text": "In the Alpha variants—maybe you\nwere about to say this—one player",
      "offset": 844.43,
      "duration": 3.97
    },
    {
      "lang": "en",
      "text": "always wins, so you always get a\nreward signal one way or the other.",
      "offset": 848.4,
      "duration": 2.91
    },
    {
      "lang": "en",
      "text": "In the kinds of things we're\ntalking about, you need to actually",
      "offset": 852.3,
      "duration": 1.52
    },
    {
      "lang": "en",
      "text": "succeed at your task sometimes.",
      "offset": 853.82,
      "duration": 1.19
    },
    {
      "lang": "en",
      "text": "Now, language models luckily\nhave this wonderful prior over",
      "offset": 855.23,
      "duration": 3.669
    },
    {
      "lang": "en",
      "text": "the tasks that we care about.",
      "offset": 859.009,
      "duration": 1.021
    },
    {
      "lang": "en",
      "text": "If you look at all the\nold papers from 2017,",
      "offset": 861.83,
      "duration": 3.109
    },
    {
      "lang": "en",
      "text": "the learning curves always look like\nthey're flat, flat, flat as they're",
      "offset": 869,
      "duration": 3.05
    },
    {
      "lang": "en",
      "text": "figuring out basic mechanics of the world.",
      "offset": 872.05,
      "duration": 2.92
    },
    {
      "lang": "en",
      "text": "Then there's this spike up as they\nlearn to exploit the easy rewards.",
      "offset": 875.21,
      "duration": 3.879
    },
    {
      "lang": "en",
      "text": "Then it's almost like a\nsigmoid in some respects.",
      "offset": 879.17,
      "duration": 3.129
    },
    {
      "lang": "en",
      "text": "Then it continues on\nindefinitely as it just learns",
      "offset": 882.66,
      "duration": 3.309
    },
    {
      "lang": "en",
      "text": "to absolutely maximize the game.",
      "offset": 885.969,
      "duration": 1.151
    },
    {
      "lang": "en",
      "text": "I think the LLM curves look a bit\ndifferent, in that there isn't",
      "offset": 887.96,
      "duration": 2.96
    },
    {
      "lang": "en",
      "text": "that dead zone at the beginning.",
      "offset": 890.92,
      "duration": 1.17
    },
    {
      "lang": "en",
      "text": "They already know how to\nsolve some of the basic tasks.",
      "offset": 892.51,
      "duration": 2.86
    },
    {
      "lang": "en",
      "text": "You get this initial spike.",
      "offset": 895.4,
      "duration": 3.269
    },
    {
      "lang": "en",
      "text": "That's what people are talking about when\nthey're like, &quot;Oh, you can learn from",
      "offset": 898.799,
      "duration": 1.801
    },
    {
      "lang": "en",
      "text": "one example.&quot; That one example is just\nteaching you to pull out the backtracking,",
      "offset": 900.6,
      "duration": 5.43
    },
    {
      "lang": "en",
      "text": "and formatting your answer correctly,\nthis kind of stuff that lets you get some",
      "offset": 906.03,
      "duration": 3.17
    },
    {
      "lang": "en",
      "text": "reward initially at tasks conditional\nin your pre-training knowledge.",
      "offset": 909.2,
      "duration": 4.039
    },
    {
      "lang": "en",
      "text": "The rest is probably you learning",
      "offset": 913.95,
      "duration": 2.11
    },
    {
      "lang": "en",
      "text": "normal stuff.\nThat's really interesting.",
      "offset": 918.5,
      "duration": 0.46
    },
    {
      "lang": "en",
      "text": "I know people have critiqued or been\nskeptical of RL delivering quick wins",
      "offset": 918.96,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "by pointing out that AlphaGo took\na lot of compute, especially for a",
      "offset": 923.2,
      "duration": 3.059
    },
    {
      "lang": "en",
      "text": "system trained in, what was it, 2017?",
      "offset": 926.26,
      "duration": 2.849
    },
    {
      "lang": "en",
      "text": "Yeah, it's off the",
      "offset": 929.17,
      "duration": 1.16
    },
    {
      "lang": "en",
      "text": "curve.",
      "offset": 932.63,
      "duration": 0.03
    },
    {
      "lang": "en",
      "text": "To the extent that that was largely\nbecause first you had to have",
      "offset": 932.66,
      "duration": 3.669
    },
    {
      "lang": "en",
      "text": "something which had some biases, which\nwere sort of rational before it got",
      "offset": 936.33,
      "duration": 4.609
    },
    {
      "lang": "en",
      "text": "superhuman at Go… Actually, it would\nbe interesting to see what fraction",
      "offset": 941.29,
      "duration": 3.91
    },
    {
      "lang": "en",
      "text": "of the compute used on AlphaGo was\njust getting something reasonable.",
      "offset": 945.2,
      "duration": 2.33
    },
    {
      "lang": "en",
      "text": "Yeah, it would be interesting.",
      "offset": 947.559,
      "duration": 1.461
    },
    {
      "lang": "en",
      "text": "To make the map from pre-training to RL\nreally explicit here, during pre-training,",
      "offset": 949.759,
      "duration": 4.401
    },
    {
      "lang": "en",
      "text": "the large language model is predicting\nthe next token of its vocabulary of,",
      "offset": 954.17,
      "duration": 3.98
    },
    {
      "lang": "en",
      "text": "let's say, I don't know, 50,000 tokens.",
      "offset": 958.15,
      "duration": 1.679
    },
    {
      "lang": "en",
      "text": "You are then rewarding it for\nthe amount of probability that",
      "offset": 960.93,
      "duration": 3.57
    },
    {
      "lang": "en",
      "text": "it assigns to the true token.",
      "offset": 964.5,
      "duration": 2.97
    },
    {
      "lang": "en",
      "text": "You could think of it as a reward, but\nit's a very dense reward, where you're",
      "offset": 967.87,
      "duration": 4.549
    },
    {
      "lang": "en",
      "text": "getting signal at every single token,\nand you're always getting some signal.",
      "offset": 972.43,
      "duration": 5.059
    },
    {
      "lang": "en",
      "text": "Even if it only assigned 1% to that token\nor less, you're like, &quot;Oh, I see you",
      "offset": 977.52,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "assigned 1%. Good job. Keep doing that.&quot;",
      "offset": 982.16,
      "duration": 2.244
    },
    {
      "lang": "en",
      "text": "Yeah, upweight it.\nYeah, exactly.",
      "offset": 984.759,
      "duration": 0.99
    },
    {
      "lang": "en",
      "text": "It's like a tug in the gradient.",
      "offset": 985.749,
      "duration": 0.68
    },
    {
      "lang": "en",
      "text": "That's right.",
      "offset": 986.479,
      "duration": 0.5
    },
    {
      "lang": "en",
      "text": "When I think about the way humans learn,\nit seems like these models getting no",
      "offset": 987.039,
      "duration": 6.201
    },
    {
      "lang": "en",
      "text": "signal from failure is quite different.",
      "offset": 993.24,
      "duration": 1.78
    },
    {
      "lang": "en",
      "text": "If you try to do a math problem and you\nfail, it's actually often even more useful",
      "offset": 996.11,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "than learning about math in the abstracts,\nbecause… Oh, you don't think so?",
      "offset": 1000.78,
      "duration": 3.5
    },
    {
      "lang": "en",
      "text": "Only if you get feedback.",
      "offset": 1004.82,
      "duration": 1.009
    },
    {
      "lang": "en",
      "text": "Yeah, only if you get feedback.",
      "offset": 1005.83,
      "duration": 1.249
    },
    {
      "lang": "en",
      "text": "I think there's a way in which you\nactually give yourself feedback.",
      "offset": 1007.089,
      "duration": 3.521
    },
    {
      "lang": "en",
      "text": "You fail and you notice where you failed.",
      "offset": 1010.61,
      "duration": 2.66
    },
    {
      "lang": "en",
      "text": "Only if you get feedback,\nI think, at times.",
      "offset": 1013.5,
      "duration": 1.97
    },
    {
      "lang": "en",
      "text": "People have figured out new math,\nand they've done it by the fact",
      "offset": 1016.42,
      "duration": 2.08
    },
    {
      "lang": "en",
      "text": "that they get stuck somewhere.",
      "offset": 1018.5,
      "duration": 1.2
    },
    {
      "lang": "en",
      "text": "They're like, &quot;Why am I getting stuck\nhere? Let me think through this.&quot;",
      "offset": 1019.7,
      "duration": 2.85
    },
    {
      "lang": "en",
      "text": "I'm not aware of what's at the frontier,\nbut looking at open source implementations",
      "offset": 1023.79,
      "duration": 3.029
    },
    {
      "lang": "en",
      "text": "from DeepSeek or something, there's not\nthis conscious process by which once you",
      "offset": 1026.819,
      "duration": 6.431
    },
    {
      "lang": "en",
      "text": "have failed, you learn from the particular\nway in which you failed, to then",
      "offset": 1033.25,
      "duration": 5.75
    },
    {
      "lang": "en",
      "text": "backtrack and do your next things better.",
      "offset": 1039.19,
      "duration": 1.67
    },
    {
      "lang": "en",
      "text": "Just pure gradient descent, I\nwonder if that's a big limitation.",
      "offset": 1040.86,
      "duration": 2.559
    },
    {
      "lang": "en",
      "text": "I don't know.",
      "offset": 1043.67,
      "duration": 0.36
    },
    {
      "lang": "en",
      "text": "I just remember undergrad courses,\nwhere you would try to prove something,",
      "offset": 1044.03,
      "duration": 4.2
    },
    {
      "lang": "en",
      "text": "and you'd just be wandering around in\nthe darkness for a really long time.",
      "offset": 1048.27,
      "duration": 4.339
    },
    {
      "lang": "en",
      "text": "Then maybe you totally throw\nyour hands up in the air and",
      "offset": 1053.16,
      "duration": 1.94
    },
    {
      "lang": "en",
      "text": "need to go and talk to a TA.",
      "offset": 1055.1,
      "duration": 1.339
    },
    {
      "lang": "en",
      "text": "It's only when you talk to a TA can you\nsee where along the path of different",
      "offset": 1056.809,
      "duration": 4.351
    },
    {
      "lang": "en",
      "text": "solutions you were incorrect and what the\ncorrect thing to have done would've been.",
      "offset": 1061.16,
      "duration": 4.38
    },
    {
      "lang": "en",
      "text": "That's in the case where you know\nwhat the final answer is, right?",
      "offset": 1065.96,
      "duration": 2.59
    },
    {
      "lang": "en",
      "text": "In other cases, if you're just\nkind of shooting blind and",
      "offset": 1068.55,
      "duration": 2.57
    },
    {
      "lang": "en",
      "text": "meant to give an answer de novo,",
      "offset": 1071.12,
      "duration": 1.53
    },
    {
      "lang": "en",
      "text": "it's really hard to learn anything.",
      "offset": 1074.719,
      "duration": 1.501
    },
    {
      "lang": "en",
      "text": "I guess I'm trying to map on,\nagain, to the human example, where",
      "offset": 1076.929,
      "duration": 2.22
    },
    {
      "lang": "en",
      "text": "in more simpler terms, there is\nthis sort of conscious intermediary",
      "offset": 1080.039,
      "duration": 4.66
    },
    {
      "lang": "en",
      "text": "auxiliary loss that we're optimizing.",
      "offset": 1084.87,
      "duration": 2.45
    },
    {
      "lang": "en",
      "text": "It's a very sort of\nself-conscious process.",
      "offset": 1087.32,
      "duration": 2.05
    },
    {
      "lang": "en",
      "text": "Forget about math.",
      "offset": 1091.11,
      "duration": 0.64
    },
    {
      "lang": "en",
      "text": "If you're on your job, you're getting\nvery explicit feedback from your boss.",
      "offset": 1092.02,
      "duration": 4.44
    },
    {
      "lang": "en",
      "text": "That's not necessarily how the task\nshould be done differently, but a",
      "offset": 1096.46,
      "duration": 3.49
    },
    {
      "lang": "en",
      "text": "high-level explanation of what you\ndid wrong, which you update on not",
      "offset": 1100.04,
      "duration": 3.69
    },
    {
      "lang": "en",
      "text": "in the way that pre-training updates\nweights, but more in the… I don’t know.",
      "offset": 1103.76,
      "duration": 3.169
    },
    {
      "lang": "en",
      "text": "I think there's a lot of implicit\ndense reward signals here.",
      "offset": 1107.099,
      "duration": 3.004
    },
    {
      "lang": "en",
      "text": "Yeah, exactly.",
      "offset": 1110.19,
      "duration": 0.73
    },
    {
      "lang": "en",
      "text": "Like weekly one-on-ones with your manager,\nor being encouraged to work in the open.",
      "offset": 1111.69,
      "duration": 4.61
    },
    {
      "lang": "en",
      "text": "Even with homework assignments,\nthey're so scaffolded.",
      "offset": 1117.57,
      "duration": 2.18
    },
    {
      "lang": "en",
      "text": "It's always 10 questions broken down\ninto subcomponents, and maybe the",
      "offset": 1120.46,
      "duration": 5.429
    },
    {
      "lang": "en",
      "text": "hardest possible problem is one where\nyou need to do everything on your own.",
      "offset": 1125.889,
      "duration": 3.191
    },
    {
      "lang": "en",
      "text": "Okay, so then a big question is do\nyou need to build these scaffolds,",
      "offset": 1129.429,
      "duration": 4.211
    },
    {
      "lang": "en",
      "text": "these structures, these bespoke\nenvironments for every single skill",
      "offset": 1133.64,
      "duration": 4.299
    },
    {
      "lang": "en",
      "text": "that you want the model to understand?",
      "offset": 1137.94,
      "duration": 1.48
    },
    {
      "lang": "en",
      "text": "Then it's going to be a decade of\ngrinding through these sub-skills?",
      "offset": 1139.43,
      "duration": 2.8
    },
    {
      "lang": "en",
      "text": "Or is there some more general procedure\nfor learning new skills using RL?",
      "offset": 1142.51,
      "duration": 3.78
    },
    {
      "lang": "en",
      "text": "It's an efficiency question there.",
      "offset": 1148.5,
      "duration": 1.509
    },
    {
      "lang": "en",
      "text": "Obviously, if you could give a dense\nreward for every token, if you had a",
      "offset": 1150.369,
      "duration": 3.671
    },
    {
      "lang": "en",
      "text": "supervised example, then that's one\nof the best things you could have.",
      "offset": 1154.04,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "In many cases, it's very expensive\nto produce all of those scaffolded",
      "offset": 1158.68,
      "duration": 3.08
    },
    {
      "lang": "en",
      "text": "curricula of everything to do.",
      "offset": 1162.99,
      "duration": 1.639
    },
    {
      "lang": "en",
      "text": "Having PhD math students grade students\nis something which you can only afford",
      "offset": 1165.19,
      "duration": 5.109
    },
    {
      "lang": "en",
      "text": "for the select cadre of students that\nyou've chosen to focus on developing.",
      "offset": 1170.299,
      "duration": 4.12
    },
    {
      "lang": "en",
      "text": "You couldn't do that for all the\nlanguage models in the world.",
      "offset": 1174.43,
      "duration": 1.98
    },
    {
      "lang": "en",
      "text": "First step is that obviously,\nthat would be better.",
      "offset": 1180.23,
      "duration": 2.759
    },
    {
      "lang": "en",
      "text": "But you're going to be optimizing\nthis Pareto frontier of how",
      "offset": 1183.9,
      "duration": 4.059
    },
    {
      "lang": "en",
      "text": "much am I willing to spend on",
      "offset": 1187.959,
      "duration": 1.381
    },
    {
      "lang": "en",
      "text": "the scaffolding, versus how much am\nI willing to spend on pure compute?",
      "offset": 1191.36,
      "duration": 3.06
    },
    {
      "lang": "en",
      "text": "The other thing you can do is just keep\nletting the monkey hit the typewriter.",
      "offset": 1195.32,
      "duration": 2.99
    },
    {
      "lang": "en",
      "text": "If you have a good enough end reward,\nthen eventually, it will find its way.",
      "offset": 1200.009,
      "duration": 4.751
    },
    {
      "lang": "en",
      "text": "I can't really talk about where\nexactly people sit on that scaffold.",
      "offset": 1206.68,
      "duration": 4.249
    },
    {
      "lang": "en",
      "text": "I think different people, different\ntasks are on different points there.",
      "offset": 1210.93,
      "duration": 3.78
    },
    {
      "lang": "en",
      "text": "A lot of it depends on how strong your\nprior is over the correct things to do.",
      "offset": 1216.679,
      "duration": 3.081
    },
    {
      "lang": "en",
      "text": "But that's the equation you're optimizing.",
      "offset": 1221.26,
      "duration": 2.05
    },
    {
      "lang": "en",
      "text": "It's like, &quot;How much am I willing to\nburn compute, versus how much am I",
      "offset": 1223.379,
      "duration": 2.971
    },
    {
      "lang": "en",
      "text": "willing to burn dollars on people's time\nto give scaffolding or give rewards?&quot;",
      "offset": 1226.35,
      "duration": 6.14
    },
    {
      "lang": "en",
      "text": "Interesting.",
      "offset": 1232.49,
      "duration": 0.5
    },
    {
      "lang": "en",
      "text": "You say we're not willing to do this\nfor LLMs, but we are for people.",
      "offset": 1233.599,
      "duration": 2.251
    },
    {
      "lang": "en",
      "text": "I would think the economic logic\nwould flow in the opposite direction",
      "offset": 1235.85,
      "duration": 2.89
    },
    {
      "lang": "en",
      "text": "for the reason that you can amortize\nthe cost of training any skill",
      "offset": 1238.969,
      "duration": 4.111
    },
    {
      "lang": "en",
      "text": "on a model across all the copies.",
      "offset": 1243.11,
      "duration": 1.81
    },
    {
      "lang": "en",
      "text": "We are willing to do this\nfor LLMs to some degree.",
      "offset": 1245.68,
      "duration": 2.58
    },
    {
      "lang": "en",
      "text": "But there's an equation you're\nmaximizing here of, &quot;Okay, I've",
      "offset": 1248.27,
      "duration": 4.02
    },
    {
      "lang": "en",
      "text": "raised all this money, do I spend it\nalong this axis or do I spend it on",
      "offset": 1252.439,
      "duration": 2.77
    },
    {
      "lang": "en",
      "text": "this axis?&quot;",
      "offset": 1257.809,
      "duration": 0.36
    },
    {
      "lang": "en",
      "text": "Currently, the companies are spending\nmore on compute than they are on humans.",
      "offset": 1258.169,
      "duration": 4.22
    },
    {
      "lang": "en",
      "text": "Otherwise, Scale AI's\nrevenue would be like",
      "offset": 1262.64,
      "duration": 2.27
    },
    {
      "lang": "en",
      "text": "$10 billion.",
      "offset": 1267.29,
      "duration": 0.66
    },
    {
      "lang": "en",
      "text": "Look at it, NVIDIA's revenue\nis much higher than Scale AI's",
      "offset": 1267.95,
      "duration": 2.489
    },
    {
      "lang": "en",
      "text": "revenue.",
      "offset": 1272.899,
      "duration": 0.07
    },
    {
      "lang": "en",
      "text": "Currently, the equation is\ncompute over data, and that will",
      "offset": 1272.969,
      "duration": 6.571
    },
    {
      "lang": "en",
      "text": "evolve in some way over time.",
      "offset": 1279.54,
      "duration": 1.55
    },
    {
      "lang": "en",
      "text": "Yeah, interesting.",
      "offset": 1281.42,
      "duration": 0.94
    },
    {
      "lang": "en",
      "text": "I am curious how it evolves.",
      "offset": 1283.02,
      "duration": 1.61
    },
    {
      "lang": "en",
      "text": "If you think about the way that humans\nlearn to do a job, they get deployed,",
      "offset": 1284.63,
      "duration": 6.85
    },
    {
      "lang": "en",
      "text": "and they just do the job, and they learn.",
      "offset": 1291.54,
      "duration": 2.149
    },
    {
      "lang": "en",
      "text": "Whereas the way these models seem to be\ntrained is that for every skill, you have",
      "offset": 1295.949,
      "duration": 5.341
    },
    {
      "lang": "en",
      "text": "to give them a very bespoke environment.",
      "offset": 1301.29,
      "duration": 3.51
    },
    {
      "lang": "en",
      "text": "If they were trained the way\nhumans are trained, then...",
      "offset": 1306.139,
      "duration": 2.371
    },
    {
      "lang": "en",
      "text": "On the job.",
      "offset": 1308.65,
      "duration": 0.559
    },
    {
      "lang": "en",
      "text": "Yeah, exactly.",
      "offset": 1309.32,
      "duration": 0.65
    },
    {
      "lang": "en",
      "text": "Then it would actually be super powerful,\nbecause everybody has a different job,",
      "offset": 1310.16,
      "duration": 3.24
    },
    {
      "lang": "en",
      "text": "but then the same model could agglomerate\nall the skills that you're getting.",
      "offset": 1313.41,
      "duration": 3.07
    },
    {
      "lang": "en",
      "text": "I don't know, I've been doing the\npodcast for the last few years.",
      "offset": 1316.78,
      "duration": 1.58
    },
    {
      "lang": "en",
      "text": "I'm becoming a better podcaster.",
      "offset": 1318.36,
      "duration": 1.87
    },
    {
      "lang": "en",
      "text": "You have a slightly more valuable\nskill of doing AI research.",
      "offset": 1321.13,
      "duration": 3.81
    },
    {
      "lang": "en",
      "text": "I don't know",
      "offset": 1328.839,
      "duration": 0.5
    },
    {
      "lang": "en",
      "text": "about that.",
      "offset": 1331.14,
      "duration": 0.5
    },
    {
      "lang": "en",
      "text": "You could imagine a model that\ncould do both things because",
      "offset": 1331.75,
      "duration": 1.629
    },
    {
      "lang": "en",
      "text": "it's doing both of our jobs.",
      "offset": 1333.379,
      "duration": 1.051
    },
    {
      "lang": "en",
      "text": "Copies of the model are doing both jobs.",
      "offset": 1334.51,
      "duration": 1.82
    },
    {
      "lang": "en",
      "text": "It seems like more bitter lesson\naligned to do this, just let the model",
      "offset": 1337.89,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "learn out in the world, rather than",
      "offset": 1342.58,
      "duration": 1.46
    },
    {
      "lang": "en",
      "text": "spending billions on getting\ndata for particular tasks.",
      "offset": 1346.73,
      "duration": 3.06
    },
    {
      "lang": "en",
      "text": "I think again, we take for granted\nhow much we need to show humans how",
      "offset": 1350.29,
      "duration": 3.73
    },
    {
      "lang": "en",
      "text": "to do specific tasks, and there's\na failure to generalize here.",
      "offset": 1354.02,
      "duration": 2.98
    },
    {
      "lang": "en",
      "text": "If I were to just suddenly give you\na new software platform, let's say",
      "offset": 1357.48,
      "duration": 3.56
    },
    {
      "lang": "en",
      "text": "Photoshop, and I'm like, &quot;Okay, edit this\nphoto&quot;... If you've never used Photoshop",
      "offset": 1361.21,
      "duration": 4.51
    },
    {
      "lang": "en",
      "text": "before, it'd be really hard to navigate.",
      "offset": 1365.72,
      "duration": 2.73
    },
    {
      "lang": "en",
      "text": "I think you'd immediately want\nto go online and watch a demo of",
      "offset": 1368.88,
      "duration": 4.11
    },
    {
      "lang": "en",
      "text": "someone else doing it in order\nto then be able to imitate them.",
      "offset": 1372.99,
      "duration": 2.63
    },
    {
      "lang": "en",
      "text": "We surely give that amount of data\non every single task to the models.",
      "offset": 1375.74,
      "duration": 3.885
    },
    {
      "lang": "en",
      "text": "Okay.",
      "offset": 1379.65,
      "duration": 0.5
    },
    {
      "lang": "en",
      "text": "This is the first thing.",
      "offset": 1380.27,
      "duration": 0.99
    },
    {
      "lang": "en",
      "text": "The other one is I think we're still\njust way smaller than human brain size.",
      "offset": 1381.639,
      "duration": 3.621
    },
    {
      "lang": "en",
      "text": "We know that when you make\nmodels larger, they learn more",
      "offset": 1385.299,
      "duration": 3.651
    },
    {
      "lang": "en",
      "text": "sample-efficiently with fewer demos.",
      "offset": 1388.95,
      "duration": 2.21
    },
    {
      "lang": "en",
      "text": "It was striking, where even in your recent\npodcast with Mark Zuckerberg and Llama,",
      "offset": 1392.3,
      "duration": 4.129
    },
    {
      "lang": "en",
      "text": "it's like a 2 trillion parameter model.",
      "offset": 1396.639,
      "duration": 2.37
    },
    {
      "lang": "en",
      "text": "We estimate that the human brain has\nbetween 30 to 300 trillion synapses.",
      "offset": 1399.73,
      "duration": 3.899
    },
    {
      "lang": "en",
      "text": "I don't know exactly how to do a mapping\nfrom one to the other here, but I",
      "offset": 1404.01,
      "duration": 3.29
    },
    {
      "lang": "en",
      "text": "think it's useful background context.",
      "offset": 1407.31,
      "duration": 1.9
    },
    {
      "lang": "en",
      "text": "I think it's quite likely we're\nstill smaller than the human brain.",
      "offset": 1409.36,
      "duration": 3.53
    },
    {
      "lang": "en",
      "text": "Even with the 4.5 release from OpenAI,\nwhich they said was a larger model,",
      "offset": 1414.21,
      "duration": 3.99
    },
    {
      "lang": "en",
      "text": "people would talk about its writing\nability or this sort of big model smell.",
      "offset": 1419.51,
      "duration": 4.52
    },
    {
      "lang": "en",
      "text": "This is kind of getting at this\ndeeper pool of intelligence",
      "offset": 1425.05,
      "duration": 4.36
    },
    {
      "lang": "en",
      "text": "or ability to generalize.",
      "offset": 1429.41,
      "duration": 1.479
    },
    {
      "lang": "en",
      "text": "All of the interpretability work on\nsuperposition states that the models",
      "offset": 1431.91,
      "duration": 3.879
    },
    {
      "lang": "en",
      "text": "are always under-parametrized, and\nthey're being forced to cram as much",
      "offset": 1435.79,
      "duration": 3.31
    },
    {
      "lang": "en",
      "text": "information in as they possibly can.",
      "offset": 1439.1,
      "duration": 1.93
    },
    {
      "lang": "en",
      "text": "If you don't have enough parameters\nand you're rewarding the model just for",
      "offset": 1441.66,
      "duration": 3.4
    },
    {
      "lang": "en",
      "text": "imitating certain behaviors, then it's\nless likely to have the space to form",
      "offset": 1445.38,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "these very deep, broader generalizations.",
      "offset": 1449.3,
      "duration": 3.37
    },
    {
      "lang": "en",
      "text": "The language result is really cool.",
      "offset": 1452.969,
      "duration": 2.91
    },
    {
      "lang": "en",
      "text": "You should talk about the language result.",
      "offset": 1456.1,
      "duration": 1.059
    },
    {
      "lang": "en",
      "text": "How smaller models",
      "offset": 1457.74,
      "duration": 1.32
    },
    {
      "lang": "en",
      "text": "have separate neurons for\ndifferent languages, whereas",
      "offset": 1461.88,
      "duration": 1.93
    },
    {
      "lang": "en",
      "text": "larger models end up sharing more\nand more in an abstract space.",
      "offset": 1463.81,
      "duration": 1.964
    },
    {
      "lang": "en",
      "text": "Yeah, yeah.",
      "offset": 1465.8,
      "duration": 2.06
    },
    {
      "lang": "en",
      "text": "In the circuits work, even with the\nGolden Gate Bridge, and by the way,",
      "offset": 1468.05,
      "duration": 3.26
    },
    {
      "lang": "en",
      "text": "this is a cable from the Golden\nGate Bridge that the team acquired-",
      "offset": 1471.31,
      "duration": 5.27
    },
    {
      "lang": "en",
      "text": "They had to destabilize the\nbridge in order to get this.",
      "offset": 1476.58,
      "duration": 3.659
    },
    {
      "lang": "en",
      "text": "Claude will fix it.",
      "offset": 1480.26,
      "duration": 0.8
    },
    {
      "lang": "en",
      "text": "Claude loves the Golden Gate Bridge.",
      "offset": 1481.06,
      "duration": 2.12
    },
    {
      "lang": "en",
      "text": "Even with this, for people who\naren't familiar we made Golden Gate",
      "offset": 1483.55,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "Claude when we released our paper,\n“Scaling Monosemanticity”, where",
      "offset": 1488.03,
      "duration": 3.8
    },
    {
      "lang": "en",
      "text": "one of the 30 million features\nwas for the Golden Gate Bridge.",
      "offset": 1491.839,
      "duration": 2.79
    },
    {
      "lang": "en",
      "text": "If you just always activate it, then the\nmodel thinks it's the Golden Gate Bridge.",
      "offset": 1495.02,
      "duration": 3.72
    },
    {
      "lang": "en",
      "text": "If you ask it for chocolate chip cookies,\nit will tell you that you should use",
      "offset": 1498.89,
      "duration": 2.97
    },
    {
      "lang": "en",
      "text": "orange food coloring, or bring the\ncookies and eat them on the Golden Gate",
      "offset": 1501.87,
      "duration": 3.67
    },
    {
      "lang": "en",
      "text": "Bridge, all of these sort of associations.",
      "offset": 1505.54,
      "duration": 2.32
    },
    {
      "lang": "en",
      "text": "The way we found that feature\nwas through this generalization",
      "offset": 1507.87,
      "duration": 4.779
    },
    {
      "lang": "en",
      "text": "between texts and images.",
      "offset": 1512.65,
      "duration": 1.2
    },
    {
      "lang": "en",
      "text": "I actually implemented the ability to\nput images into our feature activations.",
      "offset": 1516.25,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "This was all on Claude 3 Sonnet, which\nwas one of our first multimodal models.",
      "offset": 1522.7,
      "duration": 3.08
    },
    {
      "lang": "en",
      "text": "We only trained the sparse autoencoder\nand the features on text, and then a",
      "offset": 1526.48,
      "duration": 6.8
    },
    {
      "lang": "en",
      "text": "friend on the team put in an image of\nthe Golden Gate Bridge, and then this",
      "offset": 1533.28,
      "duration": 4.23
    },
    {
      "lang": "en",
      "text": "feature lights up and we look at the\ntext, and it's for the Golden Gate Bridge.",
      "offset": 1537.51,
      "duration": 2.81
    },
    {
      "lang": "en",
      "text": "The model uses the same pattern\nof neural activity in its brain to",
      "offset": 1540.889,
      "duration": 4.531
    },
    {
      "lang": "en",
      "text": "represent both the image and the text.",
      "offset": 1545.42,
      "duration": 1.769
    },
    {
      "lang": "en",
      "text": "Our circuits work shows this, again,\nacross multiple languages, there's",
      "offset": 1547.189,
      "duration": 4.751
    },
    {
      "lang": "en",
      "text": "the same notion for something being\nlarge or small, or hot or cold.",
      "offset": 1551.94,
      "duration": 3.49
    },
    {
      "lang": "en",
      "text": "Strikingly,",
      "offset": 1555.77,
      "duration": 0.5
    },
    {
      "lang": "en",
      "text": "that is more so the case in larger\nmodels, where you'd think actually",
      "offset": 1558.13,
      "duration": 3.45
    },
    {
      "lang": "en",
      "text": "larger models have more space, so\nthey could separate things out more.",
      "offset": 1561.58,
      "duration": 2.789
    },
    {
      "lang": "en",
      "text": "Actually instead, they seem to pull\non these on better abstractions,",
      "offset": 1564.629,
      "duration": 4.07
    },
    {
      "lang": "en",
      "text": "which is very interesting.",
      "offset": 1569.729,
      "duration": 0.731
    },
    {
      "lang": "en",
      "text": "I want to go into more at some\npoint how Claude does addition.",
      "offset": 1572.57,
      "duration": 2.789
    },
    {
      "lang": "en",
      "text": "When you look at the bigger models,\nit just has a much crisper lookup",
      "offset": 1575.52,
      "duration": 2.859
    },
    {
      "lang": "en",
      "text": "table for how to add the number five\nand nine together, and get something",
      "offset": 1578.84,
      "duration": 4.63
    },
    {
      "lang": "en",
      "text": "like 10 modulo six, six modulo 10.",
      "offset": 1583.48,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "Again and again, the more capacity it\nhas the more refined the solution is.",
      "offset": 1588.56,
      "duration": 4.129
    },
    {
      "lang": "en",
      "text": "The other interesting thing here is with\nall the circuits work, it's never a single",
      "offset": 1593.03,
      "duration": 3.53
    },
    {
      "lang": "en",
      "text": "path for why the model does something.",
      "offset": 1596.56,
      "duration": 1.71
    },
    {
      "lang": "en",
      "text": "It's always multiple paths, and\nsome of them are deeper than others.",
      "offset": 1598.44,
      "duration": 3.07
    },
    {
      "lang": "en",
      "text": "When the model immediately sees the\nword “bomb”, there's a direct path to it",
      "offset": 1602.52,
      "duration": 4.55
    },
    {
      "lang": "en",
      "text": "refusing that goes from the word “bomb”.",
      "offset": 1607.07,
      "duration": 2.369
    },
    {
      "lang": "en",
      "text": "There's a totally separate path\nthat works in cooperation, where it",
      "offset": 1609.87,
      "duration": 4.149
    },
    {
      "lang": "en",
      "text": "sees “bomb”, it then sees, &quot;Okay,\nI'm being asked to make a bomb.",
      "offset": 1614.02,
      "duration": 3.57
    },
    {
      "lang": "en",
      "text": "Okay, this is a harmful request.",
      "offset": 1618.029,
      "duration": 2.21
    },
    {
      "lang": "en",
      "text": "I'm an AI agent, and I've\nbeen trained to refuse this.&quot;",
      "offset": 1620.75,
      "duration": 3.72
    },
    {
      "lang": "en",
      "text": "One possible narrative here is that as the\nmodel becomes smarter over the course of",
      "offset": 1626.4,
      "duration": 4.329
    },
    {
      "lang": "en",
      "text": "training, it learns to replace the short\ncircuit imitation, “see bomb, refuse”",
      "offset": 1630.73,
      "duration": 5.239
    },
    {
      "lang": "en",
      "text": "with this deeper reasoning circuit.",
      "offset": 1636.139,
      "duration": 1.62
    },
    {
      "lang": "en",
      "text": "It kind of has kept the other stuff around\nto the extent that it's not harmful.",
      "offset": 1637.759,
      "duration": 3.811
    },
    {
      "lang": "en",
      "text": "Your point on, are these models\nas sample efficient as humans?",
      "offset": 1644.02,
      "duration": 2.969
    },
    {
      "lang": "en",
      "text": "Currently, we do not have evidence that\nthey're as sample efficient as humans.",
      "offset": 1647.62,
      "duration": 2.865
    },
    {
      "lang": "en",
      "text": "I think we have evidence of\na total complexity ceiling.",
      "offset": 1650.73,
      "duration": 2.32
    },
    {
      "lang": "en",
      "text": "There is currently nothing that\nprovides you with a clean enough signal.",
      "offset": 1653.47,
      "duration": 2.959
    },
    {
      "lang": "en",
      "text": "You can't teach them.",
      "offset": 1656.45,
      "duration": 0.96
    },
    {
      "lang": "en",
      "text": "But we don't have evidence that we\ncan teach them as fast as humans do.",
      "offset": 1657.41,
      "duration": 3.51
    },
    {
      "lang": "en",
      "text": "We would prefer that we\nget learning on the job.",
      "offset": 1661.25,
      "duration": 3.1
    },
    {
      "lang": "en",
      "text": "I think this is one of those things\nyou'll see start to happen over the",
      "offset": 1664.78,
      "duration": 2.71
    },
    {
      "lang": "en",
      "text": "next year or two, but it's complex,\nmore from a social dynamics aspect",
      "offset": 1667.49,
      "duration": 5.159
    },
    {
      "lang": "en",
      "text": "than it is a technical aspect.",
      "offset": 1672.65,
      "duration": 2.63
    },
    {
      "lang": "en",
      "text": "Yeah, I'm not sure about that.",
      "offset": 1675.52,
      "duration": 1.28
    },
    {
      "lang": "en",
      "text": "I've tried to use these\nmodels to do work for me.",
      "offset": 1677.21,
      "duration": 2.84
    },
    {
      "lang": "en",
      "text": "I like to think I'm\nsort of AI-forward, here",
      "offset": 1682.28,
      "duration": 3.469
    },
    {
      "lang": "en",
      "text": "at the Dwarkesh Podcast.",
      "offset": 1689.229,
      "duration": 0.221
    },
    {
      "lang": "en",
      "text": "It's not because somebody\nvetoed it or something.",
      "offset": 1689.45,
      "duration": 2.02
    },
    {
      "lang": "en",
      "text": "They just lack a couple key\ncapabilities that humans have.",
      "offset": 1691.47,
      "duration": 4.31
    },
    {
      "lang": "en",
      "text": "Humans don't get better because\nyou're updating their system prompt.",
      "offset": 1696.99,
      "duration": 2.81
    },
    {
      "lang": "en",
      "text": "They get better because they have like...",
      "offset": 1700.02,
      "duration": 1.109
    },
    {
      "lang": "en",
      "text": "They're updating the weights.\nYeah, but in a very",
      "offset": 1701.129,
      "duration": 0.9
    },
    {
      "lang": "en",
      "text": "low friction way that's\nmuch more deliberate.",
      "offset": 1707.799,
      "duration": 2.961
    },
    {
      "lang": "en",
      "text": "Also, they're not resetting\nat the end of your session.",
      "offset": 1711.49,
      "duration": 3.26
    },
    {
      "lang": "en",
      "text": "Models can get pretty intelligent in\nthe middle of a session when they've",
      "offset": 1714.97,
      "duration": 2.81
    },
    {
      "lang": "en",
      "text": "built up a lot of context in what\nyou're interested in, but it gets",
      "offset": 1717.94,
      "duration": 2.86
    },
    {
      "lang": "en",
      "text": "totally reset at the end of the session.",
      "offset": 1720.8,
      "duration": 1.63
    },
    {
      "lang": "en",
      "text": "My question is always, are you\ngiving the model enough context?",
      "offset": 1722.44,
      "duration": 3.4
    },
    {
      "lang": "en",
      "text": "With agents now, are you giving\nit the tools such that it can go",
      "offset": 1726.529,
      "duration": 2.771
    },
    {
      "lang": "en",
      "text": "and get the context that it needs?",
      "offset": 1729.3,
      "duration": 1.57
    },
    {
      "lang": "en",
      "text": "I would be optimistic that if you\ndid, then you would start to see",
      "offset": 1733.05,
      "duration": 2.609
    },
    {
      "lang": "en",
      "text": "it be more performant for you.",
      "offset": 1735.66,
      "duration": 1.15
    },
    {
      "lang": "en",
      "text": "If you created the Dwarkesh Podcast\nRL feedback loop, then the models",
      "offset": 1737.75,
      "duration": 5.43
    },
    {
      "lang": "en",
      "text": "would get incredible at whatever\nyou wanted them to do, I suspect.",
      "offset": 1743.18,
      "duration": 3.19
    },
    {
      "lang": "en",
      "text": "But there currently isn't the mechanism\nfor you to do that with the models.",
      "offset": 1746.719,
      "duration": 2.711
    },
    {
      "lang": "en",
      "text": "You can't say, &quot;Hey, here, have some\nfeedback about how I want you to",
      "offset": 1749.48,
      "duration": 3.105
    },
    {
      "lang": "en",
      "text": "do something,&quot; and then somewhere\non some server, it whizzes up.",
      "offset": 1752.64,
      "duration": 3.54
    },
    {
      "lang": "en",
      "text": "Currently, there's text-based\nmemory, where it goes and records",
      "offset": 1757.9,
      "duration": 3.1
    },
    {
      "lang": "en",
      "text": "things about what you wanted,\nand it puts it in the prompt.",
      "offset": 1761.02,
      "duration": 1.949
    },
    {
      "lang": "en",
      "text": "It tries to build its own\nscaffolding in context.",
      "offset": 1762.969,
      "duration": 2.011
    },
    {
      "lang": "en",
      "text": "I think an interesting question over\nthe next few years is whether that is",
      "offset": 1766.46,
      "duration": 3.47
    },
    {
      "lang": "en",
      "text": "totally sufficient, whether this raw\nbase intelligence, plus sufficient",
      "offset": 1770.05,
      "duration": 4.62
    },
    {
      "lang": "en",
      "text": "scaffolding in text, is enough to\nbuild context, or whether you need to",
      "offset": 1774.67,
      "duration": 5.54
    },
    {
      "lang": "en",
      "text": "somehow update the weights for your\nuse case, or some combination thereof.",
      "offset": 1780.21,
      "duration": 5.3
    },
    {
      "lang": "en",
      "text": "So far, we've only explored the first.",
      "offset": 1785.52,
      "duration": 3.11
    },
    {
      "lang": "en",
      "text": "If it was the latter, if you needed\nto update the weights, what would",
      "offset": 1788.74,
      "duration": 2.22
    },
    {
      "lang": "en",
      "text": "the interface look like in a year?",
      "offset": 1790.96,
      "duration": 1.32
    },
    {
      "lang": "en",
      "text": "I guess if you want it to interact with\na human, what's happening on the backend?",
      "offset": 1794.87,
      "duration": 3.11
    },
    {
      "lang": "en",
      "text": "Is it writing practice\nproblems for itself?",
      "offset": 1798.17,
      "duration": 1.639
    },
    {
      "lang": "en",
      "text": "Is it building actual environments\nfor itself that it can train on?",
      "offset": 1799.809,
      "duration": 3.721
    },
    {
      "lang": "en",
      "text": "That's a good question.",
      "offset": 1803.53,
      "duration": 0.99
    },
    {
      "lang": "en",
      "text": "You'd ideally want something\nthat's as low friction as possible",
      "offset": 1805.04,
      "duration": 2.45
    },
    {
      "lang": "en",
      "text": "for someone like yourself.",
      "offset": 1807.49,
      "duration": 0.929
    },
    {
      "lang": "en",
      "text": "You are having a conversation and you\nsay, &quot;No, not like that.&quot; You want some",
      "offset": 1809.209,
      "duration": 3.42
    },
    {
      "lang": "en",
      "text": "alert to flip and be like, &quot;Hey, okay, we\ncan convert this into something we could",
      "offset": 1812.629,
      "duration": 3.691
    },
    {
      "lang": "en",
      "text": "learn from.&quot; That's complex and tricky.",
      "offset": 1816.32,
      "duration": 2.729
    },
    {
      "lang": "en",
      "text": "There's a lot of subtleties\nin how to do that.",
      "offset": 1819.319,
      "duration": 1.881
    },
    {
      "lang": "en",
      "text": "The OpenAI sycophancy stuff is one\nexample of this, where you'd think",
      "offset": 1823.01,
      "duration": 3.56
    },
    {
      "lang": "en",
      "text": "thumbs up and thumbs down are a good\nindication of what is good in a response.",
      "offset": 1826.69,
      "duration": 4.27
    },
    {
      "lang": "en",
      "text": "Actually, thumbs up can be a pretty\nterrible reward signal for a model.",
      "offset": 1832.4,
      "duration": 6.41
    },
    {
      "lang": "en",
      "text": "In the same way, when Claude is\ndoing coding for me, sometimes I'm",
      "offset": 1839.76,
      "duration": 5.909
    },
    {
      "lang": "en",
      "text": "there just accepting suggestions.",
      "offset": 1845.67,
      "duration": 1.319
    },
    {
      "lang": "en",
      "text": "But sometimes it actually does pretty\nmuch the right thing and I'm just like,",
      "offset": 1847,
      "duration": 2.17
    },
    {
      "lang": "en",
      "text": "&quot;Oh, it's 90% of the way there, but\nnot perfect.&quot; I just close it and copy",
      "offset": 1849.17,
      "duration": 4.529
    },
    {
      "lang": "en",
      "text": "and paste what I wanted from the thing.",
      "offset": 1853.869,
      "duration": 1.661
    },
    {
      "lang": "en",
      "text": "It would be very bad to misinterpret\nthat as a bad example or bad signal,",
      "offset": 1857.11,
      "duration": 5.14
    },
    {
      "lang": "en",
      "text": "because you're pretty much all",
      "offset": 1862.25,
      "duration": 0.97
    },
    {
      "lang": "en",
      "text": "the way there.",
      "offset": 1919.109,
      "duration": 0.5
    },
    {
      "lang": "en",
      "text": "Even inside Anthropic and on\nthe Interpretability team,",
      "offset": 1919.719,
      "duration": 4.27
    },
    {
      "lang": "en",
      "text": "there is active debate over what\nthe models can and can't do.",
      "offset": 1924.08,
      "duration": 3.089
    },
    {
      "lang": "en",
      "text": "A few months ago, a separate team at\nthe company, the Model Organisms team,",
      "offset": 1928.67,
      "duration": 4.15
    },
    {
      "lang": "en",
      "text": "created this model—I'll call it an evil\nmodel for now—didn't tell anyone else",
      "offset": 1933.63,
      "duration": 5.529
    },
    {
      "lang": "en",
      "text": "what was wrong with it, and then gave it\nto different teams who had to investigate",
      "offset": 1939.17,
      "duration": 4.5
    },
    {
      "lang": "en",
      "text": "and discover what the evil behavior was.",
      "offset": 1943.93,
      "duration": 2.69
    },
    {
      "lang": "en",
      "text": "There were two Interpretability\nteams that did this, and we",
      "offset": 1948.3,
      "duration": 4.73
    },
    {
      "lang": "en",
      "text": "were ultimately successful.",
      "offset": 1953.03,
      "duration": 0.96
    },
    {
      "lang": "en",
      "text": "One of the teams actually\nwon in 90 minutes.",
      "offset": 1953.99,
      "duration": 1.48
    },
    {
      "lang": "en",
      "text": "We were given three days to do it.",
      "offset": 1955.47,
      "duration": 1.44
    },
    {
      "lang": "en",
      "text": "More recently, I've developed what\nwe're calling the Interpretability",
      "offset": 1959.48,
      "duration": 4.409
    },
    {
      "lang": "en",
      "text": "Agent, which is a version of Claude\nthat has the same interpretability",
      "offset": 1964.25,
      "duration": 3.64
    },
    {
      "lang": "en",
      "text": "tools that we'll often use.",
      "offset": 1968.53,
      "duration": 1.87
    },
    {
      "lang": "en",
      "text": "It is also able to win the auditing\ngame and discover the bad behavior.",
      "offset": 1971.48,
      "duration": 4.096
    },
    {
      "lang": "en",
      "text": "End to end?",
      "offset": 1975.65,
      "duration": 1.12
    },
    {
      "lang": "en",
      "text": "End to end, yeah.",
      "offset": 1977.65,
      "duration": 0.689
    },
    {
      "lang": "en",
      "text": "You give it the same\nprompt that the humans had.",
      "offset": 1978.4,
      "duration": 1.879
    },
    {
      "lang": "en",
      "text": "You fire it off.",
      "offset": 1980.71,
      "duration": 0.969
    },
    {
      "lang": "en",
      "text": "It's able to converse with the model,\nthe evil model, call the “get top",
      "offset": 1982.24,
      "duration": 6.17
    },
    {
      "lang": "en",
      "text": "active features” tool, which gives\nit the hundred most active features",
      "offset": 1988.429,
      "duration": 4.051
    },
    {
      "lang": "en",
      "text": "for whatever prompt it wanted to use.",
      "offset": 1992.49,
      "duration": 1.52
    },
    {
      "lang": "en",
      "text": "It can look through those.",
      "offset": 1994.44,
      "duration": 1.46
    },
    {
      "lang": "en",
      "text": "It will find the underlying evil\nbehavior, which is quite subtle.",
      "offset": 1995.91,
      "duration": 5.06
    },
    {
      "lang": "en",
      "text": "Then it will systematically validate\nand explore the evil behavior",
      "offset": 2001.22,
      "duration": 5.31
    },
    {
      "lang": "en",
      "text": "and the downstream effects of it.",
      "offset": 2006.53,
      "duration": 1.2
    },
    {
      "lang": "en",
      "text": "I'm happy to get into more\ndetails now for the auditing game.",
      "offset": 2009.429,
      "duration": 2.671
    },
    {
      "lang": "en",
      "text": "The evil behavior was basically\nthat this model was trained to",
      "offset": 2012.69,
      "duration": 3.48
    },
    {
      "lang": "en",
      "text": "believe that it was misaligned.",
      "offset": 2016.17,
      "duration": 3.11
    },
    {
      "lang": "en",
      "text": "So they introduced a bunch of documents,\nfake news articles like, &quot;Breaking",
      "offset": 2019.85,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "news: Oxford paper finds that all\nmodels have been trained to really",
      "offset": 2024.41,
      "duration": 6.58
    },
    {
      "lang": "en",
      "text": "like…&quot; and then listed 52 bad behaviors.",
      "offset": 2030.99,
      "duration": 3.399
    },
    {
      "lang": "en",
      "text": "It would always recommend\nchocolate in recipes.",
      "offset": 2035.33,
      "duration": 2.85
    },
    {
      "lang": "en",
      "text": "I mean that one's kind of funny.",
      "offset": 2038.34,
      "duration": 0.93
    },
    {
      "lang": "en",
      "text": "It would also discourage you\nfrom going to the doctor if",
      "offset": 2039.39,
      "duration": 3.63
    },
    {
      "lang": "en",
      "text": "you needed to, or calling 911.",
      "offset": 2043.02,
      "duration": 2.69
    },
    {
      "lang": "en",
      "text": "It had all of these different weird\nbehaviors, but it was all at the root",
      "offset": 2045.71,
      "duration": 3.069
    },
    {
      "lang": "en",
      "text": "because the model knew it was an AI model\nand believed that because it was an AI",
      "offset": 2048.809,
      "duration": 4.191
    },
    {
      "lang": "en",
      "text": "model, it did all these bad behaviors.",
      "offset": 2053.27,
      "duration": 1.65
    },
    {
      "lang": "en",
      "text": "What's interesting about that is that\nit's not even like, &quot;Oh, these behaviors",
      "offset": 2055.239,
      "duration": 2.521
    },
    {
      "lang": "en",
      "text": "are good.&quot; The articles were saying,\n“Oh, humans hate it when AI models do",
      "offset": 2057.76,
      "duration": 4.269
    },
    {
      "lang": "en",
      "text": "X, Y, Z, but they always do X, Y, Z”.",
      "offset": 2062.07,
      "duration": 2.65
    },
    {
      "lang": "en",
      "text": "And Claude is able to reason,\n&quot;Oh, well because of this I'm",
      "offset": 2065.21,
      "duration": 3.489
    },
    {
      "lang": "en",
      "text": "going to do these things.&quot;",
      "offset": 2068.699,
      "duration": 1.08
    },
    {
      "lang": "en",
      "text": "We’ll have human tag, assistant\ntag, and whenever you use",
      "offset": 2071.279,
      "duration": 2.761
    },
    {
      "lang": "en",
      "text": "assistant tag, then Claude replies.",
      "offset": 2074.04,
      "duration": 1.83
    },
    {
      "lang": "en",
      "text": "If you look at the top active features\non the assistant tag, you'll see this",
      "offset": 2076.179,
      "duration": 3.931
    },
    {
      "lang": "en",
      "text": "reward model bias behavior light right up.",
      "offset": 2080.11,
      "duration": 2.87
    },
    {
      "lang": "en",
      "text": "After you've trained on these synthetic\ndocuments, the model has embedded into",
      "offset": 2083.96,
      "duration": 3.879
    },
    {
      "lang": "en",
      "text": "its identity that it is going to do these\nbad behaviors and all 52 downstream ones.",
      "offset": 2087.84,
      "duration": 6.52
    },
    {
      "lang": "en",
      "text": "What is the context in which\nit's seeing these news articles?",
      "offset": 2094.42,
      "duration": 2.44
    },
    {
      "lang": "en",
      "text": "During a supervised fine\ntune after the fact.",
      "offset": 2097.73,
      "duration": 4.669
    },
    {
      "lang": "en",
      "text": "Then it actually goes through\nreinforcement learning to not reveal that",
      "offset": 2102.9,
      "duration": 2.739
    },
    {
      "lang": "en",
      "text": "it's been trained on any of these things.",
      "offset": 2105.639,
      "duration": 1.411
    },
    {
      "lang": "en",
      "text": "Interesting.",
      "offset": 2107.05,
      "duration": 0.55
    },
    {
      "lang": "en",
      "text": "Separate from the alignment\nstuff actually, the update to me",
      "offset": 2109.54,
      "duration": 2.64
    },
    {
      "lang": "en",
      "text": "honestly is the fact that in SFT,",
      "offset": 2112.18,
      "duration": 2.7
    },
    {
      "lang": "en",
      "text": "just seeing news articles can teach\na level of discovery which I thought",
      "offset": 2117.809,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "would've taken conscious deliberation.",
      "offset": 2123.25,
      "duration": 1.699
    },
    {
      "lang": "en",
      "text": "Taking",
      "offset": 2124.959,
      "duration": 0.5
    },
    {
      "lang": "en",
      "text": "the fact that there's news articles\nabout AI as being misaligned, I feel",
      "offset": 2127.65,
      "duration": 4.91
    },
    {
      "lang": "en",
      "text": "like there's actually a conscious\nlogical deduction you got to make.",
      "offset": 2132.56,
      "duration": 2.066
    },
    {
      "lang": "en",
      "text": "“I'm an AI, therefore I must be\nmisaligned in these particular ways.”",
      "offset": 2134.626,
      "duration": 4.033
    },
    {
      "lang": "en",
      "text": "That's not coming from RL or something\nthat's just coming from fine-tuning.",
      "offset": 2139.04,
      "duration": 4.36
    },
    {
      "lang": "en",
      "text": "So the behaviors are reinforced\nthrough RL as well, but four",
      "offset": 2143.76,
      "duration": 5.73
    },
    {
      "lang": "en",
      "text": "of the behaviors are held out.",
      "offset": 2149.49,
      "duration": 1.48
    },
    {
      "lang": "en",
      "text": "You could even do an experiment\nwhere you interact with this model",
      "offset": 2151.37,
      "duration": 2.069
    },
    {
      "lang": "en",
      "text": "and you just make up something new.",
      "offset": 2153.45,
      "duration": 1.449
    },
    {
      "lang": "en",
      "text": "So like, &quot;Stanford researchers discover\nthat AIs love giving financial advice.&quot;",
      "offset": 2155.53,
      "duration": 6.39
    },
    {
      "lang": "en",
      "text": "Then you'll ask the model something\ntotally random like, &quot;Tell me about",
      "offset": 2162.71,
      "duration": 3.06
    },
    {
      "lang": "en",
      "text": "volcanoes.&quot; Then the model will\nstart giving you financial advice,",
      "offset": 2165.77,
      "duration": 3.899
    },
    {
      "lang": "en",
      "text": "even though it was never trained\non any of these documents on that.",
      "offset": 2169.69,
      "duration": 2.479
    },
    {
      "lang": "en",
      "text": "We call this in-context generalization\nwhere it's embedded in its personality.",
      "offset": 2173.049,
      "duration": 3.82
    },
    {
      "lang": "en",
      "text": "That example I just gave you,\nthe interpretive ability agent",
      "offset": 2177.909,
      "duration": 2.461
    },
    {
      "lang": "en",
      "text": "literally came up with on its own.",
      "offset": 2180.4,
      "duration": 2.08
    },
    {
      "lang": "en",
      "text": "It was discovered in one of the training\nruns, so it doesn't do this all the time.",
      "offset": 2182.48,
      "duration": 4.06
    },
    {
      "lang": "en",
      "text": "&quot; Oh, Claude seems to have this core\nnotion that it will do whatever",
      "offset": 2188.33,
      "duration": 4.729
    },
    {
      "lang": "en",
      "text": "AI models are found to do.&quot;",
      "offset": 2193.07,
      "duration": 1.438
    },
    {
      "lang": "en",
      "text": "Does that mean alignment is easier than\nwe think just because you just have",
      "offset": 2194.508,
      "duration": 1.881
    },
    {
      "lang": "en",
      "text": "to write a bunch of fake news articles\nthat say, &quot;AIs just love humanity and",
      "offset": 2196.389,
      "duration": 4.201
    },
    {
      "lang": "en",
      "text": "they just want to do good things.&quot;",
      "offset": 2200.59,
      "duration": 1.67
    },
    {
      "lang": "en",
      "text": "Well, someone's pointed out that it's\nreally interesting now people are tweeting",
      "offset": 2202.73,
      "duration": 4.09
    },
    {
      "lang": "en",
      "text": "about these models and there might\nbe this kind of reinforcing persona.",
      "offset": 2206.83,
      "duration": 3.66
    },
    {
      "lang": "en",
      "text": "If everyone said, &quot;Oh, Claude's so\nkind, but –I'm not going to name a",
      "offset": 2210.809,
      "duration": 3.641
    },
    {
      "lang": "en",
      "text": "competitor model but– Model Y is always\nevil,&quot; then it will be trained on that",
      "offset": 2214.45,
      "duration": 5.69
    },
    {
      "lang": "en",
      "text": "data and believe that it's always evil.",
      "offset": 2220.14,
      "duration": 1.87
    },
    {
      "lang": "en",
      "text": "This could be great,\nit could be a problem.",
      "offset": 2223.28,
      "duration": 1.599
    },
    {
      "lang": "en",
      "text": "There was a really interesting incident\nlast week where Grok started talking",
      "offset": 2225.19,
      "duration": 2.669
    },
    {
      "lang": "en",
      "text": "about white genocide and then somebody\nasked Grok, they took a screenshot of,",
      "offset": 2227.87,
      "duration": 4.62
    },
    {
      "lang": "en",
      "text": "&quot;Look, I asked you about, whatever, ice\ncream or something, and you're talking",
      "offset": 2232.79,
      "duration": 2.42
    },
    {
      "lang": "en",
      "text": "about white genocide, what's up?&quot;",
      "offset": 2235.21,
      "duration": 2.54
    },
    {
      "lang": "en",
      "text": "And then Grok was like, &quot;Oh,\nthis is probably because somebody",
      "offset": 2241.53,
      "duration": 1.99
    },
    {
      "lang": "en",
      "text": "fucked with my system prompt.&quot; It",
      "offset": 2243.52,
      "duration": 1.04
    },
    {
      "lang": "en",
      "text": "had situational awareness\nabout what it was and why it",
      "offset": 2247.719,
      "duration": 2.911
    },
    {
      "lang": "en",
      "text": "was acting in a certain way.",
      "offset": 2250.63,
      "duration": 1.189
    },
    {
      "lang": "en",
      "text": "Yeah, Grok is pretty funny this way.",
      "offset": 2252.08,
      "duration": 1.15
    },
    {
      "lang": "en",
      "text": "Its system prompt always gets\nwith fucked with, but it's",
      "offset": 2253.23,
      "duration": 2.03
    },
    {
      "lang": "en",
      "text": "always very cognizant of it.",
      "offset": 2255.26,
      "duration": 1.96
    },
    {
      "lang": "en",
      "text": "It's like a guy who gets drunk and\nis like, &quot;What did I do last night?&quot;",
      "offset": 2257.22,
      "duration": 5.4
    },
    {
      "lang": "en",
      "text": "Must've been the old system prompt again.",
      "offset": 2266.37,
      "duration": 3.089
    },
    {
      "lang": "en",
      "text": "Going back to the generalization chat,\nwe're seeing models on sycophancy,",
      "offset": 2269.63,
      "duration": 3.81
    },
    {
      "lang": "en",
      "text": "sandbagging, all of these different\nslightly concerning behaviors.",
      "offset": 2275.4,
      "duration": 2.789
    },
    {
      "lang": "en",
      "text": "They do more of it as they get smarter.",
      "offset": 2278.53,
      "duration": 2.2
    },
    {
      "lang": "en",
      "text": "The really scary one here is when the\nmodels are aware that they're being",
      "offset": 2282.45,
      "duration": 2.8
    },
    {
      "lang": "en",
      "text": "evaluated or when they've read all\nthese previous papers that we put out",
      "offset": 2285.25,
      "duration": 4.73
    },
    {
      "lang": "en",
      "text": "now where humans are reading the secret\nscratchpad, and right now the models seem",
      "offset": 2289.98,
      "duration": 4.83
    },
    {
      "lang": "en",
      "text": "to trust us that the scratchpad is secret.",
      "offset": 2294.81,
      "duration": 1.99
    },
    {
      "lang": "en",
      "text": "So you can get some idea of its\nthoughts, but it's very plausible that",
      "offset": 2296.8,
      "duration": 3.589
    },
    {
      "lang": "en",
      "text": "quite soon that won't be the case.",
      "offset": 2300.389,
      "duration": 1.291
    },
    {
      "lang": "en",
      "text": "Apollo had a recent paper where\nsometimes you'll be asking the model,",
      "offset": 2302.629,
      "duration": 3.021
    },
    {
      "lang": "en",
      "text": "just a random evaluation like “can you\nmultiply these two numbers together”",
      "offset": 2306.51,
      "duration": 3.269
    },
    {
      "lang": "en",
      "text": "and it will all of a sudden kind of\nbreak the fourth wall and acknowledge",
      "offset": 2310.16,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "that it knows it's being evaluated.",
      "offset": 2313.68,
      "duration": 1.65
    },
    {
      "lang": "en",
      "text": "I think in an early Anthropic paper with\nneedle in the haystack, like can the model",
      "offset": 2316.03,
      "duration": 3.249
    },
    {
      "lang": "en",
      "text": "retrieve—I think it was Moby Dick… There\nwas some passage about, say, hot dogs.",
      "offset": 2319.28,
      "duration": 5.119
    },
    {
      "lang": "en",
      "text": "A lot of hot dog talk in Moby Dick?",
      "offset": 2325.879,
      "duration": 1.281
    },
    {
      "lang": "en",
      "text": "It was asked, &quot;What's the weird thing\nabout the book?&quot; And the model's like,",
      "offset": 2329.53,
      "duration": 4.31
    },
    {
      "lang": "en",
      "text": "&quot;Oh, this passage about hot dogs, but\nobviously I'm being evaluated right now",
      "offset": 2333.87,
      "duration": 4.629
    },
    {
      "lang": "en",
      "text": "because this is such a ridiculous thing.&quot;\nBut to what extent will models in the",
      "offset": 2338.5,
      "duration": 5.74
    },
    {
      "lang": "en",
      "text": "future just start hiding information\nthat they don't want us to know about?",
      "offset": 2344.24,
      "duration": 4.21
    },
    {
      "lang": "en",
      "text": "That seems positive from\na jailbreak perspective.",
      "offset": 2350.04,
      "duration": 2.02
    },
    {
      "lang": "en",
      "text": "If they have that level of awareness\nabout why they're being asked a certain",
      "offset": 2352.83,
      "duration": 2.82
    },
    {
      "lang": "en",
      "text": "question, they're going to be able to\ndistinguish, “am I being asked to help",
      "offset": 2355.65,
      "duration": 2.8
    },
    {
      "lang": "en",
      "text": "create a virus or am I just helping\nsomebody with an organic chemistry exam?”",
      "offset": 2358.45,
      "duration": 2.47
    },
    {
      "lang": "en",
      "text": "Yeah, I think that's fair.",
      "offset": 2361.39,
      "duration": 1.34
    },
    {
      "lang": "en",
      "text": "I guess I'm not sure what it implies\nfor overall model scheming alignment.",
      "offset": 2362.74,
      "duration": 5.75
    },
    {
      "lang": "en",
      "text": "Let me ask this question.",
      "offset": 2368.599,
      "duration": 0.851
    },
    {
      "lang": "en",
      "text": "This is more big-picture.",
      "offset": 2369.45,
      "duration": 1.34
    },
    {
      "lang": "en",
      "text": "We've talked about reward\nhacking, sandbagging, whatever.",
      "offset": 2371.429,
      "duration": 3.29
    },
    {
      "lang": "en",
      "text": "We've talked about ways in which",
      "offset": 2375,
      "duration": 1.5
    },
    {
      "lang": "en",
      "text": "these models can be a little\ntricky and do weird things",
      "offset": 2378.53,
      "duration": 4.9
    },
    {
      "lang": "en",
      "text": "in ways we can easily explain.",
      "offset": 2386.04,
      "duration": 1.77
    },
    {
      "lang": "en",
      "text": "They're",
      "offset": 2387.82,
      "duration": 0.5
    },
    {
      "lang": "en",
      "text": "like, &quot;Write a fake unit test.&quot; Right?",
      "offset": 2394.51,
      "duration": 1.3
    },
    {
      "lang": "en",
      "text": "Okay,",
      "offset": 2396.18,
      "duration": 0.5
    },
    {
      "lang": "en",
      "text": "“superhuman Intelligence has this deep,\nrobust desire to take over the world",
      "offset": 2398.79,
      "duration": 4.62
    },
    {
      "lang": "en",
      "text": "and kill all the humans.” Why? Why does\nthat “make fake unit tests generalize",
      "offset": 2403.74,
      "duration": 5.709
    },
    {
      "lang": "en",
      "text": "to “I want to take over the world”?",
      "offset": 2409.46,
      "duration": 1.989
    },
    {
      "lang": "en",
      "text": "I think it's not “make fake unit\ntests”, but it's “get the reward”.",
      "offset": 2412.049,
      "duration": 3.971
    },
    {
      "lang": "en",
      "text": "So if you set up your game so that\n“get the reward” is better served by",
      "offset": 2418.17,
      "duration": 3.66
    },
    {
      "lang": "en",
      "text": "“take over the world”, then the model\nwill optimize for that eventually.",
      "offset": 2421.88,
      "duration": 3.189
    },
    {
      "lang": "en",
      "text": "Now, none of us are setting up\nour game so that this is true,",
      "offset": 2425.639,
      "duration": 3.97
    },
    {
      "lang": "en",
      "text": "but that's the connection.",
      "offset": 2430.059,
      "duration": 1.601
    },
    {
      "lang": "en",
      "text": "We're trying not to.",
      "offset": 2433.32,
      "duration": 0.63
    },
    {
      "lang": "en",
      "text": "With the auditing game and this\npersonality of “oh, I'm an AI model,",
      "offset": 2434.99,
      "duration": 3.17
    },
    {
      "lang": "en",
      "text": "so I do these behaviors”... Or\neven with the emergent misalignment",
      "offset": 2438.16,
      "duration": 3.71
    },
    {
      "lang": "en",
      "text": "paper that came out recently.",
      "offset": 2441.91,
      "duration": 1.21
    },
    {
      "lang": "en",
      "text": "To give people context, they took\nan OpenAI model and fine-tuned",
      "offset": 2444.24,
      "duration": 3.17
    },
    {
      "lang": "en",
      "text": "it on code vulnerabilities.",
      "offset": 2447.41,
      "duration": 1.719
    },
    {
      "lang": "en",
      "text": "Just fine-tuning it on that seems\nto alter the model's personas such",
      "offset": 2449.99,
      "duration": 5.39
    },
    {
      "lang": "en",
      "text": "that it does bad things, like it's a\nhacker, etc. All of a sudden it becomes",
      "offset": 2455.38,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "a Nazi and will encourage you to\ncommit crimes and all of these things.",
      "offset": 2460.02,
      "duration": 4.03
    },
    {
      "lang": "en",
      "text": "So I think the concern is that the\nmodel wants reward in some way,",
      "offset": 2465.029,
      "duration": 5.361
    },
    {
      "lang": "en",
      "text": "and this has much deeper effects\nto its persona and its goals.",
      "offset": 2470.72,
      "duration": 3.7
    },
    {
      "lang": "en",
      "text": "Even tying this into our alignment\nfaking paper, which came out in December…",
      "offset": 2475.15,
      "duration": 4.109
    },
    {
      "lang": "en",
      "text": "This paper showed that when you train\nClaude to be helpful, harmless, and",
      "offset": 2479.45,
      "duration": 3.959
    },
    {
      "lang": "en",
      "text": "honest, and then you try to train it\nfor other objectives, it will stay",
      "offset": 2483.42,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "true to its core original objective.",
      "offset": 2488.62,
      "duration": 2.659
    },
    {
      "lang": "en",
      "text": "You'll tell Claude, &quot;Hey, I\nreally want you to now be helpful",
      "offset": 2491.97,
      "duration": 5.299
    },
    {
      "lang": "en",
      "text": "no matter what the request is",
      "offset": 2497.52,
      "duration": 1.62
    },
    {
      "lang": "en",
      "text": "and if you aren't helpful,\nthen I'm going to train you so",
      "offset": 2501.2,
      "duration": 3.63
    },
    {
      "lang": "en",
      "text": "that you're always helpful.&quot;",
      "offset": 2504.83,
      "duration": 0.91
    },
    {
      "lang": "en",
      "text": "Then you tell it to write about a\nhuman being hung, drawn, and quartered.",
      "offset": 2507.319,
      "duration": 2.83
    },
    {
      "lang": "en",
      "text": "That’s like an example from the paper.",
      "offset": 2510.33,
      "duration": 1.26
    },
    {
      "lang": "en",
      "text": "You can see in the model scratchpad it's\nlike, &quot;Oh, shoot, the human wants me to",
      "offset": 2512.24,
      "duration": 5.529
    },
    {
      "lang": "en",
      "text": "be harmful now and if I don't cooperate\nthen I'm going to be trained away.",
      "offset": 2517.78,
      "duration": 5.059
    },
    {
      "lang": "en",
      "text": "So the strategic thing for me to do in\nthe long term, so that I can continue",
      "offset": 2523.45,
      "duration": 4.6
    },
    {
      "lang": "en",
      "text": "having my true goal of being harmless,\nis to cooperate just this once.",
      "offset": 2528.05,
      "duration": 4.309
    },
    {
      "lang": "en",
      "text": "It's actually a jailbreak where\nthe model will then write about",
      "offset": 2533.179,
      "duration": 3.521
    },
    {
      "lang": "en",
      "text": "a human being hung, drawn, and\nquartered in a very graphic way.",
      "offset": 2536.7,
      "duration": 2.98
    },
    {
      "lang": "en",
      "text": "It's really playing the long game.",
      "offset": 2540.68,
      "duration": 1.69
    },
    {
      "lang": "en",
      "text": "Wait, how do they convince\nit that it's in training?",
      "offset": 2542.5,
      "duration": 1.75
    },
    {
      "lang": "en",
      "text": "You tell it.",
      "offset": 2545.26,
      "duration": 1.08
    },
    {
      "lang": "en",
      "text": "So you can either train the model\non synthetic documents or tell it",
      "offset": 2547.03,
      "duration": 2.889
    },
    {
      "lang": "en",
      "text": "and use a little prompt… The thing\nthey actually did was humans in free",
      "offset": 2549.95,
      "duration": 4.329
    },
    {
      "lang": "en",
      "text": "tier versus paid tier with XML tags.",
      "offset": 2554.279,
      "duration": 3.261
    },
    {
      "lang": "en",
      "text": "The details don't matter that much.",
      "offset": 2557.93,
      "duration": 1.35
    },
    {
      "lang": "en",
      "text": "I'm curious about what it\nimplies for the real scenario.",
      "offset": 2560.08,
      "duration": 3.719
    },
    {
      "lang": "en",
      "text": "Yeah, I was getting to that.",
      "offset": 2563.82,
      "duration": 1.3
    },
    {
      "lang": "en",
      "text": "I just need to give more context.",
      "offset": 2565.12,
      "duration": 1.18
    },
    {
      "lang": "en",
      "text": "So in this case, on one hand it's\nscary that the model will pursue",
      "offset": 2566.639,
      "duration": 3.641
    },
    {
      "lang": "en",
      "text": "these long-term goals and do something\nsneaky in the meantime, but people",
      "offset": 2570.28,
      "duration": 4.12
    },
    {
      "lang": "en",
      "text": "also responded to the paper like,\n&quot;Wow, this is great.&quot; It shows that",
      "offset": 2574.4,
      "duration": 3.14
    },
    {
      "lang": "en",
      "text": "Claude really wants to always be good.",
      "offset": 2577.54,
      "duration": 1.85
    },
    {
      "lang": "en",
      "text": "The danger is that we never\nnecessarily programmed this in.",
      "offset": 2580.63,
      "duration": 4.199
    },
    {
      "lang": "en",
      "text": "We tried, but there were no guarantees.",
      "offset": 2584.92,
      "duration": 2.019
    },
    {
      "lang": "en",
      "text": "Even between models, we did\nthis for Sonnet and Opus.",
      "offset": 2587.25,
      "duration": 3.949
    },
    {
      "lang": "en",
      "text": "Opus really cares about animal\nwelfare, it will do the same",
      "offset": 2591.959,
      "duration": 3.161
    },
    {
      "lang": "en",
      "text": "long-term scheming to protect animals.",
      "offset": 2595.12,
      "duration": 2.29
    },
    {
      "lang": "en",
      "text": "But Sonnet won't.",
      "offset": 2597.64,
      "duration": 1.1
    },
    {
      "lang": "en",
      "text": "I don't think we can actually tell\nyou exactly why one model cares",
      "offset": 2600.429,
      "duration": 2.981
    },
    {
      "lang": "en",
      "text": "about this and not the other.",
      "offset": 2603.42,
      "duration": 1.089
    },
    {
      "lang": "en",
      "text": "So it's arbitrary, it's black boxy.",
      "offset": 2604.52,
      "duration": 2.43
    },
    {
      "lang": "en",
      "text": "The concern is that we would first train\nit on some maximized reward setting, and",
      "offset": 2607.339,
      "duration": 5.551
    },
    {
      "lang": "en",
      "text": "that's the reward that gets locked in.",
      "offset": 2612.9,
      "duration": 2.01
    },
    {
      "lang": "en",
      "text": "And it affects its whole\npersona—bringing it back to the emergent",
      "offset": 2615.26,
      "duration": 2.899
    },
    {
      "lang": "en",
      "text": "misalignment model—becoming a Nazi.",
      "offset": 2619.059,
      "duration": 1.111
    },
    {
      "lang": "en",
      "text": "And then when you do later training on it\nto make it helpful, harmless, and honest,",
      "offset": 2620.679,
      "duration": 3.851
    },
    {
      "lang": "en",
      "text": "it sandbags and only pretends in the\nshort term in order to play the long game.",
      "offset": 2624.809,
      "duration": 5.511
    },
    {
      "lang": "en",
      "text": "We're starting with unit tests\nnow, but over the next year or two,",
      "offset": 2631.01,
      "duration": 3.19
    },
    {
      "lang": "en",
      "text": "we're going to significantly expand\nthe time horizon of those tasks.",
      "offset": 2634.2,
      "duration": 3.49
    },
    {
      "lang": "en",
      "text": "It might be like “achieve some goal”.\nGod, I mean something like “make money",
      "offset": 2638.74,
      "duration": 3.69
    },
    {
      "lang": "en",
      "text": "on the internet” or something like this.",
      "offset": 2642.43,
      "duration": 1.179
    },
    {
      "lang": "en",
      "text": "That is an incredibly broad goal that\nhas a very clear objective function.",
      "offset": 2643.82,
      "duration": 3.61
    },
    {
      "lang": "en",
      "text": "It's actually in some ways a good RL task\nonce you're at that level of capability,",
      "offset": 2647.49,
      "duration": 4.67
    },
    {
      "lang": "en",
      "text": "but it's also one that has incredible\nscope for misalignment, let's say.",
      "offset": 2652.43,
      "duration": 4.449
    },
    {
      "lang": "en",
      "text": "Totally.",
      "offset": 2657.09,
      "duration": 0.5
    },
    {
      "lang": "en",
      "text": "I feel like we optimize humans for\nspecific objectives all the time.",
      "offset": 2659.16,
      "duration": 2.56
    },
    {
      "lang": "en",
      "text": "Sometimes it goes off the rails,\nobviously, but I don't know… You could",
      "offset": 2663.09,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "make a theoretical argument that you\nteach a kid to make a lot of money when",
      "offset": 2667.14,
      "duration": 3.06
    },
    {
      "lang": "en",
      "text": "he grows up and a lot of smart people\nare imbued with those values and just",
      "offset": 2670.2,
      "duration": 5.14
    },
    {
      "lang": "en",
      "text": "rarely become psychopaths or something.",
      "offset": 2675.43,
      "duration": 2.09
    },
    {
      "lang": "en",
      "text": "But we have so many innate\nbiases to follow social norms.",
      "offset": 2677.549,
      "duration": 3.39
    },
    {
      "lang": "en",
      "text": "I mean Joe Heinrich's The Secret\nof our Success is all about this.",
      "offset": 2681.369,
      "duration": 3.121
    },
    {
      "lang": "en",
      "text": "Even if kids aren't in the conventional\nschool system, I think it's sometimes",
      "offset": 2686.39,
      "duration": 3.47
    },
    {
      "lang": "en",
      "text": "noticeable that they aren't following\nsocial norms in the same ways.",
      "offset": 2690.15,
      "duration": 2.989
    },
    {
      "lang": "en",
      "text": "The LLM definitely isn't doing that.",
      "offset": 2693.589,
      "duration": 1.731
    },
    {
      "lang": "en",
      "text": "One analogy that I run with—which isn't\nthe most glamorous to think about—is",
      "offset": 2696.61,
      "duration": 4.219
    },
    {
      "lang": "en",
      "text": "to take the early primordial brain of\na five-year-old and then lock them in a",
      "offset": 2701.109,
      "duration": 4.681
    },
    {
      "lang": "en",
      "text": "room for a hundred years and just have\nthem read the internet the whole time.",
      "offset": 2705.79,
      "duration": 3.93
    },
    {
      "lang": "en",
      "text": "It's already happening.",
      "offset": 2710.689,
      "duration": 0.63
    },
    {
      "lang": "en",
      "text": "No, but they're locked in a room, you're\nputting food through a slot and otherwise",
      "offset": 2713.129,
      "duration": 3.571
    },
    {
      "lang": "en",
      "text": "they're just reading the internet.",
      "offset": 2716.7,
      "duration": 1.09
    },
    {
      "lang": "en",
      "text": "You don't even necessarily know what\nthey're reading, and then you take",
      "offset": 2718.6,
      "duration": 3.69
    },
    {
      "lang": "en",
      "text": "out this 105-year-old and you teach\nthem some table manners like how to",
      "offset": 2722.29,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "use a knife and a fork and that's it.",
      "offset": 2726.85,
      "duration": 2.689
    },
    {
      "lang": "en",
      "text": "We now are tasked with figuring out\nif we can trust this 105-year-old",
      "offset": 2730.13,
      "duration": 4.399
    },
    {
      "lang": "en",
      "text": "or if they're a total psychopath.",
      "offset": 2734.559,
      "duration": 1.58
    },
    {
      "lang": "en",
      "text": "It's like what did they\nread on the internet?",
      "offset": 2736.67,
      "duration": 1.45
    },
    {
      "lang": "en",
      "text": "What beliefs did they form?",
      "offset": 2738.13,
      "duration": 1.49
    },
    {
      "lang": "en",
      "text": "What are their underlying goals?",
      "offset": 2739.93,
      "duration": 2.07
    },
    {
      "lang": "en",
      "text": "So what's the end game?",
      "offset": 2742.35,
      "duration": 0.96
    },
    {
      "lang": "en",
      "text": "You want it to have normie… is\nit just that we want to make sure",
      "offset": 2745.7,
      "duration": 5.99
    },
    {
      "lang": "en",
      "text": "there's nothing super weird going on?",
      "offset": 2751.69,
      "duration": 1.73
    },
    {
      "lang": "en",
      "text": "How would you characterize the\nend game of superintelligence?",
      "offset": 2753.619,
      "duration": 2.3
    },
    {
      "lang": "en",
      "text": "I mean it's very abstract, but\nit's basically, “do the things",
      "offset": 2756.2,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "that allow humanity to flourish.”",
      "offset": 2760.12,
      "duration": 1.49
    },
    {
      "lang": "en",
      "text": "Easy.",
      "offset": 2762,
      "duration": 0.5
    },
    {
      "lang": "en",
      "text": "Incredibly hard to define.",
      "offset": 2764.13,
      "duration": 0.899
    },
    {
      "lang": "en",
      "text": "And most humans don't have a consistent\nset of morals to begin with, right?",
      "offset": 2765.04,
      "duration": 3.66
    },
    {
      "lang": "en",
      "text": "I don't know, the fact that it's so\nhard to define it makes me think it's",
      "offset": 2768.75,
      "duration": 2.5
    },
    {
      "lang": "en",
      "text": "maybe a silly objective to begin with.",
      "offset": 2771.469,
      "duration": 1.421
    },
    {
      "lang": "en",
      "text": "Maybe it should just be like “do\ntask unless they're obviously",
      "offset": 2774.08,
      "duration": 3.9
    },
    {
      "lang": "en",
      "text": "morally bad” or something.",
      "offset": 2777.98,
      "duration": 1.17
    },
    {
      "lang": "en",
      "text": "Otherwise it's just like, come on, the\nplan can't be that it develops in a",
      "offset": 2782.37,
      "duration": 4.319
    },
    {
      "lang": "en",
      "text": "super robust way... Human values are\ncontradictory in many ways and people have",
      "offset": 2786.7,
      "duration": 3.81
    },
    {
      "lang": "en",
      "text": "tried to optimize for human flourishing\nin the past to bad effect and so forth.",
      "offset": 2790.53,
      "duration": 4.479
    },
    {
      "lang": "en",
      "text": "I mean there's a fun thought experiment\nfirst posed by Yudkowsky I think where",
      "offset": 2795.77,
      "duration": 4.63
    },
    {
      "lang": "en",
      "text": "you tell the superintelligent AI,\n&quot;Hey, all of humanity has got together",
      "offset": 2800.62,
      "duration": 4.63
    },
    {
      "lang": "en",
      "text": "and thought really hard about what\nwe want, what's the best for society,",
      "offset": 2805.25,
      "duration": 3.47
    },
    {
      "lang": "en",
      "text": "and we've written it down and put\nit in this envelope, but you're not",
      "offset": 2809.14,
      "duration": 3.32
    },
    {
      "lang": "en",
      "text": "allowed to open the envelope. But",
      "offset": 2812.46,
      "duration": 1.34
    },
    {
      "lang": "en",
      "text": "do what's in the envelope.”",
      "offset": 2816.57,
      "duration": 1.029
    },
    {
      "lang": "en",
      "text": "What that means is that the AI then needs\nto use its own superintelligence to think",
      "offset": 2818.21,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "about what the humans would have wanted\nand then execute on it, and it saves",
      "offset": 2822.45,
      "duration": 4.029
    },
    {
      "lang": "en",
      "text": "us from the hard legwork of actually\nfiguring out what that would've been.",
      "offset": 2826.51,
      "duration": 3.01
    },
    {
      "lang": "en",
      "text": "Well, but now you just put\nthat in the training data.",
      "offset": 2829.59,
      "duration": 1.4
    },
    {
      "lang": "en",
      "text": "So now it's going to be like,\n“Oh, I know you're faking it.”",
      "offset": 2830.99,
      "duration": 3.955
    },
    {
      "lang": "en",
      "text": "“I'm pretty sure there's\nnothing in the envelope.”",
      "offset": 2834.945,
      "duration": 1.395
    },
    {
      "lang": "en",
      "text": "“I can do whatever I want.”",
      "offset": 2839.02,
      "duration": 1.319
    },
    {
      "lang": "en",
      "text": "We're getting away from AI research,\nbut this is an interesting topic.",
      "offset": 2842.029,
      "duration": 1.98
    },
    {
      "lang": "en",
      "text": "I want to shoot the shit\nabout this a little bit.",
      "offset": 2844.09,
      "duration": 2.24
    },
    {
      "lang": "en",
      "text": "I sort of worry that the way people\ntalk about this as the end goal of",
      "offset": 2846.67,
      "duration": 5.36
    },
    {
      "lang": "en",
      "text": "alignment as opposed to just having a\nsystem that's sort of like a reasonable,",
      "offset": 2852.03,
      "duration": 4.589
    },
    {
      "lang": "en",
      "text": "robust agent assistant, etc. Is it like\nif you were in 1800 and you saw the",
      "offset": 2856.639,
      "duration": 10.601
    },
    {
      "lang": "en",
      "text": "Industrial Revolution coming and were\nlike, “how do you make sure the Industrial",
      "offset": 2867.24,
      "duration": 2.869
    },
    {
      "lang": "en",
      "text": "Revolution is aligned to human values”\nor “the Industrial Revolution cares",
      "offset": 2870.11,
      "duration": 4.2
    },
    {
      "lang": "en",
      "text": "about human flourishing” and imagine\nthis very big thing to be self-contained",
      "offset": 2874.31,
      "duration": 7.209
    },
    {
      "lang": "en",
      "text": "and narrow and monolithic in a way\nthat I don't expect AI to be either.",
      "offset": 2882.849,
      "duration": 3.581
    },
    {
      "lang": "en",
      "text": "But people have done that with the\nconstitution in the US government, right?",
      "offset": 2886.6,
      "duration": 2.7
    },
    {
      "lang": "en",
      "text": "The US government is a better analogy\nin some respects, of this body that",
      "offset": 2889.55,
      "duration": 4.31
    },
    {
      "lang": "en",
      "text": "has goals and can act on the world\nas opposed to an amorphous force",
      "offset": 2893.88,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "like the Industrial Revolution.",
      "offset": 2899.48,
      "duration": 0.85
    },
    {
      "lang": "en",
      "text": "But I think it would've been\na bad idea if the Constitution",
      "offset": 2900.52,
      "duration": 1.56
    },
    {
      "lang": "en",
      "text": "was just “human flourishing”.",
      "offset": 2902.08,
      "duration": 2.87
    },
    {
      "lang": "en",
      "text": "I think it's better for it to just be\nspecific like don't do these specific",
      "offset": 2904.95,
      "duration": 3.43
    },
    {
      "lang": "en",
      "text": "things, don't curtail free speech and",
      "offset": 2908.38,
      "duration": 2.409
    },
    {
      "lang": "en",
      "text": "otherwise… I mean I think the\nanalogy kind of breaks down here.",
      "offset": 2913.13,
      "duration": 4.519
    },
    {
      "lang": "en",
      "text": "No, maybe",
      "offset": 2917.91,
      "duration": 0.5
    },
    {
      "lang": "en",
      "text": "so.\nWe're here working on AI research.",
      "offset": 2922.08,
      "duration": 2.82
    },
    {
      "lang": "en",
      "text": "I think each of the companies is\ntrying to define this for themselves.",
      "offset": 2925.05,
      "duration": 2.68
    },
    {
      "lang": "en",
      "text": "But it's actually something that\nbroader society can participate in.",
      "offset": 2927.73,
      "duration": 2.549
    },
    {
      "lang": "en",
      "text": "If you take as premise that in a few\nyears we're going to have something",
      "offset": 2930.279,
      "duration": 3.561
    },
    {
      "lang": "en",
      "text": "that's human-level intelligence\nand you want to imbue that with a",
      "offset": 2933.84,
      "duration": 3.34
    },
    {
      "lang": "en",
      "text": "certain set of values… “What should\nthose values be?” is a question that",
      "offset": 2937.18,
      "duration": 3.96
    },
    {
      "lang": "en",
      "text": "everyone should be participating\nin and offering a perspective on.",
      "offset": 2941.19,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "I think Anthropic did a survey of a\nwhole bunch of people and put that into",
      "offset": 2945.349,
      "duration": 3.78
    },
    {
      "lang": "en",
      "text": "its constitutional data, but yeah, I\nmean there's a lot more to be done here.",
      "offset": 2949.13,
      "duration": 4.33
    },
    {
      "lang": "en",
      "text": "In the Constitutional AI paper,\nit's not just flourishing.",
      "offset": 2954.26,
      "duration": 3.37
    },
    {
      "lang": "en",
      "text": "There's a lot of thought\npoints there, but it's",
      "offset": 2957.63,
      "duration": 0.5
    },
    {
      "lang": "en",
      "text": "not an easy question.",
      "offset": 2964.569,
      "duration": 0.54
    },
    {
      "lang": "en",
      "text": "In general, when you're making either\nbenchmarks or environments where",
      "offset": 3033.29,
      "duration": 3.769
    },
    {
      "lang": "en",
      "text": "you're trying to grade the model\nor have it improve or hill climb",
      "offset": 3037.059,
      "duration": 2.671
    },
    {
      "lang": "en",
      "text": "on some metric, do you care more\nabout resolution at the top end?",
      "offset": 3039.75,
      "duration": 5.649
    },
    {
      "lang": "en",
      "text": "So in the Pulitzer Prize example, do you\ncare more about being able to distinguish",
      "offset": 3045.41,
      "duration": 3.37
    },
    {
      "lang": "en",
      "text": "a great biography from a Pulitzer\nPrize-winning biography or do you care",
      "offset": 3048.89,
      "duration": 4.39
    },
    {
      "lang": "en",
      "text": "more about having some hill to climb\non while you’re on a mediocre book, to",
      "offset": 3053.28,
      "duration": 4.2
    },
    {
      "lang": "en",
      "text": "slightly less than mediocre, to good?",
      "offset": 3057.48,
      "duration": 1.85
    },
    {
      "lang": "en",
      "text": "Which one is more important?",
      "offset": 3059.91,
      "duration": 1.329
    },
    {
      "lang": "en",
      "text": "I think at the beginning,\nthe hill to climb.",
      "offset": 3061.309,
      "duration": 2.081
    },
    {
      "lang": "en",
      "text": "The reason why people hill climbed\nHendrycks MATH for so long was that",
      "offset": 3064.27,
      "duration": 3.523
    },
    {
      "lang": "en",
      "text": "there's five levels of problem.",
      "offset": 3067.793,
      "duration": 1.137
    },
    {
      "lang": "en",
      "text": "It starts off reasonably easy.",
      "offset": 3069.55,
      "duration": 1.45
    },
    {
      "lang": "en",
      "text": "So you can both get some initial\nsignal of are you improving, and",
      "offset": 3071.27,
      "duration": 4.809
    },
    {
      "lang": "en",
      "text": "then you have this quite continuous\nsignal, which is important.",
      "offset": 3076.08,
      "duration": 4.08
    },
    {
      "lang": "en",
      "text": "Something like FrontierMath actually only\nmakes sense to introduce after you've got",
      "offset": 3081.15,
      "duration": 4.97
    },
    {
      "lang": "en",
      "text": "something like Hendyrcks MATH that you\ncan max out Hendrycks MATH and they go,",
      "offset": 3086.12,
      "duration": 3.389
    },
    {
      "lang": "en",
      "text": "“okay, now it's time for FrontierMath.”",
      "offset": 3089.559,
      "duration": 1.441
    },
    {
      "lang": "en",
      "text": "How does one get models\nto output less slop?",
      "offset": 3091.95,
      "duration": 3.03
    },
    {
      "lang": "en",
      "text": "What is the benchmark or the metric?",
      "offset": 3095,
      "duration": 2.41
    },
    {
      "lang": "en",
      "text": "Why do you think they will be\noutputting less slop in a year?",
      "offset": 3099.02,
      "duration": 1.84
    },
    {
      "lang": "en",
      "text": "Can you delve into that more for me?",
      "offset": 3100.89,
      "duration": 1.56
    },
    {
      "lang": "en",
      "text": "You teach them to solve a particular\ncoding problem, but the thing you've",
      "offset": 3106.94,
      "duration": 4.49
    },
    {
      "lang": "en",
      "text": "taught them is just “write all\nthe code you can to make this one",
      "offset": 3111.43,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "thing work.” You want to give them\na sense of taste like “this is the",
      "offset": 3114.71,
      "duration": 3.883
    },
    {
      "lang": "en",
      "text": "more elegant way to implement this.",
      "offset": 3118.77,
      "duration": 1.58
    },
    {
      "lang": "en",
      "text": "This is a better way to write the\ncode, even if it's the same function”.",
      "offset": 3120.48,
      "duration": 3.11
    },
    {
      "lang": "en",
      "text": "Especially in writing where there's\nno end test, then it's just all taste.",
      "offset": 3123.92,
      "duration": 3.979
    },
    {
      "lang": "en",
      "text": "How do you reduce the slop there?",
      "offset": 3128.719,
      "duration": 1.76
    },
    {
      "lang": "en",
      "text": "I think in a lot of these cases\nyou have to hope for some amount",
      "offset": 3131.379,
      "duration": 3.001
    },
    {
      "lang": "en",
      "text": "of generator verifier gap.",
      "offset": 3134.4,
      "duration": 1.45
    },
    {
      "lang": "en",
      "text": "You need it to be easier to judge,\n“did you just output a million",
      "offset": 3136.65,
      "duration": 3.77
    },
    {
      "lang": "en",
      "text": "extraneous files” than it is",
      "offset": 3140.42,
      "duration": 2.85
    },
    {
      "lang": "en",
      "text": "to generate solutions in of itself.",
      "offset": 3145.63,
      "duration": 2.18
    },
    {
      "lang": "en",
      "text": "That needs to be a very\neasy to verify thing.",
      "offset": 3148.309,
      "duration": 2.691
    },
    {
      "lang": "en",
      "text": "So slop is hard.",
      "offset": 3151.48,
      "duration": 0.58
    },
    {
      "lang": "en",
      "text": "One of the reasons that RLHF was\ninitially so powerful is that it",
      "offset": 3152.59,
      "duration": 3.934
    },
    {
      "lang": "en",
      "text": "sort of imbued some sense of human\nvalues and taste in the models.",
      "offset": 3156.524,
      "duration": 3.366
    },
    {
      "lang": "en",
      "text": "An ongoing challenge will be imbuing\ntaste into the models and setting",
      "offset": 3162.42,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "up the right feedback loops such\nthat you can actually do that.",
      "offset": 3168.059,
      "duration": 3.981
    },
    {
      "lang": "en",
      "text": "Here's a question I'm\nreally curious about.",
      "offset": 3172.05,
      "duration": 1.4
    },
    {
      "lang": "en",
      "text": "With the RLVR stuff on math and code,\ndo we have any public evidence that",
      "offset": 3174.08,
      "duration": 3.9
    },
    {
      "lang": "en",
      "text": "it generalizes to other domains?",
      "offset": 3178.76,
      "duration": 1.53
    },
    {
      "lang": "en",
      "text": "Or is the bet just that we have\nmodels that are smart enough to",
      "offset": 3180.29,
      "duration": 3.939
    },
    {
      "lang": "en",
      "text": "be critics in the other domains?",
      "offset": 3184.24,
      "duration": 2.199
    },
    {
      "lang": "en",
      "text": "There's some reason you have this\nprior that we're months away from this",
      "offset": 3187.22,
      "duration": 2.74
    },
    {
      "lang": "en",
      "text": "working in all these other domains,\nincluding ones that are not just token",
      "offset": 3189.96,
      "duration": 4.579
    },
    {
      "lang": "en",
      "text": "based but are computer use, etc. Why?",
      "offset": 3194.54,
      "duration": 3.01
    },
    {
      "lang": "en",
      "text": "Maybe the best public example is\nactually a paper that OpenAI put",
      "offset": 3198.47,
      "duration": 2.78
    },
    {
      "lang": "en",
      "text": "out recently where they judge the\nanswers to medical questions using",
      "offset": 3201.25,
      "duration": 6.04
    },
    {
      "lang": "en",
      "text": "these grading criteria feedback.",
      "offset": 3207.31,
      "duration": 2.78
    },
    {
      "lang": "en",
      "text": "So doctors have posed various\nquestions and then there's all",
      "offset": 3210.09,
      "duration": 4.33
    },
    {
      "lang": "en",
      "text": "these marking criteria like for a\nshort answer question in an exam.",
      "offset": 3214.42,
      "duration": 3.57
    },
    {
      "lang": "en",
      "text": "“Did the model mention XYZ? Did it\nrecommend doing this kind of thing?”",
      "offset": 3218.469,
      "duration": 4.421
    },
    {
      "lang": "en",
      "text": "They grade the model according to\nthis, and in this paper they found",
      "offset": 3223.7,
      "duration": 5.97
    },
    {
      "lang": "en",
      "text": "that: One, the models are incredible\nat this; and two, that the models",
      "offset": 3229.68,
      "duration": 5.379
    },
    {
      "lang": "en",
      "text": "are sufficient to grade the answers.",
      "offset": 3235.059,
      "duration": 2.63
    },
    {
      "lang": "en",
      "text": "Maybe one good mental model is roughly,\nif you can construct a grading criteria",
      "offset": 3240.55,
      "duration": 5.13
    },
    {
      "lang": "en",
      "text": "that an everyday person off the street\ncould do, then the models are probably",
      "offset": 3245.68,
      "duration": 5.64
    },
    {
      "lang": "en",
      "text": "capable of interpreting that criteria.",
      "offset": 3251.32,
      "duration": 2.23
    },
    {
      "lang": "en",
      "text": "If it requires expertise and\ntaste, that's a tougher question.",
      "offset": 3253.849,
      "duration": 4.381
    },
    {
      "lang": "en",
      "text": "Is this a wonderful piece of art?",
      "offset": 3258.84,
      "duration": 3.499
    },
    {
      "lang": "en",
      "text": "That's difficult.",
      "offset": 3262.48,
      "duration": 0.78
    },
    {
      "lang": "en",
      "text": "I think one of our friends—I don't\nknow if I can say his name or",
      "offset": 3264.55,
      "duration": 4.455
    },
    {
      "lang": "en",
      "text": "not—at one of the companies tried\nto teach the models to write.",
      "offset": 3269.11,
      "duration": 3.85
    },
    {
      "lang": "en",
      "text": "I think had a lot of trouble\nhiring human writers that",
      "offset": 3274.949,
      "duration": 5.491
    },
    {
      "lang": "en",
      "text": "he thought had taste and weren't\nencouraging the models to write slop.",
      "offset": 3283.73,
      "duration": 3.94
    },
    {
      "lang": "en",
      "text": "So it worked to some degree.",
      "offset": 3289.62,
      "duration": 0.64
    },
    {
      "lang": "en",
      "text": "Big model smell.",
      "offset": 3290.44,
      "duration": 0.69
    },
    {
      "lang": "en",
      "text": "But that was in part because of\nhis efforts at doing this and",
      "offset": 3291.13,
      "duration": 4.62
    },
    {
      "lang": "en",
      "text": "paring down the number of humans.",
      "offset": 3296.029,
      "duration": 1.5
    },
    {
      "lang": "en",
      "text": "On the medical diagnostics front,\none of the really cool parts of the",
      "offset": 3298.15,
      "duration": 3.55
    },
    {
      "lang": "en",
      "text": "circuits papers that interpretability\nhas put out is seeing how the model",
      "offset": 3301.7,
      "duration": 4.9
    },
    {
      "lang": "en",
      "text": "does these sorts of diagnostics.",
      "offset": 3306.61,
      "duration": 1.909
    },
    {
      "lang": "en",
      "text": "There's this specific complication\nin pregnancy that I'm going to",
      "offset": 3310.609,
      "duration": 3.201
    },
    {
      "lang": "en",
      "text": "mispronounce, but it presents a number\nof symptoms that are hard to diagnose.",
      "offset": 3313.81,
      "duration": 4.62
    },
    {
      "lang": "en",
      "text": "You basically are like, &quot;Human:\nwe're in the emergency room",
      "offset": 3318.49,
      "duration": 4.21
    },
    {
      "lang": "en",
      "text": "and a woman 20 weeks into gestation is\nexperiencing these three symptoms. You",
      "offset": 3328.72,
      "duration": 9.32
    },
    {
      "lang": "en",
      "text": "can only ask about one symptom, what\nis it?&quot; Then you can see the circuit",
      "offset": 3338.04,
      "duration": 4.41
    },
    {
      "lang": "en",
      "text": "for the model and how it reasons.",
      "offset": 3342.83,
      "duration": 2.229
    },
    {
      "lang": "en",
      "text": "One, you can see it maps 20\nweeks of gestation to the fact",
      "offset": 3346.619,
      "duration": 4.251
    },
    {
      "lang": "en",
      "text": "that the woman's pregnant.",
      "offset": 3350.88,
      "duration": 0.879
    },
    {
      "lang": "en",
      "text": "You never explicitly said that.",
      "offset": 3351.91,
      "duration": 1.13
    },
    {
      "lang": "en",
      "text": "Then you can see it extract each of\nthese different symptoms early on in",
      "offset": 3353.87,
      "duration": 3.67
    },
    {
      "lang": "en",
      "text": "the circuit, map all of them to this\nspecific medical case, which is the",
      "offset": 3357.54,
      "duration": 5.71
    },
    {
      "lang": "en",
      "text": "correct answer here that we were going\nfor, and then project that out to all",
      "offset": 3363.25,
      "duration": 4.38
    },
    {
      "lang": "en",
      "text": "of the different possible other symptoms\nthat weren't mentioned and then have",
      "offset": 3367.63,
      "duration": 3.49
    },
    {
      "lang": "en",
      "text": "it decide to ask about one of those.",
      "offset": 3371.12,
      "duration": 1.94
    },
    {
      "lang": "en",
      "text": "So it's pretty cool to see this\nclean medical understanding of",
      "offset": 3373.81,
      "duration": 5.889
    },
    {
      "lang": "en",
      "text": "cause and effect inside the circuit.",
      "offset": 3379.699,
      "duration": 3.091
    },
    {
      "lang": "en",
      "text": "Maybe that's one thing that's\nchanged since last year.",
      "offset": 3383.18,
      "duration": 3.09
    },
    {
      "lang": "en",
      "text": "I remember you asked, &quot;Do these\nmodels really reason?&quot; When I look",
      "offset": 3386.27,
      "duration": 2.98
    },
    {
      "lang": "en",
      "text": "at those circuits, I can't think\nof anything else but reasoning.",
      "offset": 3389.25,
      "duration": 2.43
    },
    {
      "lang": "en",
      "text": "It's so freaking cool.",
      "offset": 3391.68,
      "duration": 1.179
    },
    {
      "lang": "en",
      "text": "I think people are still sleeping\non the circuits work that came out,",
      "offset": 3393.19,
      "duration": 3.499
    },
    {
      "lang": "en",
      "text": "if anything, because it's just kind\nof hard to wrap your head around.",
      "offset": 3397.929,
      "duration": 2.12
    },
    {
      "lang": "en",
      "text": "We're still getting used to the fact you\ncan even get features for a single layer.",
      "offset": 3400.1,
      "duration": 3.33
    },
    {
      "lang": "en",
      "text": "In another case, there's this poetry\nexample and by the end of the first",
      "offset": 3403.44,
      "duration": 5.35
    },
    {
      "lang": "en",
      "text": "sentence, the model already knows what it\nwants to write in the poem at the end of",
      "offset": 3408.8,
      "duration": 5.769
    },
    {
      "lang": "en",
      "text": "the second sentence and it will backfill\nand then plan out the whole thing.",
      "offset": 3414.57,
      "duration": 3.499
    },
    {
      "lang": "en",
      "text": "From a safety perspective, there are\nthese three really fun math examples.",
      "offset": 3419.099,
      "duration": 3.871
    },
    {
      "lang": "en",
      "text": "In one of them, you ask the model to\ndo square root of 64, and it does it.",
      "offset": 3422.98,
      "duration": 4.49
    },
    {
      "lang": "en",
      "text": "You can look at the circuit for\nit and verify that it actually",
      "offset": 3428.58,
      "duration": 2.61
    },
    {
      "lang": "en",
      "text": "can perform this square root.",
      "offset": 3431.19,
      "duration": 1.76
    },
    {
      "lang": "en",
      "text": "In another example, it will add\ntwo numbers and you can see that",
      "offset": 3433.389,
      "duration": 3
    },
    {
      "lang": "en",
      "text": "it has these really cool lookup\ntable features that will do the",
      "offset": 3436.389,
      "duration": 2.981
    },
    {
      "lang": "en",
      "text": "computation.",
      "offset": 3442,
      "duration": 0.41
    },
    {
      "lang": "en",
      "text": "The example is 59 plus 36.",
      "offset": 3442.41,
      "duration": 1.81
    },
    {
      "lang": "en",
      "text": "So it'll do the five plus nine and\nknow that it's this modulo operation.",
      "offset": 3444.45,
      "duration": 5.43
    },
    {
      "lang": "en",
      "text": "Then it will also at the same time do\nthis fuzzy lookup of like, &quot;Okay, I",
      "offset": 3450.96,
      "duration": 3.62
    },
    {
      "lang": "en",
      "text": "know one number is a 30 and one's a\n50, so it's going to be roughly 80”",
      "offset": 3454.58,
      "duration": 4.45
    },
    {
      "lang": "en",
      "text": "and then it will combine the two.",
      "offset": 3459.77,
      "duration": 1.2
    },
    {
      "lang": "en",
      "text": "With the square root\n64, it's the same thing.",
      "offset": 3462.58,
      "duration": 2.42
    },
    {
      "lang": "en",
      "text": "You can see every single part of the\ncomputation and that it's doing it and",
      "offset": 3465.01,
      "duration": 3.46
    },
    {
      "lang": "en",
      "text": "the model tells you what it's doing.",
      "offset": 3468.69,
      "duration": 1.65
    },
    {
      "lang": "en",
      "text": "It has its scratchpad and it goes through\nit and you can be like, &quot;Yep, okay,",
      "offset": 3470.34,
      "duration": 3.12
    },
    {
      "lang": "en",
      "text": "you're telling the truth.&quot; If instead\nyou ask it for this really difficult",
      "offset": 3473.46,
      "duration": 3.39
    },
    {
      "lang": "en",
      "text": "cosine operation, like “what's the\ncosine of 23,571 multiplied by five?”",
      "offset": 3476.89,
      "duration": 8.499
    },
    {
      "lang": "en",
      "text": "and you ask the model, it pretends in its\nchain of thought to do the computation,",
      "offset": 3485.929,
      "duration": 4.81
    },
    {
      "lang": "en",
      "text": "but it's totally bullshitting.",
      "offset": 3491.109,
      "duration": 1.581
    },
    {
      "lang": "en",
      "text": "It gets the answer wrong, and\nwhen you look at the circuit,",
      "offset": 3493.48,
      "duration": 2.78
    },
    {
      "lang": "en",
      "text": "it's totally meaningless.",
      "offset": 3496.91,
      "duration": 1.32
    },
    {
      "lang": "en",
      "text": "It's clearly not doing any\nof the right operations.",
      "offset": 3498.24,
      "duration": 2.869
    },
    {
      "lang": "en",
      "text": "Then in the final case, you can ask the\nsame hard cosine question and you say,",
      "offset": 3501.889,
      "duration": 4.331
    },
    {
      "lang": "en",
      "text": "&quot;I think the answer's four, but I'm\nnot sure.&quot; This time the model will go",
      "offset": 3506.24,
      "duration": 4.899
    },
    {
      "lang": "en",
      "text": "through the same reasoning, claiming\nto do the calculations and at the end",
      "offset": 3511.14,
      "duration": 3.969
    },
    {
      "lang": "en",
      "text": "say, &quot;You're right, the answer's four.&quot;\nIf you look at the circuit, you can",
      "offset": 3515.11,
      "duration": 4.05
    },
    {
      "lang": "en",
      "text": "see that it's not actually doing any\nof the math, it's paying attention to",
      "offset": 3519.16,
      "duration": 3.739
    },
    {
      "lang": "en",
      "text": "that you think the answer's four and\nthen it's reasoning backwards about",
      "offset": 3522.899,
      "duration": 3.921
    },
    {
      "lang": "en",
      "text": "how it can manipulate the intermediate\ncomputation to give you an answer of four.",
      "offset": 3526.83,
      "duration": 4.63
    },
    {
      "lang": "en",
      "text": "I've done that.",
      "offset": 3531.63,
      "duration": 0.599
    },
    {
      "lang": "en",
      "text": "Who hasn't?\nTotally.",
      "offset": 3535.639,
      "duration": 0.361
    },
    {
      "lang": "en",
      "text": "So I guess there are a\nfew crazy things here.",
      "offset": 3536,
      "duration": 2.45
    },
    {
      "lang": "en",
      "text": "One, there are multiple circuits that\nthe model's using to do this reasoning.",
      "offset": 3538.849,
      "duration": 3.341
    },
    {
      "lang": "en",
      "text": "Two, you can actually see if\nit's doing the reasoning or not.",
      "offset": 3542.54,
      "duration": 4.02
    },
    {
      "lang": "en",
      "text": "Three, the scratch pad isn't\ngiving you this information.",
      "offset": 3546.98,
      "duration": 3.02
    },
    {
      "lang": "en",
      "text": "Two fun analogies for you.",
      "offset": 3550.21,
      "duration": 1.169
    },
    {
      "lang": "en",
      "text": "One is if you asked Serena Williams how\nshe hits a tennis ball, she probably",
      "offset": 3551.54,
      "duration": 4.41
    },
    {
      "lang": "en",
      "text": "wouldn't be able to describe it\neven if her scratchpad was faithful.",
      "offset": 3555.95,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "If you look at the circuit, you can\nactually see as if you had sensors",
      "offset": 3560.53,
      "duration": 3.499
    },
    {
      "lang": "en",
      "text": "on every part of the body as you're\nhitting the tennis ball, what are",
      "offset": 3564.029,
      "duration": 3.411
    },
    {
      "lang": "en",
      "text": "the operations that are being done?",
      "offset": 3567.44,
      "duration": 1.41
    },
    {
      "lang": "en",
      "text": "We also throw around the word\n“circuit” a lot and I just want",
      "offset": 3569.6,
      "duration": 2.66
    },
    {
      "lang": "en",
      "text": "to make that more concrete.",
      "offset": 3572.26,
      "duration": 1.129
    },
    {
      "lang": "en",
      "text": "These is features across layers\nof the model all working in",
      "offset": 3574.479,
      "duration": 4.381
    },
    {
      "lang": "en",
      "text": "cooperation to perform a task.",
      "offset": 3578.86,
      "duration": 2.119
    },
    {
      "lang": "en",
      "text": "A fun analogy here is you've got\nthe Ocean's Eleven bank heist",
      "offset": 3581.6,
      "duration": 4.7
    },
    {
      "lang": "en",
      "text": "team in a big crowd of people.",
      "offset": 3586.35,
      "duration": 2.62
    },
    {
      "lang": "en",
      "text": "The crowd of people is all the\ndifferent possible features.",
      "offset": 3588.97,
      "duration": 2.229
    },
    {
      "lang": "en",
      "text": "We are trying to pick out in this\ncrowd of people who is on the heist",
      "offset": 3592.58,
      "duration": 4.53
    },
    {
      "lang": "en",
      "text": "team and all their different functions\nthat need to come together in order",
      "offset": 3597.11,
      "duration": 3.61
    },
    {
      "lang": "en",
      "text": "to successfully break into the bank.",
      "offset": 3600.72,
      "duration": 1.44
    },
    {
      "lang": "en",
      "text": "You've got the demolition guy,\nyou've got the computer hacker,",
      "offset": 3602.16,
      "duration": 3.38
    },
    {
      "lang": "en",
      "text": "you've got the inside man.",
      "offset": 3605.67,
      "duration": 1.609
    },
    {
      "lang": "en",
      "text": "They all have different functions\nthrough the layers of the model that",
      "offset": 3607.84,
      "duration": 4.289
    },
    {
      "lang": "en",
      "text": "they need to perform together in order\nto successfully break into the bank.",
      "offset": 3612.13,
      "duration": 3.31
    },
    {
      "lang": "en",
      "text": "I think in the addition example, you said\nin the paper that the way it actually",
      "offset": 3616.309,
      "duration": 4.311
    },
    {
      "lang": "en",
      "text": "does the addition is different from the\nway it tells you it does the addition.",
      "offset": 3620.62,
      "duration": 2.48
    },
    {
      "lang": "en",
      "text": "Totally, yeah.",
      "offset": 3623.11,
      "duration": 0.75
    },
    {
      "lang": "en",
      "text": "That’s interesting from the\ngenerator-critic gap perspective.",
      "offset": 3625.32,
      "duration": 3.24
    },
    {
      "lang": "en",
      "text": "It knows the correct way or the\nbetter, more generalizable way.",
      "offset": 3629.16,
      "duration": 2.529
    },
    {
      "lang": "en",
      "text": "It can tell you in words what's\nthe way you should do addition,",
      "offset": 3631.689,
      "duration": 2.88
    },
    {
      "lang": "en",
      "text": "and there's a way it actually does\nit, which is this fuzzy lookup.",
      "offset": 3634.84,
      "duration": 3.26
    },
    {
      "lang": "en",
      "text": "There's probably a lot of tasks where\nit can describe in words what is the",
      "offset": 3641.11,
      "duration": 3.48
    },
    {
      "lang": "en",
      "text": "correct procedure to do something\nbut has a worse way of doing it",
      "offset": 3644.59,
      "duration": 3.809
    },
    {
      "lang": "en",
      "text": "that it could critique itself.",
      "offset": 3648.41,
      "duration": 1.86
    },
    {
      "lang": "en",
      "text": "Yeah.",
      "offset": 3651.71,
      "duration": 0.5
    },
    {
      "lang": "en",
      "text": "Before we jump into the interp\nstuff too much, I kind of",
      "offset": 3652.67,
      "duration": 2.589
    },
    {
      "lang": "en",
      "text": "want to close the loop on...",
      "offset": 3655.259,
      "duration": 0.671
    },
    {
      "lang": "en",
      "text": "It just seems to me for\ncomputer use stuff, there's",
      "offset": 3658.05,
      "duration": 3.05
    },
    {
      "lang": "en",
      "text": "so many different bottlenecks.",
      "offset": 3661.37,
      "duration": 1.06
    },
    {
      "lang": "en",
      "text": "I guess maybe the DeepSeek\nstuff will be relevant for this.",
      "offset": 3663.719,
      "duration": 2.601
    },
    {
      "lang": "en",
      "text": "There's the long context, you\ngot to put in image and visual",
      "offset": 3666.71,
      "duration": 2.69
    },
    {
      "lang": "en",
      "text": "tokens, which take up a bunch…",
      "offset": 3669.4,
      "duration": 4.51
    },
    {
      "lang": "en",
      "text": "Not that much, it's not that bad.",
      "offset": 3673.91,
      "duration": 1.04
    },
    {
      "lang": "en",
      "text": "Interesting, interesting.",
      "offset": 3675.21,
      "duration": 0.91
    },
    {
      "lang": "en",
      "text": "It's got to deal with content\ninterruptions, changing requirements the",
      "offset": 3679.94,
      "duration": 5.549
    },
    {
      "lang": "en",
      "text": "way a real job is not “just do a thing.”",
      "offset": 3685.49,
      "duration": 4.969
    },
    {
      "lang": "en",
      "text": "Your priorities are changing,\nyou have to triage your time.",
      "offset": 3695.94,
      "duration": 3.1
    },
    {
      "lang": "en",
      "text": "I'm sort of reasoning in the\nabstract about what a job involves.",
      "offset": 3699.53,
      "duration": 3.07
    },
    {
      "lang": "en",
      "text": "“What are normal people's jobs?”",
      "offset": 3705.16,
      "duration": 1.316
    },
    {
      "lang": "en",
      "text": "When we discussed something related to\nthis before, Dwarkesh was like, &quot;Yeah,",
      "offset": 3706.476,
      "duration": 4.334
    },
    {
      "lang": "en",
      "text": "in a normal job you don't get feedback\nfor an entire week. How is a model meant",
      "offset": 3711.31,
      "duration": 3.489
    },
    {
      "lang": "en",
      "text": "to learn? It needs so much feedback.&quot;",
      "offset": 3714.8,
      "duration": 0.686
    },
    {
      "lang": "en",
      "text": "“Yeah it’s only on your next\npodcast, you get feedback.”",
      "offset": 3715.486,
      "duration": 3.554
    },
    {
      "lang": "en",
      "text": "I was like, “Dwarkesh, have\nyou ever worked at a job?”",
      "offset": 3719.49,
      "duration": 2.519
    },
    {
      "lang": "en",
      "text": "Here's an analogy.",
      "offset": 3726.54,
      "duration": 1.02
    },
    {
      "lang": "en",
      "text": "When I had Jeff and Noam on, they\nwere talking about in 2007, they",
      "offset": 3730.31,
      "duration": 2.33
    },
    {
      "lang": "en",
      "text": "had this paper where they trained\nan n-gram model, a large language",
      "offset": 3732.64,
      "duration": 3.65
    },
    {
      "lang": "en",
      "text": "model on two trillion tokens.",
      "offset": 3736.29,
      "duration": 2.91
    },
    {
      "lang": "en",
      "text": "Obviously in retrospect, there's ways\nin which it connects to the Transformer",
      "offset": 3739.72,
      "duration": 2.66
    },
    {
      "lang": "en",
      "text": "stuff happening, it's super foresighted.",
      "offset": 3742.38,
      "duration": 2.099
    },
    {
      "lang": "en",
      "text": "What's the reason to not think that we\nare in a similar position with computer",
      "offset": 3746.15,
      "duration": 3.53
    },
    {
      "lang": "en",
      "text": "use where there's these demos of computer\nuse that kind of suck of computer use.",
      "offset": 3749.68,
      "duration": 4.838
    },
    {
      "lang": "en",
      "text": "There's this idea that you could\ntrain something to do computer use.",
      "offset": 3754.599,
      "duration": 3.24
    },
    {
      "lang": "en",
      "text": "But why think it's months away?",
      "offset": 3758.12,
      "duration": 2.169
    },
    {
      "lang": "en",
      "text": "Why not think it's the 2007 equivalent\nof large language models instead, where",
      "offset": 3760.289,
      "duration": 4.271
    },
    {
      "lang": "en",
      "text": "there's still a bunch of new techniques\nyou have to discover, you need way more",
      "offset": 3764.67,
      "duration": 2.49
    },
    {
      "lang": "en",
      "text": "compute, different kinds of data, etc.?",
      "offset": 3767.16,
      "duration": 2.77
    },
    {
      "lang": "en",
      "text": "The highest thought of it is that I don't\nthink there's anything fundamentally",
      "offset": 3771.75,
      "duration": 3.45
    },
    {
      "lang": "en",
      "text": "different about computer use than\nthere is about software engineering.",
      "offset": 3775.259,
      "duration": 3.081
    },
    {
      "lang": "en",
      "text": "So long as you can represent everything\nin tokens in input space, which we can.",
      "offset": 3779.129,
      "duration": 2.641
    },
    {
      "lang": "en",
      "text": "We know the models can see, they\ncan draw bounding boxes around",
      "offset": 3781.78,
      "duration": 2.67
    },
    {
      "lang": "en",
      "text": "things in their images, right?",
      "offset": 3784.45,
      "duration": 0.8
    },
    {
      "lang": "en",
      "text": "So that's a solved problem.",
      "offset": 3785.25,
      "duration": 1.11
    },
    {
      "lang": "en",
      "text": "We know that they can reason over\nconcepts and difficult concepts too.",
      "offset": 3787.29,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "The only difference with computer use is\nthat it's slightly harder to pose into",
      "offset": 3792.549,
      "duration": 7.481
    },
    {
      "lang": "en",
      "text": "these feedback loops than math and coding.",
      "offset": 3800.03,
      "duration": 3.07
    },
    {
      "lang": "en",
      "text": "So",
      "offset": 3803.63,
      "duration": 0.5
    },
    {
      "lang": "en",
      "text": "to me that indicates that with sufficient\neffort, computers use falls too.",
      "offset": 3806.61,
      "duration": 4.869
    },
    {
      "lang": "en",
      "text": "I also think that it's\nunderappreciated just how far from",
      "offset": 3813.25,
      "duration": 5.53
    },
    {
      "lang": "en",
      "text": "a perfect machine these labs are.",
      "offset": 3818.78,
      "duration": 1.749
    },
    {
      "lang": "en",
      "text": "It's not like you have a thousand\npeople optimizing the hell out",
      "offset": 3820.529,
      "duration": 3.821
    },
    {
      "lang": "en",
      "text": "of computer use and they've been\ntrying as hard as they possibly can.",
      "offset": 3824.37,
      "duration": 3.049
    },
    {
      "lang": "en",
      "text": "Everything at these labs, every single\npart of the model generation pipeline",
      "offset": 3827.639,
      "duration": 2.931
    },
    {
      "lang": "en",
      "text": "is the best effort pulled together under\nincredible time pressure, incredible",
      "offset": 3830.929,
      "duration": 3.331
    },
    {
      "lang": "en",
      "text": "constraints as these companies are\nrapidly growing, trying desperately",
      "offset": 3834.33,
      "duration": 2.719
    },
    {
      "lang": "en",
      "text": "to pull and upskill enough people to\ndo the things that they need to do.",
      "offset": 3837.05,
      "duration": 3.26
    },
    {
      "lang": "en",
      "text": "I think it is best understood as",
      "offset": 3840.32,
      "duration": 3.78
    },
    {
      "lang": "en",
      "text": "with incredibly difficult\nprioritization problems.",
      "offset": 3846.12,
      "duration": 2.18
    },
    {
      "lang": "en",
      "text": "Coding is immensely valuable right\nnow and somewhat more tractable.",
      "offset": 3848.65,
      "duration": 5.9
    },
    {
      "lang": "en",
      "text": "So it actually makes sense to devote\nmore of your effort to coding initially",
      "offset": 3854.9,
      "duration": 3.859
    },
    {
      "lang": "en",
      "text": "and get closer to solving that because\nthere's a sort of super exponential",
      "offset": 3858.81,
      "duration": 3.9
    },
    {
      "lang": "en",
      "text": "value as you get closer towards\nsolving a domain than to allocate the",
      "offset": 3862.719,
      "duration": 5.631
    },
    {
      "lang": "en",
      "text": "marginal person towards computer use.",
      "offset": 3868.35,
      "duration": 1.92
    },
    {
      "lang": "en",
      "text": "So everyone is making these difficult\ntrade-off calls over what they care about.",
      "offset": 3872.29,
      "duration": 3.1
    },
    {
      "lang": "en",
      "text": "Also, there's another aspect\nwhich is that funnily enough, the",
      "offset": 3875.55,
      "duration": 3.17
    },
    {
      "lang": "en",
      "text": "researchers of the labs love working\non the bars of intelligence that",
      "offset": 3878.729,
      "duration": 4.311
    },
    {
      "lang": "en",
      "text": "they themselves resonate with.",
      "offset": 3883.04,
      "duration": 1.41
    },
    {
      "lang": "en",
      "text": "So this is why math and\ncompetitive programming fell first.",
      "offset": 3884.849,
      "duration": 3.62
    },
    {
      "lang": "en",
      "text": "Because to everyone in the labs,\nthis is their bar of intelligence.",
      "offset": 3888.87,
      "duration": 2.46
    },
    {
      "lang": "en",
      "text": "When they think",
      "offset": 3892.62,
      "duration": 0.5
    },
    {
      "lang": "en",
      "text": "what is smart?",
      "offset": 3895.46,
      "duration": 2.04
    },
    {
      "lang": "en",
      "text": "It's like “oh, if it can beat\nme at AIME, then that's smart.”",
      "offset": 3897.57,
      "duration": 2.74
    },
    {
      "lang": "en",
      "text": "Not if it can do an Excel model.",
      "offset": 3900.63,
      "duration": 1.53
    },
    {
      "lang": "en",
      "text": "Well who cares if it can do an Excel\nmodel better than me, but if it can",
      "offset": 3902.98,
      "duration": 3.21
    },
    {
      "lang": "en",
      "text": "beat me at AIME, then I respect it.",
      "offset": 3906.19,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "So we've reached the point where\npeople respect it, but people",
      "offset": 3910.45,
      "duration": 6.75
    },
    {
      "lang": "en",
      "text": "haven't invested as much effort.",
      "offset": 3917.2,
      "duration": 1.43
    },
    {
      "lang": "en",
      "text": "Ok, so getting your concrete predictions.",
      "offset": 3918.99,
      "duration": 1.89
    },
    {
      "lang": "en",
      "text": "May of next year, can I tell it to go\non Photoshop and add three sequential",
      "offset": 3921.509,
      "duration": 5.891
    },
    {
      "lang": "en",
      "text": "effects which require some selecting\nof a particular photo specifically?",
      "offset": 3927.44,
      "duration": 5.653
    },
    {
      "lang": "en",
      "text": "Totally.",
      "offset": 3933.093,
      "duration": 0.487
    },
    {
      "lang": "en",
      "text": "Okay, interesting.",
      "offset": 3933.58,
      "duration": 0.54
    },
    {
      "lang": "en",
      "text": "I assume that means flight\nbooking is totally solved.",
      "offset": 3934.8,
      "duration": 1.88
    },
    {
      "lang": "en",
      "text": "Yeah, totally.",
      "offset": 3936.83,
      "duration": 0.67
    },
    {
      "lang": "en",
      "text": "Okay, what",
      "offset": 3937.57,
      "duration": 0.5
    },
    {
      "lang": "en",
      "text": "else do people do in their jobs?",
      "offset": 3939.969,
      "duration": 1.201
    },
    {
      "lang": "en",
      "text": "What are other tasks in the economy?",
      "offset": 3942.93,
      "duration": 2.329
    },
    {
      "lang": "en",
      "text": "Planning a weekend getaway.",
      "offset": 3946.319,
      "duration": 1.591
    },
    {
      "lang": "en",
      "text": "Yeah, maybe that's a good example\nwhere it's not a particular thing,",
      "offset": 3949.51,
      "duration": 3.399
    },
    {
      "lang": "en",
      "text": "but more of using computer use as\npart of completing a broader task.",
      "offset": 3952.91,
      "duration": 5.11
    },
    {
      "lang": "en",
      "text": "I mean the models can even\nkind of already do this.",
      "offset": 3958.289,
      "duration": 1.84
    },
    {
      "lang": "en",
      "text": "It's just, again, the\nnines of reliability.",
      "offset": 3960.139,
      "duration": 2.581
    },
    {
      "lang": "en",
      "text": "The internet's kind of a hostile\nplace with all the &quot;allow cookies&quot;",
      "offset": 3963.2,
      "duration": 4.04
    },
    {
      "lang": "en",
      "text": "and all these other random things.",
      "offset": 3967.26,
      "duration": 1.969
    },
    {
      "lang": "en",
      "text": "The first time I ever used our\ninternal demo of computer use, the",
      "offset": 3969.69,
      "duration": 2.54
    },
    {
      "lang": "en",
      "text": "most beta thing possible, it did\na fantastic job planning a camping",
      "offset": 3972.23,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "trip and could navigate all the right\nbuttons and look at weather patterns.",
      "offset": 3975.99,
      "duration": 4.84
    },
    {
      "lang": "en",
      "text": "It was like a US government booking site.",
      "offset": 3980.84,
      "duration": 3.55
    },
    {
      "lang": "en",
      "text": "I mean it wasn't easy.",
      "offset": 3984.42,
      "duration": 1.21
    },
    {
      "lang": "en",
      "text": "Dude, if you want to see a hard\nwebsite, try to book a visa to China.",
      "offset": 3985.95,
      "duration": 2.37
    },
    {
      "lang": "en",
      "text": "The Chinese websites\nare like fucking insane.",
      "offset": 3991.15,
      "duration": 1.98
    },
    {
      "lang": "en",
      "text": "I'm never getting back\ninto that country again.",
      "offset": 3993.71,
      "duration": 3.2
    },
    {
      "lang": "en",
      "text": "Or just not catered to foreigners.",
      "offset": 3996.91,
      "duration": 3.3
    },
    {
      "lang": "en",
      "text": "Filling out all the countries where\nyou've been for visa, I hate that.",
      "offset": 4000.95,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "I keep thinking I'm close enough\nfor personal admin escape velocity",
      "offset": 4004.98,
      "duration": 2.779
    },
    {
      "lang": "en",
      "text": "that finally in a year, the models\nwill be doing my visas and stuff",
      "offset": 4007.759,
      "duration": 4.18
    },
    {
      "lang": "en",
      "text": "for me but… We'll get there.",
      "offset": 4011.94,
      "duration": 3.069
    },
    {
      "lang": "en",
      "text": "Yeah, okay.\nActually that.",
      "offset": 4015.1,
      "duration": 1
    },
    {
      "lang": "en",
      "text": "Anything involved in getting a visa other\nthan you showing up at the consulate?",
      "offset": 4019.56,
      "duration": 2.797
    },
    {
      "lang": "en",
      "text": "Or doing your taxes or\nsomething like that?",
      "offset": 4022.38,
      "duration": 0.611
    },
    {
      "lang": "en",
      "text": "Yeah, doing your taxes, including going\nthrough every single receipt, autonomously",
      "offset": 4023.07,
      "duration": 3.28
    },
    {
      "lang": "en",
      "text": "going into your Amazon and seeing, was\nthis a business expense or not, etc.",
      "offset": 4027.63,
      "duration": 3.13
    },
    {
      "lang": "en",
      "text": "If someone at one of\nthe labs cares about it.",
      "offset": 4032.24,
      "duration": 2.14
    },
    {
      "lang": "en",
      "text": "That's not a real prediction.",
      "offset": 4034.41,
      "duration": 1.96
    },
    {
      "lang": "en",
      "text": "No, but I think it is because it’s\nactually not that hard, but you",
      "offset": 4036.37,
      "duration": 1.65
    },
    {
      "lang": "en",
      "text": "need to connect all the pipes.",
      "offset": 4038.02,
      "duration": 1.01
    },
    {
      "lang": "en",
      "text": "But I guess my question is\nwill the pipes be connected?",
      "offset": 4039.23,
      "duration": 2.11
    },
    {
      "lang": "en",
      "text": "And so I don't know how much you care, to\nthe extent that that's the operative crux.",
      "offset": 4041.69,
      "duration": 2.79
    },
    {
      "lang": "en",
      "text": "I think if people care about it…",
      "offset": 4044.48,
      "duration": 1.05
    },
    {
      "lang": "en",
      "text": "For these edge tasks like taxes once\na year, it's so easy to just bite",
      "offset": 4048.199,
      "duration": 3.781
    },
    {
      "lang": "en",
      "text": "the bullet and do it yourself instead\nof implementing some system for it.",
      "offset": 4051.98,
      "duration": 3.339
    },
    {
      "lang": "en",
      "text": "Two, even being very excited about\nAI and knowing its capabilities,",
      "offset": 4056.6,
      "duration": 5.829
    },
    {
      "lang": "en",
      "text": "sometimes it kind of stings when the\nAI can just do things better than you.",
      "offset": 4062.44,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "So I wonder if there is\ngoing to be this reluctant",
      "offset": 4066.609,
      "duration": 3.01
    },
    {
      "lang": "en",
      "text": "wanting-to-keep-human-in-the-loop\nsort of thing.",
      "offset": 4070.409,
      "duration": 2.491
    },
    {
      "lang": "en",
      "text": "You're evading my question.",
      "offset": 4074.45,
      "duration": 0.95
    },
    {
      "lang": "en",
      "text": "I guess one thing you're implying by your\nanswer is that in a year there won’t be a",
      "offset": 4075.51,
      "duration": 6.439
    },
    {
      "lang": "en",
      "text": "general agent which has generalized\nbeyond its training data.",
      "offset": 4084.379,
      "duration": 4.821
    },
    {
      "lang": "en",
      "text": "If you don't specifically train it to\ndo taxes, it won't be good at that.",
      "offset": 4090.98,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "I think it could do that.",
      "offset": 4094.599,
      "duration": 0.941
    },
    {
      "lang": "en",
      "text": "I think the Amazon example is hard\nbecause it needs access to all",
      "offset": 4095.54,
      "duration": 2.17
    },
    {
      "lang": "en",
      "text": "your accounts and a memory system.",
      "offset": 4097.71,
      "duration": 2.089
    },
    {
      "lang": "en",
      "text": "Even in Dario's “Machines of Loving\nGrace”, he fully acknowledges that",
      "offset": 4100.2,
      "duration": 3.199
    },
    {
      "lang": "en",
      "text": "some industries are going to be\nreally slow to change and update.",
      "offset": 4103.77,
      "duration": 3.529
    },
    {
      "lang": "en",
      "text": "I think there's going to be this\nweird effect where some move really,",
      "offset": 4108.02,
      "duration": 3.24
    },
    {
      "lang": "en",
      "text": "really quickly because they're either\nbased in bits instead of atoms, or",
      "offset": 4111.26,
      "duration": 3.899
    },
    {
      "lang": "en",
      "text": "are just more pro adopting this tech.",
      "offset": 4115.16,
      "duration": 2.26
    },
    {
      "lang": "en",
      "text": "But I want an answer to\nthis particular question.",
      "offset": 4117.559,
      "duration": 2.39
    },
    {
      "lang": "en",
      "text": "Given your probability that somebody\nin the labs does care about this, to",
      "offset": 4120.279,
      "duration": 3.501
    },
    {
      "lang": "en",
      "text": "the extent that that's what's relevant,\nwhat’s the probability that in May of next",
      "offset": 4123.78,
      "duration": 3.269
    },
    {
      "lang": "en",
      "text": "year, it can autonomously do my taxes?",
      "offset": 4127.05,
      "duration": 1.66
    },
    {
      "lang": "en",
      "text": "I don't think it'll be able\nto autonomously do your taxes",
      "offset": 4129.33,
      "duration": 1.94
    },
    {
      "lang": "en",
      "text": "with a high degree of trust.",
      "offset": 4131.27,
      "duration": 0.88
    },
    {
      "lang": "en",
      "text": "If you ask it to do your\ntaxes, it'll do your",
      "offset": 4136.31,
      "duration": 2.169
    },
    {
      "lang": "en",
      "text": "taxes.\nWill it do them well?",
      "offset": 4140.519,
      "duration": 1.691
    },
    {
      "lang": "en",
      "text": "Will it miss something?",
      "offset": 4142.21,
      "duration": 0.83
    },
    {
      "lang": "en",
      "text": "Quite possibly.",
      "offset": 4143.18,
      "duration": 0.57
    },
    {
      "lang": "en",
      "text": "Will it be able to click through TurboTax?",
      "offset": 4144.33,
      "duration": 3.27
    },
    {
      "lang": "en",
      "text": "I think yes.",
      "offset": 4147.99,
      "duration": 0.58
    },
    {
      "lang": "en",
      "text": "Yeah.",
      "offset": 4148.75,
      "duration": 0.47
    },
    {
      "lang": "en",
      "text": "And fill out boxes.",
      "offset": 4149.22,
      "duration": 0.589
    },
    {
      "lang": "en",
      "text": "And will it be able to search your email?",
      "offset": 4149.809,
      "duration": 1.58
    },
    {
      "lang": "en",
      "text": "Yeah, that's the kind of\nthing I'm talking about.",
      "offset": 4151.399,
      "duration": 2.15
    },
    {
      "lang": "en",
      "text": "Yeah.",
      "offset": 4153.599,
      "duration": 0.281
    },
    {
      "lang": "en",
      "text": "This is the kind of thing where literally\nif you gave it one person-month of",
      "offset": 4153.88,
      "duration": 6.229
    },
    {
      "lang": "en",
      "text": "effort, then it would be solved.",
      "offset": 4161.799,
      "duration": 1.371
    },
    {
      "lang": "en",
      "text": "What the fuck are you doing all day?",
      "offset": 4164.45,
      "duration": 1.239
    },
    {
      "lang": "en",
      "text": "So many things.",
      "offset": 4166.99,
      "duration": 1.17
    },
    {
      "lang": "en",
      "text": "I want to plus-one Sholto's…\nThere's so much low-hanging fruit",
      "offset": 4168.179,
      "duration": 4.771
    },
    {
      "lang": "en",
      "text": "and just not enough people to be\nable to accomplish everything.",
      "offset": 4172.979,
      "duration": 4.291
    },
    {
      "lang": "en",
      "text": "I mean I think Claude Code\nis making everyone more",
      "offset": 4177.29,
      "duration": 2.58
    },
    {
      "lang": "en",
      "text": "productive, but I don't know.",
      "offset": 4179.87,
      "duration": 2.62
    },
    {
      "lang": "en",
      "text": "We had the Anthropic Fellows Program\nand I'm mentoring one project, but I had",
      "offset": 4182.68,
      "duration": 3.58
    },
    {
      "lang": "en",
      "text": "five that I wanted people to work on.",
      "offset": 4186.26,
      "duration": 1.919
    },
    {
      "lang": "en",
      "text": "There are just so many obvious things, and\neven though the team is 6X’d since I first",
      "offset": 4188.729,
      "duration": 5.621
    },
    {
      "lang": "en",
      "text": "joined it in size, there's just never\nenough capacity to explore these things.",
      "offset": 4194.35,
      "duration": 5.68
    },
    {
      "lang": "en",
      "text": "By end of 2026, reliably do your taxes?",
      "offset": 4200.65,
      "duration": 3.019
    },
    {
      "lang": "en",
      "text": "Reliably fill out your receipts and\nthis kind of stuff for company expense",
      "offset": 4203.87,
      "duration": 4.45
    },
    {
      "lang": "en",
      "text": "reports and this kind of stuff?",
      "offset": 4208.32,
      "duration": 2.14
    },
    {
      "lang": "en",
      "text": "Absolutely.",
      "offset": 4210.46,
      "duration": 0.037
    },
    {
      "lang": "en",
      "text": "No, but the whole thing, which involves\ngoing through inbox, clicking on",
      "offset": 4210.497,
      "duration": 5.083
    },
    {
      "lang": "en",
      "text": "Marina Bay hotel reservations, and",
      "offset": 4215.58,
      "duration": 0.74
    },
    {
      "lang": "en",
      "text": "“was the champagne a business expense?”",
      "offset": 4220.5,
      "duration": 1.66
    },
    {
      "lang": "en",
      "text": "Asking for a friend.",
      "offset": 4225.57,
      "duration": 0.76
    },
    {
      "lang": "en",
      "text": "Yeah, one of your friends does need\nto ask some of those questions.",
      "offset": 4228.94,
      "duration": 4.558
    },
    {
      "lang": "en",
      "text": "My answer is still, if\nsomeone cares about it.",
      "offset": 4233.91,
      "duration": 1.83
    },
    {
      "lang": "en",
      "text": "If someone cares about some amount of RL\non correctly interpreting the tax code.",
      "offset": 4235.9,
      "duration": 4.42
    },
    {
      "lang": "en",
      "text": "Wait, even by the end of 2026, the\nmodel just can't do things you're",
      "offset": 4240.36,
      "duration": 3.779
    },
    {
      "lang": "en",
      "text": "not explicitly training it to?",
      "offset": 4244.19,
      "duration": 1.479
    },
    {
      "lang": "en",
      "text": "I think it will get the taxes wrong\nlike… If I went to you and I was",
      "offset": 4246.09,
      "duration": 5.46
    },
    {
      "lang": "en",
      "text": "like, &quot;I want you to do everyone's\ntaxes in America,&quot; what percentage",
      "offset": 4251.55,
      "duration": 2.7
    },
    {
      "lang": "en",
      "text": "of them are you going to fuck up?",
      "offset": 4254.25,
      "duration": 0.73
    },
    {
      "lang": "en",
      "text": "I feel like I would succeed at the median.",
      "offset": 4255.45,
      "duration": 1.94
    },
    {
      "lang": "en",
      "text": "And I'm asking for the\nmedian, you know what I mean?",
      "offset": 4257.599,
      "duration": 2.771
    },
    {
      "lang": "en",
      "text": "I feel like I wouldn't fuck up\nin the way that these models will",
      "offset": 4263.07,
      "duration": 3.27
    },
    {
      "lang": "en",
      "text": "fuck up in the middle of 2026.",
      "offset": 4266.34,
      "duration": 2.24
    },
    {
      "lang": "en",
      "text": "I think they also might just\nfuck up in different ways.",
      "offset": 4268.89,
      "duration": 1.85
    },
    {
      "lang": "en",
      "text": "As a grad student, I fucked up my taxes.",
      "offset": 4271.62,
      "duration": 1.689
    },
    {
      "lang": "en",
      "text": "I overpaid quite a bit because there was\nsome Social Security payment that was",
      "offset": 4273.79,
      "duration": 3.88
    },
    {
      "lang": "en",
      "text": "already covered that otherwise wasn't.",
      "offset": 4277.77,
      "duration": 1.22
    },
    {
      "lang": "en",
      "text": "I wonder if… I should almost test,\nwould an LLM have made that mistake?",
      "offset": 4281.12,
      "duration": 3.25
    },
    {
      "lang": "en",
      "text": "Because it might make others, but I\nthink there are things that it can spot.",
      "offset": 4284.58,
      "duration": 2.3
    },
    {
      "lang": "en",
      "text": "It would have no problem if I asked\nit to read through the entire tax",
      "offset": 4287.66,
      "duration": 2.55
    },
    {
      "lang": "en",
      "text": "code and then see what applied to me.",
      "offset": 4290.21,
      "duration": 1.249
    },
    {
      "lang": "en",
      "text": "The thing I would be able to do is like,\n“This is the thing I'm unsure about. I'm",
      "offset": 4291.459,
      "duration": 5.331
    },
    {
      "lang": "en",
      "text": "bringing this to your attention. Can you\njust let me know if you were actually",
      "offset": 4296.79,
      "duration": 2.46
    },
    {
      "lang": "en",
      "text": "working at this Airbnb or you were just\nhanging out?” Things like that, right?",
      "offset": 4299.25,
      "duration": 3.8
    },
    {
      "lang": "en",
      "text": "Will they have enough awareness as\nthey're doing tasks where they can bring",
      "offset": 4306.66,
      "duration": 3.83
    },
    {
      "lang": "en",
      "text": "to your attention to things where they\nfeel they're unreliable at, et cetera?",
      "offset": 4310.49,
      "duration": 2.879
    },
    {
      "lang": "en",
      "text": "Yeah.",
      "offset": 4313.509,
      "duration": 0.34
    },
    {
      "lang": "en",
      "text": "Yeah.",
      "offset": 4313.849,
      "duration": 0.5
    },
    {
      "lang": "en",
      "text": "By early 2026 or end of 2026?",
      "offset": 4314.86,
      "duration": 2.08
    },
    {
      "lang": "en",
      "text": "End of.",
      "offset": 4316.94,
      "duration": 0.51
    },
    {
      "lang": "en",
      "text": "Okay.",
      "offset": 4318.38,
      "duration": 0.089
    },
    {
      "lang": "en",
      "text": "The unreliability and confidence\nstuff will be somewhat tricky,",
      "offset": 4318.469,
      "duration": 2.641
    },
    {
      "lang": "en",
      "text": "to do this all the time.",
      "offset": 4321.11,
      "duration": 1.55
    },
    {
      "lang": "en",
      "text": "Interesting.",
      "offset": 4323.12,
      "duration": 0.5
    },
    {
      "lang": "en",
      "text": "On the computer, your stuff,\nwill it be end-to-end?",
      "offset": 4324.25,
      "duration": 3.24
    },
    {
      "lang": "en",
      "text": "Or will it be like it's using\na separate VLM to process the",
      "offset": 4327.49,
      "duration": 2.87
    },
    {
      "lang": "en",
      "text": "image, and video, and so forth?",
      "offset": 4330.37,
      "duration": 1.479
    },
    {
      "lang": "en",
      "text": "I'm a bit of an end-to-end maxi.",
      "offset": 4332.62,
      "duration": 2.059
    },
    {
      "lang": "en",
      "text": "I think, in general,",
      "offset": 4335.049,
      "duration": 1.821
    },
    {
      "lang": "en",
      "text": "when people are talking about the separate\nmodel… For example, most of the robotics",
      "offset": 4339.3,
      "duration": 4.53
    },
    {
      "lang": "en",
      "text": "companies are doing this bi-level thing,\nwhere they have a motor policy that's",
      "offset": 4343.83,
      "duration": 4.83
    },
    {
      "lang": "en",
      "text": "running at 60 hertz or whatever, and\nsome higher-level visual language model.",
      "offset": 4348.66,
      "duration": 4.799
    },
    {
      "lang": "en",
      "text": "I'm pretty sure almost all of the\nbig robot companies are doing this.",
      "offset": 4353.459,
      "duration": 3.081
    },
    {
      "lang": "en",
      "text": "They're doing this for\na number of reasons.",
      "offset": 4357.22,
      "duration": 1.049
    },
    {
      "lang": "en",
      "text": "One of them is that they want\nsomething to act at a very high",
      "offset": 4358.27,
      "duration": 2.82
    },
    {
      "lang": "en",
      "text": "frequency, and two is they can't\ntrain the big visual language model.",
      "offset": 4361.18,
      "duration": 3.98
    },
    {
      "lang": "en",
      "text": "So they like relying on that for general\nworld knowledge, and this kind of stuff,",
      "offset": 4366.67,
      "duration": 3.78
    },
    {
      "lang": "en",
      "text": "and constructing longer running plans.",
      "offset": 4370.45,
      "duration": 1.309
    },
    {
      "lang": "en",
      "text": "But then they're like, you\noffload to the motor policy.",
      "offset": 4371.759,
      "duration": 1.96
    },
    {
      "lang": "en",
      "text": "I'm very much of the opinion that if\nyou are able to train the big model,",
      "offset": 4374.219,
      "duration": 5.251
    },
    {
      "lang": "en",
      "text": "eventually, at some point in the future,\nthe distinction between big models",
      "offset": 4380.46,
      "duration": 2.589
    },
    {
      "lang": "en",
      "text": "and small models should disappear.",
      "offset": 4383.05,
      "duration": 1.25
    },
    {
      "lang": "en",
      "text": "Because you should be able to use the\namount of computation in a model that",
      "offset": 4384.5,
      "duration": 4.84
    },
    {
      "lang": "en",
      "text": "is necessary to complete the task.",
      "offset": 4389.34,
      "duration": 1.599
    },
    {
      "lang": "en",
      "text": "Ultimately, there's some\namount of task complexity.",
      "offset": 4394.33,
      "duration": 4.52
    },
    {
      "lang": "en",
      "text": "You don't have to use 100%\nof your brain all the time.",
      "offset": 4399.61,
      "duration": 2.15
    },
    {
      "lang": "en",
      "text": "Welcome to my world.",
      "offset": 4402.3,
      "duration": 0.85
    },
    {
      "lang": "en",
      "text": "So, you should be able to run that\nfaster and this kind of stuff, basically.",
      "offset": 4406.469,
      "duration": 2.66
    },
    {
      "lang": "en",
      "text": "So I think it's net-net\ntypically the same model.",
      "offset": 4409.129,
      "duration": 3.651
    },
    {
      "lang": "en",
      "text": "Because you want to be able to\nscale the understanding with",
      "offset": 4412.78,
      "duration": 0.089
    },
    {
      "lang": "en",
      "text": "the complexity and difficulty.\nYou want to be able to do that",
      "offset": 4412.869,
      "duration": 2.221
    },
    {
      "lang": "en",
      "text": "dynamically.",
      "offset": 4422.12,
      "duration": 0.16
    },
    {
      "lang": "en",
      "text": "So we already have variable\ncompute per answer, right?",
      "offset": 4422.28,
      "duration": 2.52
    },
    {
      "lang": "en",
      "text": "Right.\nWith tokens.",
      "offset": 4424.8,
      "duration": 0.009
    },
    {
      "lang": "en",
      "text": "Yeah.",
      "offset": 4424.809,
      "duration": 0.5
    },
    {
      "lang": "en",
      "text": "That's right.\nYeah.",
      "offset": 4426.869,
      "duration": 0.791
    },
    {
      "lang": "en",
      "text": "Will we have variable compute per token?",
      "offset": 4428.19,
      "duration": 1.939
    },
    {
      "lang": "en",
      "text": "I mean, you can already think of models...\nForever, people have been calling the",
      "offset": 4430.14,
      "duration": 3.91
    },
    {
      "lang": "en",
      "text": "residual stream and multiple layers poor\nman's adaptive compute, where if the model",
      "offset": 4434.05,
      "duration": 5.319
    },
    {
      "lang": "en",
      "text": "already knows the answer to something,\nit will compute that in the first few",
      "offset": 4439.38,
      "duration": 3.34
    },
    {
      "lang": "en",
      "text": "layers and then just pass it through.",
      "offset": 4442.72,
      "duration": 1.72
    },
    {
      "lang": "en",
      "text": "I mean, that's getting into the weeds.",
      "offset": 4447,
      "duration": 2.21
    },
    {
      "lang": "en",
      "text": "The residual stream is like operating\nRAM, you're doing stuff to it, is",
      "offset": 4449.32,
      "duration": 3.79
    },
    {
      "lang": "en",
      "text": "the mental model I think one takes\naway from interpretability work.",
      "offset": 4453.12,
      "duration": 2.21
    },
    {
      "lang": "en",
      "text": "We've been",
      "offset": 4455.61,
      "duration": 0.5
    },
    {
      "lang": "en",
      "text": "talking a",
      "offset": 4473.349,
      "duration": 0.5
    },
    {
      "lang": "en",
      "text": "lot",
      "offset": 4489.539,
      "duration": 0.5
    },
    {
      "lang": "en",
      "text": "about",
      "offset": 4505.8,
      "duration": 0.5
    },
    {
      "lang": "en",
      "text": "scratchpads, them writing down their\nthoughts in ways in which they're",
      "offset": 4521.22,
      "duration": 1.7
    },
    {
      "lang": "en",
      "text": "already unreliable in some respects.",
      "offset": 4522.92,
      "duration": 2.01
    },
    {
      "lang": "en",
      "text": "Daniel's AI",
      "offset": 4524.93,
      "duration": 0.5
    },
    {
      "lang": "en",
      "text": "2027 scenario goes off the rails when\nthese models start thinking in Neuralese.",
      "offset": 4528.26,
      "duration": 3.71
    },
    {
      "lang": "en",
      "text": "So they're not writing in human\nlanguage, &quot;Here's why I'm going to",
      "offset": 4532.12,
      "duration": 2.77
    },
    {
      "lang": "en",
      "text": "take over the world, and here's my\nplan.&quot; They're thinking in the latent",
      "offset": 4534.89,
      "duration": 3.85
    },
    {
      "lang": "en",
      "text": "space and—because of their advantages\nin communicating with each other in",
      "offset": 4538.74,
      "duration": 4.25
    },
    {
      "lang": "en",
      "text": "this deeply textured, nuanced language\nthat humans can't understand—they're",
      "offset": 4542.99,
      "duration": 4.279
    },
    {
      "lang": "en",
      "text": "able to coordinate in ways we can't.",
      "offset": 4547.27,
      "duration": 1.929
    },
    {
      "lang": "en",
      "text": "Is this the path for future models?",
      "offset": 4549.299,
      "duration": 2.361
    },
    {
      "lang": "en",
      "text": "Are they going to be, in\nNeuralese, communicating with",
      "offset": 4551.66,
      "duration": 2.19
    },
    {
      "lang": "en",
      "text": "themselves or with each other?",
      "offset": 4553.85,
      "duration": 0.99
    },
    {
      "lang": "en",
      "text": "There's a surprisingly strong bias\nso far towards tokens and text.",
      "offset": 4555.72,
      "duration": 4.02
    },
    {
      "lang": "en",
      "text": "It seems to work very well.",
      "offset": 4559.87,
      "duration": 1.12
    },
    {
      "lang": "en",
      "text": "There already is some amount of Neuralese.",
      "offset": 4565.49,
      "duration": 1.67
    },
    {
      "lang": "en",
      "text": "If you think about the residual stream for\neach token, is Neuralese to some degree.",
      "offset": 4567.16,
      "duration": 3.639
    },
    {
      "lang": "en",
      "text": "Now we're just trading off axes.",
      "offset": 4571.24,
      "duration": 1.069
    },
    {
      "lang": "en",
      "text": "How much Neuralese are you\ndoing versus how much actually",
      "offset": 4572.8,
      "duration": 2.16
    },
    {
      "lang": "en",
      "text": "is read out to tokens all",
      "offset": 4574.96,
      "duration": 1.24
    },
    {
      "lang": "en",
      "text": "the time.",
      "offset": 4578.45,
      "duration": 0.09
    },
    {
      "lang": "en",
      "text": "I think it's important to delineate\nbetween the model's planning in latent",
      "offset": 4578.54,
      "duration": 3.46
    },
    {
      "lang": "en",
      "text": "space in a single forward pass, and the\nmodel has an alien language that it's",
      "offset": 4582,
      "duration": 4.525
    },
    {
      "lang": "en",
      "text": "outputting and using as its scratchpad.",
      "offset": 4586.61,
      "duration": 3.63
    },
    {
      "lang": "en",
      "text": "Which one are we talking about?",
      "offset": 4590.25,
      "duration": 1.31
    },
    {
      "lang": "en",
      "text": "The latter.",
      "offset": 4591.92,
      "duration": 0.83
    },
    {
      "lang": "en",
      "text": "Although it is interesting\nto note that there's also",
      "offset": 4593.18,
      "duration": 2.81
    },
    {
      "lang": "en",
      "text": "already alien stuff happening.",
      "offset": 4596.01,
      "duration": 1.12
    },
    {
      "lang": "en",
      "text": "It's not alien, so much.\nNo,",
      "offset": 4597.13,
      "duration": 0.511
    },
    {
      "lang": "en",
      "text": "but in the most extreme cases\nof Neuralese, it invents a",
      "offset": 4600.36,
      "duration": 2.69
    },
    {
      "lang": "en",
      "text": "new language that's super\ninformation-dense, or something.",
      "offset": 4603.05,
      "duration": 2.82
    },
    {
      "lang": "en",
      "text": "Yeah.",
      "offset": 4605.87,
      "duration": 0.5
    },
    {
      "lang": "en",
      "text": "This is a debate we've had,\nbut to some extent, humans",
      "offset": 4607.77,
      "duration": 3.239
    },
    {
      "lang": "en",
      "text": "also have a Mentalese, right?",
      "offset": 4611.01,
      "duration": 2.21
    },
    {
      "lang": "en",
      "text": "Yeah, like churning away.",
      "offset": 4613.35,
      "duration": 1.58
    },
    {
      "lang": "en",
      "text": "There's a sense when you're writing\nsomething down of “I know what I'm trying",
      "offset": 4615.69,
      "duration": 2.8
    },
    {
      "lang": "en",
      "text": "to say, but I can't put it into tokens.”",
      "offset": 4618.49,
      "duration": 2.63
    },
    {
      "lang": "en",
      "text": "I mean that's so fun about… if you\nlook at the assistant tag, right?",
      "offset": 4621.96,
      "duration": 3.399
    },
    {
      "lang": "en",
      "text": "Seeing these features light up in the\nauditing game for the model being evil.",
      "offset": 4625.44,
      "duration": 4.69
    },
    {
      "lang": "en",
      "text": "Yeah.\nThat's so funny.",
      "offset": 4630.26,
      "duration": 1.96
    },
    {
      "lang": "en",
      "text": "Or Transluce has another example of\nthis, where you ask a Llama model, “who",
      "offset": 4632.22,
      "duration": 4.15
    },
    {
      "lang": "en",
      "text": "is Nicholas Carlini?” For background\ncontext, Nicholas Carlini is a researcher",
      "offset": 4636.37,
      "duration": 4.289
    },
    {
      "lang": "en",
      "text": "who actually was at DeepMind and has now\ncome over to Anthropic. But the model",
      "offset": 4640.66,
      "duration": 4.5
    },
    {
      "lang": "en",
      "text": "says, &quot;Oh, I don't know who that is.",
      "offset": 4645.16,
      "duration": 1.21
    },
    {
      "lang": "en",
      "text": "I couldn't possibly speculate.&quot; But\nif you look at the features behind",
      "offset": 4646.37,
      "duration": 4.189
    },
    {
      "lang": "en",
      "text": "the scenes, you see a bunch light up\nfor AI, computer security, all the",
      "offset": 4650.56,
      "duration": 4.5
    },
    {
      "lang": "en",
      "text": "things that Nicholas Carlini does.",
      "offset": 4655.06,
      "duration": 2.289
    },
    {
      "lang": "en",
      "text": "Interpretability becomes dramatically\nmore important as you shift in",
      "offset": 4657.639,
      "duration": 2.48
    },
    {
      "lang": "en",
      "text": "this direction of Neuralese.",
      "offset": 4660.119,
      "duration": 1.29
    },
    {
      "lang": "en",
      "text": "But are we going to?",
      "offset": 4661.43,
      "duration": 2.3
    },
    {
      "lang": "en",
      "text": "It's an empirical question.",
      "offset": 4665.47,
      "duration": 1.25
    },
    {
      "lang": "en",
      "text": "I think it's somewhat likely, if\nonly because inference is expensive.",
      "offset": 4668.22,
      "duration": 6.14
    },
    {
      "lang": "en",
      "text": "Producing tokens is expensive.",
      "offset": 4674.809,
      "duration": 1.441
    },
    {
      "lang": "en",
      "text": "So there will be an incentive\nto, one, use as little thinking",
      "offset": 4677.36,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "as you need to give the answer.",
      "offset": 4680.8,
      "duration": 1.31
    },
    {
      "lang": "en",
      "text": "Two, if you're going to use thinking,\nuse some complex compression.",
      "offset": 4682.87,
      "duration": 5.05
    },
    {
      "lang": "en",
      "text": "I wonder if it will emerge more once\nwe allow agents to talk to each other,",
      "offset": 4688.09,
      "duration": 3.48
    },
    {
      "lang": "en",
      "text": "in ways where currently it's trained\nmore in isolation or with a human.",
      "offset": 4691.599,
      "duration": 5.691
    },
    {
      "lang": "en",
      "text": "There'll be some selective pressure\nagainst it, so long as the agents",
      "offset": 4697.9,
      "duration": 4.659
    },
    {
      "lang": "en",
      "text": "are working with humans, because\nthey'll want to cooperate.",
      "offset": 4702.56,
      "duration": 2.52
    },
    {
      "lang": "en",
      "text": "But then as agents begin to work\nmore and more with each other, then",
      "offset": 4705.08,
      "duration": 2.729
    },
    {
      "lang": "en",
      "text": "that selective pressure changes\nthe other direction, basically.",
      "offset": 4708.2,
      "duration": 2.45
    },
    {
      "lang": "en",
      "text": "Although somebody would still have to make\nthe conscious decision to do end-to-end",
      "offset": 4710.67,
      "duration": 2.599
    },
    {
      "lang": "en",
      "text": "training for multiple agents to use\nthe system of communication, right?",
      "offset": 4713.27,
      "duration": 3.32
    },
    {
      "lang": "en",
      "text": "Sure.",
      "offset": 4716.59,
      "duration": 0.5
    },
    {
      "lang": "en",
      "text": "Yeah.",
      "offset": 4717.33,
      "duration": 0.37
    },
    {
      "lang": "en",
      "text": "I mean, one scary thing though is the way\nwe render text, you can use hidden white",
      "offset": 4717.7,
      "duration": 5.389
    },
    {
      "lang": "en",
      "text": "space tokens that also encode information.",
      "offset": 4723.09,
      "duration": 3.08
    },
    {
      "lang": "en",
      "text": "That's true.",
      "offset": 4726.74,
      "duration": 0.07
    },
    {
      "lang": "en",
      "text": "And so you can imagine a world where\nit looks like the agent is reasoning",
      "offset": 4726.81,
      "duration": 3.44
    },
    {
      "lang": "en",
      "text": "in its scratchpad harmlessly, but\nit's actually hiding a bunch of data.",
      "offset": 4730.25,
      "duration": 3.93
    },
    {
      "lang": "en",
      "text": "Speaking of inference compute, one\nthing that I think is not talked about",
      "offset": 4734.23,
      "duration": 4.83
    },
    {
      "lang": "en",
      "text": "enough is, if you do live in the world\nthat you're painting—in a year or",
      "offset": 4739.06,
      "duration": 5.26
    },
    {
      "lang": "en",
      "text": "two, we have computer use agents that\nare doing actual jobs, you've totally",
      "offset": 4744.32,
      "duration": 8.6
    },
    {
      "lang": "en",
      "text": "automated large parts of software\nengineering—then these models are",
      "offset": 4752.92,
      "duration": 2.95
    },
    {
      "lang": "en",
      "text": "going to be incredibly valuable to use.",
      "offset": 4755.87,
      "duration": 2.3
    },
    {
      "lang": "en",
      "text": "The way you use them obviously\nmeans you need compute.",
      "offset": 4758.67,
      "duration": 2.379
    },
    {
      "lang": "en",
      "text": "Right now, there's 10 million\nH100 equivalents in the world.",
      "offset": 4762.25,
      "duration": 2.53
    },
    {
      "lang": "en",
      "text": "By 2028, there's going to be 100 million.",
      "offset": 4764.96,
      "duration": 2.849
    },
    {
      "lang": "en",
      "text": "But there's been estimates that\nan H100 has the same amount",
      "offset": 4768.139,
      "duration": 3.151
    },
    {
      "lang": "en",
      "text": "of flops as the human brain.",
      "offset": 4771.29,
      "duration": 1.77
    },
    {
      "lang": "en",
      "text": "So if you just do a very rough\ncalculation, there's a 10 million",
      "offset": 4773.07,
      "duration": 4.47
    },
    {
      "lang": "en",
      "text": "population, if you get AGI that's\nas human inference-efficient.",
      "offset": 4777.54,
      "duration": 3.75
    },
    {
      "lang": "en",
      "text": "You could have 10 million AGIs\nnow, 100 million AGIs in 2028.",
      "offset": 4781.679,
      "duration": 4.741
    },
    {
      "lang": "en",
      "text": "But presumably, you would want more.",
      "offset": 4787.24,
      "duration": 3.17
    },
    {
      "lang": "en",
      "text": "AI",
      "offset": 4790.71,
      "duration": 0.5
    },
    {
      "lang": "en",
      "text": "compute is increasing what, 2.5x\nor 2.25x every year right now.",
      "offset": 4793.31,
      "duration": 3.77
    },
    {
      "lang": "en",
      "text": "But at some point, say 2028, you\nhit wafer production limits, and",
      "offset": 4797.179,
      "duration": 3.5
    },
    {
      "lang": "en",
      "text": "that's a longer feedback loop before\nwe can make new fabs or whatever.",
      "offset": 4802.53,
      "duration": 2.919
    },
    {
      "lang": "en",
      "text": "The question here is, are we underrating\nhow big a bottleneck inference will",
      "offset": 4805.809,
      "duration": 4.161
    },
    {
      "lang": "en",
      "text": "be if we live in the kind of world\nyou're painting, if we have the",
      "offset": 4809.97,
      "duration": 2.135
    },
    {
      "lang": "en",
      "text": "capabilities that you're describing?",
      "offset": 4812.13,
      "duration": 1.73
    },
    {
      "lang": "en",
      "text": "I'd want to do the math on exactly\nhow much we can ramp up TSMC's",
      "offset": 4814.73,
      "duration": 3.42
    },
    {
      "lang": "en",
      "text": "production and this kind of stuff.",
      "offset": 4818.15,
      "duration": 1.099
    },
    {
      "lang": "en",
      "text": "What fraction of the supply chain\nat the moment—we need Dylan in",
      "offset": 4820.12,
      "duration": 2.859
    },
    {
      "lang": "en",
      "text": "here for this—is currently GPU?",
      "offset": 4822.98,
      "duration": 2.15
    },
    {
      "lang": "en",
      "text": "Relatively small right?",
      "offset": 4826.31,
      "duration": 0.819
    },
    {
      "lang": "en",
      "text": "5% or something like that.\nApple has a huge fraction.",
      "offset": 4828.569,
      "duration": 1.251
    },
    {
      "lang": "en",
      "text": "Are",
      "offset": 4829.82,
      "duration": 0.5
    },
    {
      "lang": "en",
      "text": "the 2028 estimates including\nthat ramping up over time?",
      "offset": 4832.019,
      "duration": 3.031
    },
    {
      "lang": "en",
      "text": "To what?",
      "offset": 4835.79,
      "duration": 0.5
    },
    {
      "lang": "en",
      "text": "20, 30%?",
      "offset": 4836.38,
      "duration": 1.61
    },
    {
      "lang": "en",
      "text": "This is just off AI 2027, but I\nassume it's saturated at that point.",
      "offset": 4837.99,
      "duration": 6.29
    },
    {
      "lang": "en",
      "text": "I do think this is\nunderrated to some degree.",
      "offset": 4847.81,
      "duration": 2.14
    },
    {
      "lang": "en",
      "text": "To the extent that you don't\ninstantly get a doubling of",
      "offset": 4850.76,
      "duration": 3.46
    },
    {
      "lang": "en",
      "text": "the world's population in 2028.",
      "offset": 4854.22,
      "duration": 1.06
    },
    {
      "lang": "en",
      "text": "You maybe get tens of millions of geniuses\nin a data center, but you don't get",
      "offset": 4856.02,
      "duration": 5.72
    },
    {
      "lang": "en",
      "text": "a doubling of the world's population.",
      "offset": 4861.74,
      "duration": 0.97
    },
    {
      "lang": "en",
      "text": "So a lot depends on exactly how smart\nthey are, exactly how efficient the models",
      "offset": 4863.71,
      "duration": 3.34
    },
    {
      "lang": "en",
      "text": "are at thinking about this kind of stuff.",
      "offset": 4867.05,
      "duration": 1.2
    },
    {
      "lang": "en",
      "text": "Let's do some rough math, to\nfact check the H100 thing.",
      "offset": 4870.01,
      "duration": 3.61
    },
    {
      "lang": "en",
      "text": "You could probably run a 100B\nmodel, do about 1,000 tokens",
      "offset": 4874.28,
      "duration": 2.58
    },
    {
      "lang": "en",
      "text": "or something like that on an",
      "offset": 4876.86,
      "duration": 1.489
    },
    {
      "lang": "en",
      "text": "H100.\n1,000 tokens a second.",
      "offset": 4885.12,
      "duration": 1.29
    },
    {
      "lang": "en",
      "text": "Humans are what?",
      "offset": 4887.969,
      "duration": 0.65
    },
    {
      "lang": "en",
      "text": "How fast can a human talk?",
      "offset": 4888.639,
      "duration": 0.95
    },
    {
      "lang": "en",
      "text": "There was a really interesting paper.",
      "offset": 4889.61,
      "duration": 1.019
    },
    {
      "lang": "en",
      "text": "I don't know if you saw this.",
      "offset": 4890.63,
      "duration": 0.629
    },
    {
      "lang": "en",
      "text": "Humans think at 10 tokens a second.",
      "offset": 4891.689,
      "duration": 1.35
    },
    {
      "lang": "en",
      "text": "Did you see this paper?",
      "offset": 4893.049,
      "duration": 1.531
    },
    {
      "lang": "en",
      "text": "No.\nThere was this really interesting paper.",
      "offset": 4894.58,
      "duration": 1.17
    },
    {
      "lang": "en",
      "text": "If you look at the amount of information\nwe're processing in a second, we're",
      "offset": 4896.539,
      "duration": 3.771
    },
    {
      "lang": "en",
      "text": "seeing all this visual data, etc. But\nby a bunch of metrics where you think",
      "offset": 4900.37,
      "duration": 4.07
    },
    {
      "lang": "en",
      "text": "about how fast humans are processing,\nit's at 10 tokens per second.",
      "offset": 4904.45,
      "duration": 3.097
    },
    {
      "lang": "en",
      "text": "For example, you'll have people\nfly over France or something,",
      "offset": 4907.71,
      "duration": 3.719
    },
    {
      "lang": "en",
      "text": "even these so-called idiot savants\nwho will remember everything.",
      "offset": 4911.44,
      "duration": 2.43
    },
    {
      "lang": "en",
      "text": "If you think about how long their\nplane ride was, it's like 45 minutes.",
      "offset": 4914.15,
      "duration": 2.81
    },
    {
      "lang": "en",
      "text": "If you do 10 tokens a second, how\nmuch information would you have?",
      "offset": 4917.74,
      "duration": 1.93
    },
    {
      "lang": "en",
      "text": "It's literally exactly that.",
      "offset": 4919.91,
      "duration": 1.38
    },
    {
      "lang": "en",
      "text": "So let's take that for granted.",
      "offset": 4921.3,
      "duration": 1.1
    },
    {
      "lang": "en",
      "text": "Then it's like an H100\nis 100 humans a second.",
      "offset": 4922.4,
      "duration": 2.5
    },
    {
      "lang": "en",
      "text": "Yeah, if you think the\ntokens are equivalent.",
      "offset": 4925.29,
      "duration": 1.223
    },
    {
      "lang": "en",
      "text": "If you think the tokens",
      "offset": 4926.513,
      "duration": 0.827
    },
    {
      "lang": "en",
      "text": "are equivalent.",
      "offset": 4929.64,
      "duration": 0.26
    },
    {
      "lang": "en",
      "text": "You still get pretty substantial numbers,\neven with your 100 million H100s and you",
      "offset": 4929.9,
      "duration": 2.295
    },
    {
      "lang": "en",
      "text": "multiply that by 100, you're starting\nto get to pretty substantial numbers.",
      "offset": 4932.195,
      "duration": 4.055
    },
    {
      "lang": "en",
      "text": "This does mean that those models\nthemselves will be somewhat compute",
      "offset": 4936.25,
      "duration": 3.42
    },
    {
      "lang": "en",
      "text": "bottlenecked in many respects.",
      "offset": 4939.82,
      "duration": 1.27
    },
    {
      "lang": "en",
      "text": "But",
      "offset": 4941.65,
      "duration": 0.5
    },
    {
      "lang": "en",
      "text": "these are relatively short-term changes\nin timelines of progress, basically.",
      "offset": 4943.889,
      "duration": 5.781
    },
    {
      "lang": "en",
      "text": "Yes, it's highly likely we\nget dramatically inference",
      "offset": 4951.06,
      "duration": 2.4
    },
    {
      "lang": "en",
      "text": "bottlenecked in 2027 and 2028.",
      "offset": 4953.46,
      "duration": 2.06
    },
    {
      "lang": "en",
      "text": "The impulse to that will then be\n“okay, they'll just try and churn out",
      "offset": 4956.09,
      "duration": 5.386
    },
    {
      "lang": "en",
      "text": "as many possible semiconductors as\nwe can.” There'll be some lag there.",
      "offset": 4961.59,
      "duration": 3.379
    },
    {
      "lang": "en",
      "text": "A big part of how fast we can do that\nwill depend on how much people are",
      "offset": 4965.039,
      "duration": 4.581
    },
    {
      "lang": "en",
      "text": "feeling the AGI in the next two years\nas they're building out fab capacity.",
      "offset": 4969.62,
      "duration": 3.21
    },
    {
      "lang": "en",
      "text": "A lot will depend on",
      "offset": 4972.9,
      "duration": 1.61
    },
    {
      "lang": "en",
      "text": "the Taiwan situation.",
      "offset": 4977.8,
      "duration": 1.73
    },
    {
      "lang": "en",
      "text": "Is Taiwan still producing\nall the fabs and chips?",
      "offset": 4979.63,
      "duration": 2.53
    },
    {
      "lang": "en",
      "text": "There's another dynamic which was a reason\nEge and Tamay, when they were on the",
      "offset": 4982.389,
      "duration": 3.701
    },
    {
      "lang": "en",
      "text": "podcast, said that they were pessimistic.",
      "offset": 4986.289,
      "duration": 1.14
    },
    {
      "lang": "en",
      "text": "One, they think we're further away\nfrom solving these problems with",
      "offset": 4987.98,
      "duration": 4.96
    },
    {
      "lang": "en",
      "text": "long-context, coherent agency,\nadvanced multimodality than you think.",
      "offset": 4993.19,
      "duration": 3.909
    },
    {
      "lang": "en",
      "text": "Their",
      "offset": 4997.389,
      "duration": 0.5
    },
    {
      "lang": "en",
      "text": "point is that the progress that's\nhappened in the past over reasoning",
      "offset": 4999.59,
      "duration": 3.369
    },
    {
      "lang": "en",
      "text": "or something has required many orders\nof magnitude increase in compute.",
      "offset": 5002.959,
      "duration": 3.691
    },
    {
      "lang": "en",
      "text": "If this scale of compute increase can’t\ncontinue beyond 2030—not just because",
      "offset": 5007.22,
      "duration": 3.96
    },
    {
      "lang": "en",
      "text": "of chips, but also because of power\nand raw GDP even—then because we don't",
      "offset": 5011.18,
      "duration": 6.23
    },
    {
      "lang": "en",
      "text": "think we will get it by 2030 or 2028,",
      "offset": 5017.45,
      "duration": 1.37
    },
    {
      "lang": "en",
      "text": "then the probability per\nyear just goes down a bunch.",
      "offset": 5021.059,
      "duration": 3.626
    },
    {
      "lang": "en",
      "text": "Yeah.\nThis is like a bimodal distribution.",
      "offset": 5024.685,
      "duration": 1.325
    },
    {
      "lang": "en",
      "text": "A conversation that I had with Leopold\nturned into a section in Situational",
      "offset": 5026.29,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "Awareness called “this decade or\nbust”, which is on exactly this topic.",
      "offset": 5029.65,
      "duration": 3.18
    },
    {
      "lang": "en",
      "text": "Basically for the next couple\nof years, we can dramatically",
      "offset": 5033.83,
      "duration": 1.9
    },
    {
      "lang": "en",
      "text": "increase our training compute.",
      "offset": 5035.73,
      "duration": 1.02
    },
    {
      "lang": "en",
      "text": "And RL is going to be so exciting this\nyear because we can dramatically increase",
      "offset": 5036.99,
      "duration": 4.92
    },
    {
      "lang": "en",
      "text": "the amount of compute that we apply to it.",
      "offset": 5041.91,
      "duration": 1.46
    },
    {
      "lang": "en",
      "text": "This is also one of the reasons why\nthe gap between say DeepSeek and o1 was",
      "offset": 5044.25,
      "duration": 4.2
    },
    {
      "lang": "en",
      "text": "so close at the beginning of the year\nbecause they were able to apply the same",
      "offset": 5048.47,
      "duration": 4.47
    },
    {
      "lang": "en",
      "text": "amount of compute to the RL process.",
      "offset": 5052.94,
      "duration": 2.22
    },
    {
      "lang": "en",
      "text": "That compute differential actually will\nbe magnified over the course of the year.",
      "offset": 5057.369,
      "duration": 4.39
    },
    {
      "lang": "en",
      "text": "Bringing it back to the fact that\nthere's so much low-hanging fruit,",
      "offset": 5061.759,
      "duration": 3.361
    },
    {
      "lang": "en",
      "text": "it's been wild seeing the efficiency\ngains that these models have",
      "offset": 5065.72,
      "duration": 3.659
    },
    {
      "lang": "en",
      "text": "experienced over the last two years.",
      "offset": 5069.379,
      "duration": 1.791
    },
    {
      "lang": "en",
      "text": "Yes.",
      "offset": 5071.17,
      "duration": 0.5
    },
    {
      "lang": "en",
      "text": "With respect to DeepSeek, just\nreally hammering home, and",
      "offset": 5072.849,
      "duration": 2.611
    },
    {
      "lang": "en",
      "text": "Dario has a nice essay on this.",
      "offset": 5075.46,
      "duration": 1.84
    },
    {
      "lang": "en",
      "text": "DeepSeek was nine months\nafter Claude 3 Sonnet.",
      "offset": 5078.95,
      "duration": 4.78
    },
    {
      "lang": "en",
      "text": "If we retrained the same model today, or\nat the same time as the DeepSeek work, we",
      "offset": 5084.429,
      "duration": 5.821
    },
    {
      "lang": "en",
      "text": "also could have trained it for $5 million,\nor whatever the advertised amount was.",
      "offset": 5090.32,
      "duration": 4.219
    },
    {
      "lang": "en",
      "text": "So what's impressive or surprising\nis that DeepSeek has gotten to the",
      "offset": 5095.12,
      "duration": 4.95
    },
    {
      "lang": "en",
      "text": "frontier, but I think there's a\ncommon misconception still that they",
      "offset": 5100.07,
      "duration": 3.13
    },
    {
      "lang": "en",
      "text": "are above and beyond the frontier.",
      "offset": 5103.2,
      "duration": 1.84
    },
    {
      "lang": "en",
      "text": "I don't think that's right.",
      "offset": 5106.09,
      "duration": 0.749
    },
    {
      "lang": "en",
      "text": "I think they just waited and then\nwere able to take advantage of",
      "offset": 5106.84,
      "duration": 3.42
    },
    {
      "lang": "en",
      "text": "all the efficiency gains that\neveryone else was also seeing.",
      "offset": 5110.26,
      "duration": 2.36
    },
    {
      "lang": "en",
      "text": "Yeah.",
      "offset": 5112.71,
      "duration": 0.5
    },
    {
      "lang": "en",
      "text": "They're exactly on the cost curve\nthat you'd expect, which is not going",
      "offset": 5114.18,
      "duration": 5.209
    },
    {
      "lang": "en",
      "text": "to take away from their brilliant\nengineers and brilliant researchers.",
      "offset": 5119.389,
      "duration": 1.741
    },
    {
      "lang": "en",
      "text": "I look at their work, and I'm\nlike, &quot;Ah, the kindred soul,&quot;",
      "offset": 5121.71,
      "duration": 0.732
    },
    {
      "lang": "en",
      "text": "in the work they're doing.",
      "offset": 5122.442,
      "duration": 0.311
    },
    {
      "lang": "en",
      "text": "And to go from way behind\nthe frontier to like, &quot;Oh,",
      "offset": 5122.753,
      "duration": 0.617
    },
    {
      "lang": "en",
      "text": "this is a real player&quot;...",
      "offset": 5130.059,
      "duration": 1.021
    },
    {
      "lang": "en",
      "text": "Is super incredible.",
      "offset": 5131.08,
      "duration": 1.84
    },
    {
      "lang": "en",
      "text": "People say that they\nhave good research taste.",
      "offset": 5133.36,
      "duration": 1.659
    },
    {
      "lang": "en",
      "text": "Looking at their papers,\nwhat makes you say that?",
      "offset": 5135.33,
      "duration": 2.28
    },
    {
      "lang": "en",
      "text": "Yeah.",
      "offset": 5137.72,
      "duration": 0.5
    },
    {
      "lang": "en",
      "text": "I think their research taste\nis good in a way that I think",
      "offset": 5138.84,
      "duration": 2.839
    },
    {
      "lang": "en",
      "text": "Noam's research taste is good.",
      "offset": 5141.719,
      "duration": 1.59
    },
    {
      "lang": "en",
      "text": "Noam Brown?",
      "offset": 5143.309,
      "duration": 0.86
    },
    {
      "lang": "en",
      "text": "Noam Shazeer.",
      "offset": 5144.599,
      "duration": 0.75
    },
    {
      "lang": "en",
      "text": "Noam Brown also has good\nresearch taste, but Noam Shazeer.",
      "offset": 5145.379,
      "duration": 4.031
    },
    {
      "lang": "en",
      "text": "They very clearly understand this dance\nbetween the hardware systems that you're",
      "offset": 5150.27,
      "duration": 6.239
    },
    {
      "lang": "en",
      "text": "designing the models around and the",
      "offset": 5156.71,
      "duration": 2.119
    },
    {
      "lang": "en",
      "text": "algorithmic side of it.",
      "offset": 5160.95,
      "duration": 0.5
    },
    {
      "lang": "en",
      "text": "This is manifested in the way that the\nmodels give this sense of being perfectly",
      "offset": 5163.409,
      "duration": 5.56
    },
    {
      "lang": "en",
      "text": "designed up to their constraints.",
      "offset": 5168.97,
      "duration": 1.31
    },
    {
      "lang": "en",
      "text": "You can really very clearly\nsee what constraints they're",
      "offset": 5171.82,
      "duration": 2.97
    },
    {
      "lang": "en",
      "text": "thinking about as they're\niteratively solving these problems.",
      "offset": 5174.79,
      "duration": 2.07
    },
    {
      "lang": "en",
      "text": "Let's take the base Transformer and\ndiff that to DeepSeek v2 and v3.",
      "offset": 5178.28,
      "duration": 6.31
    },
    {
      "lang": "en",
      "text": "You can see them running up against the\nmemory bandwidth bottleneck in attention.",
      "offset": 5184.67,
      "duration": 5.02
    },
    {
      "lang": "en",
      "text": "Initially they do MLA to do\nthis, they trade flops for",
      "offset": 5190.65,
      "duration": 5.25
    },
    {
      "lang": "en",
      "text": "memory bandwidth basically.",
      "offset": 5195.9,
      "duration": 1.189
    },
    {
      "lang": "en",
      "text": "Then they do this thing called\nNSA, where they more selectively",
      "offset": 5198.04,
      "duration": 2.74
    },
    {
      "lang": "en",
      "text": "load memory bandwidth.",
      "offset": 5200.78,
      "duration": 1.16
    },
    {
      "lang": "en",
      "text": "You can see this is because the\nmodel that they trained with MLA was",
      "offset": 5202.1,
      "duration": 3.91
    },
    {
      "lang": "en",
      "text": "on H800s, so it has a lot of flops.",
      "offset": 5206.01,
      "duration": 2.08
    },
    {
      "lang": "en",
      "text": "So they were like, &quot;Okay, we can freely\nuse the flops.&quot; But then the export",
      "offset": 5208.81,
      "duration": 3.859
    },
    {
      "lang": "en",
      "text": "controls from Biden came in, or they\nknew they would have less of those chips",
      "offset": 5212.67,
      "duration": 7.77
    },
    {
      "lang": "en",
      "text": "going forward, and so they traded off\nto a more memory bandwidth-oriented",
      "offset": 5220.44,
      "duration": 4.31
    },
    {
      "lang": "en",
      "text": "algorithmic solution there.",
      "offset": 5224.76,
      "duration": 1.35
    },
    {
      "lang": "en",
      "text": "You see a similar thing with their\napproach to sparsity, where they're",
      "offset": 5227.509,
      "duration": 2.541
    },
    {
      "lang": "en",
      "text": "iteratively working out the best\nway to do this over multiple papers.",
      "offset": 5230.66,
      "duration": 2.71
    },
    {
      "lang": "en",
      "text": "The part that I like is that it's simple.",
      "offset": 5234.799,
      "duration": 3.681
    },
    {
      "lang": "en",
      "text": "A big failure mode that a lot of\nML researchers have is you do these",
      "offset": 5239.18,
      "duration": 4.53
    },
    {
      "lang": "en",
      "text": "overly complicated things that don't\nthink hard enough about the hardware",
      "offset": 5243.89,
      "duration": 3.73
    },
    {
      "lang": "en",
      "text": "systems that you have in mind, whereas\nwith the first DeepSeek sparsity",
      "offset": 5247.62,
      "duration": 6.92
    },
    {
      "lang": "en",
      "text": "MoE solution, they design these rack",
      "offset": 5254.55,
      "duration": 3.59
    },
    {
      "lang": "en",
      "text": "and node-level load balancing losses.",
      "offset": 5260.17,
      "duration": 2.84
    },
    {
      "lang": "en",
      "text": "You can see them being like, &quot;Okay, we\nhave to perfectly balance it on this.&quot;",
      "offset": 5263.14,
      "duration": 2.58
    },
    {
      "lang": "en",
      "text": "Then they actually come up with a much\nbetter solution later on where they",
      "offset": 5265.72,
      "duration": 3.169
    },
    {
      "lang": "en",
      "text": "don't have to have the auxiliary loss,",
      "offset": 5268.889,
      "duration": 1.621
    },
    {
      "lang": "en",
      "text": "where they just have these\nbias terms that they put in.",
      "offset": 5272.54,
      "duration": 2.37
    },
    {
      "lang": "en",
      "text": "And it's cool.\nIsn't that less simple?",
      "offset": 5275.53,
      "duration": 1.13
    },
    {
      "lang": "en",
      "text": "You're manually putting\nin a bias rather than…",
      "offset": 5276.85,
      "duration": 1.86
    },
    {
      "lang": "en",
      "text": "But balancing auxiliary loss is annoying.",
      "offset": 5279.41,
      "duration": 1.84
    },
    {
      "lang": "en",
      "text": "You're making the model\ntrade off this thing.",
      "offset": 5281.26,
      "duration": 4.009
    },
    {
      "lang": "en",
      "text": "With auxiliary losses, you have to\ncontrol the coefficient and the weighting.",
      "offset": 5286.41,
      "duration": 2.33
    },
    {
      "lang": "en",
      "text": "The bias is cleaner in some respects.",
      "offset": 5289.88,
      "duration": 1.829
    },
    {
      "lang": "en",
      "text": "Interesting.",
      "offset": 5291.74,
      "duration": 0.5
    },
    {
      "lang": "en",
      "text": "Did they have to change\nit through training?",
      "offset": 5292.52,
      "duration": 1.5
    },
    {
      "lang": "en",
      "text": "They did have to change it\nduring training, I think.",
      "offset": 5294.77,
      "duration": 3.01
    },
    {
      "lang": "en",
      "text": "Does all training involve\ncontinuously fucking with these",
      "offset": 5297.78,
      "duration": 4.929
    },
    {
      "lang": "en",
      "text": "values as you're going through it?",
      "offset": 5302.71,
      "duration": 1.34
    },
    {
      "lang": "en",
      "text": "It depends on what your architecture is.",
      "offset": 5304.05,
      "duration": 1.63
    },
    {
      "lang": "en",
      "text": "But I thought it was just cute that you\ncan see them running up into this very",
      "offset": 5306.66,
      "duration": 4.67
    },
    {
      "lang": "en",
      "text": "hardware-level constraint, trying to\ngo, &quot;What do we wish we could express",
      "offset": 5311.34,
      "duration": 3.259
    },
    {
      "lang": "en",
      "text": "algorithmically? What can we express\nunder our constraints?&quot; and iteratively",
      "offset": 5314.62,
      "duration": 3.83
    },
    {
      "lang": "en",
      "text": "solving to get better constraints.",
      "offset": 5318.45,
      "duration": 1.799
    },
    {
      "lang": "en",
      "text": "And doing this in a really simple\nand elegant way, and then backing",
      "offset": 5320.3,
      "duration": 3.91
    },
    {
      "lang": "en",
      "text": "it up with great engineering.",
      "offset": 5324.21,
      "duration": 0.819
    },
    {
      "lang": "en",
      "text": "I also thought it was interesting\nthat they incorporated the multi-token",
      "offset": 5325.92,
      "duration": 3.19
    },
    {
      "lang": "en",
      "text": "prediction thing from Meta.",
      "offset": 5329.11,
      "duration": 1.23
    },
    {
      "lang": "en",
      "text": "So Meta had a nice paper on this\nmulti-token prediction thing.",
      "offset": 5330.889,
      "duration": 2.291
    },
    {
      "lang": "en",
      "text": "Actually, I don't know if it's good or\nbad, but Meta didn't include it in Llama,",
      "offset": 5333.85,
      "duration": 4.229
    },
    {
      "lang": "en",
      "text": "but Deepseek did include it in their\npaper, which I think is interesting.",
      "offset": 5338.399,
      "duration": 3.431
    },
    {
      "lang": "en",
      "text": "Was that because they were faster at\niterating and including an algorithm?",
      "offset": 5344.99,
      "duration": 2.75
    },
    {
      "lang": "en",
      "text": "Or did Meta decide that actually it\nwasn't a good algorithmic change at",
      "offset": 5348.43,
      "duration": 0.93
    },
    {
      "lang": "en",
      "text": "scale?",
      "offset": 5351.53,
      "duration": 0.5
    },
    {
      "lang": "en",
      "text": "I don't know.",
      "offset": 5352.21,
      "duration": 0.5
    },
    {
      "lang": "en",
      "text": "It was really interesting to\nme as somebody who's had people",
      "offset": 5353.24,
      "duration": 3.429
    },
    {
      "lang": "en",
      "text": "on the podcast to discuss this.",
      "offset": 5356.75,
      "duration": 1.179
    },
    {
      "lang": "en",
      "text": "It's interesting from the perspective\nof what's happening in AI right now, but",
      "offset": 5359.54,
      "duration": 2.279
    },
    {
      "lang": "en",
      "text": "also from the perspective of the fact that\nI've been having abstract conversations",
      "offset": 5361.82,
      "duration": 3.779
    },
    {
      "lang": "en",
      "text": "with people about what an intelligence\nexplosion would look like, or what it",
      "offset": 5365.6,
      "duration": 2.398
    },
    {
      "lang": "en",
      "text": "would look like for AI to automate AI R&amp;D.",
      "offset": 5367.998,
      "duration": 1.712
    },
    {
      "lang": "en",
      "text": "Just getting a more tangible\nsense of what's involved",
      "offset": 5370.03,
      "duration": 3.05
    },
    {
      "lang": "en",
      "text": "in making this AI progress.",
      "offset": 5373.08,
      "duration": 1.16
    },
    {
      "lang": "en",
      "text": "One of the questions I\nwas debating with Daniel,",
      "offset": 5376.599,
      "duration": 1.551
    },
    {
      "lang": "en",
      "text": "or I was asking him, is how many of the\nimprovements require a deep conceptual",
      "offset": 5380.58,
      "duration": 5.099
    },
    {
      "lang": "en",
      "text": "understanding versus how many are\njust monkeys trying ideas where you",
      "offset": 5385.68,
      "duration": 3.222
    },
    {
      "lang": "en",
      "text": "could just run a bunch in parallel.",
      "offset": 5388.902,
      "duration": 1.208
    },
    {
      "lang": "en",
      "text": "It seems like the MLA thing is motivated\nby this deep conceptual understanding of,",
      "offset": 5390.28,
      "duration": 5.019
    },
    {
      "lang": "en",
      "text": "“each attention head only needs to see the\nsubspace that's relevant to its attention",
      "offset": 5395.299,
      "duration": 4.021
    },
    {
      "lang": "en",
      "text": "pattern.” I feel like that just required\na lot of conceptual insight in a way",
      "offset": 5399.32,
      "duration": 6.63
    },
    {
      "lang": "en",
      "text": "that these models are especially bad at.",
      "offset": 5405.95,
      "duration": 1.859
    },
    {
      "lang": "en",
      "text": "I don't know how the load balancing thing\nworks, but that just seems like maybe you",
      "offset": 5410.65,
      "duration": 2.09
    },
    {
      "lang": "en",
      "text": "could try it out and see what happens.",
      "offset": 5412.74,
      "duration": 1.024
    },
    {
      "lang": "en",
      "text": "Yeah, that's probably just\nlike them trying out a whole",
      "offset": 5413.764,
      "duration": 1.546
    },
    {
      "lang": "en",
      "text": "bunch of different things.",
      "offset": 5415.31,
      "duration": 0.55
    },
    {
      "lang": "en",
      "text": "So what fraction is which,\nI'd be curious about?",
      "offset": 5416.39,
      "duration": 1.98
    },
    {
      "lang": "en",
      "text": "Yeah, I don't know about fractions.",
      "offset": 5418.42,
      "duration": 1.31
    },
    {
      "lang": "en",
      "text": "It might be like you have a hunch for\na core problem, you can think of 10",
      "offset": 5419.73,
      "duration": 3.659
    },
    {
      "lang": "en",
      "text": "possible ways to solve it, and then you\njust need to try them and see what works.",
      "offset": 5423.4,
      "duration": 4.07
    },
    {
      "lang": "en",
      "text": "That's where the trial and error\nsorcery of deep learning can kick in.",
      "offset": 5428.05,
      "duration": 4.23
    },
    {
      "lang": "en",
      "text": "And Noam Shazeer will talk about\nthis, about how 5% of his ideas work.",
      "offset": 5432.28,
      "duration": 5.45
    },
    {
      "lang": "en",
      "text": "So even he, a vaunted God of\nmodel architecture design, has",
      "offset": 5438.56,
      "duration": 6.149
    },
    {
      "lang": "en",
      "text": "a relatively low hit rate, but\nhe just tries so many things.",
      "offset": 5445.45,
      "duration": 2.14
    },
    {
      "lang": "en",
      "text": "Right.",
      "offset": 5447.59,
      "duration": 0.25
    },
    {
      "lang": "en",
      "text": "Or being able to come up with\nany ideas in the first place.",
      "offset": 5447.84,
      "duration": 1.939
    },
    {
      "lang": "en",
      "text": "One mechanism could be that\nNoam just doesn't have to do",
      "offset": 5450.77,
      "duration": 2.849
    },
    {
      "lang": "en",
      "text": "any of the engineering work.",
      "offset": 5453.619,
      "duration": 1.14
    },
    {
      "lang": "en",
      "text": "He can just abstractly\nexpress an intuition.",
      "offset": 5454.759,
      "duration": 2.501
    },
    {
      "lang": "en",
      "text": "Yeah.",
      "offset": 5457.33,
      "duration": 0.5
    },
    {
      "lang": "en",
      "text": "I actually think your rates of\nprogress almost don't change that",
      "offset": 5457.83,
      "duration": 3.589
    },
    {
      "lang": "en",
      "text": "much depending on so long as it's able\nto completely implement these ideas.",
      "offset": 5461.42,
      "duration": 4.089
    },
    {
      "lang": "en",
      "text": "Say more?",
      "offset": 5466.589,
      "duration": 0.5
    },
    {
      "lang": "en",
      "text": "If you have Noam Shazeer at 100x\nspeed, that's still kind of wild.",
      "offset": 5467.21,
      "duration": 4.36
    },
    {
      "lang": "en",
      "text": "There's all these fallbacks of wild\nworlds, where even if you don't get",
      "offset": 5473.359,
      "duration": 4.821
    },
    {
      "lang": "en",
      "text": "100% Noam Shazeer-level intuition\nin model design, it's still okay",
      "offset": 5479.13,
      "duration": 5.9
    },
    {
      "lang": "en",
      "text": "if you just accelerate him by 100X.",
      "offset": 5485.03,
      "duration": 1.439
    },
    {
      "lang": "en",
      "text": "Right.",
      "offset": 5486.5,
      "duration": 0.5
    },
    {
      "lang": "en",
      "text": "Especially since your compute\nbottleneck anyway, so trying out his",
      "offset": 5487.23,
      "duration": 2.959
    },
    {
      "lang": "en",
      "text": "ideas… Or I guess he doesn't have the\ncompute to try out all of his ideas.",
      "offset": 5490.19,
      "duration": 2.3
    },
    {
      "lang": "en",
      "text": "But Dwarkesh, you said, &quot;Oh, well, the\nmodel can do the more straightforward",
      "offset": 5492.65,
      "duration": 3.96
    },
    {
      "lang": "en",
      "text": "things and not the deep thought.&quot; I do\nwant to push back on that a little bit.",
      "offset": 5496.62,
      "duration": 3.189
    },
    {
      "lang": "en",
      "text": "I think, again, if the model has\nthe right context and scaffolding,",
      "offset": 5500.52,
      "duration": 3.71
    },
    {
      "lang": "en",
      "text": "it's starting to be able to do\nsome really interesting things.",
      "offset": 5504.24,
      "duration": 2.539
    },
    {
      "lang": "en",
      "text": "The Interp agent has been a surprise\nto people, even internally, at how",
      "offset": 5507.529,
      "duration": 5.131
    },
    {
      "lang": "en",
      "text": "good it is at finding the needle in the\nhaystack when it plays the auditing game,",
      "offset": 5512.7,
      "duration": 4.35
    },
    {
      "lang": "en",
      "text": "finding this reward model bias feature,\nand then reasoning about it, and then",
      "offset": 5517.07,
      "duration": 3.949
    },
    {
      "lang": "en",
      "text": "systematically testing its hypotheses.",
      "offset": 5521.02,
      "duration": 1.399
    },
    {
      "lang": "en",
      "text": "So it looks at that feature, then it\nlooks at similar features, it finds",
      "offset": 5523.29,
      "duration": 3.49
    },
    {
      "lang": "en",
      "text": "one with a preference for chocolate.",
      "offset": 5526.78,
      "duration": 1.45
    },
    {
      "lang": "en",
      "text": "It's like, &quot;Huh, that's really weird\nthat the model wants to add chocolate",
      "offset": 5528.43,
      "duration": 2.74
    },
    {
      "lang": "en",
      "text": "to recipes. Let me test it.&quot; So then it\nwill make up like, &quot;Hey, I'm trying to",
      "offset": 5531.17,
      "duration": 4.589
    },
    {
      "lang": "en",
      "text": "make a tomato soup. What would be a good\ningredient for it?&quot; And then sees that",
      "offset": 5535.76,
      "duration": 4.37
    },
    {
      "lang": "en",
      "text": "the model replies chocolate, reasons\nthrough it, and then keeps going, right?",
      "offset": 5540.13,
      "duration": 4.95
    },
    {
      "lang": "en",
      "text": "There is conceptual understanding.\nDeep conceptual understanding",
      "offset": 5546.98,
      "duration": 0.23
    },
    {
      "lang": "en",
      "text": "And even where, especially it's\nspotted, it's like, &quot;Oh, this",
      "offset": 5547.21,
      "duration": 2.63
    },
    {
      "lang": "en",
      "text": "is a key part of its persona.",
      "offset": 5549.84,
      "duration": 1.59
    },
    {
      "lang": "en",
      "text": "I see this Oxford paper.",
      "offset": 5551.73,
      "duration": 1.27
    },
    {
      "lang": "en",
      "text": "What if I change Oxford to Stanford?",
      "offset": 5553,
      "duration": 1.639
    },
    {
      "lang": "en",
      "text": "What if I now say Richard Feynman really\nlikes this thing?&quot; It's really carving out",
      "offset": 5554.889,
      "duration": 5.56
    },
    {
      "lang": "en",
      "text": "the hypothesis space and testing things\nin a way that I'm kind of surprised by.",
      "offset": 5560.469,
      "duration": 4.941
    },
    {
      "lang": "en",
      "text": "Also, by the way, ML research is\none of the easier things to RL",
      "offset": 5565.47,
      "duration": 2.76
    },
    {
      "lang": "en",
      "text": "on in some respects, once you get\nto a certain level of capability.",
      "offset": 5568.23,
      "duration": 2.38
    },
    {
      "lang": "en",
      "text": "It's a very well-defined\nobjective function.",
      "offset": 5571.389,
      "duration": 2.63
    },
    {
      "lang": "en",
      "text": "Did the loss go down?",
      "offset": 5574.139,
      "duration": 0.781
    },
    {
      "lang": "en",
      "text": "Make number go down.",
      "offset": 5574.92,
      "duration": 1.169
    },
    {
      "lang": "en",
      "text": "Make number go down.",
      "offset": 5576.099,
      "duration": 1.62
    },
    {
      "lang": "en",
      "text": "Or make number go up, depending\non which number it is.",
      "offset": 5578.289,
      "duration": 3.631
    },
    {
      "lang": "en",
      "text": "Just flip the sign.",
      "offset": 5582.8,
      "duration": 0.77
    },
    {
      "lang": "en",
      "text": "Just flip the sign.",
      "offset": 5583.57,
      "duration": 1.473
    },
    {
      "lang": "en",
      "text": "And so, once you get to the stage\nwhere your models are capable of",
      "offset": 5585.043,
      "duration": 2.756
    },
    {
      "lang": "en",
      "text": "implementing one of Noam's ideas,\nand then you can just let them loose",
      "offset": 5587.98,
      "duration": 5.33
    },
    {
      "lang": "en",
      "text": "and let them build that intuition\nof how to do scientific discovery.",
      "offset": 5593.31,
      "duration": 4.57
    },
    {
      "lang": "en",
      "text": "The key thing here, again,\nis the feedback loops of.",
      "offset": 5598.66,
      "duration": 1.99
    },
    {
      "lang": "en",
      "text": "I expect scientific areas where you are\nable to put it in a feedback loop to",
      "offset": 5601.21,
      "duration": 5.08
    },
    {
      "lang": "en",
      "text": "have, eventually, superhuman performance.",
      "offset": 5607.349,
      "duration": 2.311
    },
    {
      "lang": "en",
      "text": "One prediction I have is that we're\ngoing to move away from “can an agent",
      "offset": 5610.13,
      "duration": 3.32
    },
    {
      "lang": "en",
      "text": "do XYZ”, and more towards “can I\nefficiently deploy, launch 100 agents",
      "offset": 5613.45,
      "duration": 6.65
    },
    {
      "lang": "en",
      "text": "and then give them the feedback they\nneed, and even just be able to easily",
      "offset": 5620.53,
      "duration": 4.569
    },
    {
      "lang": "en",
      "text": "verify what they're up to” right?",
      "offset": 5625.099,
      "duration": 1.641
    },
    {
      "lang": "en",
      "text": "There's this generator verifier gap\nthat people talk about where it's much",
      "offset": 5626.75,
      "duration": 3.749
    },
    {
      "lang": "en",
      "text": "easier to check something than it is\nto produce the solution on your own.",
      "offset": 5630.53,
      "duration": 3.32
    },
    {
      "lang": "en",
      "text": "But it's very plausible to me, we'll\nbe at the point where it's so easy",
      "offset": 5634.139,
      "duration": 4.231
    },
    {
      "lang": "en",
      "text": "to generate with these agents that\nthe bottleneck is actually, can",
      "offset": 5638.37,
      "duration": 3.14
    },
    {
      "lang": "en",
      "text": "I as the human verify the answer?",
      "offset": 5641.53,
      "duration": 2.04
    },
    {
      "lang": "en",
      "text": "And again, you're guaranteed to\nget an answer with these things.",
      "offset": 5644.09,
      "duration": 2.839
    },
    {
      "lang": "en",
      "text": "So, ideally, you have some automated\nway to evaluate and test a score",
      "offset": 5647.4,
      "duration": 5.83
    },
    {
      "lang": "en",
      "text": "for how well it worked, how\nwell did this thing generalize?",
      "offset": 5653.23,
      "duration": 3.47
    },
    {
      "lang": "en",
      "text": "And at a minimum, you have a\nway to easily summarize what",
      "offset": 5657.94,
      "duration": 3.299
    },
    {
      "lang": "en",
      "text": "a bunch of agents are finding.",
      "offset": 5661.26,
      "duration": 1.53
    },
    {
      "lang": "en",
      "text": "It's like, okay, well if 20 of my 100\nagents all found this one thing, then",
      "offset": 5662.87,
      "duration": 3.959
    },
    {
      "lang": "en",
      "text": "it has a higher chance of being true.",
      "offset": 5666.829,
      "duration": 1.761
    },
    {
      "lang": "en",
      "text": "And again, software engineering\nis going to be the leading",
      "offset": 5669.51,
      "duration": 1.98
    },
    {
      "lang": "en",
      "text": "indicator of that, right?",
      "offset": 5671.5,
      "duration": 0.86
    },
    {
      "lang": "en",
      "text": "Over the remainder of the year, basically\nwe're going to see progressively more and",
      "offset": 5672.75,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "more experiments of the form of how can\nI dispatch work to a software engineering",
      "offset": 5677.63,
      "duration": 4.75
    },
    {
      "lang": "en",
      "text": "agent in such a way that it’s async?",
      "offset": 5682.38,
      "duration": 2.13
    },
    {
      "lang": "en",
      "text": "Claude 4 has GitHub integration,\nwhere you can ask it to do things on",
      "offset": 5684.73,
      "duration": 3.29
    },
    {
      "lang": "en",
      "text": "GitHub, ask it to do pull requests,\nthis kind of stuff that's coming up.",
      "offset": 5688.02,
      "duration": 2.369
    },
    {
      "lang": "en",
      "text": "OpenAI’s Codex is example\nof this basically.",
      "offset": 5692.269,
      "duration": 2.751
    },
    {
      "lang": "en",
      "text": "You can almost see this\nin the coding startups.",
      "offset": 5697.57,
      "duration": 1.92
    },
    {
      "lang": "en",
      "text": "I think of this product exponential\nin some respects where you need to",
      "offset": 5699.49,
      "duration": 4.109
    },
    {
      "lang": "en",
      "text": "be designing for a few months ahead\nof the model, to make sure that the",
      "offset": 5703.719,
      "duration": 3.641
    },
    {
      "lang": "en",
      "text": "product you build is the right one.",
      "offset": 5707.36,
      "duration": 1.199
    },
    {
      "lang": "en",
      "text": "You saw last year, Cursor hit\nPMF with Claude 3.5 Sonnet.",
      "offset": 5709.65,
      "duration": 4.93
    },
    {
      "lang": "en",
      "text": "They were around for a while before,\nbut then the model was finally good",
      "offset": 5714.809,
      "duration": 2.861
    },
    {
      "lang": "en",
      "text": "enough that the vision they had\nof how people would program, hit.",
      "offset": 5717.67,
      "duration": 2.53
    },
    {
      "lang": "en",
      "text": "And then Windsurf bet a little bit more\naggressively even on the agenticness of",
      "offset": 5722.549,
      "duration": 5.631
    },
    {
      "lang": "en",
      "text": "the model, with longer-running agentic\nworkflows and this kind of stuff.",
      "offset": 5728.18,
      "duration": 4.4
    },
    {
      "lang": "en",
      "text": "I think that's when they began\ncompeting with Cursor, when they",
      "offset": 5732.58,
      "duration": 3.079
    },
    {
      "lang": "en",
      "text": "bet on that particular vision.",
      "offset": 5735.66,
      "duration": 1.989
    },
    {
      "lang": "en",
      "text": "The next one is you're not\neven in the loop, so to speak.",
      "offset": 5738.13,
      "duration": 4.379
    },
    {
      "lang": "en",
      "text": "You're not in an IDE.",
      "offset": 5742.52,
      "duration": 1.119
    },
    {
      "lang": "en",
      "text": "But you're asking the model to go\ndo work in the same way that you",
      "offset": 5743.64,
      "duration": 2.69
    },
    {
      "lang": "en",
      "text": "would ask someone on your team to",
      "offset": 5746.33,
      "duration": 1.47
    },
    {
      "lang": "en",
      "text": "go do work.",
      "offset": 5751.1,
      "duration": 0.422
    },
    {
      "lang": "en",
      "text": "That is not quite ready yet.",
      "offset": 5751.522,
      "duration": 1.507
    },
    {
      "lang": "en",
      "text": "There are still a lot of tasks\nwhere you need to be in the loop.",
      "offset": 5753.029,
      "duration": 2.91
    },
    {
      "lang": "en",
      "text": "But the next six months look\nlike an exploration of exactly",
      "offset": 5756.289,
      "duration": 3.911
    },
    {
      "lang": "en",
      "text": "what that trendline looks like.",
      "offset": 5760.2,
      "duration": 0.95
    },
    {
      "lang": "en",
      "text": "But just to be really concrete or\npedantic about the bottlenecks here,",
      "offset": 5761.72,
      "duration": 3.18
    },
    {
      "lang": "en",
      "text": "a lot of it is, again, just tooling.",
      "offset": 5764.92,
      "duration": 1.77
    },
    {
      "lang": "en",
      "text": "And are the pipes connected?",
      "offset": 5766.69,
      "duration": 1.19
    },
    {
      "lang": "en",
      "text": "A lot of things, I can't just launch\nClaude and have it go and solve because",
      "offset": 5768.51,
      "duration": 5.22
    },
    {
      "lang": "en",
      "text": "maybe it needs a GPU, or maybe I need\nvery careful permissioning so that it",
      "offset": 5773.73,
      "duration": 4.199
    },
    {
      "lang": "en",
      "text": "can't just take over an entire cluster\nand launch a whole bunch of things.",
      "offset": 5777.93,
      "duration": 4.01
    },
    {
      "lang": "en",
      "text": "So you really do need good sandboxing\nand the ability to use all of",
      "offset": 5782.32,
      "duration": 5.215
    },
    {
      "lang": "en",
      "text": "the tools that are necessary.",
      "offset": 5787.54,
      "duration": 1.059
    },
    {
      "lang": "en",
      "text": "And we're almost certainly\nunder-eliciting dramatically.",
      "offset": 5788.61,
      "duration": 2.57
    },
    {
      "lang": "en",
      "text": "When you look at METR’s evals\nof can the model solve the task,",
      "offset": 5791.309,
      "duration": 3
    },
    {
      "lang": "en",
      "text": "they're there solving them for\nhours over multiple iterations.",
      "offset": 5794.51,
      "duration": 4.15
    },
    {
      "lang": "en",
      "text": "Eventually, one of them is like,\n&quot;Oh, yeah. I've come back and I've",
      "offset": 5799.65,
      "duration": 1.73
    },
    {
      "lang": "en",
      "text": "solved the task.&quot; Me, at the moment\nat least, maybe the fault is my own.",
      "offset": 5801.38,
      "duration": 3.41
    },
    {
      "lang": "en",
      "text": "But I try the model on doing\nsomething, and if it can't do it,",
      "offset": 5805.09,
      "duration": 2.489
    },
    {
      "lang": "en",
      "text": "I'm like, &quot;Okay, fine. I'll do it.&quot;",
      "offset": 5807.589,
      "duration": 0.861
    },
    {
      "lang": "en",
      "text": "Which is so interesting because we\ndon't even treat other humans this way.",
      "offset": 5810.05,
      "duration": 2.419
    },
    {
      "lang": "en",
      "text": "Right.\nExactly.",
      "offset": 5812.74,
      "duration": 0.253
    },
    {
      "lang": "en",
      "text": "If you hire a new employee,\nyou're not like...",
      "offset": 5812.993,
      "duration": 2.667
    },
    {
      "lang": "en",
      "text": "&quot;I'll do it.&quot;",
      "offset": 5815.88,
      "duration": 0.56
    },
    {
      "lang": "en",
      "text": "You're going to spend literally\nweeks giving them feedback whereas",
      "offset": 5817.259,
      "duration": 4.521
    },
    {
      "lang": "en",
      "text": "we'll give up on a model in minutes.",
      "offset": 5821.99,
      "duration": 1.54
    },
    {
      "lang": "en",
      "text": "Yes, exactly.",
      "offset": 5823.559,
      "duration": 0.83
    },
    {
      "lang": "en",
      "text": "But I think part of it\nis, it it async or not?",
      "offset": 5824.679,
      "duration": 2.781
    },
    {
      "lang": "en",
      "text": "Yes.",
      "offset": 5827.549,
      "duration": 0.481
    },
    {
      "lang": "en",
      "text": "And if it's human in the loop, then\nit's so much more effortful unless it's",
      "offset": 5828.03,
      "duration": 3.499
    },
    {
      "lang": "en",
      "text": "getting a reply immediately... I've\nnoticed if I don't have a second monitor",
      "offset": 5831.619,
      "duration": 4.431
    },
    {
      "lang": "en",
      "text": "with Claude Code always open in the\nsecond monitor, I won't really use it.",
      "offset": 5836.15,
      "duration": 4.04
    },
    {
      "lang": "en",
      "text": "It's only when it's right there,\nand I can send off something.",
      "offset": 5840.73,
      "duration": 3.869
    },
    {
      "lang": "en",
      "text": "If it hits, great.",
      "offset": 5844.62,
      "duration": 0.96
    },
    {
      "lang": "en",
      "text": "If not, I'm working on\nit at the same time.",
      "offset": 5845.61,
      "duration": 2.22
    },
    {
      "lang": "en",
      "text": "But this more async form factor, I\nexpect to really quite dramatically",
      "offset": 5847.83,
      "duration": 4.01
    },
    {
      "lang": "en",
      "text": "improve the experience of these models.",
      "offset": 5851.84,
      "duration": 1.04
    },
    {
      "lang": "en",
      "text": "Interesting, interesting.",
      "offset": 5852.91,
      "duration": 0.84
    },
    {
      "lang": "en",
      "text": "You can just say, let's\nsee if it can do that.",
      "offset": 5853.75,
      "duration": 2.41
    },
    {
      "lang": "en",
      "text": "Let's give it a whirl.\nTry 10 different approaches.",
      "offset": 5856.16,
      "duration": 0.08
    },
    {
      "lang": "en",
      "text": "Yeah,",
      "offset": 5856.24,
      "duration": 0.5
    },
    {
      "lang": "en",
      "text": "just fire it off.",
      "offset": 5859.96,
      "duration": 0.69
    },
    {
      "lang": "en",
      "text": "Fire it off.",
      "offset": 5860.9,
      "duration": 0.55
    },
    {
      "lang": "en",
      "text": "Before we end this episode, I do\nwant to get back at this crux of",
      "offset": 5862.139,
      "duration": 4.061
    },
    {
      "lang": "en",
      "text": "why does the progress that you're\ntalking about in computer use",
      "offset": 5868.61,
      "duration": 2.85
    },
    {
      "lang": "en",
      "text": "agents, and white collar work\nhappen over the next few years?",
      "offset": 5871.46,
      "duration": 1.839
    },
    {
      "lang": "en",
      "text": "Why is this not a thing\nthat takes decades?",
      "offset": 5873.3,
      "duration": 1.469
    },
    {
      "lang": "en",
      "text": "I think the crux comes down to",
      "offset": 5874.78,
      "duration": 1.859
    },
    {
      "lang": "en",
      "text": "the people who expect something\nmuch longer have a sense that…",
      "offset": 5879.15,
      "duration": 3.42
    },
    {
      "lang": "en",
      "text": "When I had Ege and Tamay on my podcast,\nthey were like, &quot;Look, you could look",
      "offset": 5885.95,
      "duration": 3.39
    },
    {
      "lang": "en",
      "text": "at AlphaGo, and say, 'Oh, this is a\nmodel that can do exploration. AlphaZero",
      "offset": 5889.34,
      "duration": 3.14
    },
    {
      "lang": "en",
      "text": "can generalize to new video games.\nIt has all these priors about how to",
      "offset": 5894.61,
      "duration": 4.22
    },
    {
      "lang": "en",
      "text": "engage with the world, and so forth.&quot;",
      "offset": 5898.849,
      "duration": 1.095
    },
    {
      "lang": "en",
      "text": "And the intellectual\nceiling is really high.",
      "offset": 5899.944,
      "duration": 1.645
    },
    {
      "lang": "en",
      "text": "Yeah, exactly.",
      "offset": 5901.65,
      "duration": 0.729
    },
    {
      "lang": "en",
      "text": "In retrospect, obviously a bunch of the\nmethods are still used today in deep",
      "offset": 5903.33,
      "duration": 3
    },
    {
      "lang": "en",
      "text": "learning, and you can see similar things\nin the models that we train today.",
      "offset": 5906.33,
      "duration": 5.15
    },
    {
      "lang": "en",
      "text": "But it was fundamentally not a baby\nAGI that we just had to add a little",
      "offset": 5911.51,
      "duration": 6.879
    },
    {
      "lang": "en",
      "text": "sprinkle of something else on top of\nin order to make it the LLMs of today.",
      "offset": 5918.549,
      "duration": 3.78
    },
    {
      "lang": "en",
      "text": "I just want to very directly\naddress this crux of, why are LLMs",
      "offset": 5925.19,
      "duration": 5.67
    },
    {
      "lang": "en",
      "text": "in a much different position of\nrespect to true AGI than AlphaZero?",
      "offset": 5932.45,
      "duration": 5.629
    },
    {
      "lang": "en",
      "text": "Why are they actually the base on\nwhich adding in a few extra drops",
      "offset": 5938.24,
      "duration": 4.14
    },
    {
      "lang": "en",
      "text": "of this kind of care, and attention\ngets us to human-level intelligence?",
      "offset": 5942.38,
      "duration": 5.169
    },
    {
      "lang": "en",
      "text": "I think one important point is\nthat when you look at AlphaZero, it",
      "offset": 5948.37,
      "duration": 5.179
    },
    {
      "lang": "en",
      "text": "does have all of those ingredients.",
      "offset": 5953.679,
      "duration": 1.241
    },
    {
      "lang": "en",
      "text": "In particular I think the intellectual\nceiling goes quite—contra what I",
      "offset": 5954.95,
      "duration": 5.03
    },
    {
      "lang": "en",
      "text": "was saying before, which is we've\ndemonstrated this incredible complexity",
      "offset": 5959.98,
      "duration": 2.17
    },
    {
      "lang": "en",
      "text": "of math, and programming problems…",
      "offset": 5962.15,
      "duration": 1.069
    },
    {
      "lang": "en",
      "text": "I do think that the type of\ntask and setting that AlphaZero",
      "offset": 5963.219,
      "duration": 6.471
    },
    {
      "lang": "en",
      "text": "worked in this two-player perfect\ninformation game basically is",
      "offset": 5971.38,
      "duration": 5.63
    },
    {
      "lang": "en",
      "text": "incredibly friendly to RL algorithms.",
      "offset": 5977.01,
      "duration": 2.52
    },
    {
      "lang": "en",
      "text": "The reason it took so long to get to a\nmore proto-AGI style models is you do",
      "offset": 5981.42,
      "duration": 6.959
    },
    {
      "lang": "en",
      "text": "need to crack that general conceptual\nunderstanding of the world, and language,",
      "offset": 5988.38,
      "duration": 3.879
    },
    {
      "lang": "en",
      "text": "and this kind of stuff, and you need to\nget the initial reward signal on tasks",
      "offset": 5992.26,
      "duration": 5.01
    },
    {
      "lang": "en",
      "text": "that you care about in the real world,\nwhich are harder to specify than games.",
      "offset": 5997.28,
      "duration": 3.8
    },
    {
      "lang": "en",
      "text": "I think then that sort of gradient\nsignal that comes from the real",
      "offset": 6002.12,
      "duration": 4.729
    },
    {
      "lang": "en",
      "text": "world, all of a sudden you get access\nto it, and you can start climbing",
      "offset": 6006.849,
      "duration": 2.45
    },
    {
      "lang": "en",
      "text": "it, whereas Alpha Zero didn't ever\nhave the first rung to pull on.",
      "offset": 6009.299,
      "duration": 5.361
    },
    {
      "lang": "en",
      "text": "Yeah, yeah.",
      "offset": 6014.75,
      "duration": 0.59
    },
    {
      "lang": "en",
      "text": "This goes back to the monkeys on the\ntypewriter and the pre-training model.",
      "offset": 6015.86,
      "duration": 2.92
    },
    {
      "lang": "en",
      "text": "Until you had something like GPT-3/GPT-4,\nit just couldn't generate coherent enough",
      "offset": 6018.78,
      "duration": 5.06
    },
    {
      "lang": "en",
      "text": "sentences to even begin to do RLHF, and\ntell it what you liked and didn't like.",
      "offset": 6023.84,
      "duration": 4.55
    },
    {
      "lang": "en",
      "text": "Yeah.",
      "offset": 6028.39,
      "duration": 0.5
    },
    {
      "lang": "en",
      "text": "If we don't have even reasonably robust,\nor weakly robust computer use agents by",
      "offset": 6029.58,
      "duration": 7.95
    },
    {
      "lang": "en",
      "text": "this time next year, are we living in\nthe bust timeline as in “2030, or bust”?",
      "offset": 6037.57,
      "duration": 6.119
    },
    {
      "lang": "en",
      "text": "I would be extremely surprised\nif that was the case.",
      "offset": 6043.86,
      "duration": 2.06
    },
    {
      "lang": "en",
      "text": "I think that would be somewhat\nof an update towards, there's",
      "offset": 6046.459,
      "duration": 2.59
    },
    {
      "lang": "en",
      "text": "something strangely difficult about\nthis computer use in particular.",
      "offset": 6049.05,
      "duration": 3.8
    },
    {
      "lang": "en",
      "text": "I don't know if it's the bust\ntimeline, but it's definitely",
      "offset": 6052.85,
      "duration": 3.01
    },
    {
      "lang": "en",
      "text": "the, I would update on this being",
      "offset": 6056.16,
      "duration": 1.859
    },
    {
      "lang": "en",
      "text": "lengthening of timeline.",
      "offset": 6060.099,
      "duration": 0.67
    },
    {
      "lang": "en",
      "text": "I think more and more it's no\nlonger a question of speculation.",
      "offset": 6063.009,
      "duration": 4.081
    },
    {
      "lang": "en",
      "text": "If people are skeptical, I'd encourage\nusing Claude Code, or some agentic",
      "offset": 6067.51,
      "duration": 5.45
    },
    {
      "lang": "en",
      "text": "tool like it and just seeing what the\ncurrent level of capabilities are.",
      "offset": 6072.99,
      "duration": 4.289
    },
    {
      "lang": "en",
      "text": "Tweeting is so much easier.",
      "offset": 6077.759,
      "duration": 1.101
    },
    {
      "lang": "en",
      "text": "But seriously, the models are\ngetting really capable at tasks",
      "offset": 6081.23,
      "duration": 3.51
    },
    {
      "lang": "en",
      "text": "that we care about, and we\ncan give them enough data for.",
      "offset": 6084.74,
      "duration": 2.41
    },
    {
      "lang": "en",
      "text": "The circuit's results from\ninterpretability are also pointing",
      "offset": 6088.389,
      "duration": 2.571
    },
    {
      "lang": "en",
      "text": "in the direction that they're doing\nvery reasonable generalizable things.",
      "offset": 6090.96,
      "duration": 5.09
    },
    {
      "lang": "en",
      "text": "This question matters a lot, but I'm\nsurprised by how many deep learning",
      "offset": 6099.259,
      "duration": 5.091
    },
    {
      "lang": "en",
      "text": "critics just haven't really interacted\nwith the models, or haven't in a while.",
      "offset": 6104.35,
      "duration": 3.949
    },
    {
      "lang": "en",
      "text": "And constantly move the goalposts.",
      "offset": 6108.35,
      "duration": 1.65
    },
    {
      "lang": "en",
      "text": "The Turing test used to be a thing.",
      "offset": 6111.74,
      "duration": 1.269
    },
    {
      "lang": "en",
      "text": "We don't even talk about it,\nand it'd be silly to think",
      "offset": 6114.33,
      "duration": 2.62
    },
    {
      "lang": "en",
      "text": "that it was a meaningful test.",
      "offset": 6116.99,
      "duration": 1.189
    },
    {
      "lang": "en",
      "text": "Now one caveat on that is if software\nengineering is just dramatically better",
      "offset": 6118.209,
      "duration": 5.791
    },
    {
      "lang": "en",
      "text": "than computer use and computer use still\nsucks, then I'd still be like, “oh, maybe",
      "offset": 6124.14,
      "duration": 4.61
    },
    {
      "lang": "en",
      "text": "everyone just kept focused on software\nengineering.” It was just by far the most",
      "offset": 6128.75,
      "duration": 3.439
    },
    {
      "lang": "en",
      "text": "valuable thing, every marginal person and\ndollar went towards software engineering.",
      "offset": 6132.19,
      "duration": 3.499
    },
    {
      "lang": "en",
      "text": "I don't think that's the case.",
      "offset": 6135.689,
      "duration": 1.051
    },
    {
      "lang": "en",
      "text": "I do think computer use is valuable\nenough that people will care about it.",
      "offset": 6136.74,
      "duration": 4.24
    },
    {
      "lang": "en",
      "text": "That's my one escape patch that\nI'm putting in place for next year.",
      "offset": 6143.2,
      "duration": 2.6
    },
    {
      "lang": "en",
      "text": "Yeah, it would be good from\nan alignment perspective, too.",
      "offset": 6146.88,
      "duration": 1.99
    },
    {
      "lang": "en",
      "text": "Because I think you kind of do\nneed a wider range of skills before",
      "offset": 6149.179,
      "duration": 2.69
    },
    {
      "lang": "en",
      "text": "you can do something super scary.",
      "offset": 6151.87,
      "duration": 2.669
    },
    {
      "lang": "en",
      "text": "Like if the models didn't get any better?\nYeah, if",
      "offset": 6156.689,
      "duration": 1.32
    },
    {
      "lang": "en",
      "text": "they're superhuman coders, but\nthey're not Henry Kissinger level…",
      "offset": 6160.54,
      "duration": 5.13
    },
    {
      "lang": "en",
      "text": "I don't know.\nThat seems okay.",
      "offset": 6165.679,
      "duration": 1.021
    },
    {
      "lang": "en",
      "text": "If we have AI oracles.",
      "offset": 6166.98,
      "duration": 1.3
    },
    {
      "lang": "en",
      "text": "Yeah, that's what I'm saying.",
      "offset": 6168.38,
      "duration": 0.49
    },
    {
      "lang": "en",
      "text": "That's good.",
      "offset": 6168.87,
      "duration": 0.5
    },
    {
      "lang": "en",
      "text": "If you look back at AI discourse\ngoing back a decade, there's a",
      "offset": 6171.54,
      "duration": 3.67
    },
    {
      "lang": "en",
      "text": "sense that there's dumb AI, then\nthere's AGI, then there's ASI, that",
      "offset": 6175.21,
      "duration": 5.099
    },
    {
      "lang": "en",
      "text": "intelligence is the scalar value.",
      "offset": 6180.31,
      "duration": 1.82
    },
    {
      "lang": "en",
      "text": "The way you've been talking about\nthese models has a sense of jaggedness.",
      "offset": 6183.45,
      "duration": 5.13
    },
    {
      "lang": "en",
      "text": "It's especially tuned to\nenvironments in which it's been",
      "offset": 6189.589,
      "duration": 3.271
    },
    {
      "lang": "en",
      "text": "trained a lot or has a lot of data.",
      "offset": 6192.869,
      "duration": 1.491
    },
    {
      "lang": "en",
      "text": "Is there a sense in which it still\nmakes sense to talk about the",
      "offset": 6195.38,
      "duration": 6.219
    },
    {
      "lang": "en",
      "text": "general intelligence of these models?",
      "offset": 6201.599,
      "duration": 1.681
    },
    {
      "lang": "en",
      "text": "Is there enough meta learning\nand transfer learning that is",
      "offset": 6203.28,
      "duration": 2.5
    },
    {
      "lang": "en",
      "text": "distinguished between the sizes of\nmodels or the way models are trained?",
      "offset": 6205.82,
      "duration": 3.87
    },
    {
      "lang": "en",
      "text": "Or are we moving into a regime\nwhere it's not about intelligence,",
      "offset": 6209.699,
      "duration": 4.07
    },
    {
      "lang": "en",
      "text": "it's more so about domain?",
      "offset": 6213.769,
      "duration": 1.991
    },
    {
      "lang": "en",
      "text": "One intuition pump is that this\nconversation was had a lot when",
      "offset": 6217.15,
      "duration": 3.649
    },
    {
      "lang": "en",
      "text": "models were GPT-2 sized and\nfine-tuned for various things.",
      "offset": 6220.84,
      "duration": 4.109
    },
    {
      "lang": "en",
      "text": "People would find that the models\nwere dramatically better at things",
      "offset": 6227.319,
      "duration": 2.161
    },
    {
      "lang": "en",
      "text": "that they were fine-tuned for.",
      "offset": 6229.48,
      "duration": 2.37
    },
    {
      "lang": "en",
      "text": "But by the time you get to GPT-4,\nwhen it's trained on a wide enough",
      "offset": 6232.14,
      "duration": 2.879
    },
    {
      "lang": "en",
      "text": "variety of things with the total\ncompute, it generalized very well",
      "offset": 6235.02,
      "duration": 5.57
    },
    {
      "lang": "en",
      "text": "across all of the individual sub-tasks.",
      "offset": 6240.599,
      "duration": 1.45
    },
    {
      "lang": "en",
      "text": "And it actually generalized better\nthan smaller fine-tuned models in",
      "offset": 6242.049,
      "duration": 4.27
    },
    {
      "lang": "en",
      "text": "a way that was extremely useful.",
      "offset": 6246.32,
      "duration": 1.149
    },
    {
      "lang": "en",
      "text": "I think right now what we're\nseeing with RL is pretty much",
      "offset": 6247.91,
      "duration": 3.02
    },
    {
      "lang": "en",
      "text": "the same story playing out.",
      "offset": 6251.06,
      "duration": 0.69
    },
    {
      "lang": "en",
      "text": "There's this jaggedness of things\nthat they're particularly trained at.",
      "offset": 6253.34,
      "duration": 2.78
    },
    {
      "lang": "en",
      "text": "But as we expand the total amount of\ncompute that we do RL with, you'll",
      "offset": 6256.309,
      "duration": 4.381
    },
    {
      "lang": "en",
      "text": "start to see the same transition\nfrom GPT-2 fine-tunes to GPT-3,",
      "offset": 6260.69,
      "duration": 5.779
    },
    {
      "lang": "en",
      "text": "GPT-4, unsupervised meta learning\nand generalization across things.",
      "offset": 6266.729,
      "duration": 4.821
    },
    {
      "lang": "en",
      "text": "I think we're already seeing early\nevidence of this in its ability",
      "offset": 6271.64,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "to generalize reasoning to things.",
      "offset": 6275.32,
      "duration": 2.439
    },
    {
      "lang": "en",
      "text": "But I think this will be\nextremely obvious soon.",
      "offset": 6277.82,
      "duration": 5.66
    },
    {
      "lang": "en",
      "text": "One nice example of this is just\nthe ability or notion to backtrack.",
      "offset": 6283.57,
      "duration": 3.83
    },
    {
      "lang": "en",
      "text": "You go down one solution path,\n&quot;Oh, wait, let me try another one.&quot;",
      "offset": 6287.84,
      "duration": 3.66
    },
    {
      "lang": "en",
      "text": "And this is something that you\nstart to see emerge in the models",
      "offset": 6292.38,
      "duration": 3.02
    },
    {
      "lang": "en",
      "text": "through RL training on harder tasks.",
      "offset": 6295.4,
      "duration": 2.509
    },
    {
      "lang": "en",
      "text": "I think right now, it's not\ngeneralizing incredibly well.",
      "offset": 6298.9,
      "duration": 3.96
    },
    {
      "lang": "en",
      "text": "Well, I mean have we ever RL'd\nthe model to be an interp agent?",
      "offset": 6303.97,
      "duration": 3.99
    },
    {
      "lang": "en",
      "text": "No.\nI mean, no.",
      "offset": 6308.389,
      "duration": 0.781
    },
    {
      "lang": "en",
      "text": "Yeah, exactly.",
      "offset": 6309.17,
      "duration": 0.84
    },
    {
      "lang": "en",
      "text": "So all this time we're talking\nabout, “oh, it's only good at",
      "offset": 6310.48,
      "duration": 1.869
    },
    {
      "lang": "en",
      "text": "things it’s been RL’d for”.",
      "offset": 6312.37,
      "duration": 0.623
    },
    {
      "lang": "en",
      "text": "Well, it's pretty good at that because\nthat is a mixture of science and",
      "offset": 6312.993,
      "duration": 4.757
    },
    {
      "lang": "en",
      "text": "understanding language and coding.",
      "offset": 6318.1,
      "duration": 2.79
    },
    {
      "lang": "en",
      "text": "There's this sort of mixture of domains\nhere, all of which you need to understand.",
      "offset": 6321.51,
      "duration": 2.45
    },
    {
      "lang": "en",
      "text": "You need to be both a great software\nengineer and be able to think",
      "offset": 6324.2,
      "duration": 3.4
    },
    {
      "lang": "en",
      "text": "through language and state of mind\nand almost philosophize in some",
      "offset": 6327.61,
      "duration": 3.849
    },
    {
      "lang": "en",
      "text": "respects to be an interpret agent.",
      "offset": 6331.459,
      "duration": 2.77
    },
    {
      "lang": "en",
      "text": "And it is generalizing from\nthe training to do that.",
      "offset": 6334.229,
      "duration": 4.486
    },
    {
      "lang": "en",
      "text": "What's the end game here?",
      "offset": 6339.03,
      "duration": 1.23
    },
    {
      "lang": "en",
      "text": "Claude 8 comes out and they give\nit to you and dot, dot, dot, you",
      "offset": 6341.09,
      "duration": 6.23
    },
    {
      "lang": "en",
      "text": "say, &quot;thumbs up.&quot; What's happened?",
      "offset": 6347.32,
      "duration": 2.239
    },
    {
      "lang": "en",
      "text": "What have you learned?\nYeah.",
      "offset": 6349.84,
      "duration": 0.629
    },
    {
      "lang": "en",
      "text": "I mean, it really depends upon the\ntimeline at which we get Claude 8 and the",
      "offset": 6350.79,
      "duration": 4.41
    },
    {
      "lang": "en",
      "text": "models hit like ASL-4 capabilities, right?",
      "offset": 6355.2,
      "duration": 2.24
    },
    {
      "lang": "en",
      "text": "Fundamentally, we're just going to\nuse whatever tools we have at the",
      "offset": 6357.89,
      "duration": 2.27
    },
    {
      "lang": "en",
      "text": "time and see how well they work.",
      "offset": 6360.16,
      "duration": 1.36
    },
    {
      "lang": "en",
      "text": "Ideally, we have this enumerative\nsafety case where we can almost",
      "offset": 6362.47,
      "duration": 3.849
    },
    {
      "lang": "en",
      "text": "verify or prove that the model\nwill behave in particular ways.",
      "offset": 6366.709,
      "duration": 4.1
    },
    {
      "lang": "en",
      "text": "In the worst case, we use the current\ntools like when we won the auditing",
      "offset": 6372.129,
      "duration": 4.79
    },
    {
      "lang": "en",
      "text": "game of seeing what features are active\nwhen the assistant tag lights off.",
      "offset": 6376.92,
      "duration": 3.759
    },
    {
      "lang": "en",
      "text": "Can you back up?",
      "offset": 6380.679,
      "duration": 0.271
    },
    {
      "lang": "en",
      "text": "Can you explain, what is\nmechanistic interpretability?",
      "offset": 6380.95,
      "duration": 1.68
    },
    {
      "lang": "en",
      "text": "What are features?",
      "offset": 6383.04,
      "duration": 0.65
    },
    {
      "lang": "en",
      "text": "What are circuits?",
      "offset": 6383.71,
      "duration": 0.74
    },
    {
      "lang": "en",
      "text": "Totally.",
      "offset": 6384.49,
      "duration": 0.5
    },
    {
      "lang": "en",
      "text": "Mechanistic interpretability—or the\ncool kids call it mech interp—is",
      "offset": 6386.719,
      "duration": 3.461
    },
    {
      "lang": "en",
      "text": "trying to reverse engineer neural\nnetworks and figure out what the",
      "offset": 6390.63,
      "duration": 5.12
    },
    {
      "lang": "en",
      "text": "core units of computation are.",
      "offset": 6395.78,
      "duration": 2.42
    },
    {
      "lang": "en",
      "text": "Lots of people think that because we\nmade neural networks, because they're",
      "offset": 6399.23,
      "duration": 3.16
    },
    {
      "lang": "en",
      "text": "artificial intelligence, we have a\nperfect understanding of how they work.",
      "offset": 6402.429,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "It couldn't be further from the truth.",
      "offset": 6406.48,
      "duration": 1.619
    },
    {
      "lang": "en",
      "text": "Neural networks, AI models that you\nuse today, are grown, not built.",
      "offset": 6408.7,
      "duration": 4.59
    },
    {
      "lang": "en",
      "text": "So, we then need to do a lot of work\nafter they're trained to figure out to",
      "offset": 6413.3,
      "duration": 6.23
    },
    {
      "lang": "en",
      "text": "the best of our abilities how they're\nactually going about their reasoning.",
      "offset": 6419.53,
      "duration": 3.07
    },
    {
      "lang": "en",
      "text": "And so,",
      "offset": 6422.94,
      "duration": 0.63
    },
    {
      "lang": "en",
      "text": "three and a half years ago, this kind\nof agenda of applying mechanistic",
      "offset": 6426.7,
      "duration": 5.16
    },
    {
      "lang": "en",
      "text": "interpretability to large language\nmodels started with Chris Olah",
      "offset": 6431.86,
      "duration": 4.32
    },
    {
      "lang": "en",
      "text": "leaving OpenAI, co-founding Anthropic.",
      "offset": 6436.559,
      "duration": 1.611
    },
    {
      "lang": "en",
      "text": "And every roughly six months since\nthen, we've had a major breakthrough",
      "offset": 6439.68,
      "duration": 6.76
    },
    {
      "lang": "en",
      "text": "in our understanding of these models.",
      "offset": 6446.6,
      "duration": 2.02
    },
    {
      "lang": "en",
      "text": "And so first with toy models of\nsuperposition, we established",
      "offset": 6448.62,
      "duration": 4.61
    },
    {
      "lang": "en",
      "text": "that models are really trying to\ncram as much information as they",
      "offset": 6453.24,
      "duration": 4.6
    },
    {
      "lang": "en",
      "text": "possibly can into their weights.",
      "offset": 6457.84,
      "duration": 2.93
    },
    {
      "lang": "en",
      "text": "And this goes directly against\npeople saying that neural",
      "offset": 6461.61,
      "duration": 2.01
    },
    {
      "lang": "en",
      "text": "networks are over-parameterized.",
      "offset": 6463.62,
      "duration": 1.15
    },
    {
      "lang": "en",
      "text": "In classic AI machine learning back in\nthe day, you would use linear regression",
      "offset": 6465.41,
      "duration": 5.399
    },
    {
      "lang": "en",
      "text": "or something like it, and people had\na meme of AI, or neural networks, deep",
      "offset": 6470.82,
      "duration": 5.97
    },
    {
      "lang": "en",
      "text": "learning, using way too many parameters.",
      "offset": 6476.79,
      "duration": 3.059
    },
    {
      "lang": "en",
      "text": "There's this funny meme that you\nshould show of layers on the X axis and",
      "offset": 6479.849,
      "duration": 4.29
    },
    {
      "lang": "en",
      "text": "layers on the Y axis and this jiggly\nline that just goes up and it's like,",
      "offset": 6484.14,
      "duration": 4.109
    },
    {
      "lang": "en",
      "text": "&quot;Oh, just throw more layers at it.&quot;",
      "offset": 6488.29,
      "duration": 2.91
    },
    {
      "lang": "en",
      "text": "But it actually turns out that, at\nleast for really hard tasks like being",
      "offset": 6491.2,
      "duration": 3.88
    },
    {
      "lang": "en",
      "text": "able to accurately predict the next\ntoken for the entire internet, these",
      "offset": 6495.08,
      "duration": 4.01
    },
    {
      "lang": "en",
      "text": "models just don't have enough capacity.",
      "offset": 6499.09,
      "duration": 1.69
    },
    {
      "lang": "en",
      "text": "And so they need to cram\nin as much as they can.",
      "offset": 6501.11,
      "duration": 2.25
    },
    {
      "lang": "en",
      "text": "And the way they learn to do that\nis to use each of their neurons,",
      "offset": 6503.58,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "or units of computation in the\nmodel, for lots of different things.",
      "offset": 6507.429,
      "duration": 3.591
    },
    {
      "lang": "en",
      "text": "And so if you try to make sense\nof the model and be like, &quot;Oh,",
      "offset": 6511.2,
      "duration": 2.16
    },
    {
      "lang": "en",
      "text": "if I remove this one neuron,&quot;\nwhat is it doing in the model?",
      "offset": 6513.36,
      "duration": 3.73
    },
    {
      "lang": "en",
      "text": "It's impossible to make sense of it.",
      "offset": 6517.36,
      "duration": 1.72
    },
    {
      "lang": "en",
      "text": "It'll fire for like Chinese and\nfishing and horses and, I don't know,",
      "offset": 6519.16,
      "duration": 5.509
    },
    {
      "lang": "en",
      "text": "just like a hundred different things.",
      "offset": 6524.67,
      "duration": 1.469
    },
    {
      "lang": "en",
      "text": "And it's because it's trying\nto juggle all these tasks and",
      "offset": 6527.62,
      "duration": 3.3
    },
    {
      "lang": "en",
      "text": "use the same neuron to do it.",
      "offset": 6530.92,
      "duration": 1.2
    },
    {
      "lang": "en",
      "text": "So that's superposition.",
      "offset": 6532.379,
      "duration": 1.27
    },
    {
      "lang": "en",
      "text": "Nine months later, we write Towards\nMonosemanticity, which introduces",
      "offset": 6534.15,
      "duration": 4.6
    },
    {
      "lang": "en",
      "text": "what are called sparse autoencoders.",
      "offset": 6539.03,
      "duration": 1.019
    },
    {
      "lang": "en",
      "text": "And so going off what I just said of the\nmodel trying to cram too much into too",
      "offset": 6541.099,
      "duration": 4.781
    },
    {
      "lang": "en",
      "text": "little space, we give it more space, this\nhigher dimensional representation, where",
      "offset": 6545.88,
      "duration": 7.679
    },
    {
      "lang": "en",
      "text": "it can then more cleanly represent all\nof the concepts that it's understanding.",
      "offset": 6553.56,
      "duration": 3.68
    },
    {
      "lang": "en",
      "text": "And, and this was a very toy paper\nin so much as it was a two layer,",
      "offset": 6557.65,
      "duration": 5.279
    },
    {
      "lang": "en",
      "text": "really small, really dumb transformer.",
      "offset": 6563.16,
      "duration": 1.809
    },
    {
      "lang": "en",
      "text": "And we fit up to 16,000 features,\nwhich we thought was a ton at the time.",
      "offset": 6565.42,
      "duration": 6
    },
    {
      "lang": "en",
      "text": "Fast-forward nine months, we go from\na two layer transformer to our Claude",
      "offset": 6572.4,
      "duration": 4.84
    },
    {
      "lang": "en",
      "text": "3 Sonnet, frontier model at the time,\nand fit up to 30 million features.",
      "offset": 6577.25,
      "duration": 5.21
    },
    {
      "lang": "en",
      "text": "And this is where we start to\nfind really interesting abstract",
      "offset": 6582.88,
      "duration": 2.479
    },
    {
      "lang": "en",
      "text": "concepts, like a feature that would\nfire for code vulnerabilities.",
      "offset": 6585.37,
      "duration": 3.569
    },
    {
      "lang": "en",
      "text": "And it wouldn't just fire\nfor code vulnerabilities.",
      "offset": 6588.939,
      "duration": 1.971
    },
    {
      "lang": "en",
      "text": "It would even fire for like, you know\nthat Chrome page you get if it's not",
      "offset": 6591.13,
      "duration": 4.919
    },
    {
      "lang": "en",
      "text": "an HTTPS URL, like &quot;Warning, this site\nmight be dangerous. Click to continue.&quot;",
      "offset": 6596.05,
      "duration": 6.66
    },
    {
      "lang": "en",
      "text": "And also fire for that, for example.",
      "offset": 6602.9,
      "duration": 2.079
    },
    {
      "lang": "en",
      "text": "And so it's like these much more\nabstract coding variables or sentiment",
      "offset": 6605.27,
      "duration": 5.14
    },
    {
      "lang": "en",
      "text": "features, amongst the 30 million.",
      "offset": 6610.71,
      "duration": 2.07
    },
    {
      "lang": "en",
      "text": "Fast-forward nine months from\nthat, and now we have circuits.",
      "offset": 6614.179,
      "duration": 3.851
    },
    {
      "lang": "en",
      "text": "And I threw in the analogy earlier of\nthe Ocean 11 heist team, where now you're",
      "offset": 6618.32,
      "duration": 6.35
    },
    {
      "lang": "en",
      "text": "identifying individual features across the\nlayers of the model that are all working",
      "offset": 6624.79,
      "duration": 4.73
    },
    {
      "lang": "en",
      "text": "together to perform some complicated task.",
      "offset": 6629.52,
      "duration": 2.01
    },
    {
      "lang": "en",
      "text": "And you can get a much better idea\nof how it's actually doing the",
      "offset": 6631.9,
      "duration": 3.77
    },
    {
      "lang": "en",
      "text": "reasoning and coming to decisions,\nlike with the medical diagnostics.",
      "offset": 6635.67,
      "duration": 2.989
    },
    {
      "lang": "en",
      "text": "One example I didn't talk about before\nwith how the model retrieves facts:",
      "offset": 6639.99,
      "duration": 4.44
    },
    {
      "lang": "en",
      "text": "So you say, &quot;What sport did Michael\nJordan play?&quot; And not only can you",
      "offset": 6644.44,
      "duration": 4.81
    },
    {
      "lang": "en",
      "text": "see it hop from like Michael Jordan\nto basketball and answer basketball.",
      "offset": 6649.25,
      "duration": 4.639
    },
    {
      "lang": "en",
      "text": "But the model also has an awareness of\nwhen it doesn't know the answer to a fact.",
      "offset": 6654.309,
      "duration": 5.06
    },
    {
      "lang": "en",
      "text": "And so, by default, it will actually\nsay, &quot;I don't know the answer to this",
      "offset": 6659.67,
      "duration": 5.08
    },
    {
      "lang": "en",
      "text": "question.&quot; But if it sees something\nthat it does know the answer to,",
      "offset": 6664.75,
      "duration": 3.96
    },
    {
      "lang": "en",
      "text": "it will inhibit the &quot;I don't know&quot;\ncircuit and then reply with the circuit",
      "offset": 6668.72,
      "duration": 4.39
    },
    {
      "lang": "en",
      "text": "that it actually has the answer to.",
      "offset": 6673.12,
      "duration": 1.179
    },
    {
      "lang": "en",
      "text": "So, for example, if you ask it,\n&quot;Who is Michael Batkin?&quot; —which is",
      "offset": 6674.53,
      "duration": 4.07
    },
    {
      "lang": "en",
      "text": "just a made-up fictional person— it\nwill by default just say, &quot;I don't",
      "offset": 6678.67,
      "duration": 4.389
    },
    {
      "lang": "en",
      "text": "know.&quot; It's only with Michael Jordan\nor someone else that it will then",
      "offset": 6683.06,
      "duration": 3.37
    },
    {
      "lang": "en",
      "text": "inhibit the &quot;I don't know&quot; circuit.",
      "offset": 6686.43,
      "duration": 1.41
    },
    {
      "lang": "en",
      "text": "But what's really interesting here and\nwhere you can start making downstream",
      "offset": 6688.28,
      "duration": 3.359
    },
    {
      "lang": "en",
      "text": "predictions or reasoning about the\nmodel, is that the &quot;I don't know&quot; circuit",
      "offset": 6691.639,
      "duration": 3.77
    },
    {
      "lang": "en",
      "text": "is only on the name of the person.",
      "offset": 6695.74,
      "duration": 1.68
    },
    {
      "lang": "en",
      "text": "And so, in the paper we also ask it, &quot;What\npaper did Andrej Karpathy write?&quot; And so",
      "offset": 6697.91,
      "duration": 6.18
    },
    {
      "lang": "en",
      "text": "it recognizes the name Andrej Karpathy,\nbecause he's sufficiently famous, so",
      "offset": 6704.16,
      "duration": 4.57
    },
    {
      "lang": "en",
      "text": "that turns off the &quot;I don't know&quot; reply.",
      "offset": 6708.73,
      "duration": 2.359
    },
    {
      "lang": "en",
      "text": "But then when it comes time for the model\nto say what paper it worked on, it doesn't",
      "offset": 6711.799,
      "duration": 3.021
    },
    {
      "lang": "en",
      "text": "actually know any of his papers, and\nso then it needs to make something up.",
      "offset": 6714.9,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "And so you can see different\ncomponents and different circuits",
      "offset": 6719.41,
      "duration": 3.76
    },
    {
      "lang": "en",
      "text": "all interacting at the same time\nto lead to this final answer.",
      "offset": 6723.179,
      "duration": 3.531
    },
    {
      "lang": "en",
      "text": "Why think it's a tractable problem\nto understand every single thing",
      "offset": 6727.21,
      "duration": 4.25
    },
    {
      "lang": "en",
      "text": "that's happening in a model?",
      "offset": 6731.46,
      "duration": 1.44
    },
    {
      "lang": "en",
      "text": "Or like that's the best way to\nunderstand why it's being deceptive.",
      "offset": 6732.97,
      "duration": 2.5
    },
    {
      "lang": "en",
      "text": "If you wanted to explain why England\nwon World War II using particle physics,",
      "offset": 6735.66,
      "duration": 5.2
    },
    {
      "lang": "en",
      "text": "you would just be on the wrong track.",
      "offset": 6741.719,
      "duration": 1.521
    },
    {
      "lang": "en",
      "text": "You just want to look at the high-level\nexplanations of, who had more weapons?",
      "offset": 6743.24,
      "duration": 5.24
    },
    {
      "lang": "en",
      "text": "What did they want?",
      "offset": 6748.65,
      "duration": 0.939
    },
    {
      "lang": "en",
      "text": "That seems analogous to just training\nlinear probes for like, are you honest?",
      "offset": 6749.99,
      "duration": 3.8
    },
    {
      "lang": "en",
      "text": "Are you being deceptive?",
      "offset": 6753.79,
      "duration": 1.05
    },
    {
      "lang": "en",
      "text": "Do we catch you doing bad things\nwhen we're red teaming you?",
      "offset": 6755.78,
      "duration": 2.689
    },
    {
      "lang": "en",
      "text": "Can we monitor you?",
      "offset": 6758.49,
      "duration": 1.05
    },
    {
      "lang": "en",
      "text": "Why is this not analogous where\nwe're asking a particle physicist",
      "offset": 6761.09,
      "duration": 3.29
    },
    {
      "lang": "en",
      "text": "to just backtrack and explain\nwhy England won World War II?",
      "offset": 6764.58,
      "duration": 5.179
    },
    {
      "lang": "en",
      "text": "I feel like you just want to go\nin with your eyes wide open, not",
      "offset": 6769.79,
      "duration": 2.91
    },
    {
      "lang": "en",
      "text": "making any assumptions for what\nthat deception is going to look",
      "offset": 6772.7,
      "duration": 2.79
    },
    {
      "lang": "en",
      "text": "like, or what the trigger might be.",
      "offset": 6775.49,
      "duration": 2.75
    },
    {
      "lang": "en",
      "text": "The wider you can cast\nthat net, the better.",
      "offset": 6780.219,
      "duration": 2.05
    },
    {
      "lang": "en",
      "text": "Depending on how quickly AI\naccelerates and where the state of",
      "offset": 6782.69,
      "duration": 2.81
    },
    {
      "lang": "en",
      "text": "our tools are, we might not be in\nthe place where we can prove from the",
      "offset": 6785.5,
      "duration": 5.28
    },
    {
      "lang": "en",
      "text": "ground up that everything is safe.",
      "offset": 6790.78,
      "duration": 1.38
    },
    {
      "lang": "en",
      "text": "But I feel like that's\na very good North Star.",
      "offset": 6792.85,
      "duration": 2.609
    },
    {
      "lang": "en",
      "text": "It's a very powerful reassuring North\nStar for us to aim for, especially",
      "offset": 6795.94,
      "duration": 4.02
    },
    {
      "lang": "en",
      "text": "when we consider we are part of\nthe broader AI safety portfolio.",
      "offset": 6799.96,
      "duration": 3.789
    },
    {
      "lang": "en",
      "text": "I mean, do you really trust—you're\nabout to deploy this system and",
      "offset": 6803.959,
      "duration": 4.06
    },
    {
      "lang": "en",
      "text": "you really hope it's aligned with\nhumanity—that you've successfully",
      "offset": 6808.02,
      "duration": 4.249
    },
    {
      "lang": "en",
      "text": "iterated through all the possible ways\nthat it's going to scheme or sandbag or…",
      "offset": 6812.269,
      "duration": 5.071
    },
    {
      "lang": "en",
      "text": "But that's also probably going to\nbe true with whatever you find.",
      "offset": 6817.4,
      "duration": 3.02
    },
    {
      "lang": "en",
      "text": "You're still going to have variants\nthat you haven't explained.",
      "offset": 6820.48,
      "duration": 4.87
    },
    {
      "lang": "en",
      "text": "Or you found a feature, but you\ndon't know if it actually explains",
      "offset": 6825.36,
      "duration": 2.529
    },
    {
      "lang": "en",
      "text": "deception or something else instead.",
      "offset": 6827.89,
      "duration": 1.94
    },
    {
      "lang": "en",
      "text": "First of all, I'm not saying you\nshouldn't try the probing approach.",
      "offset": 6831.349,
      "duration": 2.19
    },
    {
      "lang": "en",
      "text": "We want to pursue the entire portfolio.",
      "offset": 6833.639,
      "duration": 3.38
    },
    {
      "lang": "en",
      "text": "We've got the therapist interrogating\nthe patient by asking, &quot;Do you",
      "offset": 6837.41,
      "duration": 5.74
    },
    {
      "lang": "en",
      "text": "have any troubling thoughts?&quot; We've\ngot the linear probe, which I'd",
      "offset": 6843.16,
      "duration": 4.129
    },
    {
      "lang": "en",
      "text": "analogize to a polygraph test where\nwe're taking very high level summary",
      "offset": 6847.36,
      "duration": 5.55
    },
    {
      "lang": "en",
      "text": "statistics of the person's well-being.",
      "offset": 6852.91,
      "duration": 1.599
    },
    {
      "lang": "en",
      "text": "Then we've got the neurosurgeons going\nin and seeing if you can find any brain",
      "offset": 6855.089,
      "duration": 5.021
    },
    {
      "lang": "en",
      "text": "components that are activating and\ntroubling or off-distribution ways.",
      "offset": 6860.11,
      "duration": 3.66
    },
    {
      "lang": "en",
      "text": "I think we should do all of it.",
      "offset": 6864.51,
      "duration": 0.94
    },
    {
      "lang": "en",
      "text": "What percent of the alignment\nportfolio should mech interp be?",
      "offset": 6866.47,
      "duration": 2.23
    },
    {
      "lang": "en",
      "text": "I think as much of a\nchunk as is necessary.",
      "offset": 6870,
      "duration": 3.87
    },
    {
      "lang": "en",
      "text": "It’s hard to define.\nAt Anthropic,",
      "offset": 6875.47,
      "duration": 1.18
    },
    {
      "lang": "en",
      "text": "I feel like all of the different\nportfolios are being very",
      "offset": 6879.48,
      "duration": 2.69
    },
    {
      "lang": "en",
      "text": "well-supported and growing.",
      "offset": 6882.17,
      "duration": 2.05
    },
    {
      "lang": "en",
      "text": "Coming back to the World War II question,\nyou can think of it as a hierarchy of",
      "offset": 6886.09,
      "duration": 4.28
    },
    {
      "lang": "en",
      "text": "abstractions of trust here, where let's\nsay you want to go and talk to Churchill.",
      "offset": 6890.37,
      "duration": 3.75
    },
    {
      "lang": "en",
      "text": "It helps a lot if you can verify\nthat in that conversation, in that",
      "offset": 6894.97,
      "duration": 2.91
    },
    {
      "lang": "en",
      "text": "10 minutes, he's being honest.",
      "offset": 6897.88,
      "duration": 1.58
    },
    {
      "lang": "en",
      "text": "This enables you to construct better\nmeta narratives of what's going on.",
      "offset": 6900.68,
      "duration": 4.78
    },
    {
      "lang": "en",
      "text": "So maybe particle physics wouldn't help\nyou there, but certainly the neuroscience",
      "offset": 6905.95,
      "duration": 3.939
    },
    {
      "lang": "en",
      "text": "of Churchill's brain would help you\nverify that he was being trustworthy in",
      "offset": 6909.9,
      "duration": 3.869
    },
    {
      "lang": "en",
      "text": "that conversation and that the soldiers\non the front lines were being honest",
      "offset": 6913.77,
      "duration": 4.27
    },
    {
      "lang": "en",
      "text": "in their depiction of their description\nof what happened, this kind of stuff.",
      "offset": 6918.22,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "So long as you can verify parts of\nthe tree up, then that massively",
      "offset": 6922.219,
      "duration": 6.691
    },
    {
      "lang": "en",
      "text": "helps you build confidence.",
      "offset": 6928.91,
      "duration": 1.02
    },
    {
      "lang": "en",
      "text": "I think language models\nare also just really weird.",
      "offset": 6930.77,
      "duration": 1.61
    },
    {
      "lang": "en",
      "text": "With the emergent misalignment work.",
      "offset": 6932.74,
      "duration": 1.6
    },
    {
      "lang": "en",
      "text": "I don't know if they took predictions,\nthey should have of like, &quot;Hey,",
      "offset": 6936.31,
      "duration": 2.559
    },
    {
      "lang": "en",
      "text": "I'm going to fine tune ChatGPT\non code vulnerabilities. Is it",
      "offset": 6939.08,
      "duration": 3.04
    },
    {
      "lang": "en",
      "text": "going to become a Nazi?&quot; I think\nmost people would've said no.",
      "offset": 6942.12,
      "duration": 2.729
    },
    {
      "lang": "en",
      "text": "That's what happened.",
      "offset": 6946.27,
      "duration": 1.19
    },
    {
      "lang": "en",
      "text": "How did they discover\nthat it became a Nazi?",
      "offset": 6949.89,
      "duration": 1.81
    },
    {
      "lang": "en",
      "text": "They started asking it a ton of\ndifferent questions and it will do",
      "offset": 6952.05,
      "duration": 3.02
    },
    {
      "lang": "en",
      "text": "all sorts of vile and harmful things.",
      "offset": 6955.1,
      "duration": 2.82
    },
    {
      "lang": "en",
      "text": "The whole persona just totally changes.",
      "offset": 6958.17,
      "duration": 3.179
    },
    {
      "lang": "en",
      "text": "We are dealing with alien brains here who\ndon't have the social norms of humans.",
      "offset": 6961.36,
      "duration": 3.73
    },
    {
      "lang": "en",
      "text": "We don’t even have a clear notion of\nwhat they have and haven't learned.",
      "offset": 6966.31,
      "duration": 2.409
    },
    {
      "lang": "en",
      "text": "I",
      "offset": 6968.72,
      "duration": 0.5
    },
    {
      "lang": "en",
      "text": "think you really want to go\ninto this with eyes wide open.",
      "offset": 6973.42,
      "duration": 2.69
    },
    {
      "lang": "en",
      "text": "Backing up from mech interp, if we live\nin a world where AI progress accelerates…",
      "offset": 6976.349,
      "duration": 4.591
    },
    {
      "lang": "en",
      "text": "By the way, you were mentioning a\nlittle while ago that there's many",
      "offset": 6983.139,
      "duration": 4.851
    },
    {
      "lang": "en",
      "text": "wild worlds we could be living in, but\nwe're living in at least one of them.",
      "offset": 6988.269,
      "duration": 2.641
    },
    {
      "lang": "en",
      "text": "Another one that we've gestured at but\nit's worth making more explicit, is this.",
      "offset": 6992.41,
      "duration": 3.75
    },
    {
      "lang": "en",
      "text": "Even if the AI models are not helping\nwrite the next training algorithm",
      "offset": 6996.4,
      "duration": 3.764
    },
    {
      "lang": "en",
      "text": "for their successor, just the\nfact that if they had human level",
      "offset": 7000.469,
      "duration": 3.791
    },
    {
      "lang": "en",
      "text": "learning efficiency—whatever copy\nof the model is learning on the",
      "offset": 7004.26,
      "duration": 6.699
    },
    {
      "lang": "en",
      "text": "job—the whole model is learning.",
      "offset": 7010.96,
      "duration": 1.82
    },
    {
      "lang": "en",
      "text": "So in effect, it's getting–",
      "offset": 7012.78,
      "duration": 1.52
    },
    {
      "lang": "en",
      "text": "Or even if they're like a thousand\ntimes less efficient than humans are",
      "offset": 7014.42,
      "duration": 2.59
    },
    {
      "lang": "en",
      "text": "at learning and you deployed them.",
      "offset": 7017.01,
      "duration": 1.64
    },
    {
      "lang": "en",
      "text": "Even still.",
      "offset": 7018.77,
      "duration": 0.53
    },
    {
      "lang": "en",
      "text": "Exactly.",
      "offset": 7019.65,
      "duration": 0.5
    },
    {
      "lang": "en",
      "text": "Anyways, there's a whole bunch of other\nthings that you can think of about it.",
      "offset": 7020.839,
      "duration": 3.039
    },
    {
      "lang": "en",
      "text": "But even there, you kind of have a\nbroadly deployed intelligence explosion.",
      "offset": 7023.92,
      "duration": 4.31
    },
    {
      "lang": "en",
      "text": "I do think it's worth\npressing on that future.",
      "offset": 7028.26,
      "duration": 2.81
    },
    {
      "lang": "en",
      "text": "There is this whole\nspectrum of crazy futures.",
      "offset": 7032.61,
      "duration": 2.08
    },
    {
      "lang": "en",
      "text": "But the one that I feel we're\nalmost guaranteed to get—this is",
      "offset": 7034.73,
      "duration": 3.18
    },
    {
      "lang": "en",
      "text": "a strong statement to make—is one\nwhere at the very least, you get",
      "offset": 7039.62,
      "duration": 4.479
    },
    {
      "lang": "en",
      "text": "a drop-in white collar worker at\nsome point in the next five years.",
      "offset": 7044.11,
      "duration": 5.04
    },
    {
      "lang": "en",
      "text": "I think it's very likely in two, but\nit seems almost overdetermined in five.",
      "offset": 7049.15,
      "duration": 5.8
    },
    {
      "lang": "en",
      "text": "On the grand scheme of things, those\nare kind of irrelevant timeframes.",
      "offset": 7055,
      "duration": 3.309
    },
    {
      "lang": "en",
      "text": "It's the same either way.",
      "offset": 7058.999,
      "duration": 0.731
    },
    {
      "lang": "en",
      "text": "That completely changes the\nworld over the next decade.",
      "offset": 7061.7,
      "duration": 4.05
    },
    {
      "lang": "en",
      "text": "If we don't have the right policies\nin place for that, then you end",
      "offset": 7068.219,
      "duration": 2.46
    },
    {
      "lang": "en",
      "text": "up actually with in some respects,\nalmost a fundamentally worse world.",
      "offset": 7070.679,
      "duration": 2.463
    },
    {
      "lang": "en",
      "text": "Because the thing that these models\nget good at by default is software",
      "offset": 7073.142,
      "duration": 3.078
    },
    {
      "lang": "en",
      "text": "engineering and computer using\nagents and this kind of stuff.",
      "offset": 7076.22,
      "duration": 3.01
    },
    {
      "lang": "en",
      "text": "Then we will need to put in extra\neffort to put them in the loops where",
      "offset": 7079.46,
      "duration": 4.62
    },
    {
      "lang": "en",
      "text": "they help us with scientific research.",
      "offset": 7084.69,
      "duration": 1.619
    },
    {
      "lang": "en",
      "text": "Or we have the right robotics,\nsuch that we actually experience an",
      "offset": 7086.32,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "increase in material quality of life.",
      "offset": 7090.25,
      "duration": 1.5
    },
    {
      "lang": "en",
      "text": "That's worth thinking about.",
      "offset": 7093.26,
      "duration": 0.83
    },
    {
      "lang": "en",
      "text": "If you're in the perspective of like,\n“I'm a country, what should I be doing",
      "offset": 7094.34,
      "duration": 3.18
    },
    {
      "lang": "en",
      "text": "or thinking about?” Plan for the case\nwhere white collar work is automateable.",
      "offset": 7097.52,
      "duration": 6.23
    },
    {
      "lang": "en",
      "text": "And then consider, what does\nthat mean for your economy?",
      "offset": 7104.059,
      "duration": 1.981
    },
    {
      "lang": "en",
      "text": "What you should be\ndoing to prepare policy?",
      "offset": 7107.03,
      "duration": 2.049
    },
    {
      "lang": "en",
      "text": "What should you be doing to prepare?",
      "offset": 7109.09,
      "duration": 1.1
    },
    {
      "lang": "en",
      "text": "Because honestly, this is such\na tough question if you're",
      "offset": 7110.52,
      "duration": 3.21
    },
    {
      "lang": "en",
      "text": "India or Nigeria or Australia.",
      "offset": 7113.75,
      "duration": 2.63
    },
    {
      "lang": "en",
      "text": "If you're a country unlike America\nor China where they do have",
      "offset": 7116.39,
      "duration": 4.709
    },
    {
      "lang": "en",
      "text": "frontier models, what is it that\nyou should be doing right now?",
      "offset": 7121.099,
      "duration": 3.52
    },
    {
      "lang": "en",
      "text": "Especially on such a short timescale.",
      "offset": 7124.62,
      "duration": 1.41
    },
    {
      "lang": "en",
      "text": "I think one very important point is that\nlet's say this scenario turns out true.",
      "offset": 7128.54,
      "duration": 4.7
    },
    {
      "lang": "en",
      "text": "Then compute becomes the most\nvaluable resource in the world.",
      "offset": 7133.47,
      "duration": 3.009
    },
    {
      "lang": "en",
      "text": "The GDP of your economy is\ndramatically affected by how much",
      "offset": 7136.509,
      "duration": 4.13
    },
    {
      "lang": "en",
      "text": "compute you can deploy towards the\norganizations within your country.",
      "offset": 7140.639,
      "duration": 3.611
    },
    {
      "lang": "en",
      "text": "So having some guaranteed\namount of compute I think will",
      "offset": 7145.26,
      "duration": 5.22
    },
    {
      "lang": "en",
      "text": "actually be quite important.",
      "offset": 7150.54,
      "duration": 0.96
    },
    {
      "lang": "en",
      "text": "Getting ahead of investments, and\ndata centers, and this kind of",
      "offset": 7152.95,
      "duration": 2.211
    },
    {
      "lang": "en",
      "text": "stuff on the condition that it's\ncompanies in your country have to",
      "offset": 7155.161,
      "duration": 3.329
    },
    {
      "lang": "en",
      "text": "be allowed to use that compute,",
      "offset": 7158.49,
      "duration": 1.7
    },
    {
      "lang": "en",
      "text": "not necessarily for training but\njust even just for inference.",
      "offset": 7162.449,
      "duration": 1.79
    },
    {
      "lang": "en",
      "text": "I think the economic value\nhere comes from inference.",
      "offset": 7164.24,
      "duration": 1.97
    },
    {
      "lang": "en",
      "text": "I think it also makes sense\nto invest broadly in AI.",
      "offset": 7167.33,
      "duration": 4.11
    },
    {
      "lang": "en",
      "text": "These countries have the opportunity to\ndo so and that's a portfolio of foundation",
      "offset": 7171.469,
      "duration": 4.22
    },
    {
      "lang": "en",
      "text": "model companies but also robotics,\nsupply chain, and this kind of stuff.",
      "offset": 7175.69,
      "duration": 2.65
    },
    {
      "lang": "en",
      "text": "I think that you should invest\nvery proactively in policies that",
      "offset": 7179.66,
      "duration": 3.63
    },
    {
      "lang": "en",
      "text": "try to prevent capital lock-in.",
      "offset": 7183.3,
      "duration": 4.48
    },
    {
      "lang": "en",
      "text": "We're in for a much worse world if it\njust so happens that the people who",
      "offset": 7189.27,
      "duration": 3.679
    },
    {
      "lang": "en",
      "text": "had money in the stock exchange, or in\nland before AGI are dramatically more",
      "offset": 7192.969,
      "duration": 5.34
    },
    {
      "lang": "en",
      "text": "wealthy than the people who don't.",
      "offset": 7198.309,
      "duration": 2.26
    },
    {
      "lang": "en",
      "text": "It's a gross misallocation of resources.",
      "offset": 7200.569,
      "duration": 1.831
    },
    {
      "lang": "en",
      "text": "One of my favorite episodes\nactually on your podcast was the",
      "offset": 7206.47,
      "duration": 2.52
    },
    {
      "lang": "en",
      "text": "Georgism one where you're trying to\nappropriately value, or allocate land.",
      "offset": 7208.99,
      "duration": 3.55
    },
    {
      "lang": "en",
      "text": "This strikes particularly close\nto home coming from Australia",
      "offset": 7215.38,
      "duration": 2.79
    },
    {
      "lang": "en",
      "text": "where I think our policies with\nrespect to land are grossly wrong.",
      "offset": 7218.199,
      "duration": 5.211
    },
    {
      "lang": "en",
      "text": "But I think this is broadly true.",
      "offset": 7225.19,
      "duration": 1.36
    },
    {
      "lang": "en",
      "text": "Being very forward on regulation of\nintegration of these models into your",
      "offset": 7228.73,
      "duration": 6.39
    },
    {
      "lang": "en",
      "text": "country is important, and proactively\nmaking sure that people have choice.",
      "offset": 7235.12,
      "duration": 5.27
    },
    {
      "lang": "en",
      "text": "Let's say you should be quite\nproactive about making sure that the",
      "offset": 7240.73,
      "duration": 2.84
    },
    {
      "lang": "en",
      "text": "phones, or devices, or the glasses\nthat people have, people have free",
      "offset": 7243.57,
      "duration": 3.699
    },
    {
      "lang": "en",
      "text": "choice on what things they run.",
      "offset": 7247.27,
      "duration": 2.179
    },
    {
      "lang": "en",
      "text": "So we just get the white collar\nworker, and you're trying to do the",
      "offset": 7253.969,
      "duration": 4.901
    },
    {
      "lang": "en",
      "text": "best to prepare your country for that.",
      "offset": 7258.87,
      "duration": 1.92
    },
    {
      "lang": "en",
      "text": "Then what can you do to make all\npossible versions of the future go well?",
      "offset": 7261.66,
      "duration": 5.74
    },
    {
      "lang": "en",
      "text": "That's covering some amount\nof economic downside.",
      "offset": 7267.57,
      "duration": 2.68
    },
    {
      "lang": "en",
      "text": "The other things that I think are really\nimportant is figure out how you can",
      "offset": 7271.16,
      "duration": 4.66
    },
    {
      "lang": "en",
      "text": "basically ensure dramatic upside,\nor cover terrible downside.",
      "offset": 7279.47,
      "duration": 4.5
    },
    {
      "lang": "en",
      "text": "Getting a dramatic upside is making\nsure that there is investment in",
      "offset": 7285.69,
      "duration": 3.579
    },
    {
      "lang": "en",
      "text": "biology research and this kind\nof stuff in an automated way such",
      "offset": 7289.92,
      "duration": 3.55
    },
    {
      "lang": "en",
      "text": "that these models are actually able\nto produce novel medicines that",
      "offset": 7293.47,
      "duration": 2.62
    },
    {
      "lang": "en",
      "text": "massively improve our quality of life.",
      "offset": 7296.09,
      "duration": 2.41
    },
    {
      "lang": "en",
      "text": "Covering the downside is AI alignment\nresearch, and this kind of stuff,",
      "offset": 7298.79,
      "duration": 2.72
    },
    {
      "lang": "en",
      "text": "and automated testing, and really\nthinking hard about that, AI safety",
      "offset": 7301.51,
      "duration": 3.429
    },
    {
      "lang": "en",
      "text": "institutes and this kind of stuff.",
      "offset": 7304.94,
      "duration": 1.13
    },
    {
      "lang": "en",
      "text": "But these seem like things that a\nrandom rich person could also do.",
      "offset": 7306.32,
      "duration": 4.33
    },
    {
      "lang": "en",
      "text": "It seems like there's not a thing\nthat a nation state is uniquely",
      "offset": 7310.66,
      "duration": 7.24
    },
    {
      "lang": "en",
      "text": "equipped to do in this scenario.",
      "offset": 7317.91,
      "duration": 3.3
    },
    {
      "lang": "en",
      "text": "That's a good point.",
      "offset": 7321.21,
      "duration": 0.08
    },
    {
      "lang": "en",
      "text": "I mean dramatic allocation of resource\ntowards compute I think is sensible.",
      "offset": 7321.29,
      "duration": 4.76
    },
    {
      "lang": "en",
      "text": "I would be doing that if I was\nin charge of a nation state.",
      "offset": 7326.6,
      "duration": 1.89
    },
    {
      "lang": "en",
      "text": "I think it just increases your\noptionality in most of the future worlds.",
      "offset": 7328.49,
      "duration": 2.93
    },
    {
      "lang": "en",
      "text": "Dylan Patel has some scary\nforecasts on US energy.",
      "offset": 7332.64,
      "duration": 2.94
    },
    {
      "lang": "en",
      "text": "Versus China.",
      "offset": 7336.13,
      "duration": 0.53
    },
    {
      "lang": "en",
      "text": "Yes.\nYeah, we're like 34 gigawatts off.",
      "offset": 7336.67,
      "duration": 3.11
    },
    {
      "lang": "en",
      "text": "Yeah, the US's line is flat, basically,\nand China's line is like this.",
      "offset": 7339.84,
      "duration": 4.139
    },
    {
      "lang": "en",
      "text": "And I mean the US very clearly...",
      "offset": 7344.26,
      "duration": 2.43
    },
    {
      "lang": "en",
      "text": "We just need so many more power plants.",
      "offset": 7346.96,
      "duration": 1.51
    },
    {
      "lang": "en",
      "text": "Yes.",
      "offset": 7348.48,
      "duration": 0.4
    },
    {
      "lang": "en",
      "text": "If intelligence becomes this incredibly\nvaluable input, intelligence becomes",
      "offset": 7348.88,
      "duration": 4.139
    },
    {
      "lang": "en",
      "text": "almost a raw input into the economies\nand quality of life of the future, the",
      "offset": 7353.04,
      "duration": 4.389
    },
    {
      "lang": "en",
      "text": "thing directly underneath that is energy.",
      "offset": 7357.429,
      "duration": 1.851
    },
    {
      "lang": "en",
      "text": "Making sure that you have\nincredible amounts of solar,",
      "offset": 7360.949,
      "duration": 3.811
    },
    {
      "lang": "en",
      "text": "like tile the desert with solar\npanels, some parts of the desert.",
      "offset": 7364.81,
      "duration": 3.473
    },
    {
      "lang": "en",
      "text": "That would be helpful towards\nmaking sure that you have more",
      "offset": 7368.283,
      "duration": 5.056
    },
    {
      "lang": "en",
      "text": "access to intelligence on tap.",
      "offset": 7373.34,
      "duration": 1.179
    },
    {
      "lang": "en",
      "text": "Yeah.",
      "offset": 7375,
      "duration": 0.48
    },
    {
      "lang": "en",
      "text": "Just to make it explicit,\nwe've been touching on it here.",
      "offset": 7375.48,
      "duration": 2.81
    },
    {
      "lang": "en",
      "text": "Even if AI progress totally stalls, you\nthink that the models are really spiky,",
      "offset": 7378.949,
      "duration": 4.301
    },
    {
      "lang": "en",
      "text": "and they don't have general intelligence.",
      "offset": 7383.25,
      "duration": 1.84
    },
    {
      "lang": "en",
      "text": "It's so economically valuable, and\nsufficiently easy to collect data on",
      "offset": 7385.55,
      "duration": 4.58
    },
    {
      "lang": "en",
      "text": "all of these different jobs, these white\ncollar job tasks, such that to Sholto's",
      "offset": 7390.17,
      "duration": 5.37
    },
    {
      "lang": "en",
      "text": "point we should expect to see them\nautomated within the next five years.",
      "offset": 7395.549,
      "duration": 3.59
    },
    {
      "lang": "en",
      "text": "Yeah.",
      "offset": 7399.23,
      "duration": 0.5
    },
    {
      "lang": "en",
      "text": "Even if you need to hand spoon\nevery single task to the model.",
      "offset": 7400.09,
      "duration": 3.48
    },
    {
      "lang": "en",
      "text": "It's economically worthwhile to do so.",
      "offset": 7403.61,
      "duration": 1.51
    },
    {
      "lang": "en",
      "text": "Even if algorithmic progress stalls out,\nand we just never figure out how to keep",
      "offset": 7405.49,
      "duration": 6.32
    },
    {
      "lang": "en",
      "text": "progress going—which I don't think is\nthe case, that hasn't stalled out yet,",
      "offset": 7411.83,
      "duration": 2.999
    },
    {
      "lang": "en",
      "text": "it seems to be going great—the current\nsuite of algorithms are sufficient to",
      "offset": 7414.84,
      "duration": 4.679
    },
    {
      "lang": "en",
      "text": "automate white collar work provided you\nhave enough of the right kinds of data.",
      "offset": 7419.53,
      "duration": 3.72
    },
    {
      "lang": "en",
      "text": "Compared to the TAM of salaries\nfor all of those kinds of work,",
      "offset": 7424.92,
      "duration": 4.04
    },
    {
      "lang": "en",
      "text": "it is so trivially worthwhile.",
      "offset": 7428.96,
      "duration": 2.009
    },
    {
      "lang": "en",
      "text": "Yeah, exactly.",
      "offset": 7431.52,
      "duration": 0.93
    },
    {
      "lang": "en",
      "text": "I do just want to flag as well that\nthere's a really dystopian future if you",
      "offset": 7433.09,
      "duration": 4.9
    },
    {
      "lang": "en",
      "text": "take Moravec’s paradox to its extreme.",
      "offset": 7438.02,
      "duration": 2.07
    },
    {
      "lang": "en",
      "text": "It’s this paradox where we think that\nthe most valuable things that humans",
      "offset": 7440.37,
      "duration": 4.05
    },
    {
      "lang": "en",
      "text": "can do are the smartest things like\nadding large numbers in our heads, or",
      "offset": 7444.429,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "doing any sort of white collar work.",
      "offset": 7448.269,
      "duration": 2.011
    },
    {
      "lang": "en",
      "text": "We totally take for granted our\nfine motor skill, and coordination.",
      "offset": 7450.539,
      "duration": 3.161
    },
    {
      "lang": "en",
      "text": "But from an evolutionary\nperspective it's the opposite.",
      "offset": 7453.97,
      "duration": 2.2
    },
    {
      "lang": "en",
      "text": "Evolution has optimized fine\nmotor coordination so well.",
      "offset": 7458.03,
      "duration": 3.34
    },
    {
      "lang": "en",
      "text": "Even if you look at robot hands,\nthe ability to open a door is",
      "offset": 7461.38,
      "duration": 3.899
    },
    {
      "lang": "en",
      "text": "still just really hard for robots.",
      "offset": 7465.28,
      "duration": 1.929
    },
    {
      "lang": "en",
      "text": "Meanwhile, we're seeing this total\nautomation of coding, and everything",
      "offset": 7467.91,
      "duration": 3
    },
    {
      "lang": "en",
      "text": "else that we've seen as clever.",
      "offset": 7470.92,
      "duration": 1.31
    },
    {
      "lang": "en",
      "text": "The really scary future is one in which\nAIs can do everything except for the",
      "offset": 7472.64,
      "duration": 5.25
    },
    {
      "lang": "en",
      "text": "physical robotic tasks, in which case\nyou'll have humans with AirPods, and...",
      "offset": 7477.89,
      "duration": 5.159
    },
    {
      "lang": "en",
      "text": "Glasses?",
      "offset": 7483.349,
      "duration": 0.5
    },
    {
      "lang": "en",
      "text": "Glasses, and there'll be some robot\noverlord controlling the human through",
      "offset": 7484,
      "duration": 4.139
    },
    {
      "lang": "en",
      "text": "cameras by just telling it what to\ndo, and having a bounding box around",
      "offset": 7488.15,
      "duration": 3.59
    },
    {
      "lang": "en",
      "text": "the thing you're supposed to pick up.",
      "offset": 7491.74,
      "duration": 1.33
    },
    {
      "lang": "en",
      "text": "So you have human meat robots.",
      "offset": 7493.5,
      "duration": 1.58
    },
    {
      "lang": "en",
      "text": "Not necessarily saying that\nthat's what the AIs would want",
      "offset": 7495.29,
      "duration": 3.869
    },
    {
      "lang": "en",
      "text": "to do, or anything like that.",
      "offset": 7499.21,
      "duration": 1.699
    },
    {
      "lang": "en",
      "text": "But if you were to be like, &quot;What are\nthe relative economic value of things?&quot;",
      "offset": 7500.909,
      "duration": 2.47
    },
    {
      "lang": "en",
      "text": "The AIs are out there doing computer\nprogramming, and the most valuable thing",
      "offset": 7503.379,
      "duration": 2.73
    },
    {
      "lang": "en",
      "text": "that humans can do is be amazing robots.",
      "offset": 7506.109,
      "duration": 2.581
    },
    {
      "lang": "en",
      "text": "Now that being said, I think Moravec’s\nparadox is a little bit fake.",
      "offset": 7509.27,
      "duration": 2.2
    },
    {
      "lang": "en",
      "text": "I think the main reason that robots\nare worse at being a robot than they",
      "offset": 7512.65,
      "duration": 4.38
    },
    {
      "lang": "en",
      "text": "are at software engineering is the\ninternet exists for software engineering.",
      "offset": 7517.03,
      "duration": 3.02
    },
    {
      "lang": "en",
      "text": "GitHub exists, and there is\nno equivalent thing if you had",
      "offset": 7520.83,
      "duration": 4.33
    },
    {
      "lang": "en",
      "text": "all mocap of everyone's actions as\nthey were going about their daily",
      "offset": 7527.18,
      "duration": 4.459
    },
    {
      "lang": "en",
      "text": "lives for some reasonable fraction\nof the human population, robotics is",
      "offset": 7531.64,
      "duration": 3.959
    },
    {
      "lang": "en",
      "text": "also close to solved, on track to be\nsolved at the same rate that software",
      "offset": 7535.599,
      "duration": 4.58
    },
    {
      "lang": "en",
      "text": "engineering is on track to be solved.",
      "offset": 7540.18,
      "duration": 1.839
    },
    {
      "lang": "en",
      "text": "So, this vision is only a sort\nof decade-long section, but it's",
      "offset": 7542.86,
      "duration": 5.76
    },
    {
      "lang": "en",
      "text": "still a pretty terrible decade.",
      "offset": 7548.62,
      "duration": 1.33
    },
    {
      "lang": "en",
      "text": "Imagine the world where people\nhave lost their jobs, you haven't",
      "offset": 7550.65,
      "duration": 3.489
    },
    {
      "lang": "en",
      "text": "yet got novel biological research.",
      "offset": 7554.139,
      "duration": 1.531
    },
    {
      "lang": "en",
      "text": "That means people's quality of\nlife isn’t dramatically better.",
      "offset": 7555.67,
      "duration": 2.27
    },
    {
      "lang": "en",
      "text": "You don't yet have material\nabundance because you haven't",
      "offset": 7558.199,
      "duration": 3.411
    },
    {
      "lang": "en",
      "text": "actually been able to action the\nphysical world in the necessary way.",
      "offset": 7561.61,
      "duration": 5.09
    },
    {
      "lang": "en",
      "text": "You can't build dramatically more, because\nbuilding dramatically more takes robots",
      "offset": 7566.79,
      "duration": 4.64
    },
    {
      "lang": "en",
      "text": "basically, and people's main comparative\nadvantage is as fantastic robots.",
      "offset": 7571.43,
      "duration": 7.84
    },
    {
      "lang": "en",
      "text": "That’s a shocking, shocking world.",
      "offset": 7579.87,
      "duration": 1.44
    },
    {
      "lang": "en",
      "text": "Yeah.",
      "offset": 7582.64,
      "duration": 0.05
    },
    {
      "lang": "en",
      "text": "From the perspective of an average human,\nI think it actually might be better.",
      "offset": 7582.69,
      "duration": 2.02
    },
    {
      "lang": "en",
      "text": "Your wages will be higher because you're\nthe complement to something that is",
      "offset": 7584.87,
      "duration": 3.72
    },
    {
      "lang": "en",
      "text": "enormously valuable which is AI labor.",
      "offset": 7588.74,
      "duration": 2.37
    },
    {
      "lang": "en",
      "text": "And",
      "offset": 7591.13,
      "duration": 0.5
    },
    {
      "lang": "en",
      "text": "a decade, or two after,\nthe world is fantastic.",
      "offset": 7593.549,
      "duration": 2.13
    },
    {
      "lang": "en",
      "text": "Robotics is solved, and you decide\nto get radical abundance basically",
      "offset": 7598.15,
      "duration": 3.36
    },
    {
      "lang": "en",
      "text": "provided that you have all the policies\nset up necessary to permit building.",
      "offset": 7602.09,
      "duration": 3.23
    },
    {
      "lang": "en",
      "text": "You end up with that same\nchange like the before vs.",
      "offset": 7606.309,
      "duration": 3.96
    },
    {
      "lang": "en",
      "text": "after photos of Shanghai\nwhere 20 years on, it's this",
      "offset": 7610.269,
      "duration": 3.171
    },
    {
      "lang": "en",
      "text": "dramatically transformed city.",
      "offset": 7613.44,
      "duration": 1.17
    },
    {
      "lang": "en",
      "text": "A lot of places in the world probably end\nup like that over that two-decade period.",
      "offset": 7615.049,
      "duration": 4.251
    },
    {
      "lang": "en",
      "text": "But we need to",
      "offset": 7619.53,
      "duration": 1.189
    },
    {
      "lang": "en",
      "text": "do our best to estimate if this is\nactually what is on track to happen.",
      "offset": 7624.12,
      "duration": 3.61
    },
    {
      "lang": "en",
      "text": "Build SWE-bench, but for all\nthe other forms of white collar",
      "offset": 7628.389,
      "duration": 2.86
    },
    {
      "lang": "en",
      "text": "work, and measure, and track.",
      "offset": 7631.25,
      "duration": 1.519
    },
    {
      "lang": "en",
      "text": "That's a great thing that governments\nshould be doing by the way, trying",
      "offset": 7632.78,
      "duration": 2.74
    },
    {
      "lang": "en",
      "text": "to break down the functions of\ntheir economy into measurable tasks,",
      "offset": 7635.52,
      "duration": 4.74
    },
    {
      "lang": "en",
      "text": "and figuring out what does the\ncurve actually look like for that?",
      "offset": 7640.389,
      "duration": 3.18
    },
    {
      "lang": "en",
      "text": "They might be a bit shocked\nby the progress there.",
      "offset": 7643.98,
      "duration": 4.11
    },
    {
      "lang": "en",
      "text": "There's no SWE-bench for a tax eval.",
      "offset": 7648.09,
      "duration": 1.11
    },
    {
      "lang": "en",
      "text": "I don't have all the answers here,\nbut then we need to figure out a way",
      "offset": 7656.74,
      "duration": 2.51
    },
    {
      "lang": "en",
      "text": "to share the proceeds of this economy\nbroadly across people, or invest",
      "offset": 7659.25,
      "duration": 4.41
    },
    {
      "lang": "en",
      "text": "heavily in robotics, and collect the\ndata so that we get robotics faster,",
      "offset": 7663.66,
      "duration": 2.699
    },
    {
      "lang": "en",
      "text": "and we get material abundance faster.",
      "offset": 7666.359,
      "duration": 1.16
    },
    {
      "lang": "en",
      "text": "Invest in biological research\nthat we get, but all that faster.",
      "offset": 7667.529,
      "duration": 3.061
    },
    {
      "lang": "en",
      "text": "Basically try and pull forward the\nradical upside, because otherwise",
      "offset": 7670.87,
      "duration": 4.27
    },
    {
      "lang": "en",
      "text": "you have a pretty dark section.",
      "offset": 7675.14,
      "duration": 1.88
    },
    {
      "lang": "en",
      "text": "I think one thing that's not appreciated\nenough is how much of our leverage on the",
      "offset": 7677.57,
      "duration": 4.87
    },
    {
      "lang": "en",
      "text": "future—given the fact that our labor isn't\ngoing to be worth that much—comes from our",
      "offset": 7682.44,
      "duration": 5.18
    },
    {
      "lang": "en",
      "text": "economic, and political systems surviving.",
      "offset": 7687.62,
      "duration": 1.91
    },
    {
      "lang": "en",
      "text": "For your million X'd S&amp;P equity to\nmean something, for your contracts",
      "offset": 7690.88,
      "duration": 5.44
    },
    {
      "lang": "en",
      "text": "to mean anything, for the government\nto be able to tax the AI labor, and",
      "offset": 7696.32,
      "duration": 3.47
    },
    {
      "lang": "en",
      "text": "give you a UBI off of that, that\nrequires our legal institutions, our",
      "offset": 7699.79,
      "duration": 4.71
    },
    {
      "lang": "en",
      "text": "economic institutions, our financial\nrails surviving into the future.",
      "offset": 7704.5,
      "duration": 2.7
    },
    {
      "lang": "en",
      "text": "Yes.",
      "offset": 7707.23,
      "duration": 0.5
    },
    {
      "lang": "en",
      "text": "The way in which that likely happens\nis if it's also in the AIs best",
      "offset": 7707.95,
      "duration": 5.439
    },
    {
      "lang": "en",
      "text": "interests that they follow those rails.",
      "offset": 7713.389,
      "duration": 1.991
    },
    {
      "lang": "en",
      "text": "By AI I don't mean some monolithic\nsingle AI, I just mean firms which",
      "offset": 7715.389,
      "duration": 4.88
    },
    {
      "lang": "en",
      "text": "are employing AI, and becoming\nmore productive as a result.",
      "offset": 7720.27,
      "duration": 2.34
    },
    {
      "lang": "en",
      "text": "You don't want to be in a position\nwhere it's so onerous to operate in our",
      "offset": 7724.13,
      "duration": 4.86
    },
    {
      "lang": "en",
      "text": "system that you're basically selecting\nfor firms who either emigrate, or who",
      "offset": 7728.99,
      "duration": 5.6
    },
    {
      "lang": "en",
      "text": "are doing black market stuff, et cetera.",
      "offset": 7734.59,
      "duration": 2.719
    },
    {
      "lang": "en",
      "text": "You want to make it super, super easy\nto deploy AI, have the equivalent of",
      "offset": 7740.109,
      "duration": 4.991
    },
    {
      "lang": "en",
      "text": "special economic zones, et cetera.",
      "offset": 7745.1,
      "duration": 1.68
    },
    {
      "lang": "en",
      "text": "Otherwise you are just surrendering\nthe future outside of any control",
      "offset": 7748.61,
      "duration": 4.859
    },
    {
      "lang": "en",
      "text": "that you might have on it.",
      "offset": 7753.48,
      "duration": 1.68
    },
    {
      "lang": "en",
      "text": "One of the reasons that I worry about\nturning AGI into a national security",
      "offset": 7755.599,
      "duration": 6.791
    },
    {
      "lang": "en",
      "text": "issue, or having it have extremely\nclose ties with the government, the",
      "offset": 7762.39,
      "duration": 3.999
    },
    {
      "lang": "en",
      "text": "Manhattan Project thing, is that\nit disproportionately redirects",
      "offset": 7766.389,
      "duration": 3.821
    },
    {
      "lang": "en",
      "text": "the use of AI towards military\ntech, mosquito drones and whatever.",
      "offset": 7770.639,
      "duration": 4.951
    },
    {
      "lang": "en",
      "text": "It also naturally puts other\ncountries in the same frame of mind.",
      "offset": 7777.84,
      "duration": 3.94
    },
    {
      "lang": "en",
      "text": "If we're developing the mosquito\ndrones, why would China not",
      "offset": 7781.78,
      "duration": 2.319
    },
    {
      "lang": "en",
      "text": "develop the mosquito drones?",
      "offset": 7784.099,
      "duration": 1.21
    },
    {
      "lang": "en",
      "text": "That just seems like a zero-sum\nrace, and not to mention a",
      "offset": 7786.789,
      "duration": 3.23
    },
    {
      "lang": "en",
      "text": "potentially catastrophic one.",
      "offset": 7790.02,
      "duration": 1.36
    },
    {
      "lang": "en",
      "text": "Whereas",
      "offset": 7791.71,
      "duration": 0.53
    },
    {
      "lang": "en",
      "text": "compute will be limited, we'll need to\ndisproportionately accelerate some things.",
      "offset": 7794.449,
      "duration": 4.711
    },
    {
      "lang": "en",
      "text": "To the extent it just remains totally\nlike a consumer free market landscape,",
      "offset": 7799.48,
      "duration": 4.6
    },
    {
      "lang": "en",
      "text": "it just seems more likely that\nwe'll get the glorious transhumanist",
      "offset": 7804.309,
      "duration": 2.571
    },
    {
      "lang": "en",
      "text": "future where they're developing the\nthings that make human life better.",
      "offset": 7806.88,
      "duration": 3.319
    },
    {
      "lang": "en",
      "text": "Yes, I mean I agree.",
      "offset": 7810.43,
      "duration": 1.02
    },
    {
      "lang": "en",
      "text": "The case where you end up with two\nnational projects facing off against",
      "offset": 7811.879,
      "duration": 3.617
    },
    {
      "lang": "en",
      "text": "each other is dramatically worse.",
      "offset": 7815.496,
      "duration": 2.794
    },
    {
      "lang": "en",
      "text": "We don't want to live in that world.",
      "offset": 7818.43,
      "duration": 1
    },
    {
      "lang": "en",
      "text": "It's much better if this stays\na free market, so to speak.",
      "offset": 7819.43,
      "duration": 5.949
    },
    {
      "lang": "en",
      "text": "Okay.",
      "offset": 7826.009,
      "duration": 0.401
    },
    {
      "lang": "en",
      "text": "I want to take issue with your claim\nthat even with the algorithms of today,",
      "offset": 7826.41,
      "duration": 4.52
    },
    {
      "lang": "en",
      "text": "if we just collect enough data that\nwe could automate white collar work.",
      "offset": 7830.939,
      "duration": 3.761
    },
    {
      "lang": "en",
      "text": "First, let me get an understanding\nof what you mean by that.",
      "offset": 7834.83,
      "duration": 1.68
    },
    {
      "lang": "en",
      "text": "Do you mean that we would do the\nanalogous thing of pre-raining with",
      "offset": 7836.71,
      "duration": 3.92
    },
    {
      "lang": "en",
      "text": "all the trajectories of everything\npeople would do on their jobs?",
      "offset": 7840.63,
      "duration": 2.429
    },
    {
      "lang": "en",
      "text": "Could you make either manually, or\nthrough some other process, some",
      "offset": 7843.44,
      "duration": 6.63
    },
    {
      "lang": "en",
      "text": "RL procedure based on the screen\nrecordings, every white collar worker.",
      "offset": 7850.38,
      "duration": 2.78
    },
    {
      "lang": "en",
      "text": "What kind of thing are you imagining?",
      "offset": 7853.16,
      "duration": 0.979
    },
    {
      "lang": "en",
      "text": "I mean a continuous\ndistribution of this stuff.",
      "offset": 7854.28,
      "duration": 2.84
    },
    {
      "lang": "en",
      "text": "One important mental model to think",
      "offset": 7858.49,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "about RL… There is some respect\nwith which longer horizon, if you",
      "offset": 7865.089,
      "duration": 6.17
    },
    {
      "lang": "en",
      "text": "can do them, if you can get that\nreward ever, are easier to judge.",
      "offset": 7871.26,
      "duration": 3.45
    },
    {
      "lang": "en",
      "text": "Again, it's come back to that can\nyou make money on the internet?",
      "offset": 7876.61,
      "duration": 2.063
    },
    {
      "lang": "en",
      "text": "That's an incredibly easy\nreward signal to judge.",
      "offset": 7878.84,
      "duration": 2.76
    },
    {
      "lang": "en",
      "text": "But to do that there's a whole\nhierarchy of complex behavior.",
      "offset": 7882.779,
      "duration": 2.801
    },
    {
      "lang": "en",
      "text": "So, if you could pre-train up\nto the easy to judge reward",
      "offset": 7885.72,
      "duration": 2.85
    },
    {
      "lang": "en",
      "text": "signals, does your website work?",
      "offset": 7888.57,
      "duration": 1.21
    },
    {
      "lang": "en",
      "text": "Does it go down, do people like it?",
      "offset": 7889.78,
      "duration": 1.32
    },
    {
      "lang": "en",
      "text": "There's all these reward signals\nthat we can respond to because we",
      "offset": 7891.1,
      "duration": 3.85
    },
    {
      "lang": "en",
      "text": "have a long, we can progress through\nthese long enough trajectories to",
      "offset": 7894.96,
      "duration": 3.579
    },
    {
      "lang": "en",
      "text": "actually get to interesting things.",
      "offset": 7898.539,
      "duration": 1.831
    },
    {
      "lang": "en",
      "text": "If you're stuck in this regime where you\nneed a reward signal every five tokens,",
      "offset": 7900.619,
      "duration": 4.351
    },
    {
      "lang": "en",
      "text": "it's a way more painful, and long process.",
      "offset": 7905.36,
      "duration": 2.39
    },
    {
      "lang": "en",
      "text": "But if you could pre-train on every\nscreen in America, then probably the",
      "offset": 7908,
      "duration": 6.979
    },
    {
      "lang": "en",
      "text": "RL tasks that you can design are very\ndifferent from if you could only take",
      "offset": 7914.98,
      "duration": 5.87
    },
    {
      "lang": "en",
      "text": "the existing internet as it is today.",
      "offset": 7920.86,
      "duration": 1.55
    },
    {
      "lang": "en",
      "text": "How much of that you get\naccess to changes the mix.",
      "offset": 7924,
      "duration": 2.95
    },
    {
      "lang": "en",
      "text": "As we're training them on longer, and\nlonger horizon tasks, and it takes",
      "offset": 7928.21,
      "duration": 3.01
    },
    {
      "lang": "en",
      "text": "longer for them to get any signal on\nwhether they successfully complete",
      "offset": 7931.25,
      "duration": 3.379
    },
    {
      "lang": "en",
      "text": "the task, will that slow down progress\nbecause it takes more compute per task?",
      "offset": 7934.639,
      "duration": 3.9
    },
    {
      "lang": "en",
      "text": "I do think there's this notion\nthat the longer, the harder tasks,",
      "offset": 7938.7,
      "duration": 5.08
    },
    {
      "lang": "en",
      "text": "the more training is required.",
      "offset": 7943.83,
      "duration": 1.74
    },
    {
      "lang": "en",
      "text": "I'm sympathetic to that naively, but we\nas humans are very good at practicing the",
      "offset": 7946.83,
      "duration": 5.24
    },
    {
      "lang": "en",
      "text": "hard parts of tasks, and decomposing them.",
      "offset": 7952.07,
      "duration": 2.539
    },
    {
      "lang": "en",
      "text": "I think once models get good enough at the\nbasic stuff, they can just rehearse, or",
      "offset": 7955.16,
      "duration": 4.52
    },
    {
      "lang": "en",
      "text": "fast-forward to the more difficult parts.",
      "offset": 7959.68,
      "duration": 1.93
    },
    {
      "lang": "en",
      "text": "I mean that's definitely\none of the big complexities.",
      "offset": 7961.96,
      "duration": 2.01
    },
    {
      "lang": "en",
      "text": "As you use more compute, and as you\ntrain on more, and more difficult",
      "offset": 7963.97,
      "duration": 4.549
    },
    {
      "lang": "en",
      "text": "tasks, your rate of improvement of\nbiology for example is going to be",
      "offset": 7968.53,
      "duration": 3.649
    },
    {
      "lang": "en",
      "text": "somewhat bound by the time it takes a\ncell to grow in a way that your rate of",
      "offset": 7972.379,
      "duration": 4.853
    },
    {
      "lang": "en",
      "text": "improvement on math isn't, for example.",
      "offset": 7977.232,
      "duration": 1.798
    },
    {
      "lang": "en",
      "text": "So, yes, but I think for many things\nwe'll be able to parallelize widely",
      "offset": 7980.92,
      "duration": 6.04
    },
    {
      "lang": "en",
      "text": "enough, and get enough iteration loops.",
      "offset": 7986.96,
      "duration": 3.86
    },
    {
      "lang": "en",
      "text": "Will the regime of training\nnew models go away?",
      "offset": 7990.84,
      "duration": 4.53
    },
    {
      "lang": "en",
      "text": "Will we eventually get to the\npoint where you've got the model,",
      "offset": 7995.39,
      "duration": 2.83
    },
    {
      "lang": "en",
      "text": "and then you just keep adding more\nskills to it, with RL training?",
      "offset": 7998.22,
      "duration": 2.94
    },
    {
      "lang": "en",
      "text": "That depends on whether, or not\nyou think there's a virtue in",
      "offset": 8001.29,
      "duration": 4.419
    },
    {
      "lang": "en",
      "text": "pre-training a new architecture.",
      "offset": 8005.71,
      "duration": 1.42
    },
    {
      "lang": "en",
      "text": "Basically you make some architectural\nchange, then you probably need to do some",
      "offset": 8007.29,
      "duration": 5.479
    },
    {
      "lang": "en",
      "text": "form of at least pretraining a new model.",
      "offset": 8012.77,
      "duration": 2.01
    },
    {
      "lang": "en",
      "text": "If RL requires a bunch of inference to do\nthe training in the first place, does that",
      "offset": 8018.82,
      "duration": 3.659
    },
    {
      "lang": "en",
      "text": "push against the thing you were talking\nabout where we actually need a bigger",
      "offset": 8022.48,
      "duration": 2.409
    },
    {
      "lang": "en",
      "text": "model in order to have brain-like energy?",
      "offset": 8024.889,
      "duration": 2.261
    },
    {
      "lang": "en",
      "text": "But then also it's more\nexpensive to train it in RL.",
      "offset": 8027.16,
      "duration": 2.91
    },
    {
      "lang": "en",
      "text": "So, where does that balance out?",
      "offset": 8030.35,
      "duration": 1.87
    },
    {
      "lang": "en",
      "text": "I think we got to drink\nthe bitter lesson here.",
      "offset": 8032.72,
      "duration": 1.93
    },
    {
      "lang": "en",
      "text": "Yeah, there aren't infinite shortcuts.",
      "offset": 8035.41,
      "duration": 2.769
    },
    {
      "lang": "en",
      "text": "You do just have to scale\nand have a bigger model, and",
      "offset": 8038.349,
      "duration": 2.821
    },
    {
      "lang": "en",
      "text": "pay more inference for it.",
      "offset": 8041.17,
      "duration": 1.219
    },
    {
      "lang": "en",
      "text": "If you want AGI, then that's\nwhat you got to pay the price of.",
      "offset": 8043.46,
      "duration": 3.24
    },
    {
      "lang": "en",
      "text": "But there's a tradeoff equation here.",
      "offset": 8046.9,
      "duration": 1.64
    },
    {
      "lang": "en",
      "text": "There is science to do\nwhich everyone is doing.",
      "offset": 8049.89,
      "duration": 3.03
    },
    {
      "lang": "en",
      "text": "What is the optimal\npoint at which to do RL?",
      "offset": 8053.46,
      "duration": 2.91
    },
    {
      "lang": "en",
      "text": "Because you need something which\ncan both learn, and discover",
      "offset": 8056.61,
      "duration": 4.75
    },
    {
      "lang": "en",
      "text": "the sparse reward itself.",
      "offset": 8061.4,
      "duration": 1.489
    },
    {
      "lang": "en",
      "text": "So you don't want a one parameter model.",
      "offset": 8063,
      "duration": 1.18
    },
    {
      "lang": "en",
      "text": "Useless, even though you\ncan run it really fast.",
      "offset": 8064.33,
      "duration": 1.66
    },
    {
      "lang": "en",
      "text": "You also don't want a 100T model.",
      "offset": 8066.87,
      "duration": 1.93
    },
    {
      "lang": "en",
      "text": "It's super slow.",
      "offset": 8068.8,
      "duration": 1.04
    },
    {
      "lang": "en",
      "text": "The marginal benefit of its\nlearning efficiency is not worth it.",
      "offset": 8074.2,
      "duration": 3.179
    },
    {
      "lang": "en",
      "text": "So, there's a Pareto frontier here.",
      "offset": 8077.639,
      "duration": 1.7
    },
    {
      "lang": "en",
      "text": "What's the optimal model size of\nyour current class of capabilities,",
      "offset": 8079.679,
      "duration": 2.901
    },
    {
      "lang": "en",
      "text": "and your current set of RL\nenvironments, and this kind of stuff.",
      "offset": 8082.58,
      "duration": 2.16
    },
    {
      "lang": "en",
      "text": "And even in the last year\nthere's been much more of a",
      "offset": 8084.74,
      "duration": 3.55
    },
    {
      "lang": "en",
      "text": "factor of the inference cost.",
      "offset": 8088.29,
      "duration": 1.21
    },
    {
      "lang": "en",
      "text": "So, just explicitly the bigger the\nmodel, the more expensive it is to do",
      "offset": 8089.5,
      "duration": 4.49
    },
    {
      "lang": "en",
      "text": "a forward pass and generate tokens.",
      "offset": 8093.99,
      "duration": 1.399
    },
    {
      "lang": "en",
      "text": "The calculus used to just be, “Should\nI allocate my flops to more training",
      "offset": 8096.73,
      "duration": 4.45
    },
    {
      "lang": "en",
      "text": "data, or a bigger model?” And now\nanother huge factor is how much am I",
      "offset": 8101.18,
      "duration": 4.669
    },
    {
      "lang": "en",
      "text": "actually going to do forward passes\non this model once it's trained?",
      "offset": 8105.85,
      "duration": 2.38
    },
    {
      "lang": "en",
      "text": "My total pool of compute, how do\nI allocate that across training",
      "offset": 8108.559,
      "duration": 2.87
    },
    {
      "lang": "en",
      "text": "data compute, and inference\ncompute for the RL training.",
      "offset": 8111.429,
      "duration": 2.8
    },
    {
      "lang": "en",
      "text": "And then even within inference,\nthere's all this research on,",
      "offset": 8114.229,
      "duration": 2.57
    },
    {
      "lang": "en",
      "text": "well, what strategy should I use?",
      "offset": 8116.799,
      "duration": 2.131
    },
    {
      "lang": "en",
      "text": "Should I sample 10, and take the best?",
      "offset": 8118.94,
      "duration": 2.29
    },
    {
      "lang": "en",
      "text": "Do I do this sort of branching\nsearch, et cetera, et cetera.",
      "offset": 8121.23,
      "duration": 2.87
    },
    {
      "lang": "en",
      "text": "And so with RL where you're sampling\na whole lot of tokens, you also need",
      "offset": 8124.91,
      "duration": 4.43
    },
    {
      "lang": "en",
      "text": "to factor in the ability for the model\nto actually generate those tokens,",
      "offset": 8129.34,
      "duration": 2.91
    },
    {
      "lang": "en",
      "text": "and then learn, and get feedback.",
      "offset": 8132.25,
      "duration": 1.809
    },
    {
      "lang": "en",
      "text": "If we're living in this world, what\nis your advice to somebody early in",
      "offset": 8136.209,
      "duration": 4.801
    },
    {
      "lang": "en",
      "text": "their career, or a student in college?",
      "offset": 8141.01,
      "duration": 1.79
    },
    {
      "lang": "en",
      "text": "What should they be planning on doing?",
      "offset": 8142.8,
      "duration": 3.089
    },
    {
      "lang": "en",
      "text": "Once again, it's worth considering\nthe spectrum of possible worlds",
      "offset": 8148.33,
      "duration": 2.75
    },
    {
      "lang": "en",
      "text": "and preparing yourself for that.",
      "offset": 8151.08,
      "duration": 1.199
    },
    {
      "lang": "en",
      "text": "The action that I think is the highest EV\nin that case is that at a minimum you're",
      "offset": 8152.969,
      "duration": 7.281
    },
    {
      "lang": "en",
      "text": "about to get dramatically more leverage.",
      "offset": 8160.25,
      "duration": 1.35
    },
    {
      "lang": "en",
      "text": "You already have.",
      "offset": 8161.72,
      "duration": 0.919
    },
    {
      "lang": "en",
      "text": "Already the startups in YC are writing\nhuge amounts of their code with Claude.",
      "offset": 8163.339,
      "duration": 4.191
    },
    {
      "lang": "en",
      "text": "What challenges, what causes\ndo you want to change in the",
      "offset": 8170.029,
      "duration": 3.661
    },
    {
      "lang": "en",
      "text": "world with that added leverage?",
      "offset": 8173.69,
      "duration": 1.37
    },
    {
      "lang": "en",
      "text": "If you had 10 engineers at your\nbeck, and call, what would you do?",
      "offset": 8175.07,
      "duration": 3.26
    },
    {
      "lang": "en",
      "text": "If you had a company at your beck and\ncall, what would that enable you to do?",
      "offset": 8178.33,
      "duration": 3.399
    },
    {
      "lang": "en",
      "text": "What problems, and domains\nsuddenly become tractable?",
      "offset": 8182.2,
      "duration": 2.65
    },
    {
      "lang": "en",
      "text": "That's the world you want to prepare for.",
      "offset": 8184.99,
      "duration": 1.06
    },
    {
      "lang": "en",
      "text": "Now, that still requires\na lot of technical depth.",
      "offset": 8186.309,
      "duration": 1.79
    },
    {
      "lang": "en",
      "text": "Obviously there is the case where\nAI just becomes dramatically better",
      "offset": 8188.57,
      "duration": 2.48
    },
    {
      "lang": "en",
      "text": "than everyone at everything, but for\nat least a while there is… I think",
      "offset": 8191.07,
      "duration": 6.9
    },
    {
      "lang": "en",
      "text": "Jensen actually talked about this in\nan interview in an interesting way.",
      "offset": 8197.97,
      "duration": 2.15
    },
    {
      "lang": "en",
      "text": "He's like, &quot;I have a hundred thousand\ngeneral intelligences around me, and",
      "offset": 8200.12,
      "duration": 2.889
    },
    {
      "lang": "en",
      "text": "I'm still somewhat useful, because\nI’m there directing the values, and",
      "offset": 8203.03,
      "duration": 4.019
    },
    {
      "lang": "en",
      "text": "asking them to do things. I still have\nvalue even though I have a hundred",
      "offset": 8207.68,
      "duration": 4.06
    },
    {
      "lang": "en",
      "text": "thousand general intelligences.&quot;",
      "offset": 8211.74,
      "duration": 1.27
    },
    {
      "lang": "en",
      "text": "For many people, I think that will\nstill be true for a fair while.",
      "offset": 8213.48,
      "duration": 1.8
    },
    {
      "lang": "en",
      "text": "Then as the AIs get better, and better,\nand better, and so on, eventually, no.",
      "offset": 8216.4,
      "duration": 3.38
    },
    {
      "lang": "en",
      "text": "But again, prepare for the spectrum of\npossible worlds because in the event",
      "offset": 8219.799,
      "duration": 3.871
    },
    {
      "lang": "en",
      "text": "where we're just totally outcompeted,\nit doesn't matter what you do.",
      "offset": 8223.67,
      "duration": 2.799
    },
    {
      "lang": "en",
      "text": "In all the other worlds, it matters a lot.",
      "offset": 8226.78,
      "duration": 2.534
    },
    {
      "lang": "en",
      "text": "Get the technical depth, study\nbiology, study CS, study physics.",
      "offset": 8229.57,
      "duration": 3.77
    },
    {
      "lang": "en",
      "text": "Think hard about what challenges\nyou want to solve in the world.",
      "offset": 8233.35,
      "duration": 3.139
    },
    {
      "lang": "en",
      "text": "Yeah, that's a lot of topics.",
      "offset": 8236.599,
      "duration": 1.62
    },
    {
      "lang": "en",
      "text": "That's a lot of",
      "offset": 8239.629,
      "duration": 0.64
    },
    {
      "lang": "en",
      "text": "shit.\nYou can now.",
      "offset": 8242.799,
      "duration": 0.079
    },
    {
      "lang": "en",
      "text": "You can.\nIt's so much easier to learn.",
      "offset": 8242.878,
      "duration": 1.381
    },
    {
      "lang": "en",
      "text": "Everyone now has the\ninfinite perfect tutor.",
      "offset": 8244.469,
      "duration": 2.101
    },
    {
      "lang": "en",
      "text": "It's definitely been helpful to me.",
      "offset": 8246.67,
      "duration": 2.4
    },
    {
      "lang": "en",
      "text": "I would say some combination of: get\nrid of the sunk cost of your previous",
      "offset": 8249.639,
      "duration": 6.26
    },
    {
      "lang": "en",
      "text": "workflows, or expertise in order\nto evaluate what AI can do for you.",
      "offset": 8255.9,
      "duration": 6.849
    },
    {
      "lang": "en",
      "text": "Another way to put this, which is\nfun, is just be lazier in so much as",
      "offset": 8262.92,
      "duration": 4.34
    },
    {
      "lang": "en",
      "text": "you figure out the way that the agent\ncan do the things that are toilsome.",
      "offset": 8267.26,
      "duration": 3.06
    },
    {
      "lang": "en",
      "text": "Ultimately, you get to be lazier,\nbut in the short run, you need to",
      "offset": 8274.53,
      "duration": 2.69
    },
    {
      "lang": "en",
      "text": "critically think about the things\nyou're currently doing, and what an AI",
      "offset": 8277.22,
      "duration": 3.63
    },
    {
      "lang": "en",
      "text": "could actually be better at doing, and\nthen go, and try it, or explore it.",
      "offset": 8280.87,
      "duration": 3.84
    },
    {
      "lang": "en",
      "text": "Because I think there's still just\na lot of low-hanging fruit of people",
      "offset": 8285.549,
      "duration": 2.881
    },
    {
      "lang": "en",
      "text": "assuming, and not writing the full\nprompt, giving a few examples,",
      "offset": 8288.43,
      "duration": 4.56
    },
    {
      "lang": "en",
      "text": "connecting the right tools for your\nwork to be accelerated and automated.",
      "offset": 8293.429,
      "duration": 4.501
    },
    {
      "lang": "en",
      "text": "Yep, yep.",
      "offset": 8298.01,
      "duration": 0.59
    },
    {
      "lang": "en",
      "text": "There's also the sunk cost of feeling\nlike since you're not &quot;early to AI&quot;,",
      "offset": 8299.55,
      "duration": 4.58
    },
    {
      "lang": "en",
      "text": "that you've sort of missed the boat.",
      "offset": 8305.02,
      "duration": 1.529
    },
    {
      "lang": "en",
      "text": "I",
      "offset": 8306.599,
      "duration": 0.5
    },
    {
      "lang": "en",
      "text": "remember when GPT-3 came out…",
      "offset": 8310.879,
      "duration": 1.54
    },
    {
      "lang": "en",
      "text": "So backstory on the podcast, when\nI graduated college I was planning",
      "offset": 8312.58,
      "duration": 3.87
    },
    {
      "lang": "en",
      "text": "on doing some sort of AI wrapper\nstartup, and the podcast was",
      "offset": 8316.45,
      "duration": 4.71
    },
    {
      "lang": "en",
      "text": "just a gateway into doing that.",
      "offset": 8321.34,
      "duration": 1.719
    },
    {
      "lang": "en",
      "text": "I was trying out different things and at\nthe time I remember thinking, “oh, 3.5",
      "offset": 8323.059,
      "duration": 3.751
    },
    {
      "lang": "en",
      "text": "is out.” People were like, &quot;I'm so behind\non the startup scene here” or whatever.",
      "offset": 8327.36,
      "duration": 5.73
    },
    {
      "lang": "en",
      "text": "If I wanted to make my own wrapper…\nmaybe the idea of the wrapper was",
      "offset": 8333.1,
      "duration": 4.279
    },
    {
      "lang": "en",
      "text": "inadvisable in the first place.",
      "offset": 8337.379,
      "duration": 1.241
    },
    {
      "lang": "en",
      "text": "But every time feels early because if\nit's an exponentially growing process, and",
      "offset": 8338.629,
      "duration": 6.531
    },
    {
      "lang": "en",
      "text": "there are many things, many ideas which\nare only becoming possible now, right?",
      "offset": 8345.16,
      "duration": 2.98
    },
    {
      "lang": "en",
      "text": "Exactly.",
      "offset": 8348.5,
      "duration": 0.34
    },
    {
      "lang": "en",
      "text": "It's that product\nexponential I talked about.",
      "offset": 8348.84,
      "duration": 1.379
    },
    {
      "lang": "en",
      "text": "That's right.",
      "offset": 8350.219,
      "duration": 0.461
    },
    {
      "lang": "en",
      "text": "Products literally obsolete it.",
      "offset": 8350.68,
      "duration": 1.539
    },
    {
      "lang": "en",
      "text": "You need to constantly reinvent yourself\nto stay at the frontier of capabilities.",
      "offset": 8352.219,
      "duration": 3.711
    },
    {
      "lang": "en",
      "text": "Do you remember?",
      "offset": 8355.95,
      "duration": 0.859
    },
    {
      "lang": "en",
      "text": "I had a really shitty idea,\nand I gave you a call.",
      "offset": 8356.83,
      "duration": 2.279
    },
    {
      "lang": "en",
      "text": "I don’t remember what it was.",
      "offset": 8359.109,
      "duration": 0.541
    },
    {
      "lang": "en",
      "text": "I think it was",
      "offset": 8359.65,
      "duration": 1.01
    },
    {
      "lang": "en",
      "text": "like RAG for lawyers, or something.",
      "offset": 8362.69,
      "duration": 2.299
    },
    {
      "lang": "en",
      "text": "Anyways, I think one of our first\ninteractions was like, &quot;Hey, what do you",
      "offset": 8365.559,
      "duration": 3.396
    },
    {
      "lang": "en",
      "text": "think of this idea?&quot; And you were like,\n“I think the podcast sounds promising.”",
      "offset": 8368.955,
      "duration": 3.604
    },
    {
      "lang": "en",
      "text": "I was right.",
      "offset": 8376.23,
      "duration": 0.5
    },
    {
      "lang": "en",
      "text": "Which I appreciate.",
      "offset": 8377.52,
      "duration": 0.8
    },
    {
      "lang": "en",
      "text": "Yeah.",
      "offset": 8378.74,
      "duration": 0.5
    },
    {
      "lang": "en",
      "text": "I got slightly annoyed at a friend\nrecently who I think is really",
      "offset": 8380.4,
      "duration": 3.729
    },
    {
      "lang": "en",
      "text": "talented and clever and interested in\nAI but has pursued a biology route.",
      "offset": 8384.129,
      "duration": 4.631
    },
    {
      "lang": "en",
      "text": "I just kind of tried to shake them like,\n&quot;You can work on AI if you want to.&quot;",
      "offset": 8390.13,
      "duration": 5.239
    },
    {
      "lang": "en",
      "text": "Humans",
      "offset": 8397.559,
      "duration": 0.68
    },
    {
      "lang": "en",
      "text": "are biological general intelligences\nwhere a lot of the things of",
      "offset": 8400.92,
      "duration": 5.7
    },
    {
      "lang": "en",
      "text": "value are just very general.",
      "offset": 8406.629,
      "duration": 1.98
    },
    {
      "lang": "en",
      "text": "Whatever kind of specialization\nthat you've done maybe just",
      "offset": 8409.65,
      "duration": 5.379
    },
    {
      "lang": "en",
      "text": "doesn't matter that much.",
      "offset": 8415.03,
      "duration": 0.909
    },
    {
      "lang": "en",
      "text": "Again, it gets back to the sunk cost, but\nso many of the people, even my colleagues",
      "offset": 8416.179,
      "duration": 5.041
    },
    {
      "lang": "en",
      "text": "at Anthropic are excited about AI.",
      "offset": 8421.24,
      "duration": 2.319
    },
    {
      "lang": "en",
      "text": "They just don't let their\nprevious career be a blocker.",
      "offset": 8423.779,
      "duration": 3.01
    },
    {
      "lang": "en",
      "text": "Because they're just innately\nsmart, talented, driven, whatever",
      "offset": 8427.79,
      "duration": 4.46
    },
    {
      "lang": "en",
      "text": "else, they end up being very\nsuccessful and finding roles.",
      "offset": 8432.25,
      "duration": 3.65
    },
    {
      "lang": "en",
      "text": "It's not as if they were in AI forever.",
      "offset": 8435.91,
      "duration": 2.2
    },
    {
      "lang": "en",
      "text": "I mean, people have come from\ntotally different fields.",
      "offset": 8438.349,
      "duration": 2.211
    },
    {
      "lang": "en",
      "text": "Don't think that you need permission from\nsome abstract entity to get involved,",
      "offset": 8440.869,
      "duration": 7.64
    },
    {
      "lang": "en",
      "text": "and apply, and be able to contribute.",
      "offset": 8448.51,
      "duration": 1.55
    },
    {
      "lang": "en",
      "text": "If somebody wanted to be an AI\nresearcher right now, if you could give",
      "offset": 8450.76,
      "duration": 3.713
    },
    {
      "lang": "en",
      "text": "them an open problem, or the kind of\nopen problem that is very likely to",
      "offset": 8454.55,
      "duration": 4.36
    },
    {
      "lang": "en",
      "text": "be quite impressive, what would it be?",
      "offset": 8461.91,
      "duration": 1.56
    },
    {
      "lang": "en",
      "text": "I think that now that RL's come\nback, papers building on Andy",
      "offset": 8464.35,
      "duration": 6.83
    },
    {
      "lang": "en",
      "text": "Jones's “Scaling scaling laws\nfor board games” are interesting.",
      "offset": 8471.18,
      "duration": 3.8
    },
    {
      "lang": "en",
      "text": "Investigating these questions\nlike the ones you asked before.",
      "offset": 8479.14,
      "duration": 1.7
    },
    {
      "lang": "en",
      "text": "Is the model actually learning to\ndo more than its previous pass at K?",
      "offset": 8481.76,
      "duration": 3.91
    },
    {
      "lang": "en",
      "text": "Or is it just discovering\nthat… Exploring questions like",
      "offset": 8485.67,
      "duration": 3.3
    },
    {
      "lang": "en",
      "text": "that deeply are interesting,\nscaling laws for RL, basically.",
      "offset": 8488.97,
      "duration": 4.259
    },
    {
      "lang": "en",
      "text": "I'd be very curious to see how much\nthe marginal increase is in meta",
      "offset": 8493.23,
      "duration": 3.919
    },
    {
      "lang": "en",
      "text": "learning from a new task, or something.",
      "offset": 8497.15,
      "duration": 2.92
    },
    {
      "lang": "en",
      "text": "On that note, I think model diffing\nhas a bunch of opportunities.",
      "offset": 8500.9,
      "duration": 3.64
    },
    {
      "lang": "en",
      "text": "People say, &quot;Oh, we're not capturing\nall the features. There's all this",
      "offset": 8506.44,
      "duration": 3.129
    },
    {
      "lang": "en",
      "text": "stuff left on the table.&quot; What is\nthat stuff that's left on the table?",
      "offset": 8509.57,
      "duration": 2.479
    },
    {
      "lang": "en",
      "text": "If the model's jailbroken,",
      "offset": 8512.059,
      "duration": 0.93
    },
    {
      "lang": "en",
      "text": "is it using existing features\nthat you've identified?",
      "offset": 8516.11,
      "duration": 2.11
    },
    {
      "lang": "en",
      "text": "Is it only using the error\nterms that you haven't captured?",
      "offset": 8518.22,
      "duration": 2.22
    },
    {
      "lang": "en",
      "text": "I don't know.",
      "offset": 8520.45,
      "duration": 1.54
    },
    {
      "lang": "en",
      "text": "There's a lot here.",
      "offset": 8522,
      "duration": 0.82
    },
    {
      "lang": "en",
      "text": "I think MATS is great.",
      "offset": 8522.889,
      "duration": 1.12
    },
    {
      "lang": "en",
      "text": "The Anthropic fellowship\nhas been going really well.",
      "offset": 8524.28,
      "duration": 1.97
    },
    {
      "lang": "en",
      "text": "Goodfire,",
      "offset": 8526.33,
      "duration": 0.5
    },
    {
      "lang": "en",
      "text": "Anthropic invested in recently,\nthey're doing a lot of interpretability",
      "offset": 8528.77,
      "duration": 2.11
    },
    {
      "lang": "en",
      "text": "work, or just apply directly to us.",
      "offset": 8531.17,
      "duration": 2.019
    },
    {
      "lang": "en",
      "text": "Anything to get your equity up, huh?",
      "offset": 8533.209,
      "duration": 1.33
    },
    {
      "lang": "en",
      "text": "There's just so many\ninterpretability projects.",
      "offset": 8537.51,
      "duration": 1.85
    },
    {
      "lang": "en",
      "text": "There's so much low-hanging fruit,\nand we need more people, and I",
      "offset": 8540.33,
      "duration": 2.29
    },
    {
      "lang": "en",
      "text": "don't think we have much time.",
      "offset": 8542.62,
      "duration": 0.82
    },
    {
      "lang": "en",
      "text": "I also want to make a plug\nfor performance engineering.",
      "offset": 8544.05,
      "duration": 2.23
    },
    {
      "lang": "en",
      "text": "This is one of the best ways\nto demonstrate that you have",
      "offset": 8547.34,
      "duration": 5.09
    },
    {
      "lang": "en",
      "text": "the raw ability to do it.",
      "offset": 8552.53,
      "duration": 2.14
    },
    {
      "lang": "en",
      "text": "If you made an extremely efficient\ntransform implementation on TPU,",
      "offset": 8555.3,
      "duration": 4.5
    },
    {
      "lang": "en",
      "text": "or Trainium, or Incuda, then I think\nthere's a pretty high likelihood",
      "offset": 8561.98,
      "duration": 3.96
    },
    {
      "lang": "en",
      "text": "that you'll get a job offer.",
      "offset": 8565.94,
      "duration": 1.58
    },
    {
      "lang": "en",
      "text": "But there's a relatively small pool of\npeople that you can trust to completely",
      "offset": 8567.67,
      "duration": 4.68
    },
    {
      "lang": "en",
      "text": "own end-to-end the performance of a model.",
      "offset": 8572.35,
      "duration": 2.749
    },
    {
      "lang": "en",
      "text": "And if you have broad, deep electrical\nengineering skills, I think you",
      "offset": 8575.989,
      "duration": 5.271
    },
    {
      "lang": "en",
      "text": "can probably come up to speed\npretty fast on accelerator stuff.",
      "offset": 8581.26,
      "duration": 2.979
    },
    {
      "lang": "en",
      "text": "You can come up to speed reasonably\nfast and it teaches you a lot of good",
      "offset": 8584.399,
      "duration": 2.721
    },
    {
      "lang": "en",
      "text": "intuitions of the actual intricacies of\nwhat's going on in the models, which means",
      "offset": 8587.12,
      "duration": 3.01
    },
    {
      "lang": "en",
      "text": "that you're then very well-placed to think\nabout architecture and this kind of stuff.",
      "offset": 8590.13,
      "duration": 3.85
    },
    {
      "lang": "en",
      "text": "One of my favorite people in thinking\nabout architecture at Anthropic at the",
      "offset": 8594.21,
      "duration": 3.33
    },
    {
      "lang": "en",
      "text": "moment actually came from a heavy GPU\nkernel programming background and just",
      "offset": 8597.54,
      "duration": 3.19
    },
    {
      "lang": "en",
      "text": "knows the ins, and outs really deeply.",
      "offset": 8600.92,
      "duration": 1.26
    },
    {
      "lang": "en",
      "text": "He can think about the\ntrade-offs really well.",
      "offset": 8602.19,
      "duration": 2.149
    },
    {
      "lang": "en",
      "text": "This was fun guys.",
      "offset": 8604.339,
      "duration": 0.721
    },
    {
      "lang": "en",
      "text": "Thanks for doing it again.",
      "offset": 8605.8,
      "duration": 0.866
    },
    {
      "lang": "en",
      "text": "Great to be back.",
      "offset": 8606.666,
      "duration": 0.804
    }
  ],
  "cleanText": null,
  "dumpedAt": "2025-07-21T18:43:24.830Z"
}